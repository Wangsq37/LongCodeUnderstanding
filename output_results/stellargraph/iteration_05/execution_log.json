[
  {
    "command": "pytest",
    "success": false,
    "stdout": "============================= test session starts ==============================\nplatform linux -- Python 3.10.12, pytest-8.4.1, pluggy-1.6.0\nrootdir: /app/repo_to_process\nconfigfile: pytest.ini\ncollected 904 items\n\nscripts/test_demos.py F                                                  [  0%]\ntests/core/test_convert.py ............................................. [  5%]\n....                                                                     [  5%]\ntests/core/test_element_data.py .....E                                   [  6%]\ntests/core/test_experimental.py ...                                      [  6%]\ntests/core/test_graph.py .....F..............EE......................... [ 11%]\n...F.EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE [ 19%]\nEEEEEEEEEFFFFFFFFFF........FFFF...................EEFF.................. [ 27%]\n.....FF...F                                                              [ 28%]\ntests/core/test_indexed_array.py ...                                     [ 29%]\ntests/core/test_schema.py .....                                          [ 29%]\ntests/core/test_utils.py F...........                                    [ 31%]\ntests/data/test_biased_random_walker.py .FFFFEFFFFFFE                    [ 32%]\ntests/data/test_breadth_first_walker.py .FFFFFFFEEFF                     [ 33%]\ntests/data/test_directed_breadth_first_sampler.py .....EE..              [ 34%]\ntests/data/test_edge_splitter.py ...XX.....                              [ 35%]\ntests/data/test_epgm.py .........                                        [ 36%]\ntests/data/test_heterogeneous_breadth_first_walker.py .....E             [ 37%]\ntests/data/test_metapath_walker.py .FFFFFE                               [ 38%]\ntests/data/test_temporal_random_walker.py FF....F.F                      [ 39%]\ntests/data/test_uniform_random_walker.py .FFFFFE                         [ 40%]\ntests/data/test_unsupervised_sampler.py .FFFF.                           [ 40%]\ntests/datasets/test_datasets.py ......FF...........FFF..........F....... [ 45%]\n.                                                                        [ 45%]\ntests/interpretability/test_saliency_maps_gat.py F                       [ 45%]\ntests/interpretability/test_saliency_maps_gcn.py FF                      [ 45%]\ntests/layer/test_appnp.py .FFFFF..FFx                                    [ 46%]\ntests/layer/test_attri2vec.py ..FF                                       [ 47%]\ntests/layer/test_cluster_gcn.py .F...F                                   [ 48%]\ntests/layer/test_cluster_models.py FFF                                   [ 48%]\ntests/layer/test_deep_graph_infomax.py FFFFFFFFFFFssssFF.FF              [ 50%]\ntests/layer/test_gcn.py ...F.FFFF...Fx                                   [ 52%]\ntests/layer/test_gcn_lstm.py .....FFFEEEE                                [ 53%]\ntests/layer/test_graph_attention.py ..FF...........FF.F.F                [ 55%]\ntests/layer/test_graph_classification.py ..FFFFFF                        [ 56%]\ntests/layer/test_graphsage.py ...................FFFFFFFFFFF             [ 59%]\ntests/layer/test_hinsage.py .F.........F.......F                         [ 62%]\ntests/layer/test_knowledge_graph.py FFFFFFFFFFF....FFFFF                 [ 64%]\ntests/layer/test_link_inference.py ...........                           [ 65%]\ntests/layer/test_misc.py ...FF                                           [ 66%]\ntests/layer/test_node2vec.py ...F                                        [ 66%]\ntests/layer/test_ppnp.py .FF                                             [ 66%]\ntests/layer/test_rgcn.py ..FF.FFFF..FFxx                                 [ 68%]\ntests/layer/test_sort_pooling.py ......                                  [ 69%]\ntests/layer/test_watch_your_step.py .F..FFFF                             [ 70%]\ntests/mapper/test_adjacency_generators.py .............                  [ 71%]\ntests/mapper/test_benchmark_generators.py EEEEEE                         [ 72%]\ntests/mapper/test_cluster_gcn_node_mapper.py .....EEE.                   [ 73%]\ntests/mapper/test_corrupted.py .F.FFFFFFFFFFF                            [ 74%]\ntests/mapper/test_directed_node_generator.py ...                         [ 75%]\ntests/mapper/test_full_batch_generators.py ......................        [ 77%]\ntests/mapper/test_graphwave_generator.py .................               [ 79%]\ntests/mapper/test_knowledge_graph.py ..........                          [ 80%]\ntests/mapper/test_link_mappers.py .FF.F.FFFFF..F.........FF.....FF...... [ 84%]\n....FF.                                                                  [ 85%]\ntests/mapper/test_node_mappers.py ...FFFFFF.F............F.............. [ 89%]\n......                                                                   [ 90%]\ntests/mapper/test_padded_graph_generator.py .....................        [ 92%]\ntests/mapper/test_relational_node_mappers.py ...........                 [ 93%]\ntests/mapper/test_sliding.py .FFFFFFF                                    [ 94%]\ntests/reproducibility/test_deep_graph_infomax.py FFFFFFFs                [ 95%]\ntests/reproducibility/test_graphsage.py FFFFFF                           [ 96%]\ntests/test_aaa_on_gpu.py s                                               [ 96%]\ntests/test_calibration.py ...F..                                         [ 97%]\ntests/test_ensemble.py FFFFFFFFF                                         [ 98%]\ntests/test_losses.py .........                                           [ 99%]\ntests/test_random.py .                                                   [ 99%]\ntests/utils/test_hyperbolic.py .F..                                      [ 99%]\ntests/utils/test_version_validation.py ...                               [100%]\n--- Writing function-level test call chains report to report_functions.jsonl ---\nSuccessfully wrote 780 records to report_functions.jsonl\n\n--- Writing aggregated file-level test call chains report to report_files.jsonl ---\nSuccessfully wrote 59 records to report_files.jsonl\n\n--- End of Reports ---\n\n\n==================================== ERRORS ====================================\n_________ ERROR at setup of test_benchmark_external_id_index_from_iloc _________\nfile /app/repo_to_process/tests/core/test_element_data.py, line 45\n  def test_benchmark_external_id_index_from_iloc(benchmark):\nE       fixture 'benchmark' not found\n>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/app/repo_to_process/tests/core/test_element_data.py:45\n_______________ ERROR at setup of test_benchmark_graph_schema[1] _______________\nfile /app/repo_to_process/tests/core/test_graph.py, line 381\n  @pytest.mark.benchmark(group=\"StellarGraph create_graph_schema\")\n  @pytest.mark.parametrize(\"num_types\", [1, 4])\n  def test_benchmark_graph_schema(benchmark, num_types):\nE       fixture 'benchmark' not found\n>       available fixtures: allocation_benchmark, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, knowledge_graph, line_graph, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, rowframe_convert, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, weighted_hin\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/app/repo_to_process/tests/core/test_graph.py:381\n_______________ ERROR at setup of test_benchmark_graph_schema[4] _______________\nfile /app/repo_to_process/tests/core/test_graph.py, line 381\n  @pytest.mark.benchmark(group=\"StellarGraph create_graph_schema\")\n  @pytest.mark.parametrize(\"num_types\", [1, 4])\n  def test_benchmark_graph_schema(benchmark, num_types):\nE       fixture 'benchmark' not found\n>       available fixtures: allocation_benchmark, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, knowledge_graph, line_graph, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, rowframe_convert, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, weighted_hin\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/app/repo_to_process/tests/core/test_graph.py:381\n____________ ERROR at setup of test_benchmark_get_neighbours[False] ____________\nfile /app/repo_to_process/tests/core/test_graph.py, line 991\n  @pytest.mark.benchmark(group=\"StellarGraph neighbours\")\n  @pytest.mark.parametrize(\"use_ilocs\", [False, True])\n  def test_benchmark_get_neighbours(benchmark, use_ilocs):\nE       fixture 'benchmark' not found\n>       available fixtures: allocation_benchmark, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, knowledge_graph, line_graph, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, rowframe_convert, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, weighted_hin\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/app/repo_to_process/tests/core/test_graph.py:991\n____________ ERROR at setup of test_benchmark_get_neighbours[True] _____________\nfile /app/repo_to_process/tests/core/test_graph.py, line 991\n  @pytest.mark.benchmark(group=\"StellarGraph neighbours\")\n  @pytest.mark.parametrize(\"use_ilocs\", [False, True])\n  def test_benchmark_get_neighbours(benchmark, use_ilocs):\nE       fixture 'benchmark' not found\n>       available fixtures: allocation_benchmark, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, knowledge_graph, line_graph, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, rowframe_convert, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, weighted_hin\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/app/repo_to_process/tests/core/test_graph.py:991\n________ ERROR at setup of test_benchmark_get_features[10-infer-1-None] ________\nfile /app/repo_to_process/tests/core/test_graph.py, line 1006\n  @pytest.mark.benchmark(group=\"StellarGraph node features\")\n  @pytest.mark.parametrize(\"use_ilocs\", [None, False, True])\n  @pytest.mark.parametrize(\"num_types\", [1, 4])\n  @pytest.mark.parametrize(\"type_arg\", [\"infer\", \"specify\"])\n  @pytest.mark.parametrize(\"feature_size\", [10, 1000])\n  def test_benchmark_get_features(\nE       fixture 'benchmark' not found\n>       available fixtures: allocation_benchmark, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, knowledge_graph, line_graph, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, rowframe_convert, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, weighted_hin\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/app/repo_to_process/tests/core/test_graph.py:1006\n_______ ERROR at setup of test_benchmark_get_features[10-infer-1-False] ________\nfile /app/repo_to_process/tests/core/test_graph.py, line 1006\n  @pytest.mark.benchmark(group=\"StellarGraph node features\")\n  @pytest.mark.parametrize(\"use_ilocs\", [None, False, True])\n  @pytest.mark.parametrize(\"num_types\", [1, 4])\n  @pytest.mark.parametrize(\"type_arg\", [\"infer\", \"specify\"])\n  @pytest.mark.parametrize(\"feature_size\", [10, 1000])\n  def test_benchmark_get_features(\nE       fixture 'benchmark' not found\n>       available fixtures: allocation_benchmark, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, knowledge_graph, line_graph, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, rowframe_convert, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, weighted_hin\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/app/repo_to_process/tests/core/test_graph.py:1006\n________ ERROR at setup of test_benchmark_get_features[10-infer-1-True] ________\nfile /app/repo_to_process/tests/core/test_graph.py, line 1006\n  @pytest.mark.benchmark(group=\"StellarGraph node features\")\n  @pytest.mark.parametrize(\"use_ilocs\", [None, False, True])\n  @pytest.mark.parametrize(\"num_types\", [1, 4])\n  @pytest.mark.parametrize(\"type_arg\", [\"infer\", \"specify\"])\n  @pytest.mark.parametrize(\"feature_size\", [10, 1000])\n  def test_benchmark_get_features(\nE       fixture 'benchmark' not found\n>       available fixtures: allocation_benchmark, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, knowledge_graph, line_graph, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, rowframe_convert, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, weighted_hin\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/app/repo_to_process/tests/core/test_graph.py:1006\n________ ERROR at setup of test_benchmark_get_features[10-infer-4-None] ________\nfile /app/repo_to_process/tests/core/test_graph.py, line 1006\n  @pytest.mark.benchmark(group=\"StellarGraph node features\")\n  @pytest.mark.parametrize(\"use_ilocs\", [None, False, True])\n  @pytest.mark.parametrize(\"num_types\", [1, 4])\n  @pytest.mark.parametrize(\"type_arg\", [\"infer\", \"specify\"])\n  @pytest.mark.parametrize(\"feature_size\", [10, 1000])\n  def test_benchmark_get_features(\nE       fixture 'benchmark' not found\n>       available fixtures: allocation_benchmark, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, knowledge_graph, line_graph, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, rowframe_convert, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, weighted_hin\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/app/repo_to_process/tests/core/test_graph.py:1006\n_______ ERROR at setup of test_benchmark_get_features[10-infer-4-False] ________\nfile /app/repo_to_process/tests/core/test_graph.py, line 1006\n  @pytest.mark.benchmark(group=\"StellarGraph node features\")\n  @pytest.mark.parametrize(\"use_ilocs\", [None, False, True])\n  @pytest.mark.parametrize(\"num_types\", [1, 4])\n  @pytest.mark.parametrize(\"type_arg\", [\"infer\", \"specify\"])\n  @pytest.mark.parametrize(\"feature_size\", [10, 1000])\n  def test_benchmark_get_features(\nE       fixture 'benchmark' not found\n>       available fixtures: allocation_benchmark, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, knowledge_graph, line_graph, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, rowframe_convert, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, weighted_hin\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/app/repo_to_process/tests/core/test_graph.py:1006\n________ ERROR at setup of test_benchmark_get_features[10-infer-4-True] ________\nfile /app/repo_to_process/tests/core/test_graph.py, line 1006\n  @pytest.mark.benchmark(group=\"StellarGraph node features\")\n  @pytest.mark.parametrize(\"use_ilocs\", [None, False, True])\n  @pytest.mark.parametrize(\"num_types\", [1, 4])\n  @pytest.mark.parametrize(\"type_arg\", [\"infer\", \"specify\"])\n  @pytest.mark.parametrize(\"feature_size\", [10, 1000])\n  def test_benchmark_get_features(\nE       fixture 'benchmark' not found\n>       available fixtures: allocation_benchmark, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, knowledge_graph, line_graph, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, rowframe_convert, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, weighted_hin\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/app/repo_to_process/tests/core/test_graph.py:1006\n_______ ERROR at setup of test_benchmark_get_features[10-specify-1-None] _______\nfile /app/repo_to_process/tests/core/test_graph.py, line 1006\n  @pytest.mark.benchmark(group=\"StellarGraph node features\")\n  @pytest.mark.parametrize(\"use_ilocs\", [None, False, True])\n  @pytest.mark.parametrize(\"num_types\", [1, 4])\n  @pytest.mark.parametrize(\"type_arg\", [\"infer\", \"specify\"])\n  @pytest.mark.parametrize(\"feature_size\", [10, 1000])\n  def test_benchmark_get_features(\nE       fixture 'benchmark' not found\n>       available fixtures: allocation_benchmark, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, knowledge_graph, line_graph, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, rowframe_convert, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, weighted_hin\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/app/repo_to_process/tests/core/test_graph.py:1006\n______ ERROR at setup of test_benchmark_get_features[10-specify-1-False] _______\nfile /app/repo_to_process/tests/core/test_graph.py, line 1006\n  @pytest.mark.benchmark(group=\"StellarGraph node features\")\n  @pytest.mark.parametrize(\"use_ilocs\", [None, False, True])\n  @pytest.mark.parametrize(\"num_types\", [1, 4])\n  @pytest.mark.parametrize(\"type_arg\", [\"infer\", \"specify\"])\n  @pytest.mark.parametrize(\"feature_size\", [10, 1000])\n  def test_benchmark_get_features(\nE       fixture 'benchmark' not found\n>       available fixtures: allocation_benchmark, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, knowledge_graph, line_graph, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, rowframe_convert, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, weighted_hin\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/app/repo_to_process/tests/core/test_graph.py:1006\n_______ ERROR at setup of test_benchmark_get_features[10-specify-1-True] _______\nfile /app/repo_to_process/tests/core/test_graph.py, line 1006\n  @pytest.mark.benchmark(group=\"StellarGraph node features\")\n  @pytest.mark.parametrize(\"use_ilocs\", [None, False, True])\n  @pytest.mark.parametrize(\"num_types\", [1, 4])\n  @pytest.mark.parametrize(\"type_arg\", [\"infer\", \"specify\"])\n  @pytest.mark.parametrize(\"feature_size\", [10, 1000])\n  def test_benchmark_get_features(\nE       fixture 'benchmark' not found\n>       available fixtures: allocation_benchmark, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, knowledge_graph, line_graph, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, rowframe_convert, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, weighted_hin\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/app/repo_to_process/tests/core/test_graph.py:1006\n_______ ERROR at setup of test_benchmark_get_features[10-specify-4-None] _______\nfile /app/repo_to_process/tests/core/test_graph.py, line 1006\n  @pytest.mark.benchmark(group=\"StellarGraph node features\")\n  @pytest.mark.parametrize(\"use_ilocs\", [None, False, True])\n  @pytest.mark.parametrize(\"num_types\", [1, 4])\n  @pytest.mark.parametrize(\"type_arg\", [\"infer\", \"specify\"])\n  @pytest.mark.parametrize(\"feature_size\", [10, 1000])\n  def test_benchmark_get_features(\nE       fixture 'benchmark' not found\n>       available fixtures: allocation_benchmark, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, knowledge_graph, line_graph, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, rowframe_convert, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, weighted_hin\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/app/repo_to_process/tests/core/test_graph.py:1006\n______ ERROR at setup of test_benchmark_get_features[10-specify-4-False] _______\nfile /app/repo_to_process/tests/core/test_graph.py, line 1006\n  @pytest.mark.benchmark(group=\"StellarGraph node features\")\n  @pytest.mark.parametrize(\"use_ilocs\", [None, False, True])\n  @pytest.mark.parametrize(\"num_types\", [1, 4])\n  @pytest.mark.parametrize(\"type_arg\", [\"infer\", \"specify\"])\n  @pytest.mark.parametrize(\"feature_size\", [10, 1000])\n  def test_benchmark_get_features(\nE       fixture 'benchmark' not found\n>       available fixtures: allocation_benchmark, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, knowledge_graph, line_graph, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, rowframe_convert, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, weighted_hin\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/app/repo_to_process/tests/core/test_graph.py:1006\n_______ ERROR at setup of test_benchmark_get_features[10-specify-4-True] _______\nfile /app/repo_to_process/tests/core/test_graph.py, line 1006\n  @pytest.mark.benchmark(group=\"StellarGraph node features\")\n  @pytest.mark.parametrize(\"use_ilocs\", [None, False, True])\n  @pytest.mark.parametrize(\"num_types\", [1, 4])\n  @pytest.mark.parametrize(\"type_arg\", [\"infer\", \"specify\"])\n  @pytest.mark.parametrize(\"feature_size\", [10, 1000])\n  def test_benchmark_get_features(\nE       fixture 'benchmark' not found\n>       available fixtures: allocation_benchmark, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, knowledge_graph, line_graph, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, rowframe_convert, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, weighted_hin\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/app/repo_to_process/tests/core/test_graph.py:1006\n_______ ERROR at setup of test_benchmark_get_features[1000-infer-1-None] _______\nfile /app/repo_to_process/tests/core/test_graph.py, line 1006\n  @pytest.mark.benchmark(group=\"StellarGraph node features\")\n  @pytest.mark.parametrize(\"use_ilocs\", [None, False, True])\n  @pytest.mark.parametrize(\"num_types\", [1, 4])\n  @pytest.mark.parametrize(\"type_arg\", [\"infer\", \"specify\"])\n  @pytest.mark.parametrize(\"feature_size\", [10, 1000])\n  def test_benchmark_get_features(\nE       fixture 'benchmark' not found\n>       available fixtures: allocation_benchmark, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, knowledge_graph, line_graph, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, rowframe_convert, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, weighted_hin\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/app/repo_to_process/tests/core/test_graph.py:1006\n______ ERROR at setup of test_benchmark_get_features[1000-infer-1-False] _______\nfile /app/repo_to_process/tests/core/test_graph.py, line 1006\n  @pytest.mark.benchmark(group=\"StellarGraph node features\")\n  @pytest.mark.parametrize(\"use_ilocs\", [None, False, True])\n  @pytest.mark.parametrize(\"num_types\", [1, 4])\n  @pytest.mark.parametrize(\"type_arg\", [\"infer\", \"specify\"])\n  @pytest.mark.parametrize(\"feature_size\", [10, 1000])\n  def test_benchmark_get_features(\nE       fixture 'benchmark' not found\n>       available fixtures: allocation_benchmark, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, knowledge_graph, line_graph, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, rowframe_convert, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, weighted_hin\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/app/repo_to_process/tests/core/test_graph.py:1006\n_______ ERROR at setup of test_benchmark_get_features[1000-infer-1-True] _______\nfile /app/repo_to_process/tests/core/test_graph.py, line 1006\n  @pytest.mark.benchmark(group=\"StellarGraph node features\")\n  @pytest.mark.parametrize(\"use_ilocs\", [None, False, True])\n  @pytest.mark.parametrize(\"num_types\", [1, 4])\n  @pytest.mark.parametrize(\"type_arg\", [\"infer\", \"specify\"])\n  @pytest.mark.parametrize(\"feature_size\", [10, 1000])\n  def test_benchmark_get_features(\nE       fixture 'benchmark' not found\n>       available fixtures: allocation_benchmark, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, knowledge_graph, line_graph, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, rowframe_convert, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, weighted_hin\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/app/repo_to_process/tests/core/test_graph.py:1006\n_______ ERROR at setup of test_benchmark_get_features[1000-infer-4-None] _______\nfile /app/repo_to_process/tests/core/test_graph.py, line 1006\n  @pytest.mark.benchmark(group=\"StellarGraph node features\")\n  @pytest.mark.parametrize(\"use_ilocs\", [None, False, True])\n  @pytest.mark.parametrize(\"num_types\", [1, 4])\n  @pytest.mark.parametrize(\"type_arg\", [\"infer\", \"specify\"])\n  @pytest.mark.parametrize(\"feature_size\", [10, 1000])\n  def test_benchmark_get_features(\nE       fixture 'benchmark' not found\n>       available fixtures: allocation_benchmark, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, knowledge_graph, line_graph, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, rowframe_convert, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, weighted_hin\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/app/repo_to_process/tests/core/test_graph.py:1006\n______ ERROR at setup of test_benchmark_get_features[1000-infer-4-False] _______\nfile /app/repo_to_process/tests/core/test_graph.py, line 1006\n  @pytest.mark.benchmark(group=\"StellarGraph node features\")\n  @pytest.mark.parametrize(\"use_ilocs\", [None, False, True])\n  @pytest.mark.parametrize(\"num_types\", [1, 4])\n  @pytest.mark.parametrize(\"type_arg\", [\"infer\", \"specify\"])\n  @pytest.mark.parametrize(\"feature_size\", [10, 1000])\n  def test_benchmark_get_features(\nE       fixture 'benchmark' not found\n>       available fixtures: allocation_benchmark, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, knowledge_graph, line_graph, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, rowframe_convert, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, weighted_hin\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/app/repo_to_process/tests/core/test_graph.py:1006\n_______ ERROR at setup of test_benchmark_get_features[1000-infer-4-True] _______\nfile /app/repo_to_process/tests/core/test_graph.py, line 1006\n  @pytest.mark.benchmark(group=\"StellarGraph node features\")\n  @pytest.mark.parametrize(\"use_ilocs\", [None, False, True])\n  @pytest.mark.parametrize(\"num_types\", [1, 4])\n  @pytest.mark.parametrize(\"type_arg\", [\"infer\", \"specify\"])\n  @pytest.mark.parametrize(\"feature_size\", [10, 1000])\n  def test_benchmark_get_features(\nE       fixture 'benchmark' not found\n>       available fixtures: allocation_benchmark, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, knowledge_graph, line_graph, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, rowframe_convert, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, weighted_hin\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/app/repo_to_process/tests/core/test_graph.py:1006\n______ ERROR at setup of test_benchmark_get_features[1000-specify-1-None] ______\nfile /app/repo_to_process/tests/core/test_graph.py, line 1006\n  @pytest.mark.benchmark(group=\"StellarGraph node features\")\n  @pytest.mark.parametrize(\"use_ilocs\", [None, False, True])\n  @pytest.mark.parametrize(\"num_types\", [1, 4])\n  @pytest.mark.parametrize(\"type_arg\", [\"infer\", \"specify\"])\n  @pytest.mark.parametrize(\"feature_size\", [10, 1000])\n  def test_benchmark_get_features(\nE       fixture 'benchmark' not found\n>       available fixtures: allocation_benchmark, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, knowledge_graph, line_graph, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, rowframe_convert, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, weighted_hin\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/app/repo_to_process/tests/core/test_graph.py:1006\n_____ ERROR at setup of test_benchmark_get_features[1000-specify-1-False] ______\nfile /app/repo_to_process/tests/core/test_graph.py, line 1006\n  @pytest.mark.benchmark(group=\"StellarGraph node features\")\n  @pytest.mark.parametrize(\"use_ilocs\", [None, False, True])\n  @pytest.mark.parametrize(\"num_types\", [1, 4])\n  @pytest.mark.parametrize(\"type_arg\", [\"infer\", \"specify\"])\n  @pytest.mark.parametrize(\"feature_size\", [10, 1000])\n  def test_benchmark_get_features(\nE       fixture 'benchmark' not found\n>       available fixtures: allocation_benchmark, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, knowledge_graph, line_graph, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, rowframe_convert, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, weighted_hin\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/app/repo_to_process/tests/core/test_graph.py:1006\n______ ERROR at setup of test_benchmark_get_features[1000-specify-1-True] ______\nfile /app/repo_to_process/tests/core/test_graph.py, line 1006\n  @pytest.mark.benchmark(group=\"StellarGraph node features\")\n  @pytest.mark.parametrize(\"use_ilocs\", [None, False, True])\n  @pytest.mark.parametrize(\"num_types\", [1, 4])\n  @pytest.mark.parametrize(\"type_arg\", [\"infer\", \"specify\"])\n  @pytest.mark.parametrize(\"feature_size\", [10, 1000])\n  def test_benchmark_get_features(\nE       fixture 'benchmark' not found\n>       available fixtures: allocation_benchmark, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, knowledge_graph, line_graph, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, rowframe_convert, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, weighted_hin\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/app/repo_to_process/tests/core/test_graph.py:1006\n______ ERROR at setup of test_benchmark_get_features[1000-specify-4-None] ______\nfile /app/repo_to_process/tests/core/test_graph.py, line 1006\n  @pytest.mark.benchmark(group=\"StellarGraph node features\")\n  @pytest.mark.parametrize(\"use_ilocs\", [None, False, True])\n  @pytest.mark.parametrize(\"num_types\", [1, 4])\n  @pytest.mark.parametrize(\"type_arg\", [\"infer\", \"specify\"])\n  @pytest.mark.parametrize(\"feature_size\", [10, 1000])\n  def test_benchmark_get_features(\nE       fixture 'benchmark' not found\n>       available fixtures: allocation_benchmark, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, knowledge_graph, line_graph, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, rowframe_convert, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, weighted_hin\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/app/repo_to_process/tests/core/test_graph.py:1006\n_____ ERROR at setup of test_benchmark_get_features[1000-specify-4-False] ______\nfile /app/repo_to_process/tests/core/test_graph.py, line 1006\n  @pytest.mark.benchmark(group=\"StellarGraph node features\")\n  @pytest.mark.parametrize(\"use_ilocs\", [None, False, True])\n  @pytest.mark.parametrize(\"num_types\", [1, 4])\n  @pytest.mark.parametrize(\"type_arg\", [\"infer\", \"specify\"])\n  @pytest.mark.parametrize(\"feature_size\", [10, 1000])\n  def test_benchmark_get_features(\nE       fixture 'benchmark' not found\n>       available fixtures: allocation_benchmark, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, knowledge_graph, line_graph, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, rowframe_convert, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, weighted_hin\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/app/repo_to_process/tests/core/test_graph.py:1006\n______ ERROR at setup of test_benchmark_get_features[1000-specify-4-True] ______\nfile /app/repo_to_process/tests/core/test_graph.py, line 1006\n  @pytest.mark.benchmark(group=\"StellarGraph node features\")\n  @pytest.mark.parametrize(\"use_ilocs\", [None, False, True])\n  @pytest.mark.parametrize(\"num_types\", [1, 4])\n  @pytest.mark.parametrize(\"type_arg\", [\"infer\", \"specify\"])\n  @pytest.mark.parametrize(\"feature_size\", [10, 1000])\n  def test_benchmark_get_features(\nE       fixture 'benchmark' not found\n>       available fixtures: allocation_benchmark, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, knowledge_graph, line_graph, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, rowframe_convert, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, weighted_hin\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/app/repo_to_process/tests/core/test_graph.py:1006\n__________ ERROR at setup of test_benchmark_creation[None-0-0-pandas] __________\nfile /app/repo_to_process/tests/core/test_graph.py, line 1070\n  @pytest.mark.benchmark(group=\"StellarGraph creation (time)\")\n  @pytest.mark.parametrize(\"input_data\", [\"pandas\", \"rowframe\"])\n  # various element counts, to give an indication of the relationship\n  # between those and memory use (0,0 gives the overhead of the\n  # StellarGraph object itself, without any data)\n  @pytest.mark.parametrize(\"num_nodes,num_edges\", [(0, 0), (1000, 5000), (20000, 100000)])\n  # features or not, to capture their cost\n  @pytest.mark.parametrize(\"feature_size\", [None, 100])\n  def test_benchmark_creation(benchmark, input_data, feature_size, num_nodes, num_edges):\nE       fixture 'benchmark' not found\n>       available fixtures: allocation_benchmark, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, knowledge_graph, line_graph, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, rowframe_convert, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, weighted_hin\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/app/repo_to_process/tests/core/test_graph.py:1070\n_________ ERROR at setup of test_benchmark_creation[None-0-0-rowframe] _________\nfile /app/repo_to_process/tests/core/test_graph.py, line 1070\n  @pytest.mark.benchmark(group=\"StellarGraph creation (time)\")\n  @pytest.mark.parametrize(\"input_data\", [\"pandas\", \"rowframe\"])\n  # various element counts, to give an indication of the relationship\n  # between those and memory use (0,0 gives the overhead of the\n  # StellarGraph object itself, without any data)\n  @pytest.mark.parametrize(\"num_nodes,num_edges\", [(0, 0), (1000, 5000), (20000, 100000)])\n  # features or not, to capture their cost\n  @pytest.mark.parametrize(\"feature_size\", [None, 100])\n  def test_benchmark_creation(benchmark, input_data, feature_size, num_nodes, num_edges):\nE       fixture 'benchmark' not found\n>       available fixtures: allocation_benchmark, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, knowledge_graph, line_graph, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, rowframe_convert, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, weighted_hin\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/app/repo_to_process/tests/core/test_graph.py:1070\n_______ ERROR at setup of test_benchmark_creation[None-1000-5000-pandas] _______\nfile /app/repo_to_process/tests/core/test_graph.py, line 1070\n  @pytest.mark.benchmark(group=\"StellarGraph creation (time)\")\n  @pytest.mark.parametrize(\"input_data\", [\"pandas\", \"rowframe\"])\n  # various element counts, to give an indication of the relationship\n  # between those and memory use (0,0 gives the overhead of the\n  # StellarGraph object itself, without any data)\n  @pytest.mark.parametrize(\"num_nodes,num_edges\", [(0, 0), (1000, 5000), (20000, 100000)])\n  # features or not, to capture their cost\n  @pytest.mark.parametrize(\"feature_size\", [None, 100])\n  def test_benchmark_creation(benchmark, input_data, feature_size, num_nodes, num_edges):\nE       fixture 'benchmark' not found\n>       available fixtures: allocation_benchmark, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, knowledge_graph, line_graph, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, rowframe_convert, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, weighted_hin\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/app/repo_to_process/tests/core/test_graph.py:1070\n______ ERROR at setup of test_benchmark_creation[None-1000-5000-rowframe] ______\nfile /app/repo_to_process/tests/core/test_graph.py, line 1070\n  @pytest.mark.benchmark(group=\"StellarGraph creation (time)\")\n  @pytest.mark.parametrize(\"input_data\", [\"pandas\", \"rowframe\"])\n  # various element counts, to give an indication of the relationship\n  # between those and memory use (0,0 gives the overhead of the\n  # StellarGraph object itself, without any data)\n  @pytest.mark.parametrize(\"num_nodes,num_edges\", [(0, 0), (1000, 5000), (20000, 100000)])\n  # features or not, to capture their cost\n  @pytest.mark.parametrize(\"feature_size\", [None, 100])\n  def test_benchmark_creation(benchmark, input_data, feature_size, num_nodes, num_edges):\nE       fixture 'benchmark' not found\n>       available fixtures: allocation_benchmark, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, knowledge_graph, line_graph, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, rowframe_convert, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, weighted_hin\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/app/repo_to_process/tests/core/test_graph.py:1070\n_____ ERROR at setup of test_benchmark_creation[None-20000-100000-pandas] ______\nfile /app/repo_to_process/tests/core/test_graph.py, line 1070\n  @pytest.mark.benchmark(group=\"StellarGraph creation (time)\")\n  @pytest.mark.parametrize(\"input_data\", [\"pandas\", \"rowframe\"])\n  # various element counts, to give an indication of the relationship\n  # between those and memory use (0,0 gives the overhead of the\n  # StellarGraph object itself, without any data)\n  @pytest.mark.parametrize(\"num_nodes,num_edges\", [(0, 0), (1000, 5000), (20000, 100000)])\n  # features or not, to capture their cost\n  @pytest.mark.parametrize(\"feature_size\", [None, 100])\n  def test_benchmark_creation(benchmark, input_data, feature_size, num_nodes, num_edges):\nE       fixture 'benchmark' not found\n>       available fixtures: allocation_benchmark, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, knowledge_graph, line_graph, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, rowframe_convert, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, weighted_hin\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/app/repo_to_process/tests/core/test_graph.py:1070\n____ ERROR at setup of test_benchmark_creation[None-20000-100000-rowframe] _____\nfile /app/repo_to_process/tests/core/test_graph.py, line 1070\n  @pytest.mark.benchmark(group=\"StellarGraph creation (time)\")\n  @pytest.mark.parametrize(\"input_data\", [\"pandas\", \"rowframe\"])\n  # various element counts, to give an indication of the relationship\n  # between those and memory use (0,0 gives the overhead of the\n  # StellarGraph object itself, without any data)\n  @pytest.mark.parametrize(\"num_nodes,num_edges\", [(0, 0), (1000, 5000), (20000, 100000)])\n  # features or not, to capture their cost\n  @pytest.mark.parametrize(\"feature_size\", [None, 100])\n  def test_benchmark_creation(benchmark, input_data, feature_size, num_nodes, num_edges):\nE       fixture 'benchmark' not found\n>       available fixtures: allocation_benchmark, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, knowledge_graph, line_graph, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, rowframe_convert, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, weighted_hin\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/app/repo_to_process/tests/core/test_graph.py:1070\n__________ ERROR at setup of test_benchmark_creation[100-0-0-pandas] ___________\nfile /app/repo_to_process/tests/core/test_graph.py, line 1070\n  @pytest.mark.benchmark(group=\"StellarGraph creation (time)\")\n  @pytest.mark.parametrize(\"input_data\", [\"pandas\", \"rowframe\"])\n  # various element counts, to give an indication of the relationship\n  # between those and memory use (0,0 gives the overhead of the\n  # StellarGraph object itself, without any data)\n  @pytest.mark.parametrize(\"num_nodes,num_edges\", [(0, 0), (1000, 5000), (20000, 100000)])\n  # features or not, to capture their cost\n  @pytest.mark.parametrize(\"feature_size\", [None, 100])\n  def test_benchmark_creation(benchmark, input_data, feature_size, num_nodes, num_edges):\nE       fixture 'benchmark' not found\n>       available fixtures: allocation_benchmark, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, knowledge_graph, line_graph, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, rowframe_convert, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, weighted_hin\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/app/repo_to_process/tests/core/test_graph.py:1070\n_________ ERROR at setup of test_benchmark_creation[100-0-0-rowframe] __________\nfile /app/repo_to_process/tests/core/test_graph.py, line 1070\n  @pytest.mark.benchmark(group=\"StellarGraph creation (time)\")\n  @pytest.mark.parametrize(\"input_data\", [\"pandas\", \"rowframe\"])\n  # various element counts, to give an indication of the relationship\n  # between those and memory use (0,0 gives the overhead of the\n  # StellarGraph object itself, without any data)\n  @pytest.mark.parametrize(\"num_nodes,num_edges\", [(0, 0), (1000, 5000), (20000, 100000)])\n  # features or not, to capture their cost\n  @pytest.mark.parametrize(\"feature_size\", [None, 100])\n  def test_benchmark_creation(benchmark, input_data, feature_size, num_nodes, num_edges):\nE       fixture 'benchmark' not found\n>       available fixtures: allocation_benchmark, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, knowledge_graph, line_graph, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, rowframe_convert, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, weighted_hin\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/app/repo_to_process/tests/core/test_graph.py:1070\n_______ ERROR at setup of test_benchmark_creation[100-1000-5000-pandas] ________\nfile /app/repo_to_process/tests/core/test_graph.py, line 1070\n  @pytest.mark.benchmark(group=\"StellarGraph creation (time)\")\n  @pytest.mark.parametrize(\"input_data\", [\"pandas\", \"rowframe\"])\n  # various element counts, to give an indication of the relationship\n  # between those and memory use (0,0 gives the overhead of the\n  # StellarGraph object itself, without any data)\n  @pytest.mark.parametrize(\"num_nodes,num_edges\", [(0, 0), (1000, 5000), (20000, 100000)])\n  # features or not, to capture their cost\n  @pytest.mark.parametrize(\"feature_size\", [None, 100])\n  def test_benchmark_creation(benchmark, input_data, feature_size, num_nodes, num_edges):\nE       fixture 'benchmark' not found\n>       available fixtures: allocation_benchmark, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, knowledge_graph, line_graph, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, rowframe_convert, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, weighted_hin\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/app/repo_to_process/tests/core/test_graph.py:1070\n______ ERROR at setup of test_benchmark_creation[100-1000-5000-rowframe] _______\nfile /app/repo_to_process/tests/core/test_graph.py, line 1070\n  @pytest.mark.benchmark(group=\"StellarGraph creation (time)\")\n  @pytest.mark.parametrize(\"input_data\", [\"pandas\", \"rowframe\"])\n  # various element counts, to give an indication of the relationship\n  # between those and memory use (0,0 gives the overhead of the\n  # StellarGraph object itself, without any data)\n  @pytest.mark.parametrize(\"num_nodes,num_edges\", [(0, 0), (1000, 5000), (20000, 100000)])\n  # features or not, to capture their cost\n  @pytest.mark.parametrize(\"feature_size\", [None, 100])\n  def test_benchmark_creation(benchmark, input_data, feature_size, num_nodes, num_edges):\nE       fixture 'benchmark' not found\n>       available fixtures: allocation_benchmark, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, knowledge_graph, line_graph, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, rowframe_convert, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, weighted_hin\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/app/repo_to_process/tests/core/test_graph.py:1070\n______ ERROR at setup of test_benchmark_creation[100-20000-100000-pandas] ______\nfile /app/repo_to_process/tests/core/test_graph.py, line 1070\n  @pytest.mark.benchmark(group=\"StellarGraph creation (time)\")\n  @pytest.mark.parametrize(\"input_data\", [\"pandas\", \"rowframe\"])\n  # various element counts, to give an indication of the relationship\n  # between those and memory use (0,0 gives the overhead of the\n  # StellarGraph object itself, without any data)\n  @pytest.mark.parametrize(\"num_nodes,num_edges\", [(0, 0), (1000, 5000), (20000, 100000)])\n  # features or not, to capture their cost\n  @pytest.mark.parametrize(\"feature_size\", [None, 100])\n  def test_benchmark_creation(benchmark, input_data, feature_size, num_nodes, num_edges):\nE       fixture 'benchmark' not found\n>       available fixtures: allocation_benchmark, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, knowledge_graph, line_graph, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, rowframe_convert, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, weighted_hin\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/app/repo_to_process/tests/core/test_graph.py:1070\n_____ ERROR at setup of test_benchmark_creation[100-20000-100000-rowframe] _____\nfile /app/repo_to_process/tests/core/test_graph.py, line 1070\n  @pytest.mark.benchmark(group=\"StellarGraph creation (time)\")\n  @pytest.mark.parametrize(\"input_data\", [\"pandas\", \"rowframe\"])\n  # various element counts, to give an indication of the relationship\n  # between those and memory use (0,0 gives the overhead of the\n  # StellarGraph object itself, without any data)\n  @pytest.mark.parametrize(\"num_nodes,num_edges\", [(0, 0), (1000, 5000), (20000, 100000)])\n  # features or not, to capture their cost\n  @pytest.mark.parametrize(\"feature_size\", [None, 100])\n  def test_benchmark_creation(benchmark, input_data, feature_size, num_nodes, num_edges):\nE       fixture 'benchmark' not found\n>       available fixtures: allocation_benchmark, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, knowledge_graph, line_graph, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, rowframe_convert, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, weighted_hin\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/app/repo_to_process/tests/core/test_graph.py:1070\n____ ERROR at setup of test_allocation_benchmark_creation[None-0-0-pandas] _____\nfile /app/repo_to_process/tests/core/test_graph.py, line 1082\n  @pytest.mark.benchmark(group=\"StellarGraph creation (size)\", timer=snapshot)\n  @pytest.mark.parametrize(\"input_data\", [\"pandas\", \"rowframe\"])\n  @pytest.mark.parametrize(\"num_nodes,num_edges\", [(0, 0), (100, 200), (1000, 5000)])\n  @pytest.mark.parametrize(\"feature_size\", [None, 100])\n  def test_allocation_benchmark_creation(\nfile /app/repo_to_process/tests/test_utils/alloc.py, line 79\n  @pytest.fixture\n  def allocation_benchmark(request, benchmark):\nE       fixture 'benchmark' not found\n>       available fixtures: allocation_benchmark, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, knowledge_graph, line_graph, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, rowframe_convert, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, weighted_hin\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/app/repo_to_process/tests/test_utils/alloc.py:79\n___ ERROR at setup of test_allocation_benchmark_creation[None-0-0-rowframe] ____\nfile /app/repo_to_process/tests/core/test_graph.py, line 1082\n  @pytest.mark.benchmark(group=\"StellarGraph creation (size)\", timer=snapshot)\n  @pytest.mark.parametrize(\"input_data\", [\"pandas\", \"rowframe\"])\n  @pytest.mark.parametrize(\"num_nodes,num_edges\", [(0, 0), (100, 200), (1000, 5000)])\n  @pytest.mark.parametrize(\"feature_size\", [None, 100])\n  def test_allocation_benchmark_creation(\nfile /app/repo_to_process/tests/test_utils/alloc.py, line 79\n  @pytest.fixture\n  def allocation_benchmark(request, benchmark):\nE       fixture 'benchmark' not found\n>       available fixtures: allocation_benchmark, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, knowledge_graph, line_graph, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, rowframe_convert, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, weighted_hin\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/app/repo_to_process/tests/test_utils/alloc.py:79\n__ ERROR at setup of test_allocation_benchmark_creation[None-100-200-pandas] ___\nfile /app/repo_to_process/tests/core/test_graph.py, line 1082\n  @pytest.mark.benchmark(group=\"StellarGraph creation (size)\", timer=snapshot)\n  @pytest.mark.parametrize(\"input_data\", [\"pandas\", \"rowframe\"])\n  @pytest.mark.parametrize(\"num_nodes,num_edges\", [(0, 0), (100, 200), (1000, 5000)])\n  @pytest.mark.parametrize(\"feature_size\", [None, 100])\n  def test_allocation_benchmark_creation(\nfile /app/repo_to_process/tests/test_utils/alloc.py, line 79\n  @pytest.fixture\n  def allocation_benchmark(request, benchmark):\nE       fixture 'benchmark' not found\n>       available fixtures: allocation_benchmark, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, knowledge_graph, line_graph, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, rowframe_convert, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, weighted_hin\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/app/repo_to_process/tests/test_utils/alloc.py:79\n_ ERROR at setup of test_allocation_benchmark_creation[None-100-200-rowframe] __\nfile /app/repo_to_process/tests/core/test_graph.py, line 1082\n  @pytest.mark.benchmark(group=\"StellarGraph creation (size)\", timer=snapshot)\n  @pytest.mark.parametrize(\"input_data\", [\"pandas\", \"rowframe\"])\n  @pytest.mark.parametrize(\"num_nodes,num_edges\", [(0, 0), (100, 200), (1000, 5000)])\n  @pytest.mark.parametrize(\"feature_size\", [None, 100])\n  def test_allocation_benchmark_creation(\nfile /app/repo_to_process/tests/test_utils/alloc.py, line 79\n  @pytest.fixture\n  def allocation_benchmark(request, benchmark):\nE       fixture 'benchmark' not found\n>       available fixtures: allocation_benchmark, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, knowledge_graph, line_graph, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, rowframe_convert, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, weighted_hin\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/app/repo_to_process/tests/test_utils/alloc.py:79\n_ ERROR at setup of test_allocation_benchmark_creation[None-1000-5000-pandas] __\nfile /app/repo_to_process/tests/core/test_graph.py, line 1082\n  @pytest.mark.benchmark(group=\"StellarGraph creation (size)\", timer=snapshot)\n  @pytest.mark.parametrize(\"input_data\", [\"pandas\", \"rowframe\"])\n  @pytest.mark.parametrize(\"num_nodes,num_edges\", [(0, 0), (100, 200), (1000, 5000)])\n  @pytest.mark.parametrize(\"feature_size\", [None, 100])\n  def test_allocation_benchmark_creation(\nfile /app/repo_to_process/tests/test_utils/alloc.py, line 79\n  @pytest.fixture\n  def allocation_benchmark(request, benchmark):\nE       fixture 'benchmark' not found\n>       available fixtures: allocation_benchmark, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, knowledge_graph, line_graph, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, rowframe_convert, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, weighted_hin\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/app/repo_to_process/tests/test_utils/alloc.py:79\n_ ERROR at setup of test_allocation_benchmark_creation[None-1000-5000-rowframe] _\nfile /app/repo_to_process/tests/core/test_graph.py, line 1082\n  @pytest.mark.benchmark(group=\"StellarGraph creation (size)\", timer=snapshot)\n  @pytest.mark.parametrize(\"input_data\", [\"pandas\", \"rowframe\"])\n  @pytest.mark.parametrize(\"num_nodes,num_edges\", [(0, 0), (100, 200), (1000, 5000)])\n  @pytest.mark.parametrize(\"feature_size\", [None, 100])\n  def test_allocation_benchmark_creation(\nfile /app/repo_to_process/tests/test_utils/alloc.py, line 79\n  @pytest.fixture\n  def allocation_benchmark(request, benchmark):\nE       fixture 'benchmark' not found\n>       available fixtures: allocation_benchmark, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, knowledge_graph, line_graph, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, rowframe_convert, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, weighted_hin\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/app/repo_to_process/tests/test_utils/alloc.py:79\n_____ ERROR at setup of test_allocation_benchmark_creation[100-0-0-pandas] _____\nfile /app/repo_to_process/tests/core/test_graph.py, line 1082\n  @pytest.mark.benchmark(group=\"StellarGraph creation (size)\", timer=snapshot)\n  @pytest.mark.parametrize(\"input_data\", [\"pandas\", \"rowframe\"])\n  @pytest.mark.parametrize(\"num_nodes,num_edges\", [(0, 0), (100, 200), (1000, 5000)])\n  @pytest.mark.parametrize(\"feature_size\", [None, 100])\n  def test_allocation_benchmark_creation(\nfile /app/repo_to_process/tests/test_utils/alloc.py, line 79\n  @pytest.fixture\n  def allocation_benchmark(request, benchmark):\nE       fixture 'benchmark' not found\n>       available fixtures: allocation_benchmark, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, knowledge_graph, line_graph, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, rowframe_convert, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, weighted_hin\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/app/repo_to_process/tests/test_utils/alloc.py:79\n____ ERROR at setup of test_allocation_benchmark_creation[100-0-0-rowframe] ____\nfile /app/repo_to_process/tests/core/test_graph.py, line 1082\n  @pytest.mark.benchmark(group=\"StellarGraph creation (size)\", timer=snapshot)\n  @pytest.mark.parametrize(\"input_data\", [\"pandas\", \"rowframe\"])\n  @pytest.mark.parametrize(\"num_nodes,num_edges\", [(0, 0), (100, 200), (1000, 5000)])\n  @pytest.mark.parametrize(\"feature_size\", [None, 100])\n  def test_allocation_benchmark_creation(\nfile /app/repo_to_process/tests/test_utils/alloc.py, line 79\n  @pytest.fixture\n  def allocation_benchmark(request, benchmark):\nE       fixture 'benchmark' not found\n>       available fixtures: allocation_benchmark, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, knowledge_graph, line_graph, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, rowframe_convert, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, weighted_hin\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/app/repo_to_process/tests/test_utils/alloc.py:79\n___ ERROR at setup of test_allocation_benchmark_creation[100-100-200-pandas] ___\nfile /app/repo_to_process/tests/core/test_graph.py, line 1082\n  @pytest.mark.benchmark(group=\"StellarGraph creation (size)\", timer=snapshot)\n  @pytest.mark.parametrize(\"input_data\", [\"pandas\", \"rowframe\"])\n  @pytest.mark.parametrize(\"num_nodes,num_edges\", [(0, 0), (100, 200), (1000, 5000)])\n  @pytest.mark.parametrize(\"feature_size\", [None, 100])\n  def test_allocation_benchmark_creation(\nfile /app/repo_to_process/tests/test_utils/alloc.py, line 79\n  @pytest.fixture\n  def allocation_benchmark(request, benchmark):\nE       fixture 'benchmark' not found\n>       available fixtures: allocation_benchmark, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, knowledge_graph, line_graph, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, rowframe_convert, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, weighted_hin\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/app/repo_to_process/tests/test_utils/alloc.py:79\n__ ERROR at setup of test_allocation_benchmark_creation[100-100-200-rowframe] __\nfile /app/repo_to_process/tests/core/test_graph.py, line 1082\n  @pytest.mark.benchmark(group=\"StellarGraph creation (size)\", timer=snapshot)\n  @pytest.mark.parametrize(\"input_data\", [\"pandas\", \"rowframe\"])\n  @pytest.mark.parametrize(\"num_nodes,num_edges\", [(0, 0), (100, 200), (1000, 5000)])\n  @pytest.mark.parametrize(\"feature_size\", [None, 100])\n  def test_allocation_benchmark_creation(\nfile /app/repo_to_process/tests/test_utils/alloc.py, line 79\n  @pytest.fixture\n  def allocation_benchmark(request, benchmark):\nE       fixture 'benchmark' not found\n>       available fixtures: allocation_benchmark, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, knowledge_graph, line_graph, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, rowframe_convert, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, weighted_hin\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/app/repo_to_process/tests/test_utils/alloc.py:79\n__ ERROR at setup of test_allocation_benchmark_creation[100-1000-5000-pandas] __\nfile /app/repo_to_process/tests/core/test_graph.py, line 1082\n  @pytest.mark.benchmark(group=\"StellarGraph creation (size)\", timer=snapshot)\n  @pytest.mark.parametrize(\"input_data\", [\"pandas\", \"rowframe\"])\n  @pytest.mark.parametrize(\"num_nodes,num_edges\", [(0, 0), (100, 200), (1000, 5000)])\n  @pytest.mark.parametrize(\"feature_size\", [None, 100])\n  def test_allocation_benchmark_creation(\nfile /app/repo_to_process/tests/test_utils/alloc.py, line 79\n  @pytest.fixture\n  def allocation_benchmark(request, benchmark):\nE       fixture 'benchmark' not found\n>       available fixtures: allocation_benchmark, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, knowledge_graph, line_graph, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, rowframe_convert, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, weighted_hin\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/app/repo_to_process/tests/test_utils/alloc.py:79\n_ ERROR at setup of test_allocation_benchmark_creation[100-1000-5000-rowframe] _\nfile /app/repo_to_process/tests/core/test_graph.py, line 1082\n  @pytest.mark.benchmark(group=\"StellarGraph creation (size)\", timer=snapshot)\n  @pytest.mark.parametrize(\"input_data\", [\"pandas\", \"rowframe\"])\n  @pytest.mark.parametrize(\"num_nodes,num_edges\", [(0, 0), (100, 200), (1000, 5000)])\n  @pytest.mark.parametrize(\"feature_size\", [None, 100])\n  def test_allocation_benchmark_creation(\nfile /app/repo_to_process/tests/test_utils/alloc.py, line 79\n  @pytest.fixture\n  def allocation_benchmark(request, benchmark):\nE       fixture 'benchmark' not found\n>       available fixtures: allocation_benchmark, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, knowledge_graph, line_graph, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, rowframe_convert, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, weighted_hin\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/app/repo_to_process/tests/test_utils/alloc.py:79\n__ ERROR at setup of test_allocation_benchmark_creation_peak[None-0-0-pandas] __\nfile /app/repo_to_process/tests/core/test_graph.py, line 1094\n  @pytest.mark.benchmark(group=\"StellarGraph creation (peak)\", timer=peak)\n  @pytest.mark.parametrize(\"input_data\", [\"pandas\", \"rowframe\"])\n  @pytest.mark.parametrize(\"num_nodes,num_edges\", [(0, 0), (100, 200), (1000, 5000)])\n  @pytest.mark.parametrize(\"feature_size\", [None, 100])\n  def test_allocation_benchmark_creation_peak(\nfile /app/repo_to_process/tests/test_utils/alloc.py, line 79\n  @pytest.fixture\n  def allocation_benchmark(request, benchmark):\nE       fixture 'benchmark' not found\n>       available fixtures: allocation_benchmark, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, knowledge_graph, line_graph, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, rowframe_convert, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, weighted_hin\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/app/repo_to_process/tests/test_utils/alloc.py:79\n_ ERROR at setup of test_allocation_benchmark_creation_peak[None-0-0-rowframe] _\nfile /app/repo_to_process/tests/core/test_graph.py, line 1094\n  @pytest.mark.benchmark(group=\"StellarGraph creation (peak)\", timer=peak)\n  @pytest.mark.parametrize(\"input_data\", [\"pandas\", \"rowframe\"])\n  @pytest.mark.parametrize(\"num_nodes,num_edges\", [(0, 0), (100, 200), (1000, 5000)])\n  @pytest.mark.parametrize(\"feature_size\", [None, 100])\n  def test_allocation_benchmark_creation_peak(\nfile /app/repo_to_process/tests/test_utils/alloc.py, line 79\n  @pytest.fixture\n  def allocation_benchmark(request, benchmark):\nE       fixture 'benchmark' not found\n>       available fixtures: allocation_benchmark, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, knowledge_graph, line_graph, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, rowframe_convert, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, weighted_hin\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/app/repo_to_process/tests/test_utils/alloc.py:79\n_ ERROR at setup of test_allocation_benchmark_creation_peak[None-100-200-pandas] _\nfile /app/repo_to_process/tests/core/test_graph.py, line 1094\n  @pytest.mark.benchmark(group=\"StellarGraph creation (peak)\", timer=peak)\n  @pytest.mark.parametrize(\"input_data\", [\"pandas\", \"rowframe\"])\n  @pytest.mark.parametrize(\"num_nodes,num_edges\", [(0, 0), (100, 200), (1000, 5000)])\n  @pytest.mark.parametrize(\"feature_size\", [None, 100])\n  def test_allocation_benchmark_creation_peak(\nfile /app/repo_to_process/tests/test_utils/alloc.py, line 79\n  @pytest.fixture\n  def allocation_benchmark(request, benchmark):\nE       fixture 'benchmark' not found\n>       available fixtures: allocation_benchmark, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, knowledge_graph, line_graph, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, rowframe_convert, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, weighted_hin\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/app/repo_to_process/tests/test_utils/alloc.py:79\n_ ERROR at setup of test_allocation_benchmark_creation_peak[None-100-200-rowframe] _\nfile /app/repo_to_process/tests/core/test_graph.py, line 1094\n  @pytest.mark.benchmark(group=\"StellarGraph creation (peak)\", timer=peak)\n  @pytest.mark.parametrize(\"input_data\", [\"pandas\", \"rowframe\"])\n  @pytest.mark.parametrize(\"num_nodes,num_edges\", [(0, 0), (100, 200), (1000, 5000)])\n  @pytest.mark.parametrize(\"feature_size\", [None, 100])\n  def test_allocation_benchmark_creation_peak(\nfile /app/repo_to_process/tests/test_utils/alloc.py, line 79\n  @pytest.fixture\n  def allocation_benchmark(request, benchmark):\nE       fixture 'benchmark' not found\n>       available fixtures: allocation_benchmark, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, knowledge_graph, line_graph, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, rowframe_convert, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, weighted_hin\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/app/repo_to_process/tests/test_utils/alloc.py:79\n_ ERROR at setup of test_allocation_benchmark_creation_peak[None-1000-5000-pandas] _\nfile /app/repo_to_process/tests/core/test_graph.py, line 1094\n  @pytest.mark.benchmark(group=\"StellarGraph creation (peak)\", timer=peak)\n  @pytest.mark.parametrize(\"input_data\", [\"pandas\", \"rowframe\"])\n  @pytest.mark.parametrize(\"num_nodes,num_edges\", [(0, 0), (100, 200), (1000, 5000)])\n  @pytest.mark.parametrize(\"feature_size\", [None, 100])\n  def test_allocation_benchmark_creation_peak(\nfile /app/repo_to_process/tests/test_utils/alloc.py, line 79\n  @pytest.fixture\n  def allocation_benchmark(request, benchmark):\nE       fixture 'benchmark' not found\n>       available fixtures: allocation_benchmark, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, knowledge_graph, line_graph, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, rowframe_convert, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, weighted_hin\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/app/repo_to_process/tests/test_utils/alloc.py:79\n_ ERROR at setup of test_allocation_benchmark_creation_peak[None-1000-5000-rowframe] _\nfile /app/repo_to_process/tests/core/test_graph.py, line 1094\n  @pytest.mark.benchmark(group=\"StellarGraph creation (peak)\", timer=peak)\n  @pytest.mark.parametrize(\"input_data\", [\"pandas\", \"rowframe\"])\n  @pytest.mark.parametrize(\"num_nodes,num_edges\", [(0, 0), (100, 200), (1000, 5000)])\n  @pytest.mark.parametrize(\"feature_size\", [None, 100])\n  def test_allocation_benchmark_creation_peak(\nfile /app/repo_to_process/tests/test_utils/alloc.py, line 79\n  @pytest.fixture\n  def allocation_benchmark(request, benchmark):\nE       fixture 'benchmark' not found\n>       available fixtures: allocation_benchmark, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, knowledge_graph, line_graph, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, rowframe_convert, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, weighted_hin\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/app/repo_to_process/tests/test_utils/alloc.py:79\n__ ERROR at setup of test_allocation_benchmark_creation_peak[100-0-0-pandas] ___\nfile /app/repo_to_process/tests/core/test_graph.py, line 1094\n  @pytest.mark.benchmark(group=\"StellarGraph creation (peak)\", timer=peak)\n  @pytest.mark.parametrize(\"input_data\", [\"pandas\", \"rowframe\"])\n  @pytest.mark.parametrize(\"num_nodes,num_edges\", [(0, 0), (100, 200), (1000, 5000)])\n  @pytest.mark.parametrize(\"feature_size\", [None, 100])\n  def test_allocation_benchmark_creation_peak(\nfile /app/repo_to_process/tests/test_utils/alloc.py, line 79\n  @pytest.fixture\n  def allocation_benchmark(request, benchmark):\nE       fixture 'benchmark' not found\n>       available fixtures: allocation_benchmark, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, knowledge_graph, line_graph, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, rowframe_convert, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, weighted_hin\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/app/repo_to_process/tests/test_utils/alloc.py:79\n_ ERROR at setup of test_allocation_benchmark_creation_peak[100-0-0-rowframe] __\nfile /app/repo_to_process/tests/core/test_graph.py, line 1094\n  @pytest.mark.benchmark(group=\"StellarGraph creation (peak)\", timer=peak)\n  @pytest.mark.parametrize(\"input_data\", [\"pandas\", \"rowframe\"])\n  @pytest.mark.parametrize(\"num_nodes,num_edges\", [(0, 0), (100, 200), (1000, 5000)])\n  @pytest.mark.parametrize(\"feature_size\", [None, 100])\n  def test_allocation_benchmark_creation_peak(\nfile /app/repo_to_process/tests/test_utils/alloc.py, line 79\n  @pytest.fixture\n  def allocation_benchmark(request, benchmark):\nE       fixture 'benchmark' not found\n>       available fixtures: allocation_benchmark, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, knowledge_graph, line_graph, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, rowframe_convert, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, weighted_hin\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/app/repo_to_process/tests/test_utils/alloc.py:79\n_ ERROR at setup of test_allocation_benchmark_creation_peak[100-100-200-pandas] _\nfile /app/repo_to_process/tests/core/test_graph.py, line 1094\n  @pytest.mark.benchmark(group=\"StellarGraph creation (peak)\", timer=peak)\n  @pytest.mark.parametrize(\"input_data\", [\"pandas\", \"rowframe\"])\n  @pytest.mark.parametrize(\"num_nodes,num_edges\", [(0, 0), (100, 200), (1000, 5000)])\n  @pytest.mark.parametrize(\"feature_size\", [None, 100])\n  def test_allocation_benchmark_creation_peak(\nfile /app/repo_to_process/tests/test_utils/alloc.py, line 79\n  @pytest.fixture\n  def allocation_benchmark(request, benchmark):\nE       fixture 'benchmark' not found\n>       available fixtures: allocation_benchmark, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, knowledge_graph, line_graph, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, rowframe_convert, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, weighted_hin\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/app/repo_to_process/tests/test_utils/alloc.py:79\n_ ERROR at setup of test_allocation_benchmark_creation_peak[100-100-200-rowframe] _\nfile /app/repo_to_process/tests/core/test_graph.py, line 1094\n  @pytest.mark.benchmark(group=\"StellarGraph creation (peak)\", timer=peak)\n  @pytest.mark.parametrize(\"input_data\", [\"pandas\", \"rowframe\"])\n  @pytest.mark.parametrize(\"num_nodes,num_edges\", [(0, 0), (100, 200), (1000, 5000)])\n  @pytest.mark.parametrize(\"feature_size\", [None, 100])\n  def test_allocation_benchmark_creation_peak(\nfile /app/repo_to_process/tests/test_utils/alloc.py, line 79\n  @pytest.fixture\n  def allocation_benchmark(request, benchmark):\nE       fixture 'benchmark' not found\n>       available fixtures: allocation_benchmark, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, knowledge_graph, line_graph, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, rowframe_convert, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, weighted_hin\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/app/repo_to_process/tests/test_utils/alloc.py:79\n_ ERROR at setup of test_allocation_benchmark_creation_peak[100-1000-5000-pandas] _\nfile /app/repo_to_process/tests/core/test_graph.py, line 1094\n  @pytest.mark.benchmark(group=\"StellarGraph creation (peak)\", timer=peak)\n  @pytest.mark.parametrize(\"input_data\", [\"pandas\", \"rowframe\"])\n  @pytest.mark.parametrize(\"num_nodes,num_edges\", [(0, 0), (100, 200), (1000, 5000)])\n  @pytest.mark.parametrize(\"feature_size\", [None, 100])\n  def test_allocation_benchmark_creation_peak(\nfile /app/repo_to_process/tests/test_utils/alloc.py, line 79\n  @pytest.fixture\n  def allocation_benchmark(request, benchmark):\nE       fixture 'benchmark' not found\n>       available fixtures: allocation_benchmark, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, knowledge_graph, line_graph, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, rowframe_convert, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, weighted_hin\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/app/repo_to_process/tests/test_utils/alloc.py:79\n_ ERROR at setup of test_allocation_benchmark_creation_peak[100-1000-5000-rowframe] _\nfile /app/repo_to_process/tests/core/test_graph.py, line 1094\n  @pytest.mark.benchmark(group=\"StellarGraph creation (peak)\", timer=peak)\n  @pytest.mark.parametrize(\"input_data\", [\"pandas\", \"rowframe\"])\n  @pytest.mark.parametrize(\"num_nodes,num_edges\", [(0, 0), (100, 200), (1000, 5000)])\n  @pytest.mark.parametrize(\"feature_size\", [None, 100])\n  def test_allocation_benchmark_creation_peak(\nfile /app/repo_to_process/tests/test_utils/alloc.py, line 79\n  @pytest.fixture\n  def allocation_benchmark(request, benchmark):\nE       fixture 'benchmark' not found\n>       available fixtures: allocation_benchmark, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, knowledge_graph, line_graph, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, rowframe_convert, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, weighted_hin\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/app/repo_to_process/tests/test_utils/alloc.py:79\n_________ ERROR at setup of test_benchmark_adj_list[directed-100-200] __________\nfile /app/repo_to_process/tests/core/test_graph.py, line 1120\n  @pytest.mark.benchmark(group=\"StellarGraph adjacency lists (time)\")\n  @pytest.mark.parametrize(\n      \"num_nodes,num_edges\", [(100, 200), (1000, 5000), (20000, 100000)]\n  )\n  @pytest.mark.parametrize(\"force_adj_lists\", [\"directed\", \"undirected\"])\n  def test_benchmark_adj_list(benchmark, num_nodes, num_edges, force_adj_lists):\nE       fixture 'benchmark' not found\n>       available fixtures: allocation_benchmark, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, knowledge_graph, line_graph, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, rowframe_convert, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, weighted_hin\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/app/repo_to_process/tests/core/test_graph.py:1120\n________ ERROR at setup of test_benchmark_adj_list[directed-1000-5000] _________\nfile /app/repo_to_process/tests/core/test_graph.py, line 1120\n  @pytest.mark.benchmark(group=\"StellarGraph adjacency lists (time)\")\n  @pytest.mark.parametrize(\n      \"num_nodes,num_edges\", [(100, 200), (1000, 5000), (20000, 100000)]\n  )\n  @pytest.mark.parametrize(\"force_adj_lists\", [\"directed\", \"undirected\"])\n  def test_benchmark_adj_list(benchmark, num_nodes, num_edges, force_adj_lists):\nE       fixture 'benchmark' not found\n>       available fixtures: allocation_benchmark, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, knowledge_graph, line_graph, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, rowframe_convert, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, weighted_hin\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/app/repo_to_process/tests/core/test_graph.py:1120\n_______ ERROR at setup of test_benchmark_adj_list[directed-20000-100000] _______\nfile /app/repo_to_process/tests/core/test_graph.py, line 1120\n  @pytest.mark.benchmark(group=\"StellarGraph adjacency lists (time)\")\n  @pytest.mark.parametrize(\n      \"num_nodes,num_edges\", [(100, 200), (1000, 5000), (20000, 100000)]\n  )\n  @pytest.mark.parametrize(\"force_adj_lists\", [\"directed\", \"undirected\"])\n  def test_benchmark_adj_list(benchmark, num_nodes, num_edges, force_adj_lists):\nE       fixture 'benchmark' not found\n>       available fixtures: allocation_benchmark, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, knowledge_graph, line_graph, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, rowframe_convert, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, weighted_hin\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/app/repo_to_process/tests/core/test_graph.py:1120\n________ ERROR at setup of test_benchmark_adj_list[undirected-100-200] _________\nfile /app/repo_to_process/tests/core/test_graph.py, line 1120\n  @pytest.mark.benchmark(group=\"StellarGraph adjacency lists (time)\")\n  @pytest.mark.parametrize(\n      \"num_nodes,num_edges\", [(100, 200), (1000, 5000), (20000, 100000)]\n  )\n  @pytest.mark.parametrize(\"force_adj_lists\", [\"directed\", \"undirected\"])\n  def test_benchmark_adj_list(benchmark, num_nodes, num_edges, force_adj_lists):\nE       fixture 'benchmark' not found\n>       available fixtures: allocation_benchmark, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, knowledge_graph, line_graph, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, rowframe_convert, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, weighted_hin\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/app/repo_to_process/tests/core/test_graph.py:1120\n_______ ERROR at setup of test_benchmark_adj_list[undirected-1000-5000] ________\nfile /app/repo_to_process/tests/core/test_graph.py, line 1120\n  @pytest.mark.benchmark(group=\"StellarGraph adjacency lists (time)\")\n  @pytest.mark.parametrize(\n      \"num_nodes,num_edges\", [(100, 200), (1000, 5000), (20000, 100000)]\n  )\n  @pytest.mark.parametrize(\"force_adj_lists\", [\"directed\", \"undirected\"])\n  def test_benchmark_adj_list(benchmark, num_nodes, num_edges, force_adj_lists):\nE       fixture 'benchmark' not found\n>       available fixtures: allocation_benchmark, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, knowledge_graph, line_graph, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, rowframe_convert, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, weighted_hin\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/app/repo_to_process/tests/core/test_graph.py:1120\n______ ERROR at setup of test_benchmark_adj_list[undirected-20000-100000] ______\nfile /app/repo_to_process/tests/core/test_graph.py, line 1120\n  @pytest.mark.benchmark(group=\"StellarGraph adjacency lists (time)\")\n  @pytest.mark.parametrize(\n      \"num_nodes,num_edges\", [(100, 200), (1000, 5000), (20000, 100000)]\n  )\n  @pytest.mark.parametrize(\"force_adj_lists\", [\"directed\", \"undirected\"])\n  def test_benchmark_adj_list(benchmark, num_nodes, num_edges, force_adj_lists):\nE       fixture 'benchmark' not found\n>       available fixtures: allocation_benchmark, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, knowledge_graph, line_graph, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, rowframe_convert, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, weighted_hin\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/app/repo_to_process/tests/core/test_graph.py:1120\n____ ERROR at setup of test_allocation_benchmark_adj_list[directed-100-200] ____\nfile /app/repo_to_process/tests/core/test_graph.py, line 1129\n  @pytest.mark.benchmark(group=\"StellarGraph adjacency lists (size)\", timer=snapshot)\n  @pytest.mark.parametrize(\"num_nodes,num_edges\", [(100, 200), (1000, 5000)])\n  @pytest.mark.parametrize(\"force_adj_lists\", [\"directed\", \"undirected\"])\n  def test_allocation_benchmark_adj_list(\nfile /app/repo_to_process/tests/test_utils/alloc.py, line 79\n  @pytest.fixture\n  def allocation_benchmark(request, benchmark):\nE       fixture 'benchmark' not found\n>       available fixtures: allocation_benchmark, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, knowledge_graph, line_graph, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, rowframe_convert, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, weighted_hin\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/app/repo_to_process/tests/test_utils/alloc.py:79\n___ ERROR at setup of test_allocation_benchmark_adj_list[directed-1000-5000] ___\nfile /app/repo_to_process/tests/core/test_graph.py, line 1129\n  @pytest.mark.benchmark(group=\"StellarGraph adjacency lists (size)\", timer=snapshot)\n  @pytest.mark.parametrize(\"num_nodes,num_edges\", [(100, 200), (1000, 5000)])\n  @pytest.mark.parametrize(\"force_adj_lists\", [\"directed\", \"undirected\"])\n  def test_allocation_benchmark_adj_list(\nfile /app/repo_to_process/tests/test_utils/alloc.py, line 79\n  @pytest.fixture\n  def allocation_benchmark(request, benchmark):\nE       fixture 'benchmark' not found\n>       available fixtures: allocation_benchmark, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, knowledge_graph, line_graph, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, rowframe_convert, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, weighted_hin\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/app/repo_to_process/tests/test_utils/alloc.py:79\n___ ERROR at setup of test_allocation_benchmark_adj_list[undirected-100-200] ___\nfile /app/repo_to_process/tests/core/test_graph.py, line 1129\n  @pytest.mark.benchmark(group=\"StellarGraph adjacency lists (size)\", timer=snapshot)\n  @pytest.mark.parametrize(\"num_nodes,num_edges\", [(100, 200), (1000, 5000)])\n  @pytest.mark.parametrize(\"force_adj_lists\", [\"directed\", \"undirected\"])\n  def test_allocation_benchmark_adj_list(\nfile /app/repo_to_process/tests/test_utils/alloc.py, line 79\n  @pytest.fixture\n  def allocation_benchmark(request, benchmark):\nE       fixture 'benchmark' not found\n>       available fixtures: allocation_benchmark, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, knowledge_graph, line_graph, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, rowframe_convert, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, weighted_hin\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/app/repo_to_process/tests/test_utils/alloc.py:79\n__ ERROR at setup of test_allocation_benchmark_adj_list[undirected-1000-5000] __\nfile /app/repo_to_process/tests/core/test_graph.py, line 1129\n  @pytest.mark.benchmark(group=\"StellarGraph adjacency lists (size)\", timer=snapshot)\n  @pytest.mark.parametrize(\"num_nodes,num_edges\", [(100, 200), (1000, 5000)])\n  @pytest.mark.parametrize(\"force_adj_lists\", [\"directed\", \"undirected\"])\n  def test_allocation_benchmark_adj_list(\nfile /app/repo_to_process/tests/test_utils/alloc.py, line 79\n  @pytest.fixture\n  def allocation_benchmark(request, benchmark):\nE       fixture 'benchmark' not found\n>       available fixtures: allocation_benchmark, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, knowledge_graph, line_graph, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, rowframe_convert, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, weighted_hin\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/app/repo_to_process/tests/test_utils/alloc.py:79\n_ ERROR at setup of test_allocation_benchmark_adj_list_peak[directed-100-200] __\nfile /app/repo_to_process/tests/core/test_graph.py, line 1138\n  @pytest.mark.benchmark(group=\"StellarGraph adjacency lists (peak)\", timer=peak)\n  @pytest.mark.parametrize(\"num_nodes,num_edges\", [(100, 200), (1000, 5000)])\n  @pytest.mark.parametrize(\"force_adj_lists\", [\"directed\", \"undirected\"])\n  def test_allocation_benchmark_adj_list_peak(\nfile /app/repo_to_process/tests/test_utils/alloc.py, line 79\n  @pytest.fixture\n  def allocation_benchmark(request, benchmark):\nE       fixture 'benchmark' not found\n>       available fixtures: allocation_benchmark, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, knowledge_graph, line_graph, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, rowframe_convert, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, weighted_hin\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/app/repo_to_process/tests/test_utils/alloc.py:79\n_ ERROR at setup of test_allocation_benchmark_adj_list_peak[directed-1000-5000] _\nfile /app/repo_to_process/tests/core/test_graph.py, line 1138\n  @pytest.mark.benchmark(group=\"StellarGraph adjacency lists (peak)\", timer=peak)\n  @pytest.mark.parametrize(\"num_nodes,num_edges\", [(100, 200), (1000, 5000)])\n  @pytest.mark.parametrize(\"force_adj_lists\", [\"directed\", \"undirected\"])\n  def test_allocation_benchmark_adj_list_peak(\nfile /app/repo_to_process/tests/test_utils/alloc.py, line 79\n  @pytest.fixture\n  def allocation_benchmark(request, benchmark):\nE       fixture 'benchmark' not found\n>       available fixtures: allocation_benchmark, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, knowledge_graph, line_graph, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, rowframe_convert, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, weighted_hin\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/app/repo_to_process/tests/test_utils/alloc.py:79\n_ ERROR at setup of test_allocation_benchmark_adj_list_peak[undirected-100-200] _\nfile /app/repo_to_process/tests/core/test_graph.py, line 1138\n  @pytest.mark.benchmark(group=\"StellarGraph adjacency lists (peak)\", timer=peak)\n  @pytest.mark.parametrize(\"num_nodes,num_edges\", [(100, 200), (1000, 5000)])\n  @pytest.mark.parametrize(\"force_adj_lists\", [\"directed\", \"undirected\"])\n  def test_allocation_benchmark_adj_list_peak(\nfile /app/repo_to_process/tests/test_utils/alloc.py, line 79\n  @pytest.fixture\n  def allocation_benchmark(request, benchmark):\nE       fixture 'benchmark' not found\n>       available fixtures: allocation_benchmark, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, knowledge_graph, line_graph, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, rowframe_convert, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, weighted_hin\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/app/repo_to_process/tests/test_utils/alloc.py:79\n_ ERROR at setup of test_allocation_benchmark_adj_list_peak[undirected-1000-5000] _\nfile /app/repo_to_process/tests/core/test_graph.py, line 1138\n  @pytest.mark.benchmark(group=\"StellarGraph adjacency lists (peak)\", timer=peak)\n  @pytest.mark.parametrize(\"num_nodes,num_edges\", [(100, 200), (1000, 5000)])\n  @pytest.mark.parametrize(\"force_adj_lists\", [\"directed\", \"undirected\"])\n  def test_allocation_benchmark_adj_list_peak(\nfile /app/repo_to_process/tests/test_utils/alloc.py, line 79\n  @pytest.fixture\n  def allocation_benchmark(request, benchmark):\nE       fixture 'benchmark' not found\n>       available fixtures: allocation_benchmark, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, knowledge_graph, line_graph, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, rowframe_convert, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, weighted_hin\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/app/repo_to_process/tests/test_utils/alloc.py:79\n_________ ERROR at setup of test_benchmark_to_adjacency_matrix[False] __________\nfile /app/repo_to_process/tests/core/test_graph.py, line 1996\n  @pytest.mark.benchmark(group=\"StellarGraph to_adjacency_matrix\")\n  @pytest.mark.parametrize(\"is_directed\", [False, True])\n  def test_benchmark_to_adjacency_matrix(is_directed, benchmark):\nE       fixture 'benchmark' not found\n>       available fixtures: allocation_benchmark, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, knowledge_graph, line_graph, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, rowframe_convert, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, weighted_hin\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/app/repo_to_process/tests/core/test_graph.py:1996\n__________ ERROR at setup of test_benchmark_to_adjacency_matrix[True] __________\nfile /app/repo_to_process/tests/core/test_graph.py, line 1996\n  @pytest.mark.benchmark(group=\"StellarGraph to_adjacency_matrix\")\n  @pytest.mark.parametrize(\"is_directed\", [False, True])\n  def test_benchmark_to_adjacency_matrix(is_directed, benchmark):\nE       fixture 'benchmark' not found\n>       available fixtures: allocation_benchmark, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, knowledge_graph, line_graph, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, rowframe_convert, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, weighted_hin\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/app/repo_to_process/tests/core/test_graph.py:1996\n_ ERROR at setup of TestBiasedWeightedRandomWalk.test_benchmark_biasedweightedrandomwalk _\nfile /app/repo_to_process/tests/data/test_biased_random_walker.py, line 228\n      def test_benchmark_biasedweightedrandomwalk(self, benchmark):\nE       fixture 'benchmark' not found\n>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/app/repo_to_process/tests/data/test_biased_random_walker.py:228\n____ ERROR at setup of TestBiasedRandomWalk.test_benchmark_biasedrandomwalk ____\nfile /app/repo_to_process/tests/data/test_biased_random_walker.py, line 546\n      def test_benchmark_biasedrandomwalk(self, benchmark):\nE       fixture 'benchmark' not found\n>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/app/repo_to_process/tests/data/test_biased_random_walker.py:546\n____ ERROR at setup of TestBreadthFirstWalk.test_benchmark_bfs_walk[False] _____\nfile /app/repo_to_process/tests/data/test_breadth_first_walker.py, line 547\n      @pytest.mark.parametrize(\"weighted\", [False, True])\n      def test_benchmark_bfs_walk(self, benchmark, weighted):\nE       fixture 'benchmark' not found\n>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, tree_graph\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/app/repo_to_process/tests/data/test_breadth_first_walker.py:547\n_____ ERROR at setup of TestBreadthFirstWalk.test_benchmark_bfs_walk[True] _____\nfile /app/repo_to_process/tests/data/test_breadth_first_walker.py, line 547\n      @pytest.mark.parametrize(\"weighted\", [False, True])\n      def test_benchmark_bfs_walk(self, benchmark, weighted):\nE       fixture 'benchmark' not found\n>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, tree_graph\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/app/repo_to_process/tests/data/test_breadth_first_walker.py:547\n_ ERROR at setup of TestDirectedBreadthFirstNeighbours.test_benchmark_bfs_walk[False] _\nfile /app/repo_to_process/tests/data/test_directed_breadth_first_sampler.py, line 238\n      @pytest.mark.parametrize(\"weighted\", [False, True])\n      def test_benchmark_bfs_walk(self, benchmark, weighted):\nE       fixture 'benchmark' not found\n>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, tree_graph\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/app/repo_to_process/tests/data/test_directed_breadth_first_sampler.py:238\n_ ERROR at setup of TestDirectedBreadthFirstNeighbours.test_benchmark_bfs_walk[True] _\nfile /app/repo_to_process/tests/data/test_directed_breadth_first_sampler.py, line 238\n      @pytest.mark.parametrize(\"weighted\", [False, True])\n      def test_benchmark_bfs_walk(self, benchmark, weighted):\nE       fixture 'benchmark' not found\n>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, tree_graph\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/app/repo_to_process/tests/data/test_directed_breadth_first_sampler.py:238\n_ ERROR at setup of TestSampledHeterogeneousBreadthFirstWalk.test_benchmark_sampledheterogeneousbreadthfirstwalk _\nfile /app/repo_to_process/tests/data/test_heterogeneous_breadth_first_walker.py, line 534\n      def test_benchmark_sampledheterogeneousbreadthfirstwalk(self, benchmark):\nE       fixture 'benchmark' not found\n>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/app/repo_to_process/tests/data/test_heterogeneous_breadth_first_walker.py:534\n_ ERROR at setup of TestMetaPathWalk.test_benchmark_uniformrandommetapathwalk __\nfile /app/repo_to_process/tests/data/test_metapath_walker.py, line 320\n      def test_benchmark_uniformrandommetapathwalk(self, benchmark):\nE       fixture 'benchmark' not found\n>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/app/repo_to_process/tests/data/test_metapath_walker.py:320\n___ ERROR at setup of TestUniformRandomWalk.test_benchmark_uniformrandomwalk ___\nfile /app/repo_to_process/tests/data/test_uniform_random_walker.py, line 241\n      def test_benchmark_uniformrandomwalk(self, benchmark):\nE       fixture 'benchmark' not found\n>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/app/repo_to_process/tests/data/test_uniform_random_walker.py:241\n____________ ERROR at setup of test_gcn_lstm_generator[univariate] _____________\n\nrequest = <SubRequest 'arange_graph' for <Function test_gcn_lstm_generator[univariate]>>\n\n    @pytest.fixture(params=[\"univariate\", \"multivariate\"])\n    def arange_graph(request):\n        shape = (3, 7, 11) if request.param == \"multivariate\" else (3, 7)\n>       total_elems = np.product(shape)\n\ntests/layer/test_gcn_lstm.py:195: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'product'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n            raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\n    \n        if attr == \"chararray\":\n            warnings.warn(\n                \"`np.chararray` is deprecated and will be removed from \"\n                \"the main namespace in the future. Use an array with a string \"\n                \"or bytes dtype instead.\", DeprecationWarning, stacklevel=2)\n            import numpy.char as char\n            return char.chararray\n    \n>       raise AttributeError(\"module {!r} has no attribute \"\n                             \"{!r}\".format(__name__, attr))\nE       AttributeError: module 'numpy' has no attribute 'product'\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:414: AttributeError\n___________ ERROR at setup of test_gcn_lstm_generator[multivariate] ____________\n\nrequest = <SubRequest 'arange_graph' for <Function test_gcn_lstm_generator[multivariate]>>\n\n    @pytest.fixture(params=[\"univariate\", \"multivariate\"])\n    def arange_graph(request):\n        shape = (3, 7, 11) if request.param == \"multivariate\" else (3, 7)\n>       total_elems = np.product(shape)\n\ntests/layer/test_gcn_lstm.py:195: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'product'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n            raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\n    \n        if attr == \"chararray\":\n            warnings.warn(\n                \"`np.chararray` is deprecated and will be removed from \"\n                \"the main namespace in the future. Use an array with a string \"\n                \"or bytes dtype instead.\", DeprecationWarning, stacklevel=2)\n            import numpy.char as char\n            return char.chararray\n    \n>       raise AttributeError(\"module {!r} has no attribute \"\n                             \"{!r}\".format(__name__, attr))\nE       AttributeError: module 'numpy' has no attribute 'product'\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:414: AttributeError\n____________ ERROR at setup of test_gcn_lstm_save_load[univariate] _____________\n\nrequest = <SubRequest 'arange_graph' for <Function test_gcn_lstm_save_load[univariate]>>\n\n    @pytest.fixture(params=[\"univariate\", \"multivariate\"])\n    def arange_graph(request):\n        shape = (3, 7, 11) if request.param == \"multivariate\" else (3, 7)\n>       total_elems = np.product(shape)\n\ntests/layer/test_gcn_lstm.py:195: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'product'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n            raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\n    \n        if attr == \"chararray\":\n            warnings.warn(\n                \"`np.chararray` is deprecated and will be removed from \"\n                \"the main namespace in the future. Use an array with a string \"\n                \"or bytes dtype instead.\", DeprecationWarning, stacklevel=2)\n            import numpy.char as char\n            return char.chararray\n    \n>       raise AttributeError(\"module {!r} has no attribute \"\n                             \"{!r}\".format(__name__, attr))\nE       AttributeError: module 'numpy' has no attribute 'product'\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:414: AttributeError\n___________ ERROR at setup of test_gcn_lstm_save_load[multivariate] ____________\n\nrequest = <SubRequest 'arange_graph' for <Function test_gcn_lstm_save_load[multivariate]>>\n\n    @pytest.fixture(params=[\"univariate\", \"multivariate\"])\n    def arange_graph(request):\n        shape = (3, 7, 11) if request.param == \"multivariate\" else (3, 7)\n>       total_elems = np.product(shape)\n\ntests/layer/test_gcn_lstm.py:195: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'product'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n            raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\n    \n        if attr == \"chararray\":\n            warnings.warn(\n                \"`np.chararray` is deprecated and will be removed from \"\n                \"the main namespace in the future. Use an array with a string \"\n                \"or bytes dtype instead.\", DeprecationWarning, stacklevel=2)\n            import numpy.char as char\n            return char.chararray\n    \n>       raise AttributeError(\"module {!r} has no attribute \"\n                             \"{!r}\".format(__name__, attr))\nE       AttributeError: module 'numpy' has no attribute 'product'\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:414: AttributeError\n____________ ERROR at setup of test_benchmark_setup_generator_small ____________\nfile /app/repo_to_process/tests/mapper/test_benchmark_generators.py, line 33\n  @pytest.mark.benchmark(group=\"generator\")\n  def test_benchmark_setup_generator_small(benchmark):\nE       fixture 'benchmark' not found\n>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/app/repo_to_process/tests/mapper/test_benchmark_generators.py:33\n____________ ERROR at setup of test_benchmark_setup_generator_large ____________\nfile /app/repo_to_process/tests/mapper/test_benchmark_generators.py, line 52\n  @pytest.mark.benchmark(group=\"generator\")\n  def test_benchmark_setup_generator_large(benchmark):\nE       fixture 'benchmark' not found\n>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/app/repo_to_process/tests/mapper/test_benchmark_generators.py:52\n____________ ERROR at setup of test_benchmark_link_generator_small _____________\nfile /app/repo_to_process/tests/mapper/test_benchmark_generators.py, line 71\n  @pytest.mark.benchmark(group=\"generator\")\n  def test_benchmark_link_generator_small(benchmark):\nE       fixture 'benchmark' not found\n>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/app/repo_to_process/tests/mapper/test_benchmark_generators.py:71\n____________ ERROR at setup of test_benchmark_link_generator_large _____________\nfile /app/repo_to_process/tests/mapper/test_benchmark_generators.py, line 96\n  @pytest.mark.benchmark(group=\"generator\")\n  def test_benchmark_link_generator_large(benchmark):\nE       fixture 'benchmark' not found\n>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/app/repo_to_process/tests/mapper/test_benchmark_generators.py:96\n____________ ERROR at setup of test_benchmark_node_generator_small _____________\nfile /app/repo_to_process/tests/mapper/test_benchmark_generators.py, line 121\n  @pytest.mark.benchmark(group=\"generator\")\n  def test_benchmark_node_generator_small(benchmark):\nE       fixture 'benchmark' not found\n>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/app/repo_to_process/tests/mapper/test_benchmark_generators.py:121\n____________ ERROR at setup of test_benchmark_node_generator_large _____________\nfile /app/repo_to_process/tests/mapper/test_benchmark_generators.py, line 146\n  @pytest.mark.benchmark(group=\"generator\")\n  def test_benchmark_node_generator_large(benchmark):\nE       fixture 'benchmark' not found\n>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/app/repo_to_process/tests/mapper/test_benchmark_generators.py:146\n___________ ERROR at setup of test_benchmark_ClusterGCN_generator[1] ___________\nfile /app/repo_to_process/tests/mapper/test_cluster_gcn_node_mapper.py, line 222\n  @pytest.mark.benchmark(group=\"ClusterGCN generator\")\n  @pytest.mark.parametrize(\"q\", [1, 2, 10])\n  def test_benchmark_ClusterGCN_generator(benchmark, q):\nE       fixture 'benchmark' not found\n>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/app/repo_to_process/tests/mapper/test_cluster_gcn_node_mapper.py:222\n___________ ERROR at setup of test_benchmark_ClusterGCN_generator[2] ___________\nfile /app/repo_to_process/tests/mapper/test_cluster_gcn_node_mapper.py, line 222\n  @pytest.mark.benchmark(group=\"ClusterGCN generator\")\n  @pytest.mark.parametrize(\"q\", [1, 2, 10])\n  def test_benchmark_ClusterGCN_generator(benchmark, q):\nE       fixture 'benchmark' not found\n>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/app/repo_to_process/tests/mapper/test_cluster_gcn_node_mapper.py:222\n__________ ERROR at setup of test_benchmark_ClusterGCN_generator[10] ___________\nfile /app/repo_to_process/tests/mapper/test_cluster_gcn_node_mapper.py, line 222\n  @pytest.mark.benchmark(group=\"ClusterGCN generator\")\n  @pytest.mark.parametrize(\"q\", [1, 2, 10])\n  def test_benchmark_ClusterGCN_generator(benchmark, q):\nE       fixture 'benchmark' not found\n>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/app/repo_to_process/tests/mapper/test_cluster_gcn_node_mapper.py:222\n=================================== FAILURES ===================================\n________________________________ test_notebooks ________________________________\n\n    def test_notebooks():\n        \"\"\"\n        Run all notebooks in the directories given by the list `notebook_paths`.\n    \n        The notebooks are run locally using [treon](https://github.com/ReviewNB/treon)\n        and executed in each directory so that local resources can be imported.\n    \n        Returns:\n            num_errors (int): Number of notebooks that failed to run\n            num_passed (int): Number of notebooks that successfully run\n        \"\"\"\n        num_errors = 0\n        num_passed = 0\n        for nb_path in notebook_paths:\n            abs_nb_path = os.path.join(SGDIR, nb_path)\n            cmd_line = f\"treon . --threads=2\"\n    \n            print(f\"\\033[1;33;40m Running {abs_nb_path}\\033[0m\")\n    \n            # Add path to PYTHONPATH\n            environ = dict(os.environ, PYTHONPATH=abs_nb_path)\n    \n>           procout = subprocess.run(\n                cmd_line,\n                shell=True,\n                check=False,\n                env=environ,\n                cwd=abs_nb_path,\n                # stdout=subprocess.PIPE,\n                # stderr=subprocess.PIPE,\n            )\n\nscripts/test_demos.py:89: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n/usr/lib/python3.10/subprocess.py:503: in run\n    with Popen(*popenargs, **kwargs) as process:\n/usr/lib/python3.10/subprocess.py:971: in __init__\n    self._execute_child(args, executable, preexec_fn, close_fds,\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <Popen: returncode: 255 args: 'treon . --threads=2'>\nargs = ['/bin/sh', '-c', 'treon . --threads=2'], executable = b'/bin/sh'\npreexec_fn = None, close_fds = True, pass_fds = ()\ncwd = '/usr/local/demos/node-classification/attri2vec/'\nenv = {'DEBIAN_FRONTEND': 'noninteractive', 'ENABLE_RUNTIME_UPTIME_TELEMETRY': '1', 'HOME': '/root', 'HOSTNAME': 'ac1475261bde', ...}\nstartupinfo = None, creationflags = 0, shell = True, p2cread = -1, p2cwrite = -1\nc2pread = -1, c2pwrite = -1, errread = -1, errwrite = -1, restore_signals = True\ngid = None, gids = None, uid = None, umask = -1, start_new_session = False\n\n    def _execute_child(self, args, executable, preexec_fn, close_fds,\n                       pass_fds, cwd, env,\n                       startupinfo, creationflags, shell,\n                       p2cread, p2cwrite,\n                       c2pread, c2pwrite,\n                       errread, errwrite,\n                       restore_signals,\n                       gid, gids, uid, umask,\n                       start_new_session):\n        \"\"\"Execute program (POSIX version)\"\"\"\n    \n        if isinstance(args, (str, bytes)):\n            args = [args]\n        elif isinstance(args, os.PathLike):\n            if shell:\n                raise TypeError('path-like args is not allowed when '\n                                'shell is true')\n            args = [args]\n        else:\n            args = list(args)\n    \n        if shell:\n            # On Android the default shell is at '/system/bin/sh'.\n            unix_shell = ('/system/bin/sh' if\n                      hasattr(sys, 'getandroidapilevel') else '/bin/sh')\n            args = [unix_shell, \"-c\"] + args\n            if executable:\n                args[0] = executable\n    \n        if executable is None:\n            executable = args[0]\n    \n        sys.audit(\"subprocess.Popen\", executable, args, cwd, env)\n    \n        if (_USE_POSIX_SPAWN\n                and os.path.dirname(executable)\n                and preexec_fn is None\n                and not close_fds\n                and not pass_fds\n                and cwd is None\n                and (p2cread == -1 or p2cread > 2)\n                and (c2pwrite == -1 or c2pwrite > 2)\n                and (errwrite == -1 or errwrite > 2)\n                and not start_new_session\n                and gid is None\n                and gids is None\n                and uid is None\n                and umask < 0):\n            self._posix_spawn(args, executable, env, restore_signals,\n                              p2cread, p2cwrite,\n                              c2pread, c2pwrite,\n                              errread, errwrite)\n            return\n    \n        orig_executable = executable\n    \n        # For transferring possible exec failure from child to parent.\n        # Data format: \"exception name:hex errno:description\"\n        # Pickle is not used; it is complex and involves memory allocation.\n        errpipe_read, errpipe_write = os.pipe()\n        # errpipe_write must not be in the standard io 0, 1, or 2 fd range.\n        low_fds_to_close = []\n        while errpipe_write < 3:\n            low_fds_to_close.append(errpipe_write)\n            errpipe_write = os.dup(errpipe_write)\n        for low_fd in low_fds_to_close:\n            os.close(low_fd)\n        try:\n            try:\n                # We must avoid complex work that could involve\n                # malloc or free in the child process to avoid\n                # potential deadlocks, thus we do all this here.\n                # and pass it to fork_exec()\n    \n                if env is not None:\n                    env_list = []\n                    for k, v in env.items():\n                        k = os.fsencode(k)\n                        if b'=' in k:\n                            raise ValueError(\"illegal environment variable name\")\n                        env_list.append(k + b'=' + os.fsencode(v))\n                else:\n                    env_list = None  # Use execv instead of execve.\n                executable = os.fsencode(executable)\n                if os.path.dirname(executable):\n                    executable_list = (executable,)\n                else:\n                    # This matches the behavior of os._execvpe().\n                    executable_list = tuple(\n                        os.path.join(os.fsencode(dir), executable)\n                        for dir in os.get_exec_path(env))\n                fds_to_keep = set(pass_fds)\n                fds_to_keep.add(errpipe_write)\n                self.pid = _posixsubprocess.fork_exec(\n                        args, executable_list,\n                        close_fds, tuple(sorted(map(int, fds_to_keep))),\n                        cwd, env_list,\n                        p2cread, p2cwrite, c2pread, c2pwrite,\n                        errread, errwrite,\n                        errpipe_read, errpipe_write,\n                        restore_signals, start_new_session,\n                        gid, gids, uid, umask,\n                        preexec_fn)\n                self._child_created = True\n            finally:\n                # be sure the FD is closed no matter what\n                os.close(errpipe_write)\n    \n            self._close_pipe_fds(p2cread, p2cwrite,\n                                 c2pread, c2pwrite,\n                                 errread, errwrite)\n    \n            # Wait for exec to fail or succeed; possibly raising an\n            # exception (limited in size)\n            errpipe_data = bytearray()\n            while True:\n                part = os.read(errpipe_read, 50000)\n                errpipe_data += part\n                if not part or len(errpipe_data) > 50000:\n                    break\n        finally:\n            # be sure the FD is closed no matter what\n            os.close(errpipe_read)\n    \n        if errpipe_data:\n            try:\n                pid, sts = os.waitpid(self.pid, 0)\n                if pid == self.pid:\n                    self._handle_exitstatus(sts)\n                else:\n                    self.returncode = sys.maxsize\n            except ChildProcessError:\n                pass\n    \n            try:\n                exception_name, hex_errno, err_msg = (\n                        errpipe_data.split(b':', 2))\n                # The encoding here should match the encoding\n                # written in by the subprocess implementations\n                # like _posixsubprocess\n                err_msg = err_msg.decode()\n            except ValueError:\n                exception_name = b'SubprocessError'\n                hex_errno = b'0'\n                err_msg = 'Bad exception data from child: {!r}'.format(\n                              bytes(errpipe_data))\n            child_exception_type = getattr(\n                    builtins, exception_name.decode('ascii'),\n                    SubprocessError)\n            if issubclass(child_exception_type, OSError) and hex_errno:\n                errno_num = int(hex_errno, 16)\n                child_exec_never_called = (err_msg == \"noexec\")\n                if child_exec_never_called:\n                    err_msg = \"\"\n                    # The error must be from chdir(cwd).\n                    err_filename = cwd\n                else:\n                    err_filename = orig_executable\n                if errno_num != 0:\n                    err_msg = os.strerror(errno_num)\n>               raise child_exception_type(errno_num, err_msg, err_filename)\nE               FileNotFoundError: [Errno 2] No such file or directory: '/usr/local/demos/node-classification/attri2vec/'\n\n/usr/lib/python3.10/subprocess.py:1863: FileNotFoundError\n----------------------------- Captured stdout call -----------------------------\n\u001b[1;33;40m Running /usr/local/demos/node-classification/attri2vec/\u001b[0m\n_________________ test_graph_constructor_extra_nodes_in_edges __________________\n\nnode_ids = array([4, 5])\n\n    def _node_ids_to_iloc(node_ids):\n        try:\n>           return nodes.ids.to_iloc(node_ids, strict=True)\n\nstellargraph/core/convert.py:276: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/core/element_data.py:97: in to_iloc\n    self.require_valid(ids, internal_ids)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <stellargraph.core.element_data.ExternalIdIndex object at 0x7fc1ac397eb0>\nquery_ids = array([4, 5]), ilocs = array([ 4, -1])\n\n    def require_valid(self, query_ids, ilocs: np.ndarray) -> np.ndarray:\n        valid = self.is_valid(ilocs)\n    \n        if not valid.all():\n            missing_values = np.asarray(query_ids)[~valid]\n    \n            if len(missing_values) == 1:\n>               raise KeyError(missing_values[0])\nE               KeyError: np.int64(5)\n\nstellargraph/core/element_data.py:77: KeyError\n\nDuring handling of the above exception, another exception occurred:\n\n    def test_graph_constructor_extra_nodes_in_edges():\n        nodes = pd.DataFrame(np.ones((5, 1)), index=[0, 1, 2, 3, 4])\n        edges = {\n            \"a\": pd.DataFrame({\"source\": [1], \"target\": [0]}, index=[0]),\n            \"b\": pd.DataFrame({\"source\": [4, 5], \"target\": [0, 2]}, index=[1, 2]),\n        }\n    \n        with pytest.raises(\n            ValueError,\n            match=\"^edges: expected all source and target node IDs to be contained in `nodes`, found some missing: 5$\",\n        ):\n>           g = StellarGraph(nodes, edges)\n\ntests/core/test_graph.py:153: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/core/graph.py:418: in __init__\n    internal_edges = convert.convert_edges(\nstellargraph/core/convert.py:309: in convert_edges\n    ids, columns, type_info = converter.convert(data)\nstellargraph/core/convert.py:235: in convert\n    singles = {\nstellargraph/core/convert.py:236: in <dictcomp>\n    type_name: self._convert_single(type_name, data)\nstellargraph/core/convert.py:82: in _convert_single\n    return self._convert_pandas(type_name, data)\nstellargraph/core/convert.py:115: in _convert_pandas\n    columns = {\nstellargraph/core/convert.py:116: in <dictcomp>\n    new_name: select_column(old_name)\nstellargraph/core/convert.py:111: in select_column\n    column = transform(column)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nnode_ids = array([4, 5])\n\n    def _node_ids_to_iloc(node_ids):\n        try:\n            return nodes.ids.to_iloc(node_ids, strict=True)\n        except KeyError as e:\n            missing_values = e.args[0]\n            if not is_real_iterable(missing_values):\n                missing_values = [missing_values]\n            missing_values = pd.unique(missing_values)\n    \n>           raise ValueError(\n                f\"edges: expected all source and target node IDs to be contained in `nodes`, \"\n                f\"found some missing: {comma_sep(missing_values)}\"\n            )\nE           ValueError: edges: expected all source and target node IDs to be contained in `nodes`, found some missing: np.int64(5)\n\nstellargraph/core/convert.py:283: ValueError\n\nDuring handling of the above exception, another exception occurred:\n\n    def test_graph_constructor_extra_nodes_in_edges():\n        nodes = pd.DataFrame(np.ones((5, 1)), index=[0, 1, 2, 3, 4])\n        edges = {\n            \"a\": pd.DataFrame({\"source\": [1], \"target\": [0]}, index=[0]),\n            \"b\": pd.DataFrame({\"source\": [4, 5], \"target\": [0, 2]}, index=[1, 2]),\n        }\n    \n>       with pytest.raises(\n            ValueError,\n            match=\"^edges: expected all source and target node IDs to be contained in `nodes`, found some missing: 5$\",\n        ):\nE       AssertionError: Skipping 85 identical leading characters in diff, use -v to show\nE       -  missing: np.int64(5)\nE       +  missing: 5\n\ntests/core/test_graph.py:149: AssertionError\n_________________________ test_to_networkx_deprecation _________________________\n\nline_graph = <stellargraph.core.graph.StellarGraph object at 0x7fc1ac22cb50>\n\n    def test_to_networkx_deprecation(line_graph):\n>       with pytest.warns(None) as record:\n\ntests/core/test_graph.py:943: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = WarningsChecker(record=True), expected_warning = None, match_expr = None\n\n    def __init__(\n        self,\n        expected_warning: type[Warning] | tuple[type[Warning], ...] = Warning,\n        match_expr: str | re.Pattern[str] | None = None,\n        *,\n        _ispytest: bool = False,\n    ) -> None:\n        check_ispytest(_ispytest)\n        super().__init__(_ispytest=True)\n    \n        msg = \"exceptions must be derived from Warning, not %s\"\n        if isinstance(expected_warning, tuple):\n            for exc in expected_warning:\n                if not issubclass(exc, Warning):\n                    raise TypeError(msg % type(exc))\n            expected_warning_tup = expected_warning\n        elif isinstance(expected_warning, type) and issubclass(\n            expected_warning, Warning\n        ):\n            expected_warning_tup = (expected_warning,)\n        else:\n>           raise TypeError(msg % type(expected_warning))\nE           TypeError: exceptions must be derived from Warning, not <class 'NoneType'>\n\n/usr/local/lib/python3.10/dist-packages/_pytest/recwarn.py:280: TypeError\n____________________ test_neighbors_weighted_hin[True-True] ____________________\n\nis_directed = True, use_ilocs = True\n\n    @pytest.mark.parametrize(\"use_ilocs\", [True, False])\n    @pytest.mark.parametrize(\"is_directed\", [True, False])\n    def test_neighbors_weighted_hin(is_directed, use_ilocs):\n        graph = example_weighted_hin(is_directed=is_directed)\n    \n        node = graph.node_ids_to_ilocs([1])[0] if use_ilocs else 1\n        expected_nodes = (\n            graph.node_ids_to_ilocs([0, 0, 2, 3]) if use_ilocs else [0, 0, 2, 3]\n        )\n        expected_weights = [0.0, 1.0, 10.0, 10.0]\n    \n>       assert_items_equal(graph.neighbors(node, use_ilocs=use_ilocs), expected_nodes)\n\ntests/core/test_graph.py:1188: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/core/graph.py:821: in neighbors\n    neigh_arrs = self.neighbor_arrays(\nstellargraph/core/graph.py:792: in neighbor_arrays\n    edge_ilocs = self._edges.edge_ilocs(node, ins=True, outs=True)\nstellargraph/core/element_data.py:452: in edge_ilocs\n    return self._adj_lookup(ins=ins, outs=outs)[node_id]\nstellargraph/core/element_data.py:410: in _adj_lookup\n    self._init_undirected_adj_lists()\nstellargraph/core/element_data.py:365: in _init_undirected_adj_lists\n    self._edges_dict = self._create_undirected_adj_lists()\nstellargraph/core/element_data.py:377: in _create_undirected_adj_lists\n    sentinel = np.cast[np.min_scalar_type(self.number_of_nodes)](-1)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'cast'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n>           raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\nE           AttributeError: `np.cast` was removed in the NumPy 2.0 release. Use `np.asarray(arr, dtype=dtype)` instead.\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:400: AttributeError\n___________________ test_neighbors_weighted_hin[True-False] ____________________\n\nis_directed = True, use_ilocs = False\n\n    @pytest.mark.parametrize(\"use_ilocs\", [True, False])\n    @pytest.mark.parametrize(\"is_directed\", [True, False])\n    def test_neighbors_weighted_hin(is_directed, use_ilocs):\n        graph = example_weighted_hin(is_directed=is_directed)\n    \n        node = graph.node_ids_to_ilocs([1])[0] if use_ilocs else 1\n        expected_nodes = (\n            graph.node_ids_to_ilocs([0, 0, 2, 3]) if use_ilocs else [0, 0, 2, 3]\n        )\n        expected_weights = [0.0, 1.0, 10.0, 10.0]\n    \n>       assert_items_equal(graph.neighbors(node, use_ilocs=use_ilocs), expected_nodes)\n\ntests/core/test_graph.py:1188: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/core/graph.py:821: in neighbors\n    neigh_arrs = self.neighbor_arrays(\nstellargraph/core/graph.py:792: in neighbor_arrays\n    edge_ilocs = self._edges.edge_ilocs(node, ins=True, outs=True)\nstellargraph/core/element_data.py:452: in edge_ilocs\n    return self._adj_lookup(ins=ins, outs=outs)[node_id]\nstellargraph/core/element_data.py:410: in _adj_lookup\n    self._init_undirected_adj_lists()\nstellargraph/core/element_data.py:365: in _init_undirected_adj_lists\n    self._edges_dict = self._create_undirected_adj_lists()\nstellargraph/core/element_data.py:377: in _create_undirected_adj_lists\n    sentinel = np.cast[np.min_scalar_type(self.number_of_nodes)](-1)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'cast'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n>           raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\nE           AttributeError: `np.cast` was removed in the NumPy 2.0 release. Use `np.asarray(arr, dtype=dtype)` instead.\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:400: AttributeError\n___________________ test_neighbors_weighted_hin[False-True] ____________________\n\nis_directed = False, use_ilocs = True\n\n    @pytest.mark.parametrize(\"use_ilocs\", [True, False])\n    @pytest.mark.parametrize(\"is_directed\", [True, False])\n    def test_neighbors_weighted_hin(is_directed, use_ilocs):\n        graph = example_weighted_hin(is_directed=is_directed)\n    \n        node = graph.node_ids_to_ilocs([1])[0] if use_ilocs else 1\n        expected_nodes = (\n            graph.node_ids_to_ilocs([0, 0, 2, 3]) if use_ilocs else [0, 0, 2, 3]\n        )\n        expected_weights = [0.0, 1.0, 10.0, 10.0]\n    \n>       assert_items_equal(graph.neighbors(node, use_ilocs=use_ilocs), expected_nodes)\n\ntests/core/test_graph.py:1188: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/core/graph.py:821: in neighbors\n    neigh_arrs = self.neighbor_arrays(\nstellargraph/core/graph.py:792: in neighbor_arrays\n    edge_ilocs = self._edges.edge_ilocs(node, ins=True, outs=True)\nstellargraph/core/element_data.py:452: in edge_ilocs\n    return self._adj_lookup(ins=ins, outs=outs)[node_id]\nstellargraph/core/element_data.py:410: in _adj_lookup\n    self._init_undirected_adj_lists()\nstellargraph/core/element_data.py:365: in _init_undirected_adj_lists\n    self._edges_dict = self._create_undirected_adj_lists()\nstellargraph/core/element_data.py:377: in _create_undirected_adj_lists\n    sentinel = np.cast[np.min_scalar_type(self.number_of_nodes)](-1)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'cast'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n>           raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\nE           AttributeError: `np.cast` was removed in the NumPy 2.0 release. Use `np.asarray(arr, dtype=dtype)` instead.\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:400: AttributeError\n___________________ test_neighbors_weighted_hin[False-False] ___________________\n\nis_directed = False, use_ilocs = False\n\n    @pytest.mark.parametrize(\"use_ilocs\", [True, False])\n    @pytest.mark.parametrize(\"is_directed\", [True, False])\n    def test_neighbors_weighted_hin(is_directed, use_ilocs):\n        graph = example_weighted_hin(is_directed=is_directed)\n    \n        node = graph.node_ids_to_ilocs([1])[0] if use_ilocs else 1\n        expected_nodes = (\n            graph.node_ids_to_ilocs([0, 0, 2, 3]) if use_ilocs else [0, 0, 2, 3]\n        )\n        expected_weights = [0.0, 1.0, 10.0, 10.0]\n    \n>       assert_items_equal(graph.neighbors(node, use_ilocs=use_ilocs), expected_nodes)\n\ntests/core/test_graph.py:1188: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/core/graph.py:821: in neighbors\n    neigh_arrs = self.neighbor_arrays(\nstellargraph/core/graph.py:792: in neighbor_arrays\n    edge_ilocs = self._edges.edge_ilocs(node, ins=True, outs=True)\nstellargraph/core/element_data.py:452: in edge_ilocs\n    return self._adj_lookup(ins=ins, outs=outs)[node_id]\nstellargraph/core/element_data.py:410: in _adj_lookup\n    self._init_undirected_adj_lists()\nstellargraph/core/element_data.py:365: in _init_undirected_adj_lists\n    self._edges_dict = self._create_undirected_adj_lists()\nstellargraph/core/element_data.py:377: in _create_undirected_adj_lists\n    sentinel = np.cast[np.min_scalar_type(self.number_of_nodes)](-1)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'cast'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n>           raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\nE           AttributeError: `np.cast` was removed in the NumPy 2.0 release. Use `np.asarray(arr, dtype=dtype)` instead.\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:400: AttributeError\n___________________ test_neighbors_unweighted_hom[True-True] ___________________\n\nis_directed = True, use_ilocs = True\n\n    @pytest.mark.parametrize(\"use_ilocs\", [True, False])\n    @pytest.mark.parametrize(\"is_directed\", [True, False])\n    def test_neighbors_unweighted_hom(is_directed, use_ilocs):\n        graph = example_unweighted_hom(is_directed=is_directed)\n        node = graph.node_ids_to_ilocs([1])[0] if use_ilocs else 1\n        expected_nodes = (\n            graph.node_ids_to_ilocs([0, 0, 2, 3]) if use_ilocs else [0, 0, 2, 3]\n        )\n        expected_weights = [1, 1, 1, 1]\n    \n>       assert_items_equal(graph.neighbors(node, use_ilocs=use_ilocs), expected_nodes)\n\ntests/core/test_graph.py:1219: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/core/graph.py:821: in neighbors\n    neigh_arrs = self.neighbor_arrays(\nstellargraph/core/graph.py:792: in neighbor_arrays\n    edge_ilocs = self._edges.edge_ilocs(node, ins=True, outs=True)\nstellargraph/core/element_data.py:452: in edge_ilocs\n    return self._adj_lookup(ins=ins, outs=outs)[node_id]\nstellargraph/core/element_data.py:410: in _adj_lookup\n    self._init_undirected_adj_lists()\nstellargraph/core/element_data.py:365: in _init_undirected_adj_lists\n    self._edges_dict = self._create_undirected_adj_lists()\nstellargraph/core/element_data.py:377: in _create_undirected_adj_lists\n    sentinel = np.cast[np.min_scalar_type(self.number_of_nodes)](-1)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'cast'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n>           raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\nE           AttributeError: `np.cast` was removed in the NumPy 2.0 release. Use `np.asarray(arr, dtype=dtype)` instead.\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:400: AttributeError\n__________________ test_neighbors_unweighted_hom[True-False] ___________________\n\nis_directed = True, use_ilocs = False\n\n    @pytest.mark.parametrize(\"use_ilocs\", [True, False])\n    @pytest.mark.parametrize(\"is_directed\", [True, False])\n    def test_neighbors_unweighted_hom(is_directed, use_ilocs):\n        graph = example_unweighted_hom(is_directed=is_directed)\n        node = graph.node_ids_to_ilocs([1])[0] if use_ilocs else 1\n        expected_nodes = (\n            graph.node_ids_to_ilocs([0, 0, 2, 3]) if use_ilocs else [0, 0, 2, 3]\n        )\n        expected_weights = [1, 1, 1, 1]\n    \n>       assert_items_equal(graph.neighbors(node, use_ilocs=use_ilocs), expected_nodes)\n\ntests/core/test_graph.py:1219: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/core/graph.py:821: in neighbors\n    neigh_arrs = self.neighbor_arrays(\nstellargraph/core/graph.py:792: in neighbor_arrays\n    edge_ilocs = self._edges.edge_ilocs(node, ins=True, outs=True)\nstellargraph/core/element_data.py:452: in edge_ilocs\n    return self._adj_lookup(ins=ins, outs=outs)[node_id]\nstellargraph/core/element_data.py:410: in _adj_lookup\n    self._init_undirected_adj_lists()\nstellargraph/core/element_data.py:365: in _init_undirected_adj_lists\n    self._edges_dict = self._create_undirected_adj_lists()\nstellargraph/core/element_data.py:377: in _create_undirected_adj_lists\n    sentinel = np.cast[np.min_scalar_type(self.number_of_nodes)](-1)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'cast'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n>           raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\nE           AttributeError: `np.cast` was removed in the NumPy 2.0 release. Use `np.asarray(arr, dtype=dtype)` instead.\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:400: AttributeError\n__________________ test_neighbors_unweighted_hom[False-True] ___________________\n\nis_directed = False, use_ilocs = True\n\n    @pytest.mark.parametrize(\"use_ilocs\", [True, False])\n    @pytest.mark.parametrize(\"is_directed\", [True, False])\n    def test_neighbors_unweighted_hom(is_directed, use_ilocs):\n        graph = example_unweighted_hom(is_directed=is_directed)\n        node = graph.node_ids_to_ilocs([1])[0] if use_ilocs else 1\n        expected_nodes = (\n            graph.node_ids_to_ilocs([0, 0, 2, 3]) if use_ilocs else [0, 0, 2, 3]\n        )\n        expected_weights = [1, 1, 1, 1]\n    \n>       assert_items_equal(graph.neighbors(node, use_ilocs=use_ilocs), expected_nodes)\n\ntests/core/test_graph.py:1219: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/core/graph.py:821: in neighbors\n    neigh_arrs = self.neighbor_arrays(\nstellargraph/core/graph.py:792: in neighbor_arrays\n    edge_ilocs = self._edges.edge_ilocs(node, ins=True, outs=True)\nstellargraph/core/element_data.py:452: in edge_ilocs\n    return self._adj_lookup(ins=ins, outs=outs)[node_id]\nstellargraph/core/element_data.py:410: in _adj_lookup\n    self._init_undirected_adj_lists()\nstellargraph/core/element_data.py:365: in _init_undirected_adj_lists\n    self._edges_dict = self._create_undirected_adj_lists()\nstellargraph/core/element_data.py:377: in _create_undirected_adj_lists\n    sentinel = np.cast[np.min_scalar_type(self.number_of_nodes)](-1)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'cast'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n>           raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\nE           AttributeError: `np.cast` was removed in the NumPy 2.0 release. Use `np.asarray(arr, dtype=dtype)` instead.\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:400: AttributeError\n__________________ test_neighbors_unweighted_hom[False-False] __________________\n\nis_directed = False, use_ilocs = False\n\n    @pytest.mark.parametrize(\"use_ilocs\", [True, False])\n    @pytest.mark.parametrize(\"is_directed\", [True, False])\n    def test_neighbors_unweighted_hom(is_directed, use_ilocs):\n        graph = example_unweighted_hom(is_directed=is_directed)\n        node = graph.node_ids_to_ilocs([1])[0] if use_ilocs else 1\n        expected_nodes = (\n            graph.node_ids_to_ilocs([0, 0, 2, 3]) if use_ilocs else [0, 0, 2, 3]\n        )\n        expected_weights = [1, 1, 1, 1]\n    \n>       assert_items_equal(graph.neighbors(node, use_ilocs=use_ilocs), expected_nodes)\n\ntests/core/test_graph.py:1219: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/core/graph.py:821: in neighbors\n    neigh_arrs = self.neighbor_arrays(\nstellargraph/core/graph.py:792: in neighbor_arrays\n    edge_ilocs = self._edges.edge_ilocs(node, ins=True, outs=True)\nstellargraph/core/element_data.py:452: in edge_ilocs\n    return self._adj_lookup(ins=ins, outs=outs)[node_id]\nstellargraph/core/element_data.py:410: in _adj_lookup\n    self._init_undirected_adj_lists()\nstellargraph/core/element_data.py:365: in _init_undirected_adj_lists\n    self._edges_dict = self._create_undirected_adj_lists()\nstellargraph/core/element_data.py:377: in _create_undirected_adj_lists\n    sentinel = np.cast[np.min_scalar_type(self.number_of_nodes)](-1)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'cast'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n>           raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\nE           AttributeError: `np.cast` was removed in the NumPy 2.0 release. Use `np.asarray(arr, dtype=dtype)` instead.\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:400: AttributeError\n__________________ test_undirected_hin_neighbor_methods[True] __________________\n\nuse_ilocs = True\n\n    @pytest.mark.parametrize(\"use_ilocs\", [True, False])\n    def test_undirected_hin_neighbor_methods(use_ilocs):\n        graph = example_weighted_hin(is_directed=False)\n        node = graph.node_ids_to_ilocs([1])[0] if use_ilocs else 1\n        assert_items_equal(\n>           graph.neighbors(node, use_ilocs=use_ilocs),\n            graph.in_nodes(node, use_ilocs=use_ilocs),\n        )\n\ntests/core/test_graph.py:1238: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/core/graph.py:821: in neighbors\n    neigh_arrs = self.neighbor_arrays(\nstellargraph/core/graph.py:792: in neighbor_arrays\n    edge_ilocs = self._edges.edge_ilocs(node, ins=True, outs=True)\nstellargraph/core/element_data.py:452: in edge_ilocs\n    return self._adj_lookup(ins=ins, outs=outs)[node_id]\nstellargraph/core/element_data.py:410: in _adj_lookup\n    self._init_undirected_adj_lists()\nstellargraph/core/element_data.py:365: in _init_undirected_adj_lists\n    self._edges_dict = self._create_undirected_adj_lists()\nstellargraph/core/element_data.py:377: in _create_undirected_adj_lists\n    sentinel = np.cast[np.min_scalar_type(self.number_of_nodes)](-1)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'cast'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n>           raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\nE           AttributeError: `np.cast` was removed in the NumPy 2.0 release. Use `np.asarray(arr, dtype=dtype)` instead.\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:400: AttributeError\n_________________ test_undirected_hin_neighbor_methods[False] __________________\n\nuse_ilocs = False\n\n    @pytest.mark.parametrize(\"use_ilocs\", [True, False])\n    def test_undirected_hin_neighbor_methods(use_ilocs):\n        graph = example_weighted_hin(is_directed=False)\n        node = graph.node_ids_to_ilocs([1])[0] if use_ilocs else 1\n        assert_items_equal(\n>           graph.neighbors(node, use_ilocs=use_ilocs),\n            graph.in_nodes(node, use_ilocs=use_ilocs),\n        )\n\ntests/core/test_graph.py:1238: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/core/graph.py:821: in neighbors\n    neigh_arrs = self.neighbor_arrays(\nstellargraph/core/graph.py:792: in neighbor_arrays\n    edge_ilocs = self._edges.edge_ilocs(node, ins=True, outs=True)\nstellargraph/core/element_data.py:452: in edge_ilocs\n    return self._adj_lookup(ins=ins, outs=outs)[node_id]\nstellargraph/core/element_data.py:410: in _adj_lookup\n    self._init_undirected_adj_lists()\nstellargraph/core/element_data.py:365: in _init_undirected_adj_lists\n    self._edges_dict = self._create_undirected_adj_lists()\nstellargraph/core/element_data.py:377: in _create_undirected_adj_lists\n    sentinel = np.cast[np.min_scalar_type(self.number_of_nodes)](-1)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'cast'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n>           raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\nE           AttributeError: `np.cast` was removed in the NumPy 2.0 release. Use `np.asarray(arr, dtype=dtype)` instead.\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:400: AttributeError\n_______________ test_isolated_node_neighbor_methods[False-True] ________________\n\nis_directed = False, use_ilocs = True\n\n    @pytest.mark.parametrize(\"use_ilocs\", [True, False])\n    @pytest.mark.parametrize(\"is_directed\", [False, True])\n    def test_isolated_node_neighbor_methods(is_directed, use_ilocs):\n        cls = StellarDiGraph if is_directed else StellarGraph\n        graph = cls(\n            nodes=pd.DataFrame(index=[1]), edges=pd.DataFrame(columns=[\"source\", \"target\"])\n        )\n        node = graph.node_ids_to_ilocs([1])[0] if use_ilocs else 1\n>       assert graph.neighbors(node, use_ilocs=use_ilocs) == []\n\ntests/core/test_graph.py:1336: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/core/graph.py:821: in neighbors\n    neigh_arrs = self.neighbor_arrays(\nstellargraph/core/graph.py:792: in neighbor_arrays\n    edge_ilocs = self._edges.edge_ilocs(node, ins=True, outs=True)\nstellargraph/core/element_data.py:452: in edge_ilocs\n    return self._adj_lookup(ins=ins, outs=outs)[node_id]\nstellargraph/core/element_data.py:410: in _adj_lookup\n    self._init_undirected_adj_lists()\nstellargraph/core/element_data.py:365: in _init_undirected_adj_lists\n    self._edges_dict = self._create_undirected_adj_lists()\nstellargraph/core/element_data.py:377: in _create_undirected_adj_lists\n    sentinel = np.cast[np.min_scalar_type(self.number_of_nodes)](-1)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'cast'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n>           raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\nE           AttributeError: `np.cast` was removed in the NumPy 2.0 release. Use `np.asarray(arr, dtype=dtype)` instead.\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:400: AttributeError\n_______________ test_isolated_node_neighbor_methods[False-False] _______________\n\nis_directed = False, use_ilocs = False\n\n    @pytest.mark.parametrize(\"use_ilocs\", [True, False])\n    @pytest.mark.parametrize(\"is_directed\", [False, True])\n    def test_isolated_node_neighbor_methods(is_directed, use_ilocs):\n        cls = StellarDiGraph if is_directed else StellarGraph\n        graph = cls(\n            nodes=pd.DataFrame(index=[1]), edges=pd.DataFrame(columns=[\"source\", \"target\"])\n        )\n        node = graph.node_ids_to_ilocs([1])[0] if use_ilocs else 1\n>       assert graph.neighbors(node, use_ilocs=use_ilocs) == []\n\ntests/core/test_graph.py:1336: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/core/graph.py:821: in neighbors\n    neigh_arrs = self.neighbor_arrays(\nstellargraph/core/graph.py:792: in neighbor_arrays\n    edge_ilocs = self._edges.edge_ilocs(node, ins=True, outs=True)\nstellargraph/core/element_data.py:452: in edge_ilocs\n    return self._adj_lookup(ins=ins, outs=outs)[node_id]\nstellargraph/core/element_data.py:410: in _adj_lookup\n    self._init_undirected_adj_lists()\nstellargraph/core/element_data.py:365: in _init_undirected_adj_lists\n    self._edges_dict = self._create_undirected_adj_lists()\nstellargraph/core/element_data.py:377: in _create_undirected_adj_lists\n    sentinel = np.cast[np.min_scalar_type(self.number_of_nodes)](-1)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'cast'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n>           raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\nE           AttributeError: `np.cast` was removed in the NumPy 2.0 release. Use `np.asarray(arr, dtype=dtype)` instead.\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:400: AttributeError\n________________ test_isolated_node_neighbor_methods[True-True] ________________\n\nis_directed = True, use_ilocs = True\n\n    @pytest.mark.parametrize(\"use_ilocs\", [True, False])\n    @pytest.mark.parametrize(\"is_directed\", [False, True])\n    def test_isolated_node_neighbor_methods(is_directed, use_ilocs):\n        cls = StellarDiGraph if is_directed else StellarGraph\n        graph = cls(\n            nodes=pd.DataFrame(index=[1]), edges=pd.DataFrame(columns=[\"source\", \"target\"])\n        )\n        node = graph.node_ids_to_ilocs([1])[0] if use_ilocs else 1\n>       assert graph.neighbors(node, use_ilocs=use_ilocs) == []\n\ntests/core/test_graph.py:1336: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/core/graph.py:821: in neighbors\n    neigh_arrs = self.neighbor_arrays(\nstellargraph/core/graph.py:792: in neighbor_arrays\n    edge_ilocs = self._edges.edge_ilocs(node, ins=True, outs=True)\nstellargraph/core/element_data.py:452: in edge_ilocs\n    return self._adj_lookup(ins=ins, outs=outs)[node_id]\nstellargraph/core/element_data.py:410: in _adj_lookup\n    self._init_undirected_adj_lists()\nstellargraph/core/element_data.py:365: in _init_undirected_adj_lists\n    self._edges_dict = self._create_undirected_adj_lists()\nstellargraph/core/element_data.py:377: in _create_undirected_adj_lists\n    sentinel = np.cast[np.min_scalar_type(self.number_of_nodes)](-1)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'cast'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n>           raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\nE           AttributeError: `np.cast` was removed in the NumPy 2.0 release. Use `np.asarray(arr, dtype=dtype)` instead.\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:400: AttributeError\n_______________ test_isolated_node_neighbor_methods[True-False] ________________\n\nis_directed = True, use_ilocs = False\n\n    @pytest.mark.parametrize(\"use_ilocs\", [True, False])\n    @pytest.mark.parametrize(\"is_directed\", [False, True])\n    def test_isolated_node_neighbor_methods(is_directed, use_ilocs):\n        cls = StellarDiGraph if is_directed else StellarGraph\n        graph = cls(\n            nodes=pd.DataFrame(index=[1]), edges=pd.DataFrame(columns=[\"source\", \"target\"])\n        )\n        node = graph.node_ids_to_ilocs([1])[0] if use_ilocs else 1\n>       assert graph.neighbors(node, use_ilocs=use_ilocs) == []\n\ntests/core/test_graph.py:1336: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/core/graph.py:821: in neighbors\n    neigh_arrs = self.neighbor_arrays(\nstellargraph/core/graph.py:792: in neighbor_arrays\n    edge_ilocs = self._edges.edge_ilocs(node, ins=True, outs=True)\nstellargraph/core/element_data.py:452: in edge_ilocs\n    return self._adj_lookup(ins=ins, outs=outs)[node_id]\nstellargraph/core/element_data.py:410: in _adj_lookup\n    self._init_undirected_adj_lists()\nstellargraph/core/element_data.py:365: in _init_undirected_adj_lists\n    self._edges_dict = self._create_undirected_adj_lists()\nstellargraph/core/element_data.py:377: in _create_undirected_adj_lists\n    sentinel = np.cast[np.min_scalar_type(self.number_of_nodes)](-1)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'cast'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n>           raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\nE           AttributeError: `np.cast` was removed in the NumPy 2.0 release. Use `np.asarray(arr, dtype=dtype)` instead.\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:400: AttributeError\n______________________ test_edge_weights_undirected[True] ______________________\n\nuse_ilocs = True\n\n    @pytest.mark.parametrize(\"use_ilocs\", [True, False])\n    def test_edge_weights_undirected(use_ilocs):\n        g = example_hin_1(is_directed=False, self_loop=True, reverse_order=True)\n    \n        edges = [(5, 5), (4, 5), (5, 4), (0, 4), (4, 0)]\n        weights = [[11.0, 12.0, 1.0], [10.0], [10.0], [1], [1]]\n    \n        if use_ilocs:\n            edges = [g.node_ids_to_ilocs(edge) for edge in edges]\n    \n        for edge, weight in zip(edges, weights):\n>           assert g._edge_weights(*edge, use_ilocs=use_ilocs) == weight\n\ntests/core/test_graph.py:2017: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/core/graph.py:1865: in _edge_weights\n    source_edge_ilocs = self._edges.edge_ilocs(\nstellargraph/core/element_data.py:452: in edge_ilocs\n    return self._adj_lookup(ins=ins, outs=outs)[node_id]\nstellargraph/core/element_data.py:410: in _adj_lookup\n    self._init_undirected_adj_lists()\nstellargraph/core/element_data.py:365: in _init_undirected_adj_lists\n    self._edges_dict = self._create_undirected_adj_lists()\nstellargraph/core/element_data.py:377: in _create_undirected_adj_lists\n    sentinel = np.cast[np.min_scalar_type(self.number_of_nodes)](-1)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'cast'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n>           raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\nE           AttributeError: `np.cast` was removed in the NumPy 2.0 release. Use `np.asarray(arr, dtype=dtype)` instead.\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:400: AttributeError\n_____________________ test_edge_weights_undirected[False] ______________________\n\nuse_ilocs = False\n\n    @pytest.mark.parametrize(\"use_ilocs\", [True, False])\n    def test_edge_weights_undirected(use_ilocs):\n        g = example_hin_1(is_directed=False, self_loop=True, reverse_order=True)\n    \n        edges = [(5, 5), (4, 5), (5, 4), (0, 4), (4, 0)]\n        weights = [[11.0, 12.0, 1.0], [10.0], [10.0], [1], [1]]\n    \n        if use_ilocs:\n            edges = [g.node_ids_to_ilocs(edge) for edge in edges]\n    \n        for edge, weight in zip(edges, weights):\n>           assert g._edge_weights(*edge, use_ilocs=use_ilocs) == weight\n\ntests/core/test_graph.py:2017: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/core/graph.py:1865: in _edge_weights\n    source_edge_ilocs = self._edges.edge_ilocs(\nstellargraph/core/element_data.py:452: in edge_ilocs\n    return self._adj_lookup(ins=ins, outs=outs)[node_id]\nstellargraph/core/element_data.py:410: in _adj_lookup\n    self._init_undirected_adj_lists()\nstellargraph/core/element_data.py:365: in _init_undirected_adj_lists\n    self._edges_dict = self._create_undirected_adj_lists()\nstellargraph/core/element_data.py:377: in _create_undirected_adj_lists\n    sentinel = np.cast[np.min_scalar_type(self.number_of_nodes)](-1)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'cast'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n>           raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\nE           AttributeError: `np.cast` was removed in the NumPy 2.0 release. Use `np.asarray(arr, dtype=dtype)` instead.\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:400: AttributeError\n___________________________ test_node_degrees[True] ____________________________\n\nuse_ilocs = True\n\n    @pytest.mark.parametrize(\"use_ilocs\", [True, False])\n    def test_node_degrees(use_ilocs):\n        g = example_hin_1(reverse_order=True)\n>       degrees = g.node_degrees(use_ilocs=use_ilocs)\n\ntests/core/test_graph.py:2225: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/core/graph.py:1546: in node_degrees\n    degrees = self._edges.degrees()\nstellargraph/core/element_data.py:437: in degrees\n    adj = self._adj_lookup(ins=ins, outs=outs)\nstellargraph/core/element_data.py:410: in _adj_lookup\n    self._init_undirected_adj_lists()\nstellargraph/core/element_data.py:365: in _init_undirected_adj_lists\n    self._edges_dict = self._create_undirected_adj_lists()\nstellargraph/core/element_data.py:377: in _create_undirected_adj_lists\n    sentinel = np.cast[np.min_scalar_type(self.number_of_nodes)](-1)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'cast'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n>           raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\nE           AttributeError: `np.cast` was removed in the NumPy 2.0 release. Use `np.asarray(arr, dtype=dtype)` instead.\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:400: AttributeError\n___________________________ test_node_degrees[False] ___________________________\n\nuse_ilocs = False\n\n    @pytest.mark.parametrize(\"use_ilocs\", [True, False])\n    def test_node_degrees(use_ilocs):\n        g = example_hin_1(reverse_order=True)\n>       degrees = g.node_degrees(use_ilocs=use_ilocs)\n\ntests/core/test_graph.py:2225: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/core/graph.py:1546: in node_degrees\n    degrees = self._edges.degrees()\nstellargraph/core/element_data.py:437: in degrees\n    adj = self._adj_lookup(ins=ins, outs=outs)\nstellargraph/core/element_data.py:410: in _adj_lookup\n    self._init_undirected_adj_lists()\nstellargraph/core/element_data.py:365: in _init_undirected_adj_lists\n    self._edges_dict = self._create_undirected_adj_lists()\nstellargraph/core/element_data.py:377: in _create_undirected_adj_lists\n    sentinel = np.cast[np.min_scalar_type(self.number_of_nodes)](-1)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'cast'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n>           raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\nE           AttributeError: `np.cast` was removed in the NumPy 2.0 release. Use `np.asarray(arr, dtype=dtype)` instead.\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:400: AttributeError\n_______________________ test_correct_adjacency_list_type _______________________\n\n    def test_correct_adjacency_list_type():\n    \n        # the dtype of index into \"sg._edges._edges_dict\"\n        # can be larger than \"sg._edges.ids.dtype\"\n        # because there are 2 undirected edges for every (non-self loop) directed edge\n        # this test checks this edge case\n        cycle_graph = nx.cycle_graph(200)\n        sg = StellarGraph.from_networkx(cycle_graph)\n>       sg._edges._init_undirected_adj_lists()\n\ntests/core/test_graph.py:2297: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/core/element_data.py:365: in _init_undirected_adj_lists\n    self._edges_dict = self._create_undirected_adj_lists()\nstellargraph/core/element_data.py:377: in _create_undirected_adj_lists\n    sentinel = np.cast[np.min_scalar_type(self.number_of_nodes)](-1)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'cast'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n>           raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\nE           AttributeError: `np.cast` was removed in the NumPy 2.0 release. Use `np.asarray(arr, dtype=dtype)` instead.\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:400: AttributeError\n_________________________ test_smart_array_index_empty _________________________\n\n    def test_smart_array_index_empty():\n        d1 = np.zeros(0)\n        d2 = np.zeros((0, 2))\n>       _check_smart_index(d1, np.array([], dtype=int))\n\ntests/core/test_utils.py:48: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\narray = array([], dtype=float64), idx = array([], dtype=int64)\nshould_be_broadcast = False\n\n    def _check_smart_index(array, idx, should_be_broadcast=False):\n        result = smart_array_index(array, idx)\n        np.testing.assert_array_equal(result, array[idx])\n    \n        if should_be_broadcast:\n            assert result.strides[0] == 0\n        else:\n>           assert result.strides[0] > 0\nE           assert 0 > 0\n\ntests/core/test_utils.py:42: AssertionError\n______________ TestBiasedWeightedRandomWalk.test_init_parameters _______________\n\nself = <tests.data.test_biased_random_walker.TestBiasedWeightedRandomWalk object at 0x7fc1ac738dc0>\n\n    def test_init_parameters(self):\n        g = weighted(1, 2, 3, 4)\n        nodes = list(g.nodes())\n        n = 4\n        length = 4\n        seed = 42\n        p = 1.0\n        q = 1.0\n    \n        rw = BiasedRandomWalk(g, n=n, p=p, q=q, length=length, seed=seed, weighted=True)\n        rw_no_params = BiasedRandomWalk(g)\n    \n>       run_1 = rw.run(nodes=nodes)\n\ntests/data/test_biased_random_walker.py:105: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/data/explorer.py:459: in run\n    cast_func = np.cast[weight_dtype]\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'cast'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n>           raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\nE           AttributeError: `np.cast` was removed in the NumPy 2.0 release. Use `np.asarray(arr, dtype=dtype)` instead.\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:400: AttributeError\n____ TestBiasedWeightedRandomWalk.test_identity_unweighted_weighted_1_walks ____\n\nself = <tests.data.test_biased_random_walker.TestBiasedWeightedRandomWalk object at 0x7fc1ac738fa0>\n\n    def test_identity_unweighted_weighted_1_walks(self):\n    \n        # graph with all edge weights = 1\n        g = weighted(1, 1, 1, 1)\n        nodes = g.nodes()\n        n = 4\n        length = 4\n        seed = 42\n        p = 1.0\n        q = 1.0\n    \n        biasedrw = BiasedRandomWalk(g)\n>       run_1 = biasedrw.run(\n            nodes=nodes, n=n, p=p, q=q, length=length, seed=seed, weighted=True\n        )\n\ntests/data/test_biased_random_walker.py:123: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/data/explorer.py:459: in run\n    cast_func = np.cast[weight_dtype]\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'cast'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n>           raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\nE           AttributeError: `np.cast` was removed in the NumPy 2.0 release. Use `np.asarray(arr, dtype=dtype)` instead.\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:400: AttributeError\n_______________ TestBiasedWeightedRandomWalk.test_weighted_walks _______________\n\nself = <tests.data.test_biased_random_walker.TestBiasedWeightedRandomWalk object at 0x7fc1ac739120>\n\n    def test_weighted_walks(self):\n    \n        # all positive walks\n        g = weighted(1, 2, 3, 4)\n    \n        nodes = list(g.nodes())\n        n = 1\n        length = 1\n        seed = None\n        p = 1.0\n        q = 1.0\n    \n        biasedrw = BiasedRandomWalk(g)\n        assert (\n            len(\n>               biasedrw.run(\n                    nodes=nodes, n=n, p=p, q=q, length=length, seed=seed, weighted=True\n                )\n            )\n            == 4\n        )\n\ntests/data/test_biased_random_walker.py:146: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/data/explorer.py:459: in run\n    cast_func = np.cast[weight_dtype]\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'cast'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n>           raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\nE           AttributeError: `np.cast` was removed in the NumPy 2.0 release. Use `np.asarray(arr, dtype=dtype)` instead.\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:400: AttributeError\n____________ TestBiasedWeightedRandomWalk.test_weighted_graph_label ____________\n\nself = <tests.data.test_biased_random_walker.TestBiasedWeightedRandomWalk object at 0x7fc1ac7392a0>\n\n    def test_weighted_graph_label(self):\n    \n        g = nx.Graph()\n        edges = [(1, 2), (2, 3), (3, 4), (4, 1)]\n        g.add_edges_from(edges)\n        g[1][2][\"w\"] = 1\n        g[2][3][\"w\"] = 2\n        g[3][4][\"w\"] = 3\n        g[4][1][\"w\"] = 4\n    \n        g = StellarGraph.from_networkx(g, edge_weight_attr=\"w\")\n    \n        nodes = list(g.nodes())\n        n = 1\n        length = 1\n        seed = None\n        p = 1.0\n        q = 1.0\n    \n        biasedrw = BiasedRandomWalk(g)\n    \n        assert (\n            len(\n>               biasedrw.run(\n                    nodes=nodes, n=n, p=p, q=q, length=length, seed=seed, weighted=True\n                )\n            )\n            == 4\n        )\n\ntests/data/test_biased_random_walker.py:213: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/data/explorer.py:459: in run\n    cast_func = np.cast[weight_dtype]\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'cast'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n>           raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\nE           AttributeError: `np.cast` was removed in the NumPy 2.0 release. Use `np.asarray(arr, dtype=dtype)` instead.\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:400: AttributeError\n_________________ TestBiasedRandomWalk.test_parameter_checking _________________\n\nself = <tests.data.test_biased_random_walker.TestBiasedRandomWalk object at 0x7fc1ac739630>\n\n    def test_parameter_checking(self):\n        g = create_test_graph()\n        biasedrw = BiasedRandomWalk(g)\n    \n        nodes = [\"0\"]\n        n = 1\n        length = 2\n        p = 1.0\n        q = 1.0\n        seed = None\n    \n        with pytest.raises(ValueError):\n            # nodes should be a list of node ids even for a single node\n            biasedrw.run(nodes=None, n=n, p=p, q=q, length=length, seed=seed)\n        with pytest.raises(ValueError):\n            biasedrw.run(\n                nodes=\"0\", n=n, p=p, q=q, length=length, seed=seed\n            )  # can't just pass a node id, need list, e.g., [\"0\"]\n    \n        # n has to be positive integer\n        with pytest.raises(ValueError):\n            biasedrw.run(nodes=nodes, n=0, p=p, q=q, length=length, seed=seed)\n        with pytest.raises(ValueError):\n            biasedrw.run(nodes=nodes, n=-121, p=p, q=q, length=length, seed=seed)\n        with pytest.raises(TypeError):\n            biasedrw.run(nodes=nodes, n=21.4, p=p, q=q, length=length, seed=seed)\n        with pytest.raises(TypeError):\n            biasedrw.run(nodes=nodes, n=-0.5, p=p, q=q, length=length, seed=seed)\n        with pytest.raises(TypeError):\n            biasedrw.run(nodes=nodes, n=0.0001, p=p, q=q, length=length, seed=seed)\n        with pytest.raises(TypeError):\n            biasedrw.run(nodes=nodes, n=\"2\", p=p, q=q, length=length, seed=seed)\n    \n        # p has to be > 0.\n        with pytest.raises(ValueError):\n            biasedrw.run(nodes=nodes, n=n, p=0.0, q=q, length=length, seed=seed)\n        with pytest.raises(ValueError):\n            biasedrw.run(nodes=nodes, n=n, p=-0.25, q=q, length=length, seed=seed)\n        with pytest.raises(ValueError):\n            biasedrw.run(nodes=nodes, n=n, p=-1, q=q, length=length, seed=seed)\n    \n        # q has to be > 0.\n        with pytest.raises(ValueError):\n            biasedrw.run(nodes=nodes, n=n, p=p, q=0.0, length=length, seed=seed)\n        with pytest.raises(ValueError):\n            biasedrw.run(nodes=nodes, n=n, p=p, q=-0.9, length=length, seed=seed)\n        with pytest.raises(ValueError):\n            biasedrw.run(nodes=nodes, n=n, p=p, q=-75, length=length, seed=seed)\n    \n        # length has to be positive integer\n        with pytest.raises(ValueError):\n            biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=0, seed=seed)\n        with pytest.raises(ValueError):\n            biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=-5, seed=seed)\n        with pytest.raises(TypeError):\n            biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=11.9, seed=seed)\n        with pytest.raises(TypeError):\n            biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=-9.9, seed=seed)\n        with pytest.raises(TypeError):\n            biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=\"10\", seed=seed)\n    \n        # seed has to be None, 0,  or positive integer\n        with pytest.raises(ValueError):\n            biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=-1)\n        with pytest.raises(TypeError):\n            biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=1010.8)\n    \n        # If no root nodes are given, an empty list is returned which is not an error but I thought this method\n        # is the best for checking this behaviour.\n        nodes = []\n>       subgraph = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=None)\n\ntests/data/test_biased_random_walker.py:316: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/data/explorer.py:459: in run\n    cast_func = np.cast[weight_dtype]\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'cast'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n>           raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\nE           AttributeError: `np.cast` was removed in the NumPy 2.0 release. Use `np.asarray(arr, dtype=dtype)` instead.\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:400: AttributeError\n__________ TestBiasedRandomWalk.test_walk_generation_single_root_node __________\n\nself = <tests.data.test_biased_random_walker.TestBiasedRandomWalk object at 0x7fc1ac7397b0>\n\n    def test_walk_generation_single_root_node(self):\n    \n        g = create_test_graph()\n        biasedrw = BiasedRandomWalk(g)\n    \n        nodes = [\"0\"]\n        n = 1\n        length = 1\n        seed = 42\n        p = 0.25\n        q = 0.5\n    \n>       subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n\ntests/data/test_biased_random_walker.py:331: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/data/explorer.py:459: in run\n    cast_func = np.cast[weight_dtype]\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'cast'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n>           raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\nE           AttributeError: `np.cast` was removed in the NumPy 2.0 release. Use `np.asarray(arr, dtype=dtype)` instead.\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:400: AttributeError\n__________ TestBiasedRandomWalk.test_walk_generation_many_root_nodes ___________\n\nself = <tests.data.test_biased_random_walker.TestBiasedRandomWalk object at 0x7fc1ac739930>\n\n    def test_walk_generation_many_root_nodes(self):\n    \n        g = create_test_graph()\n        biasedrw = BiasedRandomWalk(g)\n    \n        nodes = [\"0\", 2]\n        n = 1\n        length = 1\n        seed = None\n        p = 1.0\n        q = 0.3\n    \n>       subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n\ntests/data/test_biased_random_walker.py:364: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/data/explorer.py:459: in run\n    cast_func = np.cast[weight_dtype]\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'cast'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n>           raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\nE           AttributeError: `np.cast` was removed in the NumPy 2.0 release. Use `np.asarray(arr, dtype=dtype)` instead.\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:400: AttributeError\n__________ TestBiasedRandomWalk.test_walk_generation_loner_root_node ___________\n\nself = <tests.data.test_biased_random_walker.TestBiasedRandomWalk object at 0x7fc1ac739ab0>\n\n    def test_walk_generation_loner_root_node(self):\n    \n        g = create_test_graph()\n        biasedrw = BiasedRandomWalk(g)\n    \n        nodes = [\"loner\"]  # this node has no edges including itself\n        n = 1\n        length = 1\n        seed = None\n        p = 0.5\n        q = 1.0\n    \n>       subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n\ntests/data/test_biased_random_walker.py:408: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/data/explorer.py:459: in run\n    cast_func = np.cast[weight_dtype]\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'cast'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n>           raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\nE           AttributeError: `np.cast` was removed in the NumPy 2.0 release. Use `np.asarray(arr, dtype=dtype)` instead.\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:400: AttributeError\n________ TestBiasedRandomWalk.test_walk_generation_self_loner_root_node ________\n\nself = <tests.data.test_biased_random_walker.TestBiasedRandomWalk object at 0x7fc1ac739c30>\n\n    def test_walk_generation_self_loner_root_node(self):\n    \n        g = create_test_graph()\n        biasedrw = BiasedRandomWalk(g)\n    \n        nodes = [\"self loner\"]  # this node has link to self but no other edges\n        n = 1\n        length = 1\n        seed = None\n        p = 1.0\n        q = 1.0\n    \n>       subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n\ntests/data/test_biased_random_walker.py:444: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/data/explorer.py:459: in run\n    cast_func = np.cast[weight_dtype]\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'cast'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n>           raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\nE           AttributeError: `np.cast` was removed in the NumPy 2.0 release. Use `np.asarray(arr, dtype=dtype)` instead.\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:400: AttributeError\n____________________ TestBiasedRandomWalk.test_walk_biases _____________________\n\nself = <tests.data.test_biased_random_walker.TestBiasedRandomWalk object at 0x7fc1ac739db0>\n\n    def test_walk_biases(self):\n        # a square with a triangle:\n        #   0-3\n        #  /| |\n        # 1-2-4\n        nodes = pd.DataFrame(index=range(5))\n        edges = pd.DataFrame(\n            [(0, 1), (0, 2), (0, 3), (1, 2), (2, 4), (3, 4)],\n            columns=[\"source\", \"target\"],\n        )\n        graph = StellarGraph(nodes, edges)\n        biasedrw = BiasedRandomWalk(graph)\n    \n        # there's 18 total walks of length 4 starting at 0 in `graph`,\n        # and the non-tiny transition probabilities are always equal\n        # so with a large enough sample, all the possible paths for a\n        # given p, q should come up.\n        nodes = [0]\n        n = 1000\n        seed = None\n        length = 4\n    \n        always = 1e-20\n        never = 1e20\n    \n        # always return to the last visited node\n        p = always\n        q = never\n        walks = {\n            tuple(w)\n>           for w in biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n        }\n\ntests/data/test_biased_random_walker.py:505: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/data/explorer.py:459: in run\n    cast_func = np.cast[weight_dtype]\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'cast'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n>           raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\nE           AttributeError: `np.cast` was removed in the NumPy 2.0 release. Use `np.asarray(arr, dtype=dtype)` instead.\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:400: AttributeError\n_______ TestBreadthFirstWalk.test_walk_generation_single_root_node_loner _______\n\nself = <tests.data.test_breadth_first_walker.TestBreadthFirstWalk object at 0x7fc1ac739ae0>\n\n    def test_walk_generation_single_root_node_loner(self):\n        g = create_test_graph()\n        bfw = SampledBreadthFirstWalk(g)\n    \n        nodes = g.node_ids_to_ilocs([\"loner\"])\n        n = 1\n        n_size = [0]\n    \n>       subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n\ntests/data/test_breadth_first_walker.py:110: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/data/explorer.py:733: in run\n    neighbours = self._sample_neighbours_untyped(\nstellargraph/data/explorer.py:242: in _sample_neighbours_untyped\n    neighbours = neigh_func(\nstellargraph/core/graph.py:792: in neighbor_arrays\n    edge_ilocs = self._edges.edge_ilocs(node, ins=True, outs=True)\nstellargraph/core/element_data.py:452: in edge_ilocs\n    return self._adj_lookup(ins=ins, outs=outs)[node_id]\nstellargraph/core/element_data.py:410: in _adj_lookup\n    self._init_undirected_adj_lists()\nstellargraph/core/element_data.py:365: in _init_undirected_adj_lists\n    self._edges_dict = self._create_undirected_adj_lists()\nstellargraph/core/element_data.py:377: in _create_undirected_adj_lists\n    sentinel = np.cast[np.min_scalar_type(self.number_of_nodes)](-1)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'cast'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n>           raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\nE           AttributeError: `np.cast` was removed in the NumPy 2.0 release. Use `np.asarray(arr, dtype=dtype)` instead.\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:400: AttributeError\n_____ TestBreadthFirstWalk.test_directed_walk_generation_single_root_node ______\n\nself = <tests.data.test_breadth_first_walker.TestBreadthFirstWalk object at 0x7fc1ac739750>\ntree_graph = <stellargraph.core.graph.StellarDiGraph object at 0x7fc1ac20f130>\n\n    def test_directed_walk_generation_single_root_node(self, tree_graph):\n        def _check_directed_walk(walk, n_size):\n            if len(n_size) > 1 and n_size[0] > 0 and n_size[1] > 0:\n                for child_pos in range(n_size[0]):\n                    child = walk[child_pos + 1]\n                    grandchildren_start = 1 + n_size[0] + child_pos * n_size[1]\n                    grandchildren_end = grandchildren_start + n_size[1]\n                    grandchildren = walk[grandchildren_start:grandchildren_end]\n                    if child == \"root\":  # node with three children\n                        for grandchild in grandchildren:\n                            assert grandchild in [0, 1, 2]\n                    elif child == \"0\":  # node without children\n                        for grandchild in grandchildren:\n                            assert grandchild == \"root\"\n                    elif child == 1:  # node with single child\n                        for grandchild in grandchildren:\n                            assert grandchild in [\"c1.1\", \"root\"]\n                    elif child == 2:  # node with two children\n                        for grandchild in grandchildren:\n                            assert grandchild in [\"c2.1\", \"c2.2\", \"root\"]\n                    else:\n                        assert 1 == 0\n    \n        bfw = SampledBreadthFirstWalk(tree_graph)\n    \n        nodes = tree_graph.node_ids_to_ilocs([\"root\"])\n        n = 1\n        n_size = [0]\n    \n>       subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n\ntests/data/test_breadth_first_walker.py:203: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/data/explorer.py:733: in run\n    neighbours = self._sample_neighbours_untyped(\nstellargraph/data/explorer.py:242: in _sample_neighbours_untyped\n    neighbours = neigh_func(\nstellargraph/core/graph.py:792: in neighbor_arrays\n    edge_ilocs = self._edges.edge_ilocs(node, ins=True, outs=True)\nstellargraph/core/element_data.py:452: in edge_ilocs\n    return self._adj_lookup(ins=ins, outs=outs)[node_id]\nstellargraph/core/element_data.py:410: in _adj_lookup\n    self._init_undirected_adj_lists()\nstellargraph/core/element_data.py:365: in _init_undirected_adj_lists\n    self._edges_dict = self._create_undirected_adj_lists()\nstellargraph/core/element_data.py:377: in _create_undirected_adj_lists\n    sentinel = np.cast[np.min_scalar_type(self.number_of_nodes)](-1)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'cast'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n>           raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\nE           AttributeError: `np.cast` was removed in the NumPy 2.0 release. Use `np.asarray(arr, dtype=dtype)` instead.\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:400: AttributeError\n____ TestBreadthFirstWalk.test_walk_generation_single_root_node_self_loner _____\n\nself = <tests.data.test_breadth_first_walker.TestBreadthFirstWalk object at 0x7fc1ac739390>\n\n    def test_walk_generation_single_root_node_self_loner(self):\n        g = create_test_graph()\n        bfw = SampledBreadthFirstWalk(g)\n    \n        nodes = g.node_ids_to_ilocs([\"self loner\"])\n        n = 1\n    \n        n_size = [0]\n>       subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n\ntests/data/test_breadth_first_walker.py:276: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/data/explorer.py:733: in run\n    neighbours = self._sample_neighbours_untyped(\nstellargraph/data/explorer.py:242: in _sample_neighbours_untyped\n    neighbours = neigh_func(\nstellargraph/core/graph.py:792: in neighbor_arrays\n    edge_ilocs = self._edges.edge_ilocs(node, ins=True, outs=True)\nstellargraph/core/element_data.py:452: in edge_ilocs\n    return self._adj_lookup(ins=ins, outs=outs)[node_id]\nstellargraph/core/element_data.py:410: in _adj_lookup\n    self._init_undirected_adj_lists()\nstellargraph/core/element_data.py:365: in _init_undirected_adj_lists\n    self._edges_dict = self._create_undirected_adj_lists()\nstellargraph/core/element_data.py:377: in _create_undirected_adj_lists\n    sentinel = np.cast[np.min_scalar_type(self.number_of_nodes)](-1)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'cast'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n>           raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\nE           AttributeError: `np.cast` was removed in the NumPy 2.0 release. Use `np.asarray(arr, dtype=dtype)` instead.\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:400: AttributeError\n__________ TestBreadthFirstWalk.test_walk_generation_single_root_node __________\n\nself = <tests.data.test_breadth_first_walker.TestBreadthFirstWalk object at 0x7fc1ac738b50>\n\n    def test_walk_generation_single_root_node(self):\n    \n        g = create_test_graph()\n        bfw = SampledBreadthFirstWalk(g)\n    \n        nodes = g.node_ids_to_ilocs([\"0\"])\n        n = 1\n        n_size = [0]\n    \n>       subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n\ntests/data/test_breadth_first_walker.py:337: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/data/explorer.py:733: in run\n    neighbours = self._sample_neighbours_untyped(\nstellargraph/data/explorer.py:242: in _sample_neighbours_untyped\n    neighbours = neigh_func(\nstellargraph/core/graph.py:792: in neighbor_arrays\n    edge_ilocs = self._edges.edge_ilocs(node, ins=True, outs=True)\nstellargraph/core/element_data.py:452: in edge_ilocs\n    return self._adj_lookup(ins=ins, outs=outs)[node_id]\nstellargraph/core/element_data.py:410: in _adj_lookup\n    self._init_undirected_adj_lists()\nstellargraph/core/element_data.py:365: in _init_undirected_adj_lists\n    self._edges_dict = self._create_undirected_adj_lists()\nstellargraph/core/element_data.py:377: in _create_undirected_adj_lists\n    sentinel = np.cast[np.min_scalar_type(self.number_of_nodes)](-1)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'cast'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n>           raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\nE           AttributeError: `np.cast` was removed in the NumPy 2.0 release. Use `np.asarray(arr, dtype=dtype)` instead.\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:400: AttributeError\n__________ TestBreadthFirstWalk.test_walk_generation_many_root_nodes ___________\n\nself = <tests.data.test_breadth_first_walker.TestBreadthFirstWalk object at 0x7fc1ac73a800>\n\n    def test_walk_generation_many_root_nodes(self):\n    \n        g = create_test_graph()\n        bfw = SampledBreadthFirstWalk(g)\n    \n        nodes = g.node_ids_to_ilocs([\"0\", 2])\n        n = 1\n        n_size = [0]\n    \n>       subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n\ntests/data/test_breadth_first_walker.py:380: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/data/explorer.py:733: in run\n    neighbours = self._sample_neighbours_untyped(\nstellargraph/data/explorer.py:242: in _sample_neighbours_untyped\n    neighbours = neigh_func(\nstellargraph/core/graph.py:792: in neighbor_arrays\n    edge_ilocs = self._edges.edge_ilocs(node, ins=True, outs=True)\nstellargraph/core/element_data.py:452: in edge_ilocs\n    return self._adj_lookup(ins=ins, outs=outs)[node_id]\nstellargraph/core/element_data.py:410: in _adj_lookup\n    self._init_undirected_adj_lists()\nstellargraph/core/element_data.py:365: in _init_undirected_adj_lists\n    self._edges_dict = self._create_undirected_adj_lists()\nstellargraph/core/element_data.py:377: in _create_undirected_adj_lists\n    sentinel = np.cast[np.min_scalar_type(self.number_of_nodes)](-1)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'cast'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n>           raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\nE           AttributeError: `np.cast` was removed in the NumPy 2.0 release. Use `np.asarray(arr, dtype=dtype)` instead.\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:400: AttributeError\n___ TestBreadthFirstWalk.test_walk_generation_number_of_walks_per_root_nodes ___\n\nself = <tests.data.test_breadth_first_walker.TestBreadthFirstWalk object at 0x7fc1ac73a980>\n\n    def test_walk_generation_number_of_walks_per_root_nodes(self):\n    \n        g = create_test_graph()\n        bfw = SampledBreadthFirstWalk(g)\n    \n        nodes = [1]\n        n = 2\n        n_size = [0]\n    \n>       subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n\ntests/data/test_breadth_first_walker.py:443: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/data/explorer.py:733: in run\n    neighbours = self._sample_neighbours_untyped(\nstellargraph/data/explorer.py:242: in _sample_neighbours_untyped\n    neighbours = neigh_func(\nstellargraph/core/graph.py:792: in neighbor_arrays\n    edge_ilocs = self._edges.edge_ilocs(node, ins=True, outs=True)\nstellargraph/core/element_data.py:452: in edge_ilocs\n    return self._adj_lookup(ins=ins, outs=outs)[node_id]\nstellargraph/core/element_data.py:410: in _adj_lookup\n    self._init_undirected_adj_lists()\nstellargraph/core/element_data.py:365: in _init_undirected_adj_lists\n    self._edges_dict = self._create_undirected_adj_lists()\nstellargraph/core/element_data.py:377: in _create_undirected_adj_lists\n    sentinel = np.cast[np.min_scalar_type(self.number_of_nodes)](-1)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'cast'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n>           raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\nE           AttributeError: `np.cast` was removed in the NumPy 2.0 release. Use `np.asarray(arr, dtype=dtype)` instead.\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:400: AttributeError\n_________________ TestBreadthFirstWalk.test_fixed_random_seed __________________\n\nself = <tests.data.test_breadth_first_walker.TestBreadthFirstWalk object at 0x7fc1ac73ab00>\n\n    def test_fixed_random_seed(self):\n    \n        g = create_test_graph()\n        _conv = g.node_ids_to_ilocs\n        bfw = SampledBreadthFirstWalk(g)\n    \n>       w0 = bfw.run(nodes=_conv([1]), n=1, n_size=[7], seed=42)\n\ntests/data/test_breadth_first_walker.py:517: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/data/explorer.py:733: in run\n    neighbours = self._sample_neighbours_untyped(\nstellargraph/data/explorer.py:242: in _sample_neighbours_untyped\n    neighbours = neigh_func(\nstellargraph/core/graph.py:792: in neighbor_arrays\n    edge_ilocs = self._edges.edge_ilocs(node, ins=True, outs=True)\nstellargraph/core/element_data.py:452: in edge_ilocs\n    return self._adj_lookup(ins=ins, outs=outs)[node_id]\nstellargraph/core/element_data.py:410: in _adj_lookup\n    self._init_undirected_adj_lists()\nstellargraph/core/element_data.py:365: in _init_undirected_adj_lists\n    self._edges_dict = self._create_undirected_adj_lists()\nstellargraph/core/element_data.py:377: in _create_undirected_adj_lists\n    sentinel = np.cast[np.min_scalar_type(self.number_of_nodes)](-1)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'cast'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n>           raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\nE           AttributeError: `np.cast` was removed in the NumPy 2.0 release. Use `np.asarray(arr, dtype=dtype)` instead.\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:400: AttributeError\n______________________ TestBreadthFirstWalk.test_weighted ______________________\n\nself = <tests.data.test_breadth_first_walker.TestBreadthFirstWalk object at 0x7fc1ac73afb0>\n\n    def test_weighted(self):\n        g, checker = weighted_tree()\n        bfw = SampledBreadthFirstWalk(g)\n>       walks = bfw.run(nodes=[0], n=10, n_size=[20, 20], weighted=True)\n\ntests/data/test_breadth_first_walker.py:561: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/data/explorer.py:733: in run\n    neighbours = self._sample_neighbours_untyped(\nstellargraph/data/explorer.py:242: in _sample_neighbours_untyped\n    neighbours = neigh_func(\nstellargraph/core/graph.py:792: in neighbor_arrays\n    edge_ilocs = self._edges.edge_ilocs(node, ins=True, outs=True)\nstellargraph/core/element_data.py:452: in edge_ilocs\n    return self._adj_lookup(ins=ins, outs=outs)[node_id]\nstellargraph/core/element_data.py:410: in _adj_lookup\n    self._init_undirected_adj_lists()\nstellargraph/core/element_data.py:365: in _init_undirected_adj_lists\n    self._edges_dict = self._create_undirected_adj_lists()\nstellargraph/core/element_data.py:377: in _create_undirected_adj_lists\n    sentinel = np.cast[np.min_scalar_type(self.number_of_nodes)](-1)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'cast'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n>           raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\nE           AttributeError: `np.cast` was removed in the NumPy 2.0 release. Use `np.asarray(arr, dtype=dtype)` instead.\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:400: AttributeError\n_________________ TestBreadthFirstWalk.test_weighted_all_zero __________________\n\nself = <tests.data.test_breadth_first_walker.TestBreadthFirstWalk object at 0x7fc1ac73b130>\n\n    def test_weighted_all_zero(self):\n        edges = pd.DataFrame({\"source\": [0, 0], \"target\": [1, 2], \"weight\": [0.0, 0]})\n    \n        g = StellarGraph(edges=edges)\n        bfw = SampledBreadthFirstWalk(g)\n>       walks = bfw.run(nodes=[0], n=10, n_size=[20, 20], weighted=True)\n\ntests/data/test_breadth_first_walker.py:570: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/data/explorer.py:733: in run\n    neighbours = self._sample_neighbours_untyped(\nstellargraph/data/explorer.py:242: in _sample_neighbours_untyped\n    neighbours = neigh_func(\nstellargraph/core/graph.py:792: in neighbor_arrays\n    edge_ilocs = self._edges.edge_ilocs(node, ins=True, outs=True)\nstellargraph/core/element_data.py:452: in edge_ilocs\n    return self._adj_lookup(ins=ins, outs=outs)[node_id]\nstellargraph/core/element_data.py:410: in _adj_lookup\n    self._init_undirected_adj_lists()\nstellargraph/core/element_data.py:365: in _init_undirected_adj_lists\n    self._edges_dict = self._create_undirected_adj_lists()\nstellargraph/core/element_data.py:377: in _create_undirected_adj_lists\n    sentinel = np.cast[np.min_scalar_type(self.number_of_nodes)](-1)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'cast'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n>           raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\nE           AttributeError: `np.cast` was removed in the NumPy 2.0 release. Use `np.asarray(arr, dtype=dtype)` instead.\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:400: AttributeError\n_________ TestMetaPathWalk.test_walk_generation_single_root_node_loner _________\n\nself = <tests.data.test_metapath_walker.TestMetaPathWalk object at 0x7fc1ac763490>\n\n    def test_walk_generation_single_root_node_loner(self):\n        g = create_test_graph()\n        mrw = UniformRandomMetaPathWalk(g)\n    \n        seed = None\n        nodes = [\"loner\"]  # has no edges, not even to itself\n        n = 1\n        length = 5\n        metapaths = [[\"s\", \"n\", \"s\"]]\n    \n>       walks = mrw.run(nodes=nodes, n=n, length=length, metapaths=metapaths, seed=seed)\n\ntests/data/test_metapath_walker.py:168: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/data/explorer.py:626: in run\n    neighbours = self.graph.neighbor_arrays(\nstellargraph/core/graph.py:792: in neighbor_arrays\n    edge_ilocs = self._edges.edge_ilocs(node, ins=True, outs=True)\nstellargraph/core/element_data.py:452: in edge_ilocs\n    return self._adj_lookup(ins=ins, outs=outs)[node_id]\nstellargraph/core/element_data.py:410: in _adj_lookup\n    self._init_undirected_adj_lists()\nstellargraph/core/element_data.py:365: in _init_undirected_adj_lists\n    self._edges_dict = self._create_undirected_adj_lists()\nstellargraph/core/element_data.py:377: in _create_undirected_adj_lists\n    sentinel = np.cast[np.min_scalar_type(self.number_of_nodes)](-1)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'cast'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n>           raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\nE           AttributeError: `np.cast` was removed in the NumPy 2.0 release. Use `np.asarray(arr, dtype=dtype)` instead.\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:400: AttributeError\n______ TestMetaPathWalk.test_walk_generation_single_root_node_self_loner _______\n\nself = <tests.data.test_metapath_walker.TestMetaPathWalk object at 0x7fc1ac763100>\n\n    def test_walk_generation_single_root_node_self_loner(self):\n        g = create_test_graph()\n        mrw = UniformRandomMetaPathWalk(g)\n    \n        seed = None\n        nodes = [\"self loner\"]  # this node has self edges but not other edges\n        n = 1\n        length = 10\n        metapaths = [[\"s\", \"n\", \"n\", \"s\"]]\n    \n>       walks = mrw.run(nodes=nodes, n=n, length=length, metapaths=metapaths, seed=seed)\n\ntests/data/test_metapath_walker.py:188: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/data/explorer.py:626: in run\n    neighbours = self.graph.neighbor_arrays(\nstellargraph/core/graph.py:792: in neighbor_arrays\n    edge_ilocs = self._edges.edge_ilocs(node, ins=True, outs=True)\nstellargraph/core/element_data.py:452: in edge_ilocs\n    return self._adj_lookup(ins=ins, outs=outs)[node_id]\nstellargraph/core/element_data.py:410: in _adj_lookup\n    self._init_undirected_adj_lists()\nstellargraph/core/element_data.py:365: in _init_undirected_adj_lists\n    self._edges_dict = self._create_undirected_adj_lists()\nstellargraph/core/element_data.py:377: in _create_undirected_adj_lists\n    sentinel = np.cast[np.min_scalar_type(self.number_of_nodes)](-1)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'cast'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n>           raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\nE           AttributeError: `np.cast` was removed in the NumPy 2.0 release. Use `np.asarray(arr, dtype=dtype)` instead.\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:400: AttributeError\n____________ TestMetaPathWalk.test_walk_generation_single_root_node ____________\n\nself = <tests.data.test_metapath_walker.TestMetaPathWalk object at 0x7fc1ac762830>\n\n    def test_walk_generation_single_root_node(self):\n    \n        g = create_test_graph()\n        mrw = UniformRandomMetaPathWalk(g)\n    \n        nodes = [\"0\"]\n        n = 1\n        length = 15\n        metapaths = [[\"s\", \"n\", \"n\", \"s\"]]\n        seed = 42\n    \n>       walks = mrw.run(nodes=nodes, n=n, length=length, metapaths=metapaths, seed=seed)\n\ntests/data/test_metapath_walker.py:212: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/data/explorer.py:626: in run\n    neighbours = self.graph.neighbor_arrays(\nstellargraph/core/graph.py:792: in neighbor_arrays\n    edge_ilocs = self._edges.edge_ilocs(node, ins=True, outs=True)\nstellargraph/core/element_data.py:452: in edge_ilocs\n    return self._adj_lookup(ins=ins, outs=outs)[node_id]\nstellargraph/core/element_data.py:410: in _adj_lookup\n    self._init_undirected_adj_lists()\nstellargraph/core/element_data.py:365: in _init_undirected_adj_lists\n    self._edges_dict = self._create_undirected_adj_lists()\nstellargraph/core/element_data.py:377: in _create_undirected_adj_lists\n    sentinel = np.cast[np.min_scalar_type(self.number_of_nodes)](-1)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'cast'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n>           raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\nE           AttributeError: `np.cast` was removed in the NumPy 2.0 release. Use `np.asarray(arr, dtype=dtype)` instead.\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:400: AttributeError\n____________ TestMetaPathWalk.test_walk_generation_many_root_nodes _____________\n\nself = <tests.data.test_metapath_walker.TestMetaPathWalk object at 0x7fc1ac760ac0>\n\n    def test_walk_generation_many_root_nodes(self):\n    \n        g = create_test_graph()\n        mrw = UniformRandomMetaPathWalk(g)\n    \n        nodes = [\"0\", 2]\n        n = 1\n        length = 15\n        metapaths = [[\"s\", \"n\", \"n\", \"s\"]]\n        seed = 42\n    \n>       walks = mrw.run(nodes=nodes, n=n, length=length, metapaths=metapaths, seed=seed)\n\ntests/data/test_metapath_walker.py:256: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/data/explorer.py:626: in run\n    neighbours = self.graph.neighbor_arrays(\nstellargraph/core/graph.py:792: in neighbor_arrays\n    edge_ilocs = self._edges.edge_ilocs(node, ins=True, outs=True)\nstellargraph/core/element_data.py:452: in edge_ilocs\n    return self._adj_lookup(ins=ins, outs=outs)[node_id]\nstellargraph/core/element_data.py:410: in _adj_lookup\n    self._init_undirected_adj_lists()\nstellargraph/core/element_data.py:365: in _init_undirected_adj_lists\n    self._edges_dict = self._create_undirected_adj_lists()\nstellargraph/core/element_data.py:377: in _create_undirected_adj_lists\n    sentinel = np.cast[np.min_scalar_type(self.number_of_nodes)](-1)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'cast'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n>           raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\nE           AttributeError: `np.cast` was removed in the NumPy 2.0 release. Use `np.asarray(arr, dtype=dtype)` instead.\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:400: AttributeError\n____________________ TestMetaPathWalk.test_init_parameters _____________________\n\nself = <tests.data.test_metapath_walker.TestMetaPathWalk object at 0x7fc1ac761750>\n\n    def test_init_parameters(self):\n        g = create_test_graph()\n        n = 2\n        length = 15\n        metapaths = [[\"s\", \"n\", \"n\", \"s\"]]\n        seed = 42\n        nodes = [\"0\", \"5\"]\n    \n        mrw = UniformRandomMetaPathWalk(\n            g, n=n, length=length, metapaths=metapaths, seed=seed\n        )\n        mrw_no_params = UniformRandomMetaPathWalk(g)\n    \n>       run_1 = mrw.run(nodes=nodes)\n\ntests/data/test_metapath_walker.py:312: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/data/explorer.py:626: in run\n    neighbours = self.graph.neighbor_arrays(\nstellargraph/core/graph.py:792: in neighbor_arrays\n    edge_ilocs = self._edges.edge_ilocs(node, ins=True, outs=True)\nstellargraph/core/element_data.py:452: in edge_ilocs\n    return self._adj_lookup(ins=ins, outs=outs)[node_id]\nstellargraph/core/element_data.py:410: in _adj_lookup\n    self._init_undirected_adj_lists()\nstellargraph/core/element_data.py:365: in _init_undirected_adj_lists\n    self._edges_dict = self._create_undirected_adj_lists()\nstellargraph/core/element_data.py:377: in _create_undirected_adj_lists\n    sentinel = np.cast[np.min_scalar_type(self.number_of_nodes)](-1)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'cast'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n>           raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\nE           AttributeError: `np.cast` was removed in the NumPy 2.0 release. Use `np.asarray(arr, dtype=dtype)` instead.\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:400: AttributeError\n_____________________________ test_temporal_walks ______________________________\n\ntemporal_graph = <stellargraph.core.graph.StellarGraph object at 0x7fc18c7778b0>\n\n    def test_temporal_walks(temporal_graph):\n    \n        \"\"\"\n        valid time respecting walks (node -[time]-> node):\n    \n            1 -[2]-> 2 -[10]-> 4\n            2 -[10]-> 4 -[12]-> 6\n            3 -[2]-> 2 -[10]-> 4\n            5 -[4]-> 4 -[12]-> 6\n            1 -[2]-> 2 -[10]-> 4 -[12]-> 6\n            3 -[2]-> 2 -[10]-> 4 -[12] -> 6\n        \"\"\"\n        expected = {(1, 2, 4), (2, 4, 6), (3, 2, 4), (5, 4, 6), (1, 2, 4, 6), (3, 2, 4, 6)}\n    \n        rw = TemporalRandomWalk(temporal_graph)\n        num_cw = 20  # how many walks to be sure we're getting valid temporal walks\n    \n>       for walk in rw.run(num_cw=num_cw, cw_size=3, max_walk_length=4, seed=None):\n\ntests/data/test_temporal_random_walker.py:52: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/data/explorer.py:1116: in run\n    walk = self._walk(\nstellargraph/data/explorer.py:1183: in _walk\n    result = self._step(node, time=time, bias_type=bias_type, np_rs=np_rs)\nstellargraph/data/explorer.py:1164: in _step\n    neighbours, times = self.graph.neighbor_arrays(node, include_edge_weight=True)\nstellargraph/core/graph.py:792: in neighbor_arrays\n    edge_ilocs = self._edges.edge_ilocs(node, ins=True, outs=True)\nstellargraph/core/element_data.py:452: in edge_ilocs\n    return self._adj_lookup(ins=ins, outs=outs)[node_id]\nstellargraph/core/element_data.py:410: in _adj_lookup\n    self._init_undirected_adj_lists()\nstellargraph/core/element_data.py:365: in _init_undirected_adj_lists\n    self._edges_dict = self._create_undirected_adj_lists()\nstellargraph/core/element_data.py:377: in _create_undirected_adj_lists\n    sentinel = np.cast[np.min_scalar_type(self.number_of_nodes)](-1)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'cast'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n>           raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\nE           AttributeError: `np.cast` was removed in the NumPy 2.0 release. Use `np.asarray(arr, dtype=dtype)` instead.\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:400: AttributeError\n_________________________ test_not_progressing_enough __________________________\n\ntemporal_graph = <stellargraph.core.graph.StellarGraph object at 0x7fc18c6b0ac0>\n\n    def test_not_progressing_enough(temporal_graph):\n    \n        rw = TemporalRandomWalk(temporal_graph)\n        cw_size = 5  # no valid temporal walks of this size\n    \n        with pytest.raises(RuntimeError, match=r\".* discarded .*\"):\n>           rw.run(num_cw=1, cw_size=cw_size, max_walk_length=cw_size, seed=None)\n\ntests/data/test_temporal_random_walker.py:62: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/data/explorer.py:1116: in run\n    walk = self._walk(\nstellargraph/data/explorer.py:1183: in _walk\n    result = self._step(node, time=time, bias_type=bias_type, np_rs=np_rs)\nstellargraph/data/explorer.py:1164: in _step\n    neighbours, times = self.graph.neighbor_arrays(node, include_edge_weight=True)\nstellargraph/core/graph.py:792: in neighbor_arrays\n    edge_ilocs = self._edges.edge_ilocs(node, ins=True, outs=True)\nstellargraph/core/element_data.py:452: in edge_ilocs\n    return self._adj_lookup(ins=ins, outs=outs)[node_id]\nstellargraph/core/element_data.py:410: in _adj_lookup\n    self._init_undirected_adj_lists()\nstellargraph/core/element_data.py:365: in _init_undirected_adj_lists\n    self._edges_dict = self._create_undirected_adj_lists()\nstellargraph/core/element_data.py:377: in _create_undirected_adj_lists\n    sentinel = np.cast[np.min_scalar_type(self.number_of_nodes)](-1)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'cast'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n>           raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\nE           AttributeError: `np.cast` was removed in the NumPy 2.0 release. Use `np.asarray(arr, dtype=dtype)` instead.\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:400: AttributeError\n_______________________ test_cw_size_and_walk_length[2] ________________________\n\ntemporal_graph = <stellargraph.core.graph.StellarGraph object at 0x7fc18c7662c0>\ncw_size = 2\n\n    @pytest.mark.parametrize(\"cw_size\", [-1, 1, 2, 4])\n    def test_cw_size_and_walk_length(temporal_graph, cw_size):\n        rw = TemporalRandomWalk(temporal_graph)\n        num_cw = 5\n        max_walk_length = 3\n    \n        def run():\n            return rw.run(num_cw=num_cw, cw_size=cw_size, max_walk_length=max_walk_length)\n    \n        if cw_size < 2:\n            with pytest.raises(ValueError, match=r\".* context window size .*\"):\n                run()\n        elif max_walk_length < cw_size:\n            with pytest.raises(ValueError, match=r\".* maximum walk length .*\"):\n                run()\n        else:\n>           walks = run()\n\ntests/data/test_temporal_random_walker.py:102: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ntests/data/test_temporal_random_walker.py:93: in run\n    return rw.run(num_cw=num_cw, cw_size=cw_size, max_walk_length=max_walk_length)\nstellargraph/data/explorer.py:1116: in run\n    walk = self._walk(\nstellargraph/data/explorer.py:1183: in _walk\n    result = self._step(node, time=time, bias_type=bias_type, np_rs=np_rs)\nstellargraph/data/explorer.py:1164: in _step\n    neighbours, times = self.graph.neighbor_arrays(node, include_edge_weight=True)\nstellargraph/core/graph.py:792: in neighbor_arrays\n    edge_ilocs = self._edges.edge_ilocs(node, ins=True, outs=True)\nstellargraph/core/element_data.py:452: in edge_ilocs\n    return self._adj_lookup(ins=ins, outs=outs)[node_id]\nstellargraph/core/element_data.py:410: in _adj_lookup\n    self._init_undirected_adj_lists()\nstellargraph/core/element_data.py:365: in _init_undirected_adj_lists\n    self._edges_dict = self._create_undirected_adj_lists()\nstellargraph/core/element_data.py:377: in _create_undirected_adj_lists\n    sentinel = np.cast[np.min_scalar_type(self.number_of_nodes)](-1)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'cast'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n>           raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\nE           AttributeError: `np.cast` was removed in the NumPy 2.0 release. Use `np.asarray(arr, dtype=dtype)` instead.\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:400: AttributeError\n_____________________________ test_init_parameters _____________________________\n\ntemporal_graph = <stellargraph.core.graph.StellarGraph object at 0x7fc18c639870>\n\n    def test_init_parameters(temporal_graph):\n    \n        num_cw = 5\n        cw_size = 3\n        max_walk_length = 3\n        seed = 0\n    \n        rw = TemporalRandomWalk(\n            temporal_graph, cw_size=cw_size, max_walk_length=max_walk_length, seed=seed\n        )\n        rw_no_params = TemporalRandomWalk(temporal_graph)\n    \n>       run_1 = rw.run(num_cw=num_cw)\n\ntests/data/test_temporal_random_walker.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/data/explorer.py:1116: in run\n    walk = self._walk(\nstellargraph/data/explorer.py:1183: in _walk\n    result = self._step(node, time=time, bias_type=bias_type, np_rs=np_rs)\nstellargraph/data/explorer.py:1164: in _step\n    neighbours, times = self.graph.neighbor_arrays(node, include_edge_weight=True)\nstellargraph/core/graph.py:792: in neighbor_arrays\n    edge_ilocs = self._edges.edge_ilocs(node, ins=True, outs=True)\nstellargraph/core/element_data.py:452: in edge_ilocs\n    return self._adj_lookup(ins=ins, outs=outs)[node_id]\nstellargraph/core/element_data.py:410: in _adj_lookup\n    self._init_undirected_adj_lists()\nstellargraph/core/element_data.py:365: in _init_undirected_adj_lists\n    self._edges_dict = self._create_undirected_adj_lists()\nstellargraph/core/element_data.py:377: in _create_undirected_adj_lists\n    sentinel = np.cast[np.min_scalar_type(self.number_of_nodes)](-1)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'cast'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n>           raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\nE           AttributeError: `np.cast` was removed in the NumPy 2.0 release. Use `np.asarray(arr, dtype=dtype)` instead.\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:400: AttributeError\n_________ TestUniformRandomWalk.test_walk_generation_single_root_node __________\n\nself = <tests.data.test_uniform_random_walker.TestUniformRandomWalk object at 0x7fc1ac78d900>\n\n    def test_walk_generation_single_root_node(self):\n    \n        g = create_test_graph()\n        urw = UniformRandomWalk(g)\n    \n        nodes = [\"0\"]\n        n = 1\n        length = 1\n        seed = 42\n    \n        subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n        assert len(subgraphs[0]) == length\n    \n        length = 2\n>       subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n\ntests/data/test_uniform_random_walker.py:92: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/data/explorer.py:313: in run\n    return [self._walk(rs, node, length) for node in nodes for _ in range(n)]\nstellargraph/data/explorer.py:313: in <listcomp>\n    return [self._walk(rs, node, length) for node in nodes for _ in range(n)]\nstellargraph/data/explorer.py:319: in _walk\n    neighbours = self.graph.neighbor_arrays(current_node, use_ilocs=True)\nstellargraph/core/graph.py:792: in neighbor_arrays\n    edge_ilocs = self._edges.edge_ilocs(node, ins=True, outs=True)\nstellargraph/core/element_data.py:452: in edge_ilocs\n    return self._adj_lookup(ins=ins, outs=outs)[node_id]\nstellargraph/core/element_data.py:410: in _adj_lookup\n    self._init_undirected_adj_lists()\nstellargraph/core/element_data.py:365: in _init_undirected_adj_lists\n    self._edges_dict = self._create_undirected_adj_lists()\nstellargraph/core/element_data.py:377: in _create_undirected_adj_lists\n    sentinel = np.cast[np.min_scalar_type(self.number_of_nodes)](-1)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'cast'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n>           raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\nE           AttributeError: `np.cast` was removed in the NumPy 2.0 release. Use `np.asarray(arr, dtype=dtype)` instead.\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:400: AttributeError\n__________ TestUniformRandomWalk.test_walk_generation_many_root_nodes __________\n\nself = <tests.data.test_uniform_random_walker.TestUniformRandomWalk object at 0x7fc1ac763f40>\n\n    def test_walk_generation_many_root_nodes(self):\n    \n        g = create_test_graph()\n        urw = UniformRandomWalk(g)\n    \n        nodes = [\"0\", 2]\n        n = 1\n        length = 1\n        seed = None\n    \n        subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n        assert len(subgraphs) == n * len(nodes)\n        for i, subgraph in enumerate(subgraphs):\n            assert len(subgraph) == length  # should be 1\n            assert subgraph[0] == nodes[i]  # should equal the root node\n    \n        length = 2\n>       subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n\ntests/data/test_uniform_random_walker.py:126: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/data/explorer.py:313: in run\n    return [self._walk(rs, node, length) for node in nodes for _ in range(n)]\nstellargraph/data/explorer.py:313: in <listcomp>\n    return [self._walk(rs, node, length) for node in nodes for _ in range(n)]\nstellargraph/data/explorer.py:319: in _walk\n    neighbours = self.graph.neighbor_arrays(current_node, use_ilocs=True)\nstellargraph/core/graph.py:792: in neighbor_arrays\n    edge_ilocs = self._edges.edge_ilocs(node, ins=True, outs=True)\nstellargraph/core/element_data.py:452: in edge_ilocs\n    return self._adj_lookup(ins=ins, outs=outs)[node_id]\nstellargraph/core/element_data.py:410: in _adj_lookup\n    self._init_undirected_adj_lists()\nstellargraph/core/element_data.py:365: in _init_undirected_adj_lists\n    self._edges_dict = self._create_undirected_adj_lists()\nstellargraph/core/element_data.py:377: in _create_undirected_adj_lists\n    sentinel = np.cast[np.min_scalar_type(self.number_of_nodes)](-1)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'cast'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n>           raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\nE           AttributeError: `np.cast` was removed in the NumPy 2.0 release. Use `np.asarray(arr, dtype=dtype)` instead.\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:400: AttributeError\n__________ TestUniformRandomWalk.test_walk_generation_loner_root_node __________\n\nself = <tests.data.test_uniform_random_walker.TestUniformRandomWalk object at 0x7fc1ac763280>\n\n    def test_walk_generation_loner_root_node(self):\n    \n        g = create_test_graph()\n        urw = UniformRandomWalk(g)\n    \n        nodes = [\"loner\"]  # this node has no edges including itself\n        n = 1\n        length = 1\n        seed = None\n    \n        subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n        assert len(subgraphs) == 1\n        assert (\n            len(subgraphs[0]) == 1\n        )  # always 1 since only the root node can every be added to the walk\n    \n        n = 10\n        length = 1\n        subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n        assert len(subgraphs) == n\n        for subgraph in subgraphs:\n            assert (\n                len(subgraph) == 1\n            )  # always 1 since only the root node can ever be added to the walk\n    \n        n = 10\n        length = 10\n>       subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n\ntests/data/test_uniform_random_walker.py:178: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/data/explorer.py:313: in run\n    return [self._walk(rs, node, length) for node in nodes for _ in range(n)]\nstellargraph/data/explorer.py:313: in <listcomp>\n    return [self._walk(rs, node, length) for node in nodes for _ in range(n)]\nstellargraph/data/explorer.py:319: in _walk\n    neighbours = self.graph.neighbor_arrays(current_node, use_ilocs=True)\nstellargraph/core/graph.py:792: in neighbor_arrays\n    edge_ilocs = self._edges.edge_ilocs(node, ins=True, outs=True)\nstellargraph/core/element_data.py:452: in edge_ilocs\n    return self._adj_lookup(ins=ins, outs=outs)[node_id]\nstellargraph/core/element_data.py:410: in _adj_lookup\n    self._init_undirected_adj_lists()\nstellargraph/core/element_data.py:365: in _init_undirected_adj_lists\n    self._edges_dict = self._create_undirected_adj_lists()\nstellargraph/core/element_data.py:377: in _create_undirected_adj_lists\n    sentinel = np.cast[np.min_scalar_type(self.number_of_nodes)](-1)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'cast'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n>           raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\nE           AttributeError: `np.cast` was removed in the NumPy 2.0 release. Use `np.asarray(arr, dtype=dtype)` instead.\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:400: AttributeError\n_______ TestUniformRandomWalk.test_walk_generation_self_loner_root_node ________\n\nself = <tests.data.test_uniform_random_walker.TestUniformRandomWalk object at 0x7fc1ac78d660>\n\n    def test_walk_generation_self_loner_root_node(self):\n    \n        g = create_test_graph()\n        urw = UniformRandomWalk(g)\n    \n        nodes = [\"self loner\"]  # this node has link to self but no other edges\n        n = 1\n        length = 1\n        seed = None\n    \n        subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n        assert len(subgraphs) == 1\n        assert len(subgraphs[0]) == 1\n    \n        n = 10\n        length = 1\n        subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n        assert len(subgraphs) == n\n        for subgraph in subgraphs:\n            assert len(subgraph) == length\n            for node in subgraph:\n                assert node == \"self loner\"  # all nodes should be the same node\n    \n        n = 1\n        length = 99\n>       subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n\ntests/data/test_uniform_random_walker.py:210: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/data/explorer.py:313: in run\n    return [self._walk(rs, node, length) for node in nodes for _ in range(n)]\nstellargraph/data/explorer.py:313: in <listcomp>\n    return [self._walk(rs, node, length) for node in nodes for _ in range(n)]\nstellargraph/data/explorer.py:319: in _walk\n    neighbours = self.graph.neighbor_arrays(current_node, use_ilocs=True)\nstellargraph/core/graph.py:792: in neighbor_arrays\n    edge_ilocs = self._edges.edge_ilocs(node, ins=True, outs=True)\nstellargraph/core/element_data.py:452: in edge_ilocs\n    return self._adj_lookup(ins=ins, outs=outs)[node_id]\nstellargraph/core/element_data.py:410: in _adj_lookup\n    self._init_undirected_adj_lists()\nstellargraph/core/element_data.py:365: in _init_undirected_adj_lists\n    self._edges_dict = self._create_undirected_adj_lists()\nstellargraph/core/element_data.py:377: in _create_undirected_adj_lists\n    sentinel = np.cast[np.min_scalar_type(self.number_of_nodes)](-1)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'cast'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n>           raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\nE           AttributeError: `np.cast` was removed in the NumPy 2.0 release. Use `np.asarray(arr, dtype=dtype)` instead.\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:400: AttributeError\n__________________ TestUniformRandomWalk.test_init_parameters __________________\n\nself = <tests.data.test_uniform_random_walker.TestUniformRandomWalk object at 0x7fc1ac78d6f0>\n\n    def test_init_parameters(self):\n        g = create_test_graph()\n    \n        nodes = [\"0\", 2]\n        n = 1\n        length = 2\n        seed = 0\n    \n        urw = UniformRandomWalk(g, n=n, length=length, seed=seed)\n        urw_no_params = UniformRandomWalk(g)\n    \n>       run_1 = urw.run(nodes=nodes)\n\ntests/data/test_uniform_random_walker.py:237: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/data/explorer.py:313: in run\n    return [self._walk(rs, node, length) for node in nodes for _ in range(n)]\nstellargraph/data/explorer.py:313: in <listcomp>\n    return [self._walk(rs, node, length) for node in nodes for _ in range(n)]\nstellargraph/data/explorer.py:319: in _walk\n    neighbours = self.graph.neighbor_arrays(current_node, use_ilocs=True)\nstellargraph/core/graph.py:792: in neighbor_arrays\n    edge_ilocs = self._edges.edge_ilocs(node, ins=True, outs=True)\nstellargraph/core/element_data.py:452: in edge_ilocs\n    return self._adj_lookup(ins=ins, outs=outs)[node_id]\nstellargraph/core/element_data.py:410: in _adj_lookup\n    self._init_undirected_adj_lists()\nstellargraph/core/element_data.py:365: in _init_undirected_adj_lists\n    self._edges_dict = self._create_undirected_adj_lists()\nstellargraph/core/element_data.py:377: in _create_undirected_adj_lists\n    sentinel = np.cast[np.min_scalar_type(self.number_of_nodes)](-1)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'cast'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n>           raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\nE           AttributeError: `np.cast` was removed in the NumPy 2.0 release. Use `np.asarray(arr, dtype=dtype)` instead.\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:400: AttributeError\n_____________________________ test_run_batch_sizes _____________________________\n\nline_graph = <stellargraph.core.graph.StellarGraph object at 0x7fc1ac1ca950>\n\n    def test_run_batch_sizes(line_graph):\n        batch_size = 4\n        sampler = UnsupervisedSampler(G=line_graph, length=2, number_of_walks=2)\n>       batches = sampler.run(batch_size)\n\ntests/data/test_unsupervised_sampler.py:52: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/data/unsupervised_sampler.py:148: in run\n    degrees = self.graph.node_degrees(use_ilocs=True)\nstellargraph/core/graph.py:1546: in node_degrees\n    degrees = self._edges.degrees()\nstellargraph/core/element_data.py:437: in degrees\n    adj = self._adj_lookup(ins=ins, outs=outs)\nstellargraph/core/element_data.py:410: in _adj_lookup\n    self._init_undirected_adj_lists()\nstellargraph/core/element_data.py:365: in _init_undirected_adj_lists\n    self._edges_dict = self._create_undirected_adj_lists()\nstellargraph/core/element_data.py:377: in _create_undirected_adj_lists\n    sentinel = np.cast[np.min_scalar_type(self.number_of_nodes)](-1)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'cast'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n>           raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\nE           AttributeError: `np.cast` was removed in the NumPy 2.0 release. Use `np.asarray(arr, dtype=dtype)` instead.\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:400: AttributeError\n____________________________ test_run_context_pairs ____________________________\n\nline_graph = <stellargraph.core.graph.StellarGraph object at 0x7fc18c554c40>\n\n    def test_run_context_pairs(line_graph):\n        batch_size = 4\n        sampler = UnsupervisedSampler(G=line_graph, length=2, number_of_walks=2)\n>       batches = sampler.run(batch_size)\n\ntests/data/test_unsupervised_sampler.py:68: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/data/unsupervised_sampler.py:148: in run\n    degrees = self.graph.node_degrees(use_ilocs=True)\nstellargraph/core/graph.py:1546: in node_degrees\n    degrees = self._edges.degrees()\nstellargraph/core/element_data.py:437: in degrees\n    adj = self._adj_lookup(ins=ins, outs=outs)\nstellargraph/core/element_data.py:410: in _adj_lookup\n    self._init_undirected_adj_lists()\nstellargraph/core/element_data.py:365: in _init_undirected_adj_lists\n    self._edges_dict = self._create_undirected_adj_lists()\nstellargraph/core/element_data.py:377: in _create_undirected_adj_lists\n    sentinel = np.cast[np.min_scalar_type(self.number_of_nodes)](-1)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'cast'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n>           raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\nE           AttributeError: `np.cast` was removed in the NumPy 2.0 release. Use `np.asarray(arr, dtype=dtype)` instead.\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:400: AttributeError\n__________________________ test_walker_uniform_random __________________________\n\nline_graph = <stellargraph.core.graph.StellarGraph object at 0x7fc18c44b550>\n\n    def test_walker_uniform_random(line_graph):\n        length = 3\n        number_of_walks = 2\n        batch_size = 4\n    \n        walker = UniformRandomWalk(line_graph, n=number_of_walks, length=length)\n        sampler = UnsupervisedSampler(line_graph, walker=walker)\n    \n>       batches = sampler.run(batch_size)\n\ntests/data/test_unsupervised_sampler.py:96: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/data/unsupervised_sampler.py:148: in run\n    degrees = self.graph.node_degrees(use_ilocs=True)\nstellargraph/core/graph.py:1546: in node_degrees\n    degrees = self._edges.degrees()\nstellargraph/core/element_data.py:437: in degrees\n    adj = self._adj_lookup(ins=ins, outs=outs)\nstellargraph/core/element_data.py:410: in _adj_lookup\n    self._init_undirected_adj_lists()\nstellargraph/core/element_data.py:365: in _init_undirected_adj_lists\n    self._edges_dict = self._create_undirected_adj_lists()\nstellargraph/core/element_data.py:377: in _create_undirected_adj_lists\n    sentinel = np.cast[np.min_scalar_type(self.number_of_nodes)](-1)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'cast'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n>           raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\nE           AttributeError: `np.cast` was removed in the NumPy 2.0 release. Use `np.asarray(arr, dtype=dtype)` instead.\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:400: AttributeError\n______________________________ test_walker_custom ______________________________\n\nline_graph = <stellargraph.core.graph.StellarGraph object at 0x7fc18c6bfb20>\n\n    def test_walker_custom(line_graph):\n        walker = CustomWalker()\n        sampler = UnsupervisedSampler(line_graph, walker=walker)\n>       batches = sampler.run(2)\n\ntests/data/test_unsupervised_sampler.py:114: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/data/unsupervised_sampler.py:148: in run\n    degrees = self.graph.node_degrees(use_ilocs=True)\nstellargraph/core/graph.py:1546: in node_degrees\n    degrees = self._edges.degrees()\nstellargraph/core/element_data.py:437: in degrees\n    adj = self._adj_lookup(ins=ins, outs=outs)\nstellargraph/core/element_data.py:410: in _adj_lookup\n    self._init_undirected_adj_lists()\nstellargraph/core/element_data.py:365: in _init_undirected_adj_lists\n    self._edges_dict = self._create_undirected_adj_lists()\nstellargraph/core/element_data.py:377: in _create_undirected_adj_lists\n    sentinel = np.cast[np.min_scalar_type(self.number_of_nodes)](-1)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'cast'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n>           raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\nE           AttributeError: `np.cast` was removed in the NumPy 2.0 release. Use `np.asarray(arr, dtype=dtype)` instead.\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:400: AttributeError\n_________________________ test_dataset_download[MUTAG] _________________________\n\ndataset_class = <class 'stellargraph.datasets.datasets.MUTAG'>\n\n    @pytest.mark.parametrize(\"dataset_class\", list(DatasetLoader.__subclasses__()))\n    def test_dataset_download(dataset_class):\n>       dataset_class().download(ignore_cache=True)\n\ntests/datasets/test_datasets.py:32: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/datasets/dataset_loader.py:189: in download\n    temporary_filename, _ = urlretrieve(self.url)\n/usr/lib/python3.10/urllib/request.py:241: in urlretrieve\n    with contextlib.closing(urlopen(url, data)) as fp:\n/usr/lib/python3.10/urllib/request.py:216: in urlopen\n    return opener.open(url, data, timeout)\n/usr/lib/python3.10/urllib/request.py:525: in open\n    response = meth(req, response)\n/usr/lib/python3.10/urllib/request.py:634: in http_response\n    response = self.parent.error(\n/usr/lib/python3.10/urllib/request.py:563: in error\n    return self._call_chain(*args)\n/usr/lib/python3.10/urllib/request.py:496: in _call_chain\n    result = func(*args)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <urllib.request.HTTPDefaultErrorHandler object at 0x7fc18c555450>\nreq = <urllib.request.Request object at 0x7fc2316f8c40>\nfp = <http.client.HTTPResponse object at 0x7fc2316f94e0>, code = 404\nmsg = 'Not Found', hdrs = <http.client.HTTPMessage object at 0x7fc2316d32b0>\n\n    def http_error_default(self, req, fp, code, msg, hdrs):\n>       raise HTTPError(req.full_url, code, msg, hdrs, fp)\nE       urllib.error.HTTPError: HTTP Error 404: Not Found\n\n/usr/lib/python3.10/urllib/request.py:643: HTTPError\n_______________________ test_dataset_download[PROTEINS] ________________________\n\ndataset_class = <class 'stellargraph.datasets.datasets.PROTEINS'>\n\n    @pytest.mark.parametrize(\"dataset_class\", list(DatasetLoader.__subclasses__()))\n    def test_dataset_download(dataset_class):\n>       dataset_class().download(ignore_cache=True)\n\ntests/datasets/test_datasets.py:32: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/datasets/dataset_loader.py:189: in download\n    temporary_filename, _ = urlretrieve(self.url)\n/usr/lib/python3.10/urllib/request.py:241: in urlretrieve\n    with contextlib.closing(urlopen(url, data)) as fp:\n/usr/lib/python3.10/urllib/request.py:216: in urlopen\n    return opener.open(url, data, timeout)\n/usr/lib/python3.10/urllib/request.py:525: in open\n    response = meth(req, response)\n/usr/lib/python3.10/urllib/request.py:634: in http_response\n    response = self.parent.error(\n/usr/lib/python3.10/urllib/request.py:563: in error\n    return self._call_chain(*args)\n/usr/lib/python3.10/urllib/request.py:496: in _call_chain\n    result = func(*args)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <urllib.request.HTTPDefaultErrorHandler object at 0x7fc18c555450>\nreq = <urllib.request.Request object at 0x7fc1bc11fc10>\nfp = <http.client.HTTPResponse object at 0x7fc1bc11ed40>, code = 404\nmsg = 'Not Found', hdrs = <http.client.HTTPMessage object at 0x7fc1bc11efe0>\n\n    def http_error_default(self, req, fp, code, msg, hdrs):\n>       raise HTTPError(req.full_url, code, msg, hdrs, fp)\nE       urllib.error.HTTPError: HTTP Error 404: Not Found\n\n/usr/lib/python3.10/urllib/request.py:643: HTTPError\n_______________________________ test_mutag_load ________________________________\n\n    def test_mutag_load() -> None:\n>       _graph_kernels_load(\n            MUTAG(),\n            n_graphs=188,\n            total_nodes=3371,\n            max_nodes=28,  # graph 6\n            total_edges=7442,\n            expected_labels={\"-1\", \"1\"},\n            node_features=7,  # 7 labels\n            mean_nodes=17.93,\n            mean_edges=19.79,\n        )\n\ntests/datasets/test_datasets.py:132: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ntests/datasets/test_datasets.py:103: in _graph_kernels_load\n    graphs, labels = dataset.load()\nstellargraph/datasets/datasets.py:629: in load\n    return _load_graph_kernel_dataset(self)\nstellargraph/datasets/datasets.py:533: in _load_graph_kernel_dataset\n    dataset.download()\nstellargraph/datasets/dataset_loader.py:189: in download\n    temporary_filename, _ = urlretrieve(self.url)\n/usr/lib/python3.10/urllib/request.py:241: in urlretrieve\n    with contextlib.closing(urlopen(url, data)) as fp:\n/usr/lib/python3.10/urllib/request.py:216: in urlopen\n    return opener.open(url, data, timeout)\n/usr/lib/python3.10/urllib/request.py:525: in open\n    response = meth(req, response)\n/usr/lib/python3.10/urllib/request.py:634: in http_response\n    response = self.parent.error(\n/usr/lib/python3.10/urllib/request.py:563: in error\n    return self._call_chain(*args)\n/usr/lib/python3.10/urllib/request.py:496: in _call_chain\n    result = func(*args)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <urllib.request.HTTPDefaultErrorHandler object at 0x7fc18c555450>\nreq = <urllib.request.Request object at 0x7fc18c7dbdc0>\nfp = <http.client.HTTPResponse object at 0x7fc18c7da6b0>, code = 404\nmsg = 'Not Found', hdrs = <http.client.HTTPMessage object at 0x7fc18c7db010>\n\n    def http_error_default(self, req, fp, code, msg, hdrs):\n>       raise HTTPError(req.full_url, code, msg, hdrs, fp)\nE       urllib.error.HTTPError: HTTP Error 404: Not Found\n\n/usr/lib/python3.10/urllib/request.py:643: HTTPError\n______________________________ test_proteins_load ______________________________\n\n    def test_proteins_load() -> None:\n>       _graph_kernels_load(\n            PROTEINS(),\n            n_graphs=1113,\n            total_nodes=43471,\n            max_nodes=620,  # graph 77\n            total_edges=162088,\n            expected_labels={\"1\", \"2\"},\n            node_features=3 + 1,  # 3 labels, one attribute\n            mean_nodes=39.06,\n            mean_edges=72.82,\n        )\n\ntests/datasets/test_datasets.py:146: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ntests/datasets/test_datasets.py:103: in _graph_kernels_load\n    graphs, labels = dataset.load()\nstellargraph/datasets/datasets.py:662: in load\n    return _load_graph_kernel_dataset(self)\nstellargraph/datasets/datasets.py:533: in _load_graph_kernel_dataset\n    dataset.download()\nstellargraph/datasets/dataset_loader.py:189: in download\n    temporary_filename, _ = urlretrieve(self.url)\n/usr/lib/python3.10/urllib/request.py:241: in urlretrieve\n    with contextlib.closing(urlopen(url, data)) as fp:\n/usr/lib/python3.10/urllib/request.py:216: in urlopen\n    return opener.open(url, data, timeout)\n/usr/lib/python3.10/urllib/request.py:525: in open\n    response = meth(req, response)\n/usr/lib/python3.10/urllib/request.py:634: in http_response\n    response = self.parent.error(\n/usr/lib/python3.10/urllib/request.py:563: in error\n    return self._call_chain(*args)\n/usr/lib/python3.10/urllib/request.py:496: in _call_chain\n    result = func(*args)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <urllib.request.HTTPDefaultErrorHandler object at 0x7fc18c555450>\nreq = <urllib.request.Request object at 0x7fc18c7001f0>\nfp = <http.client.HTTPResponse object at 0x7fc18c703160>, code = 404\nmsg = 'Not Found', hdrs = <http.client.HTTPMessage object at 0x7fc18c701360>\n\n    def http_error_default(self, req, fp, code, msg, hdrs):\n>       raise HTTPError(req.full_url, code, msg, hdrs, fp)\nE       urllib.error.HTTPError: HTTP Error 404: Not Found\n\n/usr/lib/python3.10/urllib/request.py:643: HTTPError\n_____________________________ test_movielens_load ______________________________\n\n    def test_movielens_load() -> None:\n>       g, edges_with_ratings = MovieLens().load()\n\ntests/datasets/test_datasets.py:160: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <stellargraph.datasets.datasets.MovieLens object at 0x7fc18c6ebfd0>\n\n    def load(self):\n        \"\"\"\n        Load this dataset into an undirected heterogeneous graph, downloading it if required.\n    \n        The graph has two types of nodes (``user`` and ``movie``) and one type of edge (``rating``).\n    \n        The dataset includes some node features on both users and movies: on users, they consist of\n        categorical features (``gender`` and ``job``) which are one-hot encoded into binary\n        features, and an ``age`` feature that is scaled to have mean = 0 and standard deviation = 1.\n    \n        Returns:\n            A tuple where the first element is a :class:`.StellarGraph` instance containing the graph\n            data and features, and the second element is a pandas DataFrame of edges, with columns\n            ``user_id``, ``movie_id`` and ``rating`` (a label from 1 to 5).\n        \"\"\"\n        self.download()\n    \n        ratings, users, movies, *_ = [\n            self._resolve_path(path) for path in self.expected_files\n        ]\n    \n        edges = pd.read_csv(\n            ratings,\n            sep=\"\\t\",\n            header=None,\n            names=[\"user_id\", \"movie_id\", \"rating\", \"timestamp\"],\n            usecols=[\"user_id\", \"movie_id\", \"rating\"],\n        )\n    \n        users = pd.read_csv(\n            users,\n            sep=\"|\",\n            header=None,\n            names=[\"user_id\", \"age\", \"gender\", \"job\", \"zipcode\"],\n            usecols=[\"user_id\", \"age\", \"gender\", \"job\"],\n        )\n    \n        movie_columns = [\n            \"movie_id\",\n            \"title\",\n            \"release_date\",\n            \"video_release_date\",\n            \"imdb_url\",\n            # features from here:\n            \"unknown\",\n            \"action\",\n            \"adventure\",\n            \"animation\",\n            \"childrens\",\n            \"comedy\",\n            \"crime\",\n            \"documentary\",\n            \"drama\",\n            \"fantasy\",\n            \"film_noir\",\n            \"horror\",\n            \"musical\",\n            \"mystery\",\n            \"romance\",\n            \"sci_fi\",\n            \"thriller\",\n            \"war\",\n            \"western\",\n        ]\n        movies = pd.read_csv(\n            movies,\n            sep=\"|\",\n            header=None,\n            names=movie_columns,\n            usecols=[\"movie_id\"] + movie_columns[5:],\n            encoding=\"iso-8859-1\",\n        )\n    \n        # manage the IDs\n        def u(users):\n            return \"u_\" + users.astype(str)\n    \n        def m(movies):\n            return \"m_\" + movies.astype(str)\n    \n        users_ids = u(users[\"user_id\"])\n    \n        movies[\"movie_id\"] = m(movies[\"movie_id\"])\n        movies.set_index(\"movie_id\", inplace=True)\n    \n        edges[\"user_id\"] = u(edges[\"user_id\"])\n        edges[\"movie_id\"] = m(edges[\"movie_id\"])\n    \n        # convert categorical user features to numeric, and normalize age\n>       feature_encoding = preprocessing.OneHotEncoder(sparse=False)\nE       TypeError: OneHotEncoder.__init__() got an unexpected keyword argument 'sparse'\n\nstellargraph/datasets/datasets.py:443: TypeError\n________________________________ test_aifb_load ________________________________\n\n    def test_aifb_load() -> None:\n>       g, affiliation = AIFB().load()\n\ntests/datasets/test_datasets.py:253: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <stellargraph.datasets.datasets.AIFB object at 0x7fc18c7daf20>\n\n    def load(self):\n        \"\"\"\n        Loads the dataset into a directed heterogeneous graph.\n    \n        The nodes features are the node's position after being one-hot encoded; for example, the\n        first node has features ``[1, 0, 0, ...]``, the second has ``[0, 1, 0, ...]``.\n    \n        This requires the ``rdflib`` library to be installed.\n    \n        Returns:\n            A tuple where the first element is a graph containing all edges except for those with\n            type ``affiliation`` and ``employs`` (the inverse of ``affiliation``), and the second\n            element is a DataFrame containing the one-hot encoded affiliation of the 178 nodes that\n            have an affiliation.\n        \"\"\"\n        try:\n            import rdflib\n        except ModuleNotFoundError as e:\n>           raise ModuleNotFoundError(\n                f\"{e.msg}. Loading the AIFB dataset requires the 'rdflib' module; please install it\",\n                name=e.name,\n                path=e.path,\n            ) from None\nE           ModuleNotFoundError: No module named 'rdflib'. Loading the AIFB dataset requires the 'rdflib' module; please install it\n\nstellargraph/datasets/datasets.py:495: ModuleNotFoundError\n_____________________________ test_ig_saliency_map _____________________________\n\n    def test_ig_saliency_map():\n        graph = example_graph_1(feature_size=4)\n        base_model, keras_model_gat, generator, train_gen = create_GAT_model(graph)\n        keras_model_gat.compile(\n>           optimizer=Adam(lr=0.1), loss=categorical_crossentropy, weighted_metrics=[\"acc\"]\n        )\n\ntests/interpretability/test_saliency_maps_gat.py:60: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/adam.py:62: in __init__\n    super().__init__(\n/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/optimizer.py:21: in __init__\n    super().__init__(*args, **kwargs)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <keras.src.optimizers.adam.Adam object at 0x7fc18c4a52a0>\nlearning_rate = 0.001, weight_decay = None, clipnorm = None, clipvalue = None\nglobal_clipnorm = None, use_ema = False, ema_momentum = 0.99\nema_overwrite_frequency = None, loss_scale_factor = None\ngradient_accumulation_steps = None, name = 'adam', kwargs = {'lr': 0.1}\n\n    def __init__(\n        self,\n        learning_rate,\n        weight_decay=None,\n        clipnorm=None,\n        clipvalue=None,\n        global_clipnorm=None,\n        use_ema=False,\n        ema_momentum=0.99,\n        ema_overwrite_frequency=None,\n        loss_scale_factor=None,\n        gradient_accumulation_steps=None,\n        name=None,\n        **kwargs,\n    ):\n        self._lock = False\n    \n        if kwargs.pop(\"decay\", None) is not None:\n            warnings.warn(\n                \"Argument `decay` is no longer supported and will be ignored.\"\n            )\n        if kwargs:\n>           raise ValueError(f\"Argument(s) not recognized: {kwargs}\")\nE           ValueError: Argument(s) not recognized: {'lr': 0.1}\n\n/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/base_optimizer.py:90: ValueError\n_____________________________ test_ig_saliency_map _____________________________\n\n    def test_ig_saliency_map():\n    \n        graph = example_graph_1(feature_size=4)\n        base_model, keras_model_gcn, generator, train_gen = create_GCN_model_dense(graph)\n        (\n            base_model_sp,\n            keras_model_gcn_sp,\n            generator_sp,\n            train_gen_sp,\n        ) = create_GCN_model_sparse(graph)\n    \n        keras_model_gcn.compile(\n>           optimizer=Adam(lr=0.1), loss=categorical_crossentropy, weighted_metrics=[\"acc\"]\n        )\n\ntests/interpretability/test_saliency_maps_gcn.py:80: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/adam.py:62: in __init__\n    super().__init__(\n/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/optimizer.py:21: in __init__\n    super().__init__(*args, **kwargs)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <keras.src.optimizers.adam.Adam object at 0x7fc1ac2ba080>\nlearning_rate = 0.001, weight_decay = None, clipnorm = None, clipvalue = None\nglobal_clipnorm = None, use_ema = False, ema_momentum = 0.99\nema_overwrite_frequency = None, loss_scale_factor = None\ngradient_accumulation_steps = None, name = 'adam', kwargs = {'lr': 0.1}\n\n    def __init__(\n        self,\n        learning_rate,\n        weight_decay=None,\n        clipnorm=None,\n        clipvalue=None,\n        global_clipnorm=None,\n        use_ema=False,\n        ema_momentum=0.99,\n        ema_overwrite_frequency=None,\n        loss_scale_factor=None,\n        gradient_accumulation_steps=None,\n        name=None,\n        **kwargs,\n    ):\n        self._lock = False\n    \n        if kwargs.pop(\"decay\", None) is not None:\n            warnings.warn(\n                \"Argument `decay` is no longer supported and will be ignored.\"\n            )\n        if kwargs:\n>           raise ValueError(f\"Argument(s) not recognized: {kwargs}\")\nE           ValueError: Argument(s) not recognized: {'lr': 0.1}\n\n/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/base_optimizer.py:90: ValueError\n----------------------------- Captured stdout call -----------------------------\nUsing GCN (local pooling) filters...\nUsing GCN (local pooling) filters...\n________________________ test_saliency_init_parameters _________________________\n\n    def test_saliency_init_parameters():\n        graph = example_graph_1(feature_size=4)\n        base_model, keras_model_gcn, generator, train_gen = create_GCN_model_dense(graph)\n        (\n            base_model_sp,\n            keras_model_gcn_sp,\n            generator_sp,\n            train_gen_sp,\n        ) = create_GCN_model_sparse(graph)\n    \n        keras_model_gcn.compile(\n>           optimizer=Adam(lr=0.1), loss=categorical_crossentropy, weighted_metrics=[\"acc\"]\n        )\n\ntests/interpretability/test_saliency_maps_gcn.py:152: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/adam.py:62: in __init__\n    super().__init__(\n/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/optimizer.py:21: in __init__\n    super().__init__(*args, **kwargs)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <keras.src.optimizers.adam.Adam object at 0x7fc1ac11e2c0>\nlearning_rate = 0.001, weight_decay = None, clipnorm = None, clipvalue = None\nglobal_clipnorm = None, use_ema = False, ema_momentum = 0.99\nema_overwrite_frequency = None, loss_scale_factor = None\ngradient_accumulation_steps = None, name = 'adam', kwargs = {'lr': 0.1}\n\n    def __init__(\n        self,\n        learning_rate,\n        weight_decay=None,\n        clipnorm=None,\n        clipvalue=None,\n        global_clipnorm=None,\n        use_ema=False,\n        ema_momentum=0.99,\n        ema_overwrite_frequency=None,\n        loss_scale_factor=None,\n        gradient_accumulation_steps=None,\n        name=None,\n        **kwargs,\n    ):\n        self._lock = False\n    \n        if kwargs.pop(\"decay\", None) is not None:\n            warnings.warn(\n                \"Argument `decay` is no longer supported and will be ignored.\"\n            )\n        if kwargs:\n>           raise ValueError(f\"Argument(s) not recognized: {kwargs}\")\nE           ValueError: Argument(s) not recognized: {'lr': 0.1}\n\n/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/base_optimizer.py:90: ValueError\n----------------------------- Captured stdout call -----------------------------\nUsing GCN (local pooling) filters...\nUsing GCN (local pooling) filters...\n____________________________ test_APPNP_apply_dense ____________________________\n\n    def test_APPNP_apply_dense():\n        G, features = create_graph_features()\n        adj = G.to_adjacency_matrix()\n        features, adj = GCN_Aadj_feats_op(features, adj)\n        adj = np.array(adj.todense()[None, :, :])\n    \n        generator = FullBatchNodeGenerator(G, sparse=False, method=\"gcn\")\n        appnpModel = APPNP([2], generator=generator, activations=[\"relu\"], dropout=0.5)\n    \n        x_in, x_out = appnpModel.in_out_tensors()\n        model = keras.Model(inputs=x_in, outputs=x_out)\n    \n        # Check fit method\n        out_indices = np.array([[0, 1]], dtype=\"int32\")\n        preds_1 = model.predict([features[None, :, :], out_indices, adj])\n        assert preds_1.shape == (1, 2, 2)\n    \n        # Check fit method\n>       preds_2 = model.predict(generator.flow([\"a\", \"b\"]))\n\ntests/layer/test_appnp.py:112: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py:122: in error_handler\n    raise e.with_traceback(filtered_tb) from None\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nfunc = <function get_keras_tensor_spec.<locals>.get_single_tensor_spec at 0x7fc178dcb880>\ntree = ([array([[[1., 1.],\n        [1., 0.],\n        [0., 1.]]], dtype=float32), array([[0, 1]], dtype=uint8), array([[[0.333...333, 0.33333333],\n        [0.33333333, 0.33333333, 0.33333333],\n        [0.33333333, 0.33333333, 0.33333333]]])], None)\nis_leaf = None, none_is_leaf = True, namespace = 'keras', rests = ()\n\n    def tree_map(\n        func: Callable[..., U],\n        tree: PyTree[T],\n        /,\n        *rests: PyTree[S],\n        is_leaf: Callable[[T], bool] | None = None,\n        none_is_leaf: bool = False,\n        namespace: str = '',\n    ) -> PyTree[U]:\n        \"\"\"Map a multi-input function over pytree args to produce a new pytree.\n    \n        See also :func:`tree_map_`, :func:`tree_map_with_path`, :func:`tree_map_with_path_`,\n        and :func:`tree_broadcast_map`.\n    \n        >>> tree_map(lambda x: x + 1, {'x': 7, 'y': (42, 64)})\n        {'x': 8, 'y': (43, 65)}\n        >>> tree_map(lambda x: x + 1, {'x': 7, 'y': (42, 64), 'z': None})\n        {'x': 8, 'y': (43, 65), 'z': None}\n        >>> tree_map(lambda x: x is None, {'x': 7, 'y': (42, 64), 'z': None})\n        {'x': False, 'y': (False, False), 'z': None}\n        >>> tree_map(lambda x: x is None, {'x': 7, 'y': (42, 64), 'z': None}, none_is_leaf=True)\n        {'x': False, 'y': (False, False), 'z': True}\n    \n        If multiple inputs are given, the structure of the tree is taken from the first input;\n        subsequent inputs need only have ``tree`` as a prefix:\n    \n        >>> tree_map(lambda x, y: [x] + y, [5, 6], [[7, 9], [1, 2]])\n        [[5, 7, 9], [6, 1, 2]]\n    \n        Args:\n            func (callable): A function that takes ``1 + len(rests)`` arguments, to be applied at the\n                corresponding leaves of the pytrees.\n            tree (pytree): A pytree to be mapped over, with each leaf providing the first positional\n                argument to function ``func``.\n            rests (tuple of pytree): A tuple of pytrees, each of which has the same structure as\n                ``tree`` or has ``tree`` as a prefix.\n            is_leaf (callable, optional): An optionally specified function that will be called at each\n                flattening step. It should return a boolean, with :data:`True` stopping the traversal\n                and the whole subtree being treated as a leaf, and :data:`False` indicating the\n                flattening should traverse the current object.\n            none_is_leaf (bool, optional): Whether to treat :data:`None` as a leaf. If :data:`False`,\n                :data:`None` is a non-leaf node with arity 0. Thus :data:`None` is contained in the\n                treespec rather than in the leaves list and :data:`None` will be remain in the result\n                pytree. (default: :data:`False`)\n            namespace (str, optional): The registry namespace used for custom pytree node types.\n                (default: :const:`''`, i.e., the global namespace)\n    \n        Returns:\n            A new pytree with the same structure as ``tree`` but with the value at each leaf given by\n            ``func(x, *xs)`` where ``x`` is the value at the corresponding leaf in ``tree`` and ``xs``\n            is the tuple of values at corresponding nodes in ``rests``.\n        \"\"\"\n        leaves, treespec = _C.flatten(tree, is_leaf, none_is_leaf, namespace)\n        flat_args = [leaves] + [treespec.flatten_up_to(r) for r in rests]\n>       return treespec.unflatten(map(func, *flat_args))\nE       ValueError: When passing a dataset to a Keras model, the arrays must be at least rank 1. Received: None of rank 0.\n\n/usr/local/lib/python3.10/dist-packages/optree/ops.py:766: ValueError\n----------------------------- Captured stdout call -----------------------------\nUsing GCN (local pooling) filters...\nUsing GCN (local pooling) filters...\n\n\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 316ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329ms/step\n___________________________ test_APPNP_apply_sparse ____________________________\n\n    def test_APPNP_apply_sparse():\n    \n        G, features = create_graph_features()\n        adj = G.to_adjacency_matrix()\n        features, adj = GCN_Aadj_feats_op(features, adj)\n        adj = adj.tocoo()\n        A_indices = np.expand_dims(\n            np.hstack((adj.row[:, None], adj.col[:, None])).astype(np.int64), 0\n        )\n        A_values = np.expand_dims(adj.data, 0)\n    \n        generator = FullBatchNodeGenerator(G, sparse=True, method=\"gcn\")\n        appnpnModel = APPNP([2], generator=generator, activations=[\"relu\"], dropout=0.5)\n    \n        x_in, x_out = appnpnModel.in_out_tensors()\n        model = keras.Model(inputs=x_in, outputs=x_out)\n    \n        # Check fit method\n        out_indices = np.array([[0, 1]], dtype=\"int32\")\n        preds_1 = model.predict([features[None, :, :], out_indices, A_indices, A_values])\n        assert preds_1.shape == (1, 2, 2)\n    \n        # Check fit method\n>       preds_2 = model.predict(generator.flow([\"a\", \"b\"]))\n\ntests/layer/test_appnp.py:141: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py:122: in error_handler\n    raise e.with_traceback(filtered_tb) from None\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nfunc = <function get_keras_tensor_spec.<locals>.get_single_tensor_spec at 0x7fc178daa0e0>\ntree = ([array([[[1., 1.],\n        [1., 0.],\n        [0., 1.]]], dtype=float32), array([[0, 1]], dtype=uint8), array([[[0, 0]...3333, 0.33333333, 0.33333333, 0.33333333, 0.33333333,\n        0.33333333, 0.33333333, 0.33333333, 0.33333333]])], None)\nis_leaf = None, none_is_leaf = True, namespace = 'keras', rests = ()\n\n    def tree_map(\n        func: Callable[..., U],\n        tree: PyTree[T],\n        /,\n        *rests: PyTree[S],\n        is_leaf: Callable[[T], bool] | None = None,\n        none_is_leaf: bool = False,\n        namespace: str = '',\n    ) -> PyTree[U]:\n        \"\"\"Map a multi-input function over pytree args to produce a new pytree.\n    \n        See also :func:`tree_map_`, :func:`tree_map_with_path`, :func:`tree_map_with_path_`,\n        and :func:`tree_broadcast_map`.\n    \n        >>> tree_map(lambda x: x + 1, {'x': 7, 'y': (42, 64)})\n        {'x': 8, 'y': (43, 65)}\n        >>> tree_map(lambda x: x + 1, {'x': 7, 'y': (42, 64), 'z': None})\n        {'x': 8, 'y': (43, 65), 'z': None}\n        >>> tree_map(lambda x: x is None, {'x': 7, 'y': (42, 64), 'z': None})\n        {'x': False, 'y': (False, False), 'z': None}\n        >>> tree_map(lambda x: x is None, {'x': 7, 'y': (42, 64), 'z': None}, none_is_leaf=True)\n        {'x': False, 'y': (False, False), 'z': True}\n    \n        If multiple inputs are given, the structure of the tree is taken from the first input;\n        subsequent inputs need only have ``tree`` as a prefix:\n    \n        >>> tree_map(lambda x, y: [x] + y, [5, 6], [[7, 9], [1, 2]])\n        [[5, 7, 9], [6, 1, 2]]\n    \n        Args:\n            func (callable): A function that takes ``1 + len(rests)`` arguments, to be applied at the\n                corresponding leaves of the pytrees.\n            tree (pytree): A pytree to be mapped over, with each leaf providing the first positional\n                argument to function ``func``.\n            rests (tuple of pytree): A tuple of pytrees, each of which has the same structure as\n                ``tree`` or has ``tree`` as a prefix.\n            is_leaf (callable, optional): An optionally specified function that will be called at each\n                flattening step. It should return a boolean, with :data:`True` stopping the traversal\n                and the whole subtree being treated as a leaf, and :data:`False` indicating the\n                flattening should traverse the current object.\n            none_is_leaf (bool, optional): Whether to treat :data:`None` as a leaf. If :data:`False`,\n                :data:`None` is a non-leaf node with arity 0. Thus :data:`None` is contained in the\n                treespec rather than in the leaves list and :data:`None` will be remain in the result\n                pytree. (default: :data:`False`)\n            namespace (str, optional): The registry namespace used for custom pytree node types.\n                (default: :const:`''`, i.e., the global namespace)\n    \n        Returns:\n            A new pytree with the same structure as ``tree`` but with the value at each leaf given by\n            ``func(x, *xs)`` where ``x`` is the value at the corresponding leaf in ``tree`` and ``xs``\n            is the tuple of values at corresponding nodes in ``rests``.\n        \"\"\"\n        leaves, treespec = _C.flatten(tree, is_leaf, none_is_leaf, namespace)\n        flat_args = [leaves] + [treespec.flatten_up_to(r) for r in rests]\n>       return treespec.unflatten(map(func, *flat_args))\nE       ValueError: When passing a dataset to a Keras model, the arrays must be at least rank 1. Received: None of rank 0.\n\n/usr/local/lib/python3.10/dist-packages/optree/ops.py:766: ValueError\n----------------------------- Captured stdout call -----------------------------\nUsing GCN (local pooling) filters...\nUsing GCN (local pooling) filters...\n\n\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 318ms/step\n_______________________ test_APPNP_linkmodel_apply_dense _______________________\n\n    def test_APPNP_linkmodel_apply_dense():\n        G, features = create_graph_features()\n        adj = G.to_adjacency_matrix()\n        adj = np.array(adj.todense()[None, :, :])\n    \n        generator = FullBatchLinkGenerator(G, sparse=False, method=\"none\")\n        appnpnModel = APPNP([3], generator, activations=[\"relu\"], dropout=0.5)\n    \n        x_in, x_out = appnpnModel.in_out_tensors()\n        model = keras.Model(inputs=x_in, outputs=x_out)\n    \n        # Check fit method\n        out_indices = np.array([[[0, 1], [1, 2]]], dtype=\"int32\")\n        preds_1 = model.predict([features[None, :, :], out_indices, adj])\n        assert preds_1.shape == (1, 2, 2, 3)\n    \n        # Check fit method\n>       preds_2 = model.predict(generator.flow([(\"a\", \"b\"), (\"b\", \"c\")]))\n\ntests/layer/test_appnp.py:164: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py:122: in error_handler\n    raise e.with_traceback(filtered_tb) from None\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nfunc = <function get_keras_tensor_spec.<locals>.get_single_tensor_spec at 0x7fc178d15cf0>\ntree = ([array([[[1., 1.],\n        [1., 0.],\n        [0., 1.]]], dtype=float32), array([[[0, 1],\n        [1, 2]]], dtype=uint8), array([[[0., 1., 1.],\n        [1., 0., 1.],\n        [1., 1., 0.]]], dtype=float32)], None)\nis_leaf = None, none_is_leaf = True, namespace = 'keras', rests = ()\n\n    def tree_map(\n        func: Callable[..., U],\n        tree: PyTree[T],\n        /,\n        *rests: PyTree[S],\n        is_leaf: Callable[[T], bool] | None = None,\n        none_is_leaf: bool = False,\n        namespace: str = '',\n    ) -> PyTree[U]:\n        \"\"\"Map a multi-input function over pytree args to produce a new pytree.\n    \n        See also :func:`tree_map_`, :func:`tree_map_with_path`, :func:`tree_map_with_path_`,\n        and :func:`tree_broadcast_map`.\n    \n        >>> tree_map(lambda x: x + 1, {'x': 7, 'y': (42, 64)})\n        {'x': 8, 'y': (43, 65)}\n        >>> tree_map(lambda x: x + 1, {'x': 7, 'y': (42, 64), 'z': None})\n        {'x': 8, 'y': (43, 65), 'z': None}\n        >>> tree_map(lambda x: x is None, {'x': 7, 'y': (42, 64), 'z': None})\n        {'x': False, 'y': (False, False), 'z': None}\n        >>> tree_map(lambda x: x is None, {'x': 7, 'y': (42, 64), 'z': None}, none_is_leaf=True)\n        {'x': False, 'y': (False, False), 'z': True}\n    \n        If multiple inputs are given, the structure of the tree is taken from the first input;\n        subsequent inputs need only have ``tree`` as a prefix:\n    \n        >>> tree_map(lambda x, y: [x] + y, [5, 6], [[7, 9], [1, 2]])\n        [[5, 7, 9], [6, 1, 2]]\n    \n        Args:\n            func (callable): A function that takes ``1 + len(rests)`` arguments, to be applied at the\n                corresponding leaves of the pytrees.\n            tree (pytree): A pytree to be mapped over, with each leaf providing the first positional\n                argument to function ``func``.\n            rests (tuple of pytree): A tuple of pytrees, each of which has the same structure as\n                ``tree`` or has ``tree`` as a prefix.\n            is_leaf (callable, optional): An optionally specified function that will be called at each\n                flattening step. It should return a boolean, with :data:`True` stopping the traversal\n                and the whole subtree being treated as a leaf, and :data:`False` indicating the\n                flattening should traverse the current object.\n            none_is_leaf (bool, optional): Whether to treat :data:`None` as a leaf. If :data:`False`,\n                :data:`None` is a non-leaf node with arity 0. Thus :data:`None` is contained in the\n                treespec rather than in the leaves list and :data:`None` will be remain in the result\n                pytree. (default: :data:`False`)\n            namespace (str, optional): The registry namespace used for custom pytree node types.\n                (default: :const:`''`, i.e., the global namespace)\n    \n        Returns:\n            A new pytree with the same structure as ``tree`` but with the value at each leaf given by\n            ``func(x, *xs)`` where ``x`` is the value at the corresponding leaf in ``tree`` and ``xs``\n            is the tuple of values at corresponding nodes in ``rests``.\n        \"\"\"\n        leaves, treespec = _C.flatten(tree, is_leaf, none_is_leaf, namespace)\n        flat_args = [leaves] + [treespec.flatten_up_to(r) for r in rests]\n>       return treespec.unflatten(map(func, *flat_args))\nE       ValueError: When passing a dataset to a Keras model, the arrays must be at least rank 1. Received: None of rank 0.\n\n/usr/local/lib/python3.10/dist-packages/optree/ops.py:766: ValueError\n----------------------------- Captured stdout call -----------------------------\n\n\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step\n______________________ test_APPNP_linkmodel_apply_sparse _______________________\n\n    def test_APPNP_linkmodel_apply_sparse():\n    \n        G, features = create_graph_features()\n        adj = G.to_adjacency_matrix()\n        features, adj = GCN_Aadj_feats_op(features, adj)\n        adj = adj.tocoo()\n        A_indices = np.expand_dims(\n            np.hstack((adj.row[:, None], adj.col[:, None])).astype(np.int64), 0\n        )\n        A_values = np.expand_dims(adj.data, 0)\n    \n        generator = FullBatchLinkGenerator(G, sparse=True, method=\"gcn\")\n        appnpnModel = APPNP(\n            layer_sizes=[3], activations=[\"relu\"], generator=generator, dropout=0.5\n        )\n    \n        x_in, x_out = appnpnModel.in_out_tensors()\n        model = keras.Model(inputs=x_in, outputs=x_out)\n    \n        # Check fit method\n        out_indices = np.array([[[0, 1], [1, 2]]], dtype=\"int32\")\n        preds_1 = model.predict([features[None, :, :], out_indices, A_indices, A_values])\n        assert preds_1.shape == (1, 2, 2, 3)\n    \n        # Check fit method\n>       preds_2 = model.predict(generator.flow([(\"a\", \"b\"), (\"b\", \"c\")]))\n\ntests/layer/test_appnp.py:195: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py:122: in error_handler\n    raise e.with_traceback(filtered_tb) from None\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nfunc = <function get_keras_tensor_spec.<locals>.get_single_tensor_spec at 0x7fc14d7ea5f0>\ntree = ([array([[[1., 1.],\n        [1., 0.],\n        [0., 1.]]], dtype=float32), array([[[0, 1],\n        [1, 2]]], dtype=uint...3333, 0.33333333, 0.33333333, 0.33333333, 0.33333333,\n        0.33333333, 0.33333333, 0.33333333, 0.33333333]])], None)\nis_leaf = None, none_is_leaf = True, namespace = 'keras', rests = ()\n\n    def tree_map(\n        func: Callable[..., U],\n        tree: PyTree[T],\n        /,\n        *rests: PyTree[S],\n        is_leaf: Callable[[T], bool] | None = None,\n        none_is_leaf: bool = False,\n        namespace: str = '',\n    ) -> PyTree[U]:\n        \"\"\"Map a multi-input function over pytree args to produce a new pytree.\n    \n        See also :func:`tree_map_`, :func:`tree_map_with_path`, :func:`tree_map_with_path_`,\n        and :func:`tree_broadcast_map`.\n    \n        >>> tree_map(lambda x: x + 1, {'x': 7, 'y': (42, 64)})\n        {'x': 8, 'y': (43, 65)}\n        >>> tree_map(lambda x: x + 1, {'x': 7, 'y': (42, 64), 'z': None})\n        {'x': 8, 'y': (43, 65), 'z': None}\n        >>> tree_map(lambda x: x is None, {'x': 7, 'y': (42, 64), 'z': None})\n        {'x': False, 'y': (False, False), 'z': None}\n        >>> tree_map(lambda x: x is None, {'x': 7, 'y': (42, 64), 'z': None}, none_is_leaf=True)\n        {'x': False, 'y': (False, False), 'z': True}\n    \n        If multiple inputs are given, the structure of the tree is taken from the first input;\n        subsequent inputs need only have ``tree`` as a prefix:\n    \n        >>> tree_map(lambda x, y: [x] + y, [5, 6], [[7, 9], [1, 2]])\n        [[5, 7, 9], [6, 1, 2]]\n    \n        Args:\n            func (callable): A function that takes ``1 + len(rests)`` arguments, to be applied at the\n                corresponding leaves of the pytrees.\n            tree (pytree): A pytree to be mapped over, with each leaf providing the first positional\n                argument to function ``func``.\n            rests (tuple of pytree): A tuple of pytrees, each of which has the same structure as\n                ``tree`` or has ``tree`` as a prefix.\n            is_leaf (callable, optional): An optionally specified function that will be called at each\n                flattening step. It should return a boolean, with :data:`True` stopping the traversal\n                and the whole subtree being treated as a leaf, and :data:`False` indicating the\n                flattening should traverse the current object.\n            none_is_leaf (bool, optional): Whether to treat :data:`None` as a leaf. If :data:`False`,\n                :data:`None` is a non-leaf node with arity 0. Thus :data:`None` is contained in the\n                treespec rather than in the leaves list and :data:`None` will be remain in the result\n                pytree. (default: :data:`False`)\n            namespace (str, optional): The registry namespace used for custom pytree node types.\n                (default: :const:`''`, i.e., the global namespace)\n    \n        Returns:\n            A new pytree with the same structure as ``tree`` but with the value at each leaf given by\n            ``func(x, *xs)`` where ``x`` is the value at the corresponding leaf in ``tree`` and ``xs``\n            is the tuple of values at corresponding nodes in ``rests``.\n        \"\"\"\n        leaves, treespec = _C.flatten(tree, is_leaf, none_is_leaf, namespace)\n        flat_args = [leaves] + [treespec.flatten_up_to(r) for r in rests]\n>       return treespec.unflatten(map(func, *flat_args))\nE       ValueError: When passing a dataset to a Keras model, the arrays must be at least rank 1. Received: None of rank 0.\n\n/usr/local/lib/python3.10/dist-packages/optree/ops.py:766: ValueError\n----------------------------- Captured stdout call -----------------------------\nUsing GCN (local pooling) filters...\nUsing GCN (local pooling) filters...\n\n\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 313ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 325ms/step\n____________________ test_APPNP_apply_propagate_model_dense ____________________\n\n    def test_APPNP_apply_propagate_model_dense():\n        G, features = create_graph_features()\n        adj = G.to_adjacency_matrix()\n        features, adj = GCN_Aadj_feats_op(features, adj)\n        adj = np.array(adj.todense()[None, :, :])\n    \n        generator = FullBatchNodeGenerator(G, sparse=False, method=\"gcn\")\n        appnpnModel = APPNP([2], generator=generator, activations=[\"relu\"], dropout=0.5)\n    \n        fully_connected_model = keras.Sequential()\n        fully_connected_model.add(Dense(2))\n    \n        x_in, x_out = appnpnModel.propagate_model(fully_connected_model)\n        model = keras.Model(inputs=x_in, outputs=x_out)\n    \n        # Check fit method\n        out_indices = np.array([[0, 1]], dtype=\"int32\")\n        preds_1 = model.predict([features[None, :, :], out_indices, adj])\n        assert preds_1.shape == (1, 2, 2)\n    \n        # Check fit method\n>       preds_2 = model.predict(generator.flow([\"a\", \"b\"]))\n\ntests/layer/test_appnp.py:222: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py:122: in error_handler\n    raise e.with_traceback(filtered_tb) from None\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nfunc = <function get_keras_tensor_spec.<locals>.get_single_tensor_spec at 0x7fc14d737640>\ntree = ([array([[[1., 1.],\n        [1., 0.],\n        [0., 1.]]], dtype=float32), array([[0, 1]], dtype=uint8), array([[[0.333...333, 0.33333333],\n        [0.33333333, 0.33333333, 0.33333333],\n        [0.33333333, 0.33333333, 0.33333333]]])], None)\nis_leaf = None, none_is_leaf = True, namespace = 'keras', rests = ()\n\n    def tree_map(\n        func: Callable[..., U],\n        tree: PyTree[T],\n        /,\n        *rests: PyTree[S],\n        is_leaf: Callable[[T], bool] | None = None,\n        none_is_leaf: bool = False,\n        namespace: str = '',\n    ) -> PyTree[U]:\n        \"\"\"Map a multi-input function over pytree args to produce a new pytree.\n    \n        See also :func:`tree_map_`, :func:`tree_map_with_path`, :func:`tree_map_with_path_`,\n        and :func:`tree_broadcast_map`.\n    \n        >>> tree_map(lambda x: x + 1, {'x': 7, 'y': (42, 64)})\n        {'x': 8, 'y': (43, 65)}\n        >>> tree_map(lambda x: x + 1, {'x': 7, 'y': (42, 64), 'z': None})\n        {'x': 8, 'y': (43, 65), 'z': None}\n        >>> tree_map(lambda x: x is None, {'x': 7, 'y': (42, 64), 'z': None})\n        {'x': False, 'y': (False, False), 'z': None}\n        >>> tree_map(lambda x: x is None, {'x': 7, 'y': (42, 64), 'z': None}, none_is_leaf=True)\n        {'x': False, 'y': (False, False), 'z': True}\n    \n        If multiple inputs are given, the structure of the tree is taken from the first input;\n        subsequent inputs need only have ``tree`` as a prefix:\n    \n        >>> tree_map(lambda x, y: [x] + y, [5, 6], [[7, 9], [1, 2]])\n        [[5, 7, 9], [6, 1, 2]]\n    \n        Args:\n            func (callable): A function that takes ``1 + len(rests)`` arguments, to be applied at the\n                corresponding leaves of the pytrees.\n            tree (pytree): A pytree to be mapped over, with each leaf providing the first positional\n                argument to function ``func``.\n            rests (tuple of pytree): A tuple of pytrees, each of which has the same structure as\n                ``tree`` or has ``tree`` as a prefix.\n            is_leaf (callable, optional): An optionally specified function that will be called at each\n                flattening step. It should return a boolean, with :data:`True` stopping the traversal\n                and the whole subtree being treated as a leaf, and :data:`False` indicating the\n                flattening should traverse the current object.\n            none_is_leaf (bool, optional): Whether to treat :data:`None` as a leaf. If :data:`False`,\n                :data:`None` is a non-leaf node with arity 0. Thus :data:`None` is contained in the\n                treespec rather than in the leaves list and :data:`None` will be remain in the result\n                pytree. (default: :data:`False`)\n            namespace (str, optional): The registry namespace used for custom pytree node types.\n                (default: :const:`''`, i.e., the global namespace)\n    \n        Returns:\n            A new pytree with the same structure as ``tree`` but with the value at each leaf given by\n            ``func(x, *xs)`` where ``x`` is the value at the corresponding leaf in ``tree`` and ``xs``\n            is the tuple of values at corresponding nodes in ``rests``.\n        \"\"\"\n        leaves, treespec = _C.flatten(tree, is_leaf, none_is_leaf, namespace)\n        flat_args = [leaves] + [treespec.flatten_up_to(r) for r in rests]\n>       return treespec.unflatten(map(func, *flat_args))\nE       ValueError: When passing a dataset to a Keras model, the arrays must be at least rank 1. Received: None of rank 0.\n\n/usr/local/lib/python3.10/dist-packages/optree/ops.py:766: ValueError\n----------------------------- Captured stdout call -----------------------------\nUsing GCN (local pooling) filters...\nUsing GCN (local pooling) filters...\n\n\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 245ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256ms/step\n------------------------------ Captured log call -------------------------------\nWARNING  tensorflow:polymorphic_function.py:157 5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7fc14d737130> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n___________________ test_APPNP_apply_propagate_model_sparse ____________________\n\n    def test_APPNP_apply_propagate_model_sparse():\n    \n        G, features = create_graph_features()\n        adj = G.to_adjacency_matrix()\n        features, adj = GCN_Aadj_feats_op(features, adj)\n        adj = adj.tocoo()\n        A_indices = np.expand_dims(\n            np.hstack((adj.row[:, None], adj.col[:, None])).astype(np.int64), 0\n        )\n        A_values = np.expand_dims(adj.data, 0)\n    \n        generator = FullBatchNodeGenerator(G, sparse=True, method=\"gcn\")\n        appnpnModel = APPNP([2], generator=generator, activations=[\"relu\"], dropout=0.5)\n    \n        fully_connected_model = keras.Sequential()\n        fully_connected_model.add(Dense(2))\n    \n        x_in, x_out = appnpnModel.propagate_model(fully_connected_model)\n        model = keras.Model(inputs=x_in, outputs=x_out)\n    \n        # Check fit method\n        out_indices = np.array([[0, 1]], dtype=\"int32\")\n        preds_1 = model.predict([features[None, :, :], out_indices, A_indices, A_values])\n        assert preds_1.shape == (1, 2, 2)\n    \n        # Check fit method\n>       preds_2 = model.predict(generator.flow([\"a\", \"b\"]))\n\ntests/layer/test_appnp.py:294: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py:122: in error_handler\n    raise e.with_traceback(filtered_tb) from None\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nfunc = <function get_keras_tensor_spec.<locals>.get_single_tensor_spec at 0x7fc14d6fa200>\ntree = ([array([[[1., 1.],\n        [1., 0.],\n        [0., 1.]]], dtype=float32), array([[0, 1]], dtype=uint8), array([[[0, 0]...3333, 0.33333333, 0.33333333, 0.33333333, 0.33333333,\n        0.33333333, 0.33333333, 0.33333333, 0.33333333]])], None)\nis_leaf = None, none_is_leaf = True, namespace = 'keras', rests = ()\n\n    def tree_map(\n        func: Callable[..., U],\n        tree: PyTree[T],\n        /,\n        *rests: PyTree[S],\n        is_leaf: Callable[[T], bool] | None = None,\n        none_is_leaf: bool = False,\n        namespace: str = '',\n    ) -> PyTree[U]:\n        \"\"\"Map a multi-input function over pytree args to produce a new pytree.\n    \n        See also :func:`tree_map_`, :func:`tree_map_with_path`, :func:`tree_map_with_path_`,\n        and :func:`tree_broadcast_map`.\n    \n        >>> tree_map(lambda x: x + 1, {'x': 7, 'y': (42, 64)})\n        {'x': 8, 'y': (43, 65)}\n        >>> tree_map(lambda x: x + 1, {'x': 7, 'y': (42, 64), 'z': None})\n        {'x': 8, 'y': (43, 65), 'z': None}\n        >>> tree_map(lambda x: x is None, {'x': 7, 'y': (42, 64), 'z': None})\n        {'x': False, 'y': (False, False), 'z': None}\n        >>> tree_map(lambda x: x is None, {'x': 7, 'y': (42, 64), 'z': None}, none_is_leaf=True)\n        {'x': False, 'y': (False, False), 'z': True}\n    \n        If multiple inputs are given, the structure of the tree is taken from the first input;\n        subsequent inputs need only have ``tree`` as a prefix:\n    \n        >>> tree_map(lambda x, y: [x] + y, [5, 6], [[7, 9], [1, 2]])\n        [[5, 7, 9], [6, 1, 2]]\n    \n        Args:\n            func (callable): A function that takes ``1 + len(rests)`` arguments, to be applied at the\n                corresponding leaves of the pytrees.\n            tree (pytree): A pytree to be mapped over, with each leaf providing the first positional\n                argument to function ``func``.\n            rests (tuple of pytree): A tuple of pytrees, each of which has the same structure as\n                ``tree`` or has ``tree`` as a prefix.\n            is_leaf (callable, optional): An optionally specified function that will be called at each\n                flattening step. It should return a boolean, with :data:`True` stopping the traversal\n                and the whole subtree being treated as a leaf, and :data:`False` indicating the\n                flattening should traverse the current object.\n            none_is_leaf (bool, optional): Whether to treat :data:`None` as a leaf. If :data:`False`,\n                :data:`None` is a non-leaf node with arity 0. Thus :data:`None` is contained in the\n                treespec rather than in the leaves list and :data:`None` will be remain in the result\n                pytree. (default: :data:`False`)\n            namespace (str, optional): The registry namespace used for custom pytree node types.\n                (default: :const:`''`, i.e., the global namespace)\n    \n        Returns:\n            A new pytree with the same structure as ``tree`` but with the value at each leaf given by\n            ``func(x, *xs)`` where ``x`` is the value at the corresponding leaf in ``tree`` and ``xs``\n            is the tuple of values at corresponding nodes in ``rests``.\n        \"\"\"\n        leaves, treespec = _C.flatten(tree, is_leaf, none_is_leaf, namespace)\n        flat_args = [leaves] + [treespec.flatten_up_to(r) for r in rests]\n>       return treespec.unflatten(map(func, *flat_args))\nE       ValueError: When passing a dataset to a Keras model, the arrays must be at least rank 1. Received: None of rank 0.\n\n/usr/local/lib/python3.10/dist-packages/optree/ops.py:766: ValueError\n----------------------------- Captured stdout call -----------------------------\nUsing GCN (local pooling) filters...\nUsing GCN (local pooling) filters...\n\n\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 324ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336ms/step\n_________________________ test_APPNP_save_load[False] __________________________\n\ntmpdir = local('/tmp/pytest-of-root/pytest-1/test_APPNP_save_load_False_0')\nsparse = False\n\n    @pytest.mark.parametrize(\n        \"sparse\",\n        [False, pytest.param(True, marks=pytest.mark.xfail(reason=\"FIXME #1251\"))],\n    )\n    def test_APPNP_save_load(tmpdir, sparse):\n        G, _ = create_graph_features()\n        generator = FullBatchNodeGenerator(G, sparse=sparse)\n        appnp = APPNP([2, 3], generator, [\"relu\", \"relu\"])\n>       test_utils.model_save_load(tmpdir, appnp)\n\ntests/layer/test_appnp.py:308: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ntests/test_utils/__init__.py:43: in model_save_load\n    func(model, str(saved_dir))\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nmodel = <Functional name=functional_15, built=True>\nfilepath = '/tmp/pytest-of-root/pytest-1/test_APPNP_save_load_False_0/0'\noverwrite = True, zipped = True, kwargs = {}, include_optimizer = True\nsave_format = False, is_hf = False, exists = False\n\n    @keras_export([\"keras.saving.save_model\", \"keras.models.save_model\"])\n    def save_model(model, filepath, overwrite=True, zipped=None, **kwargs):\n        \"\"\"Saves a model as a `.keras` file.\n    \n        Args:\n            model: Keras model instance to be saved.\n            filepath: `str` or `pathlib.Path` object. Path where to save the model.\n            overwrite: Whether we should overwrite any existing model at the target\n                location, or instead ask the user via an interactive prompt.\n            zipped: Whether to save the model as a zipped `.keras`\n                archive (default when saving locally), or as an unzipped directory\n                (default when saving on the Hugging Face Hub).\n    \n        Example:\n    \n        ```python\n        model = keras.Sequential(\n            [\n                keras.layers.Dense(5, input_shape=(3,)),\n                keras.layers.Softmax(),\n            ],\n        )\n        model.save(\"model.keras\")\n        loaded_model = keras.saving.load_model(\"model.keras\")\n        x = keras.random.uniform((10, 3))\n        assert np.allclose(model.predict(x), loaded_model.predict(x))\n        ```\n    \n        Note that `model.save()` is an alias for `keras.saving.save_model()`.\n    \n        The saved `.keras` file is a `zip` archive that contains:\n    \n        - The model's configuration (architecture)\n        - The model's weights\n        - The model's optimizer's state (if any)\n    \n        Thus models can be reinstantiated in the exact same state.\n        \"\"\"\n        include_optimizer = kwargs.pop(\"include_optimizer\", True)\n        save_format = kwargs.pop(\"save_format\", False)\n        if save_format:\n            if str(filepath).endswith((\".h5\", \".hdf5\")) or str(filepath).endswith(\n                \".keras\"\n            ):\n                logging.warning(\n                    \"The `save_format` argument is deprecated in Keras 3. \"\n                    \"We recommend removing this argument as it can be inferred \"\n                    \"from the file path. \"\n                    f\"Received: save_format={save_format}\"\n                )\n            else:\n                raise ValueError(\n                    \"The `save_format` argument is deprecated in Keras 3. \"\n                    \"Please remove this argument and pass a file path with \"\n                    \"either `.keras` or `.h5` extension.\"\n                    f\"Received: save_format={save_format}\"\n                )\n        if kwargs:\n            raise ValueError(\n                \"The following argument(s) are not supported: \"\n                f\"{list(kwargs.keys())}\"\n            )\n    \n        # Deprecation warnings\n        if str(filepath).endswith((\".h5\", \".hdf5\")):\n            logging.warning(\n                \"You are saving your model as an HDF5 file via \"\n                \"`model.save()` or `keras.saving.save_model(model)`. \"\n                \"This file format is considered legacy. \"\n                \"We recommend using instead the native Keras format, \"\n                \"e.g. `model.save('my_model.keras')` or \"\n                \"`keras.saving.save_model(model, 'my_model.keras')`. \"\n            )\n    \n        is_hf = str(filepath).startswith(\"hf://\")\n        if zipped is None:\n            zipped = not is_hf  # default behavior depends on destination\n    \n        # If file exists and should not be overwritten.\n        try:\n            exists = (not is_hf) and os.path.exists(filepath)\n        except TypeError:\n            exists = False\n        if exists and not overwrite:\n            proceed = io_utils.ask_to_proceed_with_overwrite(filepath)\n            if not proceed:\n                return\n    \n        if zipped and str(filepath).endswith(\".keras\"):\n            return saving_lib.save_model(model, filepath)\n        if not zipped:\n            return saving_lib.save_model(model, filepath, zipped=False)\n        if str(filepath).endswith((\".h5\", \".hdf5\")):\n            return legacy_h5_format.save_model_to_hdf5(\n                model, filepath, overwrite, include_optimizer\n            )\n>       raise ValueError(\n            \"Invalid filepath extension for saving. \"\n            \"Please add either a `.keras` extension for the native Keras \"\n            f\"format (recommended) or a `.h5` extension. \"\n            \"Use `model.export(filepath)` if you want to export a SavedModel \"\n            \"for use with TFLite/TFServing/etc. \"\n            f\"Received: filepath={filepath}.\"\n        )\nE       ValueError: Invalid filepath extension for saving. Please add either a `.keras` extension for the native Keras format (recommended) or a `.h5` extension. Use `model.export(filepath)` if you want to export a SavedModel for use with TFLite/TFServing/etc. Received: filepath=/tmp/pytest-of-root/pytest-1/test_APPNP_save_load_False_0/0.\n\n/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_api.py:114: ValueError\n----------------------------- Captured stdout call -----------------------------\nUsing GCN (local pooling) filters...\n___________________________ test_attri2vec_serialize ___________________________\n\n    def test_attri2vec_serialize():\n        attri2vec = Attri2Vec(\n            layer_sizes=[4],\n            bias=False,\n            input_dim=2,\n            node_num=4,\n            multiplicity=2,\n            activation=\"linear\",\n            normalize=None,\n        )\n    \n        inp = keras.Input(shape=(2,))\n        out = attri2vec(inp)\n        model = keras.Model(inputs=inp, outputs=out)\n    \n        # Save model\n        model_json = model.to_json()\n    \n        # Set all weights to one\n        model_weights = [np.ones_like(w) for w in model.get_weights()]\n    \n        # Load model from json & set all weights\n>       model2 = keras.models.model_from_json(model_json)\n\ntests/layer/test_attri2vec.py:162: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n/usr/local/lib/python3.10/dist-packages/keras/src/models/model.py:886: in model_from_json\n    return serialization_lib.deserialize_keras_object(\n/usr/local/lib/python3.10/dist-packages/keras/src/saving/serialization_lib.py:733: in deserialize_keras_object\n    instance = cls.from_config(inner_config)\n/usr/local/lib/python3.10/dist-packages/keras/src/models/model.py:660: in from_config\n    return functional_from_config(\n/usr/local/lib/python3.10/dist-packages/keras/src/models/functional.py:558: in functional_from_config\n    process_layer(layer_data)\n/usr/local/lib/python3.10/dist-packages/keras/src/models/functional.py:525: in process_layer\n    layer = serialization_lib.deserialize_keras_object(\n/usr/local/lib/python3.10/dist-packages/keras/src/saving/serialization_lib.py:733: in deserialize_keras_object\n    instance = cls.from_config(inner_config)\n/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/lambda_layer.py:190: in from_config\n    cls._raise_for_lambda_deserialization(\"function\", safe_mode)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\narg_name = 'function', safe_mode = True\n\n    @staticmethod\n    def _raise_for_lambda_deserialization(arg_name, safe_mode):\n        if safe_mode:\n>           raise ValueError(\n                f\"The `{arg_name}` of this `Lambda` layer is a Python lambda. \"\n                \"Deserializing it is unsafe. If you trust the source of the \"\n                \"config artifact, you can override this error \"\n                \"by passing `safe_mode=False` \"\n                \"to `from_config()`, or calling \"\n                \"`keras.config.enable_unsafe_deserialization().\"\n            )\nE           ValueError: The `function` of this `Lambda` layer is a Python lambda. Deserializing it is unsafe. If you trust the source of the config artifact, you can override this error by passing `safe_mode=False` to `from_config()`, or calling `keras.config.enable_unsafe_deserialization().\n\n/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/lambda_layer.py:172: ValueError\n___________________________ test_attri2vec_save_load ___________________________\n\ntmpdir = local('/tmp/pytest-of-root/pytest-1/test_attri2vec_save_load0')\n\n    def test_attri2vec_save_load(tmpdir):\n        attri2vec = Attri2Vec(\n            layer_sizes=[4],\n            bias=True,\n            input_dim=2,\n            node_num=4,\n            multiplicity=2,\n            activation=\"linear\",\n            normalize=None,\n        )\n>       test_utils.model_save_load(tmpdir, attri2vec)\n\ntests/layer/test_attri2vec.py:183: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ntests/test_utils/__init__.py:43: in model_save_load\n    func(model, str(saved_dir))\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nmodel = <Functional name=functional_23, built=True>\nfilepath = '/tmp/pytest-of-root/pytest-1/test_attri2vec_save_load0/0'\noverwrite = True, zipped = True, kwargs = {}, include_optimizer = True\nsave_format = False, is_hf = False, exists = False\n\n    @keras_export([\"keras.saving.save_model\", \"keras.models.save_model\"])\n    def save_model(model, filepath, overwrite=True, zipped=None, **kwargs):\n        \"\"\"Saves a model as a `.keras` file.\n    \n        Args:\n            model: Keras model instance to be saved.\n            filepath: `str` or `pathlib.Path` object. Path where to save the model.\n            overwrite: Whether we should overwrite any existing model at the target\n                location, or instead ask the user via an interactive prompt.\n            zipped: Whether to save the model as a zipped `.keras`\n                archive (default when saving locally), or as an unzipped directory\n                (default when saving on the Hugging Face Hub).\n    \n        Example:\n    \n        ```python\n        model = keras.Sequential(\n            [\n                keras.layers.Dense(5, input_shape=(3,)),\n                keras.layers.Softmax(),\n            ],\n        )\n        model.save(\"model.keras\")\n        loaded_model = keras.saving.load_model(\"model.keras\")\n        x = keras.random.uniform((10, 3))\n        assert np.allclose(model.predict(x), loaded_model.predict(x))\n        ```\n    \n        Note that `model.save()` is an alias for `keras.saving.save_model()`.\n    \n        The saved `.keras` file is a `zip` archive that contains:\n    \n        - The model's configuration (architecture)\n        - The model's weights\n        - The model's optimizer's state (if any)\n    \n        Thus models can be reinstantiated in the exact same state.\n        \"\"\"\n        include_optimizer = kwargs.pop(\"include_optimizer\", True)\n        save_format = kwargs.pop(\"save_format\", False)\n        if save_format:\n            if str(filepath).endswith((\".h5\", \".hdf5\")) or str(filepath).endswith(\n                \".keras\"\n            ):\n                logging.warning(\n                    \"The `save_format` argument is deprecated in Keras 3. \"\n                    \"We recommend removing this argument as it can be inferred \"\n                    \"from the file path. \"\n                    f\"Received: save_format={save_format}\"\n                )\n            else:\n                raise ValueError(\n                    \"The `save_format` argument is deprecated in Keras 3. \"\n                    \"Please remove this argument and pass a file path with \"\n                    \"either `.keras` or `.h5` extension.\"\n                    f\"Received: save_format={save_format}\"\n                )\n        if kwargs:\n            raise ValueError(\n                \"The following argument(s) are not supported: \"\n                f\"{list(kwargs.keys())}\"\n            )\n    \n        # Deprecation warnings\n        if str(filepath).endswith((\".h5\", \".hdf5\")):\n            logging.warning(\n                \"You are saving your model as an HDF5 file via \"\n                \"`model.save()` or `keras.saving.save_model(model)`. \"\n                \"This file format is considered legacy. \"\n                \"We recommend using instead the native Keras format, \"\n                \"e.g. `model.save('my_model.keras')` or \"\n                \"`keras.saving.save_model(model, 'my_model.keras')`. \"\n            )\n    \n        is_hf = str(filepath).startswith(\"hf://\")\n        if zipped is None:\n            zipped = not is_hf  # default behavior depends on destination\n    \n        # If file exists and should not be overwritten.\n        try:\n            exists = (not is_hf) and os.path.exists(filepath)\n        except TypeError:\n            exists = False\n        if exists and not overwrite:\n            proceed = io_utils.ask_to_proceed_with_overwrite(filepath)\n            if not proceed:\n                return\n    \n        if zipped and str(filepath).endswith(\".keras\"):\n            return saving_lib.save_model(model, filepath)\n        if not zipped:\n            return saving_lib.save_model(model, filepath, zipped=False)\n        if str(filepath).endswith((\".h5\", \".hdf5\")):\n            return legacy_h5_format.save_model_to_hdf5(\n                model, filepath, overwrite, include_optimizer\n            )\n>       raise ValueError(\n            \"Invalid filepath extension for saving. \"\n            \"Please add either a `.keras` extension for the native Keras \"\n            f\"format (recommended) or a `.h5` extension. \"\n            \"Use `model.export(filepath)` if you want to export a SavedModel \"\n            \"for use with TFLite/TFServing/etc. \"\n            f\"Received: filepath={filepath}.\"\n        )\nE       ValueError: Invalid filepath extension for saving. Please add either a `.keras` extension for the native Keras format (recommended) or a `.h5` extension. Use `model.export(filepath)` if you want to export a SavedModel for use with TFLite/TFServing/etc. Received: filepath=/tmp/pytest-of-root/pytest-1/test_attri2vec_save_load0/0.\n\n/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_api.py:114: ValueError\n____________________________ test_ClusterGCN_apply _____________________________\n\n    def test_ClusterGCN_apply():\n    \n        G, _ = create_graph_features()\n    \n        generator = ClusterNodeGenerator(G)\n    \n        cluster_gcn_model = ClusterGCN(\n            layer_sizes=[2], generator=generator, activations=[\"relu\"], dropout=0.0\n        )\n    \n        x_in, x_out = cluster_gcn_model.in_out_tensors()\n        model = keras.Model(inputs=x_in, outputs=x_out)\n    \n        # Check fit method\n>       preds_2 = model.predict(generator.flow([\"a\", \"b\", \"c\"]))\n\ntests/layer/test_cluster_gcn.py:67: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py:122: in error_handler\n    raise e.with_traceback(filtered_tb) from None\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nfunc = <function get_keras_tensor_spec.<locals>.get_single_tensor_spec at 0x7fc17832aef0>\ntree = ([array([[[1., 0.],\n        [1., 1.],\n        [0., 1.]]], dtype=float32), array([[1, 0, 2]]), array([[[0.36666667, 0.3...],\n        [0.33333334, 0.36666667, 0.33333334],\n        [0.33333334, 0.33333334, 0.36666667]]], dtype=float32)], None)\nis_leaf = None, none_is_leaf = True, namespace = 'keras', rests = ()\n\n    def tree_map(\n        func: Callable[..., U],\n        tree: PyTree[T],\n        /,\n        *rests: PyTree[S],\n        is_leaf: Callable[[T], bool] | None = None,\n        none_is_leaf: bool = False,\n        namespace: str = '',\n    ) -> PyTree[U]:\n        \"\"\"Map a multi-input function over pytree args to produce a new pytree.\n    \n        See also :func:`tree_map_`, :func:`tree_map_with_path`, :func:`tree_map_with_path_`,\n        and :func:`tree_broadcast_map`.\n    \n        >>> tree_map(lambda x: x + 1, {'x': 7, 'y': (42, 64)})\n        {'x': 8, 'y': (43, 65)}\n        >>> tree_map(lambda x: x + 1, {'x': 7, 'y': (42, 64), 'z': None})\n        {'x': 8, 'y': (43, 65), 'z': None}\n        >>> tree_map(lambda x: x is None, {'x': 7, 'y': (42, 64), 'z': None})\n        {'x': False, 'y': (False, False), 'z': None}\n        >>> tree_map(lambda x: x is None, {'x': 7, 'y': (42, 64), 'z': None}, none_is_leaf=True)\n        {'x': False, 'y': (False, False), 'z': True}\n    \n        If multiple inputs are given, the structure of the tree is taken from the first input;\n        subsequent inputs need only have ``tree`` as a prefix:\n    \n        >>> tree_map(lambda x, y: [x] + y, [5, 6], [[7, 9], [1, 2]])\n        [[5, 7, 9], [6, 1, 2]]\n    \n        Args:\n            func (callable): A function that takes ``1 + len(rests)`` arguments, to be applied at the\n                corresponding leaves of the pytrees.\n            tree (pytree): A pytree to be mapped over, with each leaf providing the first positional\n                argument to function ``func``.\n            rests (tuple of pytree): A tuple of pytrees, each of which has the same structure as\n                ``tree`` or has ``tree`` as a prefix.\n            is_leaf (callable, optional): An optionally specified function that will be called at each\n                flattening step. It should return a boolean, with :data:`True` stopping the traversal\n                and the whole subtree being treated as a leaf, and :data:`False` indicating the\n                flattening should traverse the current object.\n            none_is_leaf (bool, optional): Whether to treat :data:`None` as a leaf. If :data:`False`,\n                :data:`None` is a non-leaf node with arity 0. Thus :data:`None` is contained in the\n                treespec rather than in the leaves list and :data:`None` will be remain in the result\n                pytree. (default: :data:`False`)\n            namespace (str, optional): The registry namespace used for custom pytree node types.\n                (default: :const:`''`, i.e., the global namespace)\n    \n        Returns:\n            A new pytree with the same structure as ``tree`` but with the value at each leaf given by\n            ``func(x, *xs)`` where ``x`` is the value at the corresponding leaf in ``tree`` and ``xs``\n            is the tuple of values at corresponding nodes in ``rests``.\n        \"\"\"\n        leaves, treespec = _C.flatten(tree, is_leaf, none_is_leaf, namespace)\n        flat_args = [leaves] + [treespec.flatten_up_to(r) for r in rests]\n>       return treespec.unflatten(map(func, *flat_args))\nE       ValueError: When passing a dataset to a Keras model, the arrays must be at least rank 1. Received: None of rank 0.\n\n/usr/local/lib/python3.10/dist-packages/optree/ops.py:766: ValueError\n----------------------------- Captured stdout call -----------------------------\nNumber of clusters 1\n0 cluster has size 3\n__________________________ test_ClusterGCN_save_load ___________________________\n\ntmpdir = local('/tmp/pytest-of-root/pytest-1/test_ClusterGCN_save_load0')\n\n    def test_ClusterGCN_save_load(tmpdir):\n        G, _ = create_graph_features()\n        generator = ClusterNodeGenerator(G)\n        cluster_gcn = ClusterGCN(\n            layer_sizes=[2, 3], activations=[\"relu\", \"relu\"], generator=generator\n        )\n>       test_utils.model_save_load(tmpdir, cluster_gcn)\n\ntests/layer/test_cluster_gcn.py:172: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ntests/test_utils/__init__.py:43: in model_save_load\n    func(model, str(saved_dir))\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nmodel = <Functional name=functional_25, built=True>\nfilepath = '/tmp/pytest-of-root/pytest-1/test_ClusterGCN_save_load0/0'\noverwrite = True, zipped = True, kwargs = {}, include_optimizer = True\nsave_format = False, is_hf = False, exists = False\n\n    @keras_export([\"keras.saving.save_model\", \"keras.models.save_model\"])\n    def save_model(model, filepath, overwrite=True, zipped=None, **kwargs):\n        \"\"\"Saves a model as a `.keras` file.\n    \n        Args:\n            model: Keras model instance to be saved.\n            filepath: `str` or `pathlib.Path` object. Path where to save the model.\n            overwrite: Whether we should overwrite any existing model at the target\n                location, or instead ask the user via an interactive prompt.\n            zipped: Whether to save the model as a zipped `.keras`\n                archive (default when saving locally), or as an unzipped directory\n                (default when saving on the Hugging Face Hub).\n    \n        Example:\n    \n        ```python\n        model = keras.Sequential(\n            [\n                keras.layers.Dense(5, input_shape=(3,)),\n                keras.layers.Softmax(),\n            ],\n        )\n        model.save(\"model.keras\")\n        loaded_model = keras.saving.load_model(\"model.keras\")\n        x = keras.random.uniform((10, 3))\n        assert np.allclose(model.predict(x), loaded_model.predict(x))\n        ```\n    \n        Note that `model.save()` is an alias for `keras.saving.save_model()`.\n    \n        The saved `.keras` file is a `zip` archive that contains:\n    \n        - The model's configuration (architecture)\n        - The model's weights\n        - The model's optimizer's state (if any)\n    \n        Thus models can be reinstantiated in the exact same state.\n        \"\"\"\n        include_optimizer = kwargs.pop(\"include_optimizer\", True)\n        save_format = kwargs.pop(\"save_format\", False)\n        if save_format:\n            if str(filepath).endswith((\".h5\", \".hdf5\")) or str(filepath).endswith(\n                \".keras\"\n            ):\n                logging.warning(\n                    \"The `save_format` argument is deprecated in Keras 3. \"\n                    \"We recommend removing this argument as it can be inferred \"\n                    \"from the file path. \"\n                    f\"Received: save_format={save_format}\"\n                )\n            else:\n                raise ValueError(\n                    \"The `save_format` argument is deprecated in Keras 3. \"\n                    \"Please remove this argument and pass a file path with \"\n                    \"either `.keras` or `.h5` extension.\"\n                    f\"Received: save_format={save_format}\"\n                )\n        if kwargs:\n            raise ValueError(\n                \"The following argument(s) are not supported: \"\n                f\"{list(kwargs.keys())}\"\n            )\n    \n        # Deprecation warnings\n        if str(filepath).endswith((\".h5\", \".hdf5\")):\n            logging.warning(\n                \"You are saving your model as an HDF5 file via \"\n                \"`model.save()` or `keras.saving.save_model(model)`. \"\n                \"This file format is considered legacy. \"\n                \"We recommend using instead the native Keras format, \"\n                \"e.g. `model.save('my_model.keras')` or \"\n                \"`keras.saving.save_model(model, 'my_model.keras')`. \"\n            )\n    \n        is_hf = str(filepath).startswith(\"hf://\")\n        if zipped is None:\n            zipped = not is_hf  # default behavior depends on destination\n    \n        # If file exists and should not be overwritten.\n        try:\n            exists = (not is_hf) and os.path.exists(filepath)\n        except TypeError:\n            exists = False\n        if exists and not overwrite:\n            proceed = io_utils.ask_to_proceed_with_overwrite(filepath)\n            if not proceed:\n                return\n    \n        if zipped and str(filepath).endswith(\".keras\"):\n            return saving_lib.save_model(model, filepath)\n        if not zipped:\n            return saving_lib.save_model(model, filepath, zipped=False)\n        if str(filepath).endswith((\".h5\", \".hdf5\")):\n            return legacy_h5_format.save_model_to_hdf5(\n                model, filepath, overwrite, include_optimizer\n            )\n>       raise ValueError(\n            \"Invalid filepath extension for saving. \"\n            \"Please add either a `.keras` extension for the native Keras \"\n            f\"format (recommended) or a `.h5` extension. \"\n            \"Use `model.export(filepath)` if you want to export a SavedModel \"\n            \"for use with TFLite/TFServing/etc. \"\n            f\"Received: filepath={filepath}.\"\n        )\nE       ValueError: Invalid filepath extension for saving. Please add either a `.keras` extension for the native Keras format (recommended) or a `.h5` extension. Use `model.export(filepath)` if you want to export a SavedModel for use with TFLite/TFServing/etc. Received: filepath=/tmp/pytest-of-root/pytest-1/test_ClusterGCN_save_load0/0.\n\n/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_api.py:114: ValueError\n----------------------------- Captured stdout call -----------------------------\nNumber of clusters 1\n0 cluster has size 3\n_____________________ test_fullbatch_cluster_models[APPNP] _____________________\n\nmodel_type = <class 'stellargraph.layer.appnp.APPNP'>\n\n    @pytest.mark.parametrize(\"model_type\", [APPNP, GAT, GCN])\n    def test_fullbatch_cluster_models(model_type):\n        G = example_graph_random(n_nodes=50)\n        generator = ClusterNodeGenerator(G, clusters=10)\n        nodes = G.nodes()[:40]\n        gen = generator.flow(nodes, targets=np.ones(len(nodes)))\n    \n        gnn = model_type(\n            generator=generator,\n            layer_sizes=[16, 16, 1],\n            activations=[\"relu\", \"relu\", \"relu\"],\n        )\n    \n        model = tf.keras.Model(*gnn.in_out_tensors())\n        model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\")\n>       history = model.fit(gen, validation_data=gen, epochs=2)\n\ntests/layer/test_cluster_models.py:40: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py:122: in error_handler\n    raise e.with_traceback(filtered_tb) from None\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\ngenerator = <bound method PyDatasetAdapter._get_iterator of <keras.src.trainers.data_adapters.py_dataset_adapter.PyDatasetAdapter object at 0x7fc18c5545b0>>\noutput_types = None, output_shapes = None, args = None\noutput_signature = ([TensorSpec(shape=(None, 5, 4), dtype=tf.float32, name=None), TensorSpec(shape=(None, None), dtype=tf.int64, name=Non...sorSpec(shape=(None, 5, 5), dtype=tf.float32, name=None)], TensorSpec(shape=(None, None), dtype=tf.float64, name=None))\nname = None\n\n    def _from_generator(generator, output_types, output_shapes, args,\n                        output_signature, name):\n      \"\"\"Creates a `Dataset` whose elements are generated by `generator`.\n    \n      Note: The current implementation of `Dataset.from_generator()` uses\n      `tf.numpy_function` and inherits the same constraints. In particular, it\n      requires the dataset and iterator related operations to be placed\n      on a device in the same process as the Python program that called\n      `Dataset.from_generator()`. In particular, using `from_generator` will\n      preclude the use of tf.data service for scaling out dataset processing.\n      The body of `generator` will not be serialized in a `GraphDef`, and you\n      should not use this method if you need to serialize your model and restore\n      it in a different environment.\n    \n      The `generator` argument must be a callable object that returns\n      an object that supports the `iter()` protocol (e.g. a generator function).\n    \n      The elements generated by `generator` must be compatible with either the\n      given `output_signature` argument or with the given `output_types` and\n      (optionally) `output_shapes` arguments, whichever was specified.\n    \n      The recommended way to call `from_generator` is to use the\n      `output_signature` argument. In this case the output will be assumed to\n      consist of objects with the classes, shapes and types defined by\n      `tf.TypeSpec` objects from `output_signature` argument:\n    \n      >>> def gen():\n      ...   ragged_tensor = tf.ragged.constant([[1, 2], [3]])\n      ...   yield 42, ragged_tensor\n      >>>\n      >>> dataset = tf.data.Dataset.from_generator(\n      ...      gen,\n      ...      output_signature=(\n      ...          tf.TensorSpec(shape=(), dtype=tf.int32),\n      ...          tf.RaggedTensorSpec(shape=(2, None), dtype=tf.int32)))\n      >>>\n      >>> list(dataset.take(1))\n      [(<tf.Tensor: shape=(), dtype=int32, numpy=42>,\n      <tf.RaggedTensor [[1, 2], [3]]>)]\n    \n      There is also a deprecated way to call `from_generator` by either with\n      `output_types` argument alone or together with `output_shapes` argument.\n      In this case the output of the function will be assumed to consist of\n      `tf.Tensor` objects with the types defined by `output_types` and with the\n      shapes which are either unknown or defined by `output_shapes`.\n    \n      Note: If `generator` depends on mutable global variables or other external\n      state, be aware that the runtime may invoke `generator` multiple times\n      (in order to support repeating the `Dataset`) and at any time\n      between the call to `Dataset.from_generator()` and the production of the\n      first element from the generator. Mutating global variables or external\n      state can cause undefined behavior, and we recommend that you explicitly\n      cache any external state in `generator` before calling\n      `Dataset.from_generator()`.\n    \n      Note: While the `output_signature` parameter makes it possible to yield\n      `Dataset` elements, the scope of `Dataset.from_generator()` should be\n      limited to logic that cannot be expressed through tf.data operations. Using\n      tf.data operations within the generator function is an anti-pattern and may\n      result in incremental memory growth.\n    \n      Args:\n        generator: A callable object that returns an object that supports the\n          `iter()` protocol. If `args` is not specified, `generator` must take no\n          arguments; otherwise it must take as many arguments as there are values in\n          `args`.\n        output_types: (Optional.) A (nested) structure of `tf.DType` objects\n          corresponding to each component of an element yielded by `generator`.\n        output_shapes: (Optional.) A (nested) structure of `tf.TensorShape` objects\n          corresponding to each component of an element yielded by `generator`.\n        args: (Optional.) A tuple of `tf.Tensor` objects that will be evaluated and\n          passed to `generator` as NumPy-array arguments.\n        output_signature: (Optional.) A (nested) structure of `tf.TypeSpec` objects\n          corresponding to each component of an element yielded by `generator`.\n        name: (Optional.) A name for the tf.data operations used by\n          `from_generator`.\n    \n      Returns:\n        Dataset: A `Dataset`.\n      \"\"\"\n      if not callable(generator):\n        raise TypeError(\"`generator` must be a Python callable.\")\n    \n      if output_signature is not None:\n        if output_types is not None:\n          raise TypeError(\"The `output_types` argument can not be used together \"\n                          \"with the `output_signature` argument.\")\n        if output_shapes is not None:\n          raise TypeError(\"The `output_shapes` argument can not be used together \"\n                          \"with the `output_signature` argument.\")\n        for spec in nest.flatten(output_signature):\n          if not isinstance(spec, type_spec.TypeSpec):\n>           raise TypeError(f\"`output_signature` must contain objects that are \"\n                            f\"subclass of `tf.TypeSpec` but found {type(spec)} \"\n                            f\"which is not.\")\nE           TypeError: `output_signature` must contain objects that are subclass of `tf.TypeSpec` but found <class 'list'> which is not.\n\n/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/from_generator_op.py:124: TypeError\n----------------------------- Captured stdout call -----------------------------\nNumber of clusters 10\n0 cluster has size 5\n1 cluster has size 5\n2 cluster has size 5\n3 cluster has size 5\n4 cluster has size 5\n5 cluster has size 5\n6 cluster has size 5\n7 cluster has size 5\n8 cluster has size 5\n9 cluster has size 5\n______________________ test_fullbatch_cluster_models[GAT] ______________________\n\nmodel_type = <class 'stellargraph.layer.graph_attention.GAT'>\n\n    @pytest.mark.parametrize(\"model_type\", [APPNP, GAT, GCN])\n    def test_fullbatch_cluster_models(model_type):\n        G = example_graph_random(n_nodes=50)\n        generator = ClusterNodeGenerator(G, clusters=10)\n        nodes = G.nodes()[:40]\n        gen = generator.flow(nodes, targets=np.ones(len(nodes)))\n    \n        gnn = model_type(\n            generator=generator,\n            layer_sizes=[16, 16, 1],\n            activations=[\"relu\", \"relu\", \"relu\"],\n        )\n    \n        model = tf.keras.Model(*gnn.in_out_tensors())\n        model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\")\n>       history = model.fit(gen, validation_data=gen, epochs=2)\n\ntests/layer/test_cluster_models.py:40: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py:122: in error_handler\n    raise e.with_traceback(filtered_tb) from None\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\ngenerator = <bound method PyDatasetAdapter._get_iterator of <keras.src.trainers.data_adapters.py_dataset_adapter.PyDatasetAdapter object at 0x7fc18c7d8fa0>>\noutput_types = None, output_shapes = None, args = None\noutput_signature = ([TensorSpec(shape=(None, 5, 4), dtype=tf.float32, name=None), TensorSpec(shape=(None, None), dtype=tf.int64, name=Non...sorSpec(shape=(None, 5, 5), dtype=tf.float32, name=None)], TensorSpec(shape=(None, None), dtype=tf.float64, name=None))\nname = None\n\n    def _from_generator(generator, output_types, output_shapes, args,\n                        output_signature, name):\n      \"\"\"Creates a `Dataset` whose elements are generated by `generator`.\n    \n      Note: The current implementation of `Dataset.from_generator()` uses\n      `tf.numpy_function` and inherits the same constraints. In particular, it\n      requires the dataset and iterator related operations to be placed\n      on a device in the same process as the Python program that called\n      `Dataset.from_generator()`. In particular, using `from_generator` will\n      preclude the use of tf.data service for scaling out dataset processing.\n      The body of `generator` will not be serialized in a `GraphDef`, and you\n      should not use this method if you need to serialize your model and restore\n      it in a different environment.\n    \n      The `generator` argument must be a callable object that returns\n      an object that supports the `iter()` protocol (e.g. a generator function).\n    \n      The elements generated by `generator` must be compatible with either the\n      given `output_signature` argument or with the given `output_types` and\n      (optionally) `output_shapes` arguments, whichever was specified.\n    \n      The recommended way to call `from_generator` is to use the\n      `output_signature` argument. In this case the output will be assumed to\n      consist of objects with the classes, shapes and types defined by\n      `tf.TypeSpec` objects from `output_signature` argument:\n    \n      >>> def gen():\n      ...   ragged_tensor = tf.ragged.constant([[1, 2], [3]])\n      ...   yield 42, ragged_tensor\n      >>>\n      >>> dataset = tf.data.Dataset.from_generator(\n      ...      gen,\n      ...      output_signature=(\n      ...          tf.TensorSpec(shape=(), dtype=tf.int32),\n      ...          tf.RaggedTensorSpec(shape=(2, None), dtype=tf.int32)))\n      >>>\n      >>> list(dataset.take(1))\n      [(<tf.Tensor: shape=(), dtype=int32, numpy=42>,\n      <tf.RaggedTensor [[1, 2], [3]]>)]\n    \n      There is also a deprecated way to call `from_generator` by either with\n      `output_types` argument alone or together with `output_shapes` argument.\n      In this case the output of the function will be assumed to consist of\n      `tf.Tensor` objects with the types defined by `output_types` and with the\n      shapes which are either unknown or defined by `output_shapes`.\n    \n      Note: If `generator` depends on mutable global variables or other external\n      state, be aware that the runtime may invoke `generator` multiple times\n      (in order to support repeating the `Dataset`) and at any time\n      between the call to `Dataset.from_generator()` and the production of the\n      first element from the generator. Mutating global variables or external\n      state can cause undefined behavior, and we recommend that you explicitly\n      cache any external state in `generator` before calling\n      `Dataset.from_generator()`.\n    \n      Note: While the `output_signature` parameter makes it possible to yield\n      `Dataset` elements, the scope of `Dataset.from_generator()` should be\n      limited to logic that cannot be expressed through tf.data operations. Using\n      tf.data operations within the generator function is an anti-pattern and may\n      result in incremental memory growth.\n    \n      Args:\n        generator: A callable object that returns an object that supports the\n          `iter()` protocol. If `args` is not specified, `generator` must take no\n          arguments; otherwise it must take as many arguments as there are values in\n          `args`.\n        output_types: (Optional.) A (nested) structure of `tf.DType` objects\n          corresponding to each component of an element yielded by `generator`.\n        output_shapes: (Optional.) A (nested) structure of `tf.TensorShape` objects\n          corresponding to each component of an element yielded by `generator`.\n        args: (Optional.) A tuple of `tf.Tensor` objects that will be evaluated and\n          passed to `generator` as NumPy-array arguments.\n        output_signature: (Optional.) A (nested) structure of `tf.TypeSpec` objects\n          corresponding to each component of an element yielded by `generator`.\n        name: (Optional.) A name for the tf.data operations used by\n          `from_generator`.\n    \n      Returns:\n        Dataset: A `Dataset`.\n      \"\"\"\n      if not callable(generator):\n        raise TypeError(\"`generator` must be a Python callable.\")\n    \n      if output_signature is not None:\n        if output_types is not None:\n          raise TypeError(\"The `output_types` argument can not be used together \"\n                          \"with the `output_signature` argument.\")\n        if output_shapes is not None:\n          raise TypeError(\"The `output_shapes` argument can not be used together \"\n                          \"with the `output_signature` argument.\")\n        for spec in nest.flatten(output_signature):\n          if not isinstance(spec, type_spec.TypeSpec):\n>           raise TypeError(f\"`output_signature` must contain objects that are \"\n                            f\"subclass of `tf.TypeSpec` but found {type(spec)} \"\n                            f\"which is not.\")\nE           TypeError: `output_signature` must contain objects that are subclass of `tf.TypeSpec` but found <class 'list'> which is not.\n\n/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/from_generator_op.py:124: TypeError\n----------------------------- Captured stdout call -----------------------------\nNumber of clusters 10\n0 cluster has size 5\n1 cluster has size 5\n2 cluster has size 5\n3 cluster has size 5\n4 cluster has size 5\n5 cluster has size 5\n6 cluster has size 5\n7 cluster has size 5\n8 cluster has size 5\n9 cluster has size 5\n______________________ test_fullbatch_cluster_models[GCN] ______________________\n\nmodel_type = <class 'stellargraph.layer.gcn.GCN'>\n\n    @pytest.mark.parametrize(\"model_type\", [APPNP, GAT, GCN])\n    def test_fullbatch_cluster_models(model_type):\n        G = example_graph_random(n_nodes=50)\n        generator = ClusterNodeGenerator(G, clusters=10)\n        nodes = G.nodes()[:40]\n        gen = generator.flow(nodes, targets=np.ones(len(nodes)))\n    \n        gnn = model_type(\n            generator=generator,\n            layer_sizes=[16, 16, 1],\n            activations=[\"relu\", \"relu\", \"relu\"],\n        )\n    \n        model = tf.keras.Model(*gnn.in_out_tensors())\n        model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\")\n>       history = model.fit(gen, validation_data=gen, epochs=2)\n\ntests/layer/test_cluster_models.py:40: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py:122: in error_handler\n    raise e.with_traceback(filtered_tb) from None\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\ngenerator = <bound method PyDatasetAdapter._get_iterator of <keras.src.trainers.data_adapters.py_dataset_adapter.PyDatasetAdapter object at 0x7fc1ac22c070>>\noutput_types = None, output_shapes = None, args = None\noutput_signature = ([TensorSpec(shape=(None, 5, 4), dtype=tf.float32, name=None), TensorSpec(shape=(None, 5), dtype=tf.int64, name=None), TensorSpec(shape=(None, 5, 5), dtype=tf.float32, name=None)], TensorSpec(shape=(None, 5), dtype=tf.float64, name=None))\nname = None\n\n    def _from_generator(generator, output_types, output_shapes, args,\n                        output_signature, name):\n      \"\"\"Creates a `Dataset` whose elements are generated by `generator`.\n    \n      Note: The current implementation of `Dataset.from_generator()` uses\n      `tf.numpy_function` and inherits the same constraints. In particular, it\n      requires the dataset and iterator related operations to be placed\n      on a device in the same process as the Python program that called\n      `Dataset.from_generator()`. In particular, using `from_generator` will\n      preclude the use of tf.data service for scaling out dataset processing.\n      The body of `generator` will not be serialized in a `GraphDef`, and you\n      should not use this method if you need to serialize your model and restore\n      it in a different environment.\n    \n      The `generator` argument must be a callable object that returns\n      an object that supports the `iter()` protocol (e.g. a generator function).\n    \n      The elements generated by `generator` must be compatible with either the\n      given `output_signature` argument or with the given `output_types` and\n      (optionally) `output_shapes` arguments, whichever was specified.\n    \n      The recommended way to call `from_generator` is to use the\n      `output_signature` argument. In this case the output will be assumed to\n      consist of objects with the classes, shapes and types defined by\n      `tf.TypeSpec` objects from `output_signature` argument:\n    \n      >>> def gen():\n      ...   ragged_tensor = tf.ragged.constant([[1, 2], [3]])\n      ...   yield 42, ragged_tensor\n      >>>\n      >>> dataset = tf.data.Dataset.from_generator(\n      ...      gen,\n      ...      output_signature=(\n      ...          tf.TensorSpec(shape=(), dtype=tf.int32),\n      ...          tf.RaggedTensorSpec(shape=(2, None), dtype=tf.int32)))\n      >>>\n      >>> list(dataset.take(1))\n      [(<tf.Tensor: shape=(), dtype=int32, numpy=42>,\n      <tf.RaggedTensor [[1, 2], [3]]>)]\n    \n      There is also a deprecated way to call `from_generator` by either with\n      `output_types` argument alone or together with `output_shapes` argument.\n      In this case the output of the function will be assumed to consist of\n      `tf.Tensor` objects with the types defined by `output_types` and with the\n      shapes which are either unknown or defined by `output_shapes`.\n    \n      Note: If `generator` depends on mutable global variables or other external\n      state, be aware that the runtime may invoke `generator` multiple times\n      (in order to support repeating the `Dataset`) and at any time\n      between the call to `Dataset.from_generator()` and the production of the\n      first element from the generator. Mutating global variables or external\n      state can cause undefined behavior, and we recommend that you explicitly\n      cache any external state in `generator` before calling\n      `Dataset.from_generator()`.\n    \n      Note: While the `output_signature` parameter makes it possible to yield\n      `Dataset` elements, the scope of `Dataset.from_generator()` should be\n      limited to logic that cannot be expressed through tf.data operations. Using\n      tf.data operations within the generator function is an anti-pattern and may\n      result in incremental memory growth.\n    \n      Args:\n        generator: A callable object that returns an object that supports the\n          `iter()` protocol. If `args` is not specified, `generator` must take no\n          arguments; otherwise it must take as many arguments as there are values in\n          `args`.\n        output_types: (Optional.) A (nested) structure of `tf.DType` objects\n          corresponding to each component of an element yielded by `generator`.\n        output_shapes: (Optional.) A (nested) structure of `tf.TensorShape` objects\n          corresponding to each component of an element yielded by `generator`.\n        args: (Optional.) A tuple of `tf.Tensor` objects that will be evaluated and\n          passed to `generator` as NumPy-array arguments.\n        output_signature: (Optional.) A (nested) structure of `tf.TypeSpec` objects\n          corresponding to each component of an element yielded by `generator`.\n        name: (Optional.) A name for the tf.data operations used by\n          `from_generator`.\n    \n      Returns:\n        Dataset: A `Dataset`.\n      \"\"\"\n      if not callable(generator):\n        raise TypeError(\"`generator` must be a Python callable.\")\n    \n      if output_signature is not None:\n        if output_types is not None:\n          raise TypeError(\"The `output_types` argument can not be used together \"\n                          \"with the `output_signature` argument.\")\n        if output_shapes is not None:\n          raise TypeError(\"The `output_shapes` argument can not be used together \"\n                          \"with the `output_signature` argument.\")\n        for spec in nest.flatten(output_signature):\n          if not isinstance(spec, type_spec.TypeSpec):\n>           raise TypeError(f\"`output_signature` must contain objects that are \"\n                            f\"subclass of `tf.TypeSpec` but found {type(spec)} \"\n                            f\"which is not.\")\nE           TypeError: `output_signature` must contain objects that are subclass of `tf.TypeSpec` but found <class 'list'> which is not.\n\n/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/from_generator_op.py:124: TypeError\n----------------------------- Captured stdout call -----------------------------\nNumber of clusters 10\n0 cluster has size 5\n1 cluster has size 5\n2 cluster has size 5\n3 cluster has size 5\n4 cluster has size 5\n5 cluster has size 5\n6 cluster has size 5\n7 cluster has size 5\n8 cluster has size 5\n9 cluster has size 5\n_____________________________ test_dgi[False-GCN] ______________________________\n\nmodel_type = <class 'stellargraph.layer.gcn.GCN'>, sparse = False\n\n    @pytest.mark.parametrize(\n        \"model_type\", [GCN, APPNP, GAT, PPNP, GraphSAGE, DirectedGraphSAGE, HinSAGE, RGCN]\n    )\n    @pytest.mark.parametrize(\"sparse\", [False, True])\n    def test_dgi(model_type, sparse):\n        base_generator, base_model, nodes = _model_data(model_type, sparse)\n        corrupted_generator = CorruptedGenerator(base_generator)\n        gen = corrupted_generator.flow(nodes)\n    \n        infomax = DeepGraphInfomax(base_model, corrupted_generator)\n    \n>       model = tf.keras.Model(*infomax.in_out_tensors())\n\ntests/layer/test_deep_graph_infomax.py:86: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/layer/deep_graph_infomax.py:192: in in_out_tensors\n    x_out = tf.stack([scores, scores_corrupted], axis=-1)\n/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py:153: in error_handler\n    raise e.with_traceback(filtered_tb) from None\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <KerasTensor shape=(1, None), dtype=float32, sparse=False, ragged=False, name=keras_tensor_565>\ndtype = None, name = 'stack'\n\n    def __tf_tensor__(self, dtype=None, name=None):\n>       raise ValueError(\n            \"A KerasTensor cannot be used as input to a TensorFlow function. \"\n            \"A KerasTensor is a symbolic placeholder for a shape and dtype, \"\n            \"used when constructing Keras Functional models \"\n            \"or Keras Functions. You can only use it as input to a Keras layer \"\n            \"or a Keras operation (from the namespaces `keras.layers` \"\n            \"and `keras.ops`). \"\n            \"You are likely doing something like:\\n\\n\"\n            \"```\\n\"\n            \"x = Input(...)\\n\"\n            \"...\\n\"\n            \"tf_fn(x)  # Invalid.\\n\"\n            \"```\\n\\n\"\n            \"What you should do instead is wrap `tf_fn` in a layer:\\n\\n\"\n            \"```\\n\"\n            \"class MyLayer(Layer):\\n\"\n            \"    def call(self, x):\\n\"\n            \"        return tf_fn(x)\\n\\n\"\n            \"x = MyLayer()(x)\\n\"\n            \"```\\n\"\n        )\nE       ValueError: A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.ops`). You are likely doing something like:\nE       \nE       ```\nE       x = Input(...)\nE       ...\nE       tf_fn(x)  # Invalid.\nE       ```\nE       \nE       What you should do instead is wrap `tf_fn` in a layer:\nE       \nE       ```\nE       class MyLayer(Layer):\nE           def call(self, x):\nE               return tf_fn(x)\nE       \nE       x = MyLayer()(x)\nE       ```\n\n/usr/local/lib/python3.10/dist-packages/keras/src/backend/common/keras_tensor.py:194: ValueError\n----------------------------- Captured stdout call -----------------------------\nUsing GCN (local pooling) filters...\n____________________________ test_dgi[False-APPNP] _____________________________\n\nmodel_type = <class 'stellargraph.layer.appnp.APPNP'>, sparse = False\n\n    @pytest.mark.parametrize(\n        \"model_type\", [GCN, APPNP, GAT, PPNP, GraphSAGE, DirectedGraphSAGE, HinSAGE, RGCN]\n    )\n    @pytest.mark.parametrize(\"sparse\", [False, True])\n    def test_dgi(model_type, sparse):\n        base_generator, base_model, nodes = _model_data(model_type, sparse)\n        corrupted_generator = CorruptedGenerator(base_generator)\n        gen = corrupted_generator.flow(nodes)\n    \n        infomax = DeepGraphInfomax(base_model, corrupted_generator)\n    \n>       model = tf.keras.Model(*infomax.in_out_tensors())\n\ntests/layer/test_deep_graph_infomax.py:86: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/layer/deep_graph_infomax.py:192: in in_out_tensors\n    x_out = tf.stack([scores, scores_corrupted], axis=-1)\n/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py:153: in error_handler\n    raise e.with_traceback(filtered_tb) from None\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <KerasTensor shape=(1, None), dtype=float32, sparse=False, ragged=False, name=keras_tensor_621>\ndtype = None, name = 'stack'\n\n    def __tf_tensor__(self, dtype=None, name=None):\n>       raise ValueError(\n            \"A KerasTensor cannot be used as input to a TensorFlow function. \"\n            \"A KerasTensor is a symbolic placeholder for a shape and dtype, \"\n            \"used when constructing Keras Functional models \"\n            \"or Keras Functions. You can only use it as input to a Keras layer \"\n            \"or a Keras operation (from the namespaces `keras.layers` \"\n            \"and `keras.ops`). \"\n            \"You are likely doing something like:\\n\\n\"\n            \"```\\n\"\n            \"x = Input(...)\\n\"\n            \"...\\n\"\n            \"tf_fn(x)  # Invalid.\\n\"\n            \"```\\n\\n\"\n            \"What you should do instead is wrap `tf_fn` in a layer:\\n\\n\"\n            \"```\\n\"\n            \"class MyLayer(Layer):\\n\"\n            \"    def call(self, x):\\n\"\n            \"        return tf_fn(x)\\n\\n\"\n            \"x = MyLayer()(x)\\n\"\n            \"```\\n\"\n        )\nE       ValueError: A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.ops`). You are likely doing something like:\nE       \nE       ```\nE       x = Input(...)\nE       ...\nE       tf_fn(x)  # Invalid.\nE       ```\nE       \nE       What you should do instead is wrap `tf_fn` in a layer:\nE       \nE       ```\nE       class MyLayer(Layer):\nE           def call(self, x):\nE               return tf_fn(x)\nE       \nE       x = MyLayer()(x)\nE       ```\n\n/usr/local/lib/python3.10/dist-packages/keras/src/backend/common/keras_tensor.py:194: ValueError\n----------------------------- Captured stdout call -----------------------------\nUsing GCN (local pooling) filters...\n_____________________________ test_dgi[False-GAT] ______________________________\n\nmodel_type = <class 'stellargraph.layer.graph_attention.GAT'>, sparse = False\n\n    @pytest.mark.parametrize(\n        \"model_type\", [GCN, APPNP, GAT, PPNP, GraphSAGE, DirectedGraphSAGE, HinSAGE, RGCN]\n    )\n    @pytest.mark.parametrize(\"sparse\", [False, True])\n    def test_dgi(model_type, sparse):\n        base_generator, base_model, nodes = _model_data(model_type, sparse)\n        corrupted_generator = CorruptedGenerator(base_generator)\n        gen = corrupted_generator.flow(nodes)\n    \n        infomax = DeepGraphInfomax(base_model, corrupted_generator)\n    \n>       model = tf.keras.Model(*infomax.in_out_tensors())\n\ntests/layer/test_deep_graph_infomax.py:86: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/layer/deep_graph_infomax.py:192: in in_out_tensors\n    x_out = tf.stack([scores, scores_corrupted], axis=-1)\n/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py:153: in error_handler\n    raise e.with_traceback(filtered_tb) from None\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <KerasTensor shape=(1, None), dtype=float32, sparse=False, ragged=False, name=keras_tensor_643>\ndtype = None, name = 'stack'\n\n    def __tf_tensor__(self, dtype=None, name=None):\n>       raise ValueError(\n            \"A KerasTensor cannot be used as input to a TensorFlow function. \"\n            \"A KerasTensor is a symbolic placeholder for a shape and dtype, \"\n            \"used when constructing Keras Functional models \"\n            \"or Keras Functions. You can only use it as input to a Keras layer \"\n            \"or a Keras operation (from the namespaces `keras.layers` \"\n            \"and `keras.ops`). \"\n            \"You are likely doing something like:\\n\\n\"\n            \"```\\n\"\n            \"x = Input(...)\\n\"\n            \"...\\n\"\n            \"tf_fn(x)  # Invalid.\\n\"\n            \"```\\n\\n\"\n            \"What you should do instead is wrap `tf_fn` in a layer:\\n\\n\"\n            \"```\\n\"\n            \"class MyLayer(Layer):\\n\"\n            \"    def call(self, x):\\n\"\n            \"        return tf_fn(x)\\n\\n\"\n            \"x = MyLayer()(x)\\n\"\n            \"```\\n\"\n        )\nE       ValueError: A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.ops`). You are likely doing something like:\nE       \nE       ```\nE       x = Input(...)\nE       ...\nE       tf_fn(x)  # Invalid.\nE       ```\nE       \nE       What you should do instead is wrap `tf_fn` in a layer:\nE       \nE       ```\nE       class MyLayer(Layer):\nE           def call(self, x):\nE               return tf_fn(x)\nE       \nE       x = MyLayer()(x)\nE       ```\n\n/usr/local/lib/python3.10/dist-packages/keras/src/backend/common/keras_tensor.py:194: ValueError\n----------------------------- Captured stdout call -----------------------------\nUsing GCN (local pooling) filters...\n_____________________________ test_dgi[False-PPNP] _____________________________\n\nmodel_type = <class 'stellargraph.layer.ppnp.PPNP'>, sparse = False\n\n    @pytest.mark.parametrize(\n        \"model_type\", [GCN, APPNP, GAT, PPNP, GraphSAGE, DirectedGraphSAGE, HinSAGE, RGCN]\n    )\n    @pytest.mark.parametrize(\"sparse\", [False, True])\n    def test_dgi(model_type, sparse):\n        base_generator, base_model, nodes = _model_data(model_type, sparse)\n        corrupted_generator = CorruptedGenerator(base_generator)\n        gen = corrupted_generator.flow(nodes)\n    \n        infomax = DeepGraphInfomax(base_model, corrupted_generator)\n    \n>       model = tf.keras.Model(*infomax.in_out_tensors())\n\ntests/layer/test_deep_graph_infomax.py:86: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/layer/deep_graph_infomax.py:192: in in_out_tensors\n    x_out = tf.stack([scores, scores_corrupted], axis=-1)\n/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py:153: in error_handler\n    raise e.with_traceback(filtered_tb) from None\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <KerasTensor shape=(1, None), dtype=float32, sparse=False, ragged=False, name=keras_tensor_669>\ndtype = None, name = 'stack'\n\n    def __tf_tensor__(self, dtype=None, name=None):\n>       raise ValueError(\n            \"A KerasTensor cannot be used as input to a TensorFlow function. \"\n            \"A KerasTensor is a symbolic placeholder for a shape and dtype, \"\n            \"used when constructing Keras Functional models \"\n            \"or Keras Functions. You can only use it as input to a Keras layer \"\n            \"or a Keras operation (from the namespaces `keras.layers` \"\n            \"and `keras.ops`). \"\n            \"You are likely doing something like:\\n\\n\"\n            \"```\\n\"\n            \"x = Input(...)\\n\"\n            \"...\\n\"\n            \"tf_fn(x)  # Invalid.\\n\"\n            \"```\\n\\n\"\n            \"What you should do instead is wrap `tf_fn` in a layer:\\n\\n\"\n            \"```\\n\"\n            \"class MyLayer(Layer):\\n\"\n            \"    def call(self, x):\\n\"\n            \"        return tf_fn(x)\\n\\n\"\n            \"x = MyLayer()(x)\\n\"\n            \"```\\n\"\n        )\nE       ValueError: A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.ops`). You are likely doing something like:\nE       \nE       ```\nE       x = Input(...)\nE       ...\nE       tf_fn(x)  # Invalid.\nE       ```\nE       \nE       What you should do instead is wrap `tf_fn` in a layer:\nE       \nE       ```\nE       class MyLayer(Layer):\nE           def call(self, x):\nE               return tf_fn(x)\nE       \nE       x = MyLayer()(x)\nE       ```\n\n/usr/local/lib/python3.10/dist-packages/keras/src/backend/common/keras_tensor.py:194: ValueError\n----------------------------- Captured stdout call -----------------------------\nUsing GCN (local pooling) filters...\n__________________________ test_dgi[False-GraphSAGE] ___________________________\n\nmodel_type = <class 'stellargraph.layer.graphsage.GraphSAGE'>, sparse = False\n\n    @pytest.mark.parametrize(\n        \"model_type\", [GCN, APPNP, GAT, PPNP, GraphSAGE, DirectedGraphSAGE, HinSAGE, RGCN]\n    )\n    @pytest.mark.parametrize(\"sparse\", [False, True])\n    def test_dgi(model_type, sparse):\n>       base_generator, base_model, nodes = _model_data(model_type, sparse)\n\ntests/layer/test_deep_graph_infomax.py:80: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ntests/layer/test_deep_graph_infomax.py:44: in _model_data\n    model = GraphSAGE(generator=generator, layer_sizes=[4, emb_dim])\nstellargraph/layer/graphsage.py:866: in __init__\n    self._compute_neighbourhood_sizes()\nstellargraph/layer/graphsage.py:951: in _compute_neighbourhood_sizes\n    self.neighbourhood_sizes = [size_at(i) for i in range(self.max_hops + 1)]\nstellargraph/layer/graphsage.py:951: in <listcomp>\n    self.neighbourhood_sizes = [size_at(i) for i in range(self.max_hops + 1)]\nstellargraph/layer/graphsage.py:949: in size_at\n    return np.product(self.n_samples[:i], dtype=int)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'product'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n            raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\n    \n        if attr == \"chararray\":\n            warnings.warn(\n                \"`np.chararray` is deprecated and will be removed from \"\n                \"the main namespace in the future. Use an array with a string \"\n                \"or bytes dtype instead.\", DeprecationWarning, stacklevel=2)\n            import numpy.char as char\n            return char.chararray\n    \n>       raise AttributeError(\"module {!r} has no attribute \"\n                             \"{!r}\".format(__name__, attr))\nE       AttributeError: module 'numpy' has no attribute 'product'\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:414: AttributeError\n______________________ test_dgi[False-DirectedGraphSAGE] _______________________\n\nmodel_type = <class 'stellargraph.layer.graphsage.DirectedGraphSAGE'>\nsparse = False\n\n    @pytest.mark.parametrize(\n        \"model_type\", [GCN, APPNP, GAT, PPNP, GraphSAGE, DirectedGraphSAGE, HinSAGE, RGCN]\n    )\n    @pytest.mark.parametrize(\"sparse\", [False, True])\n    def test_dgi(model_type, sparse):\n>       base_generator, base_model, nodes = _model_data(model_type, sparse)\n\ntests/layer/test_deep_graph_infomax.py:80: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ntests/layer/test_deep_graph_infomax.py:51: in _model_data\n    model = DirectedGraphSAGE(generator=generator, layer_sizes=[4, emb_dim])\nstellargraph/layer/graphsage.py:866: in __init__\n    self._compute_neighbourhood_sizes()\nstellargraph/layer/graphsage.py:1243: in _compute_neighbourhood_sizes\n    self.neighbourhood_sizes = [1] + [\nstellargraph/layer/graphsage.py:1244: in <listcomp>\n    np.product(\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'product'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n            raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\n    \n        if attr == \"chararray\":\n            warnings.warn(\n                \"`np.chararray` is deprecated and will be removed from \"\n                \"the main namespace in the future. Use an array with a string \"\n                \"or bytes dtype instead.\", DeprecationWarning, stacklevel=2)\n            import numpy.char as char\n            return char.chararray\n    \n>       raise AttributeError(\"module {!r} has no attribute \"\n                             \"{!r}\".format(__name__, attr))\nE       AttributeError: module 'numpy' has no attribute 'product'\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:414: AttributeError\n___________________________ test_dgi[False-HinSAGE] ____________________________\n\nmodel_type = <class 'stellargraph.layer.hinsage.HinSAGE'>, sparse = False\n\n    @pytest.mark.parametrize(\n        \"model_type\", [GCN, APPNP, GAT, PPNP, GraphSAGE, DirectedGraphSAGE, HinSAGE, RGCN]\n    )\n    @pytest.mark.parametrize(\"sparse\", [False, True])\n    def test_dgi(model_type, sparse):\n        base_generator, base_model, nodes = _model_data(model_type, sparse)\n        corrupted_generator = CorruptedGenerator(base_generator)\n        gen = corrupted_generator.flow(nodes)\n    \n        infomax = DeepGraphInfomax(base_model, corrupted_generator)\n    \n>       model = tf.keras.Model(*infomax.in_out_tensors())\n\ntests/layer/test_deep_graph_infomax.py:86: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/layer/deep_graph_infomax.py:192: in in_out_tensors\n    x_out = tf.stack([scores, scores_corrupted], axis=-1)\n/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py:153: in error_handler\n    raise e.with_traceback(filtered_tb) from None\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <KerasTensor shape=(None,), dtype=float32, sparse=False, ragged=False, name=keras_tensor_842>\ndtype = None, name = 'stack'\n\n    def __tf_tensor__(self, dtype=None, name=None):\n>       raise ValueError(\n            \"A KerasTensor cannot be used as input to a TensorFlow function. \"\n            \"A KerasTensor is a symbolic placeholder for a shape and dtype, \"\n            \"used when constructing Keras Functional models \"\n            \"or Keras Functions. You can only use it as input to a Keras layer \"\n            \"or a Keras operation (from the namespaces `keras.layers` \"\n            \"and `keras.ops`). \"\n            \"You are likely doing something like:\\n\\n\"\n            \"```\\n\"\n            \"x = Input(...)\\n\"\n            \"...\\n\"\n            \"tf_fn(x)  # Invalid.\\n\"\n            \"```\\n\\n\"\n            \"What you should do instead is wrap `tf_fn` in a layer:\\n\\n\"\n            \"```\\n\"\n            \"class MyLayer(Layer):\\n\"\n            \"    def call(self, x):\\n\"\n            \"        return tf_fn(x)\\n\\n\"\n            \"x = MyLayer()(x)\\n\"\n            \"```\\n\"\n        )\nE       ValueError: A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.ops`). You are likely doing something like:\nE       \nE       ```\nE       x = Input(...)\nE       ...\nE       tf_fn(x)  # Invalid.\nE       ```\nE       \nE       What you should do instead is wrap `tf_fn` in a layer:\nE       \nE       ```\nE       class MyLayer(Layer):\nE           def call(self, x):\nE               return tf_fn(x)\nE       \nE       x = MyLayer()(x)\nE       ```\n\n/usr/local/lib/python3.10/dist-packages/keras/src/backend/common/keras_tensor.py:194: ValueError\n_____________________________ test_dgi[False-RGCN] _____________________________\n\nmodel_type = <class 'stellargraph.layer.rgcn.RGCN'>, sparse = False\n\n    @pytest.mark.parametrize(\n        \"model_type\", [GCN, APPNP, GAT, PPNP, GraphSAGE, DirectedGraphSAGE, HinSAGE, RGCN]\n    )\n    @pytest.mark.parametrize(\"sparse\", [False, True])\n    def test_dgi(model_type, sparse):\n        base_generator, base_model, nodes = _model_data(model_type, sparse)\n        corrupted_generator = CorruptedGenerator(base_generator)\n        gen = corrupted_generator.flow(nodes)\n    \n        infomax = DeepGraphInfomax(base_model, corrupted_generator)\n    \n>       model = tf.keras.Model(*infomax.in_out_tensors())\n\ntests/layer/test_deep_graph_infomax.py:86: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/layer/deep_graph_infomax.py:174: in in_out_tensors\n    x_inp, node_feats = self.base_model.in_out_tensors()\nstellargraph/layer/rgcn.py:581: in in_out_tensors\n    return self._node_model()\nstellargraph/layer/rgcn.py:557: in _node_model\n    x_out = self(x_inp)\nstellargraph/layer/rgcn.py:512: in __call__\n    h_layer = layer([h_layer] + Ainput)\n/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py:122: in error_handler\n    raise e.with_traceback(filtered_tb) from None\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <RelationalGraphConvolution name=relational_graph_convolution_1, built=True>\ninput_shapes = [(1, 6, 10), (6, 6), (6, 6), (6, 6)]\n\n    def compute_output_shape(self, input_shapes):\n        \"\"\"\n        Computes the output shape of the layer.\n    \n        Args:\n            input_shapes (tuple of int)\n                Shape tuples can include None for free dimensions, instead of an integer.\n    \n        Returns:\n            An input shape tuple.\n        \"\"\"\n>       feature_shape, A_shape = input_shapes\nE       ValueError: Exception encountered when calling RelationalGraphConvolution.call().\nE       \nE       \u001b[1mtoo many values to unpack (expected 2)\u001b[0m\nE       \nE       Arguments received by RelationalGraphConvolution.call():\nE          args=(['<KerasTensor shape=(1, 6, 10), dtype=float32, sparse=False, ragged=False, name=keras_tensor_858>', '<KerasTensor shape=(6, 6), dtype=float32, sparse=False, ragged=False, name=keras_tensor_851>', '<KerasTensor shape=(6, 6), dtype=float32, sparse=False, ragged=False, name=keras_tensor_854>', '<KerasTensor shape=(6, 6), dtype=float32, sparse=False, ragged=False, name=keras_tensor_857>'],)\nE          kwargs=<class 'inspect._empty'>\n\nstellargraph/layer/rgcn.py:184: ValueError\n______________________________ test_dgi[True-GCN] ______________________________\n\nmodel_type = <class 'stellargraph.layer.gcn.GCN'>, sparse = True\n\n    @pytest.mark.parametrize(\n        \"model_type\", [GCN, APPNP, GAT, PPNP, GraphSAGE, DirectedGraphSAGE, HinSAGE, RGCN]\n    )\n    @pytest.mark.parametrize(\"sparse\", [False, True])\n    def test_dgi(model_type, sparse):\n        base_generator, base_model, nodes = _model_data(model_type, sparse)\n        corrupted_generator = CorruptedGenerator(base_generator)\n        gen = corrupted_generator.flow(nodes)\n    \n        infomax = DeepGraphInfomax(base_model, corrupted_generator)\n    \n>       model = tf.keras.Model(*infomax.in_out_tensors())\n\ntests/layer/test_deep_graph_infomax.py:86: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/layer/deep_graph_infomax.py:192: in in_out_tensors\n    x_out = tf.stack([scores, scores_corrupted], axis=-1)\n/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py:153: in error_handler\n    raise e.with_traceback(filtered_tb) from None\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <KerasTensor shape=(1, None), dtype=float32, sparse=False, ragged=False, name=keras_tensor_876>\ndtype = None, name = 'stack'\n\n    def __tf_tensor__(self, dtype=None, name=None):\n>       raise ValueError(\n            \"A KerasTensor cannot be used as input to a TensorFlow function. \"\n            \"A KerasTensor is a symbolic placeholder for a shape and dtype, \"\n            \"used when constructing Keras Functional models \"\n            \"or Keras Functions. You can only use it as input to a Keras layer \"\n            \"or a Keras operation (from the namespaces `keras.layers` \"\n            \"and `keras.ops`). \"\n            \"You are likely doing something like:\\n\\n\"\n            \"```\\n\"\n            \"x = Input(...)\\n\"\n            \"...\\n\"\n            \"tf_fn(x)  # Invalid.\\n\"\n            \"```\\n\\n\"\n            \"What you should do instead is wrap `tf_fn` in a layer:\\n\\n\"\n            \"```\\n\"\n            \"class MyLayer(Layer):\\n\"\n            \"    def call(self, x):\\n\"\n            \"        return tf_fn(x)\\n\\n\"\n            \"x = MyLayer()(x)\\n\"\n            \"```\\n\"\n        )\nE       ValueError: A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.ops`). You are likely doing something like:\nE       \nE       ```\nE       x = Input(...)\nE       ...\nE       tf_fn(x)  # Invalid.\nE       ```\nE       \nE       What you should do instead is wrap `tf_fn` in a layer:\nE       \nE       ```\nE       class MyLayer(Layer):\nE           def call(self, x):\nE               return tf_fn(x)\nE       \nE       x = MyLayer()(x)\nE       ```\n\n/usr/local/lib/python3.10/dist-packages/keras/src/backend/common/keras_tensor.py:194: ValueError\n----------------------------- Captured stdout call -----------------------------\nUsing GCN (local pooling) filters...\n_____________________________ test_dgi[True-APPNP] _____________________________\n\nmodel_type = <class 'stellargraph.layer.appnp.APPNP'>, sparse = True\n\n    @pytest.mark.parametrize(\n        \"model_type\", [GCN, APPNP, GAT, PPNP, GraphSAGE, DirectedGraphSAGE, HinSAGE, RGCN]\n    )\n    @pytest.mark.parametrize(\"sparse\", [False, True])\n    def test_dgi(model_type, sparse):\n        base_generator, base_model, nodes = _model_data(model_type, sparse)\n        corrupted_generator = CorruptedGenerator(base_generator)\n        gen = corrupted_generator.flow(nodes)\n    \n        infomax = DeepGraphInfomax(base_model, corrupted_generator)\n    \n>       model = tf.keras.Model(*infomax.in_out_tensors())\n\ntests/layer/test_deep_graph_infomax.py:86: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/layer/deep_graph_infomax.py:192: in in_out_tensors\n    x_out = tf.stack([scores, scores_corrupted], axis=-1)\n/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py:153: in error_handler\n    raise e.with_traceback(filtered_tb) from None\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <KerasTensor shape=(1, None), dtype=float32, sparse=False, ragged=False, name=keras_tensor_935>\ndtype = None, name = 'stack'\n\n    def __tf_tensor__(self, dtype=None, name=None):\n>       raise ValueError(\n            \"A KerasTensor cannot be used as input to a TensorFlow function. \"\n            \"A KerasTensor is a symbolic placeholder for a shape and dtype, \"\n            \"used when constructing Keras Functional models \"\n            \"or Keras Functions. You can only use it as input to a Keras layer \"\n            \"or a Keras operation (from the namespaces `keras.layers` \"\n            \"and `keras.ops`). \"\n            \"You are likely doing something like:\\n\\n\"\n            \"```\\n\"\n            \"x = Input(...)\\n\"\n            \"...\\n\"\n            \"tf_fn(x)  # Invalid.\\n\"\n            \"```\\n\\n\"\n            \"What you should do instead is wrap `tf_fn` in a layer:\\n\\n\"\n            \"```\\n\"\n            \"class MyLayer(Layer):\\n\"\n            \"    def call(self, x):\\n\"\n            \"        return tf_fn(x)\\n\\n\"\n            \"x = MyLayer()(x)\\n\"\n            \"```\\n\"\n        )\nE       ValueError: A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.ops`). You are likely doing something like:\nE       \nE       ```\nE       x = Input(...)\nE       ...\nE       tf_fn(x)  # Invalid.\nE       ```\nE       \nE       What you should do instead is wrap `tf_fn` in a layer:\nE       \nE       ```\nE       class MyLayer(Layer):\nE           def call(self, x):\nE               return tf_fn(x)\nE       \nE       x = MyLayer()(x)\nE       ```\n\n/usr/local/lib/python3.10/dist-packages/keras/src/backend/common/keras_tensor.py:194: ValueError\n----------------------------- Captured stdout call -----------------------------\nUsing GCN (local pooling) filters...\n______________________________ test_dgi[True-GAT] ______________________________\n\nmodel_type = <class 'stellargraph.layer.graph_attention.GAT'>, sparse = True\n\n    @pytest.mark.parametrize(\n        \"model_type\", [GCN, APPNP, GAT, PPNP, GraphSAGE, DirectedGraphSAGE, HinSAGE, RGCN]\n    )\n    @pytest.mark.parametrize(\"sparse\", [False, True])\n    def test_dgi(model_type, sparse):\n        base_generator, base_model, nodes = _model_data(model_type, sparse)\n        corrupted_generator = CorruptedGenerator(base_generator)\n        gen = corrupted_generator.flow(nodes)\n    \n        infomax = DeepGraphInfomax(base_model, corrupted_generator)\n    \n>       model = tf.keras.Model(*infomax.in_out_tensors())\n\ntests/layer/test_deep_graph_infomax.py:86: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/layer/deep_graph_infomax.py:192: in in_out_tensors\n    x_out = tf.stack([scores, scores_corrupted], axis=-1)\n/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py:153: in error_handler\n    raise e.with_traceback(filtered_tb) from None\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <KerasTensor shape=(1, None), dtype=float32, sparse=False, ragged=False, name=keras_tensor_960>\ndtype = None, name = 'stack'\n\n    def __tf_tensor__(self, dtype=None, name=None):\n>       raise ValueError(\n            \"A KerasTensor cannot be used as input to a TensorFlow function. \"\n            \"A KerasTensor is a symbolic placeholder for a shape and dtype, \"\n            \"used when constructing Keras Functional models \"\n            \"or Keras Functions. You can only use it as input to a Keras layer \"\n            \"or a Keras operation (from the namespaces `keras.layers` \"\n            \"and `keras.ops`). \"\n            \"You are likely doing something like:\\n\\n\"\n            \"```\\n\"\n            \"x = Input(...)\\n\"\n            \"...\\n\"\n            \"tf_fn(x)  # Invalid.\\n\"\n            \"```\\n\\n\"\n            \"What you should do instead is wrap `tf_fn` in a layer:\\n\\n\"\n            \"```\\n\"\n            \"class MyLayer(Layer):\\n\"\n            \"    def call(self, x):\\n\"\n            \"        return tf_fn(x)\\n\\n\"\n            \"x = MyLayer()(x)\\n\"\n            \"```\\n\"\n        )\nE       ValueError: A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.ops`). You are likely doing something like:\nE       \nE       ```\nE       x = Input(...)\nE       ...\nE       tf_fn(x)  # Invalid.\nE       ```\nE       \nE       What you should do instead is wrap `tf_fn` in a layer:\nE       \nE       ```\nE       class MyLayer(Layer):\nE           def call(self, x):\nE               return tf_fn(x)\nE       \nE       x = MyLayer()(x)\nE       ```\n\n/usr/local/lib/python3.10/dist-packages/keras/src/backend/common/keras_tensor.py:194: ValueError\n----------------------------- Captured stdout call -----------------------------\nUsing GCN (local pooling) filters...\n_____________________________ test_dgi[True-RGCN] ______________________________\n\nmodel_type = <class 'stellargraph.layer.rgcn.RGCN'>, sparse = True\n\n    @pytest.mark.parametrize(\n        \"model_type\", [GCN, APPNP, GAT, PPNP, GraphSAGE, DirectedGraphSAGE, HinSAGE, RGCN]\n    )\n    @pytest.mark.parametrize(\"sparse\", [False, True])\n    def test_dgi(model_type, sparse):\n        base_generator, base_model, nodes = _model_data(model_type, sparse)\n        corrupted_generator = CorruptedGenerator(base_generator)\n        gen = corrupted_generator.flow(nodes)\n    \n        infomax = DeepGraphInfomax(base_model, corrupted_generator)\n    \n>       model = tf.keras.Model(*infomax.in_out_tensors())\n\ntests/layer/test_deep_graph_infomax.py:86: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/layer/deep_graph_infomax.py:174: in in_out_tensors\n    x_inp, node_feats = self.base_model.in_out_tensors()\nstellargraph/layer/rgcn.py:581: in in_out_tensors\n    return self._node_model()\nstellargraph/layer/rgcn.py:557: in _node_model\n    x_out = self(x_inp)\nstellargraph/layer/rgcn.py:512: in __call__\n    h_layer = layer([h_layer] + Ainput)\n/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py:122: in error_handler\n    raise e.with_traceback(filtered_tb) from None\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <RelationalGraphConvolution name=relational_graph_convolution_5, built=True>\ninput_shapes = [(1, 6, 10), (6, 6), (6, 6), (6, 6)]\n\n    def compute_output_shape(self, input_shapes):\n        \"\"\"\n        Computes the output shape of the layer.\n    \n        Args:\n            input_shapes (tuple of int)\n                Shape tuples can include None for free dimensions, instead of an integer.\n    \n        Returns:\n            An input shape tuple.\n        \"\"\"\n>       feature_shape, A_shape = input_shapes\nE       ValueError: Exception encountered when calling RelationalGraphConvolution.call().\nE       \nE       \u001b[1mtoo many values to unpack (expected 2)\u001b[0m\nE       \nE       Arguments received by RelationalGraphConvolution.call():\nE          args=(['<KerasTensor shape=(1, 6, 10), dtype=float32, sparse=False, ragged=False, name=keras_tensor_973>', '<KerasTensor shape=(6, 6), dtype=float32, sparse=False, ragged=False, name=keras_tensor_970>', '<KerasTensor shape=(6, 6), dtype=float32, sparse=False, ragged=False, name=keras_tensor_971>', '<KerasTensor shape=(6, 6), dtype=float32, sparse=False, ragged=False, name=keras_tensor_972>'],)\nE          kwargs=<class 'inspect._empty'>\n\nstellargraph/layer/rgcn.py:184: ValueError\n______________________________ test_dgi_stateful _______________________________\n\n    @pytest.mark.skipif(require_gpu, reason=\"tf on GPU is non-deterministic\")\n    def test_dgi_stateful():\n        G = example_graph_random()\n        emb_dim = 16\n    \n        generator = FullBatchNodeGenerator(G)\n        corrupted_generator = CorruptedGenerator(generator)\n        gen = corrupted_generator.flow(G.nodes())\n    \n        infomax = DeepGraphInfomax(\n            GCN(generator=generator, activations=[\"relu\"], layer_sizes=[emb_dim]),\n            corrupted_generator,\n        )\n    \n>       model_1 = tf.keras.Model(*infomax.in_out_tensors())\n\ntests/layer/test_deep_graph_infomax.py:115: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/layer/deep_graph_infomax.py:192: in in_out_tensors\n    x_out = tf.stack([scores, scores_corrupted], axis=-1)\n/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py:153: in error_handler\n    raise e.with_traceback(filtered_tb) from None\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <KerasTensor shape=(1, None), dtype=float32, sparse=False, ragged=False, name=keras_tensor_991>\ndtype = None, name = 'stack'\n\n    def __tf_tensor__(self, dtype=None, name=None):\n>       raise ValueError(\n            \"A KerasTensor cannot be used as input to a TensorFlow function. \"\n            \"A KerasTensor is a symbolic placeholder for a shape and dtype, \"\n            \"used when constructing Keras Functional models \"\n            \"or Keras Functions. You can only use it as input to a Keras layer \"\n            \"or a Keras operation (from the namespaces `keras.layers` \"\n            \"and `keras.ops`). \"\n            \"You are likely doing something like:\\n\\n\"\n            \"```\\n\"\n            \"x = Input(...)\\n\"\n            \"...\\n\"\n            \"tf_fn(x)  # Invalid.\\n\"\n            \"```\\n\\n\"\n            \"What you should do instead is wrap `tf_fn` in a layer:\\n\\n\"\n            \"```\\n\"\n            \"class MyLayer(Layer):\\n\"\n            \"    def call(self, x):\\n\"\n            \"        return tf_fn(x)\\n\\n\"\n            \"x = MyLayer()(x)\\n\"\n            \"```\\n\"\n        )\nE       ValueError: A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.ops`). You are likely doing something like:\nE       \nE       ```\nE       x = Input(...)\nE       ...\nE       tf_fn(x)  # Invalid.\nE       ```\nE       \nE       What you should do instead is wrap `tf_fn` in a layer:\nE       \nE       ```\nE       class MyLayer(Layer):\nE           def call(self, x):\nE               return tf_fn(x)\nE       \nE       x = MyLayer()(x)\nE       ```\n\n/usr/local/lib/python3.10/dist-packages/keras/src/backend/common/keras_tensor.py:194: ValueError\n----------------------------- Captured stdout call -----------------------------\nUsing GCN (local pooling) filters...\n___________________________ test_dgi_save_load[GCN] ____________________________\n\ntmpdir = local('/tmp/pytest-of-root/pytest-1/test_dgi_save_load_GCN_0')\nmodel_type = <class 'stellargraph.layer.gcn.GCN'>\n\n    @pytest.mark.parametrize(\"model_type\", [GCN, GraphSAGE])\n    def test_dgi_save_load(tmpdir, model_type):\n        base_generator, base_model, nodes = _model_data(model_type, sparse=False)\n        corrupted_generator = CorruptedGenerator(base_generator)\n        infomax = DeepGraphInfomax(base_model, corrupted_generator)\n    \n>       test_utils.model_save_load(tmpdir, infomax)\n\ntests/layer/test_deep_graph_infomax.py:173: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ntests/test_utils/__init__.py:29: in model_save_load\n    model = tf.keras.Model(*sg_model.in_out_tensors())\nstellargraph/layer/deep_graph_infomax.py:192: in in_out_tensors\n    x_out = tf.stack([scores, scores_corrupted], axis=-1)\n/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py:153: in error_handler\n    raise e.with_traceback(filtered_tb) from None\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <KerasTensor shape=(1, None), dtype=float32, sparse=False, ragged=False, name=keras_tensor_1007>\ndtype = None, name = 'stack'\n\n    def __tf_tensor__(self, dtype=None, name=None):\n>       raise ValueError(\n            \"A KerasTensor cannot be used as input to a TensorFlow function. \"\n            \"A KerasTensor is a symbolic placeholder for a shape and dtype, \"\n            \"used when constructing Keras Functional models \"\n            \"or Keras Functions. You can only use it as input to a Keras layer \"\n            \"or a Keras operation (from the namespaces `keras.layers` \"\n            \"and `keras.ops`). \"\n            \"You are likely doing something like:\\n\\n\"\n            \"```\\n\"\n            \"x = Input(...)\\n\"\n            \"...\\n\"\n            \"tf_fn(x)  # Invalid.\\n\"\n            \"```\\n\\n\"\n            \"What you should do instead is wrap `tf_fn` in a layer:\\n\\n\"\n            \"```\\n\"\n            \"class MyLayer(Layer):\\n\"\n            \"    def call(self, x):\\n\"\n            \"        return tf_fn(x)\\n\\n\"\n            \"x = MyLayer()(x)\\n\"\n            \"```\\n\"\n        )\nE       ValueError: A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.ops`). You are likely doing something like:\nE       \nE       ```\nE       x = Input(...)\nE       ...\nE       tf_fn(x)  # Invalid.\nE       ```\nE       \nE       What you should do instead is wrap `tf_fn` in a layer:\nE       \nE       ```\nE       class MyLayer(Layer):\nE           def call(self, x):\nE               return tf_fn(x)\nE       \nE       x = MyLayer()(x)\nE       ```\n\n/usr/local/lib/python3.10/dist-packages/keras/src/backend/common/keras_tensor.py:194: ValueError\n----------------------------- Captured stdout call -----------------------------\nUsing GCN (local pooling) filters...\n________________________ test_dgi_save_load[GraphSAGE] _________________________\n\ntmpdir = local('/tmp/pytest-of-root/pytest-1/test_dgi_save_load_GraphSAGE_0')\nmodel_type = <class 'stellargraph.layer.graphsage.GraphSAGE'>\n\n    @pytest.mark.parametrize(\"model_type\", [GCN, GraphSAGE])\n    def test_dgi_save_load(tmpdir, model_type):\n>       base_generator, base_model, nodes = _model_data(model_type, sparse=False)\n\ntests/layer/test_deep_graph_infomax.py:169: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ntests/layer/test_deep_graph_infomax.py:44: in _model_data\n    model = GraphSAGE(generator=generator, layer_sizes=[4, emb_dim])\nstellargraph/layer/graphsage.py:866: in __init__\n    self._compute_neighbourhood_sizes()\nstellargraph/layer/graphsage.py:951: in _compute_neighbourhood_sizes\n    self.neighbourhood_sizes = [size_at(i) for i in range(self.max_hops + 1)]\nstellargraph/layer/graphsage.py:951: in <listcomp>\n    self.neighbourhood_sizes = [size_at(i) for i in range(self.max_hops + 1)]\nstellargraph/layer/graphsage.py:949: in size_at\n    return np.product(self.n_samples[:i], dtype=int)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'product'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n            raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\n    \n        if attr == \"chararray\":\n            warnings.warn(\n                \"`np.chararray` is deprecated and will be removed from \"\n                \"the main namespace in the future. Use an array with a string \"\n                \"or bytes dtype instead.\", DeprecationWarning, stacklevel=2)\n            import numpy.char as char\n            return char.chararray\n    \n>       raise AttributeError(\"module {!r} has no attribute \"\n                             \"{!r}\".format(__name__, attr))\nE       AttributeError: module 'numpy' has no attribute 'product'\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:414: AttributeError\n_________________________ test_GraphConvolution_sparse _________________________\n\n    def test_GraphConvolution_sparse():\n        G, features = create_graph_features()\n        n_nodes = features.shape[0]\n    \n        # We need to specify the batch shape as one for the GraphConvolutional logic to work\n        x_t = Input(batch_shape=(1,) + features.shape)\n        A_ind = Input(batch_shape=(1, None, 2), dtype=\"int64\")\n        A_val = Input(batch_shape=(1, None), dtype=\"float32\")\n    \n        A_mat = SqueezedSparseConversion(shape=(n_nodes, n_nodes), dtype=A_val.dtype)(\n            [A_ind, A_val]\n        )\n        out = GraphConvolution(2)([x_t, A_mat])\n    \n        # Note we add a batch dimension of 1 to model inputs\n        adj = G.to_adjacency_matrix().tocoo()\n        A_indices = np.expand_dims(\n            np.hstack((adj.row[:, None], adj.col[:, None])).astype(np.int64), 0\n        )\n        A_values = np.expand_dims(adj.data, 0)\n        out_indices = np.array([[0, 1]], dtype=\"int32\")\n        x = features[None, :, :]\n    \n        model = keras.Model(inputs=[x_t, A_ind, A_val], outputs=out)\n        preds = model.predict([x, A_indices, A_values], batch_size=1)\n        assert preds.shape == (1, 3, 2)\n    \n        x_t_10 = Input(batch_shape=(10,) + features.shape)\n>       with pytest.raises(\n            ValueError,\n            match=\"features: expected batch dimension = 1 .* found features batch dimension 10\",\n        ):\nE       Failed: DID NOT RAISE <class 'ValueError'>\n\ntests/layer/test_gcn.py:121: Failed\n----------------------------- Captured stdout call -----------------------------\n\n\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step\n_____________________________ test_GCN_apply_dense _____________________________\n\n    def test_GCN_apply_dense():\n        G, features = create_graph_features()\n        adj = G.to_adjacency_matrix().toarray()[None, :, :]\n        n_nodes = features.shape[0]\n    \n        generator = FullBatchNodeGenerator(G, sparse=False, method=\"none\")\n        gcnModel = GCN([2], generator, activations=[\"relu\"], dropout=0.5)\n    \n        x_in, x_out = gcnModel.in_out_tensors()\n        model = keras.Model(inputs=x_in, outputs=x_out)\n    \n        # Check fit method\n        out_indices = np.array([[0, 1]], dtype=\"int32\")\n        preds_1 = model.predict([features[None, :, :], out_indices, adj])\n        assert preds_1.shape == (1, 2, 2)\n    \n        # Check fit method\n>       preds_2 = model.predict(generator.flow([\"a\", \"b\"]))\n\ntests/layer/test_gcn.py:163: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py:122: in error_handler\n    raise e.with_traceback(filtered_tb) from None\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nfunc = <function get_keras_tensor_spec.<locals>.get_single_tensor_spec at 0x7fc178796710>\ntree = ([array([[[1., 1.],\n        [1., 0.],\n        [0., 1.]]], dtype=float32), array([[0, 1]], dtype=uint8), array([[[0., 1., 1.],\n        [1., 0., 1.],\n        [1., 1., 0.]]], dtype=float32)], None)\nis_leaf = None, none_is_leaf = True, namespace = 'keras', rests = ()\n\n    def tree_map(\n        func: Callable[..., U],\n        tree: PyTree[T],\n        /,\n        *rests: PyTree[S],\n        is_leaf: Callable[[T], bool] | None = None,\n        none_is_leaf: bool = False,\n        namespace: str = '',\n    ) -> PyTree[U]:\n        \"\"\"Map a multi-input function over pytree args to produce a new pytree.\n    \n        See also :func:`tree_map_`, :func:`tree_map_with_path`, :func:`tree_map_with_path_`,\n        and :func:`tree_broadcast_map`.\n    \n        >>> tree_map(lambda x: x + 1, {'x': 7, 'y': (42, 64)})\n        {'x': 8, 'y': (43, 65)}\n        >>> tree_map(lambda x: x + 1, {'x': 7, 'y': (42, 64), 'z': None})\n        {'x': 8, 'y': (43, 65), 'z': None}\n        >>> tree_map(lambda x: x is None, {'x': 7, 'y': (42, 64), 'z': None})\n        {'x': False, 'y': (False, False), 'z': None}\n        >>> tree_map(lambda x: x is None, {'x': 7, 'y': (42, 64), 'z': None}, none_is_leaf=True)\n        {'x': False, 'y': (False, False), 'z': True}\n    \n        If multiple inputs are given, the structure of the tree is taken from the first input;\n        subsequent inputs need only have ``tree`` as a prefix:\n    \n        >>> tree_map(lambda x, y: [x] + y, [5, 6], [[7, 9], [1, 2]])\n        [[5, 7, 9], [6, 1, 2]]\n    \n        Args:\n            func (callable): A function that takes ``1 + len(rests)`` arguments, to be applied at the\n                corresponding leaves of the pytrees.\n            tree (pytree): A pytree to be mapped over, with each leaf providing the first positional\n                argument to function ``func``.\n            rests (tuple of pytree): A tuple of pytrees, each of which has the same structure as\n                ``tree`` or has ``tree`` as a prefix.\n            is_leaf (callable, optional): An optionally specified function that will be called at each\n                flattening step. It should return a boolean, with :data:`True` stopping the traversal\n                and the whole subtree being treated as a leaf, and :data:`False` indicating the\n                flattening should traverse the current object.\n            none_is_leaf (bool, optional): Whether to treat :data:`None` as a leaf. If :data:`False`,\n                :data:`None` is a non-leaf node with arity 0. Thus :data:`None` is contained in the\n                treespec rather than in the leaves list and :data:`None` will be remain in the result\n                pytree. (default: :data:`False`)\n            namespace (str, optional): The registry namespace used for custom pytree node types.\n                (default: :const:`''`, i.e., the global namespace)\n    \n        Returns:\n            A new pytree with the same structure as ``tree`` but with the value at each leaf given by\n            ``func(x, *xs)`` where ``x`` is the value at the corresponding leaf in ``tree`` and ``xs``\n            is the tuple of values at corresponding nodes in ``rests``.\n        \"\"\"\n        leaves, treespec = _C.flatten(tree, is_leaf, none_is_leaf, namespace)\n        flat_args = [leaves] + [treespec.flatten_up_to(r) for r in rests]\n>       return treespec.unflatten(map(func, *flat_args))\nE       ValueError: When passing a dataset to a Keras model, the arrays must be at least rank 1. Received: None of rank 0.\n\n/usr/local/lib/python3.10/dist-packages/optree/ops.py:766: ValueError\n----------------------------- Captured stdout call -----------------------------\n\n\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step\n____________________________ test_GCN_apply_sparse _____________________________\n\n    def test_GCN_apply_sparse():\n    \n        G, features = create_graph_features()\n        adj = G.to_adjacency_matrix()\n        features, adj = GCN_Aadj_feats_op(features, adj)\n        adj = adj.tocoo()\n        A_indices = np.expand_dims(\n            np.hstack((adj.row[:, None], adj.col[:, None])).astype(np.int64), 0\n        )\n        A_values = np.expand_dims(adj.data, 0)\n    \n        generator = FullBatchNodeGenerator(G, sparse=True, method=\"gcn\")\n        gcnModel = GCN(\n            layer_sizes=[2], activations=[\"relu\"], generator=generator, dropout=0.5\n        )\n    \n        x_in, x_out = gcnModel.in_out_tensors()\n        model = keras.Model(inputs=x_in, outputs=x_out)\n    \n        # Check fit method\n        out_indices = np.array([[0, 1]], dtype=\"int32\")\n        preds_1 = model.predict([features[None, :, :], out_indices, A_indices, A_values])\n        assert preds_1.shape == (1, 2, 2)\n    \n        # Check fit method\n>       preds_2 = model.predict(generator.flow([\"a\", \"b\"]))\n\ntests/layer/test_gcn.py:194: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py:122: in error_handler\n    raise e.with_traceback(filtered_tb) from None\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nfunc = <function get_keras_tensor_spec.<locals>.get_single_tensor_spec at 0x7fc14db77be0>\ntree = ([array([[[1., 1.],\n        [1., 0.],\n        [0., 1.]]], dtype=float32), array([[0, 1]], dtype=uint8), array([[[0, 0]...3333, 0.33333333, 0.33333333, 0.33333333, 0.33333333,\n        0.33333333, 0.33333333, 0.33333333, 0.33333333]])], None)\nis_leaf = None, none_is_leaf = True, namespace = 'keras', rests = ()\n\n    def tree_map(\n        func: Callable[..., U],\n        tree: PyTree[T],\n        /,\n        *rests: PyTree[S],\n        is_leaf: Callable[[T], bool] | None = None,\n        none_is_leaf: bool = False,\n        namespace: str = '',\n    ) -> PyTree[U]:\n        \"\"\"Map a multi-input function over pytree args to produce a new pytree.\n    \n        See also :func:`tree_map_`, :func:`tree_map_with_path`, :func:`tree_map_with_path_`,\n        and :func:`tree_broadcast_map`.\n    \n        >>> tree_map(lambda x: x + 1, {'x': 7, 'y': (42, 64)})\n        {'x': 8, 'y': (43, 65)}\n        >>> tree_map(lambda x: x + 1, {'x': 7, 'y': (42, 64), 'z': None})\n        {'x': 8, 'y': (43, 65), 'z': None}\n        >>> tree_map(lambda x: x is None, {'x': 7, 'y': (42, 64), 'z': None})\n        {'x': False, 'y': (False, False), 'z': None}\n        >>> tree_map(lambda x: x is None, {'x': 7, 'y': (42, 64), 'z': None}, none_is_leaf=True)\n        {'x': False, 'y': (False, False), 'z': True}\n    \n        If multiple inputs are given, the structure of the tree is taken from the first input;\n        subsequent inputs need only have ``tree`` as a prefix:\n    \n        >>> tree_map(lambda x, y: [x] + y, [5, 6], [[7, 9], [1, 2]])\n        [[5, 7, 9], [6, 1, 2]]\n    \n        Args:\n            func (callable): A function that takes ``1 + len(rests)`` arguments, to be applied at the\n                corresponding leaves of the pytrees.\n            tree (pytree): A pytree to be mapped over, with each leaf providing the first positional\n                argument to function ``func``.\n            rests (tuple of pytree): A tuple of pytrees, each of which has the same structure as\n                ``tree`` or has ``tree`` as a prefix.\n            is_leaf (callable, optional): An optionally specified function that will be called at each\n                flattening step. It should return a boolean, with :data:`True` stopping the traversal\n                and the whole subtree being treated as a leaf, and :data:`False` indicating the\n                flattening should traverse the current object.\n            none_is_leaf (bool, optional): Whether to treat :data:`None` as a leaf. If :data:`False`,\n                :data:`None` is a non-leaf node with arity 0. Thus :data:`None` is contained in the\n                treespec rather than in the leaves list and :data:`None` will be remain in the result\n                pytree. (default: :data:`False`)\n            namespace (str, optional): The registry namespace used for custom pytree node types.\n                (default: :const:`''`, i.e., the global namespace)\n    \n        Returns:\n            A new pytree with the same structure as ``tree`` but with the value at each leaf given by\n            ``func(x, *xs)`` where ``x`` is the value at the corresponding leaf in ``tree`` and ``xs``\n            is the tuple of values at corresponding nodes in ``rests``.\n        \"\"\"\n        leaves, treespec = _C.flatten(tree, is_leaf, none_is_leaf, namespace)\n        flat_args = [leaves] + [treespec.flatten_up_to(r) for r in rests]\n>       return treespec.unflatten(map(func, *flat_args))\nE       ValueError: When passing a dataset to a Keras model, the arrays must be at least rank 1. Received: None of rank 0.\n\n/usr/local/lib/python3.10/dist-packages/optree/ops.py:766: ValueError\n----------------------------- Captured stdout call -----------------------------\nUsing GCN (local pooling) filters...\nUsing GCN (local pooling) filters...\n\n\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step\n________________________ test_GCN_linkmodel_apply_dense ________________________\n\n    def test_GCN_linkmodel_apply_dense():\n        G, features = create_graph_features()\n        adj = G.to_adjacency_matrix().toarray()[None, :, :]\n        n_nodes = features.shape[0]\n    \n        generator = FullBatchLinkGenerator(G, sparse=False, method=\"none\")\n        gcnModel = GCN([3], generator, activations=[\"relu\"], dropout=0.5)\n    \n        x_in, x_out = gcnModel.in_out_tensors()\n        model = keras.Model(inputs=x_in, outputs=x_out)\n    \n        # Check fit method\n        out_indices = np.array([[[0, 1], [1, 2]]], dtype=\"int32\")\n        preds_1 = model.predict([features[None, :, :], out_indices, adj])\n        assert preds_1.shape == (1, 2, 2, 3)\n    \n        # Check fit method\n>       preds_2 = model.predict(generator.flow([(\"a\", \"b\"), (\"b\", \"c\")]))\n\ntests/layer/test_gcn.py:217: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py:122: in error_handler\n    raise e.with_traceback(filtered_tb) from None\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nfunc = <function get_keras_tensor_spec.<locals>.get_single_tensor_spec at 0x7fc178778af0>\ntree = ([array([[[1., 1.],\n        [1., 0.],\n        [0., 1.]]], dtype=float32), array([[[0, 1],\n        [1, 2]]], dtype=uint8), array([[[0., 1., 1.],\n        [1., 0., 1.],\n        [1., 1., 0.]]], dtype=float32)], None)\nis_leaf = None, none_is_leaf = True, namespace = 'keras', rests = ()\n\n    def tree_map(\n        func: Callable[..., U],\n        tree: PyTree[T],\n        /,\n        *rests: PyTree[S],\n        is_leaf: Callable[[T], bool] | None = None,\n        none_is_leaf: bool = False,\n        namespace: str = '',\n    ) -> PyTree[U]:\n        \"\"\"Map a multi-input function over pytree args to produce a new pytree.\n    \n        See also :func:`tree_map_`, :func:`tree_map_with_path`, :func:`tree_map_with_path_`,\n        and :func:`tree_broadcast_map`.\n    \n        >>> tree_map(lambda x: x + 1, {'x': 7, 'y': (42, 64)})\n        {'x': 8, 'y': (43, 65)}\n        >>> tree_map(lambda x: x + 1, {'x': 7, 'y': (42, 64), 'z': None})\n        {'x': 8, 'y': (43, 65), 'z': None}\n        >>> tree_map(lambda x: x is None, {'x': 7, 'y': (42, 64), 'z': None})\n        {'x': False, 'y': (False, False), 'z': None}\n        >>> tree_map(lambda x: x is None, {'x': 7, 'y': (42, 64), 'z': None}, none_is_leaf=True)\n        {'x': False, 'y': (False, False), 'z': True}\n    \n        If multiple inputs are given, the structure of the tree is taken from the first input;\n        subsequent inputs need only have ``tree`` as a prefix:\n    \n        >>> tree_map(lambda x, y: [x] + y, [5, 6], [[7, 9], [1, 2]])\n        [[5, 7, 9], [6, 1, 2]]\n    \n        Args:\n            func (callable): A function that takes ``1 + len(rests)`` arguments, to be applied at the\n                corresponding leaves of the pytrees.\n            tree (pytree): A pytree to be mapped over, with each leaf providing the first positional\n                argument to function ``func``.\n            rests (tuple of pytree): A tuple of pytrees, each of which has the same structure as\n                ``tree`` or has ``tree`` as a prefix.\n            is_leaf (callable, optional): An optionally specified function that will be called at each\n                flattening step. It should return a boolean, with :data:`True` stopping the traversal\n                and the whole subtree being treated as a leaf, and :data:`False` indicating the\n                flattening should traverse the current object.\n            none_is_leaf (bool, optional): Whether to treat :data:`None` as a leaf. If :data:`False`,\n                :data:`None` is a non-leaf node with arity 0. Thus :data:`None` is contained in the\n                treespec rather than in the leaves list and :data:`None` will be remain in the result\n                pytree. (default: :data:`False`)\n            namespace (str, optional): The registry namespace used for custom pytree node types.\n                (default: :const:`''`, i.e., the global namespace)\n    \n        Returns:\n            A new pytree with the same structure as ``tree`` but with the value at each leaf given by\n            ``func(x, *xs)`` where ``x`` is the value at the corresponding leaf in ``tree`` and ``xs``\n            is the tuple of values at corresponding nodes in ``rests``.\n        \"\"\"\n        leaves, treespec = _C.flatten(tree, is_leaf, none_is_leaf, namespace)\n        flat_args = [leaves] + [treespec.flatten_up_to(r) for r in rests]\n>       return treespec.unflatten(map(func, *flat_args))\nE       ValueError: When passing a dataset to a Keras model, the arrays must be at least rank 1. Received: None of rank 0.\n\n/usr/local/lib/python3.10/dist-packages/optree/ops.py:766: ValueError\n----------------------------- Captured stdout call -----------------------------\n\n\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step\n_______________________ test_GCN_linkmodel_apply_sparse ________________________\n\n    def test_GCN_linkmodel_apply_sparse():\n    \n        G, features = create_graph_features()\n        adj = G.to_adjacency_matrix()\n        features, adj = GCN_Aadj_feats_op(features, adj)\n        adj = adj.tocoo()\n        A_indices = np.expand_dims(\n            np.hstack((adj.row[:, None], adj.col[:, None])).astype(np.int64), 0\n        )\n        A_values = np.expand_dims(adj.data, 0)\n    \n        generator = FullBatchLinkGenerator(G, sparse=True, method=\"gcn\")\n        gcnModel = GCN(\n            layer_sizes=[3], activations=[\"relu\"], generator=generator, dropout=0.5\n        )\n    \n        x_in, x_out = gcnModel.in_out_tensors()\n        model = keras.Model(inputs=x_in, outputs=x_out)\n    \n        # Check fit method\n        out_indices = np.array([[[0, 1], [1, 2]]], dtype=\"int32\")\n        preds_1 = model.predict([features[None, :, :], out_indices, A_indices, A_values])\n        assert preds_1.shape == (1, 2, 2, 3)\n    \n        # Check fit method\n>       preds_2 = model.predict(generator.flow([(\"a\", \"b\"), (\"b\", \"c\")]))\n\ntests/layer/test_gcn.py:248: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py:122: in error_handler\n    raise e.with_traceback(filtered_tb) from None\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nfunc = <function get_keras_tensor_spec.<locals>.get_single_tensor_spec at 0x7fc17874c550>\ntree = ([array([[[1., 1.],\n        [1., 0.],\n        [0., 1.]]], dtype=float32), array([[[0, 1],\n        [1, 2]]], dtype=uint...3333, 0.33333333, 0.33333333, 0.33333333, 0.33333333,\n        0.33333333, 0.33333333, 0.33333333, 0.33333333]])], None)\nis_leaf = None, none_is_leaf = True, namespace = 'keras', rests = ()\n\n    def tree_map(\n        func: Callable[..., U],\n        tree: PyTree[T],\n        /,\n        *rests: PyTree[S],\n        is_leaf: Callable[[T], bool] | None = None,\n        none_is_leaf: bool = False,\n        namespace: str = '',\n    ) -> PyTree[U]:\n        \"\"\"Map a multi-input function over pytree args to produce a new pytree.\n    \n        See also :func:`tree_map_`, :func:`tree_map_with_path`, :func:`tree_map_with_path_`,\n        and :func:`tree_broadcast_map`.\n    \n        >>> tree_map(lambda x: x + 1, {'x': 7, 'y': (42, 64)})\n        {'x': 8, 'y': (43, 65)}\n        >>> tree_map(lambda x: x + 1, {'x': 7, 'y': (42, 64), 'z': None})\n        {'x': 8, 'y': (43, 65), 'z': None}\n        >>> tree_map(lambda x: x is None, {'x': 7, 'y': (42, 64), 'z': None})\n        {'x': False, 'y': (False, False), 'z': None}\n        >>> tree_map(lambda x: x is None, {'x': 7, 'y': (42, 64), 'z': None}, none_is_leaf=True)\n        {'x': False, 'y': (False, False), 'z': True}\n    \n        If multiple inputs are given, the structure of the tree is taken from the first input;\n        subsequent inputs need only have ``tree`` as a prefix:\n    \n        >>> tree_map(lambda x, y: [x] + y, [5, 6], [[7, 9], [1, 2]])\n        [[5, 7, 9], [6, 1, 2]]\n    \n        Args:\n            func (callable): A function that takes ``1 + len(rests)`` arguments, to be applied at the\n                corresponding leaves of the pytrees.\n            tree (pytree): A pytree to be mapped over, with each leaf providing the first positional\n                argument to function ``func``.\n            rests (tuple of pytree): A tuple of pytrees, each of which has the same structure as\n                ``tree`` or has ``tree`` as a prefix.\n            is_leaf (callable, optional): An optionally specified function that will be called at each\n                flattening step. It should return a boolean, with :data:`True` stopping the traversal\n                and the whole subtree being treated as a leaf, and :data:`False` indicating the\n                flattening should traverse the current object.\n            none_is_leaf (bool, optional): Whether to treat :data:`None` as a leaf. If :data:`False`,\n                :data:`None` is a non-leaf node with arity 0. Thus :data:`None` is contained in the\n                treespec rather than in the leaves list and :data:`None` will be remain in the result\n                pytree. (default: :data:`False`)\n            namespace (str, optional): The registry namespace used for custom pytree node types.\n                (default: :const:`''`, i.e., the global namespace)\n    \n        Returns:\n            A new pytree with the same structure as ``tree`` but with the value at each leaf given by\n            ``func(x, *xs)`` where ``x`` is the value at the corresponding leaf in ``tree`` and ``xs``\n            is the tuple of values at corresponding nodes in ``rests``.\n        \"\"\"\n        leaves, treespec = _C.flatten(tree, is_leaf, none_is_leaf, namespace)\n        flat_args = [leaves] + [treespec.flatten_up_to(r) for r in rests]\n>       return treespec.unflatten(map(func, *flat_args))\nE       ValueError: When passing a dataset to a Keras model, the arrays must be at least rank 1. Received: None of rank 0.\n\n/usr/local/lib/python3.10/dist-packages/optree/ops.py:766: ValueError\n----------------------------- Captured stdout call -----------------------------\nUsing GCN (local pooling) filters...\nUsing GCN (local pooling) filters...\n\n\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step\n__________________________ test_gcn_save_load[False] ___________________________\n\ntmpdir = local('/tmp/pytest-of-root/pytest-1/test_gcn_save_load_False_0')\nsparse = False\n\n    @pytest.mark.parametrize(\n        \"sparse\", [False, pytest.param(True, marks=pytest.mark.xfail(reason=\"FIXME #1251\"))]\n    )\n    def test_gcn_save_load(tmpdir, sparse):\n        G, _ = create_graph_features()\n        generator = FullBatchNodeGenerator(G, sparse=sparse)\n        gcn = GCN([2, 3], generator)\n>       test_utils.model_save_load(tmpdir, gcn)\n\ntests/layer/test_gcn.py:329: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ntests/test_utils/__init__.py:43: in model_save_load\n    func(model, str(saved_dir))\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nmodel = <Functional name=functional_36, built=True>\nfilepath = '/tmp/pytest-of-root/pytest-1/test_gcn_save_load_False_0/0'\noverwrite = True, zipped = True, kwargs = {}, include_optimizer = True\nsave_format = False, is_hf = False, exists = False\n\n    @keras_export([\"keras.saving.save_model\", \"keras.models.save_model\"])\n    def save_model(model, filepath, overwrite=True, zipped=None, **kwargs):\n        \"\"\"Saves a model as a `.keras` file.\n    \n        Args:\n            model: Keras model instance to be saved.\n            filepath: `str` or `pathlib.Path` object. Path where to save the model.\n            overwrite: Whether we should overwrite any existing model at the target\n                location, or instead ask the user via an interactive prompt.\n            zipped: Whether to save the model as a zipped `.keras`\n                archive (default when saving locally), or as an unzipped directory\n                (default when saving on the Hugging Face Hub).\n    \n        Example:\n    \n        ```python\n        model = keras.Sequential(\n            [\n                keras.layers.Dense(5, input_shape=(3,)),\n                keras.layers.Softmax(),\n            ],\n        )\n        model.save(\"model.keras\")\n        loaded_model = keras.saving.load_model(\"model.keras\")\n        x = keras.random.uniform((10, 3))\n        assert np.allclose(model.predict(x), loaded_model.predict(x))\n        ```\n    \n        Note that `model.save()` is an alias for `keras.saving.save_model()`.\n    \n        The saved `.keras` file is a `zip` archive that contains:\n    \n        - The model's configuration (architecture)\n        - The model's weights\n        - The model's optimizer's state (if any)\n    \n        Thus models can be reinstantiated in the exact same state.\n        \"\"\"\n        include_optimizer = kwargs.pop(\"include_optimizer\", True)\n        save_format = kwargs.pop(\"save_format\", False)\n        if save_format:\n            if str(filepath).endswith((\".h5\", \".hdf5\")) or str(filepath).endswith(\n                \".keras\"\n            ):\n                logging.warning(\n                    \"The `save_format` argument is deprecated in Keras 3. \"\n                    \"We recommend removing this argument as it can be inferred \"\n                    \"from the file path. \"\n                    f\"Received: save_format={save_format}\"\n                )\n            else:\n                raise ValueError(\n                    \"The `save_format` argument is deprecated in Keras 3. \"\n                    \"Please remove this argument and pass a file path with \"\n                    \"either `.keras` or `.h5` extension.\"\n                    f\"Received: save_format={save_format}\"\n                )\n        if kwargs:\n            raise ValueError(\n                \"The following argument(s) are not supported: \"\n                f\"{list(kwargs.keys())}\"\n            )\n    \n        # Deprecation warnings\n        if str(filepath).endswith((\".h5\", \".hdf5\")):\n            logging.warning(\n                \"You are saving your model as an HDF5 file via \"\n                \"`model.save()` or `keras.saving.save_model(model)`. \"\n                \"This file format is considered legacy. \"\n                \"We recommend using instead the native Keras format, \"\n                \"e.g. `model.save('my_model.keras')` or \"\n                \"`keras.saving.save_model(model, 'my_model.keras')`. \"\n            )\n    \n        is_hf = str(filepath).startswith(\"hf://\")\n        if zipped is None:\n            zipped = not is_hf  # default behavior depends on destination\n    \n        # If file exists and should not be overwritten.\n        try:\n            exists = (not is_hf) and os.path.exists(filepath)\n        except TypeError:\n            exists = False\n        if exists and not overwrite:\n            proceed = io_utils.ask_to_proceed_with_overwrite(filepath)\n            if not proceed:\n                return\n    \n        if zipped and str(filepath).endswith(\".keras\"):\n            return saving_lib.save_model(model, filepath)\n        if not zipped:\n            return saving_lib.save_model(model, filepath, zipped=False)\n        if str(filepath).endswith((\".h5\", \".hdf5\")):\n            return legacy_h5_format.save_model_to_hdf5(\n                model, filepath, overwrite, include_optimizer\n            )\n>       raise ValueError(\n            \"Invalid filepath extension for saving. \"\n            \"Please add either a `.keras` extension for the native Keras \"\n            f\"format (recommended) or a `.h5` extension. \"\n            \"Use `model.export(filepath)` if you want to export a SavedModel \"\n            \"for use with TFLite/TFServing/etc. \"\n            f\"Received: filepath={filepath}.\"\n        )\nE       ValueError: Invalid filepath extension for saving. Please add either a `.keras` extension for the native Keras format (recommended) or a `.h5` extension. Use `model.export(filepath)` if you want to export a SavedModel for use with TFLite/TFServing/etc. Received: filepath=/tmp/pytest-of-root/pytest-1/test_gcn_save_load_False_0/0.\n\n/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_api.py:114: ValueError\n----------------------------- Captured stdout call -----------------------------\nUsing GCN (local pooling) filters...\n_______________________ test_gcn_lstm_model_input_output _______________________\n\n    def test_gcn_lstm_model_input_output():\n        fx, fy, a = get_timeseries_graph_data()\n    \n        gcn_lstm_model = GCN_LSTM(\n            seq_len=fx.shape[-1],\n            adj=a,\n            gc_layer_sizes=[8, 8, 16],\n            gc_activations=[\"relu\", \"relu\", \"relu\"],\n            lstm_layer_sizes=[8, 16, 32],\n            lstm_activations=[\"tanh\"],\n        )\n    \n        # check model input and output tensors\n>       x_input, x_output = gcn_lstm_model.in_out_tensors()\n\ntests/layer/test_gcn_lstm.py:140: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/layer/gcn_lstm.py:415: in in_out_tensors\n    x_out = self(x_inp)\nstellargraph/layer/gcn_lstm.py:364: in __call__\n    h_layer = tf.expand_dims(h_layer, axis=-1)\n/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/weak_tensor_ops.py:88: in wrapper\n    return op(*args, **kwargs)\n/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py:153: in error_handler\n    raise e.with_traceback(filtered_tb) from None\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <KerasTensor shape=(None, 5, 4), dtype=float32, sparse=False, ragged=False, name=keras_tensor_1100>\ndtype = None, name = None\n\n    def __tf_tensor__(self, dtype=None, name=None):\n>       raise ValueError(\n            \"A KerasTensor cannot be used as input to a TensorFlow function. \"\n            \"A KerasTensor is a symbolic placeholder for a shape and dtype, \"\n            \"used when constructing Keras Functional models \"\n            \"or Keras Functions. You can only use it as input to a Keras layer \"\n            \"or a Keras operation (from the namespaces `keras.layers` \"\n            \"and `keras.ops`). \"\n            \"You are likely doing something like:\\n\\n\"\n            \"```\\n\"\n            \"x = Input(...)\\n\"\n            \"...\\n\"\n            \"tf_fn(x)  # Invalid.\\n\"\n            \"```\\n\\n\"\n            \"What you should do instead is wrap `tf_fn` in a layer:\\n\\n\"\n            \"```\\n\"\n            \"class MyLayer(Layer):\\n\"\n            \"    def call(self, x):\\n\"\n            \"        return tf_fn(x)\\n\\n\"\n            \"x = MyLayer()(x)\\n\"\n            \"```\\n\"\n        )\nE       ValueError: A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.ops`). You are likely doing something like:\nE       \nE       ```\nE       x = Input(...)\nE       ...\nE       tf_fn(x)  # Invalid.\nE       ```\nE       \nE       What you should do instead is wrap `tf_fn` in a layer:\nE       \nE       ```\nE       class MyLayer(Layer):\nE           def call(self, x):\nE               return tf_fn(x)\nE       \nE       x = MyLayer()(x)\nE       ```\n\n/usr/local/lib/python3.10/dist-packages/keras/src/backend/common/keras_tensor.py:194: ValueError\n_____________________________ test_gcn_lstm_model ______________________________\n\n    def test_gcn_lstm_model():\n        fx, fy, a = get_timeseries_graph_data()\n    \n        gcn_lstm_model = GCN_LSTM(\n            seq_len=fx.shape[-1],\n            adj=a,\n            gc_layer_sizes=[8, 8, 16],\n            gc_activations=[\"relu\", \"relu\", \"relu\"],\n            lstm_layer_sizes=[8, 16, 32],\n            lstm_activations=[\"tanh\"],\n        )\n    \n>       x_input, x_output = gcn_lstm_model.in_out_tensors()\n\ntests/layer/test_gcn_lstm.py:158: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/layer/gcn_lstm.py:415: in in_out_tensors\n    x_out = self(x_inp)\nstellargraph/layer/gcn_lstm.py:364: in __call__\n    h_layer = tf.expand_dims(h_layer, axis=-1)\n/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/weak_tensor_ops.py:88: in wrapper\n    return op(*args, **kwargs)\n/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py:153: in error_handler\n    raise e.with_traceback(filtered_tb) from None\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <KerasTensor shape=(None, 5, 4), dtype=float32, sparse=False, ragged=False, name=keras_tensor_1102>\ndtype = None, name = None\n\n    def __tf_tensor__(self, dtype=None, name=None):\n>       raise ValueError(\n            \"A KerasTensor cannot be used as input to a TensorFlow function. \"\n            \"A KerasTensor is a symbolic placeholder for a shape and dtype, \"\n            \"used when constructing Keras Functional models \"\n            \"or Keras Functions. You can only use it as input to a Keras layer \"\n            \"or a Keras operation (from the namespaces `keras.layers` \"\n            \"and `keras.ops`). \"\n            \"You are likely doing something like:\\n\\n\"\n            \"```\\n\"\n            \"x = Input(...)\\n\"\n            \"...\\n\"\n            \"tf_fn(x)  # Invalid.\\n\"\n            \"```\\n\\n\"\n            \"What you should do instead is wrap `tf_fn` in a layer:\\n\\n\"\n            \"```\\n\"\n            \"class MyLayer(Layer):\\n\"\n            \"    def call(self, x):\\n\"\n            \"        return tf_fn(x)\\n\\n\"\n            \"x = MyLayer()(x)\\n\"\n            \"```\\n\"\n        )\nE       ValueError: A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.ops`). You are likely doing something like:\nE       \nE       ```\nE       x = Input(...)\nE       ...\nE       tf_fn(x)  # Invalid.\nE       ```\nE       \nE       What you should do instead is wrap `tf_fn` in a layer:\nE       \nE       ```\nE       class MyLayer(Layer):\nE           def call(self, x):\nE               return tf_fn(x)\nE       \nE       x = MyLayer()(x)\nE       ```\n\n/usr/local/lib/python3.10/dist-packages/keras/src/backend/common/keras_tensor.py:194: ValueError\n________________________ test_gcn_lstm_model_prediction ________________________\n\n    def test_gcn_lstm_model_prediction():\n        fx, fy, a = get_timeseries_graph_data()\n    \n        gcn_lstm_model = GCN_LSTM(\n            seq_len=fx.shape[-1],\n            adj=a,\n            gc_layer_sizes=[8, 8, 16],\n            gc_activations=[\"relu\", \"relu\", \"relu\"],\n            lstm_layer_sizes=[8, 16, 32],\n            lstm_activations=[\"tanh\"],\n        )\n    \n>       x_input, x_output = gcn_lstm_model.in_out_tensors()\n\ntests/layer/test_gcn_lstm.py:182: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/layer/gcn_lstm.py:415: in in_out_tensors\n    x_out = self(x_inp)\nstellargraph/layer/gcn_lstm.py:364: in __call__\n    h_layer = tf.expand_dims(h_layer, axis=-1)\n/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/weak_tensor_ops.py:88: in wrapper\n    return op(*args, **kwargs)\n/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py:153: in error_handler\n    raise e.with_traceback(filtered_tb) from None\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <KerasTensor shape=(None, 5, 4), dtype=float32, sparse=False, ragged=False, name=keras_tensor_1104>\ndtype = None, name = None\n\n    def __tf_tensor__(self, dtype=None, name=None):\n>       raise ValueError(\n            \"A KerasTensor cannot be used as input to a TensorFlow function. \"\n            \"A KerasTensor is a symbolic placeholder for a shape and dtype, \"\n            \"used when constructing Keras Functional models \"\n            \"or Keras Functions. You can only use it as input to a Keras layer \"\n            \"or a Keras operation (from the namespaces `keras.layers` \"\n            \"and `keras.ops`). \"\n            \"You are likely doing something like:\\n\\n\"\n            \"```\\n\"\n            \"x = Input(...)\\n\"\n            \"...\\n\"\n            \"tf_fn(x)  # Invalid.\\n\"\n            \"```\\n\\n\"\n            \"What you should do instead is wrap `tf_fn` in a layer:\\n\\n\"\n            \"```\\n\"\n            \"class MyLayer(Layer):\\n\"\n            \"    def call(self, x):\\n\"\n            \"        return tf_fn(x)\\n\\n\"\n            \"x = MyLayer()(x)\\n\"\n            \"```\\n\"\n        )\nE       ValueError: A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.ops`). You are likely doing something like:\nE       \nE       ```\nE       x = Input(...)\nE       ...\nE       tf_fn(x)  # Invalid.\nE       ```\nE       \nE       What you should do instead is wrap `tf_fn` in a layer:\nE       \nE       ```\nE       class MyLayer(Layer):\nE           def call(self, x):\nE               return tf_fn(x)\nE       \nE       x = MyLayer()(x)\nE       ```\n\n/usr/local/lib/python3.10/dist-packages/keras/src/backend/common/keras_tensor.py:194: ValueError\n____________________ Test_GraphAttention.test_apply_average ____________________\n\nself = <tests.layer.test_graph_attention.Test_GraphAttention object at 0x7fc1ac60e980>\n\n    def test_apply_average(self):\n        gat = self.layer(\n            units=self.F_out,\n            attn_heads=self.attn_heads,\n            attn_heads_reduction=\"average\",\n            activation=self.activation,\n            kernel_initializer=\"ones\",\n            attn_kernel_initializer=\"zeros\",\n            bias_initializer=\"zeros\",\n        )\n        x_inp, layer_inp = self.get_inputs()\n    \n        # Instantiate layer with squeezed matrix\n        x_out = gat(layer_inp)\n    \n        model = keras.Model(inputs=x_inp, outputs=x_out)\n        assert model.output_shape[-1] == self.F_out\n    \n        X = np.ones((1, self.N, self.F_in))  # features\n        for i in range(self.N):\n            X[:, i, :] = i + 1\n    \n        As = self.get_matrix()\n    \n        expected = (X * self.F_in)[..., : self.F_out]\n        actual = model.predict([X] + As)\n    \n>       np.testing.assert_allclose(actual.squeeze(), expected.squeeze())\n\ntests/layer/test_graph_attention.py:150: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nargs = (<function assert_allclose.<locals>.compare at 0x7fc14d6f49d0>, array([[ 4.9999995,  4.9999995],\n       [ 9.999999 ,  ....],\n       [25., 25.],\n       [30., 30.],\n       [35., 35.],\n       [40., 40.],\n       [45., 45.],\n       [50., 50.]]))\nkwds = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-07, atol=0', 'strict': False, ...}\n\n    @wraps(func)\n    def inner(*args, **kwds):\n        with self._recreate_cm():\n>           return func(*args, **kwds)\nE           AssertionError: \nE           Not equal to tolerance rtol=1e-07, atol=0\nE           \nE           Mismatched elements: 2 / 20 (10%)\nE           Max absolute difference among violations: 3.81469727e-06\nE           Max relative difference among violations: 1.0899135e-07\nE            ACTUAL: array([[ 5.      ,  5.      ],\nE                  [ 9.999999,  9.999999],\nE                  [14.999999, 14.999999],...\nE            DESIRED: array([[ 5.,  5.],\nE                  [10., 10.],\nE                  [15., 15.],...\n\n/usr/lib/python3.10/contextlib.py:79: AssertionError\n----------------------------- Captured stdout call -----------------------------\n\n\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 658ms/step\n____________ Test_GraphAttention.test_apply_average_with_neighbours ____________\n\nself = <tests.layer.test_graph_attention.Test_GraphAttention object at 0x7fc1ac60eb00>\n\n    def test_apply_average_with_neighbours(self):\n        gat_saliency = self.layer(\n            units=self.F_out,\n            attn_heads=self.attn_heads,\n            attn_heads_reduction=\"average\",\n            activation=self.activation,\n            kernel_initializer=\"ones\",\n            attn_kernel_initializer=\"zeros\",\n            bias_initializer=\"zeros\",\n            saliency_map_support=True,\n        )\n    \n        gat_origin = self.layer(\n            units=self.F_out,\n            attn_heads=self.attn_heads,\n            attn_heads_reduction=\"average\",\n            activation=self.activation,\n            kernel_initializer=\"ones\",\n            attn_kernel_initializer=\"zeros\",\n            bias_initializer=\"zeros\",\n            saliency_map_support=False,\n        )\n    \n        x_inp, layer_inp = self.get_inputs()\n    \n        # Instantiate layer with squeezed matrix\n        x_out_saliency = gat_saliency(layer_inp)\n        x_out_origin = gat_origin(layer_inp)\n    \n        model_origin = keras.Model(inputs=x_inp, outputs=x_out_origin)\n        model_saliency = keras.Model(inputs=x_inp, outputs=x_out_saliency)\n        assert model_origin.output_shape[-1] == self.F_out\n        assert model_saliency.output_shape[-1] == self.F_out\n    \n        X = np.zeros((1, self.N, self.F_in))  # features\n        for i in range(self.N):\n            X[:, i, :] = i\n    \n        As = self.get_matrix([((0, 1), 1), ((1, 0), 1)])\n    \n        expected = (X * self.F_in)[..., : self.F_out]\n        expected[:, :2] = self.F_in / 2\n        actual_origin = model_origin.predict([X] + As)\n        actual_saliency = model_saliency.predict([X] + As)\n>       np.testing.assert_allclose(expected, actual_origin)\n\ntests/layer/test_graph_attention.py:196: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nargs = (<function assert_allclose.<locals>.compare at 0x7fc178dca440>, array([[[ 2.5,  2.5],\n        [ 2.5,  2.5],\n        [1...        [34.999996 , 34.999996 ],\n        [40.       , 40.       ],\n        [45.       , 45.       ]]], dtype=float32))\nkwds = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-07, atol=0', 'strict': False, ...}\n\n    @wraps(func)\n    def inner(*args, **kwds):\n        with self._recreate_cm():\n>           return func(*args, **kwds)\nE           AssertionError: \nE           Not equal to tolerance rtol=1e-07, atol=0\nE           \nE           Mismatched elements: 2 / 20 (10%)\nE           Max absolute difference among violations: 3.81469727e-06\nE           Max relative difference among violations: 1.08991362e-07\nE            ACTUAL: array([[[ 2.5,  2.5],\nE                   [ 2.5,  2.5],\nE                   [10. , 10. ],...\nE            DESIRED: array([[[ 2.5     ,  2.5     ],\nE                   [ 2.5     ,  2.5     ],\nE                   [ 9.999999,  9.999999],...\n\n/usr/lib/python3.10/contextlib.py:79: AssertionError\n----------------------------- Captured stdout call -----------------------------\n\n\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 639ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 650ms/step\n\n\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n________________________ Test_GAT.test_gat_build_l2norm ________________________\n\nself = <tests.layer.test_graph_attention.Test_GAT object at 0x7fc1ac60feb0>\n\n    def test_gat_build_l2norm(self):\n        G = example_graph(feature_size=self.F_in)\n        gen = FullBatchNodeGenerator(G, sparse=self.sparse, method=self.method)\n        gat = GAT(\n            layer_sizes=self.layer_sizes,\n            activations=self.activations,\n            attn_heads=self.attn_heads,\n            generator=gen,\n            bias=True,\n            normalize=\"l2\",\n            kernel_initializer=\"ones\",\n            attn_kernel_initializer=\"ones\",\n        )\n    \n        x_in, x_out = gat.in_out_tensors()\n    \n        model = keras.Model(inputs=x_in, outputs=x_out)\n    \n        ng = gen.flow(G.nodes())\n>       actual = model.predict(ng)\n\ntests/layer/test_graph_attention.py:498: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py:122: in error_handler\n    raise e.with_traceback(filtered_tb) from None\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nfunc = <function get_keras_tensor_spec.<locals>.get_single_tensor_spec at 0x7fc14d685990>\ntree = ([array([[[1., 1., 1., 1., 1.],\n        [2., 2., 2., 2., 2.],\n        [3., 3., 3., 3., 3.],\n        [4., 4., 4., 4., 4...nt8), array([[[1., 1., 0., 1.],\n        [1., 1., 1., 1.],\n        [0., 1., 1., 0.],\n        [1., 1., 0., 1.]]])], None)\nis_leaf = None, none_is_leaf = True, namespace = 'keras', rests = ()\n\n    def tree_map(\n        func: Callable[..., U],\n        tree: PyTree[T],\n        /,\n        *rests: PyTree[S],\n        is_leaf: Callable[[T], bool] | None = None,\n        none_is_leaf: bool = False,\n        namespace: str = '',\n    ) -> PyTree[U]:\n        \"\"\"Map a multi-input function over pytree args to produce a new pytree.\n    \n        See also :func:`tree_map_`, :func:`tree_map_with_path`, :func:`tree_map_with_path_`,\n        and :func:`tree_broadcast_map`.\n    \n        >>> tree_map(lambda x: x + 1, {'x': 7, 'y': (42, 64)})\n        {'x': 8, 'y': (43, 65)}\n        >>> tree_map(lambda x: x + 1, {'x': 7, 'y': (42, 64), 'z': None})\n        {'x': 8, 'y': (43, 65), 'z': None}\n        >>> tree_map(lambda x: x is None, {'x': 7, 'y': (42, 64), 'z': None})\n        {'x': False, 'y': (False, False), 'z': None}\n        >>> tree_map(lambda x: x is None, {'x': 7, 'y': (42, 64), 'z': None}, none_is_leaf=True)\n        {'x': False, 'y': (False, False), 'z': True}\n    \n        If multiple inputs are given, the structure of the tree is taken from the first input;\n        subsequent inputs need only have ``tree`` as a prefix:\n    \n        >>> tree_map(lambda x, y: [x] + y, [5, 6], [[7, 9], [1, 2]])\n        [[5, 7, 9], [6, 1, 2]]\n    \n        Args:\n            func (callable): A function that takes ``1 + len(rests)`` arguments, to be applied at the\n                corresponding leaves of the pytrees.\n            tree (pytree): A pytree to be mapped over, with each leaf providing the first positional\n                argument to function ``func``.\n            rests (tuple of pytree): A tuple of pytrees, each of which has the same structure as\n                ``tree`` or has ``tree`` as a prefix.\n            is_leaf (callable, optional): An optionally specified function that will be called at each\n                flattening step. It should return a boolean, with :data:`True` stopping the traversal\n                and the whole subtree being treated as a leaf, and :data:`False` indicating the\n                flattening should traverse the current object.\n            none_is_leaf (bool, optional): Whether to treat :data:`None` as a leaf. If :data:`False`,\n                :data:`None` is a non-leaf node with arity 0. Thus :data:`None` is contained in the\n                treespec rather than in the leaves list and :data:`None` will be remain in the result\n                pytree. (default: :data:`False`)\n            namespace (str, optional): The registry namespace used for custom pytree node types.\n                (default: :const:`''`, i.e., the global namespace)\n    \n        Returns:\n            A new pytree with the same structure as ``tree`` but with the value at each leaf given by\n            ``func(x, *xs)`` where ``x`` is the value at the corresponding leaf in ``tree`` and ``xs``\n            is the tuple of values at corresponding nodes in ``rests``.\n        \"\"\"\n        leaves, treespec = _C.flatten(tree, is_leaf, none_is_leaf, namespace)\n        flat_args = [leaves] + [treespec.flatten_up_to(r) for r in rests]\n>       return treespec.unflatten(map(func, *flat_args))\nE       ValueError: When passing a dataset to a Keras model, the arrays must be at least rank 1. Received: None of rank 0.\n\n/usr/local/lib/python3.10/dist-packages/optree/ops.py:766: ValueError\n_______________________ Test_GAT.test_gat_build_no_norm ________________________\n\nself = <tests.layer.test_graph_attention.Test_GAT object at 0x7fc1ac634070>\n\n    def test_gat_build_no_norm(self):\n        G = example_graph(feature_size=self.F_in)\n        gen = FullBatchNodeGenerator(G, sparse=self.sparse, method=self.method)\n        gat = GAT(\n            layer_sizes=self.layer_sizes,\n            activations=self.activations,\n            attn_heads=self.attn_heads,\n            generator=gen,\n            bias=True,\n            normalize=None,\n            kernel_initializer=\"ones\",\n            attn_kernel_initializer=\"ones\",\n        )\n    \n        x_in, x_out = gat.in_out_tensors()\n    \n        model = keras.Model(inputs=x_in, outputs=x_out)\n    \n        ng = gen.flow(G.nodes())\n>       actual = model.predict(ng)\n\ntests/layer/test_graph_attention.py:524: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py:122: in error_handler\n    raise e.with_traceback(filtered_tb) from None\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nfunc = <function get_keras_tensor_spec.<locals>.get_single_tensor_spec at 0x7fc14d6c7250>\ntree = ([array([[[1., 1., 1., 1., 1.],\n        [2., 2., 2., 2., 2.],\n        [3., 3., 3., 3., 3.],\n        [4., 4., 4., 4., 4...nt8), array([[[1., 1., 0., 1.],\n        [1., 1., 1., 1.],\n        [0., 1., 1., 0.],\n        [1., 1., 0., 1.]]])], None)\nis_leaf = None, none_is_leaf = True, namespace = 'keras', rests = ()\n\n    def tree_map(\n        func: Callable[..., U],\n        tree: PyTree[T],\n        /,\n        *rests: PyTree[S],\n        is_leaf: Callable[[T], bool] | None = None,\n        none_is_leaf: bool = False,\n        namespace: str = '',\n    ) -> PyTree[U]:\n        \"\"\"Map a multi-input function over pytree args to produce a new pytree.\n    \n        See also :func:`tree_map_`, :func:`tree_map_with_path`, :func:`tree_map_with_path_`,\n        and :func:`tree_broadcast_map`.\n    \n        >>> tree_map(lambda x: x + 1, {'x': 7, 'y': (42, 64)})\n        {'x': 8, 'y': (43, 65)}\n        >>> tree_map(lambda x: x + 1, {'x': 7, 'y': (42, 64), 'z': None})\n        {'x': 8, 'y': (43, 65), 'z': None}\n        >>> tree_map(lambda x: x is None, {'x': 7, 'y': (42, 64), 'z': None})\n        {'x': False, 'y': (False, False), 'z': None}\n        >>> tree_map(lambda x: x is None, {'x': 7, 'y': (42, 64), 'z': None}, none_is_leaf=True)\n        {'x': False, 'y': (False, False), 'z': True}\n    \n        If multiple inputs are given, the structure of the tree is taken from the first input;\n        subsequent inputs need only have ``tree`` as a prefix:\n    \n        >>> tree_map(lambda x, y: [x] + y, [5, 6], [[7, 9], [1, 2]])\n        [[5, 7, 9], [6, 1, 2]]\n    \n        Args:\n            func (callable): A function that takes ``1 + len(rests)`` arguments, to be applied at the\n                corresponding leaves of the pytrees.\n            tree (pytree): A pytree to be mapped over, with each leaf providing the first positional\n                argument to function ``func``.\n            rests (tuple of pytree): A tuple of pytrees, each of which has the same structure as\n                ``tree`` or has ``tree`` as a prefix.\n            is_leaf (callable, optional): An optionally specified function that will be called at each\n                flattening step. It should return a boolean, with :data:`True` stopping the traversal\n                and the whole subtree being treated as a leaf, and :data:`False` indicating the\n                flattening should traverse the current object.\n            none_is_leaf (bool, optional): Whether to treat :data:`None` as a leaf. If :data:`False`,\n                :data:`None` is a non-leaf node with arity 0. Thus :data:`None` is contained in the\n                treespec rather than in the leaves list and :data:`None` will be remain in the result\n                pytree. (default: :data:`False`)\n            namespace (str, optional): The registry namespace used for custom pytree node types.\n                (default: :const:`''`, i.e., the global namespace)\n    \n        Returns:\n            A new pytree with the same structure as ``tree`` but with the value at each leaf given by\n            ``func(x, *xs)`` where ``x`` is the value at the corresponding leaf in ``tree`` and ``xs``\n            is the tuple of values at corresponding nodes in ``rests``.\n        \"\"\"\n        leaves, treespec = _C.flatten(tree, is_leaf, none_is_leaf, namespace)\n        flat_args = [leaves] + [treespec.flatten_up_to(r) for r in rests]\n>       return treespec.unflatten(map(func, *flat_args))\nE       ValueError: When passing a dataset to a Keras model, the arrays must be at least rank 1. Received: None of rank 0.\n\n/usr/local/lib/python3.10/dist-packages/optree/ops.py:766: ValueError\n_________________________ Test_GAT.test_gat_serialize __________________________\n\nself = <tests.layer.test_graph_attention.Test_GAT object at 0x7fc1ac60fe20>\n\n    def test_gat_serialize(self):\n        G = example_graph(feature_size=self.F_in)\n        gen = FullBatchNodeGenerator(G, sparse=self.sparse, method=self.method)\n        gat = GAT(\n            layer_sizes=self.layer_sizes,\n            activations=self.activations,\n            attn_heads=self.attn_heads,\n            generator=gen,\n            bias=True,\n            normalize=\"l2\",\n        )\n    \n        x_in, x_out = gat.in_out_tensors()\n        model = keras.Model(inputs=x_in, outputs=x_out)\n    \n        ng = gen.flow(G.nodes())\n    \n        # Save model\n        model_json = model.to_json()\n    \n        # Set all weights to one\n        model_weights = [np.ones_like(w) for w in model.get_weights()]\n    \n        # Load model from json & set all weights\n>       model2 = keras.models.model_from_json(\n            model_json,\n            custom_objects={\n                \"GraphAttention\": GraphAttention,\n                \"GatherIndices\": GatherIndices,\n            },\n        )\n\ntests/layer/test_graph_attention.py:571: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n/usr/local/lib/python3.10/dist-packages/keras/src/models/model.py:886: in model_from_json\n    return serialization_lib.deserialize_keras_object(\n/usr/local/lib/python3.10/dist-packages/keras/src/saving/serialization_lib.py:733: in deserialize_keras_object\n    instance = cls.from_config(inner_config)\n/usr/local/lib/python3.10/dist-packages/keras/src/models/model.py:660: in from_config\n    return functional_from_config(\n/usr/local/lib/python3.10/dist-packages/keras/src/models/functional.py:558: in functional_from_config\n    process_layer(layer_data)\n/usr/local/lib/python3.10/dist-packages/keras/src/models/functional.py:525: in process_layer\n    layer = serialization_lib.deserialize_keras_object(\n/usr/local/lib/python3.10/dist-packages/keras/src/saving/serialization_lib.py:733: in deserialize_keras_object\n    instance = cls.from_config(inner_config)\n/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/lambda_layer.py:190: in from_config\n    cls._raise_for_lambda_deserialization(\"function\", safe_mode)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\narg_name = 'function', safe_mode = True\n\n    @staticmethod\n    def _raise_for_lambda_deserialization(arg_name, safe_mode):\n        if safe_mode:\n>           raise ValueError(\n                f\"The `{arg_name}` of this `Lambda` layer is a Python lambda. \"\n                \"Deserializing it is unsafe. If you trust the source of the \"\n                \"config artifact, you can override this error \"\n                \"by passing `safe_mode=False` \"\n                \"to `from_config()`, or calling \"\n                \"`keras.config.enable_unsafe_deserialization().\"\n            )\nE           ValueError: The `function` of this `Lambda` layer is a Python lambda. Deserializing it is unsafe. If you trust the source of the config artifact, you can override this error by passing `safe_mode=False` to `from_config()`, or calling `keras.config.enable_unsafe_deserialization().\n\n/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/lambda_layer.py:172: ValueError\n___________________________ Test_GAT.test_save_load ____________________________\n\nself = <tests.layer.test_graph_attention.Test_GAT object at 0x7fc1ac60f490>\ntmpdir = local('/tmp/pytest-of-root/pytest-1/test_save_load0')\n\n    def test_save_load(self, tmpdir):\n        graph = example_graph(feature_size=self.F_in)\n        gen = FullBatchNodeGenerator(graph, sparse=self.sparse, method=self.method)\n        gat = GAT(\n            layer_sizes=self.layer_sizes,\n            activations=self.activations,\n            attn_heads=self.attn_heads,\n            generator=gen,\n        )\n    \n>       test_utils.model_save_load(tmpdir, gat)\n\ntests/layer/test_graph_attention.py:622: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ntests/test_utils/__init__.py:43: in model_save_load\n    func(model, str(saved_dir))\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nmodel = <Functional name=functional_49, built=True>\nfilepath = '/tmp/pytest-of-root/pytest-1/test_save_load0/0', overwrite = True\nzipped = True, kwargs = {}, include_optimizer = True, save_format = False\nis_hf = False, exists = False\n\n    @keras_export([\"keras.saving.save_model\", \"keras.models.save_model\"])\n    def save_model(model, filepath, overwrite=True, zipped=None, **kwargs):\n        \"\"\"Saves a model as a `.keras` file.\n    \n        Args:\n            model: Keras model instance to be saved.\n            filepath: `str` or `pathlib.Path` object. Path where to save the model.\n            overwrite: Whether we should overwrite any existing model at the target\n                location, or instead ask the user via an interactive prompt.\n            zipped: Whether to save the model as a zipped `.keras`\n                archive (default when saving locally), or as an unzipped directory\n                (default when saving on the Hugging Face Hub).\n    \n        Example:\n    \n        ```python\n        model = keras.Sequential(\n            [\n                keras.layers.Dense(5, input_shape=(3,)),\n                keras.layers.Softmax(),\n            ],\n        )\n        model.save(\"model.keras\")\n        loaded_model = keras.saving.load_model(\"model.keras\")\n        x = keras.random.uniform((10, 3))\n        assert np.allclose(model.predict(x), loaded_model.predict(x))\n        ```\n    \n        Note that `model.save()` is an alias for `keras.saving.save_model()`.\n    \n        The saved `.keras` file is a `zip` archive that contains:\n    \n        - The model's configuration (architecture)\n        - The model's weights\n        - The model's optimizer's state (if any)\n    \n        Thus models can be reinstantiated in the exact same state.\n        \"\"\"\n        include_optimizer = kwargs.pop(\"include_optimizer\", True)\n        save_format = kwargs.pop(\"save_format\", False)\n        if save_format:\n            if str(filepath).endswith((\".h5\", \".hdf5\")) or str(filepath).endswith(\n                \".keras\"\n            ):\n                logging.warning(\n                    \"The `save_format` argument is deprecated in Keras 3. \"\n                    \"We recommend removing this argument as it can be inferred \"\n                    \"from the file path. \"\n                    f\"Received: save_format={save_format}\"\n                )\n            else:\n                raise ValueError(\n                    \"The `save_format` argument is deprecated in Keras 3. \"\n                    \"Please remove this argument and pass a file path with \"\n                    \"either `.keras` or `.h5` extension.\"\n                    f\"Received: save_format={save_format}\"\n                )\n        if kwargs:\n            raise ValueError(\n                \"The following argument(s) are not supported: \"\n                f\"{list(kwargs.keys())}\"\n            )\n    \n        # Deprecation warnings\n        if str(filepath).endswith((\".h5\", \".hdf5\")):\n            logging.warning(\n                \"You are saving your model as an HDF5 file via \"\n                \"`model.save()` or `keras.saving.save_model(model)`. \"\n                \"This file format is considered legacy. \"\n                \"We recommend using instead the native Keras format, \"\n                \"e.g. `model.save('my_model.keras')` or \"\n                \"`keras.saving.save_model(model, 'my_model.keras')`. \"\n            )\n    \n        is_hf = str(filepath).startswith(\"hf://\")\n        if zipped is None:\n            zipped = not is_hf  # default behavior depends on destination\n    \n        # If file exists and should not be overwritten.\n        try:\n            exists = (not is_hf) and os.path.exists(filepath)\n        except TypeError:\n            exists = False\n        if exists and not overwrite:\n            proceed = io_utils.ask_to_proceed_with_overwrite(filepath)\n            if not proceed:\n                return\n    \n        if zipped and str(filepath).endswith(\".keras\"):\n            return saving_lib.save_model(model, filepath)\n        if not zipped:\n            return saving_lib.save_model(model, filepath, zipped=False)\n        if str(filepath).endswith((\".h5\", \".hdf5\")):\n            return legacy_h5_format.save_model_to_hdf5(\n                model, filepath, overwrite, include_optimizer\n            )\n>       raise ValueError(\n            \"Invalid filepath extension for saving. \"\n            \"Please add either a `.keras` extension for the native Keras \"\n            f\"format (recommended) or a `.h5` extension. \"\n            \"Use `model.export(filepath)` if you want to export a SavedModel \"\n            \"for use with TFLite/TFServing/etc. \"\n            f\"Received: filepath={filepath}.\"\n        )\nE       ValueError: Invalid filepath extension for saving. Please add either a `.keras` extension for the native Keras format (recommended) or a `.h5` extension. Use `model.export(filepath)` if you want to export a SavedModel for use with TFLite/TFServing/etc. Received: filepath=/tmp/pytest-of-root/pytest-1/test_save_load0/0.\n\n/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_api.py:114: ValueError\n________________________________ test_stateful _________________________________\n\n    def test_stateful():\n        layer_sizes = [16, 2]\n        activations = [\"elu\", \"elu\"]\n        targets = np.array([[0, 1], [0, 1], [1, 0]])\n        train_graphs = [0, 1, 2]\n    \n        gcn_graph_model = GCNSupervisedGraphClassification(\n            generator=generator, activations=activations, layer_sizes=layer_sizes\n        )\n    \n        train_gen = generator.flow(graphs=train_graphs, targets=targets)\n    \n        model_1 = tf.keras.Model(*gcn_graph_model.in_out_tensors())\n        model_2 = tf.keras.Model(*gcn_graph_model.in_out_tensors())\n    \n        # check embeddings are equal before training\n>       embeddings_1 = model_1.predict(train_gen)\n\ntests/layer/test_graph_classification.py:114: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py:122: in error_handler\n    raise e.with_traceback(filtered_tb) from None\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\ngenerator = <bound method PyDatasetAdapter._get_iterator of <keras.src.trainers.data_adapters.py_dataset_adapter.PyDatasetAdapter object at 0x7fc1ac17d630>>\noutput_types = None, output_shapes = None, args = None\noutput_signature = ([TensorSpec(shape=(None, None, 4), dtype=tf.float32, name=None), TensorSpec(shape=(None, None), dtype=tf.bool, name=N...orSpec(shape=(None, None, None), dtype=tf.float64, name=None)], TensorSpec(shape=(None, 2), dtype=tf.int64, name=None))\nname = None\n\n    def _from_generator(generator, output_types, output_shapes, args,\n                        output_signature, name):\n      \"\"\"Creates a `Dataset` whose elements are generated by `generator`.\n    \n      Note: The current implementation of `Dataset.from_generator()` uses\n      `tf.numpy_function` and inherits the same constraints. In particular, it\n      requires the dataset and iterator related operations to be placed\n      on a device in the same process as the Python program that called\n      `Dataset.from_generator()`. In particular, using `from_generator` will\n      preclude the use of tf.data service for scaling out dataset processing.\n      The body of `generator` will not be serialized in a `GraphDef`, and you\n      should not use this method if you need to serialize your model and restore\n      it in a different environment.\n    \n      The `generator` argument must be a callable object that returns\n      an object that supports the `iter()` protocol (e.g. a generator function).\n    \n      The elements generated by `generator` must be compatible with either the\n      given `output_signature` argument or with the given `output_types` and\n      (optionally) `output_shapes` arguments, whichever was specified.\n    \n      The recommended way to call `from_generator` is to use the\n      `output_signature` argument. In this case the output will be assumed to\n      consist of objects with the classes, shapes and types defined by\n      `tf.TypeSpec` objects from `output_signature` argument:\n    \n      >>> def gen():\n      ...   ragged_tensor = tf.ragged.constant([[1, 2], [3]])\n      ...   yield 42, ragged_tensor\n      >>>\n      >>> dataset = tf.data.Dataset.from_generator(\n      ...      gen,\n      ...      output_signature=(\n      ...          tf.TensorSpec(shape=(), dtype=tf.int32),\n      ...          tf.RaggedTensorSpec(shape=(2, None), dtype=tf.int32)))\n      >>>\n      >>> list(dataset.take(1))\n      [(<tf.Tensor: shape=(), dtype=int32, numpy=42>,\n      <tf.RaggedTensor [[1, 2], [3]]>)]\n    \n      There is also a deprecated way to call `from_generator` by either with\n      `output_types` argument alone or together with `output_shapes` argument.\n      In this case the output of the function will be assumed to consist of\n      `tf.Tensor` objects with the types defined by `output_types` and with the\n      shapes which are either unknown or defined by `output_shapes`.\n    \n      Note: If `generator` depends on mutable global variables or other external\n      state, be aware that the runtime may invoke `generator` multiple times\n      (in order to support repeating the `Dataset`) and at any time\n      between the call to `Dataset.from_generator()` and the production of the\n      first element from the generator. Mutating global variables or external\n      state can cause undefined behavior, and we recommend that you explicitly\n      cache any external state in `generator` before calling\n      `Dataset.from_generator()`.\n    \n      Note: While the `output_signature` parameter makes it possible to yield\n      `Dataset` elements, the scope of `Dataset.from_generator()` should be\n      limited to logic that cannot be expressed through tf.data operations. Using\n      tf.data operations within the generator function is an anti-pattern and may\n      result in incremental memory growth.\n    \n      Args:\n        generator: A callable object that returns an object that supports the\n          `iter()` protocol. If `args` is not specified, `generator` must take no\n          arguments; otherwise it must take as many arguments as there are values in\n          `args`.\n        output_types: (Optional.) A (nested) structure of `tf.DType` objects\n          corresponding to each component of an element yielded by `generator`.\n        output_shapes: (Optional.) A (nested) structure of `tf.TensorShape` objects\n          corresponding to each component of an element yielded by `generator`.\n        args: (Optional.) A tuple of `tf.Tensor` objects that will be evaluated and\n          passed to `generator` as NumPy-array arguments.\n        output_signature: (Optional.) A (nested) structure of `tf.TypeSpec` objects\n          corresponding to each component of an element yielded by `generator`.\n        name: (Optional.) A name for the tf.data operations used by\n          `from_generator`.\n    \n      Returns:\n        Dataset: A `Dataset`.\n      \"\"\"\n      if not callable(generator):\n        raise TypeError(\"`generator` must be a Python callable.\")\n    \n      if output_signature is not None:\n        if output_types is not None:\n          raise TypeError(\"The `output_types` argument can not be used together \"\n                          \"with the `output_signature` argument.\")\n        if output_shapes is not None:\n          raise TypeError(\"The `output_shapes` argument can not be used together \"\n                          \"with the `output_signature` argument.\")\n        for spec in nest.flatten(output_signature):\n          if not isinstance(spec, type_spec.TypeSpec):\n>           raise TypeError(f\"`output_signature` must contain objects that are \"\n                            f\"subclass of `tf.TypeSpec` but found {type(spec)} \"\n                            f\"which is not.\")\nE           TypeError: `output_signature` must contain objects that are subclass of `tf.TypeSpec` but found <class 'list'> which is not.\n\n/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/from_generator_op.py:124: TypeError\n____________________________ test_pooling[default] _____________________________\n\npooling = 'default'\n\n    @pytest.mark.parametrize(\"pooling\", [\"default\", \"custom\"])\n    def test_pooling(pooling):\n    \n        # no GCN layers, to just test the pooling directly\n        if pooling == \"default\":\n            gcn_graph_model = GCNSupervisedGraphClassification(\n                layer_sizes=[], activations=[], generator=generator\n            )\n    \n            def expected_values(array):\n                return array.mean(axis=0)\n    \n        else:\n            # shift the features to make it a bit more interesting\n            shift = 10\n    \n            def shifted_sum_pooling(tensor, mask):\n                mask_floats = tf.expand_dims(tf.cast(mask, tf.float32), axis=-1)\n                return tf.math.reduce_sum(tf.multiply(mask_floats, shift + tensor), axis=1)\n    \n            gcn_graph_model = GCNSupervisedGraphClassification(\n                layer_sizes=[],\n                activations=[],\n                generator=generator,\n                pooling=shifted_sum_pooling,\n            )\n    \n            def expected_values(array):\n                return (shift + array).sum(axis=0)\n    \n        train_graphs = [0, 1, 2]\n        train_gen = generator.flow(graphs=train_graphs, batch_size=2, shuffle=False)\n>       model = tf.keras.Model(*gcn_graph_model.in_out_tensors())\n\ntests/layer/test_graph_classification.py:170: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n/usr/local/lib/python3.10/dist-packages/keras/src/utils/tracking.py:26: in wrapper\n    return fn(*args, **kwargs)\n/usr/local/lib/python3.10/dist-packages/keras/src/models/functional.py:136: in __init__\n    Function.__init__(self, inputs, outputs, name=name)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <Functional name=functional_52, built=False>\ninputs = [<KerasTensor shape=(None, None, 4), dtype=float32, sparse=False, ragged=False, name=keras_tensor_1292>, <KerasTensor ...ensor_1293>, <KerasTensor shape=(None, None, None), dtype=float32, sparse=False, ragged=False, name=keras_tensor_1294>]\noutputs = <KerasTensor shape=(None, 4), dtype=float32, sparse=False, ragged=False, name=keras_tensor_1295>\nname = None\n\n    def __init__(self, inputs, outputs, name=None):\n        super().__init__(name=name)\n    \n        if backend() == \"tensorflow\":\n            # Temporary work around for\n            # https://github.com/keras-team/keras/issues/931\n            # This stop tensorflow from wrapping tf.function output in a\n            # _DictWrapper object.\n            _self_setattr_tracking = getattr(\n                self, \"_self_setattr_tracking\", True\n            )\n            self._self_setattr_tracking = False\n        self._inputs_struct = tree.map_structure(lambda x: x, inputs)\n        self._outputs_struct = tree.map_structure(lambda x: x, outputs)\n        self._inputs = tree.flatten(inputs)\n        self._outputs = tree.flatten(outputs)\n        if not self._inputs:\n            raise ValueError(\n                \"`inputs` argument cannot be empty. Received:\\n\"\n                f\"inputs={inputs}\\n\"\n                f\"outputs={outputs}\"\n            )\n        if not self._outputs:\n            raise ValueError(\n                \"`outputs` argument cannot be empty. Received:\\n\"\n                f\"inputs={inputs}\\n\"\n                f\"outputs={outputs}\"\n            )\n    \n        if backend() == \"tensorflow\":\n            self._self_setattr_tracking = _self_setattr_tracking\n    \n        (nodes, nodes_by_depth, operations, operations_by_depth) = map_graph(\n            self._inputs, self._outputs\n        )\n        self._nodes = nodes\n        self._nodes_by_depth = nodes_by_depth\n        self._operations = operations\n        self._operations_by_depth = operations_by_depth\n        for input in self._inputs:\n            if (\n                input._keras_history.operation\n                and not input._keras_history.operation._outbound_nodes\n            ):\n>               raise ValueError(\"`inputs` not connected to `outputs`\")\nE               ValueError: `inputs` not connected to `outputs`\n\n/usr/local/lib/python3.10/dist-packages/keras/src/ops/function.py:90: ValueError\n_____________________________ test_pooling[custom] _____________________________\n\npooling = 'custom'\n\n    @pytest.mark.parametrize(\"pooling\", [\"default\", \"custom\"])\n    def test_pooling(pooling):\n    \n        # no GCN layers, to just test the pooling directly\n        if pooling == \"default\":\n            gcn_graph_model = GCNSupervisedGraphClassification(\n                layer_sizes=[], activations=[], generator=generator\n            )\n    \n            def expected_values(array):\n                return array.mean(axis=0)\n    \n        else:\n            # shift the features to make it a bit more interesting\n            shift = 10\n    \n            def shifted_sum_pooling(tensor, mask):\n                mask_floats = tf.expand_dims(tf.cast(mask, tf.float32), axis=-1)\n                return tf.math.reduce_sum(tf.multiply(mask_floats, shift + tensor), axis=1)\n    \n            gcn_graph_model = GCNSupervisedGraphClassification(\n                layer_sizes=[],\n                activations=[],\n                generator=generator,\n                pooling=shifted_sum_pooling,\n            )\n    \n            def expected_values(array):\n                return (shift + array).sum(axis=0)\n    \n        train_graphs = [0, 1, 2]\n        train_gen = generator.flow(graphs=train_graphs, batch_size=2, shuffle=False)\n>       model = tf.keras.Model(*gcn_graph_model.in_out_tensors())\n\ntests/layer/test_graph_classification.py:170: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/layer/graph_classification.py:223: in in_out_tensors\n    x_out = self(x_inp)\nstellargraph/layer/graph_classification.py:205: in __call__\n    h_layer = self.pooling(h_layer, mask=mask)\ntests/layer/test_graph_classification.py:155: in shifted_sum_pooling\n    mask_floats = tf.expand_dims(tf.cast(mask, tf.float32), axis=-1)\n/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py:153: in error_handler\n    raise e.with_traceback(filtered_tb) from None\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <KerasTensor shape=(None, None), dtype=bool, sparse=False, ragged=False, name=keras_tensor_1297>\ndtype = None, name = 'x'\n\n    def __tf_tensor__(self, dtype=None, name=None):\n>       raise ValueError(\n            \"A KerasTensor cannot be used as input to a TensorFlow function. \"\n            \"A KerasTensor is a symbolic placeholder for a shape and dtype, \"\n            \"used when constructing Keras Functional models \"\n            \"or Keras Functions. You can only use it as input to a Keras layer \"\n            \"or a Keras operation (from the namespaces `keras.layers` \"\n            \"and `keras.ops`). \"\n            \"You are likely doing something like:\\n\\n\"\n            \"```\\n\"\n            \"x = Input(...)\\n\"\n            \"...\\n\"\n            \"tf_fn(x)  # Invalid.\\n\"\n            \"```\\n\\n\"\n            \"What you should do instead is wrap `tf_fn` in a layer:\\n\\n\"\n            \"```\\n\"\n            \"class MyLayer(Layer):\\n\"\n            \"    def call(self, x):\\n\"\n            \"        return tf_fn(x)\\n\\n\"\n            \"x = MyLayer()(x)\\n\"\n            \"```\\n\"\n        )\nE       ValueError: A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.ops`). You are likely doing something like:\nE       \nE       ```\nE       x = Input(...)\nE       ...\nE       tf_fn(x)  # Invalid.\nE       ```\nE       \nE       What you should do instead is wrap `tf_fn` in a layer:\nE       \nE       ```\nE       class MyLayer(Layer):\nE           def call(self, x):\nE               return tf_fn(x)\nE       \nE       x = MyLayer()(x)\nE       ```\n\n/usr/local/lib/python3.10/dist-packages/keras/src/backend/common/keras_tensor.py:194: ValueError\n_____________________________ test_pool_all_layers _____________________________\n\n    def test_pool_all_layers():\n        gcn_graph_model = GCNSupervisedGraphClassification(\n            layer_sizes=[5, 7, 11, 1],\n            activations=[\"relu\", \"relu\", \"relu\", \"relu\"],\n            generator=generator,\n            pool_all_layers=True,\n        )\n    \n        train_graphs = [0, 1, 2]\n        train_gen = generator.flow(graphs=train_graphs, batch_size=2)\n>       model = tf.keras.Model(*gcn_graph_model.in_out_tensors())\n\ntests/layer/test_graph_classification.py:194: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/layer/graph_classification.py:223: in in_out_tensors\n    x_out = self(x_inp)\nstellargraph/layer/graph_classification.py:202: in __call__\n    h_layer = tf.concat(gcn_layers, axis=-1)\n/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py:153: in error_handler\n    raise e.with_traceback(filtered_tb) from None\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <KerasTensor shape=(None, None, 5), dtype=float32, sparse=False, ragged=False, name=keras_tensor_1303>\ndtype = None, name = None\n\n    def __tf_tensor__(self, dtype=None, name=None):\n>       raise ValueError(\n            \"A KerasTensor cannot be used as input to a TensorFlow function. \"\n            \"A KerasTensor is a symbolic placeholder for a shape and dtype, \"\n            \"used when constructing Keras Functional models \"\n            \"or Keras Functions. You can only use it as input to a Keras layer \"\n            \"or a Keras operation (from the namespaces `keras.layers` \"\n            \"and `keras.ops`). \"\n            \"You are likely doing something like:\\n\\n\"\n            \"```\\n\"\n            \"x = Input(...)\\n\"\n            \"...\\n\"\n            \"tf_fn(x)  # Invalid.\\n\"\n            \"```\\n\\n\"\n            \"What you should do instead is wrap `tf_fn` in a layer:\\n\\n\"\n            \"```\\n\"\n            \"class MyLayer(Layer):\\n\"\n            \"    def call(self, x):\\n\"\n            \"        return tf_fn(x)\\n\\n\"\n            \"x = MyLayer()(x)\\n\"\n            \"```\\n\"\n        )\nE       ValueError: A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.ops`). You are likely doing something like:\nE       \nE       ```\nE       x = Input(...)\nE       ...\nE       tf_fn(x)  # Invalid.\nE       ```\nE       \nE       What you should do instead is wrap `tf_fn` in a layer:\nE       \nE       ```\nE       class MyLayer(Layer):\nE           def call(self, x):\nE               return tf_fn(x)\nE       \nE       x = MyLayer()(x)\nE       ```\n\n/usr/local/lib/python3.10/dist-packages/keras/src/backend/common/keras_tensor.py:194: ValueError\n_______________________________ test_dgcnn_smoke _______________________________\n\n    def test_dgcnn_smoke():\n        # this is entirely implemented in terms of GCNSupervisedGraphClassification, and so it's enough\n        # to validate that the functionality is composed correctly.\n        dgcnn = DeepGraphCNN(\n            layer_sizes=[2, 3, 4],\n            activations=[\"relu\", \"relu\", \"relu\"],\n            # one graph is perfect, one graph requires padding and one requires truncation\n            k=5,\n            generator=generator,\n        )\n    \n        # validate the expectations of the implementation\n        assert isinstance(dgcnn, GCNSupervisedGraphClassification)\n        assert isinstance(dgcnn.pooling, SortPooling)\n        assert dgcnn.pool_all_layers == True\n    \n        # check it gives output of the expected shape\n>       model = tf.keras.Model(*dgcnn.in_out_tensors())\n\ntests/layer/test_graph_classification.py:217: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/layer/graph_classification.py:223: in in_out_tensors\n    x_out = self(x_inp)\nstellargraph/layer/graph_classification.py:202: in __call__\n    h_layer = tf.concat(gcn_layers, axis=-1)\n/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py:153: in error_handler\n    raise e.with_traceback(filtered_tb) from None\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <KerasTensor shape=(None, None, 2), dtype=float32, sparse=False, ragged=False, name=keras_tensor_1314>\ndtype = None, name = None\n\n    def __tf_tensor__(self, dtype=None, name=None):\n>       raise ValueError(\n            \"A KerasTensor cannot be used as input to a TensorFlow function. \"\n            \"A KerasTensor is a symbolic placeholder for a shape and dtype, \"\n            \"used when constructing Keras Functional models \"\n            \"or Keras Functions. You can only use it as input to a Keras layer \"\n            \"or a Keras operation (from the namespaces `keras.layers` \"\n            \"and `keras.ops`). \"\n            \"You are likely doing something like:\\n\\n\"\n            \"```\\n\"\n            \"x = Input(...)\\n\"\n            \"...\\n\"\n            \"tf_fn(x)  # Invalid.\\n\"\n            \"```\\n\\n\"\n            \"What you should do instead is wrap `tf_fn` in a layer:\\n\\n\"\n            \"```\\n\"\n            \"class MyLayer(Layer):\\n\"\n            \"    def call(self, x):\\n\"\n            \"        return tf_fn(x)\\n\\n\"\n            \"x = MyLayer()(x)\\n\"\n            \"```\\n\"\n        )\nE       ValueError: A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.ops`). You are likely doing something like:\nE       \nE       ```\nE       x = Input(...)\nE       ...\nE       tf_fn(x)  # Invalid.\nE       ```\nE       \nE       What you should do instead is wrap `tf_fn` in a layer:\nE       \nE       ```\nE       class MyLayer(Layer):\nE           def call(self, x):\nE               return tf_fn(x)\nE       \nE       x = MyLayer()(x)\nE       ```\n\n/usr/local/lib/python3.10/dist-packages/keras/src/backend/common/keras_tensor.py:194: ValueError\n________________________________ test_save_load ________________________________\n\ntmpdir = local('/tmp/pytest-of-root/pytest-1/test_save_load1')\n\n    def test_save_load(tmpdir):\n        layer_sizes = [16, 8]\n        activations = [\"relu\", \"relu\"]\n    \n        model = GCNSupervisedGraphClassification(\n            layer_sizes=layer_sizes, activations=activations, generator=generator\n        )\n>       test_utils.model_save_load(tmpdir, model)\n\ntests/layer/test_graph_classification.py:230: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ntests/test_utils/__init__.py:43: in model_save_load\n    func(model, str(saved_dir))\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nmodel = <Functional name=functional_53, built=True>\nfilepath = '/tmp/pytest-of-root/pytest-1/test_save_load1/0', overwrite = True\nzipped = True, kwargs = {}, include_optimizer = True, save_format = False\nis_hf = False, exists = False\n\n    @keras_export([\"keras.saving.save_model\", \"keras.models.save_model\"])\n    def save_model(model, filepath, overwrite=True, zipped=None, **kwargs):\n        \"\"\"Saves a model as a `.keras` file.\n    \n        Args:\n            model: Keras model instance to be saved.\n            filepath: `str` or `pathlib.Path` object. Path where to save the model.\n            overwrite: Whether we should overwrite any existing model at the target\n                location, or instead ask the user via an interactive prompt.\n            zipped: Whether to save the model as a zipped `.keras`\n                archive (default when saving locally), or as an unzipped directory\n                (default when saving on the Hugging Face Hub).\n    \n        Example:\n    \n        ```python\n        model = keras.Sequential(\n            [\n                keras.layers.Dense(5, input_shape=(3,)),\n                keras.layers.Softmax(),\n            ],\n        )\n        model.save(\"model.keras\")\n        loaded_model = keras.saving.load_model(\"model.keras\")\n        x = keras.random.uniform((10, 3))\n        assert np.allclose(model.predict(x), loaded_model.predict(x))\n        ```\n    \n        Note that `model.save()` is an alias for `keras.saving.save_model()`.\n    \n        The saved `.keras` file is a `zip` archive that contains:\n    \n        - The model's configuration (architecture)\n        - The model's weights\n        - The model's optimizer's state (if any)\n    \n        Thus models can be reinstantiated in the exact same state.\n        \"\"\"\n        include_optimizer = kwargs.pop(\"include_optimizer\", True)\n        save_format = kwargs.pop(\"save_format\", False)\n        if save_format:\n            if str(filepath).endswith((\".h5\", \".hdf5\")) or str(filepath).endswith(\n                \".keras\"\n            ):\n                logging.warning(\n                    \"The `save_format` argument is deprecated in Keras 3. \"\n                    \"We recommend removing this argument as it can be inferred \"\n                    \"from the file path. \"\n                    f\"Received: save_format={save_format}\"\n                )\n            else:\n                raise ValueError(\n                    \"The `save_format` argument is deprecated in Keras 3. \"\n                    \"Please remove this argument and pass a file path with \"\n                    \"either `.keras` or `.h5` extension.\"\n                    f\"Received: save_format={save_format}\"\n                )\n        if kwargs:\n            raise ValueError(\n                \"The following argument(s) are not supported: \"\n                f\"{list(kwargs.keys())}\"\n            )\n    \n        # Deprecation warnings\n        if str(filepath).endswith((\".h5\", \".hdf5\")):\n            logging.warning(\n                \"You are saving your model as an HDF5 file via \"\n                \"`model.save()` or `keras.saving.save_model(model)`. \"\n                \"This file format is considered legacy. \"\n                \"We recommend using instead the native Keras format, \"\n                \"e.g. `model.save('my_model.keras')` or \"\n                \"`keras.saving.save_model(model, 'my_model.keras')`. \"\n            )\n    \n        is_hf = str(filepath).startswith(\"hf://\")\n        if zipped is None:\n            zipped = not is_hf  # default behavior depends on destination\n    \n        # If file exists and should not be overwritten.\n        try:\n            exists = (not is_hf) and os.path.exists(filepath)\n        except TypeError:\n            exists = False\n        if exists and not overwrite:\n            proceed = io_utils.ask_to_proceed_with_overwrite(filepath)\n            if not proceed:\n                return\n    \n        if zipped and str(filepath).endswith(\".keras\"):\n            return saving_lib.save_model(model, filepath)\n        if not zipped:\n            return saving_lib.save_model(model, filepath, zipped=False)\n        if str(filepath).endswith((\".h5\", \".hdf5\")):\n            return legacy_h5_format.save_model_to_hdf5(\n                model, filepath, overwrite, include_optimizer\n            )\n>       raise ValueError(\n            \"Invalid filepath extension for saving. \"\n            \"Please add either a `.keras` extension for the native Keras \"\n            f\"format (recommended) or a `.h5` extension. \"\n            \"Use `model.export(filepath)` if you want to export a SavedModel \"\n            \"for use with TFLite/TFServing/etc. \"\n            f\"Received: filepath={filepath}.\"\n        )\nE       ValueError: Invalid filepath extension for saving. Please add either a `.keras` extension for the native Keras format (recommended) or a `.h5` extension. Use `model.export(filepath)` if you want to export a SavedModel for use with TFLite/TFServing/etc. Received: filepath=/tmp/pytest-of-root/pytest-1/test_save_load1/0.\n\n/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_api.py:114: ValueError\n__________________________ test_graphsage_constructor __________________________\n\n    def test_graphsage_constructor():\n>       gs = GraphSAGE(\n            layer_sizes=[4], n_samples=[2], input_dim=2, normalize=\"l2\", multiplicity=1\n        )\n\ntests/layer/test_graphsage.py:407: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/layer/graphsage.py:866: in __init__\n    self._compute_neighbourhood_sizes()\nstellargraph/layer/graphsage.py:951: in _compute_neighbourhood_sizes\n    self.neighbourhood_sizes = [size_at(i) for i in range(self.max_hops + 1)]\nstellargraph/layer/graphsage.py:951: in <listcomp>\n    self.neighbourhood_sizes = [size_at(i) for i in range(self.max_hops + 1)]\nstellargraph/layer/graphsage.py:949: in size_at\n    return np.product(self.n_samples[:i], dtype=int)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'product'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n            raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\n    \n        if attr == \"chararray\":\n            warnings.warn(\n                \"`np.chararray` is deprecated and will be removed from \"\n                \"the main namespace in the future. Use an array with a string \"\n                \"or bytes dtype instead.\", DeprecationWarning, stacklevel=2)\n            import numpy.char as char\n            return char.chararray\n    \n>       raise AttributeError(\"module {!r} has no attribute \"\n                             \"{!r}\".format(__name__, attr))\nE       AttributeError: module 'numpy' has no attribute 'product'\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:414: AttributeError\n________________ test_graphsage_constructor_passing_aggregator _________________\n\n    def test_graphsage_constructor_passing_aggregator():\n>       gs = GraphSAGE(\n            layer_sizes=[4],\n            n_samples=[2],\n            input_dim=2,\n            multiplicity=1,\n            aggregator=MeanAggregator,\n        )\n\ntests/layer/test_graphsage.py:457: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/layer/graphsage.py:866: in __init__\n    self._compute_neighbourhood_sizes()\nstellargraph/layer/graphsage.py:951: in _compute_neighbourhood_sizes\n    self.neighbourhood_sizes = [size_at(i) for i in range(self.max_hops + 1)]\nstellargraph/layer/graphsage.py:951: in <listcomp>\n    self.neighbourhood_sizes = [size_at(i) for i in range(self.max_hops + 1)]\nstellargraph/layer/graphsage.py:949: in size_at\n    return np.product(self.n_samples[:i], dtype=int)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'product'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n            raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\n    \n        if attr == \"chararray\":\n            warnings.warn(\n                \"`np.chararray` is deprecated and will be removed from \"\n                \"the main namespace in the future. Use an array with a string \"\n                \"or bytes dtype instead.\", DeprecationWarning, stacklevel=2)\n            import numpy.char as char\n            return char.chararray\n    \n>       raise AttributeError(\"module {!r} has no attribute \"\n                             \"{!r}\".format(__name__, attr))\nE       AttributeError: module 'numpy' has no attribute 'product'\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:414: AttributeError\n_________________________ test_graphsage_constructor_1 _________________________\n\n    def test_graphsage_constructor_1():\n>       gs = GraphSAGE(\n            layer_sizes=[4, 6, 8],\n            n_samples=[2, 4, 6],\n            input_dim=2,\n            multiplicity=1,\n            bias=True,\n            dropout=0.5,\n        )\n\ntests/layer/test_graphsage.py:477: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/layer/graphsage.py:866: in __init__\n    self._compute_neighbourhood_sizes()\nstellargraph/layer/graphsage.py:951: in _compute_neighbourhood_sizes\n    self.neighbourhood_sizes = [size_at(i) for i in range(self.max_hops + 1)]\nstellargraph/layer/graphsage.py:951: in <listcomp>\n    self.neighbourhood_sizes = [size_at(i) for i in range(self.max_hops + 1)]\nstellargraph/layer/graphsage.py:949: in size_at\n    return np.product(self.n_samples[:i], dtype=int)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'product'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n            raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\n    \n        if attr == \"chararray\":\n            warnings.warn(\n                \"`np.chararray` is deprecated and will be removed from \"\n                \"the main namespace in the future. Use an array with a string \"\n                \"or bytes dtype instead.\", DeprecationWarning, stacklevel=2)\n            import numpy.char as char\n            return char.chararray\n    \n>       raise AttributeError(\"module {!r} has no attribute \"\n                             \"{!r}\".format(__name__, attr))\nE       AttributeError: module 'numpy' has no attribute 'product'\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:414: AttributeError\n_____________________________ test_graphsage_apply _____________________________\n\n    def test_graphsage_apply():\n>       gs = GraphSAGE(\n            layer_sizes=[4],\n            n_samples=[2],\n            bias=False,\n            input_dim=2,\n            multiplicity=1,\n            normalize=None,\n            kernel_initializer=\"ones\",\n        )\n\ntests/layer/test_graphsage.py:493: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/layer/graphsage.py:866: in __init__\n    self._compute_neighbourhood_sizes()\nstellargraph/layer/graphsage.py:951: in _compute_neighbourhood_sizes\n    self.neighbourhood_sizes = [size_at(i) for i in range(self.max_hops + 1)]\nstellargraph/layer/graphsage.py:951: in <listcomp>\n    self.neighbourhood_sizes = [size_at(i) for i in range(self.max_hops + 1)]\nstellargraph/layer/graphsage.py:949: in size_at\n    return np.product(self.n_samples[:i], dtype=int)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'product'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n            raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\n    \n        if attr == \"chararray\":\n            warnings.warn(\n                \"`np.chararray` is deprecated and will be removed from \"\n                \"the main namespace in the future. Use an array with a string \"\n                \"or bytes dtype instead.\", DeprecationWarning, stacklevel=2)\n            import numpy.char as char\n            return char.chararray\n    \n>       raise AttributeError(\"module {!r} has no attribute \"\n                             \"{!r}\".format(__name__, attr))\nE       AttributeError: module 'numpy' has no attribute 'product'\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:414: AttributeError\n____________________________ test_graphsage_apply_1 ____________________________\n\n    def test_graphsage_apply_1():\n>       gs = GraphSAGE(\n            layer_sizes=[2, 2, 2],\n            n_samples=[2, 2, 2],\n            bias=False,\n            input_dim=2,\n            multiplicity=1,\n            normalize=None,\n            kernel_initializer=\"ones\",\n        )\n\ntests/layer/test_graphsage.py:510: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/layer/graphsage.py:866: in __init__\n    self._compute_neighbourhood_sizes()\nstellargraph/layer/graphsage.py:951: in _compute_neighbourhood_sizes\n    self.neighbourhood_sizes = [size_at(i) for i in range(self.max_hops + 1)]\nstellargraph/layer/graphsage.py:951: in <listcomp>\n    self.neighbourhood_sizes = [size_at(i) for i in range(self.max_hops + 1)]\nstellargraph/layer/graphsage.py:949: in size_at\n    return np.product(self.n_samples[:i], dtype=int)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'product'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n            raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\n    \n        if attr == \"chararray\":\n            warnings.warn(\n                \"`np.chararray` is deprecated and will be removed from \"\n                \"the main namespace in the future. Use an array with a string \"\n                \"or bytes dtype instead.\", DeprecationWarning, stacklevel=2)\n            import numpy.char as char\n            return char.chararray\n    \n>       raise AttributeError(\"module {!r} has no attribute \"\n                             \"{!r}\".format(__name__, attr))\nE       AttributeError: module 'numpy' has no attribute 'product'\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:414: AttributeError\n___________________________ test_graphsage_serialize ___________________________\n\n    def test_graphsage_serialize():\n>       gs = GraphSAGE(\n            layer_sizes=[4],\n            n_samples=[2],\n            bias=False,\n            input_dim=2,\n            multiplicity=1,\n            normalize=None,\n        )\n\ntests/layer/test_graphsage.py:542: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/layer/graphsage.py:866: in __init__\n    self._compute_neighbourhood_sizes()\nstellargraph/layer/graphsage.py:951: in _compute_neighbourhood_sizes\n    self.neighbourhood_sizes = [size_at(i) for i in range(self.max_hops + 1)]\nstellargraph/layer/graphsage.py:951: in <listcomp>\n    self.neighbourhood_sizes = [size_at(i) for i in range(self.max_hops + 1)]\nstellargraph/layer/graphsage.py:949: in size_at\n    return np.product(self.n_samples[:i], dtype=int)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'product'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n            raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\n    \n        if attr == \"chararray\":\n            warnings.warn(\n                \"`np.chararray` is deprecated and will be removed from \"\n                \"the main namespace in the future. Use an array with a string \"\n                \"or bytes dtype instead.\", DeprecationWarning, stacklevel=2)\n            import numpy.char as char\n            return char.chararray\n    \n>       raise AttributeError(\"module {!r} has no attribute \"\n                             \"{!r}\".format(__name__, attr))\nE       AttributeError: module 'numpy' has no attribute 'product'\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:414: AttributeError\n________________________ test_graphsage_zero_neighbours ________________________\n\n    def test_graphsage_zero_neighbours():\n>       gs = GraphSAGE(\n            layer_sizes=[2, 2],\n            n_samples=[0, 0],\n            bias=False,\n            input_dim=2,\n            multiplicity=1,\n            normalize=\"none\",\n            kernel_initializer=\"ones\",\n        )\n\ntests/layer/test_graphsage.py:578: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/layer/graphsage.py:866: in __init__\n    self._compute_neighbourhood_sizes()\nstellargraph/layer/graphsage.py:951: in _compute_neighbourhood_sizes\n    self.neighbourhood_sizes = [size_at(i) for i in range(self.max_hops + 1)]\nstellargraph/layer/graphsage.py:951: in <listcomp>\n    self.neighbourhood_sizes = [size_at(i) for i in range(self.max_hops + 1)]\nstellargraph/layer/graphsage.py:949: in size_at\n    return np.product(self.n_samples[:i], dtype=int)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'product'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n            raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\n    \n        if attr == \"chararray\":\n            warnings.warn(\n                \"`np.chararray` is deprecated and will be removed from \"\n                \"the main namespace in the future. Use an array with a string \"\n                \"or bytes dtype instead.\", DeprecationWarning, stacklevel=2)\n            import numpy.char as char\n            return char.chararray\n    \n>       raise AttributeError(\"module {!r} has no attribute \"\n                             \"{!r}\".format(__name__, attr))\nE       AttributeError: module 'numpy' has no attribute 'product'\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:414: AttributeError\n______________________ test_graphsage_passing_activations ______________________\n\n    def test_graphsage_passing_activations():\n>       gs = GraphSAGE(layer_sizes=[4], n_samples=[2], input_dim=2, multiplicity=1)\n\ntests/layer/test_graphsage.py:600: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/layer/graphsage.py:866: in __init__\n    self._compute_neighbourhood_sizes()\nstellargraph/layer/graphsage.py:951: in _compute_neighbourhood_sizes\n    self.neighbourhood_sizes = [size_at(i) for i in range(self.max_hops + 1)]\nstellargraph/layer/graphsage.py:951: in <listcomp>\n    self.neighbourhood_sizes = [size_at(i) for i in range(self.max_hops + 1)]\nstellargraph/layer/graphsage.py:949: in size_at\n    return np.product(self.n_samples[:i], dtype=int)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'product'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n            raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\n    \n        if attr == \"chararray\":\n            warnings.warn(\n                \"`np.chararray` is deprecated and will be removed from \"\n                \"the main namespace in the future. Use an array with a string \"\n                \"or bytes dtype instead.\", DeprecationWarning, stacklevel=2)\n            import numpy.char as char\n            return char.chararray\n    \n>       raise AttributeError(\"module {!r} has no attribute \"\n                             \"{!r}\".format(__name__, attr))\nE       AttributeError: module 'numpy' has no attribute 'product'\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:414: AttributeError\n_____________________ test_graphsage_passing_regularisers ______________________\n\n    def test_graphsage_passing_regularisers():\n        with pytest.raises(ValueError):\n>           GraphSAGE(\n                layer_sizes=[4],\n                n_samples=[2],\n                input_dim=2,\n                multiplicity=1,\n                kernel_initializer=\"fred\",\n            )\n\ntests/layer/test_graphsage.py:650: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/layer/graphsage.py:866: in __init__\n    self._compute_neighbourhood_sizes()\nstellargraph/layer/graphsage.py:951: in _compute_neighbourhood_sizes\n    self.neighbourhood_sizes = [size_at(i) for i in range(self.max_hops + 1)]\nstellargraph/layer/graphsage.py:951: in <listcomp>\n    self.neighbourhood_sizes = [size_at(i) for i in range(self.max_hops + 1)]\nstellargraph/layer/graphsage.py:949: in size_at\n    return np.product(self.n_samples[:i], dtype=int)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'product'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n            raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\n    \n        if attr == \"chararray\":\n            warnings.warn(\n                \"`np.chararray` is deprecated and will be removed from \"\n                \"the main namespace in the future. Use an array with a string \"\n                \"or bytes dtype instead.\", DeprecationWarning, stacklevel=2)\n            import numpy.char as char\n            return char.chararray\n    \n>       raise AttributeError(\"module {!r} has no attribute \"\n                             \"{!r}\".format(__name__, attr))\nE       AttributeError: module 'numpy' has no attribute 'product'\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:414: AttributeError\n________________________ test_kernel_and_bias_defaults _________________________\n\n    def test_kernel_and_bias_defaults():\n>       gs = GraphSAGE(layer_sizes=[4, 4], n_samples=[2, 2], input_dim=2, multiplicity=1)\n\ntests/layer/test_graphsage.py:693: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/layer/graphsage.py:866: in __init__\n    self._compute_neighbourhood_sizes()\nstellargraph/layer/graphsage.py:951: in _compute_neighbourhood_sizes\n    self.neighbourhood_sizes = [size_at(i) for i in range(self.max_hops + 1)]\nstellargraph/layer/graphsage.py:951: in <listcomp>\n    self.neighbourhood_sizes = [size_at(i) for i in range(self.max_hops + 1)]\nstellargraph/layer/graphsage.py:949: in size_at\n    return np.product(self.n_samples[:i], dtype=int)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'product'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n            raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\n    \n        if attr == \"chararray\":\n            warnings.warn(\n                \"`np.chararray` is deprecated and will be removed from \"\n                \"the main namespace in the future. Use an array with a string \"\n                \"or bytes dtype instead.\", DeprecationWarning, stacklevel=2)\n            import numpy.char as char\n            return char.chararray\n    \n>       raise AttributeError(\"module {!r} has no attribute \"\n                             \"{!r}\".format(__name__, attr))\nE       AttributeError: module 'numpy' has no attribute 'product'\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:414: AttributeError\n___________________________ test_graphsage_save_load ___________________________\n\ntmpdir = local('/tmp/pytest-of-root/pytest-1/test_graphsage_save_load0')\n\n    def test_graphsage_save_load(tmpdir):\n>       gs = GraphSAGE(layer_sizes=[4, 4], n_samples=[2, 2], input_dim=2, multiplicity=1)\n\ntests/layer/test_graphsage.py:704: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/layer/graphsage.py:866: in __init__\n    self._compute_neighbourhood_sizes()\nstellargraph/layer/graphsage.py:951: in _compute_neighbourhood_sizes\n    self.neighbourhood_sizes = [size_at(i) for i in range(self.max_hops + 1)]\nstellargraph/layer/graphsage.py:951: in <listcomp>\n    self.neighbourhood_sizes = [size_at(i) for i in range(self.max_hops + 1)]\nstellargraph/layer/graphsage.py:949: in size_at\n    return np.product(self.n_samples[:i], dtype=int)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'product'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n            raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\n    \n        if attr == \"chararray\":\n            warnings.warn(\n                \"`np.chararray` is deprecated and will be removed from \"\n                \"the main namespace in the future. Use an array with a string \"\n                \"or bytes dtype instead.\", DeprecationWarning, stacklevel=2)\n            import numpy.char as char\n            return char.chararray\n    \n>       raise AttributeError(\"module {!r} has no attribute \"\n                             \"{!r}\".format(__name__, attr))\nE       AttributeError: module 'numpy' has no attribute 'product'\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:414: AttributeError\n_______________________ test_mean_hin_agg_constructor_1 ________________________\n\n    def test_mean_hin_agg_constructor_1():\n        agg = MeanHinAggregator(output_dim=2, bias=True, act=lambda x: x + 1)\n        assert agg.output_dim == 2\n        assert agg.half_output_dim == 1\n        assert agg.has_bias\n        assert agg.act(2) == 3\n    \n        # Check config\n        config = agg.get_config()\n        assert config[\"output_dim\"] == 2\n        assert config[\"bias\"] == True\n>       assert config[\"act\"] == \"<lambda>\"\nE       AssertionError: assert {'value': ('4wEAAAAAAAAAAAAAAAEAAAACAAAAUwAAAPMIAAAAfABkARcAUwCpAk7pAQAAAKkAKQHaAXhyBAAA\\nAHIEAAAA+jAvYXBwL3JlcG9fdG9fcHJvY2Vzcy90ZXN0cy9sYXllci90ZXN0X2hpbnNhZ2UucHna\\nCDxsYW1iZGE+KwAAAPMCAAAACAA=\\n', None, None)} == '<lambda>'\n\ntests/layer/test_hinsage.py:53: AssertionError\n____________________________ test_hinsage_serialize ____________________________\n\n    def test_hinsage_serialize():\n        hs = HinSAGE(\n            layer_sizes=[2, 2],\n            n_samples=[2, 2],\n            input_neighbor_tree=[\n                (\"1\", [1, 2]),\n                (\"1\", [3, 4]),\n                (\"2\", [5]),\n                (\"1\", []),\n                (\"2\", []),\n                (\"2\", []),\n            ],\n            multiplicity=1,\n            input_dim={\"1\": 2, \"2\": 4},\n            normalize=\"none\",\n            bias=False,\n        )\n        xin, xout = hs.in_out_tensors()\n        model = keras.Model(inputs=xin, outputs=xout)\n    \n        # Save model\n        model_json = model.to_json()\n    \n        # Set all weights to one\n        model_weights = [np.ones_like(w) for w in model.get_weights()]\n    \n        # Load model from json & set all weights\n>       model2 = keras.models.model_from_json(\n            model_json, custom_objects={\"MeanHinAggregator\": MeanHinAggregator}\n        )\n\ntests/layer/test_hinsage.py:336: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n/usr/local/lib/python3.10/dist-packages/keras/src/models/model.py:886: in model_from_json\n    return serialization_lib.deserialize_keras_object(\n/usr/local/lib/python3.10/dist-packages/keras/src/saving/serialization_lib.py:733: in deserialize_keras_object\n    instance = cls.from_config(inner_config)\n/usr/local/lib/python3.10/dist-packages/keras/src/models/model.py:660: in from_config\n    return functional_from_config(\n/usr/local/lib/python3.10/dist-packages/keras/src/models/functional.py:558: in functional_from_config\n    process_layer(layer_data)\n/usr/local/lib/python3.10/dist-packages/keras/src/models/functional.py:525: in process_layer\n    layer = serialization_lib.deserialize_keras_object(\n/usr/local/lib/python3.10/dist-packages/keras/src/saving/serialization_lib.py:733: in deserialize_keras_object\n    instance = cls.from_config(inner_config)\n/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/lambda_layer.py:190: in from_config\n    cls._raise_for_lambda_deserialization(\"function\", safe_mode)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\narg_name = 'function', safe_mode = True\n\n    @staticmethod\n    def _raise_for_lambda_deserialization(arg_name, safe_mode):\n        if safe_mode:\n>           raise ValueError(\n                f\"The `{arg_name}` of this `Lambda` layer is a Python lambda. \"\n                \"Deserializing it is unsafe. If you trust the source of the \"\n                \"config artifact, you can override this error \"\n                \"by passing `safe_mode=False` \"\n                \"to `from_config()`, or calling \"\n                \"`keras.config.enable_unsafe_deserialization().\"\n            )\nE           ValueError: The `function` of this `Lambda` layer is a Python lambda. Deserializing it is unsafe. If you trust the source of the config artifact, you can override this error by passing `safe_mode=False` to `from_config()`, or calling `keras.config.enable_unsafe_deserialization().\n\n/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/lambda_layer.py:172: ValueError\n____________________________ test_hinsage_save_load ____________________________\n\ntmpdir = local('/tmp/pytest-of-root/pytest-1/test_hinsage_save_load0')\n\n    def test_hinsage_save_load(tmpdir):\n        G = example_hin_1({\"A\": 8, \"B\": 4})\n    \n        gen = HinSAGENodeGenerator(G, 1, [2, 2], \"A\")\n    \n        hs = HinSAGE(\n            layer_sizes=[2, 2],\n            generator=gen,\n            normalize=\"none\",\n            activations=[\"relu\", \"relu\"],\n        )\n    \n>       test_utils.model_save_load(tmpdir, hs)\n\ntests/layer/test_hinsage.py:653: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ntests/test_utils/__init__.py:43: in model_save_load\n    func(model, str(saved_dir))\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nmodel = <Functional name=functional_74, built=True>\nfilepath = '/tmp/pytest-of-root/pytest-1/test_hinsage_save_load0/0'\noverwrite = True, zipped = True, kwargs = {}, include_optimizer = True\nsave_format = False, is_hf = False, exists = False\n\n    @keras_export([\"keras.saving.save_model\", \"keras.models.save_model\"])\n    def save_model(model, filepath, overwrite=True, zipped=None, **kwargs):\n        \"\"\"Saves a model as a `.keras` file.\n    \n        Args:\n            model: Keras model instance to be saved.\n            filepath: `str` or `pathlib.Path` object. Path where to save the model.\n            overwrite: Whether we should overwrite any existing model at the target\n                location, or instead ask the user via an interactive prompt.\n            zipped: Whether to save the model as a zipped `.keras`\n                archive (default when saving locally), or as an unzipped directory\n                (default when saving on the Hugging Face Hub).\n    \n        Example:\n    \n        ```python\n        model = keras.Sequential(\n            [\n                keras.layers.Dense(5, input_shape=(3,)),\n                keras.layers.Softmax(),\n            ],\n        )\n        model.save(\"model.keras\")\n        loaded_model = keras.saving.load_model(\"model.keras\")\n        x = keras.random.uniform((10, 3))\n        assert np.allclose(model.predict(x), loaded_model.predict(x))\n        ```\n    \n        Note that `model.save()` is an alias for `keras.saving.save_model()`.\n    \n        The saved `.keras` file is a `zip` archive that contains:\n    \n        - The model's configuration (architecture)\n        - The model's weights\n        - The model's optimizer's state (if any)\n    \n        Thus models can be reinstantiated in the exact same state.\n        \"\"\"\n        include_optimizer = kwargs.pop(\"include_optimizer\", True)\n        save_format = kwargs.pop(\"save_format\", False)\n        if save_format:\n            if str(filepath).endswith((\".h5\", \".hdf5\")) or str(filepath).endswith(\n                \".keras\"\n            ):\n                logging.warning(\n                    \"The `save_format` argument is deprecated in Keras 3. \"\n                    \"We recommend removing this argument as it can be inferred \"\n                    \"from the file path. \"\n                    f\"Received: save_format={save_format}\"\n                )\n            else:\n                raise ValueError(\n                    \"The `save_format` argument is deprecated in Keras 3. \"\n                    \"Please remove this argument and pass a file path with \"\n                    \"either `.keras` or `.h5` extension.\"\n                    f\"Received: save_format={save_format}\"\n                )\n        if kwargs:\n            raise ValueError(\n                \"The following argument(s) are not supported: \"\n                f\"{list(kwargs.keys())}\"\n            )\n    \n        # Deprecation warnings\n        if str(filepath).endswith((\".h5\", \".hdf5\")):\n            logging.warning(\n                \"You are saving your model as an HDF5 file via \"\n                \"`model.save()` or `keras.saving.save_model(model)`. \"\n                \"This file format is considered legacy. \"\n                \"We recommend using instead the native Keras format, \"\n                \"e.g. `model.save('my_model.keras')` or \"\n                \"`keras.saving.save_model(model, 'my_model.keras')`. \"\n            )\n    \n        is_hf = str(filepath).startswith(\"hf://\")\n        if zipped is None:\n            zipped = not is_hf  # default behavior depends on destination\n    \n        # If file exists and should not be overwritten.\n        try:\n            exists = (not is_hf) and os.path.exists(filepath)\n        except TypeError:\n            exists = False\n        if exists and not overwrite:\n            proceed = io_utils.ask_to_proceed_with_overwrite(filepath)\n            if not proceed:\n                return\n    \n        if zipped and str(filepath).endswith(\".keras\"):\n            return saving_lib.save_model(model, filepath)\n        if not zipped:\n            return saving_lib.save_model(model, filepath, zipped=False)\n        if str(filepath).endswith((\".h5\", \".hdf5\")):\n            return legacy_h5_format.save_model_to_hdf5(\n                model, filepath, overwrite, include_optimizer\n            )\n>       raise ValueError(\n            \"Invalid filepath extension for saving. \"\n            \"Please add either a `.keras` extension for the native Keras \"\n            f\"format (recommended) or a `.h5` extension. \"\n            \"Use `model.export(filepath)` if you want to export a SavedModel \"\n            \"for use with TFLite/TFServing/etc. \"\n            f\"Received: filepath={filepath}.\"\n        )\nE       ValueError: Invalid filepath extension for saving. Please add either a `.keras` extension for the native Keras format (recommended) or a `.h5` extension. Use `model.export(filepath)` if you want to export a SavedModel for use with TFLite/TFServing/etc. Received: filepath=/tmp/pytest-of-root/pytest-1/test_hinsage_save_load0/0.\n\n/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_api.py:114: ValueError\n____________________________ test_complex[uniform] _____________________________\n\nknowledge_graph = <stellargraph.core.graph.StellarDiGraph object at 0x7fc18c44bf40>\nsample_strategy = 'uniform'\n\n    @pytest.mark.parametrize(\"sample_strategy\", [\"uniform\", \"self-adversarial\"])\n    def test_complex(knowledge_graph, sample_strategy):\n        # this test creates a random untrained model and predicts every possible edge in the graph, and\n        # compares that to a direct implementation of the scoring method in the paper\n        gen = KGTripleGenerator(knowledge_graph, 3)\n    \n        # use a random initializer with a large positive range, so that any differences are obvious\n        init = initializers.RandomUniform(-1, 1)\n        complex_model = ComplEx(gen, 5, embeddings_initializer=init)\n>       x_inp, x_out = complex_model.in_out_tensors()\n\ntests/layer/test_knowledge_graph.py:65: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/layer/knowledge_graph.py:157: in in_out_tensors\n    s_iloc = Input(shape=1)\n/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:209: in Input\n    layer = InputLayer(\n/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:92: in __init__\n    shape = backend.standardize_shape(shape)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nshape = 1\n\n    def standardize_shape(shape):\n        if not isinstance(shape, tuple):\n            if shape is None:\n                raise ValueError(\"Undefined shapes are not supported.\")\n            if not hasattr(shape, \"__iter__\"):\n>               raise ValueError(f\"Cannot convert '{shape}' to a shape.\")\nE               ValueError: Cannot convert '1' to a shape.\n\n/usr/local/lib/python3.10/dist-packages/keras/src/backend/common/variables.py:592: ValueError\n________________________ test_complex[self-adversarial] ________________________\n\nknowledge_graph = <stellargraph.core.graph.StellarDiGraph object at 0x7fc1ac2aac50>\nsample_strategy = 'self-adversarial'\n\n    @pytest.mark.parametrize(\"sample_strategy\", [\"uniform\", \"self-adversarial\"])\n    def test_complex(knowledge_graph, sample_strategy):\n        # this test creates a random untrained model and predicts every possible edge in the graph, and\n        # compares that to a direct implementation of the scoring method in the paper\n        gen = KGTripleGenerator(knowledge_graph, 3)\n    \n        # use a random initializer with a large positive range, so that any differences are obvious\n        init = initializers.RandomUniform(-1, 1)\n        complex_model = ComplEx(gen, 5, embeddings_initializer=init)\n>       x_inp, x_out = complex_model.in_out_tensors()\n\ntests/layer/test_knowledge_graph.py:65: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/layer/knowledge_graph.py:157: in in_out_tensors\n    s_iloc = Input(shape=1)\n/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:209: in Input\n    layer = InputLayer(\n/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:92: in __init__\n    shape = backend.standardize_shape(shape)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nshape = 1\n\n    def standardize_shape(shape):\n        if not isinstance(shape, tuple):\n            if shape is None:\n                raise ValueError(\"Undefined shapes are not supported.\")\n            if not hasattr(shape, \"__iter__\"):\n>               raise ValueError(f\"Cannot convert '{shape}' to a shape.\")\nE               ValueError: Cannot convert '1' to a shape.\n\n/usr/local/lib/python3.10/dist-packages/keras/src/backend/common/variables.py:592: ValueError\n________________________________ test_distmult _________________________________\n\nknowledge_graph = <stellargraph.core.graph.StellarDiGraph object at 0x7fc17878dc60>\n\n    def test_distmult(knowledge_graph):\n        # this test creates a random untrained model and predicts every possible edge in the graph, and\n        # compares that to a direct implementation of the scoring method in the paper\n        gen = KGTripleGenerator(knowledge_graph, 3)\n    \n        # use a random initializer with a large range, so that any differences are obvious\n        init = initializers.RandomUniform(-1, 1)\n        distmult_model = DistMult(gen, 5, embeddings_initializer=init)\n>       x_inp, x_out = distmult_model.in_out_tensors()\n\ntests/layer/test_knowledge_graph.py:124: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/layer/knowledge_graph.py:157: in in_out_tensors\n    s_iloc = Input(shape=1)\n/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:209: in Input\n    layer = InputLayer(\n/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:92: in __init__\n    shape = backend.standardize_shape(shape)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nshape = 1\n\n    def standardize_shape(shape):\n        if not isinstance(shape, tuple):\n            if shape is None:\n                raise ValueError(\"Undefined shapes are not supported.\")\n            if not hasattr(shape, \"__iter__\"):\n>               raise ValueError(f\"Cannot convert '{shape}' to a shape.\")\nE               ValueError: Cannot convert '1' to a shape.\n\n/usr/local/lib/python3.10/dist-packages/keras/src/backend/common/variables.py:592: ValueError\n_________________________________ test_rotate __________________________________\n\nknowledge_graph = <stellargraph.core.graph.StellarDiGraph object at 0x7fc145445090>\n\n    @test_utils.flaky_xfail_mark(AssertionError, 1623)\n    def test_rotate(knowledge_graph):\n        margin = 2.34\n        norm_order = 1.234\n    \n        # this test creates a random untrained model and predicts every possible edge in the graph, and\n        # compares that to a direct implementation of the scoring method in the paper\n        gen = KGTripleGenerator(knowledge_graph, 3)\n    \n        # use a random initializer with a large range, so that any differences are obvious\n        init = initializers.RandomUniform(-1, 1)\n        rotate_model = RotatE(\n            gen, 5, margin=margin, norm_order=norm_order, embeddings_initializer=init\n        )\n>       x_inp, x_out = rotate_model.in_out_tensors()\n\ntests/layer/test_knowledge_graph.py:183: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/layer/knowledge_graph.py:157: in in_out_tensors\n    s_iloc = Input(shape=1)\n/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:209: in Input\n    layer = InputLayer(\n/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:92: in __init__\n    shape = backend.standardize_shape(shape)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nshape = 1\n\n    def standardize_shape(shape):\n        if not isinstance(shape, tuple):\n            if shape is None:\n                raise ValueError(\"Undefined shapes are not supported.\")\n            if not hasattr(shape, \"__iter__\"):\n>               raise ValueError(f\"Cannot convert '{shape}' to a shape.\")\nE               ValueError: Cannot convert '1' to a shape.\n\n/usr/local/lib/python3.10/dist-packages/keras/src/backend/common/variables.py:592: ValueError\n_____________________________ test_rote_roth[RotE] _____________________________\n\nknowledge_graph = <stellargraph.core.graph.StellarDiGraph object at 0x7fc1ac2e1420>\nmodel_class = <class 'stellargraph.layer.knowledge_graph.RotE'>\n\n    @pytest.mark.parametrize(\"model_class\", [RotE, RotH])\n    def test_rote_roth(knowledge_graph, model_class):\n        # this test creates a random untrained model and predicts every possible edge in the graph, and\n        # compares that to a direct implementation of the scoring method in the paper\n        gen = KGTripleGenerator(knowledge_graph, 3)\n    \n        # use a random initializer with a large range, so that any differences are obvious\n        init = initializers.RandomUniform(-1, 1)\n        rot_model = model_class(gen, 6, embeddings_initializer=init)\n>       x_inp, x_out = rot_model.in_out_tensors()\n\ntests/layer/test_knowledge_graph.py:241: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/layer/knowledge_graph.py:157: in in_out_tensors\n    s_iloc = Input(shape=1)\n/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:209: in Input\n    layer = InputLayer(\n/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:92: in __init__\n    shape = backend.standardize_shape(shape)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nshape = 1\n\n    def standardize_shape(shape):\n        if not isinstance(shape, tuple):\n            if shape is None:\n                raise ValueError(\"Undefined shapes are not supported.\")\n            if not hasattr(shape, \"__iter__\"):\n>               raise ValueError(f\"Cannot convert '{shape}' to a shape.\")\nE               ValueError: Cannot convert '1' to a shape.\n\n/usr/local/lib/python3.10/dist-packages/keras/src/backend/common/variables.py:592: ValueError\n_____________________________ test_rote_roth[RotH] _____________________________\n\nknowledge_graph = <stellargraph.core.graph.StellarDiGraph object at 0x7fc1ac2aa170>\nmodel_class = <class 'stellargraph.layer.knowledge_graph.RotH'>\n\n    @pytest.mark.parametrize(\"model_class\", [RotE, RotH])\n    def test_rote_roth(knowledge_graph, model_class):\n        # this test creates a random untrained model and predicts every possible edge in the graph, and\n        # compares that to a direct implementation of the scoring method in the paper\n        gen = KGTripleGenerator(knowledge_graph, 3)\n    \n        # use a random initializer with a large range, so that any differences are obvious\n        init = initializers.RandomUniform(-1, 1)\n        rot_model = model_class(gen, 6, embeddings_initializer=init)\n>       x_inp, x_out = rot_model.in_out_tensors()\n\ntests/layer/test_knowledge_graph.py:241: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/layer/knowledge_graph.py:157: in in_out_tensors\n    s_iloc = Input(shape=1)\n/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:209: in Input\n    layer = InputLayer(\n/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:92: in __init__\n    shape = backend.standardize_shape(shape)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nshape = 1\n\n    def standardize_shape(shape):\n        if not isinstance(shape, tuple):\n            if shape is None:\n                raise ValueError(\"Undefined shapes are not supported.\")\n            if not hasattr(shape, \"__iter__\"):\n>               raise ValueError(f\"Cannot convert '{shape}' to a shape.\")\nE               ValueError: Cannot convert '1' to a shape.\n\n/usr/local/lib/python3.10/dist-packages/keras/src/backend/common/variables.py:592: ValueError\n_________________________ test_model_rankings[ComplEx] _________________________\n\nmodel_maker = <class 'stellargraph.layer.knowledge_graph.ComplEx'>\n\n    @pytest.mark.parametrize(\n        \"model_maker\",\n        [\n            ComplEx,\n            DistMult,\n            pytest.param(RotatE, marks=test_utils.flaky_xfail_mark(AssertionError, 1623)),\n            pytest.param(RotH, marks=test_utils.flaky_xfail_mark(AssertionError, 1675)),\n            RotE,\n        ],\n    )\n    def test_model_rankings(model_maker):\n        nodes = pd.DataFrame(index=[\"a\", \"b\", \"c\", \"d\"])\n        rels = [\"W\", \"X\", \"Y\", \"Z\"]\n        empty = pd.DataFrame(columns=[\"source\", \"target\"])\n    \n        every_edge = itertools.product(nodes.index, rels, nodes.index)\n        every_edge_df = triple_df(*every_edge)\n    \n        no_edges = StellarDiGraph(nodes, {name: empty for name in rels})\n    \n        # the filtering is most interesting when there's a smattering of edges, somewhere between none\n        # and all; this does a stratified sample by label, to make sure there's at least one edge from\n        # each label.\n        one_per_label_df = (\n            every_edge_df.groupby(\"label\").apply(lambda df: df.sample(n=1)).droplevel(0)\n        )\n        others_df = every_edge_df.sample(frac=0.25)\n        some_edges_df = pd.concat([one_per_label_df, others_df], ignore_index=True)\n    \n        some_edges = StellarDiGraph(\n            nodes,\n            {name: df.drop(columns=\"label\") for name, df in some_edges_df.groupby(\"label\")},\n        )\n    \n        all_edges = StellarDiGraph(\n            nodes=nodes,\n            edges={\n                name: df.drop(columns=\"label\")\n                for name, df in every_edge_df.groupby(\"label\")\n            },\n        )\n    \n        gen = KGTripleGenerator(all_edges, 3)\n        sg_model = model_maker(gen, embedding_dimension=6)\n>       x_inp, x_out = sg_model.in_out_tensors()\n\ntests/layer/test_knowledge_graph.py:341: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/layer/knowledge_graph.py:157: in in_out_tensors\n    s_iloc = Input(shape=1)\n/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:209: in Input\n    layer = InputLayer(\n/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:92: in __init__\n    shape = backend.standardize_shape(shape)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nshape = 1\n\n    def standardize_shape(shape):\n        if not isinstance(shape, tuple):\n            if shape is None:\n                raise ValueError(\"Undefined shapes are not supported.\")\n            if not hasattr(shape, \"__iter__\"):\n>               raise ValueError(f\"Cannot convert '{shape}' to a shape.\")\nE               ValueError: Cannot convert '1' to a shape.\n\n/usr/local/lib/python3.10/dist-packages/keras/src/backend/common/variables.py:592: ValueError\n________________________ test_model_rankings[DistMult] _________________________\n\nmodel_maker = <class 'stellargraph.layer.knowledge_graph.DistMult'>\n\n    @pytest.mark.parametrize(\n        \"model_maker\",\n        [\n            ComplEx,\n            DistMult,\n            pytest.param(RotatE, marks=test_utils.flaky_xfail_mark(AssertionError, 1623)),\n            pytest.param(RotH, marks=test_utils.flaky_xfail_mark(AssertionError, 1675)),\n            RotE,\n        ],\n    )\n    def test_model_rankings(model_maker):\n        nodes = pd.DataFrame(index=[\"a\", \"b\", \"c\", \"d\"])\n        rels = [\"W\", \"X\", \"Y\", \"Z\"]\n        empty = pd.DataFrame(columns=[\"source\", \"target\"])\n    \n        every_edge = itertools.product(nodes.index, rels, nodes.index)\n        every_edge_df = triple_df(*every_edge)\n    \n        no_edges = StellarDiGraph(nodes, {name: empty for name in rels})\n    \n        # the filtering is most interesting when there's a smattering of edges, somewhere between none\n        # and all; this does a stratified sample by label, to make sure there's at least one edge from\n        # each label.\n        one_per_label_df = (\n            every_edge_df.groupby(\"label\").apply(lambda df: df.sample(n=1)).droplevel(0)\n        )\n        others_df = every_edge_df.sample(frac=0.25)\n        some_edges_df = pd.concat([one_per_label_df, others_df], ignore_index=True)\n    \n        some_edges = StellarDiGraph(\n            nodes,\n            {name: df.drop(columns=\"label\") for name, df in some_edges_df.groupby(\"label\")},\n        )\n    \n        all_edges = StellarDiGraph(\n            nodes=nodes,\n            edges={\n                name: df.drop(columns=\"label\")\n                for name, df in every_edge_df.groupby(\"label\")\n            },\n        )\n    \n        gen = KGTripleGenerator(all_edges, 3)\n        sg_model = model_maker(gen, embedding_dimension=6)\n>       x_inp, x_out = sg_model.in_out_tensors()\n\ntests/layer/test_knowledge_graph.py:341: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/layer/knowledge_graph.py:157: in in_out_tensors\n    s_iloc = Input(shape=1)\n/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:209: in Input\n    layer = InputLayer(\n/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:92: in __init__\n    shape = backend.standardize_shape(shape)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nshape = 1\n\n    def standardize_shape(shape):\n        if not isinstance(shape, tuple):\n            if shape is None:\n                raise ValueError(\"Undefined shapes are not supported.\")\n            if not hasattr(shape, \"__iter__\"):\n>               raise ValueError(f\"Cannot convert '{shape}' to a shape.\")\nE               ValueError: Cannot convert '1' to a shape.\n\n/usr/local/lib/python3.10/dist-packages/keras/src/backend/common/variables.py:592: ValueError\n_________________________ test_model_rankings[RotatE] __________________________\n\nmodel_maker = <class 'stellargraph.layer.knowledge_graph.RotatE'>\n\n    @pytest.mark.parametrize(\n        \"model_maker\",\n        [\n            ComplEx,\n            DistMult,\n            pytest.param(RotatE, marks=test_utils.flaky_xfail_mark(AssertionError, 1623)),\n            pytest.param(RotH, marks=test_utils.flaky_xfail_mark(AssertionError, 1675)),\n            RotE,\n        ],\n    )\n    def test_model_rankings(model_maker):\n        nodes = pd.DataFrame(index=[\"a\", \"b\", \"c\", \"d\"])\n        rels = [\"W\", \"X\", \"Y\", \"Z\"]\n        empty = pd.DataFrame(columns=[\"source\", \"target\"])\n    \n        every_edge = itertools.product(nodes.index, rels, nodes.index)\n        every_edge_df = triple_df(*every_edge)\n    \n        no_edges = StellarDiGraph(nodes, {name: empty for name in rels})\n    \n        # the filtering is most interesting when there's a smattering of edges, somewhere between none\n        # and all; this does a stratified sample by label, to make sure there's at least one edge from\n        # each label.\n        one_per_label_df = (\n            every_edge_df.groupby(\"label\").apply(lambda df: df.sample(n=1)).droplevel(0)\n        )\n        others_df = every_edge_df.sample(frac=0.25)\n        some_edges_df = pd.concat([one_per_label_df, others_df], ignore_index=True)\n    \n        some_edges = StellarDiGraph(\n            nodes,\n            {name: df.drop(columns=\"label\") for name, df in some_edges_df.groupby(\"label\")},\n        )\n    \n        all_edges = StellarDiGraph(\n            nodes=nodes,\n            edges={\n                name: df.drop(columns=\"label\")\n                for name, df in every_edge_df.groupby(\"label\")\n            },\n        )\n    \n        gen = KGTripleGenerator(all_edges, 3)\n        sg_model = model_maker(gen, embedding_dimension=6)\n>       x_inp, x_out = sg_model.in_out_tensors()\n\ntests/layer/test_knowledge_graph.py:341: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/layer/knowledge_graph.py:157: in in_out_tensors\n    s_iloc = Input(shape=1)\n/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:209: in Input\n    layer = InputLayer(\n/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:92: in __init__\n    shape = backend.standardize_shape(shape)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nshape = 1\n\n    def standardize_shape(shape):\n        if not isinstance(shape, tuple):\n            if shape is None:\n                raise ValueError(\"Undefined shapes are not supported.\")\n            if not hasattr(shape, \"__iter__\"):\n>               raise ValueError(f\"Cannot convert '{shape}' to a shape.\")\nE               ValueError: Cannot convert '1' to a shape.\n\n/usr/local/lib/python3.10/dist-packages/keras/src/backend/common/variables.py:592: ValueError\n__________________________ test_model_rankings[RotH] ___________________________\n\nmodel_maker = <class 'stellargraph.layer.knowledge_graph.RotH'>\n\n    @pytest.mark.parametrize(\n        \"model_maker\",\n        [\n            ComplEx,\n            DistMult,\n            pytest.param(RotatE, marks=test_utils.flaky_xfail_mark(AssertionError, 1623)),\n            pytest.param(RotH, marks=test_utils.flaky_xfail_mark(AssertionError, 1675)),\n            RotE,\n        ],\n    )\n    def test_model_rankings(model_maker):\n        nodes = pd.DataFrame(index=[\"a\", \"b\", \"c\", \"d\"])\n        rels = [\"W\", \"X\", \"Y\", \"Z\"]\n        empty = pd.DataFrame(columns=[\"source\", \"target\"])\n    \n        every_edge = itertools.product(nodes.index, rels, nodes.index)\n        every_edge_df = triple_df(*every_edge)\n    \n        no_edges = StellarDiGraph(nodes, {name: empty for name in rels})\n    \n        # the filtering is most interesting when there's a smattering of edges, somewhere between none\n        # and all; this does a stratified sample by label, to make sure there's at least one edge from\n        # each label.\n        one_per_label_df = (\n            every_edge_df.groupby(\"label\").apply(lambda df: df.sample(n=1)).droplevel(0)\n        )\n        others_df = every_edge_df.sample(frac=0.25)\n        some_edges_df = pd.concat([one_per_label_df, others_df], ignore_index=True)\n    \n        some_edges = StellarDiGraph(\n            nodes,\n            {name: df.drop(columns=\"label\") for name, df in some_edges_df.groupby(\"label\")},\n        )\n    \n        all_edges = StellarDiGraph(\n            nodes=nodes,\n            edges={\n                name: df.drop(columns=\"label\")\n                for name, df in every_edge_df.groupby(\"label\")\n            },\n        )\n    \n        gen = KGTripleGenerator(all_edges, 3)\n        sg_model = model_maker(gen, embedding_dimension=6)\n>       x_inp, x_out = sg_model.in_out_tensors()\n\ntests/layer/test_knowledge_graph.py:341: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/layer/knowledge_graph.py:157: in in_out_tensors\n    s_iloc = Input(shape=1)\n/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:209: in Input\n    layer = InputLayer(\n/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:92: in __init__\n    shape = backend.standardize_shape(shape)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nshape = 1\n\n    def standardize_shape(shape):\n        if not isinstance(shape, tuple):\n            if shape is None:\n                raise ValueError(\"Undefined shapes are not supported.\")\n            if not hasattr(shape, \"__iter__\"):\n>               raise ValueError(f\"Cannot convert '{shape}' to a shape.\")\nE               ValueError: Cannot convert '1' to a shape.\n\n/usr/local/lib/python3.10/dist-packages/keras/src/backend/common/variables.py:592: ValueError\n__________________________ test_model_rankings[RotE] ___________________________\n\nmodel_maker = <class 'stellargraph.layer.knowledge_graph.RotE'>\n\n    @pytest.mark.parametrize(\n        \"model_maker\",\n        [\n            ComplEx,\n            DistMult,\n            pytest.param(RotatE, marks=test_utils.flaky_xfail_mark(AssertionError, 1623)),\n            pytest.param(RotH, marks=test_utils.flaky_xfail_mark(AssertionError, 1675)),\n            RotE,\n        ],\n    )\n    def test_model_rankings(model_maker):\n        nodes = pd.DataFrame(index=[\"a\", \"b\", \"c\", \"d\"])\n        rels = [\"W\", \"X\", \"Y\", \"Z\"]\n        empty = pd.DataFrame(columns=[\"source\", \"target\"])\n    \n        every_edge = itertools.product(nodes.index, rels, nodes.index)\n        every_edge_df = triple_df(*every_edge)\n    \n        no_edges = StellarDiGraph(nodes, {name: empty for name in rels})\n    \n        # the filtering is most interesting when there's a smattering of edges, somewhere between none\n        # and all; this does a stratified sample by label, to make sure there's at least one edge from\n        # each label.\n        one_per_label_df = (\n            every_edge_df.groupby(\"label\").apply(lambda df: df.sample(n=1)).droplevel(0)\n        )\n        others_df = every_edge_df.sample(frac=0.25)\n        some_edges_df = pd.concat([one_per_label_df, others_df], ignore_index=True)\n    \n        some_edges = StellarDiGraph(\n            nodes,\n            {name: df.drop(columns=\"label\") for name, df in some_edges_df.groupby(\"label\")},\n        )\n    \n        all_edges = StellarDiGraph(\n            nodes=nodes,\n            edges={\n                name: df.drop(columns=\"label\")\n                for name, df in every_edge_df.groupby(\"label\")\n            },\n        )\n    \n        gen = KGTripleGenerator(all_edges, 3)\n        sg_model = model_maker(gen, embedding_dimension=6)\n>       x_inp, x_out = sg_model.in_out_tensors()\n\ntests/layer/test_knowledge_graph.py:341: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/layer/knowledge_graph.py:157: in in_out_tensors\n    s_iloc = Input(shape=1)\n/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:209: in Input\n    layer = InputLayer(\n/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:92: in __init__\n    shape = backend.standardize_shape(shape)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nshape = 1\n\n    def standardize_shape(shape):\n        if not isinstance(shape, tuple):\n            if shape is None:\n                raise ValueError(\"Undefined shapes are not supported.\")\n            if not hasattr(shape, \"__iter__\"):\n>               raise ValueError(f\"Cannot convert '{shape}' to a shape.\")\nE               ValueError: Cannot convert '1' to a shape.\n\n/usr/local/lib/python3.10/dist-packages/keras/src/backend/common/variables.py:592: ValueError\n___________________________ test_save_load[ComplEx] ____________________________\n\ntmpdir = local('/tmp/pytest-of-root/pytest-1/test_save_load_ComplEx_0')\nknowledge_graph = <stellargraph.core.graph.StellarDiGraph object at 0x7fc18c6bdab0>\nmodel_maker = <class 'stellargraph.layer.knowledge_graph.ComplEx'>\n\n    @pytest.mark.parametrize(\"model_maker\", [ComplEx, DistMult, RotatE, RotH, RotE])\n    def test_save_load(tmpdir, knowledge_graph, model_maker):\n        gen = KGTripleGenerator(knowledge_graph, 3)\n        sg_model = model_maker(gen, embedding_dimension=6)\n>       test_utils.model_save_load(tmpdir, sg_model)\n\ntests/layer/test_knowledge_graph.py:509: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ntests/test_utils/__init__.py:29: in model_save_load\n    model = tf.keras.Model(*sg_model.in_out_tensors())\nstellargraph/layer/knowledge_graph.py:157: in in_out_tensors\n    s_iloc = Input(shape=1)\n/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:209: in Input\n    layer = InputLayer(\n/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:92: in __init__\n    shape = backend.standardize_shape(shape)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nshape = 1\n\n    def standardize_shape(shape):\n        if not isinstance(shape, tuple):\n            if shape is None:\n                raise ValueError(\"Undefined shapes are not supported.\")\n            if not hasattr(shape, \"__iter__\"):\n>               raise ValueError(f\"Cannot convert '{shape}' to a shape.\")\nE               ValueError: Cannot convert '1' to a shape.\n\n/usr/local/lib/python3.10/dist-packages/keras/src/backend/common/variables.py:592: ValueError\n___________________________ test_save_load[DistMult] ___________________________\n\ntmpdir = local('/tmp/pytest-of-root/pytest-1/test_save_load_DistMult_0')\nknowledge_graph = <stellargraph.core.graph.StellarDiGraph object at 0x7fc1ac2aa4d0>\nmodel_maker = <class 'stellargraph.layer.knowledge_graph.DistMult'>\n\n    @pytest.mark.parametrize(\"model_maker\", [ComplEx, DistMult, RotatE, RotH, RotE])\n    def test_save_load(tmpdir, knowledge_graph, model_maker):\n        gen = KGTripleGenerator(knowledge_graph, 3)\n        sg_model = model_maker(gen, embedding_dimension=6)\n>       test_utils.model_save_load(tmpdir, sg_model)\n\ntests/layer/test_knowledge_graph.py:509: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ntests/test_utils/__init__.py:29: in model_save_load\n    model = tf.keras.Model(*sg_model.in_out_tensors())\nstellargraph/layer/knowledge_graph.py:157: in in_out_tensors\n    s_iloc = Input(shape=1)\n/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:209: in Input\n    layer = InputLayer(\n/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:92: in __init__\n    shape = backend.standardize_shape(shape)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nshape = 1\n\n    def standardize_shape(shape):\n        if not isinstance(shape, tuple):\n            if shape is None:\n                raise ValueError(\"Undefined shapes are not supported.\")\n            if not hasattr(shape, \"__iter__\"):\n>               raise ValueError(f\"Cannot convert '{shape}' to a shape.\")\nE               ValueError: Cannot convert '1' to a shape.\n\n/usr/local/lib/python3.10/dist-packages/keras/src/backend/common/variables.py:592: ValueError\n____________________________ test_save_load[RotatE] ____________________________\n\ntmpdir = local('/tmp/pytest-of-root/pytest-1/test_save_load_RotatE_0')\nknowledge_graph = <stellargraph.core.graph.StellarDiGraph object at 0x7fc14541c160>\nmodel_maker = <class 'stellargraph.layer.knowledge_graph.RotatE'>\n\n    @pytest.mark.parametrize(\"model_maker\", [ComplEx, DistMult, RotatE, RotH, RotE])\n    def test_save_load(tmpdir, knowledge_graph, model_maker):\n        gen = KGTripleGenerator(knowledge_graph, 3)\n        sg_model = model_maker(gen, embedding_dimension=6)\n>       test_utils.model_save_load(tmpdir, sg_model)\n\ntests/layer/test_knowledge_graph.py:509: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ntests/test_utils/__init__.py:29: in model_save_load\n    model = tf.keras.Model(*sg_model.in_out_tensors())\nstellargraph/layer/knowledge_graph.py:157: in in_out_tensors\n    s_iloc = Input(shape=1)\n/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:209: in Input\n    layer = InputLayer(\n/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:92: in __init__\n    shape = backend.standardize_shape(shape)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nshape = 1\n\n    def standardize_shape(shape):\n        if not isinstance(shape, tuple):\n            if shape is None:\n                raise ValueError(\"Undefined shapes are not supported.\")\n            if not hasattr(shape, \"__iter__\"):\n>               raise ValueError(f\"Cannot convert '{shape}' to a shape.\")\nE               ValueError: Cannot convert '1' to a shape.\n\n/usr/local/lib/python3.10/dist-packages/keras/src/backend/common/variables.py:592: ValueError\n_____________________________ test_save_load[RotH] _____________________________\n\ntmpdir = local('/tmp/pytest-of-root/pytest-1/test_save_load_RotH_0')\nknowledge_graph = <stellargraph.core.graph.StellarDiGraph object at 0x7fc18c483d90>\nmodel_maker = <class 'stellargraph.layer.knowledge_graph.RotH'>\n\n    @pytest.mark.parametrize(\"model_maker\", [ComplEx, DistMult, RotatE, RotH, RotE])\n    def test_save_load(tmpdir, knowledge_graph, model_maker):\n        gen = KGTripleGenerator(knowledge_graph, 3)\n        sg_model = model_maker(gen, embedding_dimension=6)\n>       test_utils.model_save_load(tmpdir, sg_model)\n\ntests/layer/test_knowledge_graph.py:509: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ntests/test_utils/__init__.py:29: in model_save_load\n    model = tf.keras.Model(*sg_model.in_out_tensors())\nstellargraph/layer/knowledge_graph.py:157: in in_out_tensors\n    s_iloc = Input(shape=1)\n/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:209: in Input\n    layer = InputLayer(\n/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:92: in __init__\n    shape = backend.standardize_shape(shape)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nshape = 1\n\n    def standardize_shape(shape):\n        if not isinstance(shape, tuple):\n            if shape is None:\n                raise ValueError(\"Undefined shapes are not supported.\")\n            if not hasattr(shape, \"__iter__\"):\n>               raise ValueError(f\"Cannot convert '{shape}' to a shape.\")\nE               ValueError: Cannot convert '1' to a shape.\n\n/usr/local/lib/python3.10/dist-packages/keras/src/backend/common/variables.py:592: ValueError\n_____________________________ test_save_load[RotE] _____________________________\n\ntmpdir = local('/tmp/pytest-of-root/pytest-1/test_save_load_RotE_0')\nknowledge_graph = <stellargraph.core.graph.StellarDiGraph object at 0x7fc1787c2680>\nmodel_maker = <class 'stellargraph.layer.knowledge_graph.RotE'>\n\n    @pytest.mark.parametrize(\"model_maker\", [ComplEx, DistMult, RotatE, RotH, RotE])\n    def test_save_load(tmpdir, knowledge_graph, model_maker):\n        gen = KGTripleGenerator(knowledge_graph, 3)\n        sg_model = model_maker(gen, embedding_dimension=6)\n>       test_utils.model_save_load(tmpdir, sg_model)\n\ntests/layer/test_knowledge_graph.py:509: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ntests/test_utils/__init__.py:29: in model_save_load\n    model = tf.keras.Model(*sg_model.in_out_tensors())\nstellargraph/layer/knowledge_graph.py:157: in in_out_tensors\n    s_iloc = Input(shape=1)\n/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:209: in Input\n    layer = InputLayer(\n/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:92: in __init__\n    shape = backend.standardize_shape(shape)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nshape = 1\n\n    def standardize_shape(shape):\n        if not isinstance(shape, tuple):\n            if shape is None:\n                raise ValueError(\"Undefined shapes are not supported.\")\n            if not hasattr(shape, \"__iter__\"):\n>               raise ValueError(f\"Cannot convert '{shape}' to a shape.\")\nE               ValueError: Cannot convert '1' to a shape.\n\n/usr/local/lib/python3.10/dist-packages/keras/src/backend/common/variables.py:592: ValueError\n_____________________________ test_gather_indices ______________________________\n\n    def test_gather_indices():\n        batch_dim = 3\n        data_in = keras.Input(batch_shape=(batch_dim, 5, 7))\n        indices_in = keras.Input(batch_shape=(batch_dim, 11), dtype=\"int32\")\n    \n>       data = np.arange(np.product(data_in.shape)).reshape(data_in.shape)\n\ntests/layer/test_misc.py:115: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'product'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n            raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\n    \n        if attr == \"chararray\":\n            warnings.warn(\n                \"`np.chararray` is deprecated and will be removed from \"\n                \"the main namespace in the future. Use an array with a string \"\n                \"or bytes dtype instead.\", DeprecationWarning, stacklevel=2)\n            import numpy.char as char\n            return char.chararray\n    \n>       raise AttributeError(\"module {!r} has no attribute \"\n                             \"{!r}\".format(__name__, attr))\nE       AttributeError: module 'numpy' has no attribute 'product'\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:414: AttributeError\n_______________________ test_deprecated_model_functions ________________________\n\n    def test_deprecated_model_functions():\n        G, _ = create_graph_features()\n    \n        # full batch models\n        generator = FullBatchNodeGenerator(G)\n        for model_type in [GCN, GAT, PPNP, APPNP]:\n            sg_model = model_type(\n                generator=generator, layer_sizes=[4], activations=[\"relu\"]\n            )\n            _deprecated_test(sg_model)\n    \n        # test DeepGraphInfomax here because it needs a fullbatch model\n        sg_model = DeepGraphInfomax(sg_model)\n>       _deprecated_test(sg_model)\n\ntests/layer/test_misc.py:171: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ntests/layer/test_misc.py:140: in _deprecated_test\n    x_in, x_out = sg_model.build()\nstellargraph/layer/misc.py:149: in _function_wrapper\n    return function(*args, **kwargs)\nstellargraph/layer/deep_graph_infomax.py:192: in in_out_tensors\n    x_out = tf.stack([scores, scores_corrupted], axis=-1)\n/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py:153: in error_handler\n    raise e.with_traceback(filtered_tb) from None\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <KerasTensor shape=(1, None), dtype=float32, sparse=False, ragged=False, name=keras_tensor_2096>\ndtype = None, name = 'stack'\n\n    def __tf_tensor__(self, dtype=None, name=None):\n>       raise ValueError(\n            \"A KerasTensor cannot be used as input to a TensorFlow function. \"\n            \"A KerasTensor is a symbolic placeholder for a shape and dtype, \"\n            \"used when constructing Keras Functional models \"\n            \"or Keras Functions. You can only use it as input to a Keras layer \"\n            \"or a Keras operation (from the namespaces `keras.layers` \"\n            \"and `keras.ops`). \"\n            \"You are likely doing something like:\\n\\n\"\n            \"```\\n\"\n            \"x = Input(...)\\n\"\n            \"...\\n\"\n            \"tf_fn(x)  # Invalid.\\n\"\n            \"```\\n\\n\"\n            \"What you should do instead is wrap `tf_fn` in a layer:\\n\\n\"\n            \"```\\n\"\n            \"class MyLayer(Layer):\\n\"\n            \"    def call(self, x):\\n\"\n            \"        return tf_fn(x)\\n\\n\"\n            \"x = MyLayer()(x)\\n\"\n            \"```\\n\"\n        )\nE       ValueError: A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.ops`). You are likely doing something like:\nE       \nE       ```\nE       x = Input(...)\nE       ...\nE       tf_fn(x)  # Invalid.\nE       ```\nE       \nE       What you should do instead is wrap `tf_fn` in a layer:\nE       \nE       ```\nE       class MyLayer(Layer):\nE           def call(self, x):\nE               return tf_fn(x)\nE       \nE       x = MyLayer()(x)\nE       ```\n\n/usr/local/lib/python3.10/dist-packages/keras/src/backend/common/keras_tensor.py:194: ValueError\n----------------------------- Captured stdout call -----------------------------\nUsing GCN (local pooling) filters...\n___________________________ test_node2vec_save_load ____________________________\n\ntmpdir = local('/tmp/pytest-of-root/pytest-1/test_node2vec_save_load0')\n\n    def test_node2vec_save_load(tmpdir):\n        node2vec = Node2Vec(emb_size=4, node_num=4, multiplicity=2)\n>       test_utils.model_save_load(tmpdir, node2vec)\n\ntests/layer/test_node2vec.py:113: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ntests/test_utils/__init__.py:43: in model_save_load\n    func(model, str(saved_dir))\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nmodel = <Functional name=functional_111, built=True>\nfilepath = '/tmp/pytest-of-root/pytest-1/test_node2vec_save_load0/0'\noverwrite = True, zipped = True, kwargs = {}, include_optimizer = True\nsave_format = False, is_hf = False, exists = False\n\n    @keras_export([\"keras.saving.save_model\", \"keras.models.save_model\"])\n    def save_model(model, filepath, overwrite=True, zipped=None, **kwargs):\n        \"\"\"Saves a model as a `.keras` file.\n    \n        Args:\n            model: Keras model instance to be saved.\n            filepath: `str` or `pathlib.Path` object. Path where to save the model.\n            overwrite: Whether we should overwrite any existing model at the target\n                location, or instead ask the user via an interactive prompt.\n            zipped: Whether to save the model as a zipped `.keras`\n                archive (default when saving locally), or as an unzipped directory\n                (default when saving on the Hugging Face Hub).\n    \n        Example:\n    \n        ```python\n        model = keras.Sequential(\n            [\n                keras.layers.Dense(5, input_shape=(3,)),\n                keras.layers.Softmax(),\n            ],\n        )\n        model.save(\"model.keras\")\n        loaded_model = keras.saving.load_model(\"model.keras\")\n        x = keras.random.uniform((10, 3))\n        assert np.allclose(model.predict(x), loaded_model.predict(x))\n        ```\n    \n        Note that `model.save()` is an alias for `keras.saving.save_model()`.\n    \n        The saved `.keras` file is a `zip` archive that contains:\n    \n        - The model's configuration (architecture)\n        - The model's weights\n        - The model's optimizer's state (if any)\n    \n        Thus models can be reinstantiated in the exact same state.\n        \"\"\"\n        include_optimizer = kwargs.pop(\"include_optimizer\", True)\n        save_format = kwargs.pop(\"save_format\", False)\n        if save_format:\n            if str(filepath).endswith((\".h5\", \".hdf5\")) or str(filepath).endswith(\n                \".keras\"\n            ):\n                logging.warning(\n                    \"The `save_format` argument is deprecated in Keras 3. \"\n                    \"We recommend removing this argument as it can be inferred \"\n                    \"from the file path. \"\n                    f\"Received: save_format={save_format}\"\n                )\n            else:\n                raise ValueError(\n                    \"The `save_format` argument is deprecated in Keras 3. \"\n                    \"Please remove this argument and pass a file path with \"\n                    \"either `.keras` or `.h5` extension.\"\n                    f\"Received: save_format={save_format}\"\n                )\n        if kwargs:\n            raise ValueError(\n                \"The following argument(s) are not supported: \"\n                f\"{list(kwargs.keys())}\"\n            )\n    \n        # Deprecation warnings\n        if str(filepath).endswith((\".h5\", \".hdf5\")):\n            logging.warning(\n                \"You are saving your model as an HDF5 file via \"\n                \"`model.save()` or `keras.saving.save_model(model)`. \"\n                \"This file format is considered legacy. \"\n                \"We recommend using instead the native Keras format, \"\n                \"e.g. `model.save('my_model.keras')` or \"\n                \"`keras.saving.save_model(model, 'my_model.keras')`. \"\n            )\n    \n        is_hf = str(filepath).startswith(\"hf://\")\n        if zipped is None:\n            zipped = not is_hf  # default behavior depends on destination\n    \n        # If file exists and should not be overwritten.\n        try:\n            exists = (not is_hf) and os.path.exists(filepath)\n        except TypeError:\n            exists = False\n        if exists and not overwrite:\n            proceed = io_utils.ask_to_proceed_with_overwrite(filepath)\n            if not proceed:\n                return\n    \n        if zipped and str(filepath).endswith(\".keras\"):\n            return saving_lib.save_model(model, filepath)\n        if not zipped:\n            return saving_lib.save_model(model, filepath, zipped=False)\n        if str(filepath).endswith((\".h5\", \".hdf5\")):\n            return legacy_h5_format.save_model_to_hdf5(\n                model, filepath, overwrite, include_optimizer\n            )\n>       raise ValueError(\n            \"Invalid filepath extension for saving. \"\n            \"Please add either a `.keras` extension for the native Keras \"\n            f\"format (recommended) or a `.h5` extension. \"\n            \"Use `model.export(filepath)` if you want to export a SavedModel \"\n            \"for use with TFLite/TFServing/etc. \"\n            f\"Received: filepath={filepath}.\"\n        )\nE       ValueError: Invalid filepath extension for saving. Please add either a `.keras` extension for the native Keras format (recommended) or a `.h5` extension. Use `model.export(filepath)` if you want to export a SavedModel for use with TFLite/TFServing/etc. Received: filepath=/tmp/pytest-of-root/pytest-1/test_node2vec_save_load0/0.\n\n/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_api.py:114: ValueError\n____________________________ test_PPNP_apply_dense _____________________________\n\n    def test_PPNP_apply_dense():\n        G, features = create_graph_features()\n        adj = G.to_adjacency_matrix()\n        features, adj = PPNP_Aadj_feats_op(features, adj)\n        adj = adj[None, :, :]\n    \n        generator = FullBatchNodeGenerator(G, sparse=False, method=\"ppnp\")\n        ppnpModel = PPNP([2], generator=generator, activations=[\"relu\"], dropout=0.5)\n    \n        x_in, x_out = ppnpModel.in_out_tensors()\n        model = keras.Model(inputs=x_in, outputs=x_out)\n    \n        # Check fit method\n        out_indices = np.array([[0, 1]], dtype=\"int32\")\n        preds_1 = model.predict([features[None, :, :], out_indices, adj])\n        assert preds_1.shape == (1, 2, 2)\n    \n        # Check fit method\n>       preds_2 = model.predict(generator.flow([\"a\", \"b\"]))\n\ntests/layer/test_ppnp.py:76: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py:122: in error_handler\n    raise e.with_traceback(filtered_tb) from None\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nfunc = <function get_keras_tensor_spec.<locals>.get_single_tensor_spec at 0x7fc178783a30>\ntree = ([array([[[1., 1.],\n        [1., 0.],\n        [0., 1.]]], dtype=float32), array([[0, 1]], dtype=uint8), array([[[0.4, 0.3, 0.3],\n        [0.3, 0.4, 0.3],\n        [0.3, 0.3, 0.4]]])], None)\nis_leaf = None, none_is_leaf = True, namespace = 'keras', rests = ()\n\n    def tree_map(\n        func: Callable[..., U],\n        tree: PyTree[T],\n        /,\n        *rests: PyTree[S],\n        is_leaf: Callable[[T], bool] | None = None,\n        none_is_leaf: bool = False,\n        namespace: str = '',\n    ) -> PyTree[U]:\n        \"\"\"Map a multi-input function over pytree args to produce a new pytree.\n    \n        See also :func:`tree_map_`, :func:`tree_map_with_path`, :func:`tree_map_with_path_`,\n        and :func:`tree_broadcast_map`.\n    \n        >>> tree_map(lambda x: x + 1, {'x': 7, 'y': (42, 64)})\n        {'x': 8, 'y': (43, 65)}\n        >>> tree_map(lambda x: x + 1, {'x': 7, 'y': (42, 64), 'z': None})\n        {'x': 8, 'y': (43, 65), 'z': None}\n        >>> tree_map(lambda x: x is None, {'x': 7, 'y': (42, 64), 'z': None})\n        {'x': False, 'y': (False, False), 'z': None}\n        >>> tree_map(lambda x: x is None, {'x': 7, 'y': (42, 64), 'z': None}, none_is_leaf=True)\n        {'x': False, 'y': (False, False), 'z': True}\n    \n        If multiple inputs are given, the structure of the tree is taken from the first input;\n        subsequent inputs need only have ``tree`` as a prefix:\n    \n        >>> tree_map(lambda x, y: [x] + y, [5, 6], [[7, 9], [1, 2]])\n        [[5, 7, 9], [6, 1, 2]]\n    \n        Args:\n            func (callable): A function that takes ``1 + len(rests)`` arguments, to be applied at the\n                corresponding leaves of the pytrees.\n            tree (pytree): A pytree to be mapped over, with each leaf providing the first positional\n                argument to function ``func``.\n            rests (tuple of pytree): A tuple of pytrees, each of which has the same structure as\n                ``tree`` or has ``tree`` as a prefix.\n            is_leaf (callable, optional): An optionally specified function that will be called at each\n                flattening step. It should return a boolean, with :data:`True` stopping the traversal\n                and the whole subtree being treated as a leaf, and :data:`False` indicating the\n                flattening should traverse the current object.\n            none_is_leaf (bool, optional): Whether to treat :data:`None` as a leaf. If :data:`False`,\n                :data:`None` is a non-leaf node with arity 0. Thus :data:`None` is contained in the\n                treespec rather than in the leaves list and :data:`None` will be remain in the result\n                pytree. (default: :data:`False`)\n            namespace (str, optional): The registry namespace used for custom pytree node types.\n                (default: :const:`''`, i.e., the global namespace)\n    \n        Returns:\n            A new pytree with the same structure as ``tree`` but with the value at each leaf given by\n            ``func(x, *xs)`` where ``x`` is the value at the corresponding leaf in ``tree`` and ``xs``\n            is the tuple of values at corresponding nodes in ``rests``.\n        \"\"\"\n        leaves, treespec = _C.flatten(tree, is_leaf, none_is_leaf, namespace)\n        flat_args = [leaves] + [treespec.flatten_up_to(r) for r in rests]\n>       return treespec.unflatten(map(func, *flat_args))\nE       ValueError: When passing a dataset to a Keras model, the arrays must be at least rank 1. Received: None of rank 0.\n\n/usr/local/lib/python3.10/dist-packages/optree/ops.py:766: ValueError\n----------------------------- Captured stdout call -----------------------------\n\n\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step\n_____________________________ test_PPNP_save_load ______________________________\n\ntmpdir = local('/tmp/pytest-of-root/pytest-1/test_PPNP_save_load0')\n\n    def test_PPNP_save_load(tmpdir):\n        G, _ = create_graph_features()\n        generator = FullBatchNodeGenerator(G, sparse=False)\n        ppnp = PPNP([2, 3], generator, [\"relu\", \"relu\"])\n>       test_utils.model_save_load(tmpdir, ppnp)\n\ntests/layer/test_ppnp.py:86: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ntests/test_utils/__init__.py:43: in model_save_load\n    func(model, str(saved_dir))\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nmodel = <Functional name=functional_113, built=True>\nfilepath = '/tmp/pytest-of-root/pytest-1/test_PPNP_save_load0/0'\noverwrite = True, zipped = True, kwargs = {}, include_optimizer = True\nsave_format = False, is_hf = False, exists = False\n\n    @keras_export([\"keras.saving.save_model\", \"keras.models.save_model\"])\n    def save_model(model, filepath, overwrite=True, zipped=None, **kwargs):\n        \"\"\"Saves a model as a `.keras` file.\n    \n        Args:\n            model: Keras model instance to be saved.\n            filepath: `str` or `pathlib.Path` object. Path where to save the model.\n            overwrite: Whether we should overwrite any existing model at the target\n                location, or instead ask the user via an interactive prompt.\n            zipped: Whether to save the model as a zipped `.keras`\n                archive (default when saving locally), or as an unzipped directory\n                (default when saving on the Hugging Face Hub).\n    \n        Example:\n    \n        ```python\n        model = keras.Sequential(\n            [\n                keras.layers.Dense(5, input_shape=(3,)),\n                keras.layers.Softmax(),\n            ],\n        )\n        model.save(\"model.keras\")\n        loaded_model = keras.saving.load_model(\"model.keras\")\n        x = keras.random.uniform((10, 3))\n        assert np.allclose(model.predict(x), loaded_model.predict(x))\n        ```\n    \n        Note that `model.save()` is an alias for `keras.saving.save_model()`.\n    \n        The saved `.keras` file is a `zip` archive that contains:\n    \n        - The model's configuration (architecture)\n        - The model's weights\n        - The model's optimizer's state (if any)\n    \n        Thus models can be reinstantiated in the exact same state.\n        \"\"\"\n        include_optimizer = kwargs.pop(\"include_optimizer\", True)\n        save_format = kwargs.pop(\"save_format\", False)\n        if save_format:\n            if str(filepath).endswith((\".h5\", \".hdf5\")) or str(filepath).endswith(\n                \".keras\"\n            ):\n                logging.warning(\n                    \"The `save_format` argument is deprecated in Keras 3. \"\n                    \"We recommend removing this argument as it can be inferred \"\n                    \"from the file path. \"\n                    f\"Received: save_format={save_format}\"\n                )\n            else:\n                raise ValueError(\n                    \"The `save_format` argument is deprecated in Keras 3. \"\n                    \"Please remove this argument and pass a file path with \"\n                    \"either `.keras` or `.h5` extension.\"\n                    f\"Received: save_format={save_format}\"\n                )\n        if kwargs:\n            raise ValueError(\n                \"The following argument(s) are not supported: \"\n                f\"{list(kwargs.keys())}\"\n            )\n    \n        # Deprecation warnings\n        if str(filepath).endswith((\".h5\", \".hdf5\")):\n            logging.warning(\n                \"You are saving your model as an HDF5 file via \"\n                \"`model.save()` or `keras.saving.save_model(model)`. \"\n                \"This file format is considered legacy. \"\n                \"We recommend using instead the native Keras format, \"\n                \"e.g. `model.save('my_model.keras')` or \"\n                \"`keras.saving.save_model(model, 'my_model.keras')`. \"\n            )\n    \n        is_hf = str(filepath).startswith(\"hf://\")\n        if zipped is None:\n            zipped = not is_hf  # default behavior depends on destination\n    \n        # If file exists and should not be overwritten.\n        try:\n            exists = (not is_hf) and os.path.exists(filepath)\n        except TypeError:\n            exists = False\n        if exists and not overwrite:\n            proceed = io_utils.ask_to_proceed_with_overwrite(filepath)\n            if not proceed:\n                return\n    \n        if zipped and str(filepath).endswith(\".keras\"):\n            return saving_lib.save_model(model, filepath)\n        if not zipped:\n            return saving_lib.save_model(model, filepath, zipped=False)\n        if str(filepath).endswith((\".h5\", \".hdf5\")):\n            return legacy_h5_format.save_model_to_hdf5(\n                model, filepath, overwrite, include_optimizer\n            )\n>       raise ValueError(\n            \"Invalid filepath extension for saving. \"\n            \"Please add either a `.keras` extension for the native Keras \"\n            f\"format (recommended) or a `.h5` extension. \"\n            \"Use `model.export(filepath)` if you want to export a SavedModel \"\n            \"for use with TFLite/TFServing/etc. \"\n            f\"Received: filepath={filepath}.\"\n        )\nE       ValueError: Invalid filepath extension for saving. Please add either a `.keras` extension for the native Keras format (recommended) or a `.h5` extension. Use `model.export(filepath)` if you want to export a SavedModel for use with TFLite/TFServing/etc. Received: filepath=/tmp/pytest-of-root/pytest-1/test_PPNP_save_load0/0.\n\n/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_api.py:114: ValueError\n----------------------------- Captured stdout call -----------------------------\nUsing GCN (local pooling) filters...\n____________________ test_RelationalGraphConvolution_sparse ____________________\n\n    def test_RelationalGraphConvolution_sparse():\n        G, features = create_graph_features()\n        n_edge_types = len(G.edge_types)\n    \n        # We need to specify the batch shape as one for the GraphConvolutional logic to work\n        n_nodes = features.shape[0]\n        n_feat = features.shape[1]\n    \n        # Inputs for features\n        x_t = Input(batch_shape=(1, n_nodes, n_feat))\n    \n        # Create inputs for sparse or dense matrices\n    \n        # Placeholders for the sparse adjacency matrix\n        As_indices = [\n            Input(batch_shape=(1, None, 2), dtype=\"int64\") for i in range(n_edge_types)\n        ]\n        As_values = [Input(batch_shape=(1, None)) for i in range(n_edge_types)]\n        A_placeholders = As_indices + As_values\n    \n        Ainput = [\n            SqueezedSparseConversion(shape=(n_nodes, n_nodes), dtype=As_values[i].dtype)(\n                [As_indices[i], As_values[i]]\n            )\n            for i in range(n_edge_types)\n        ]\n    \n        x_inp_model = [x_t] + A_placeholders\n        x_inp_conv = [x_t] + Ainput\n    \n>       out = RelationalGraphConvolution(2, num_relationships=n_edge_types)(x_inp_conv)\n\ntests/layer/test_rgcn.py:112: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py:122: in error_handler\n    raise e.with_traceback(filtered_tb) from None\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <RelationalGraphConvolution name=relational_graph_convolution_15, built=True>\ninput_shapes = [(1, 3, 2), (3, 3), (3, 3)]\n\n    def compute_output_shape(self, input_shapes):\n        \"\"\"\n        Computes the output shape of the layer.\n    \n        Args:\n            input_shapes (tuple of int)\n                Shape tuples can include None for free dimensions, instead of an integer.\n    \n        Returns:\n            An input shape tuple.\n        \"\"\"\n>       feature_shape, A_shape = input_shapes\nE       ValueError: Exception encountered when calling RelationalGraphConvolution.call().\nE       \nE       \u001b[1mtoo many values to unpack (expected 2)\u001b[0m\nE       \nE       Arguments received by RelationalGraphConvolution.call():\nE          args=(['<KerasTensor shape=(1, 3, 2), dtype=float32, sparse=False, ragged=False, name=keras_tensor_2153>', '<KerasTensor shape=(3, 3), dtype=float32, sparse=False, ragged=False, name=keras_tensor_2158>', '<KerasTensor shape=(3, 3), dtype=float32, sparse=False, ragged=False, name=keras_tensor_2159>'],)\nE          kwargs=<class 'inspect._empty'>\n\nstellargraph/layer/rgcn.py:184: ValueError\n____________________ test_RelationalGraphConvolution_dense _____________________\n\n    def test_RelationalGraphConvolution_dense():\n    \n        G, features = create_graph_features()\n        n_edge_types = len(G.edge_types)\n    \n        # We need to specify the batch shape as one for the GraphConvolutional logic to work\n        n_nodes = features.shape[0]\n        n_feat = features.shape[1]\n    \n        # Inputs for features & target indices\n        x_t = Input(batch_shape=(1, n_nodes, n_feat))\n        out_indices_t = Input(batch_shape=(1, None), dtype=\"int32\")\n    \n        # Create inputs for sparse or dense matrices\n    \n        # Placeholders for the sparse adjacency matrix\n        A_placeholders = [\n            Input(batch_shape=(1, n_nodes, n_nodes)) for _ in range(n_edge_types)\n        ]\n    \n        A_in = [Lambda(lambda A: K.squeeze(A, 0))(A_p) for A_p in A_placeholders]\n    \n        x_inp_model = [x_t] + A_placeholders\n        x_inp_conv = [x_t] + A_in\n    \n>       out = RelationalGraphConvolution(2, num_relationships=n_edge_types)(x_inp_conv)\n\ntests/layer/test_rgcn.py:156: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py:122: in error_handler\n    raise e.with_traceback(filtered_tb) from None\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <RelationalGraphConvolution name=relational_graph_convolution_17, built=True>\ninput_shapes = [(1, 3, 2), (3, 3), (3, 3)]\n\n    def compute_output_shape(self, input_shapes):\n        \"\"\"\n        Computes the output shape of the layer.\n    \n        Args:\n            input_shapes (tuple of int)\n                Shape tuples can include None for free dimensions, instead of an integer.\n    \n        Returns:\n            An input shape tuple.\n        \"\"\"\n>       feature_shape, A_shape = input_shapes\nE       ValueError: Exception encountered when calling RelationalGraphConvolution.call().\nE       \nE       \u001b[1mtoo many values to unpack (expected 2)\u001b[0m\nE       \nE       Arguments received by RelationalGraphConvolution.call():\nE          args=(['<KerasTensor shape=(1, 3, 2), dtype=float32, sparse=False, ragged=False, name=keras_tensor_2160>', '<KerasTensor shape=(3, 3), dtype=float32, sparse=False, ragged=False, name=keras_tensor_2166>', '<KerasTensor shape=(3, 3), dtype=float32, sparse=False, ragged=False, name=keras_tensor_2169>'],)\nE          kwargs=<class 'inspect._empty'>\n\nstellargraph/layer/rgcn.py:184: ValueError\n____________________________ test_RGCN_apply_sparse ____________________________\n\n    def test_RGCN_apply_sparse():\n        G, features = create_graph_features(is_directed=True)\n    \n        As = get_As(G)\n        As = [A.tocoo() for A in As]\n        A_indices = [\n            np.expand_dims(np.hstack((A.row[:, None], A.col[:, None])).astype(np.int64), 0)\n            for A in As\n        ]\n        A_values = [np.expand_dims(A.data, 0) for A in As]\n    \n        generator = RelationalFullBatchNodeGenerator(G, sparse=True)\n        rgcnModel = RGCN([2], generator, num_bases=10, activations=[\"relu\"], dropout=0.5)\n    \n>       x_in, x_out = rgcnModel.in_out_tensors()\n\ntests/layer/test_rgcn.py:194: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/layer/rgcn.py:581: in in_out_tensors\n    return self._node_model()\nstellargraph/layer/rgcn.py:557: in _node_model\n    x_out = self(x_inp)\nstellargraph/layer/rgcn.py:512: in __call__\n    h_layer = layer([h_layer] + Ainput)\n/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py:122: in error_handler\n    raise e.with_traceback(filtered_tb) from None\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <RelationalGraphConvolution name=relational_graph_convolution_21, built=True>\ninput_shapes = [(1, 3, 2), (3, 3), (3, 3)]\n\n    def compute_output_shape(self, input_shapes):\n        \"\"\"\n        Computes the output shape of the layer.\n    \n        Args:\n            input_shapes (tuple of int)\n                Shape tuples can include None for free dimensions, instead of an integer.\n    \n        Returns:\n            An input shape tuple.\n        \"\"\"\n>       feature_shape, A_shape = input_shapes\nE       ValueError: Exception encountered when calling RelationalGraphConvolution.call().\nE       \nE       \u001b[1mtoo many values to unpack (expected 2)\u001b[0m\nE       \nE       Arguments received by RelationalGraphConvolution.call():\nE          args=(['<KerasTensor shape=(1, 3, 2), dtype=float32, sparse=False, ragged=False, name=keras_tensor_2178>', '<KerasTensor shape=(3, 3), dtype=float32, sparse=False, ragged=False, name=keras_tensor_2176>', '<KerasTensor shape=(3, 3), dtype=float32, sparse=False, ragged=False, name=keras_tensor_2177>'],)\nE          kwargs=<class 'inspect._empty'>\n\nstellargraph/layer/rgcn.py:184: ValueError\n____________________________ test_RGCN_apply_dense _____________________________\n\n    def test_RGCN_apply_dense():\n        G, features = create_graph_features(is_directed=True)\n    \n        As = get_As(G)\n        As = [np.expand_dims(A.todense(), 0) for A in As]\n    \n        generator = RelationalFullBatchNodeGenerator(G, sparse=False)\n        rgcnModel = RGCN([2], generator, num_bases=10, activations=[\"relu\"], dropout=0.5)\n    \n>       x_in, x_out = rgcnModel.in_out_tensors()\n\ntests/layer/test_rgcn.py:218: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/layer/rgcn.py:581: in in_out_tensors\n    return self._node_model()\nstellargraph/layer/rgcn.py:557: in _node_model\n    x_out = self(x_inp)\nstellargraph/layer/rgcn.py:512: in __call__\n    h_layer = layer([h_layer] + Ainput)\n/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py:122: in error_handler\n    raise e.with_traceback(filtered_tb) from None\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <RelationalGraphConvolution name=relational_graph_convolution_23, built=True>\ninput_shapes = [(1, 3, 2), (3, 3), (3, 3)]\n\n    def compute_output_shape(self, input_shapes):\n        \"\"\"\n        Computes the output shape of the layer.\n    \n        Args:\n            input_shapes (tuple of int)\n                Shape tuples can include None for free dimensions, instead of an integer.\n    \n        Returns:\n            An input shape tuple.\n        \"\"\"\n>       feature_shape, A_shape = input_shapes\nE       ValueError: Exception encountered when calling RelationalGraphConvolution.call().\nE       \nE       \u001b[1mtoo many values to unpack (expected 2)\u001b[0m\nE       \nE       Arguments received by RelationalGraphConvolution.call():\nE          args=(['<KerasTensor shape=(1, 3, 2), dtype=float32, sparse=False, ragged=False, name=keras_tensor_2189>', '<KerasTensor shape=(3, 3), dtype=float32, sparse=False, ragged=False, name=keras_tensor_2185>', '<KerasTensor shape=(3, 3), dtype=float32, sparse=False, ragged=False, name=keras_tensor_2188>'],)\nE          kwargs=<class 'inspect._empty'>\n\nstellargraph/layer/rgcn.py:184: ValueError\n_______________________ test_RGCN_apply_sparse_directed ________________________\n\n    def test_RGCN_apply_sparse_directed():\n        G, features = create_graph_features(is_directed=True)\n    \n        As = get_As(G)\n        As = [A.tocoo() for A in As]\n    \n        A_indices = [\n            np.expand_dims(np.hstack((A.row[:, None], A.col[:, None])).astype(np.int64), 0)\n            for A in As\n        ]\n        A_values = [np.expand_dims(A.data, 0) for A in As]\n    \n        generator = RelationalFullBatchNodeGenerator(G, sparse=True)\n        rgcnModel = RGCN([2], generator, num_bases=10, activations=[\"relu\"], dropout=0.5)\n    \n>       x_in, x_out = rgcnModel.in_out_tensors()\n\ntests/layer/test_rgcn.py:248: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/layer/rgcn.py:581: in in_out_tensors\n    return self._node_model()\nstellargraph/layer/rgcn.py:557: in _node_model\n    x_out = self(x_inp)\nstellargraph/layer/rgcn.py:512: in __call__\n    h_layer = layer([h_layer] + Ainput)\n/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py:122: in error_handler\n    raise e.with_traceback(filtered_tb) from None\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <RelationalGraphConvolution name=relational_graph_convolution_25, built=True>\ninput_shapes = [(1, 3, 2), (3, 3), (3, 3)]\n\n    def compute_output_shape(self, input_shapes):\n        \"\"\"\n        Computes the output shape of the layer.\n    \n        Args:\n            input_shapes (tuple of int)\n                Shape tuples can include None for free dimensions, instead of an integer.\n    \n        Returns:\n            An input shape tuple.\n        \"\"\"\n>       feature_shape, A_shape = input_shapes\nE       ValueError: Exception encountered when calling RelationalGraphConvolution.call().\nE       \nE       \u001b[1mtoo many values to unpack (expected 2)\u001b[0m\nE       \nE       Arguments received by RelationalGraphConvolution.call():\nE          args=(['<KerasTensor shape=(1, 3, 2), dtype=float32, sparse=False, ragged=False, name=keras_tensor_2198>', '<KerasTensor shape=(3, 3), dtype=float32, sparse=False, ragged=False, name=keras_tensor_2196>', '<KerasTensor shape=(3, 3), dtype=float32, sparse=False, ragged=False, name=keras_tensor_2197>'],)\nE          kwargs=<class 'inspect._empty'>\n\nstellargraph/layer/rgcn.py:184: ValueError\n________________________ test_RGCN_apply_dense_directed ________________________\n\n    def test_RGCN_apply_dense_directed():\n        G, features = create_graph_features(is_directed=True)\n    \n        As = get_As(G)\n        As = [np.expand_dims(A.todense(), 0) for A in As]\n    \n        generator = RelationalFullBatchNodeGenerator(G, sparse=False)\n        rgcnModel = RGCN([2], generator, num_bases=10, activations=[\"relu\"], dropout=0.5)\n>       x_in, x_out = rgcnModel.in_out_tensors()\n\ntests/layer/test_rgcn.py:271: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/layer/rgcn.py:581: in in_out_tensors\n    return self._node_model()\nstellargraph/layer/rgcn.py:557: in _node_model\n    x_out = self(x_inp)\nstellargraph/layer/rgcn.py:512: in __call__\n    h_layer = layer([h_layer] + Ainput)\n/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py:122: in error_handler\n    raise e.with_traceback(filtered_tb) from None\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <RelationalGraphConvolution name=relational_graph_convolution_27, built=True>\ninput_shapes = [(1, 3, 2), (3, 3), (3, 3)]\n\n    def compute_output_shape(self, input_shapes):\n        \"\"\"\n        Computes the output shape of the layer.\n    \n        Args:\n            input_shapes (tuple of int)\n                Shape tuples can include None for free dimensions, instead of an integer.\n    \n        Returns:\n            An input shape tuple.\n        \"\"\"\n>       feature_shape, A_shape = input_shapes\nE       ValueError: Exception encountered when calling RelationalGraphConvolution.call().\nE       \nE       \u001b[1mtoo many values to unpack (expected 2)\u001b[0m\nE       \nE       Arguments received by RelationalGraphConvolution.call():\nE          args=(['<KerasTensor shape=(1, 3, 2), dtype=float32, sparse=False, ragged=False, name=keras_tensor_2209>', '<KerasTensor shape=(3, 3), dtype=float32, sparse=False, ragged=False, name=keras_tensor_2205>', '<KerasTensor shape=(3, 3), dtype=float32, sparse=False, ragged=False, name=keras_tensor_2208>'],)\nE          kwargs=<class 'inspect._empty'>\n\nstellargraph/layer/rgcn.py:184: ValueError\n_________________________ test_RGCN_save_load[False-0] _________________________\n\ntmpdir = local('/tmp/pytest-of-root/pytest-1/test_RGCN_save_load_False_0_0')\nnum_bases = 0, sparse = False\n\n    @pytest.mark.parametrize(\"num_bases\", [0, 10])\n    @pytest.mark.parametrize(\n        \"sparse\", [False, pytest.param(True, marks=pytest.mark.xfail(reason=\"FIXME #1251\"))]\n    )\n    def test_RGCN_save_load(tmpdir, num_bases, sparse):\n        graph, _ = create_graph_features()\n        generator = RelationalFullBatchNodeGenerator(graph, sparse=sparse)\n        rgcn = RGCN([2, 2], generator, num_bases=num_bases)\n>       test_utils.model_save_load(tmpdir, rgcn)\n\ntests/layer/test_rgcn.py:387: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ntests/test_utils/__init__.py:29: in model_save_load\n    model = tf.keras.Model(*sg_model.in_out_tensors())\nstellargraph/layer/rgcn.py:581: in in_out_tensors\n    return self._node_model()\nstellargraph/layer/rgcn.py:557: in _node_model\n    x_out = self(x_inp)\nstellargraph/layer/rgcn.py:512: in __call__\n    h_layer = layer([h_layer] + Ainput)\n/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py:122: in error_handler\n    raise e.with_traceback(filtered_tb) from None\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <RelationalGraphConvolution name=relational_graph_convolution_40, built=True>\ninput_shapes = [(1, 3, 2), (3, 3), (3, 3)]\n\n    def compute_output_shape(self, input_shapes):\n        \"\"\"\n        Computes the output shape of the layer.\n    \n        Args:\n            input_shapes (tuple of int)\n                Shape tuples can include None for free dimensions, instead of an integer.\n    \n        Returns:\n            An input shape tuple.\n        \"\"\"\n>       feature_shape, A_shape = input_shapes\nE       ValueError: Exception encountered when calling RelationalGraphConvolution.call().\nE       \nE       \u001b[1mtoo many values to unpack (expected 2)\u001b[0m\nE       \nE       Arguments received by RelationalGraphConvolution.call():\nE          args=(['<KerasTensor shape=(1, 3, 2), dtype=float32, sparse=False, ragged=False, name=keras_tensor_2220>', '<KerasTensor shape=(3, 3), dtype=float32, sparse=False, ragged=False, name=keras_tensor_2216>', '<KerasTensor shape=(3, 3), dtype=float32, sparse=False, ragged=False, name=keras_tensor_2219>'],)\nE          kwargs=<class 'inspect._empty'>\n\nstellargraph/layer/rgcn.py:184: ValueError\n________________________ test_RGCN_save_load[False-10] _________________________\n\ntmpdir = local('/tmp/pytest-of-root/pytest-1/test_RGCN_save_load_False_10_0')\nnum_bases = 10, sparse = False\n\n    @pytest.mark.parametrize(\"num_bases\", [0, 10])\n    @pytest.mark.parametrize(\n        \"sparse\", [False, pytest.param(True, marks=pytest.mark.xfail(reason=\"FIXME #1251\"))]\n    )\n    def test_RGCN_save_load(tmpdir, num_bases, sparse):\n        graph, _ = create_graph_features()\n        generator = RelationalFullBatchNodeGenerator(graph, sparse=sparse)\n        rgcn = RGCN([2, 2], generator, num_bases=num_bases)\n>       test_utils.model_save_load(tmpdir, rgcn)\n\ntests/layer/test_rgcn.py:387: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ntests/test_utils/__init__.py:29: in model_save_load\n    model = tf.keras.Model(*sg_model.in_out_tensors())\nstellargraph/layer/rgcn.py:581: in in_out_tensors\n    return self._node_model()\nstellargraph/layer/rgcn.py:557: in _node_model\n    x_out = self(x_inp)\nstellargraph/layer/rgcn.py:512: in __call__\n    h_layer = layer([h_layer] + Ainput)\n/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py:122: in error_handler\n    raise e.with_traceback(filtered_tb) from None\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <RelationalGraphConvolution name=relational_graph_convolution_44, built=True>\ninput_shapes = [(1, 3, 2), (3, 3), (3, 3)]\n\n    def compute_output_shape(self, input_shapes):\n        \"\"\"\n        Computes the output shape of the layer.\n    \n        Args:\n            input_shapes (tuple of int)\n                Shape tuples can include None for free dimensions, instead of an integer.\n    \n        Returns:\n            An input shape tuple.\n        \"\"\"\n>       feature_shape, A_shape = input_shapes\nE       ValueError: Exception encountered when calling RelationalGraphConvolution.call().\nE       \nE       \u001b[1mtoo many values to unpack (expected 2)\u001b[0m\nE       \nE       Arguments received by RelationalGraphConvolution.call():\nE          args=(['<KerasTensor shape=(1, 3, 2), dtype=float32, sparse=False, ragged=False, name=keras_tensor_2231>', '<KerasTensor shape=(3, 3), dtype=float32, sparse=False, ragged=False, name=keras_tensor_2227>', '<KerasTensor shape=(3, 3), dtype=float32, sparse=False, ragged=False, name=keras_tensor_2230>'],)\nE          kwargs=<class 'inspect._empty'>\n\nstellargraph/layer/rgcn.py:184: ValueError\n______________________________ test_AttentiveWalk ______________________________\n\n    def test_AttentiveWalk():\n    \n        random_partial_powers = np.random.random((2, 5, 31))\n        att_wlk = AttentiveWalk(walk_length=5, attention_initializer=\"ones\")\n    \n>       output = att_wlk(random_partial_powers).numpy()\n\ntests/layer/test_watch_your_step.py:42: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py:122: in error_handler\n    raise e.with_traceback(filtered_tb) from None\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <AttentiveWalk name=attentive_walk_1, built=True>\npartial_powers = <tf.Tensor: shape=(2, 5, 31), dtype=float32, numpy=\narray([[[4.39597994e-01, 5.26590347e-01, 3.98089617e-01, 3.4951010...348145e-01, 1.49812609e-01, 2.06426784e-01,\n         7.52075195e-01, 9.32898462e-01, 8.57781351e-01]]], dtype=float32)>\n\n    def call(self, partial_powers):\n        \"\"\"\n        Applies the layer and calculates the expected random walks.\n    \n        Args:\n            partial_powers: num_rows rows of the first num_powers powers of adjacency matrix with shape\n            (num_rows, num_powers, num_nodes)\n    \n        Returns:\n            Tensor that represents the expected random walks starting from nodes corresponding to the input rows of\n            shape (num_rows, num_nodes)\n        \"\"\"\n    \n>       attention = K.softmax(self.attention_weights)\nE       ValueError: Exception encountered when calling AttentiveWalk.call().\nE       \nE       \u001b[1mCannot apply softmax to a tensor that is 1D. Received input: <Variable path=attentive_walk_1/attention_weights, shape=(5,), dtype=float32, value=[1. 1. 1. 1. 1.]>\u001b[0m\nE       \nE       Arguments received by AttentiveWalk.call():\nE          partial_powers=tf.Tensor(shape=(2, 5, 31), dtype=float32)\n\nstellargraph/layer/watch_your_step.py:103: ValueError\n__________________________ test_WatchYourStep[False] ___________________________\n\nbarbell = <stellargraph.core.graph.StellarGraph object at 0x7fc18c555e10>\nweighted = False\n\n    @pytest.mark.parametrize(\"weighted\", [False, True])\n    def test_WatchYourStep(barbell, weighted):\n    \n        generator = AdjacencyPowerGenerator(barbell, num_powers=5, weighted=weighted)\n        gen = generator.flow(batch_size=4)\n        wys = WatchYourStep(generator)\n    \n>       x_in, x_out = wys.in_out_tensors()\n\ntests/layer/test_watch_your_step.py:83: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/layer/watch_your_step.py:228: in in_out_tensors\n    expected_walk = self.num_walks * self._attentive_walk(input_powers)\n/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py:122: in error_handler\n    raise e.with_traceback(filtered_tb) from None\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <AttentiveWalk name=attentive_walk_3, built=True>\ninput_shapes = (None, 5, 31)\n\n    def compute_output_shape(self, input_shapes):\n>       return (input_shapes[0][-1],)\nE       TypeError: Exception encountered when calling AttentiveWalk.call().\nE       \nE       \u001b[1m'NoneType' object is not subscriptable\u001b[0m\nE       \nE       Arguments received by AttentiveWalk.call():\nE          args=('<KerasTensor shape=(None, 5, 31), dtype=float32, sparse=False, ragged=False, name=keras_tensor_2250>',)\nE          kwargs=<class 'inspect._empty'>\n\nstellargraph/layer/watch_your_step.py:72: TypeError\n___________________________ test_WatchYourStep[True] ___________________________\n\nbarbell = <stellargraph.core.graph.StellarGraph object at 0x7fc14541cdf0>\nweighted = True\n\n    @pytest.mark.parametrize(\"weighted\", [False, True])\n    def test_WatchYourStep(barbell, weighted):\n    \n        generator = AdjacencyPowerGenerator(barbell, num_powers=5, weighted=weighted)\n        gen = generator.flow(batch_size=4)\n        wys = WatchYourStep(generator)\n    \n>       x_in, x_out = wys.in_out_tensors()\n\ntests/layer/test_watch_your_step.py:83: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/layer/watch_your_step.py:228: in in_out_tensors\n    expected_walk = self.num_walks * self._attentive_walk(input_powers)\n/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py:122: in error_handler\n    raise e.with_traceback(filtered_tb) from None\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <AttentiveWalk name=attentive_walk_4, built=True>\ninput_shapes = (None, 5, 31)\n\n    def compute_output_shape(self, input_shapes):\n>       return (input_shapes[0][-1],)\nE       TypeError: Exception encountered when calling AttentiveWalk.call().\nE       \nE       \u001b[1m'NoneType' object is not subscriptable\u001b[0m\nE       \nE       Arguments received by AttentiveWalk.call():\nE          args=('<KerasTensor shape=(None, 5, 31), dtype=float32, sparse=False, ragged=False, name=keras_tensor_2253>',)\nE          kwargs=<class 'inspect._empty'>\n\nstellargraph/layer/watch_your_step.py:72: TypeError\n________________________ test_WatchYourStep_embeddings _________________________\n\nbarbell = <stellargraph.core.graph.StellarGraph object at 0x7fc18c52d1e0>\n\n    def test_WatchYourStep_embeddings(barbell):\n        generator = AdjacencyPowerGenerator(barbell, num_powers=5)\n        wys = WatchYourStep(generator, embeddings_initializer=\"ones\")\n>       x_in, x_out = wys.in_out_tensors()\n\ntests/layer/test_watch_your_step.py:102: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/layer/watch_your_step.py:228: in in_out_tensors\n    expected_walk = self.num_walks * self._attentive_walk(input_powers)\n/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py:122: in error_handler\n    raise e.with_traceback(filtered_tb) from None\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <AttentiveWalk name=attentive_walk_5, built=True>\ninput_shapes = (None, 5, 31)\n\n    def compute_output_shape(self, input_shapes):\n>       return (input_shapes[0][-1],)\nE       TypeError: Exception encountered when calling AttentiveWalk.call().\nE       \nE       \u001b[1m'NoneType' object is not subscriptable\u001b[0m\nE       \nE       Arguments received by AttentiveWalk.call():\nE          args=('<KerasTensor shape=(None, 5, 31), dtype=float32, sparse=False, ragged=False, name=keras_tensor_2256>',)\nE          kwargs=<class 'inspect._empty'>\n\nstellargraph/layer/watch_your_step.py:72: TypeError\n_________________________ test_WatchYourStep_save_load _________________________\n\ntmpdir = local('/tmp/pytest-of-root/pytest-1/test_WatchYourStep_save_load0')\nbarbell = <stellargraph.core.graph.StellarGraph object at 0x7fc1ac671390>\n\n    def test_WatchYourStep_save_load(tmpdir, barbell):\n        generator = AdjacencyPowerGenerator(barbell, num_powers=5)\n        wys = WatchYourStep(generator)\n>       test_utils.model_save_load(tmpdir, wys)\n\ntests/layer/test_watch_your_step.py:114: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ntests/test_utils/__init__.py:29: in model_save_load\n    model = tf.keras.Model(*sg_model.in_out_tensors())\nstellargraph/layer/watch_your_step.py:228: in in_out_tensors\n    expected_walk = self.num_walks * self._attentive_walk(input_powers)\n/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py:122: in error_handler\n    raise e.with_traceback(filtered_tb) from None\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <AttentiveWalk name=attentive_walk_6, built=True>\ninput_shapes = (None, 5, 31)\n\n    def compute_output_shape(self, input_shapes):\n>       return (input_shapes[0][-1],)\nE       TypeError: Exception encountered when calling AttentiveWalk.call().\nE       \nE       \u001b[1m'NoneType' object is not subscriptable\u001b[0m\nE       \nE       Arguments received by AttentiveWalk.call():\nE          args=('<KerasTensor shape=(None, 5, 31), dtype=float32, sparse=False, ragged=False, name=keras_tensor_2259>',)\nE          kwargs=<class 'inspect._empty'>\n\nstellargraph/layer/watch_your_step.py:72: TypeError\n_________________________ test_corrupted_invalid_index _________________________\n\n    def test_corrupted_invalid_index():\n>       batch = [_data(0), _data(1)]\n\ntests/mapper/test_corrupted.py:115: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ntests/mapper/test_corrupted.py:110: in _data\n    per_array = np.product(shape)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'product'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n            raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\n    \n        if attr == \"chararray\":\n            warnings.warn(\n                \"`np.chararray` is deprecated and will be removed from \"\n                \"the main namespace in the future. Use an array with a string \"\n                \"or bytes dtype instead.\", DeprecationWarning, stacklevel=2)\n            import numpy.char as char\n            return char.chararray\n    \n>       raise AttributeError(\"module {!r} has no attribute \"\n                             \"{!r}\".format(__name__, attr))\nE       AttributeError: module 'numpy' has no attribute 'product'\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:414: AttributeError\n________________________ test_corrupted_groups[default] ________________________\n\ngroup_param = 'default'\n\n    @pytest.mark.parametrize(\"group_param\", [\"default\", \"override\"])\n    def test_corrupted_groups(group_param):\n>       batch = [_data(0), _data(1), _data(2), _data(3, shape=(3, 10, 10, 6))]\n\ntests/mapper/test_corrupted.py:145: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ntests/mapper/test_corrupted.py:110: in _data\n    per_array = np.product(shape)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'product'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n            raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\n    \n        if attr == \"chararray\":\n            warnings.warn(\n                \"`np.chararray` is deprecated and will be removed from \"\n                \"the main namespace in the future. Use an array with a string \"\n                \"or bytes dtype instead.\", DeprecationWarning, stacklevel=2)\n            import numpy.char as char\n            return char.chararray\n    \n>       raise AttributeError(\"module {!r} has no attribute \"\n                             \"{!r}\".format(__name__, attr))\nE       AttributeError: module 'numpy' has no attribute 'product'\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:414: AttributeError\n_______________________ test_corrupted_groups[override] ________________________\n\ngroup_param = 'override'\n\n    @pytest.mark.parametrize(\"group_param\", [\"default\", \"override\"])\n    def test_corrupted_groups(group_param):\n>       batch = [_data(0), _data(1), _data(2), _data(3, shape=(3, 10, 10, 6))]\n\ntests/mapper/test_corrupted.py:145: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ntests/mapper/test_corrupted.py:110: in _data\n    per_array = np.product(shape)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'product'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n            raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\n    \n        if attr == \"chararray\":\n            warnings.warn(\n                \"`np.chararray` is deprecated and will be removed from \"\n                \"the main namespace in the future. Use an array with a string \"\n                \"or bytes dtype instead.\", DeprecationWarning, stacklevel=2)\n            import numpy.char as char\n            return char.chararray\n    \n>       raise AttributeError(\"module {!r} has no attribute \"\n                             \"{!r}\".format(__name__, attr))\nE       AttributeError: module 'numpy' has no attribute 'product'\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:414: AttributeError\n__________________________ test_corrupted_batching[1] __________________________\n\nbatch_dims = 1\n\n    @pytest.mark.parametrize(\"batch_dims\", [1, 2, 3])\n    def test_corrupted_batching(batch_dims):\n        batch0_shape = (10, 4, 5, 6)\n>       batch0 = [_data(0, shape=batch0_shape)]\n\ntests/mapper/test_corrupted.py:178: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ntests/mapper/test_corrupted.py:110: in _data\n    per_array = np.product(shape)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'product'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n            raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\n    \n        if attr == \"chararray\":\n            warnings.warn(\n                \"`np.chararray` is deprecated and will be removed from \"\n                \"the main namespace in the future. Use an array with a string \"\n                \"or bytes dtype instead.\", DeprecationWarning, stacklevel=2)\n            import numpy.char as char\n            return char.chararray\n    \n>       raise AttributeError(\"module {!r} has no attribute \"\n                             \"{!r}\".format(__name__, attr))\nE       AttributeError: module 'numpy' has no attribute 'product'\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:414: AttributeError\n__________________________ test_corrupted_batching[2] __________________________\n\nbatch_dims = 2\n\n    @pytest.mark.parametrize(\"batch_dims\", [1, 2, 3])\n    def test_corrupted_batching(batch_dims):\n        batch0_shape = (10, 4, 5, 6)\n>       batch0 = [_data(0, shape=batch0_shape)]\n\ntests/mapper/test_corrupted.py:178: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ntests/mapper/test_corrupted.py:110: in _data\n    per_array = np.product(shape)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'product'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n            raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\n    \n        if attr == \"chararray\":\n            warnings.warn(\n                \"`np.chararray` is deprecated and will be removed from \"\n                \"the main namespace in the future. Use an array with a string \"\n                \"or bytes dtype instead.\", DeprecationWarning, stacklevel=2)\n            import numpy.char as char\n            return char.chararray\n    \n>       raise AttributeError(\"module {!r} has no attribute \"\n                             \"{!r}\".format(__name__, attr))\nE       AttributeError: module 'numpy' has no attribute 'product'\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:414: AttributeError\n__________________________ test_corrupted_batching[3] __________________________\n\nbatch_dims = 3\n\n    @pytest.mark.parametrize(\"batch_dims\", [1, 2, 3])\n    def test_corrupted_batching(batch_dims):\n        batch0_shape = (10, 4, 5, 6)\n>       batch0 = [_data(0, shape=batch0_shape)]\n\ntests/mapper/test_corrupted.py:178: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ntests/mapper/test_corrupted.py:110: in _data\n    per_array = np.product(shape)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'product'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n            raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\n    \n        if attr == \"chararray\":\n            warnings.warn(\n                \"`np.chararray` is deprecated and will be removed from \"\n                \"the main namespace in the future. Use an array with a string \"\n                \"or bytes dtype instead.\", DeprecationWarning, stacklevel=2)\n            import numpy.char as char\n            return char.chararray\n    \n>       raise AttributeError(\"module {!r} has no attribute \"\n                             \"{!r}\".format(__name__, attr))\nE       AttributeError: module 'numpy' has no attribute 'product'\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:414: AttributeError\n__________________ test_corrupt_full_batch_generator[True-10] __________________\n\nsparse = True, num_nodes = 10\n\n    @pytest.mark.parametrize(\"num_nodes\", [10, 20])\n    @pytest.mark.parametrize(\"sparse\", [True, False])\n    def test_corrupt_full_batch_generator(sparse, num_nodes):\n    \n        G = example_graph_random(n_nodes=20)\n    \n        generator = FullBatchNodeGenerator(G, sparse=sparse)\n    \n        nodes = G.nodes()[:num_nodes]\n        gen = CorruptedGenerator(generator).flow(nodes)\n    \n>       [shuffled_feats, features, *_], targets = gen[0]\n\ntests/mapper/test_corrupted.py:211: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/mapper/corrupted.py:178: in __getitem__\n    shuffled_feats = [\nstellargraph/mapper/corrupted.py:181: in <listcomp>\n    for corrupted in corrupt_group(group_idx, group)\nstellargraph/mapper/corrupted.py:164: in corrupt_group\n    nodes_per_input = [np.product(feat.shape[:-1]) for feat in feats_orig]\nstellargraph/mapper/corrupted.py:164: in <listcomp>\n    nodes_per_input = [np.product(feat.shape[:-1]) for feat in feats_orig]\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'product'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n            raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\n    \n        if attr == \"chararray\":\n            warnings.warn(\n                \"`np.chararray` is deprecated and will be removed from \"\n                \"the main namespace in the future. Use an array with a string \"\n                \"or bytes dtype instead.\", DeprecationWarning, stacklevel=2)\n            import numpy.char as char\n            return char.chararray\n    \n>       raise AttributeError(\"module {!r} has no attribute \"\n                             \"{!r}\".format(__name__, attr))\nE       AttributeError: module 'numpy' has no attribute 'product'\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:414: AttributeError\n----------------------------- Captured stdout call -----------------------------\nUsing GCN (local pooling) filters...\n__________________ test_corrupt_full_batch_generator[True-20] __________________\n\nsparse = True, num_nodes = 20\n\n    @pytest.mark.parametrize(\"num_nodes\", [10, 20])\n    @pytest.mark.parametrize(\"sparse\", [True, False])\n    def test_corrupt_full_batch_generator(sparse, num_nodes):\n    \n        G = example_graph_random(n_nodes=20)\n    \n        generator = FullBatchNodeGenerator(G, sparse=sparse)\n    \n        nodes = G.nodes()[:num_nodes]\n        gen = CorruptedGenerator(generator).flow(nodes)\n    \n>       [shuffled_feats, features, *_], targets = gen[0]\n\ntests/mapper/test_corrupted.py:211: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/mapper/corrupted.py:178: in __getitem__\n    shuffled_feats = [\nstellargraph/mapper/corrupted.py:181: in <listcomp>\n    for corrupted in corrupt_group(group_idx, group)\nstellargraph/mapper/corrupted.py:164: in corrupt_group\n    nodes_per_input = [np.product(feat.shape[:-1]) for feat in feats_orig]\nstellargraph/mapper/corrupted.py:164: in <listcomp>\n    nodes_per_input = [np.product(feat.shape[:-1]) for feat in feats_orig]\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'product'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n            raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\n    \n        if attr == \"chararray\":\n            warnings.warn(\n                \"`np.chararray` is deprecated and will be removed from \"\n                \"the main namespace in the future. Use an array with a string \"\n                \"or bytes dtype instead.\", DeprecationWarning, stacklevel=2)\n            import numpy.char as char\n            return char.chararray\n    \n>       raise AttributeError(\"module {!r} has no attribute \"\n                             \"{!r}\".format(__name__, attr))\nE       AttributeError: module 'numpy' has no attribute 'product'\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:414: AttributeError\n----------------------------- Captured stdout call -----------------------------\nUsing GCN (local pooling) filters...\n_________________ test_corrupt_full_batch_generator[False-10] __________________\n\nsparse = False, num_nodes = 10\n\n    @pytest.mark.parametrize(\"num_nodes\", [10, 20])\n    @pytest.mark.parametrize(\"sparse\", [True, False])\n    def test_corrupt_full_batch_generator(sparse, num_nodes):\n    \n        G = example_graph_random(n_nodes=20)\n    \n        generator = FullBatchNodeGenerator(G, sparse=sparse)\n    \n        nodes = G.nodes()[:num_nodes]\n        gen = CorruptedGenerator(generator).flow(nodes)\n    \n>       [shuffled_feats, features, *_], targets = gen[0]\n\ntests/mapper/test_corrupted.py:211: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/mapper/corrupted.py:178: in __getitem__\n    shuffled_feats = [\nstellargraph/mapper/corrupted.py:181: in <listcomp>\n    for corrupted in corrupt_group(group_idx, group)\nstellargraph/mapper/corrupted.py:164: in corrupt_group\n    nodes_per_input = [np.product(feat.shape[:-1]) for feat in feats_orig]\nstellargraph/mapper/corrupted.py:164: in <listcomp>\n    nodes_per_input = [np.product(feat.shape[:-1]) for feat in feats_orig]\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'product'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n            raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\n    \n        if attr == \"chararray\":\n            warnings.warn(\n                \"`np.chararray` is deprecated and will be removed from \"\n                \"the main namespace in the future. Use an array with a string \"\n                \"or bytes dtype instead.\", DeprecationWarning, stacklevel=2)\n            import numpy.char as char\n            return char.chararray\n    \n>       raise AttributeError(\"module {!r} has no attribute \"\n                             \"{!r}\".format(__name__, attr))\nE       AttributeError: module 'numpy' has no attribute 'product'\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:414: AttributeError\n----------------------------- Captured stdout call -----------------------------\nUsing GCN (local pooling) filters...\n_________________ test_corrupt_full_batch_generator[False-20] __________________\n\nsparse = False, num_nodes = 20\n\n    @pytest.mark.parametrize(\"num_nodes\", [10, 20])\n    @pytest.mark.parametrize(\"sparse\", [True, False])\n    def test_corrupt_full_batch_generator(sparse, num_nodes):\n    \n        G = example_graph_random(n_nodes=20)\n    \n        generator = FullBatchNodeGenerator(G, sparse=sparse)\n    \n        nodes = G.nodes()[:num_nodes]\n        gen = CorruptedGenerator(generator).flow(nodes)\n    \n>       [shuffled_feats, features, *_], targets = gen[0]\n\ntests/mapper/test_corrupted.py:211: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/mapper/corrupted.py:178: in __getitem__\n    shuffled_feats = [\nstellargraph/mapper/corrupted.py:181: in <listcomp>\n    for corrupted in corrupt_group(group_idx, group)\nstellargraph/mapper/corrupted.py:164: in corrupt_group\n    nodes_per_input = [np.product(feat.shape[:-1]) for feat in feats_orig]\nstellargraph/mapper/corrupted.py:164: in <listcomp>\n    nodes_per_input = [np.product(feat.shape[:-1]) for feat in feats_orig]\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'product'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n            raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\n    \n        if attr == \"chararray\":\n            warnings.warn(\n                \"`np.chararray` is deprecated and will be removed from \"\n                \"the main namespace in the future. Use an array with a string \"\n                \"or bytes dtype instead.\", DeprecationWarning, stacklevel=2)\n            import numpy.char as char\n            return char.chararray\n    \n>       raise AttributeError(\"module {!r} has no attribute \"\n                             \"{!r}\".format(__name__, attr))\nE       AttributeError: module 'numpy' has no attribute 'product'\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:414: AttributeError\n----------------------------- Captured stdout call -----------------------------\nUsing GCN (local pooling) filters...\n____________________ test_corrupt_graphsage_generator[True] ____________________\n\nis_directed = True\n\n    @pytest.mark.parametrize(\"is_directed\", [True, False])\n    def test_corrupt_graphsage_generator(is_directed):\n    \n        G = example_graph_random(n_nodes=20, is_directed=is_directed)\n    \n        if is_directed:\n            generator = DirectedGraphSAGENodeGenerator(\n                G, batch_size=5, in_samples=[2, 3], out_samples=[4, 1]\n            )\n        else:\n            generator = GraphSAGENodeGenerator(G, batch_size=5, num_samples=[2, 3])\n    \n        base_gen = generator.flow(G.nodes())\n        gen = CorruptedGenerator(generator).flow(G.nodes())\n    \n>       x, targets = gen[0]\n\ntests/mapper/test_corrupted.py:241: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/mapper/corrupted.py:178: in __getitem__\n    shuffled_feats = [\nstellargraph/mapper/corrupted.py:181: in <listcomp>\n    for corrupted in corrupt_group(group_idx, group)\nstellargraph/mapper/corrupted.py:164: in corrupt_group\n    nodes_per_input = [np.product(feat.shape[:-1]) for feat in feats_orig]\nstellargraph/mapper/corrupted.py:164: in <listcomp>\n    nodes_per_input = [np.product(feat.shape[:-1]) for feat in feats_orig]\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'product'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n            raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\n    \n        if attr == \"chararray\":\n            warnings.warn(\n                \"`np.chararray` is deprecated and will be removed from \"\n                \"the main namespace in the future. Use an array with a string \"\n                \"or bytes dtype instead.\", DeprecationWarning, stacklevel=2)\n            import numpy.char as char\n            return char.chararray\n    \n>       raise AttributeError(\"module {!r} has no attribute \"\n                             \"{!r}\".format(__name__, attr))\nE       AttributeError: module 'numpy' has no attribute 'product'\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:414: AttributeError\n___________________ test_corrupt_graphsage_generator[False] ____________________\n\nis_directed = False\n\n    @pytest.mark.parametrize(\"is_directed\", [True, False])\n    def test_corrupt_graphsage_generator(is_directed):\n    \n        G = example_graph_random(n_nodes=20, is_directed=is_directed)\n    \n        if is_directed:\n            generator = DirectedGraphSAGENodeGenerator(\n                G, batch_size=5, in_samples=[2, 3], out_samples=[4, 1]\n            )\n        else:\n            generator = GraphSAGENodeGenerator(G, batch_size=5, num_samples=[2, 3])\n    \n        base_gen = generator.flow(G.nodes())\n        gen = CorruptedGenerator(generator).flow(G.nodes())\n    \n>       x, targets = gen[0]\n\ntests/mapper/test_corrupted.py:241: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/mapper/corrupted.py:146: in __getitem__\n    inputs, _ = self.base_sequence[index]\nstellargraph/mapper/sequences.py:139: in __getitem__\n    batch_feats = self._sample_function(head_ids, batch_num)\nstellargraph/mapper/sampled_node_generators.py:264: in sample_features\n    node_samples = self._samplers[batch_num].run(\nstellargraph/data/explorer.py:733: in run\n    neighbours = self._sample_neighbours_untyped(\nstellargraph/data/explorer.py:242: in _sample_neighbours_untyped\n    neighbours = neigh_func(\nstellargraph/core/graph.py:792: in neighbor_arrays\n    edge_ilocs = self._edges.edge_ilocs(node, ins=True, outs=True)\nstellargraph/core/element_data.py:452: in edge_ilocs\n    return self._adj_lookup(ins=ins, outs=outs)[node_id]\nstellargraph/core/element_data.py:410: in _adj_lookup\n    self._init_undirected_adj_lists()\nstellargraph/core/element_data.py:365: in _init_undirected_adj_lists\n    self._edges_dict = self._create_undirected_adj_lists()\nstellargraph/core/element_data.py:377: in _create_undirected_adj_lists\n    sentinel = np.cast[np.min_scalar_type(self.number_of_nodes)](-1)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'cast'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n>           raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\nE           AttributeError: `np.cast` was removed in the NumPy 2.0 release. Use `np.asarray(arr, dtype=dtype)` instead.\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:400: AttributeError\n__________ Test_GraphSAGELinkGenerator.test_GraphSAGELinkGenerator_1 ___________\n\nself = <tests.mapper.test_link_mappers.Test_GraphSAGELinkGenerator object at 0x7fc1ac5251e0>\n\n    def test_GraphSAGELinkGenerator_1(self):\n    \n        G = example_graph(feature_size=self.n_feat)\n        data_size = G.number_of_edges()\n        edge_labels = [0] * data_size\n    \n        mapper = GraphSAGELinkGenerator(\n            G, batch_size=self.batch_size, num_samples=self.num_samples\n        ).flow(G.edges(), edge_labels)\n    \n        assert len(mapper) == 2\n    \n        for batch in range(len(mapper)):\n>           nf, nl = mapper[batch]\n\ntests/mapper/test_link_mappers.py:175: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/mapper/sequences.py:241: in __getitem__\n    batch_feats = self._sample_features(head_ids, batch_num)\nstellargraph/mapper/sampled_link_generators.py:307: in sample_features\n    node_samples = self._samplers[batch_num].run(\nstellargraph/data/explorer.py:733: in run\n    neighbours = self._sample_neighbours_untyped(\nstellargraph/data/explorer.py:242: in _sample_neighbours_untyped\n    neighbours = neigh_func(\nstellargraph/core/graph.py:792: in neighbor_arrays\n    edge_ilocs = self._edges.edge_ilocs(node, ins=True, outs=True)\nstellargraph/core/element_data.py:452: in edge_ilocs\n    return self._adj_lookup(ins=ins, outs=outs)[node_id]\nstellargraph/core/element_data.py:410: in _adj_lookup\n    self._init_undirected_adj_lists()\nstellargraph/core/element_data.py:365: in _init_undirected_adj_lists\n    self._edges_dict = self._create_undirected_adj_lists()\nstellargraph/core/element_data.py:377: in _create_undirected_adj_lists\n    sentinel = np.cast[np.min_scalar_type(self.number_of_nodes)](-1)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'cast'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n>           raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\nE           AttributeError: `np.cast` was removed in the NumPy 2.0 release. Use `np.asarray(arr, dtype=dtype)` instead.\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:400: AttributeError\n_______ Test_GraphSAGELinkGenerator.test_GraphSAGELinkGenerator_shuffle ________\n\nself = <tests.mapper.test_link_mappers.Test_GraphSAGELinkGenerator object at 0x7fc1ac54cdf0>\n\n    def test_GraphSAGELinkGenerator_shuffle(self):\n        def test_edge_consistency(shuffle):\n            G = example_graph(feature_size=1)\n            edges = list(G.edges())\n            edge_labels = list(range(len(edges)))\n    \n            mapper = GraphSAGELinkGenerator(G, batch_size=2, num_samples=[0]).flow(\n                edges, edge_labels, shuffle=shuffle\n            )\n    \n            assert len(mapper) == 2\n    \n            for batch in range(len(mapper)):\n                nf, nl = mapper[batch]\n                e1 = edges[nl[0]]\n                e2 = edges[nl[1]]\n                assert nf[0][0, 0, 0] == e1[0]\n                assert nf[1][0, 0, 0] == e1[1]\n                assert nf[0][1, 0, 0] == e2[0]\n                assert nf[1][1, 0, 0] == e2[1]\n    \n>       test_edge_consistency(True)\n\ntests/mapper/test_link_mappers.py:216: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ntests/mapper/test_link_mappers.py:208: in test_edge_consistency\n    nf, nl = mapper[batch]\nstellargraph/mapper/sequences.py:241: in __getitem__\n    batch_feats = self._sample_features(head_ids, batch_num)\nstellargraph/mapper/sampled_link_generators.py:307: in sample_features\n    node_samples = self._samplers[batch_num].run(\nstellargraph/data/explorer.py:733: in run\n    neighbours = self._sample_neighbours_untyped(\nstellargraph/data/explorer.py:242: in _sample_neighbours_untyped\n    neighbours = neigh_func(\nstellargraph/core/graph.py:792: in neighbor_arrays\n    edge_ilocs = self._edges.edge_ilocs(node, ins=True, outs=True)\nstellargraph/core/element_data.py:452: in edge_ilocs\n    return self._adj_lookup(ins=ins, outs=outs)[node_id]\nstellargraph/core/element_data.py:410: in _adj_lookup\n    self._init_undirected_adj_lists()\nstellargraph/core/element_data.py:365: in _init_undirected_adj_lists\n    self._edges_dict = self._create_undirected_adj_lists()\nstellargraph/core/element_data.py:377: in _create_undirected_adj_lists\n    sentinel = np.cast[np.min_scalar_type(self.number_of_nodes)](-1)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'cast'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n>           raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\nE           AttributeError: `np.cast` was removed in the NumPy 2.0 release. Use `np.asarray(arr, dtype=dtype)` instead.\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:400: AttributeError\n_____ Test_GraphSAGELinkGenerator.test_GraphSAGELinkGenerator_zero_samples _____\n\nself = <tests.mapper.test_link_mappers.Test_GraphSAGELinkGenerator object at 0x7fc1ac54d210>\n\n    def test_GraphSAGELinkGenerator_zero_samples(self):\n    \n        G = example_graph(feature_size=self.n_feat)\n        data_size = G.number_of_edges()\n        edge_labels = [0] * data_size\n    \n        mapper = GraphSAGELinkGenerator(\n            G, batch_size=self.batch_size, num_samples=[0]\n        ).flow(G.edges(), edge_labels)\n    \n        assert len(mapper) == 2\n    \n        for ii in range(len(mapper)):\n>           nf, nl = mapper[ii]\n\ntests/mapper/test_link_mappers.py:262: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/mapper/sequences.py:241: in __getitem__\n    batch_feats = self._sample_features(head_ids, batch_num)\nstellargraph/mapper/sampled_link_generators.py:307: in sample_features\n    node_samples = self._samplers[batch_num].run(\nstellargraph/data/explorer.py:733: in run\n    neighbours = self._sample_neighbours_untyped(\nstellargraph/data/explorer.py:242: in _sample_neighbours_untyped\n    neighbours = neigh_func(\nstellargraph/core/graph.py:792: in neighbor_arrays\n    edge_ilocs = self._edges.edge_ilocs(node, ins=True, outs=True)\nstellargraph/core/element_data.py:452: in edge_ilocs\n    return self._adj_lookup(ins=ins, outs=outs)[node_id]\nstellargraph/core/element_data.py:410: in _adj_lookup\n    self._init_undirected_adj_lists()\nstellargraph/core/element_data.py:365: in _init_undirected_adj_lists\n    self._edges_dict = self._create_undirected_adj_lists()\nstellargraph/core/element_data.py:377: in _create_undirected_adj_lists\n    sentinel = np.cast[np.min_scalar_type(self.number_of_nodes)](-1)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'cast'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n>           raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\nE           AttributeError: `np.cast` was removed in the NumPy 2.0 release. Use `np.asarray(arr, dtype=dtype)` instead.\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:400: AttributeError\n______ Test_GraphSAGELinkGenerator.test_GraphSAGELinkGenerator_no_targets ______\n\nself = <tests.mapper.test_link_mappers.Test_GraphSAGELinkGenerator object at 0x7fc1ac54d510>\n\n    def test_GraphSAGELinkGenerator_no_targets(self):\n        \"\"\"\n        This tests link generator's iterator for prediction, i.e., without targets provided\n        \"\"\"\n        G = example_graph(feature_size=self.n_feat)\n        gen = GraphSAGELinkGenerator(\n            G, batch_size=self.batch_size, num_samples=self.num_samples\n        ).flow(G.edges())\n        for i in range(len(gen)):\n>           assert gen[i][1] is None\n\ntests/mapper/test_link_mappers.py:307: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/mapper/sequences.py:241: in __getitem__\n    batch_feats = self._sample_features(head_ids, batch_num)\nstellargraph/mapper/sampled_link_generators.py:307: in sample_features\n    node_samples = self._samplers[batch_num].run(\nstellargraph/data/explorer.py:733: in run\n    neighbours = self._sample_neighbours_untyped(\nstellargraph/data/explorer.py:242: in _sample_neighbours_untyped\n    neighbours = neigh_func(\nstellargraph/core/graph.py:792: in neighbor_arrays\n    edge_ilocs = self._edges.edge_ilocs(node, ins=True, outs=True)\nstellargraph/core/element_data.py:452: in edge_ilocs\n    return self._adj_lookup(ins=ins, outs=outs)[node_id]\nstellargraph/core/element_data.py:410: in _adj_lookup\n    self._init_undirected_adj_lists()\nstellargraph/core/element_data.py:365: in _init_undirected_adj_lists\n    self._edges_dict = self._create_undirected_adj_lists()\nstellargraph/core/element_data.py:377: in _create_undirected_adj_lists\n    sentinel = np.cast[np.min_scalar_type(self.number_of_nodes)](-1)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'cast'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n>           raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\nE           AttributeError: `np.cast` was removed in the NumPy 2.0 release. Use `np.asarray(arr, dtype=dtype)` instead.\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:400: AttributeError\n_______ Test_GraphSAGELinkGenerator.test_GraphSAGELinkGenerator_isolates _______\n\nself = <tests.mapper.test_link_mappers.Test_GraphSAGELinkGenerator object at 0x7fc1ac54d690>\n\n    def test_GraphSAGELinkGenerator_isolates(self):\n        \"\"\"\n        Test for handling of isolated nodes\n        \"\"\"\n        n_feat = 4\n        n_batch = 2\n        n_samples = [2, 2]\n    \n        # test graph\n        G = example_graph_random(\n            feature_size=n_feat, n_nodes=6, n_isolates=2, n_edges=10\n        )\n    \n        # Check sizes with one isolated node\n        head_links = [(1, 5)]\n        gen = GraphSAGELinkGenerator(G, batch_size=n_batch, num_samples=n_samples).flow(\n            head_links\n        )\n    \n>       ne, nl = gen[0]\n\ntests/mapper/test_link_mappers.py:328: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/mapper/sequences.py:241: in __getitem__\n    batch_feats = self._sample_features(head_ids, batch_num)\nstellargraph/mapper/sampled_link_generators.py:307: in sample_features\n    node_samples = self._samplers[batch_num].run(\nstellargraph/data/explorer.py:733: in run\n    neighbours = self._sample_neighbours_untyped(\nstellargraph/data/explorer.py:242: in _sample_neighbours_untyped\n    neighbours = neigh_func(\nstellargraph/core/graph.py:792: in neighbor_arrays\n    edge_ilocs = self._edges.edge_ilocs(node, ins=True, outs=True)\nstellargraph/core/element_data.py:452: in edge_ilocs\n    return self._adj_lookup(ins=ins, outs=outs)[node_id]\nstellargraph/core/element_data.py:410: in _adj_lookup\n    self._init_undirected_adj_lists()\nstellargraph/core/element_data.py:365: in _init_undirected_adj_lists\n    self._edges_dict = self._create_undirected_adj_lists()\nstellargraph/core/element_data.py:377: in _create_undirected_adj_lists\n    sentinel = np.cast[np.min_scalar_type(self.number_of_nodes)](-1)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'cast'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n>           raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\nE           AttributeError: `np.cast` was removed in the NumPy 2.0 release. Use `np.asarray(arr, dtype=dtype)` instead.\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:400: AttributeError\n_ Test_GraphSAGELinkGenerator.test_GraphSAGELinkGenerator_unsupervisedSampler_flow _\n\nself = <tests.mapper.test_link_mappers.Test_GraphSAGELinkGenerator object at 0x7fc1ac54d810>\n\n    def test_GraphSAGELinkGenerator_unsupervisedSampler_flow(self):\n        \"\"\"\n        This tests link generator's initialization for on demand link generation i.e. there is no pregenerated list of samples provided to it.\n        \"\"\"\n        n_feat = 4\n        n_batch = 2\n        n_samples = [2, 2]\n    \n        # test graph\n        G = example_graph_random(\n            feature_size=n_feat, n_nodes=6, n_isolates=2, n_edges=10\n        )\n    \n        unsupervisedSamples = UnsupervisedSampler(G, nodes=G.nodes())\n    \n>       gen = GraphSAGELinkGenerator(G, batch_size=n_batch, num_samples=n_samples).flow(\n            unsupervisedSamples\n        )\n\ntests/mapper/test_link_mappers.py:355: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/mapper/sampled_link_generators.py:128: in flow\n    return OnDemandLinkSequence(self.sample_features, self.batch_size, link_ids)\nstellargraph/mapper/sequences.py:289: in __init__\n    self._batches = self._create_batches()\nstellargraph/mapper/sequences.py:326: in _create_batches\n    return self.walker.run(self.batch_size)\nstellargraph/data/unsupervised_sampler.py:148: in run\n    degrees = self.graph.node_degrees(use_ilocs=True)\nstellargraph/core/graph.py:1546: in node_degrees\n    degrees = self._edges.degrees()\nstellargraph/core/element_data.py:437: in degrees\n    adj = self._adj_lookup(ins=ins, outs=outs)\nstellargraph/core/element_data.py:410: in _adj_lookup\n    self._init_undirected_adj_lists()\nstellargraph/core/element_data.py:365: in _init_undirected_adj_lists\n    self._edges_dict = self._create_undirected_adj_lists()\nstellargraph/core/element_data.py:377: in _create_undirected_adj_lists\n    sentinel = np.cast[np.min_scalar_type(self.number_of_nodes)](-1)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'cast'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n>           raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\nE           AttributeError: `np.cast` was removed in the NumPy 2.0 release. Use `np.asarray(arr, dtype=dtype)` instead.\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:400: AttributeError\n_ Test_GraphSAGELinkGenerator.test_GraphSAGELinkGenerator_unsupervisedSampler_sample_generation _\n\nself = <tests.mapper.test_link_mappers.Test_GraphSAGELinkGenerator object at 0x7fc1ac54d990>\n\n    def test_GraphSAGELinkGenerator_unsupervisedSampler_sample_generation(self):\n    \n        G = example_graph(feature_size=self.n_feat)\n    \n        unsupervisedSamples = UnsupervisedSampler(G)\n    \n        gen = GraphSAGELinkGenerator(\n            G, batch_size=self.batch_size, num_samples=self.num_samples\n        )\n>       mapper = gen.flow(unsupervisedSamples)\n\ntests/mapper/test_link_mappers.py:380: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/mapper/sampled_link_generators.py:128: in flow\n    return OnDemandLinkSequence(self.sample_features, self.batch_size, link_ids)\nstellargraph/mapper/sequences.py:289: in __init__\n    self._batches = self._create_batches()\nstellargraph/mapper/sequences.py:326: in _create_batches\n    return self.walker.run(self.batch_size)\nstellargraph/data/unsupervised_sampler.py:148: in run\n    degrees = self.graph.node_degrees(use_ilocs=True)\nstellargraph/core/graph.py:1546: in node_degrees\n    degrees = self._edges.degrees()\nstellargraph/core/element_data.py:437: in degrees\n    adj = self._adj_lookup(ins=ins, outs=outs)\nstellargraph/core/element_data.py:410: in _adj_lookup\n    self._init_undirected_adj_lists()\nstellargraph/core/element_data.py:365: in _init_undirected_adj_lists\n    self._edges_dict = self._create_undirected_adj_lists()\nstellargraph/core/element_data.py:377: in _create_undirected_adj_lists\n    sentinel = np.cast[np.min_scalar_type(self.number_of_nodes)](-1)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'cast'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n>           raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\nE           AttributeError: `np.cast` was removed in the NumPy 2.0 release. Use `np.asarray(arr, dtype=dtype)` instead.\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:400: AttributeError\n__________________ Test_GraphSAGELinkGenerator.test_weighted ___________________\n\nself = <tests.mapper.test_link_mappers.Test_GraphSAGELinkGenerator object at 0x7fc1ac54db10>\n\n    def test_weighted(self):\n        g, checker = weighted_tree()\n    \n        gen = GraphSAGELinkGenerator(g, 7, [10, 5], weighted=True)\n        samples = gen.flow([(0, 0)] * 10)\n>       checker(node_id for array in samples[0][0] for node_id in array.ravel())\n\ntests/mapper/test_link_mappers.py:418: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/mapper/sequences.py:241: in __getitem__\n    batch_feats = self._sample_features(head_ids, batch_num)\nstellargraph/mapper/sampled_link_generators.py:307: in sample_features\n    node_samples = self._samplers[batch_num].run(\nstellargraph/data/explorer.py:733: in run\n    neighbours = self._sample_neighbours_untyped(\nstellargraph/data/explorer.py:242: in _sample_neighbours_untyped\n    neighbours = neigh_func(\nstellargraph/core/graph.py:792: in neighbor_arrays\n    edge_ilocs = self._edges.edge_ilocs(node, ins=True, outs=True)\nstellargraph/core/element_data.py:452: in edge_ilocs\n    return self._adj_lookup(ins=ins, outs=outs)[node_id]\nstellargraph/core/element_data.py:410: in _adj_lookup\n    self._init_undirected_adj_lists()\nstellargraph/core/element_data.py:365: in _init_undirected_adj_lists\n    self._edges_dict = self._create_undirected_adj_lists()\nstellargraph/core/element_data.py:377: in _create_undirected_adj_lists\n    sentinel = np.cast[np.min_scalar_type(self.number_of_nodes)](-1)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'cast'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n>           raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\nE           AttributeError: `np.cast` was removed in the NumPy 2.0 release. Use `np.asarray(arr, dtype=dtype)` instead.\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:400: AttributeError\n__ Test_HinSAGELinkGenerator.test_HinSAGELinkGenerator_homogeneous_inference ___\n\nself = <tests.mapper.test_link_mappers.Test_HinSAGELinkGenerator object at 0x7fc1ac54e020>\n\n    def test_HinSAGELinkGenerator_homogeneous_inference(self):\n        feature_size = 4\n        edge_types = 3\n        batch_size = 2\n        num_samples = [5, 7]\n        G = example_graph_random(\n            feature_size=feature_size, node_types=1, edge_types=edge_types\n        )\n    \n        # G is homogeneous so the head_node_types argument isn't required\n        mapper = HinSAGELinkGenerator(G, batch_size=batch_size, num_samples=num_samples)\n    \n        assert mapper.head_node_types == [\"n-0\", \"n-0\"]\n    \n        links = [(1, 4), (2, 3), (4, 1)]\n        seq = mapper.flow(links)\n        assert len(seq) == 2\n    \n        samples_per_head = 1 + edge_types + edge_types * edge_types\n        for batch_idx, (samples, labels) in enumerate(seq):\n            this_batch_size = {0: batch_size, 1: 1}[batch_idx]\n    \n            assert len(samples) == 2 * samples_per_head\n    \n            for i in range(0, 2):\n                assert samples[i].shape == (this_batch_size, 1, feature_size)\n            for i in range(2, 2 * (1 + edge_types)):\n                assert samples[i].shape == (\n                    this_batch_size,\n                    num_samples[0],\n                    feature_size,\n                )\n            for i in range(2 * (1 + edge_types), 2 * samples_per_head):\n                assert samples[i].shape == (\n                    this_batch_size,\n>                   np.product(num_samples),\n                    feature_size,\n                )\n\ntests/mapper/test_link_mappers.py:529: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'product'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n            raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\n    \n        if attr == \"chararray\":\n            warnings.warn(\n                \"`np.chararray` is deprecated and will be removed from \"\n                \"the main namespace in the future. Use an array with a string \"\n                \"or bytes dtype instead.\", DeprecationWarning, stacklevel=2)\n            import numpy.char as char\n            return char.chararray\n    \n>       raise AttributeError(\"module {!r} has no attribute \"\n                             \"{!r}\".format(__name__, attr))\nE       AttributeError: module 'numpy' has no attribute 'product'\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:414: AttributeError\n_ Test_Attri2VecLinkGenerator.test_Attri2VecLinkGenerator_unsupervisedSampler_flow _\n\nself = <tests.mapper.test_link_mappers.Test_Attri2VecLinkGenerator object at 0x7fc1ac54dcc0>\n\n    def test_Attri2VecLinkGenerator_unsupervisedSampler_flow(self):\n        \"\"\"\n        This tests link generator's initialization for on demand link generation i.e. there is no pregenerated list of samples provided to it.\n        \"\"\"\n        n_feat = 4\n        n_batch = 2\n    \n        # test graph\n        G = example_graph_random(\n            feature_size=n_feat, n_nodes=6, n_isolates=2, n_edges=10\n        )\n    \n        unsupervisedSamples = UnsupervisedSampler(G, nodes=G.nodes())\n    \n>       gen = Attri2VecLinkGenerator(G, batch_size=n_batch).flow(unsupervisedSamples)\n\ntests/mapper/test_link_mappers.py:784: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/mapper/sampled_link_generators.py:128: in flow\n    return OnDemandLinkSequence(self.sample_features, self.batch_size, link_ids)\nstellargraph/mapper/sequences.py:289: in __init__\n    self._batches = self._create_batches()\nstellargraph/mapper/sequences.py:326: in _create_batches\n    return self.walker.run(self.batch_size)\nstellargraph/data/unsupervised_sampler.py:148: in run\n    degrees = self.graph.node_degrees(use_ilocs=True)\nstellargraph/core/graph.py:1546: in node_degrees\n    degrees = self._edges.degrees()\nstellargraph/core/element_data.py:437: in degrees\n    adj = self._adj_lookup(ins=ins, outs=outs)\nstellargraph/core/element_data.py:410: in _adj_lookup\n    self._init_undirected_adj_lists()\nstellargraph/core/element_data.py:365: in _init_undirected_adj_lists\n    self._edges_dict = self._create_undirected_adj_lists()\nstellargraph/core/element_data.py:377: in _create_undirected_adj_lists\n    sentinel = np.cast[np.min_scalar_type(self.number_of_nodes)](-1)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'cast'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n>           raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\nE           AttributeError: `np.cast` was removed in the NumPy 2.0 release. Use `np.asarray(arr, dtype=dtype)` instead.\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:400: AttributeError\n_ Test_Attri2VecLinkGenerator.test_Attri2VecLinkGenerator_unsupervisedSampler_sample_generation _\n\nself = <tests.mapper.test_link_mappers.Test_Attri2VecLinkGenerator object at 0x7fc1ac54d900>\n\n    def test_Attri2VecLinkGenerator_unsupervisedSampler_sample_generation(self):\n    \n        G = example_graph(feature_size=self.n_feat)\n    \n        unsupervisedSamples = UnsupervisedSampler(G)\n    \n>       mapper = Attri2VecLinkGenerator(G, batch_size=self.batch_size).flow(\n            unsupervisedSamples\n        )\n\ntests/mapper/test_link_mappers.py:802: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/mapper/sampled_link_generators.py:128: in flow\n    return OnDemandLinkSequence(self.sample_features, self.batch_size, link_ids)\nstellargraph/mapper/sequences.py:289: in __init__\n    self._batches = self._create_batches()\nstellargraph/mapper/sequences.py:326: in _create_batches\n    return self.walker.run(self.batch_size)\nstellargraph/data/unsupervised_sampler.py:148: in run\n    degrees = self.graph.node_degrees(use_ilocs=True)\nstellargraph/core/graph.py:1546: in node_degrees\n    degrees = self._edges.degrees()\nstellargraph/core/element_data.py:437: in degrees\n    adj = self._adj_lookup(ins=ins, outs=outs)\nstellargraph/core/element_data.py:410: in _adj_lookup\n    self._init_undirected_adj_lists()\nstellargraph/core/element_data.py:365: in _init_undirected_adj_lists\n    self._edges_dict = self._create_undirected_adj_lists()\nstellargraph/core/element_data.py:377: in _create_undirected_adj_lists\n    sentinel = np.cast[np.min_scalar_type(self.number_of_nodes)](-1)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'cast'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n>           raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\nE           AttributeError: `np.cast` was removed in the NumPy 2.0 release. Use `np.asarray(arr, dtype=dtype)` instead.\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:400: AttributeError\n_ Test_Node2VecLinkGenerator.test_Node2VecLinkGenerator_unsupervisedSampler_flow _\n\nself = <tests.mapper.test_link_mappers.Test_Node2VecLinkGenerator object at 0x7fc1ac54f0a0>\n\n    def test_Node2VecLinkGenerator_unsupervisedSampler_flow(self):\n        \"\"\"\n        This tests link generator's initialization for on demand link generation i.e. there is no pregenerated list of samples provided to it.\n        \"\"\"\n        n_feat = 4\n        n_batch = 2\n    \n        # test graph\n        G = example_graph_random(feature_size=None, n_nodes=6, n_isolates=2, n_edges=10)\n    \n        unsupervisedSamples = UnsupervisedSampler(G, nodes=G.nodes())\n    \n>       gen = Node2VecLinkGenerator(G, batch_size=n_batch).flow(unsupervisedSamples)\n\ntests/mapper/test_link_mappers.py:921: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/mapper/sampled_link_generators.py:128: in flow\n    return OnDemandLinkSequence(self.sample_features, self.batch_size, link_ids)\nstellargraph/mapper/sequences.py:289: in __init__\n    self._batches = self._create_batches()\nstellargraph/mapper/sequences.py:326: in _create_batches\n    return self.walker.run(self.batch_size)\nstellargraph/data/unsupervised_sampler.py:148: in run\n    degrees = self.graph.node_degrees(use_ilocs=True)\nstellargraph/core/graph.py:1546: in node_degrees\n    degrees = self._edges.degrees()\nstellargraph/core/element_data.py:437: in degrees\n    adj = self._adj_lookup(ins=ins, outs=outs)\nstellargraph/core/element_data.py:410: in _adj_lookup\n    self._init_undirected_adj_lists()\nstellargraph/core/element_data.py:365: in _init_undirected_adj_lists\n    self._edges_dict = self._create_undirected_adj_lists()\nstellargraph/core/element_data.py:377: in _create_undirected_adj_lists\n    sentinel = np.cast[np.min_scalar_type(self.number_of_nodes)](-1)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'cast'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n>           raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\nE           AttributeError: `np.cast` was removed in the NumPy 2.0 release. Use `np.asarray(arr, dtype=dtype)` instead.\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:400: AttributeError\n_ Test_Node2VecLinkGenerator.test_Node2VecLinkGenerator_unsupervisedSampler_sample_generation _\n\nself = <tests.mapper.test_link_mappers.Test_Node2VecLinkGenerator object at 0x7fc1ac54f220>\n\n    def test_Node2VecLinkGenerator_unsupervisedSampler_sample_generation(self):\n    \n        G = example_graph()\n    \n        unsupervisedSamples = UnsupervisedSampler(G)\n    \n>       mapper = Node2VecLinkGenerator(G, batch_size=self.batch_size).flow(\n            unsupervisedSamples\n        )\n\ntests/mapper/test_link_mappers.py:939: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/mapper/sampled_link_generators.py:128: in flow\n    return OnDemandLinkSequence(self.sample_features, self.batch_size, link_ids)\nstellargraph/mapper/sequences.py:289: in __init__\n    self._batches = self._create_batches()\nstellargraph/mapper/sequences.py:326: in _create_batches\n    return self.walker.run(self.batch_size)\nstellargraph/data/unsupervised_sampler.py:148: in run\n    degrees = self.graph.node_degrees(use_ilocs=True)\nstellargraph/core/graph.py:1546: in node_degrees\n    degrees = self._edges.degrees()\nstellargraph/core/element_data.py:437: in degrees\n    adj = self._adj_lookup(ins=ins, outs=outs)\nstellargraph/core/element_data.py:410: in _adj_lookup\n    self._init_undirected_adj_lists()\nstellargraph/core/element_data.py:365: in _init_undirected_adj_lists\n    self._edges_dict = self._create_undirected_adj_lists()\nstellargraph/core/element_data.py:377: in _create_undirected_adj_lists\n    sentinel = np.cast[np.min_scalar_type(self.number_of_nodes)](-1)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'cast'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n>           raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\nE           AttributeError: `np.cast` was removed in the NumPy 2.0 release. Use `np.asarray(arr, dtype=dtype)` instead.\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:400: AttributeError\n______ Test_DirectedGraphSAGELinkGenerator.test_unsupervisedSampler_flow _______\n\nself = <tests.mapper.test_link_mappers.Test_DirectedGraphSAGELinkGenerator object at 0x7fc1ac54fbb0>\n\n    def test_unsupervisedSampler_flow(self):\n        \"\"\"\n        This tests link generator's initialization for on demand link generation i.e. there is no pregenerated list of samples provided to it.\n        \"\"\"\n        n_feat = 4\n        n_batch = 2\n        n_samples = [2, 2]\n    \n        # test graph\n        G = example_graph_random(\n            feature_size=n_feat, n_nodes=6, n_isolates=2, n_edges=10, is_directed=True\n        )\n    \n        unsupervisedSamples = UnsupervisedSampler(G, nodes=G.nodes())\n    \n        gen = DirectedGraphSAGELinkGenerator(\n            G,\n            batch_size=n_batch,\n            in_samples=self.in_samples,\n            out_samples=self.out_samples,\n>       ).flow(unsupervisedSamples)\n\ntests/mapper/test_link_mappers.py:1181: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/mapper/sampled_link_generators.py:128: in flow\n    return OnDemandLinkSequence(self.sample_features, self.batch_size, link_ids)\nstellargraph/mapper/sequences.py:289: in __init__\n    self._batches = self._create_batches()\nstellargraph/mapper/sequences.py:326: in _create_batches\n    return self.walker.run(self.batch_size)\nstellargraph/data/unsupervised_sampler.py:148: in run\n    degrees = self.graph.node_degrees(use_ilocs=True)\nstellargraph/core/graph.py:1546: in node_degrees\n    degrees = self._edges.degrees()\nstellargraph/core/element_data.py:437: in degrees\n    adj = self._adj_lookup(ins=ins, outs=outs)\nstellargraph/core/element_data.py:410: in _adj_lookup\n    self._init_undirected_adj_lists()\nstellargraph/core/element_data.py:365: in _init_undirected_adj_lists\n    self._edges_dict = self._create_undirected_adj_lists()\nstellargraph/core/element_data.py:377: in _create_undirected_adj_lists\n    sentinel = np.cast[np.min_scalar_type(self.number_of_nodes)](-1)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'cast'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n>           raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\nE           AttributeError: `np.cast` was removed in the NumPy 2.0 release. Use `np.asarray(arr, dtype=dtype)` instead.\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:400: AttributeError\n_ Test_DirectedGraphSAGELinkGenerator.test_unsupervisedSampler_sample_generation _\n\nself = <tests.mapper.test_link_mappers.Test_DirectedGraphSAGELinkGenerator object at 0x7fc1ac54f550>\n\n    def test_unsupervisedSampler_sample_generation(self):\n    \n        G = example_graph(feature_size=self.n_feat, is_directed=True)\n    \n        unsupervisedSamples = UnsupervisedSampler(G)\n    \n        gen = DirectedGraphSAGELinkGenerator(\n            G,\n            batch_size=self.batch_size,\n            in_samples=self.in_samples,\n            out_samples=self.out_samples,\n        )\n>       mapper = gen.flow(unsupervisedSamples)\n\ntests/mapper/test_link_mappers.py:1213: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/mapper/sampled_link_generators.py:128: in flow\n    return OnDemandLinkSequence(self.sample_features, self.batch_size, link_ids)\nstellargraph/mapper/sequences.py:289: in __init__\n    self._batches = self._create_batches()\nstellargraph/mapper/sequences.py:326: in _create_batches\n    return self.walker.run(self.batch_size)\nstellargraph/data/unsupervised_sampler.py:148: in run\n    degrees = self.graph.node_degrees(use_ilocs=True)\nstellargraph/core/graph.py:1546: in node_degrees\n    degrees = self._edges.degrees()\nstellargraph/core/element_data.py:437: in degrees\n    adj = self._adj_lookup(ins=ins, outs=outs)\nstellargraph/core/element_data.py:410: in _adj_lookup\n    self._init_undirected_adj_lists()\nstellargraph/core/element_data.py:365: in _init_undirected_adj_lists\n    self._edges_dict = self._create_undirected_adj_lists()\nstellargraph/core/element_data.py:377: in _create_undirected_adj_lists\n    sentinel = np.cast[np.min_scalar_type(self.number_of_nodes)](-1)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'cast'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n>           raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\nE           AttributeError: `np.cast` was removed in the NumPy 2.0 release. Use `np.asarray(arr, dtype=dtype)` instead.\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:400: AttributeError\n______________________________ test_nodemapper_1 _______________________________\n\n    def test_nodemapper_1():\n        n_feat = 4\n        n_batch = 2\n    \n        # test graph\n        G1 = example_graph(n_feat)\n    \n        mapper1 = GraphSAGENodeGenerator(G1, batch_size=n_batch, num_samples=[2, 2]).flow(\n            G1.nodes()\n        )\n        assert len(mapper1) == 2\n    \n        G2 = example_graph_2(n_feat)\n    \n        mapper2 = GraphSAGENodeGenerator(G2, batch_size=n_batch, num_samples=[2, 2]).flow(\n            G2.nodes()\n        )\n        assert len(mapper2) == 3\n    \n        for mapper in [mapper1, mapper2]:\n            for ii in range(2):\n>               nf, nl = mapper[ii]\n\ntests/mapper/test_node_mappers.py:166: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/mapper/sequences.py:139: in __getitem__\n    batch_feats = self._sample_function(head_ids, batch_num)\nstellargraph/mapper/sampled_node_generators.py:264: in sample_features\n    node_samples = self._samplers[batch_num].run(\nstellargraph/data/explorer.py:733: in run\n    neighbours = self._sample_neighbours_untyped(\nstellargraph/data/explorer.py:242: in _sample_neighbours_untyped\n    neighbours = neigh_func(\nstellargraph/core/graph.py:792: in neighbor_arrays\n    edge_ilocs = self._edges.edge_ilocs(node, ins=True, outs=True)\nstellargraph/core/element_data.py:452: in edge_ilocs\n    return self._adj_lookup(ins=ins, outs=outs)[node_id]\nstellargraph/core/element_data.py:410: in _adj_lookup\n    self._init_undirected_adj_lists()\nstellargraph/core/element_data.py:365: in _init_undirected_adj_lists\n    self._edges_dict = self._create_undirected_adj_lists()\nstellargraph/core/element_data.py:377: in _create_undirected_adj_lists\n    sentinel = np.cast[np.min_scalar_type(self.number_of_nodes)](-1)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'cast'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n>           raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\nE           AttributeError: `np.cast` was removed in the NumPy 2.0 release. Use `np.asarray(arr, dtype=dtype)` instead.\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:400: AttributeError\n________________________ test_nodemapper_shuffle[True] _________________________\n\nshuffle = True\n\n    @pytest.mark.parametrize(\"shuffle\", [True, False])\n    def test_nodemapper_shuffle(shuffle):\n        n_feat = 1\n        n_batch = 2\n    \n        G = example_graph_2(feature_size=n_feat)\n        nodes = list(G.nodes())\n    \n        def flatten_features(seq):\n            # check (features == labels) and return flattened features\n            batches = [\n                (np.ravel(seq[i][0][0]), np.array(seq[i][1])) for i in range(len(seq))\n            ]\n            features, labels = zip(*batches)\n            features, labels = np.concatenate(features), np.concatenate(labels)\n            assert all(features == labels)\n            return features\n    \n        def consecutive_epochs(seq):\n            features = flatten_features(seq)\n            seq.on_epoch_end()\n            features_next = flatten_features(seq)\n            return features, features_next\n    \n        seq = GraphSAGENodeGenerator(G, batch_size=n_batch, num_samples=[0]).flow(\n            nodes, nodes, shuffle=shuffle\n        )\n    \n        max_iter = 5\n        comparison_results = set()\n    \n        for i in range(max_iter):\n>           f1, f2 = consecutive_epochs(seq)\n\ntests/mapper/test_node_mappers.py:220: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ntests/mapper/test_node_mappers.py:207: in consecutive_epochs\n    features = flatten_features(seq)\ntests/mapper/test_node_mappers.py:198: in flatten_features\n    batches = [\ntests/mapper/test_node_mappers.py:199: in <listcomp>\n    (np.ravel(seq[i][0][0]), np.array(seq[i][1])) for i in range(len(seq))\nstellargraph/mapper/sequences.py:139: in __getitem__\n    batch_feats = self._sample_function(head_ids, batch_num)\nstellargraph/mapper/sampled_node_generators.py:264: in sample_features\n    node_samples = self._samplers[batch_num].run(\nstellargraph/data/explorer.py:733: in run\n    neighbours = self._sample_neighbours_untyped(\nstellargraph/data/explorer.py:242: in _sample_neighbours_untyped\n    neighbours = neigh_func(\nstellargraph/core/graph.py:792: in neighbor_arrays\n    edge_ilocs = self._edges.edge_ilocs(node, ins=True, outs=True)\nstellargraph/core/element_data.py:452: in edge_ilocs\n    return self._adj_lookup(ins=ins, outs=outs)[node_id]\nstellargraph/core/element_data.py:410: in _adj_lookup\n    self._init_undirected_adj_lists()\nstellargraph/core/element_data.py:365: in _init_undirected_adj_lists\n    self._edges_dict = self._create_undirected_adj_lists()\nstellargraph/core/element_data.py:377: in _create_undirected_adj_lists\n    sentinel = np.cast[np.min_scalar_type(self.number_of_nodes)](-1)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'cast'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n>           raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\nE           AttributeError: `np.cast` was removed in the NumPy 2.0 release. Use `np.asarray(arr, dtype=dtype)` instead.\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:400: AttributeError\n________________________ test_nodemapper_shuffle[False] ________________________\n\nshuffle = False\n\n    @pytest.mark.parametrize(\"shuffle\", [True, False])\n    def test_nodemapper_shuffle(shuffle):\n        n_feat = 1\n        n_batch = 2\n    \n        G = example_graph_2(feature_size=n_feat)\n        nodes = list(G.nodes())\n    \n        def flatten_features(seq):\n            # check (features == labels) and return flattened features\n            batches = [\n                (np.ravel(seq[i][0][0]), np.array(seq[i][1])) for i in range(len(seq))\n            ]\n            features, labels = zip(*batches)\n            features, labels = np.concatenate(features), np.concatenate(labels)\n            assert all(features == labels)\n            return features\n    \n        def consecutive_epochs(seq):\n            features = flatten_features(seq)\n            seq.on_epoch_end()\n            features_next = flatten_features(seq)\n            return features, features_next\n    \n        seq = GraphSAGENodeGenerator(G, batch_size=n_batch, num_samples=[0]).flow(\n            nodes, nodes, shuffle=shuffle\n        )\n    \n        max_iter = 5\n        comparison_results = set()\n    \n        for i in range(max_iter):\n>           f1, f2 = consecutive_epochs(seq)\n\ntests/mapper/test_node_mappers.py:220: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ntests/mapper/test_node_mappers.py:207: in consecutive_epochs\n    features = flatten_features(seq)\ntests/mapper/test_node_mappers.py:198: in flatten_features\n    batches = [\ntests/mapper/test_node_mappers.py:199: in <listcomp>\n    (np.ravel(seq[i][0][0]), np.array(seq[i][1])) for i in range(len(seq))\nstellargraph/mapper/sequences.py:139: in __getitem__\n    batch_feats = self._sample_function(head_ids, batch_num)\nstellargraph/mapper/sampled_node_generators.py:264: in sample_features\n    node_samples = self._samplers[batch_num].run(\nstellargraph/data/explorer.py:733: in run\n    neighbours = self._sample_neighbours_untyped(\nstellargraph/data/explorer.py:242: in _sample_neighbours_untyped\n    neighbours = neigh_func(\nstellargraph/core/graph.py:792: in neighbor_arrays\n    edge_ilocs = self._edges.edge_ilocs(node, ins=True, outs=True)\nstellargraph/core/element_data.py:452: in edge_ilocs\n    return self._adj_lookup(ins=ins, outs=outs)[node_id]\nstellargraph/core/element_data.py:410: in _adj_lookup\n    self._init_undirected_adj_lists()\nstellargraph/core/element_data.py:365: in _init_undirected_adj_lists\n    self._edges_dict = self._create_undirected_adj_lists()\nstellargraph/core/element_data.py:377: in _create_undirected_adj_lists\n    sentinel = np.cast[np.min_scalar_type(self.number_of_nodes)](-1)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'cast'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n>           raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\nE           AttributeError: `np.cast` was removed in the NumPy 2.0 release. Use `np.asarray(arr, dtype=dtype)` instead.\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:400: AttributeError\n_________________________ test_nodemapper_with_labels __________________________\n\n    def test_nodemapper_with_labels():\n        n_feat = 4\n        n_batch = 2\n    \n        # test graph\n        G2 = example_graph_2(n_feat)\n        nodes = list(G2.nodes())\n        labels = [n * 2 for n in nodes]\n    \n        gen = GraphSAGENodeGenerator(G2, batch_size=n_batch, num_samples=[2, 2]).flow(\n            nodes, labels\n        )\n        assert len(gen) == 3\n    \n        for ii in range(3):\n>           nf, nl = gen[ii]\n\ntests/mapper/test_node_mappers.py:244: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/mapper/sequences.py:139: in __getitem__\n    batch_feats = self._sample_function(head_ids, batch_num)\nstellargraph/mapper/sampled_node_generators.py:264: in sample_features\n    node_samples = self._samplers[batch_num].run(\nstellargraph/data/explorer.py:733: in run\n    neighbours = self._sample_neighbours_untyped(\nstellargraph/data/explorer.py:242: in _sample_neighbours_untyped\n    neighbours = neigh_func(\nstellargraph/core/graph.py:792: in neighbor_arrays\n    edge_ilocs = self._edges.edge_ilocs(node, ins=True, outs=True)\nstellargraph/core/element_data.py:452: in edge_ilocs\n    return self._adj_lookup(ins=ins, outs=outs)[node_id]\nstellargraph/core/element_data.py:410: in _adj_lookup\n    self._init_undirected_adj_lists()\nstellargraph/core/element_data.py:365: in _init_undirected_adj_lists\n    self._edges_dict = self._create_undirected_adj_lists()\nstellargraph/core/element_data.py:377: in _create_undirected_adj_lists\n    sentinel = np.cast[np.min_scalar_type(self.number_of_nodes)](-1)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'cast'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n>           raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\nE           AttributeError: `np.cast` was removed in the NumPy 2.0 release. Use `np.asarray(arr, dtype=dtype)` instead.\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:400: AttributeError\n_________________________ test_nodemapper_zero_samples _________________________\n\n    def test_nodemapper_zero_samples():\n        n_feat = 4\n        n_batch = 2\n    \n        # test graph\n        G = example_graph(feature_size=n_feat)\n        mapper = GraphSAGENodeGenerator(G, batch_size=n_batch, num_samples=[0]).flow(\n            G.nodes()\n        )\n    \n        # This is an edge case, are we sure we want this behaviour?\n        assert len(mapper) == 2\n        for ii in range(len(mapper)):\n>           nf, nl = mapper[ii]\n\ntests/mapper/test_node_mappers.py:273: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/mapper/sequences.py:139: in __getitem__\n    batch_feats = self._sample_function(head_ids, batch_num)\nstellargraph/mapper/sampled_node_generators.py:264: in sample_features\n    node_samples = self._samplers[batch_num].run(\nstellargraph/data/explorer.py:733: in run\n    neighbours = self._sample_neighbours_untyped(\nstellargraph/data/explorer.py:242: in _sample_neighbours_untyped\n    neighbours = neigh_func(\nstellargraph/core/graph.py:792: in neighbor_arrays\n    edge_ilocs = self._edges.edge_ilocs(node, ins=True, outs=True)\nstellargraph/core/element_data.py:452: in edge_ilocs\n    return self._adj_lookup(ins=ins, outs=outs)[node_id]\nstellargraph/core/element_data.py:410: in _adj_lookup\n    self._init_undirected_adj_lists()\nstellargraph/core/element_data.py:365: in _init_undirected_adj_lists\n    self._edges_dict = self._create_undirected_adj_lists()\nstellargraph/core/element_data.py:377: in _create_undirected_adj_lists\n    sentinel = np.cast[np.min_scalar_type(self.number_of_nodes)](-1)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'cast'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n>           raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\nE           AttributeError: `np.cast` was removed in the NumPy 2.0 release. Use `np.asarray(arr, dtype=dtype)` instead.\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:400: AttributeError\n________________________ test_nodemapper_isolated_nodes ________________________\n\n    def test_nodemapper_isolated_nodes():\n        n_feat = 4\n        n_batch = 2\n    \n        # test graph (a lot of edges between the 5 non-isolated nodes, to ensure they're a single\n        # connected component)\n        G = example_graph_random(feature_size=n_feat, n_nodes=6, n_isolates=1, n_edges=1000)\n    \n        # Check connectedness\n        Gnx = G.to_networkx()\n        ccs = list(nx.connected_components(Gnx))\n        assert len(ccs) == 2\n    \n        n_isolates = [5]\n        assert nx.degree(Gnx, n_isolates[0]) == 0\n    \n        # Check both isolated and non-isolated nodes have same sampled feature shape\n        for head_nodes in [[1], [2], n_isolates]:\n            mapper = GraphSAGENodeGenerator(G, batch_size=n_batch, num_samples=[2, 2]).flow(\n                head_nodes\n            )\n>           nf, nl = mapper[0]\n\ntests/mapper/test_node_mappers.py:317: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/mapper/sequences.py:139: in __getitem__\n    batch_feats = self._sample_function(head_ids, batch_num)\nstellargraph/mapper/sampled_node_generators.py:264: in sample_features\n    node_samples = self._samplers[batch_num].run(\nstellargraph/data/explorer.py:733: in run\n    neighbours = self._sample_neighbours_untyped(\nstellargraph/data/explorer.py:242: in _sample_neighbours_untyped\n    neighbours = neigh_func(\nstellargraph/core/graph.py:792: in neighbor_arrays\n    edge_ilocs = self._edges.edge_ilocs(node, ins=True, outs=True)\nstellargraph/core/element_data.py:452: in edge_ilocs\n    return self._adj_lookup(ins=ins, outs=outs)[node_id]\nstellargraph/core/element_data.py:410: in _adj_lookup\n    self._init_undirected_adj_lists()\nstellargraph/core/element_data.py:365: in _init_undirected_adj_lists\n    self._edges_dict = self._create_undirected_adj_lists()\nstellargraph/core/element_data.py:377: in _create_undirected_adj_lists\n    sentinel = np.cast[np.min_scalar_type(self.number_of_nodes)](-1)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'cast'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n>           raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\nE           AttributeError: `np.cast` was removed in the NumPy 2.0 release. Use `np.asarray(arr, dtype=dtype)` instead.\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:400: AttributeError\n___________________________ test_nodemapper_weighted ___________________________\n\n    def test_nodemapper_weighted():\n        g, checker = weighted_tree()\n    \n        gen = GraphSAGENodeGenerator(g, 7, [10, 6], weighted=True)\n        samples = gen.flow([0] * 10)\n    \n>       checker(node_id for array in samples[0][0] for node_id in array.ravel())\n\ntests/mapper/test_node_mappers.py:364: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/mapper/sequences.py:139: in __getitem__\n    batch_feats = self._sample_function(head_ids, batch_num)\nstellargraph/mapper/sampled_node_generators.py:264: in sample_features\n    node_samples = self._samplers[batch_num].run(\nstellargraph/data/explorer.py:733: in run\n    neighbours = self._sample_neighbours_untyped(\nstellargraph/data/explorer.py:242: in _sample_neighbours_untyped\n    neighbours = neigh_func(\nstellargraph/core/graph.py:792: in neighbor_arrays\n    edge_ilocs = self._edges.edge_ilocs(node, ins=True, outs=True)\nstellargraph/core/element_data.py:452: in edge_ilocs\n    return self._adj_lookup(ins=ins, outs=outs)[node_id]\nstellargraph/core/element_data.py:410: in _adj_lookup\n    self._init_undirected_adj_lists()\nstellargraph/core/element_data.py:365: in _init_undirected_adj_lists\n    self._edges_dict = self._create_undirected_adj_lists()\nstellargraph/core/element_data.py:377: in _create_undirected_adj_lists\n    sentinel = np.cast[np.min_scalar_type(self.number_of_nodes)](-1)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'cast'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n>           raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\nE           AttributeError: `np.cast` was removed in the NumPy 2.0 release. Use `np.asarray(arr, dtype=dtype)` instead.\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:400: AttributeError\n______________________ test_hinsage_homogeneous_inference ______________________\n\n    def test_hinsage_homogeneous_inference():\n        feature_size = 4\n        edge_types = 3\n        batch_size = 2\n        num_samples = [5, 7]\n        G = example_graph_random(\n            feature_size=feature_size, node_types=1, edge_types=edge_types\n        )\n    \n        # G is homogeneous so the head_node_type argument isn't required\n        mapper = HinSAGENodeGenerator(G, batch_size=batch_size, num_samples=num_samples)\n    \n        assert mapper.head_node_types == [\"n-0\"]\n    \n        nodes = [1, 4, 2]\n        seq = mapper.flow(nodes)\n        assert len(seq) == 2\n    \n        samples_per_head = 1 + edge_types + edge_types * edge_types\n        for batch_idx, (samples, labels) in enumerate(seq):\n            this_batch_size = {0: batch_size, 1: 1}[batch_idx]\n    \n            assert len(samples) == samples_per_head\n    \n            assert samples[0].shape == (this_batch_size, 1, feature_size)\n            for i in range(1, 1 + edge_types):\n                assert samples[i].shape == (this_batch_size, num_samples[0], feature_size)\n            for i in range(1 + edge_types, samples_per_head):\n                assert samples[i].shape == (\n                    this_batch_size,\n>                   np.product(num_samples),\n                    feature_size,\n                )\n\ntests/mapper/test_node_mappers.py:658: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'product'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n            raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\n    \n        if attr == \"chararray\":\n            warnings.warn(\n                \"`np.chararray` is deprecated and will be removed from \"\n                \"the main namespace in the future. Use an array with a string \"\n                \"or bytes dtype instead.\", DeprecationWarning, stacklevel=2)\n            import numpy.char as char\n            return char.chararray\n    \n>       raise AttributeError(\"module {!r} has no attribute \"\n                             \"{!r}\".format(__name__, attr))\nE       AttributeError: module 'numpy' has no attribute 'product'\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:414: AttributeError\n_____________________ test_sliding_generator_flow_invalid ______________________\n\n    def test_sliding_generator_flow_invalid():\n>       g = _graph((2, 10, 4))\n\ntests/mapper/test_sliding.py:51: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ntests/mapper/test_sliding.py:46: in _graph\n    nodes = np.arange(np.product(shape)).reshape(shape)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'product'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n            raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\n    \n        if attr == \"chararray\":\n            warnings.warn(\n                \"`np.chararray` is deprecated and will be removed from \"\n                \"the main namespace in the future. Use an array with a string \"\n                \"or bytes dtype instead.\", DeprecationWarning, stacklevel=2)\n            import numpy.char as char\n            return char.chararray\n    \n>       raise AttributeError(\"module {!r} has no attribute \"\n                             \"{!r}\".format(__name__, attr))\nE       AttributeError: module 'numpy' has no attribute 'product'\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:414: AttributeError\n_______________________________ test_feat_getter _______________________________\n\n    def test_feat_getter():\n        # 3 nodes with features like [[0, 1], [2, 3], [4, 5], [6, 7]]\n>       g = _graph((3, 4, 2))\n\ntests/mapper/test_sliding.py:95: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ntests/mapper/test_sliding.py:46: in _graph\n    nodes = np.arange(np.product(shape)).reshape(shape)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'product'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n            raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\n    \n        if attr == \"chararray\":\n            warnings.warn(\n                \"`np.chararray` is deprecated and will be removed from \"\n                \"the main namespace in the future. Use an array with a string \"\n                \"or bytes dtype instead.\", DeprecationWarning, stacklevel=2)\n            import numpy.char as char\n            return char.chararray\n    \n>       raise AttributeError(\"module {!r} has no attribute \"\n                             \"{!r}\".format(__name__, attr))\nE       AttributeError: module 'numpy' has no attribute 'product'\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:414: AttributeError\n____________________ test_sliding_sequence_no_targets[uni] _____________________\n\nvariates = 'uni'\n\n    @pytest.mark.parametrize(\"variates\", _SHAPES.keys())\n    def test_sliding_sequence_no_targets(variates):\n>       g = _graph(_SHAPES[variates])\n\ntests/mapper/test_sliding.py:126: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ntests/mapper/test_sliding.py:46: in _graph\n    nodes = np.arange(np.product(shape)).reshape(shape)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'product'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n            raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\n    \n        if attr == \"chararray\":\n            warnings.warn(\n                \"`np.chararray` is deprecated and will be removed from \"\n                \"the main namespace in the future. Use an array with a string \"\n                \"or bytes dtype instead.\", DeprecationWarning, stacklevel=2)\n            import numpy.char as char\n            return char.chararray\n    \n>       raise AttributeError(\"module {!r} has no attribute \"\n                             \"{!r}\".format(__name__, attr))\nE       AttributeError: module 'numpy' has no attribute 'product'\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:414: AttributeError\n___________________ test_sliding_sequence_no_targets[multi] ____________________\n\nvariates = 'multi'\n\n    @pytest.mark.parametrize(\"variates\", _SHAPES.keys())\n    def test_sliding_sequence_no_targets(variates):\n>       g = _graph(_SHAPES[variates])\n\ntests/mapper/test_sliding.py:126: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ntests/mapper/test_sliding.py:46: in _graph\n    nodes = np.arange(np.product(shape)).reshape(shape)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'product'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n            raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\n    \n        if attr == \"chararray\":\n            warnings.warn(\n                \"`np.chararray` is deprecated and will be removed from \"\n                \"the main namespace in the future. Use an array with a string \"\n                \"or bytes dtype instead.\", DeprecationWarning, stacklevel=2)\n            import numpy.char as char\n            return char.chararray\n    \n>       raise AttributeError(\"module {!r} has no attribute \"\n                             \"{!r}\".format(__name__, attr))\nE       AttributeError: module 'numpy' has no attribute 'product'\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:414: AttributeError\n______________________ test_sliding_sequence_targets[uni] ______________________\n\nvariates = 'uni'\n\n    @pytest.mark.parametrize(\"variates\", _SHAPES.keys())\n    def test_sliding_sequence_targets(variates):\n>       g = _graph(_SHAPES[variates])\n\ntests/mapper/test_sliding.py:150: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ntests/mapper/test_sliding.py:46: in _graph\n    nodes = np.arange(np.product(shape)).reshape(shape)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'product'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n            raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\n    \n        if attr == \"chararray\":\n            warnings.warn(\n                \"`np.chararray` is deprecated and will be removed from \"\n                \"the main namespace in the future. Use an array with a string \"\n                \"or bytes dtype instead.\", DeprecationWarning, stacklevel=2)\n            import numpy.char as char\n            return char.chararray\n    \n>       raise AttributeError(\"module {!r} has no attribute \"\n                             \"{!r}\".format(__name__, attr))\nE       AttributeError: module 'numpy' has no attribute 'product'\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:414: AttributeError\n_____________________ test_sliding_sequence_targets[multi] _____________________\n\nvariates = 'multi'\n\n    @pytest.mark.parametrize(\"variates\", _SHAPES.keys())\n    def test_sliding_sequence_targets(variates):\n>       g = _graph(_SHAPES[variates])\n\ntests/mapper/test_sliding.py:150: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ntests/mapper/test_sliding.py:46: in _graph\n    nodes = np.arange(np.product(shape)).reshape(shape)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'product'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n            raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\n    \n        if attr == \"chararray\":\n            warnings.warn(\n                \"`np.chararray` is deprecated and will be removed from \"\n                \"the main namespace in the future. Use an array with a string \"\n                \"or bytes dtype instead.\", DeprecationWarning, stacklevel=2)\n            import numpy.char as char\n            return char.chararray\n    \n>       raise AttributeError(\"module {!r} has no attribute \"\n                             \"{!r}\".format(__name__, attr))\nE       AttributeError: module 'numpy' has no attribute 'product'\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:414: AttributeError\n________________________ test_sliding_sequence_subslice ________________________\n\n    def test_sliding_sequence_subslice():\n>       g = _graph((2, 6))\n\ntests/mapper/test_sliding.py:183: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ntests/mapper/test_sliding.py:46: in _graph\n    nodes = np.arange(np.product(shape)).reshape(shape)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'product'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n            raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\n    \n        if attr == \"chararray\":\n            warnings.warn(\n                \"`np.chararray` is deprecated and will be removed from \"\n                \"the main namespace in the future. Use an array with a string \"\n                \"or bytes dtype instead.\", DeprecationWarning, stacklevel=2)\n            import numpy.char as char\n            return char.chararray\n    \n>       raise AttributeError(\"module {!r} has no attribute \"\n                             \"{!r}\".format(__name__, attr))\nE       AttributeError: module 'numpy' has no attribute 'product'\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:414: AttributeError\n_____________________________ test_dgi[False-GCN] ______________________________\n\nmodel_type = <class 'stellargraph.layer.gcn.GCN'>, sparse = False\n\n    @pytest.mark.parametrize(\"model_type\", [GCN, APPNP, GAT, PPNP])\n    @pytest.mark.parametrize(\"sparse\", [False, True])\n    @pytest.mark.skipif(require_gpu, reason=\"tf on GPU is non-deterministic\")\n    def test_dgi(model_type, sparse):\n    \n        if sparse and model_type is PPNP:\n            pytest.skip(\"PPNP doesn't support sparse=True\")\n    \n        G = example_graph_random()\n        generator = FullBatchNodeGenerator(G, sparse=sparse)\n        corrupted_generator = CorruptedGenerator(generator)\n        gen = corrupted_generator.flow(G.nodes())\n    \n>       assert_reproducible(lambda: dgi(generator, gen, model_type))\n\ntests/reproducibility/test_deep_graph_infomax.py:58: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ntests/reproducibility/fixtures.py:38: in assert_reproducible\n    model = func()\ntests/reproducibility/test_deep_graph_infomax.py:58: in <lambda>\n    assert_reproducible(lambda: dgi(generator, gen, model_type))\ntests/reproducibility/test_deep_graph_infomax.py:39: in dgi\n    model = tf.keras.Model(*infomax.in_out_tensors())\nstellargraph/layer/deep_graph_infomax.py:192: in in_out_tensors\n    x_out = tf.stack([scores, scores_corrupted], axis=-1)\n/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py:153: in error_handler\n    raise e.with_traceback(filtered_tb) from None\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <KerasTensor shape=(1, None), dtype=float32, sparse=False, ragged=False, name=keras_tensor_2276>\ndtype = None, name = 'stack'\n\n    def __tf_tensor__(self, dtype=None, name=None):\n>       raise ValueError(\n            \"A KerasTensor cannot be used as input to a TensorFlow function. \"\n            \"A KerasTensor is a symbolic placeholder for a shape and dtype, \"\n            \"used when constructing Keras Functional models \"\n            \"or Keras Functions. You can only use it as input to a Keras layer \"\n            \"or a Keras operation (from the namespaces `keras.layers` \"\n            \"and `keras.ops`). \"\n            \"You are likely doing something like:\\n\\n\"\n            \"```\\n\"\n            \"x = Input(...)\\n\"\n            \"...\\n\"\n            \"tf_fn(x)  # Invalid.\\n\"\n            \"```\\n\\n\"\n            \"What you should do instead is wrap `tf_fn` in a layer:\\n\\n\"\n            \"```\\n\"\n            \"class MyLayer(Layer):\\n\"\n            \"    def call(self, x):\\n\"\n            \"        return tf_fn(x)\\n\\n\"\n            \"x = MyLayer()(x)\\n\"\n            \"```\\n\"\n        )\nE       ValueError: A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.ops`). You are likely doing something like:\nE       \nE       ```\nE       x = Input(...)\nE       ...\nE       tf_fn(x)  # Invalid.\nE       ```\nE       \nE       What you should do instead is wrap `tf_fn` in a layer:\nE       \nE       ```\nE       class MyLayer(Layer):\nE           def call(self, x):\nE               return tf_fn(x)\nE       \nE       x = MyLayer()(x)\nE       ```\n\n/usr/local/lib/python3.10/dist-packages/keras/src/backend/common/keras_tensor.py:194: ValueError\n----------------------------- Captured stdout call -----------------------------\nUsing GCN (local pooling) filters...\n____________________________ test_dgi[False-APPNP] _____________________________\n\nmodel_type = <class 'stellargraph.layer.appnp.APPNP'>, sparse = False\n\n    @pytest.mark.parametrize(\"model_type\", [GCN, APPNP, GAT, PPNP])\n    @pytest.mark.parametrize(\"sparse\", [False, True])\n    @pytest.mark.skipif(require_gpu, reason=\"tf on GPU is non-deterministic\")\n    def test_dgi(model_type, sparse):\n    \n        if sparse and model_type is PPNP:\n            pytest.skip(\"PPNP doesn't support sparse=True\")\n    \n        G = example_graph_random()\n        generator = FullBatchNodeGenerator(G, sparse=sparse)\n        corrupted_generator = CorruptedGenerator(generator)\n        gen = corrupted_generator.flow(G.nodes())\n    \n>       assert_reproducible(lambda: dgi(generator, gen, model_type))\n\ntests/reproducibility/test_deep_graph_infomax.py:58: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ntests/reproducibility/fixtures.py:38: in assert_reproducible\n    model = func()\ntests/reproducibility/test_deep_graph_infomax.py:58: in <lambda>\n    assert_reproducible(lambda: dgi(generator, gen, model_type))\ntests/reproducibility/test_deep_graph_infomax.py:39: in dgi\n    model = tf.keras.Model(*infomax.in_out_tensors())\nstellargraph/layer/deep_graph_infomax.py:192: in in_out_tensors\n    x_out = tf.stack([scores, scores_corrupted], axis=-1)\n/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py:153: in error_handler\n    raise e.with_traceback(filtered_tb) from None\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <KerasTensor shape=(1, None), dtype=float32, sparse=False, ragged=False, name=keras_tensor_2332>\ndtype = None, name = 'stack'\n\n    def __tf_tensor__(self, dtype=None, name=None):\n>       raise ValueError(\n            \"A KerasTensor cannot be used as input to a TensorFlow function. \"\n            \"A KerasTensor is a symbolic placeholder for a shape and dtype, \"\n            \"used when constructing Keras Functional models \"\n            \"or Keras Functions. You can only use it as input to a Keras layer \"\n            \"or a Keras operation (from the namespaces `keras.layers` \"\n            \"and `keras.ops`). \"\n            \"You are likely doing something like:\\n\\n\"\n            \"```\\n\"\n            \"x = Input(...)\\n\"\n            \"...\\n\"\n            \"tf_fn(x)  # Invalid.\\n\"\n            \"```\\n\\n\"\n            \"What you should do instead is wrap `tf_fn` in a layer:\\n\\n\"\n            \"```\\n\"\n            \"class MyLayer(Layer):\\n\"\n            \"    def call(self, x):\\n\"\n            \"        return tf_fn(x)\\n\\n\"\n            \"x = MyLayer()(x)\\n\"\n            \"```\\n\"\n        )\nE       ValueError: A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.ops`). You are likely doing something like:\nE       \nE       ```\nE       x = Input(...)\nE       ...\nE       tf_fn(x)  # Invalid.\nE       ```\nE       \nE       What you should do instead is wrap `tf_fn` in a layer:\nE       \nE       ```\nE       class MyLayer(Layer):\nE           def call(self, x):\nE               return tf_fn(x)\nE       \nE       x = MyLayer()(x)\nE       ```\n\n/usr/local/lib/python3.10/dist-packages/keras/src/backend/common/keras_tensor.py:194: ValueError\n----------------------------- Captured stdout call -----------------------------\nUsing GCN (local pooling) filters...\n_____________________________ test_dgi[False-GAT] ______________________________\n\nmodel_type = <class 'stellargraph.layer.graph_attention.GAT'>, sparse = False\n\n    @pytest.mark.parametrize(\"model_type\", [GCN, APPNP, GAT, PPNP])\n    @pytest.mark.parametrize(\"sparse\", [False, True])\n    @pytest.mark.skipif(require_gpu, reason=\"tf on GPU is non-deterministic\")\n    def test_dgi(model_type, sparse):\n    \n        if sparse and model_type is PPNP:\n            pytest.skip(\"PPNP doesn't support sparse=True\")\n    \n        G = example_graph_random()\n        generator = FullBatchNodeGenerator(G, sparse=sparse)\n        corrupted_generator = CorruptedGenerator(generator)\n        gen = corrupted_generator.flow(G.nodes())\n    \n>       assert_reproducible(lambda: dgi(generator, gen, model_type))\n\ntests/reproducibility/test_deep_graph_infomax.py:58: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ntests/reproducibility/fixtures.py:38: in assert_reproducible\n    model = func()\ntests/reproducibility/test_deep_graph_infomax.py:58: in <lambda>\n    assert_reproducible(lambda: dgi(generator, gen, model_type))\ntests/reproducibility/test_deep_graph_infomax.py:39: in dgi\n    model = tf.keras.Model(*infomax.in_out_tensors())\nstellargraph/layer/deep_graph_infomax.py:192: in in_out_tensors\n    x_out = tf.stack([scores, scores_corrupted], axis=-1)\n/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py:153: in error_handler\n    raise e.with_traceback(filtered_tb) from None\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <KerasTensor shape=(1, None), dtype=float32, sparse=False, ragged=False, name=keras_tensor_2354>\ndtype = None, name = 'stack'\n\n    def __tf_tensor__(self, dtype=None, name=None):\n>       raise ValueError(\n            \"A KerasTensor cannot be used as input to a TensorFlow function. \"\n            \"A KerasTensor is a symbolic placeholder for a shape and dtype, \"\n            \"used when constructing Keras Functional models \"\n            \"or Keras Functions. You can only use it as input to a Keras layer \"\n            \"or a Keras operation (from the namespaces `keras.layers` \"\n            \"and `keras.ops`). \"\n            \"You are likely doing something like:\\n\\n\"\n            \"```\\n\"\n            \"x = Input(...)\\n\"\n            \"...\\n\"\n            \"tf_fn(x)  # Invalid.\\n\"\n            \"```\\n\\n\"\n            \"What you should do instead is wrap `tf_fn` in a layer:\\n\\n\"\n            \"```\\n\"\n            \"class MyLayer(Layer):\\n\"\n            \"    def call(self, x):\\n\"\n            \"        return tf_fn(x)\\n\\n\"\n            \"x = MyLayer()(x)\\n\"\n            \"```\\n\"\n        )\nE       ValueError: A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.ops`). You are likely doing something like:\nE       \nE       ```\nE       x = Input(...)\nE       ...\nE       tf_fn(x)  # Invalid.\nE       ```\nE       \nE       What you should do instead is wrap `tf_fn` in a layer:\nE       \nE       ```\nE       class MyLayer(Layer):\nE           def call(self, x):\nE               return tf_fn(x)\nE       \nE       x = MyLayer()(x)\nE       ```\n\n/usr/local/lib/python3.10/dist-packages/keras/src/backend/common/keras_tensor.py:194: ValueError\n----------------------------- Captured stdout call -----------------------------\nUsing GCN (local pooling) filters...\n_____________________________ test_dgi[False-PPNP] _____________________________\n\nmodel_type = <class 'stellargraph.layer.ppnp.PPNP'>, sparse = False\n\n    @pytest.mark.parametrize(\"model_type\", [GCN, APPNP, GAT, PPNP])\n    @pytest.mark.parametrize(\"sparse\", [False, True])\n    @pytest.mark.skipif(require_gpu, reason=\"tf on GPU is non-deterministic\")\n    def test_dgi(model_type, sparse):\n    \n        if sparse and model_type is PPNP:\n            pytest.skip(\"PPNP doesn't support sparse=True\")\n    \n        G = example_graph_random()\n        generator = FullBatchNodeGenerator(G, sparse=sparse)\n        corrupted_generator = CorruptedGenerator(generator)\n        gen = corrupted_generator.flow(G.nodes())\n    \n>       assert_reproducible(lambda: dgi(generator, gen, model_type))\n\ntests/reproducibility/test_deep_graph_infomax.py:58: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ntests/reproducibility/fixtures.py:38: in assert_reproducible\n    model = func()\ntests/reproducibility/test_deep_graph_infomax.py:58: in <lambda>\n    assert_reproducible(lambda: dgi(generator, gen, model_type))\ntests/reproducibility/test_deep_graph_infomax.py:39: in dgi\n    model = tf.keras.Model(*infomax.in_out_tensors())\nstellargraph/layer/deep_graph_infomax.py:192: in in_out_tensors\n    x_out = tf.stack([scores, scores_corrupted], axis=-1)\n/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py:153: in error_handler\n    raise e.with_traceback(filtered_tb) from None\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <KerasTensor shape=(1, None), dtype=float32, sparse=False, ragged=False, name=keras_tensor_2380>\ndtype = None, name = 'stack'\n\n    def __tf_tensor__(self, dtype=None, name=None):\n>       raise ValueError(\n            \"A KerasTensor cannot be used as input to a TensorFlow function. \"\n            \"A KerasTensor is a symbolic placeholder for a shape and dtype, \"\n            \"used when constructing Keras Functional models \"\n            \"or Keras Functions. You can only use it as input to a Keras layer \"\n            \"or a Keras operation (from the namespaces `keras.layers` \"\n            \"and `keras.ops`). \"\n            \"You are likely doing something like:\\n\\n\"\n            \"```\\n\"\n            \"x = Input(...)\\n\"\n            \"...\\n\"\n            \"tf_fn(x)  # Invalid.\\n\"\n            \"```\\n\\n\"\n            \"What you should do instead is wrap `tf_fn` in a layer:\\n\\n\"\n            \"```\\n\"\n            \"class MyLayer(Layer):\\n\"\n            \"    def call(self, x):\\n\"\n            \"        return tf_fn(x)\\n\\n\"\n            \"x = MyLayer()(x)\\n\"\n            \"```\\n\"\n        )\nE       ValueError: A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.ops`). You are likely doing something like:\nE       \nE       ```\nE       x = Input(...)\nE       ...\nE       tf_fn(x)  # Invalid.\nE       ```\nE       \nE       What you should do instead is wrap `tf_fn` in a layer:\nE       \nE       ```\nE       class MyLayer(Layer):\nE           def call(self, x):\nE               return tf_fn(x)\nE       \nE       x = MyLayer()(x)\nE       ```\n\n/usr/local/lib/python3.10/dist-packages/keras/src/backend/common/keras_tensor.py:194: ValueError\n----------------------------- Captured stdout call -----------------------------\nUsing GCN (local pooling) filters...\n______________________________ test_dgi[True-GCN] ______________________________\n\nmodel_type = <class 'stellargraph.layer.gcn.GCN'>, sparse = True\n\n    @pytest.mark.parametrize(\"model_type\", [GCN, APPNP, GAT, PPNP])\n    @pytest.mark.parametrize(\"sparse\", [False, True])\n    @pytest.mark.skipif(require_gpu, reason=\"tf on GPU is non-deterministic\")\n    def test_dgi(model_type, sparse):\n    \n        if sparse and model_type is PPNP:\n            pytest.skip(\"PPNP doesn't support sparse=True\")\n    \n        G = example_graph_random()\n        generator = FullBatchNodeGenerator(G, sparse=sparse)\n        corrupted_generator = CorruptedGenerator(generator)\n        gen = corrupted_generator.flow(G.nodes())\n    \n>       assert_reproducible(lambda: dgi(generator, gen, model_type))\n\ntests/reproducibility/test_deep_graph_infomax.py:58: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ntests/reproducibility/fixtures.py:38: in assert_reproducible\n    model = func()\ntests/reproducibility/test_deep_graph_infomax.py:58: in <lambda>\n    assert_reproducible(lambda: dgi(generator, gen, model_type))\ntests/reproducibility/test_deep_graph_infomax.py:39: in dgi\n    model = tf.keras.Model(*infomax.in_out_tensors())\nstellargraph/layer/deep_graph_infomax.py:192: in in_out_tensors\n    x_out = tf.stack([scores, scores_corrupted], axis=-1)\n/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py:153: in error_handler\n    raise e.with_traceback(filtered_tb) from None\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <KerasTensor shape=(1, None), dtype=float32, sparse=False, ragged=False, name=keras_tensor_2399>\ndtype = None, name = 'stack'\n\n    def __tf_tensor__(self, dtype=None, name=None):\n>       raise ValueError(\n            \"A KerasTensor cannot be used as input to a TensorFlow function. \"\n            \"A KerasTensor is a symbolic placeholder for a shape and dtype, \"\n            \"used when constructing Keras Functional models \"\n            \"or Keras Functions. You can only use it as input to a Keras layer \"\n            \"or a Keras operation (from the namespaces `keras.layers` \"\n            \"and `keras.ops`). \"\n            \"You are likely doing something like:\\n\\n\"\n            \"```\\n\"\n            \"x = Input(...)\\n\"\n            \"...\\n\"\n            \"tf_fn(x)  # Invalid.\\n\"\n            \"```\\n\\n\"\n            \"What you should do instead is wrap `tf_fn` in a layer:\\n\\n\"\n            \"```\\n\"\n            \"class MyLayer(Layer):\\n\"\n            \"    def call(self, x):\\n\"\n            \"        return tf_fn(x)\\n\\n\"\n            \"x = MyLayer()(x)\\n\"\n            \"```\\n\"\n        )\nE       ValueError: A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.ops`). You are likely doing something like:\nE       \nE       ```\nE       x = Input(...)\nE       ...\nE       tf_fn(x)  # Invalid.\nE       ```\nE       \nE       What you should do instead is wrap `tf_fn` in a layer:\nE       \nE       ```\nE       class MyLayer(Layer):\nE           def call(self, x):\nE               return tf_fn(x)\nE       \nE       x = MyLayer()(x)\nE       ```\n\n/usr/local/lib/python3.10/dist-packages/keras/src/backend/common/keras_tensor.py:194: ValueError\n----------------------------- Captured stdout call -----------------------------\nUsing GCN (local pooling) filters...\n_____________________________ test_dgi[True-APPNP] _____________________________\n\nmodel_type = <class 'stellargraph.layer.appnp.APPNP'>, sparse = True\n\n    @pytest.mark.parametrize(\"model_type\", [GCN, APPNP, GAT, PPNP])\n    @pytest.mark.parametrize(\"sparse\", [False, True])\n    @pytest.mark.skipif(require_gpu, reason=\"tf on GPU is non-deterministic\")\n    def test_dgi(model_type, sparse):\n    \n        if sparse and model_type is PPNP:\n            pytest.skip(\"PPNP doesn't support sparse=True\")\n    \n        G = example_graph_random()\n        generator = FullBatchNodeGenerator(G, sparse=sparse)\n        corrupted_generator = CorruptedGenerator(generator)\n        gen = corrupted_generator.flow(G.nodes())\n    \n>       assert_reproducible(lambda: dgi(generator, gen, model_type))\n\ntests/reproducibility/test_deep_graph_infomax.py:58: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ntests/reproducibility/fixtures.py:38: in assert_reproducible\n    model = func()\ntests/reproducibility/test_deep_graph_infomax.py:58: in <lambda>\n    assert_reproducible(lambda: dgi(generator, gen, model_type))\ntests/reproducibility/test_deep_graph_infomax.py:39: in dgi\n    model = tf.keras.Model(*infomax.in_out_tensors())\nstellargraph/layer/deep_graph_infomax.py:192: in in_out_tensors\n    x_out = tf.stack([scores, scores_corrupted], axis=-1)\n/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py:153: in error_handler\n    raise e.with_traceback(filtered_tb) from None\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <KerasTensor shape=(1, None), dtype=float32, sparse=False, ragged=False, name=keras_tensor_2458>\ndtype = None, name = 'stack'\n\n    def __tf_tensor__(self, dtype=None, name=None):\n>       raise ValueError(\n            \"A KerasTensor cannot be used as input to a TensorFlow function. \"\n            \"A KerasTensor is a symbolic placeholder for a shape and dtype, \"\n            \"used when constructing Keras Functional models \"\n            \"or Keras Functions. You can only use it as input to a Keras layer \"\n            \"or a Keras operation (from the namespaces `keras.layers` \"\n            \"and `keras.ops`). \"\n            \"You are likely doing something like:\\n\\n\"\n            \"```\\n\"\n            \"x = Input(...)\\n\"\n            \"...\\n\"\n            \"tf_fn(x)  # Invalid.\\n\"\n            \"```\\n\\n\"\n            \"What you should do instead is wrap `tf_fn` in a layer:\\n\\n\"\n            \"```\\n\"\n            \"class MyLayer(Layer):\\n\"\n            \"    def call(self, x):\\n\"\n            \"        return tf_fn(x)\\n\\n\"\n            \"x = MyLayer()(x)\\n\"\n            \"```\\n\"\n        )\nE       ValueError: A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.ops`). You are likely doing something like:\nE       \nE       ```\nE       x = Input(...)\nE       ...\nE       tf_fn(x)  # Invalid.\nE       ```\nE       \nE       What you should do instead is wrap `tf_fn` in a layer:\nE       \nE       ```\nE       class MyLayer(Layer):\nE           def call(self, x):\nE               return tf_fn(x)\nE       \nE       x = MyLayer()(x)\nE       ```\n\n/usr/local/lib/python3.10/dist-packages/keras/src/backend/common/keras_tensor.py:194: ValueError\n----------------------------- Captured stdout call -----------------------------\nUsing GCN (local pooling) filters...\n______________________________ test_dgi[True-GAT] ______________________________\n\nmodel_type = <class 'stellargraph.layer.graph_attention.GAT'>, sparse = True\n\n    @pytest.mark.parametrize(\"model_type\", [GCN, APPNP, GAT, PPNP])\n    @pytest.mark.parametrize(\"sparse\", [False, True])\n    @pytest.mark.skipif(require_gpu, reason=\"tf on GPU is non-deterministic\")\n    def test_dgi(model_type, sparse):\n    \n        if sparse and model_type is PPNP:\n            pytest.skip(\"PPNP doesn't support sparse=True\")\n    \n        G = example_graph_random()\n        generator = FullBatchNodeGenerator(G, sparse=sparse)\n        corrupted_generator = CorruptedGenerator(generator)\n        gen = corrupted_generator.flow(G.nodes())\n    \n>       assert_reproducible(lambda: dgi(generator, gen, model_type))\n\ntests/reproducibility/test_deep_graph_infomax.py:58: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ntests/reproducibility/fixtures.py:38: in assert_reproducible\n    model = func()\ntests/reproducibility/test_deep_graph_infomax.py:58: in <lambda>\n    assert_reproducible(lambda: dgi(generator, gen, model_type))\ntests/reproducibility/test_deep_graph_infomax.py:39: in dgi\n    model = tf.keras.Model(*infomax.in_out_tensors())\nstellargraph/layer/deep_graph_infomax.py:192: in in_out_tensors\n    x_out = tf.stack([scores, scores_corrupted], axis=-1)\n/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py:153: in error_handler\n    raise e.with_traceback(filtered_tb) from None\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <KerasTensor shape=(1, None), dtype=float32, sparse=False, ragged=False, name=keras_tensor_2483>\ndtype = None, name = 'stack'\n\n    def __tf_tensor__(self, dtype=None, name=None):\n>       raise ValueError(\n            \"A KerasTensor cannot be used as input to a TensorFlow function. \"\n            \"A KerasTensor is a symbolic placeholder for a shape and dtype, \"\n            \"used when constructing Keras Functional models \"\n            \"or Keras Functions. You can only use it as input to a Keras layer \"\n            \"or a Keras operation (from the namespaces `keras.layers` \"\n            \"and `keras.ops`). \"\n            \"You are likely doing something like:\\n\\n\"\n            \"```\\n\"\n            \"x = Input(...)\\n\"\n            \"...\\n\"\n            \"tf_fn(x)  # Invalid.\\n\"\n            \"```\\n\\n\"\n            \"What you should do instead is wrap `tf_fn` in a layer:\\n\\n\"\n            \"```\\n\"\n            \"class MyLayer(Layer):\\n\"\n            \"    def call(self, x):\\n\"\n            \"        return tf_fn(x)\\n\\n\"\n            \"x = MyLayer()(x)\\n\"\n            \"```\\n\"\n        )\nE       ValueError: A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.ops`). You are likely doing something like:\nE       \nE       ```\nE       x = Input(...)\nE       ...\nE       tf_fn(x)  # Invalid.\nE       ```\nE       \nE       What you should do instead is wrap `tf_fn` in a layer:\nE       \nE       ```\nE       class MyLayer(Layer):\nE           def call(self, x):\nE               return tf_fn(x)\nE       \nE       x = MyLayer()(x)\nE       ```\n\n/usr/local/lib/python3.10/dist-packages/keras/src/backend/common/keras_tensor.py:194: ValueError\n----------------------------- Captured stdout call -----------------------------\nUsing GCN (local pooling) filters...\n___________________________ test_unsupervised[True] ____________________________\n\npetersen_graph = <stellargraph.core.graph.StellarGraph object at 0x7fc14de61e10>\nshuffle = True\n\n    @pytest.mark.parametrize(\"shuffle\", [True, False])\n    @flaky_xfail_mark(AssertionError, 1115)\n    def test_unsupervised(petersen_graph, shuffle):\n>       assert_reproducible(\n            lambda: unsup_gs(\n                petersen_graph,\n                [2, 2],\n                tf.optimizers.Adam(1e-3),\n                epochs=4,\n                walk_length=2,\n                batch_size=4,\n                shuffle=shuffle,\n            )\n        )\n\ntests/reproducibility/test_graphsage.py:214: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ntests/reproducibility/fixtures.py:38: in assert_reproducible\n    model = func()\ntests/reproducibility/test_graphsage.py:215: in <lambda>\n    lambda: unsup_gs(\ntests/reproducibility/test_graphsage.py:79: in unsup_gs\n    train_gen = generator.flow(unsupervised_samples)\nstellargraph/mapper/sampled_link_generators.py:128: in flow\n    return OnDemandLinkSequence(self.sample_features, self.batch_size, link_ids)\nstellargraph/mapper/sequences.py:289: in __init__\n    self._batches = self._create_batches()\nstellargraph/mapper/sequences.py:326: in _create_batches\n    return self.walker.run(self.batch_size)\nstellargraph/data/unsupervised_sampler.py:148: in run\n    degrees = self.graph.node_degrees(use_ilocs=True)\nstellargraph/core/graph.py:1546: in node_degrees\n    degrees = self._edges.degrees()\nstellargraph/core/element_data.py:437: in degrees\n    adj = self._adj_lookup(ins=ins, outs=outs)\nstellargraph/core/element_data.py:410: in _adj_lookup\n    self._init_undirected_adj_lists()\nstellargraph/core/element_data.py:365: in _init_undirected_adj_lists\n    self._edges_dict = self._create_undirected_adj_lists()\nstellargraph/core/element_data.py:377: in _create_undirected_adj_lists\n    sentinel = np.cast[np.min_scalar_type(self.number_of_nodes)](-1)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'cast'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n>           raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\nE           AttributeError: `np.cast` was removed in the NumPy 2.0 release. Use `np.asarray(arr, dtype=dtype)` instead.\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:400: AttributeError\n___________________________ test_unsupervised[False] ___________________________\n\npetersen_graph = <stellargraph.core.graph.StellarGraph object at 0x7fc18c6bf070>\nshuffle = False\n\n    @pytest.mark.parametrize(\"shuffle\", [True, False])\n    @flaky_xfail_mark(AssertionError, 1115)\n    def test_unsupervised(petersen_graph, shuffle):\n>       assert_reproducible(\n            lambda: unsup_gs(\n                petersen_graph,\n                [2, 2],\n                tf.optimizers.Adam(1e-3),\n                epochs=4,\n                walk_length=2,\n                batch_size=4,\n                shuffle=shuffle,\n            )\n        )\n\ntests/reproducibility/test_graphsage.py:214: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ntests/reproducibility/fixtures.py:38: in assert_reproducible\n    model = func()\ntests/reproducibility/test_graphsage.py:215: in <lambda>\n    lambda: unsup_gs(\ntests/reproducibility/test_graphsage.py:79: in unsup_gs\n    train_gen = generator.flow(unsupervised_samples)\nstellargraph/mapper/sampled_link_generators.py:128: in flow\n    return OnDemandLinkSequence(self.sample_features, self.batch_size, link_ids)\nstellargraph/mapper/sequences.py:289: in __init__\n    self._batches = self._create_batches()\nstellargraph/mapper/sequences.py:326: in _create_batches\n    return self.walker.run(self.batch_size)\nstellargraph/data/unsupervised_sampler.py:148: in run\n    degrees = self.graph.node_degrees(use_ilocs=True)\nstellargraph/core/graph.py:1546: in node_degrees\n    degrees = self._edges.degrees()\nstellargraph/core/element_data.py:437: in degrees\n    adj = self._adj_lookup(ins=ins, outs=outs)\nstellargraph/core/element_data.py:410: in _adj_lookup\n    self._init_undirected_adj_lists()\nstellargraph/core/element_data.py:365: in _init_undirected_adj_lists\n    self._edges_dict = self._create_undirected_adj_lists()\nstellargraph/core/element_data.py:377: in _create_undirected_adj_lists\n    sentinel = np.cast[np.min_scalar_type(self.number_of_nodes)](-1)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'cast'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n>           raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\nE           AttributeError: `np.cast` was removed in the NumPy 2.0 release. Use `np.asarray(arr, dtype=dtype)` instead.\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:400: AttributeError\n________________________________ test_nai[True] ________________________________\n\npetersen_graph = <stellargraph.core.graph.StellarGraph object at 0x7fc1ac4fe2f0>\nshuffle = True\n\n    @pytest.mark.parametrize(\"shuffle\", [True, False])\n    @flaky_xfail_mark(AssertionError, 1115)\n    @pytest.mark.skipif(require_gpu, reason=\"tf on GPU is non-deterministic\")\n    def test_nai(petersen_graph, shuffle):\n        target_size = 10\n        targets = np.random.rand(len(petersen_graph.nodes()), target_size)\n>       assert_reproducible(\n            lambda: gs_nai(\n                petersen_graph, targets, [2, 2], tf.optimizers.Adam(1e-3), shuffle=shuffle\n            )\n        )\n\ntests/reproducibility/test_graphsage.py:233: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ntests/reproducibility/fixtures.py:38: in assert_reproducible\n    model = func()\ntests/reproducibility/test_graphsage.py:234: in <lambda>\n    lambda: gs_nai(\ntests/reproducibility/test_graphsage.py:135: in gs_nai\n    model = gs_nai_model(\ntests/reproducibility/test_graphsage.py:96: in gs_nai_model\n    graphsage = GraphSAGE(\nstellargraph/layer/graphsage.py:866: in __init__\n    self._compute_neighbourhood_sizes()\nstellargraph/layer/graphsage.py:951: in _compute_neighbourhood_sizes\n    self.neighbourhood_sizes = [size_at(i) for i in range(self.max_hops + 1)]\nstellargraph/layer/graphsage.py:951: in <listcomp>\n    self.neighbourhood_sizes = [size_at(i) for i in range(self.max_hops + 1)]\nstellargraph/layer/graphsage.py:949: in size_at\n    return np.product(self.n_samples[:i], dtype=int)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'product'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n            raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\n    \n        if attr == \"chararray\":\n            warnings.warn(\n                \"`np.chararray` is deprecated and will be removed from \"\n                \"the main namespace in the future. Use an array with a string \"\n                \"or bytes dtype instead.\", DeprecationWarning, stacklevel=2)\n            import numpy.char as char\n            return char.chararray\n    \n>       raise AttributeError(\"module {!r} has no attribute \"\n                             \"{!r}\".format(__name__, attr))\nE       AttributeError: module 'numpy' has no attribute 'product'\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:414: AttributeError\n_______________________________ test_nai[False] ________________________________\n\npetersen_graph = <stellargraph.core.graph.StellarGraph object at 0x7fc18c44b670>\nshuffle = False\n\n    @pytest.mark.parametrize(\"shuffle\", [True, False])\n    @flaky_xfail_mark(AssertionError, 1115)\n    @pytest.mark.skipif(require_gpu, reason=\"tf on GPU is non-deterministic\")\n    def test_nai(petersen_graph, shuffle):\n        target_size = 10\n        targets = np.random.rand(len(petersen_graph.nodes()), target_size)\n>       assert_reproducible(\n            lambda: gs_nai(\n                petersen_graph, targets, [2, 2], tf.optimizers.Adam(1e-3), shuffle=shuffle\n            )\n        )\n\ntests/reproducibility/test_graphsage.py:233: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ntests/reproducibility/fixtures.py:38: in assert_reproducible\n    model = func()\ntests/reproducibility/test_graphsage.py:234: in <lambda>\n    lambda: gs_nai(\ntests/reproducibility/test_graphsage.py:135: in gs_nai\n    model = gs_nai_model(\ntests/reproducibility/test_graphsage.py:96: in gs_nai_model\n    graphsage = GraphSAGE(\nstellargraph/layer/graphsage.py:866: in __init__\n    self._compute_neighbourhood_sizes()\nstellargraph/layer/graphsage.py:951: in _compute_neighbourhood_sizes\n    self.neighbourhood_sizes = [size_at(i) for i in range(self.max_hops + 1)]\nstellargraph/layer/graphsage.py:951: in <listcomp>\n    self.neighbourhood_sizes = [size_at(i) for i in range(self.max_hops + 1)]\nstellargraph/layer/graphsage.py:949: in size_at\n    return np.product(self.n_samples[:i], dtype=int)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'product'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n            raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\n    \n        if attr == \"chararray\":\n            warnings.warn(\n                \"`np.chararray` is deprecated and will be removed from \"\n                \"the main namespace in the future. Use an array with a string \"\n                \"or bytes dtype instead.\", DeprecationWarning, stacklevel=2)\n            import numpy.char as char\n            return char.chararray\n    \n>       raise AttributeError(\"module {!r} has no attribute \"\n                             \"{!r}\".format(__name__, attr))\nE       AttributeError: module 'numpy' has no attribute 'product'\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:414: AttributeError\n__________________________ test_link_prediction[True] __________________________\n\npetersen_graph = <stellargraph.core.graph.StellarGraph object at 0x7fc14d9923b0>\nshuffle = True\n\n    @flaky_xfail_mark(AssertionError, [970, 990])\n    @pytest.mark.parametrize(\"shuffle\", [True, False])\n    def test_link_prediction(petersen_graph, shuffle):\n        num_examples = 10\n        edge_ids = np.random.choice(petersen_graph.nodes(), size=(num_examples, 2))\n        edge_labels = np.random.choice([0, 1], size=num_examples)\n>       assert_reproducible(\n            lambda: gs_link_prediction(\n                petersen_graph,\n                edge_ids,\n                edge_labels,\n                [2, 2],\n                tf.optimizers.Adam(1e-3),\n                shuffle=shuffle,\n            )\n        )\n\ntests/reproducibility/test_graphsage.py:246: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ntests/reproducibility/fixtures.py:38: in assert_reproducible\n    model = func()\ntests/reproducibility/test_graphsage.py:247: in <lambda>\n    lambda: gs_link_prediction(\ntests/reproducibility/test_graphsage.py:196: in gs_link_prediction\n    model = gs_link_pred_model(\ntests/reproducibility/test_graphsage.py:152: in gs_link_pred_model\n    graphsage = GraphSAGE(\nstellargraph/layer/graphsage.py:866: in __init__\n    self._compute_neighbourhood_sizes()\nstellargraph/layer/graphsage.py:951: in _compute_neighbourhood_sizes\n    self.neighbourhood_sizes = [size_at(i) for i in range(self.max_hops + 1)]\nstellargraph/layer/graphsage.py:951: in <listcomp>\n    self.neighbourhood_sizes = [size_at(i) for i in range(self.max_hops + 1)]\nstellargraph/layer/graphsage.py:949: in size_at\n    return np.product(self.n_samples[:i], dtype=int)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'product'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n            raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\n    \n        if attr == \"chararray\":\n            warnings.warn(\n                \"`np.chararray` is deprecated and will be removed from \"\n                \"the main namespace in the future. Use an array with a string \"\n                \"or bytes dtype instead.\", DeprecationWarning, stacklevel=2)\n            import numpy.char as char\n            return char.chararray\n    \n>       raise AttributeError(\"module {!r} has no attribute \"\n                             \"{!r}\".format(__name__, attr))\nE       AttributeError: module 'numpy' has no attribute 'product'\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:414: AttributeError\n_________________________ test_link_prediction[False] __________________________\n\npetersen_graph = <stellargraph.core.graph.StellarGraph object at 0x7fc18c767c70>\nshuffle = False\n\n    @flaky_xfail_mark(AssertionError, [970, 990])\n    @pytest.mark.parametrize(\"shuffle\", [True, False])\n    def test_link_prediction(petersen_graph, shuffle):\n        num_examples = 10\n        edge_ids = np.random.choice(petersen_graph.nodes(), size=(num_examples, 2))\n        edge_labels = np.random.choice([0, 1], size=num_examples)\n>       assert_reproducible(\n            lambda: gs_link_prediction(\n                petersen_graph,\n                edge_ids,\n                edge_labels,\n                [2, 2],\n                tf.optimizers.Adam(1e-3),\n                shuffle=shuffle,\n            )\n        )\n\ntests/reproducibility/test_graphsage.py:246: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ntests/reproducibility/fixtures.py:38: in assert_reproducible\n    model = func()\ntests/reproducibility/test_graphsage.py:247: in <lambda>\n    lambda: gs_link_prediction(\ntests/reproducibility/test_graphsage.py:196: in gs_link_prediction\n    model = gs_link_pred_model(\ntests/reproducibility/test_graphsage.py:152: in gs_link_pred_model\n    graphsage = GraphSAGE(\nstellargraph/layer/graphsage.py:866: in __init__\n    self._compute_neighbourhood_sizes()\nstellargraph/layer/graphsage.py:951: in _compute_neighbourhood_sizes\n    self.neighbourhood_sizes = [size_at(i) for i in range(self.max_hops + 1)]\nstellargraph/layer/graphsage.py:951: in <listcomp>\n    self.neighbourhood_sizes = [size_at(i) for i in range(self.max_hops + 1)]\nstellargraph/layer/graphsage.py:949: in size_at\n    return np.product(self.n_samples[:i], dtype=int)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'product'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n            raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\n    \n        if attr == \"chararray\":\n            warnings.warn(\n                \"`np.chararray` is deprecated and will be removed from \"\n                \"the main namespace in the future. Use an array with a string \"\n                \"or bytes dtype instead.\", DeprecationWarning, stacklevel=2)\n            import numpy.char as char\n            return char.chararray\n    \n>       raise AttributeError(\"module {!r} has no attribute \"\n                             \"{!r}\".format(__name__, attr))\nE       AttributeError: module 'numpy' has no attribute 'product'\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:414: AttributeError\n____________________ test_isotonic_calibration_fit_predict _____________________\n\n    def test_isotonic_calibration_fit_predict():\n    \n        # Some tests for the multi-class case\n        x_train = np.array([[1, 1], [2, 3.5]])\n        y_train = np.array([[0.9, 0.1], [0.2, 0.8]])\n    \n        ic = IsotonicCalibration()\n    \n        assert len(ic.regressors) == 0\n    \n        ic.fit(x_train=x_train, y_train=y_train)\n    \n        assert ic.n_classes == 2\n    \n        # Check that predict returns data of the same dimensionality as\n        # the training data.\n        x_test = np.array([[0, 1]])\n>       y_pred = ic.predict(x=x_test)\n\ntests/test_calibration.py:212: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <stellargraph.calibration.IsotonicCalibration object at 0x7fc1ac21e2f0>\nx = array([[0, 1]])\n\n    def predict(self, x):\n        \"\"\"\n        This method calibrates the given data assumed the output of a classification model.\n    \n        For multi-class classification, the probabilities for each class are first scaled using the corresponding\n        isotonic regression model and then normalized to sum to 1.\n    \n        Args:\n            x (numpy array): The values to calibrate. For binary classification problems it should have shape (N,) where\n                N is the number of samples to calibrate. For multi-class classification problems, it should have shape\n                (N, C) where C is the number of classes.\n    \n        Returns:\n            numpy array: The calibrated probabilities. It has shape (N, C) where N is the number of samples\n            and C is the number of classes.\n        \"\"\"\n        if not isinstance(x, np.ndarray):\n            raise ValueError(\n                \"x should be numpy.ndarray but received {}\".format(type(x).__name__)\n            )\n    \n        if self.n_classes > 1 and x.shape[1] != self.n_classes:\n            raise ValueError(\n                \"Expecting input vector of dimensionality {} but received {}\".format(\n                    self.n_classes, len(x)\n                )\n            )\n    \n        if self.n_classes == 1:\n            x = x.reshape(-1, 1)\n    \n        predictions = []\n        for n in range(self.n_classes):\n>           predictions.append(self.regressors[n].transform(T=x[:, n]))\nE           TypeError: IsotonicRegression.transform() missing 1 required positional argument: 'X'\n\nstellargraph/calibration.py:461: TypeError\n________________________ test_ensemble_init_parameters _________________________\n\n    def test_ensemble_init_parameters():\n        tf.keras.backend.clear_session()\n    \n        graph = example_graph_1(feature_size=10)\n    \n>       base_model, keras_model, generator, train_gen = create_graphSAGE_model(graph)\n\ntests/test_ensemble.py:185: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ntests/test_ensemble.py:77: in create_graphSAGE_model\n    base_model = GraphSAGE(\nstellargraph/layer/graphsage.py:866: in __init__\n    self._compute_neighbourhood_sizes()\nstellargraph/layer/graphsage.py:951: in _compute_neighbourhood_sizes\n    self.neighbourhood_sizes = [size_at(i) for i in range(self.max_hops + 1)]\nstellargraph/layer/graphsage.py:951: in <listcomp>\n    self.neighbourhood_sizes = [size_at(i) for i in range(self.max_hops + 1)]\nstellargraph/layer/graphsage.py:949: in size_at\n    return np.product(self.n_samples[:i], dtype=int)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'product'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n            raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\n    \n        if attr == \"chararray\":\n            warnings.warn(\n                \"`np.chararray` is deprecated and will be removed from \"\n                \"the main namespace in the future. Use an array with a string \"\n                \"or bytes dtype instead.\", DeprecationWarning, stacklevel=2)\n            import numpy.char as char\n            return char.chararray\n    \n>       raise AttributeError(\"module {!r} has no attribute \"\n                             \"{!r}\".format(__name__, attr))\nE       AttributeError: module 'numpy' has no attribute 'product'\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:414: AttributeError\n_________________________________ test_compile _________________________________\n\n    def test_compile():\n        tf.keras.backend.clear_session()\n    \n        graph = example_graph_1(feature_size=10)\n    \n        # base_model, keras_model, generator, train_gen\n        gnn_models = [\n>           create_graphSAGE_model(graph),\n            create_HinSAGE_model(graph),\n            create_graphSAGE_model(graph, link_prediction=True),\n            create_HinSAGE_model(graph, link_prediction=True),\n            create_GCN_model(graph),\n            create_GAT_model(graph),\n        ]\n\ntests/test_ensemble.py:267: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ntests/test_ensemble.py:77: in create_graphSAGE_model\n    base_model = GraphSAGE(\nstellargraph/layer/graphsage.py:866: in __init__\n    self._compute_neighbourhood_sizes()\nstellargraph/layer/graphsage.py:951: in _compute_neighbourhood_sizes\n    self.neighbourhood_sizes = [size_at(i) for i in range(self.max_hops + 1)]\nstellargraph/layer/graphsage.py:951: in <listcomp>\n    self.neighbourhood_sizes = [size_at(i) for i in range(self.max_hops + 1)]\nstellargraph/layer/graphsage.py:949: in size_at\n    return np.product(self.n_samples[:i], dtype=int)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'product'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n            raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\n    \n        if attr == \"chararray\":\n            warnings.warn(\n                \"`np.chararray` is deprecated and will be removed from \"\n                \"the main namespace in the future. Use an array with a string \"\n                \"or bytes dtype instead.\", DeprecationWarning, stacklevel=2)\n            import numpy.char as char\n            return char.chararray\n    \n>       raise AttributeError(\"module {!r} has no attribute \"\n                             \"{!r}\".format(__name__, attr))\nE       AttributeError: module 'numpy' has no attribute 'product'\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:414: AttributeError\n______________________________ test_Ensemble_fit _______________________________\n\n    def test_Ensemble_fit():\n        tf.keras.backend.clear_session()\n    \n        graph = example_graph_1(feature_size=10)\n    \n        # base_model, keras_model, generator, train_gen\n        gnn_models = [\n>           create_graphSAGE_model(graph),\n            create_HinSAGE_model(graph),\n            create_GCN_model(graph),\n            create_GAT_model(graph),\n        ]\n\ntests/test_ensemble.py:300: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ntests/test_ensemble.py:77: in create_graphSAGE_model\n    base_model = GraphSAGE(\nstellargraph/layer/graphsage.py:866: in __init__\n    self._compute_neighbourhood_sizes()\nstellargraph/layer/graphsage.py:951: in _compute_neighbourhood_sizes\n    self.neighbourhood_sizes = [size_at(i) for i in range(self.max_hops + 1)]\nstellargraph/layer/graphsage.py:951: in <listcomp>\n    self.neighbourhood_sizes = [size_at(i) for i in range(self.max_hops + 1)]\nstellargraph/layer/graphsage.py:949: in size_at\n    return np.product(self.n_samples[:i], dtype=int)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'product'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n            raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\n    \n        if attr == \"chararray\":\n            warnings.warn(\n                \"`np.chararray` is deprecated and will be removed from \"\n                \"the main namespace in the future. Use an array with a string \"\n                \"or bytes dtype instead.\", DeprecationWarning, stacklevel=2)\n            import numpy.char as char\n            return char.chararray\n    \n>       raise AttributeError(\"module {!r} has no attribute \"\n                             \"{!r}\".format(__name__, attr))\nE       AttributeError: module 'numpy' has no attribute 'product'\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:414: AttributeError\n___________________________ test_BaggingEnsemble_fit ___________________________\n\n    def test_BaggingEnsemble_fit():\n        tf.keras.backend.clear_session()\n    \n        train_data = np.array([1, 2])\n        train_targets = np.array([[1, 0], [0, 1]])\n    \n        graph = example_graph_1(feature_size=10)\n    \n        # base_model, keras_model, generator, train_gen\n        gnn_models = [\n>           create_graphSAGE_model(graph),\n            create_HinSAGE_model(graph),\n            create_GCN_model(graph),\n            create_GAT_model(graph),\n        ]\n\ntests/test_ensemble.py:339: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ntests/test_ensemble.py:77: in create_graphSAGE_model\n    base_model = GraphSAGE(\nstellargraph/layer/graphsage.py:866: in __init__\n    self._compute_neighbourhood_sizes()\nstellargraph/layer/graphsage.py:951: in _compute_neighbourhood_sizes\n    self.neighbourhood_sizes = [size_at(i) for i in range(self.max_hops + 1)]\nstellargraph/layer/graphsage.py:951: in <listcomp>\n    self.neighbourhood_sizes = [size_at(i) for i in range(self.max_hops + 1)]\nstellargraph/layer/graphsage.py:949: in size_at\n    return np.product(self.n_samples[:i], dtype=int)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'product'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n            raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\n    \n        if attr == \"chararray\":\n            warnings.warn(\n                \"`np.chararray` is deprecated and will be removed from \"\n                \"the main namespace in the future. Use an array with a string \"\n                \"or bytes dtype instead.\", DeprecationWarning, stacklevel=2)\n            import numpy.char as char\n            return char.chararray\n    \n>       raise AttributeError(\"module {!r} has no attribute \"\n                             \"{!r}\".format(__name__, attr))\nE       AttributeError: module 'numpy' has no attribute 'product'\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:414: AttributeError\n________________________________ test_evaluate _________________________________\n\n    def test_evaluate():\n        tf.keras.backend.clear_session()\n    \n        test_data = np.array([3, 4, 5])\n        test_targets = np.array([[1, 0], [0, 1], [0, 1]])\n    \n        graph = example_graph_1(feature_size=5)\n    \n        # base_model, keras_model, generator, train_gen\n        gnn_models = [\n>           create_graphSAGE_model(graph),\n            create_HinSAGE_model(graph),\n            create_GCN_model(graph),\n            create_GAT_model(graph),\n        ]\n\ntests/test_ensemble.py:434: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ntests/test_ensemble.py:77: in create_graphSAGE_model\n    base_model = GraphSAGE(\nstellargraph/layer/graphsage.py:866: in __init__\n    self._compute_neighbourhood_sizes()\nstellargraph/layer/graphsage.py:951: in _compute_neighbourhood_sizes\n    self.neighbourhood_sizes = [size_at(i) for i in range(self.max_hops + 1)]\nstellargraph/layer/graphsage.py:951: in <listcomp>\n    self.neighbourhood_sizes = [size_at(i) for i in range(self.max_hops + 1)]\nstellargraph/layer/graphsage.py:949: in size_at\n    return np.product(self.n_samples[:i], dtype=int)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'product'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n            raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\n    \n        if attr == \"chararray\":\n            warnings.warn(\n                \"`np.chararray` is deprecated and will be removed from \"\n                \"the main namespace in the future. Use an array with a string \"\n                \"or bytes dtype instead.\", DeprecationWarning, stacklevel=2)\n            import numpy.char as char\n            return char.chararray\n    \n>       raise AttributeError(\"module {!r} has no attribute \"\n                             \"{!r}\".format(__name__, attr))\nE       AttributeError: module 'numpy' has no attribute 'product'\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:414: AttributeError\n_________________________________ test_predict _________________________________\n\n    def test_predict():\n    \n        tf.keras.backend.clear_session()\n    \n        # test_data = np.array([[0, 0], [1, 1], [0.8, 0.8]])\n        test_data = np.array([4, 5, 6])\n        test_targets = np.array([[1, 0], [0, 1], [0, 1]])\n    \n        graph = example_graph_1(feature_size=2)\n    \n        # base_model, keras_model, generator, train_gen\n        gnn_models = [\n>           create_graphSAGE_model(graph),\n            create_HinSAGE_model(graph),\n            create_GCN_model(graph),\n            create_GAT_model(graph),\n        ]\n\ntests/test_ensemble.py:534: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ntests/test_ensemble.py:77: in create_graphSAGE_model\n    base_model = GraphSAGE(\nstellargraph/layer/graphsage.py:866: in __init__\n    self._compute_neighbourhood_sizes()\nstellargraph/layer/graphsage.py:951: in _compute_neighbourhood_sizes\n    self.neighbourhood_sizes = [size_at(i) for i in range(self.max_hops + 1)]\nstellargraph/layer/graphsage.py:951: in <listcomp>\n    self.neighbourhood_sizes = [size_at(i) for i in range(self.max_hops + 1)]\nstellargraph/layer/graphsage.py:949: in size_at\n    return np.product(self.n_samples[:i], dtype=int)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'product'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n            raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\n    \n        if attr == \"chararray\":\n            warnings.warn(\n                \"`np.chararray` is deprecated and will be removed from \"\n                \"the main namespace in the future. Use an array with a string \"\n                \"or bytes dtype instead.\", DeprecationWarning, stacklevel=2)\n            import numpy.char as char\n            return char.chararray\n    \n>       raise AttributeError(\"module {!r} has no attribute \"\n                             \"{!r}\".format(__name__, attr))\nE       AttributeError: module 'numpy' has no attribute 'product'\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:414: AttributeError\n________________________ test_evaluate_link_prediction _________________________\n\n    def test_evaluate_link_prediction():\n        tf.keras.backend.clear_session()\n        edge_ids_test = np.array([[1, 2], [2, 3], [1, 3]])\n        edge_labels_test = np.array([1, 1, 0])\n    \n        graph = example_graph_1(feature_size=4)\n    \n        # base_model, keras_model, generator, train_gen\n        gnn_models = [\n>           create_graphSAGE_model(graph, link_prediction=True),\n            create_HinSAGE_model(graph, link_prediction=True),\n        ]\n\ntests/test_ensemble.py:629: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ntests/test_ensemble.py:77: in create_graphSAGE_model\n    base_model = GraphSAGE(\nstellargraph/layer/graphsage.py:866: in __init__\n    self._compute_neighbourhood_sizes()\nstellargraph/layer/graphsage.py:951: in _compute_neighbourhood_sizes\n    self.neighbourhood_sizes = [size_at(i) for i in range(self.max_hops + 1)]\nstellargraph/layer/graphsage.py:951: in <listcomp>\n    self.neighbourhood_sizes = [size_at(i) for i in range(self.max_hops + 1)]\nstellargraph/layer/graphsage.py:949: in size_at\n    return np.product(self.n_samples[:i], dtype=int)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'product'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n            raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\n    \n        if attr == \"chararray\":\n            warnings.warn(\n                \"`np.chararray` is deprecated and will be removed from \"\n                \"the main namespace in the future. Use an array with a string \"\n                \"or bytes dtype instead.\", DeprecationWarning, stacklevel=2)\n            import numpy.char as char\n            return char.chararray\n    \n>       raise AttributeError(\"module {!r} has no attribute \"\n                             \"{!r}\".format(__name__, attr))\nE       AttributeError: module 'numpy' has no attribute 'product'\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:414: AttributeError\n_________________________ test_predict_link_prediction _________________________\n\n    def test_predict_link_prediction():\n        tf.keras.backend.clear_session()\n        edge_ids_test = np.array([[1, 2], [2, 3], [1, 3]])\n    \n        graph = example_graph_1(feature_size=2)\n    \n        # base_model, keras_model, generator, train_gen\n        gnn_models = [\n>           create_graphSAGE_model(graph, link_prediction=True),\n            create_HinSAGE_model(graph, link_prediction=True),\n        ]\n\ntests/test_ensemble.py:727: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ntests/test_ensemble.py:77: in create_graphSAGE_model\n    base_model = GraphSAGE(\nstellargraph/layer/graphsage.py:866: in __init__\n    self._compute_neighbourhood_sizes()\nstellargraph/layer/graphsage.py:951: in _compute_neighbourhood_sizes\n    self.neighbourhood_sizes = [size_at(i) for i in range(self.max_hops + 1)]\nstellargraph/layer/graphsage.py:951: in <listcomp>\n    self.neighbourhood_sizes = [size_at(i) for i in range(self.max_hops + 1)]\nstellargraph/layer/graphsage.py:949: in size_at\n    return np.product(self.n_samples[:i], dtype=int)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nattr = 'product'\n\n    def __getattr__(attr):\n        # Warn for expired attributes\n        import warnings\n    \n        if attr == \"linalg\":\n            import numpy.linalg as linalg\n            return linalg\n        elif attr == \"fft\":\n            import numpy.fft as fft\n            return fft\n        elif attr == \"dtypes\":\n            import numpy.dtypes as dtypes\n            return dtypes\n        elif attr == \"random\":\n            import numpy.random as random\n            return random\n        elif attr == \"polynomial\":\n            import numpy.polynomial as polynomial\n            return polynomial\n        elif attr == \"ma\":\n            import numpy.ma as ma\n            return ma\n        elif attr == \"ctypeslib\":\n            import numpy.ctypeslib as ctypeslib\n            return ctypeslib\n        elif attr == \"exceptions\":\n            import numpy.exceptions as exceptions\n            return exceptions\n        elif attr == \"testing\":\n            import numpy.testing as testing\n            return testing\n        elif attr == \"matlib\":\n            import numpy.matlib as matlib\n            return matlib\n        elif attr == \"f2py\":\n            import numpy.f2py as f2py\n            return f2py\n        elif attr == \"typing\":\n            import numpy.typing as typing\n            return typing\n        elif attr == \"rec\":\n            import numpy.rec as rec\n            return rec\n        elif attr == \"char\":\n            import numpy.char as char\n            return char\n        elif attr == \"array_api\":\n            raise AttributeError(\"`numpy.array_api` is not available from \"\n                                 \"numpy 2.0 onwards\", name=None)\n        elif attr == \"core\":\n            import numpy.core as core\n            return core\n        elif attr == \"strings\":\n            import numpy.strings as strings\n            return strings\n        elif attr == \"distutils\":\n            if 'distutils' in __numpy_submodules__:\n                import numpy.distutils as distutils\n                return distutils\n            else:\n                raise AttributeError(\"`numpy.distutils` is not available from \"\n                                     \"Python 3.12 onwards\", name=None)\n    \n        if attr in __future_scalars__:\n            # And future warnings for those that will change, but also give\n            # the AttributeError\n            warnings.warn(\n                f\"In the future `np.{attr}` will be defined as the \"\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n    \n        if attr in __former_attrs__:\n            raise AttributeError(__former_attrs__[attr], name=None)\n    \n        if attr in __expired_attributes__:\n            raise AttributeError(\n                f\"`np.{attr}` was removed in the NumPy 2.0 release. \"\n                f\"{__expired_attributes__[attr]}\",\n                name=None\n            )\n    \n        if attr == \"chararray\":\n            warnings.warn(\n                \"`np.chararray` is deprecated and will be removed from \"\n                \"the main namespace in the future. Use an array with a string \"\n                \"or bytes dtype instead.\", DeprecationWarning, stacklevel=2)\n            import numpy.char as char\n            return char.chararray\n    \n>       raise AttributeError(\"module {!r} has no attribute \"\n                             \"{!r}\".format(__name__, attr))\nE       AttributeError: module 'numpy' has no attribute 'product'\n\n/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:414: AttributeError\n___________________________ test_deprecated_methods ____________________________\n\n    def test_deprecated_methods():\n        tf.keras.backend.clear_session()\n    \n        train_data = np.array([1, 2])\n        train_targets = np.array([[1, 0], [0, 1]])\n    \n        graph = example_graph_1(feature_size=2)\n    \n        _, keras_model, gen, train_gen = create_GAT_model(graph)\n    \n        ensemble = Ensemble(keras_model, n_estimators=1, n_predictions=1)\n        bagging = BaggingEnsemble(keras_model, n_estimators=1, n_predictions=1)\n        models = [ensemble, bagging]\n        for model in models:\n>           model.compile(optimizer=Adam(), loss=binary_crossentropy)\n\ntests/test_ensemble.py:808: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nstellargraph/ensemble.py:185: in compile\n    model.compile(\n/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py:122: in error_handler\n    raise e.with_traceback(filtered_tb) from None\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nargs = (<Functional name=functional, built=True>,)\nkwargs = {'loss': <function binary_crossentropy at 0x7fc1c02c2170>, 'loss_weights': None, 'metrics': None, 'optimizer': <keras.src.optimizers.adam.Adam object at 0x7fc18c52f820>, ...}\n\n    @wraps(fn)\n    def wrapper(*args, **kwargs):\n        with DotNotTrackScope():\n>           return fn(*args, **kwargs)\nE           TypeError: Trainer.compile() got an unexpected keyword argument 'sample_weight_mode'\n\n/usr/local/lib/python3.10/dist-packages/keras/src/utils/tracking.py:26: TypeError\n----------------------------- Captured stdout call -----------------------------\nUsing GCN (local pooling) filters...\n_______________________ test_poincare_ball_distance_self _______________________\n\nseeded = None\n\n    def test_poincare_ball_distance_self(seeded):\n        # the distance between a point and itself should be 0\n        for _ in range(100):\n            c, vs = _generate(17)\n    \n            d = poincare_ball_distance(c, vs, vs)\n            assert d.shape == vs.shape[:-1]\n>           np.testing.assert_allclose(d, 0, rtol=1e-6, atol=1e-5)\n\ntests/utils/test_hyperbolic.py:72: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nargs = (<function assert_allclose.<locals>.compare at 0x7fc14d6c1d80>, array([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., nan,\n         0.,  0.,  0.,  0.]], dtype=float32), array(0))\nkwds = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-06, atol=1e-05', 'strict': False, ...}\n\n    @wraps(func)\n    def inner(*args, **kwds):\n        with self._recreate_cm():\n>           return func(*args, **kwds)\nE           AssertionError: \nE           Not equal to tolerance rtol=1e-06, atol=1e-05\nE           \nE           nan location mismatch:\nE            ACTUAL: array([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., nan,\nE                    0.,  0.,  0.,  0.]], dtype=float32)\nE            DESIRED: array(0)\n\n/usr/lib/python3.10/contextlib.py:79: AssertionError\n---------------------------- Captured stdout setup -----------------------------\nseed: 3412345470\n=============================== warnings summary ===============================\ntests/core/test_graph.py:381\n  /app/repo_to_process/tests/core/test_graph.py:381: PytestUnknownMarkWarning: Unknown pytest.mark.benchmark - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    @pytest.mark.benchmark(group=\"StellarGraph create_graph_schema\")\n\ntests/core/test_graph.py:991\n  /app/repo_to_process/tests/core/test_graph.py:991: PytestUnknownMarkWarning: Unknown pytest.mark.benchmark - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    @pytest.mark.benchmark(group=\"StellarGraph neighbours\")\n\ntests/core/test_graph.py:1006\n  /app/repo_to_process/tests/core/test_graph.py:1006: PytestUnknownMarkWarning: Unknown pytest.mark.benchmark - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    @pytest.mark.benchmark(group=\"StellarGraph node features\")\n\ntests/core/test_graph.py:1070\n  /app/repo_to_process/tests/core/test_graph.py:1070: PytestUnknownMarkWarning: Unknown pytest.mark.benchmark - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    @pytest.mark.benchmark(group=\"StellarGraph creation (time)\")\n\ntests/core/test_graph.py:1082\n  /app/repo_to_process/tests/core/test_graph.py:1082: PytestUnknownMarkWarning: Unknown pytest.mark.benchmark - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    @pytest.mark.benchmark(group=\"StellarGraph creation (size)\", timer=snapshot)\n\ntests/core/test_graph.py:1094\n  /app/repo_to_process/tests/core/test_graph.py:1094: PytestUnknownMarkWarning: Unknown pytest.mark.benchmark - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    @pytest.mark.benchmark(group=\"StellarGraph creation (peak)\", timer=peak)\n\ntests/core/test_graph.py:1120\n  /app/repo_to_process/tests/core/test_graph.py:1120: PytestUnknownMarkWarning: Unknown pytest.mark.benchmark - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    @pytest.mark.benchmark(group=\"StellarGraph adjacency lists (time)\")\n\ntests/core/test_graph.py:1129\n  /app/repo_to_process/tests/core/test_graph.py:1129: PytestUnknownMarkWarning: Unknown pytest.mark.benchmark - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    @pytest.mark.benchmark(group=\"StellarGraph adjacency lists (size)\", timer=snapshot)\n\ntests/core/test_graph.py:1138\n  /app/repo_to_process/tests/core/test_graph.py:1138: PytestUnknownMarkWarning: Unknown pytest.mark.benchmark - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    @pytest.mark.benchmark(group=\"StellarGraph adjacency lists (peak)\", timer=peak)\n\ntests/core/test_graph.py:1996\n  /app/repo_to_process/tests/core/test_graph.py:1996: PytestUnknownMarkWarning: Unknown pytest.mark.benchmark - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    @pytest.mark.benchmark(group=\"StellarGraph to_adjacency_matrix\")\n\ntests/mapper/test_benchmark_generators.py:33\n  /app/repo_to_process/tests/mapper/test_benchmark_generators.py:33: PytestUnknownMarkWarning: Unknown pytest.mark.benchmark - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    @pytest.mark.benchmark(group=\"generator\")\n\ntests/mapper/test_benchmark_generators.py:52\n  /app/repo_to_process/tests/mapper/test_benchmark_generators.py:52: PytestUnknownMarkWarning: Unknown pytest.mark.benchmark - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    @pytest.mark.benchmark(group=\"generator\")\n\ntests/mapper/test_benchmark_generators.py:71\n  /app/repo_to_process/tests/mapper/test_benchmark_generators.py:71: PytestUnknownMarkWarning: Unknown pytest.mark.benchmark - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    @pytest.mark.benchmark(group=\"generator\")\n\ntests/mapper/test_benchmark_generators.py:96\n  /app/repo_to_process/tests/mapper/test_benchmark_generators.py:96: PytestUnknownMarkWarning: Unknown pytest.mark.benchmark - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    @pytest.mark.benchmark(group=\"generator\")\n\ntests/mapper/test_benchmark_generators.py:121\n  /app/repo_to_process/tests/mapper/test_benchmark_generators.py:121: PytestUnknownMarkWarning: Unknown pytest.mark.benchmark - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    @pytest.mark.benchmark(group=\"generator\")\n\ntests/mapper/test_benchmark_generators.py:146\n  /app/repo_to_process/tests/mapper/test_benchmark_generators.py:146: PytestUnknownMarkWarning: Unknown pytest.mark.benchmark - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    @pytest.mark.benchmark(group=\"generator\")\n\ntests/mapper/test_cluster_gcn_node_mapper.py:222\n  /app/repo_to_process/tests/mapper/test_cluster_gcn_node_mapper.py:222: PytestUnknownMarkWarning: Unknown pytest.mark.benchmark - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    @pytest.mark.benchmark(group=\"ClusterGCN generator\")\n\ntests/core/test_graph.py::test_graph_constructor_extra_nodes_in_edges\ntests/core/test_graph.py::test_graph_constructor_rowframe_numpy_invalid\ntests/core/test_graph.py::test_graph_constructor_rowframe_numpy_invalid\n  /app/repo_to_process/stellargraph/core/convert.py:281: FutureWarning: unique with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n    missing_values = pd.unique(missing_values)\n\ntests/core/test_graph.py::test_info\n  /app/repo_to_process/tests/core/test_graph.py:324: DeprecationWarning: 'show_attributes' is no longer used, remove it from the 'info()' call\n    info_str = sg.info(show_attributes=False)\n\ntests/core/test_utils.py::test_smart_array_index_size_0\ntests/core/test_utils.py::test_smart_array_index_size_0\n  /app/repo_to_process/stellargraph/core/utils.py:80: DeprecationWarning: Out of bound index found. This was previously ignored when the indexing result contained no elements. In the future the index error will be raised. This error occurs either due to an empty slice, or if an array has zero elements even before indexing.\n  (Use `warnings.simplefilter('error')` to turn this DeprecationWarning into an error and get more details on the invalid index.)\n    return array[indices]\n\ntests/core/test_utils.py::test_smart_array_index_size_0\ntests/core/test_utils.py::test_smart_array_index_size_0\n  /app/repo_to_process/tests/core/test_utils.py:37: DeprecationWarning: Out of bound index found. This was previously ignored when the indexing result contained no elements. In the future the index error will be raised. This error occurs either due to an empty slice, or if an array has zero elements even before indexing.\n  (Use `warnings.simplefilter('error')` to turn this DeprecationWarning into an error and get more details on the invalid index.)\n    np.testing.assert_array_equal(result, array[idx])\n\ntests/core/test_utils.py::test_normalize_adj\ntests/core/test_utils.py::test_normalized_laplacian\ntests/core/test_utils.py::test_rescale_laplacian\n  /app/repo_to_process/stellargraph/core/utils.py:131: RuntimeWarning: divide by zero encountered in power\n    d = sp.diags(np.power(np.array(adj.sum(1)), -0.5).flatten(), 0)\n\ntests/core/test_utils.py::test_normalize_adj\ntests/core/test_utils.py::test_normalized_laplacian\n  /app/repo_to_process/stellargraph/core/utils.py:134: RuntimeWarning: divide by zero encountered in float_power\n    d = sp.diags(np.float_power(np.array(adj.sum(1)), -1).flatten(), 0)\n\ntests/data/test_biased_random_walker.py::TestBiasedRandomWalk::test_parameter_checking\n  /app/repo_to_process/tests/data/test_biased_random_walker.py:316: RuntimeWarning: No root node IDs given. An empty list will be returned as a result.\n    subgraph = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=None)\n\ntests/data/test_breadth_first_walker.py::TestBreadthFirstWalk::test_parameter_checking\n  /app/repo_to_process/stellargraph/data/explorer.py:709: RuntimeWarning: No root node IDs given. An empty list will be returned as a result.\n    self._check_common_parameters(nodes, n, len(n_size), seed)\n\ntests/data/test_directed_breadth_first_sampler.py::TestDirectedBreadthFirstNeighbours::test_parameter_checking\n  /app/repo_to_process/stellargraph/data/explorer.py:873: RuntimeWarning: No root node IDs given. An empty list will be returned as a result.\n    self._check_common_parameters(nodes, n, len(in_size), seed)\n\ntests/data/test_edge_splitter.py::TestEdgeSplitterHomogeneous::test_split_data_local\ntests/data/test_edge_splitter.py::TestEdgeSplitterHeterogeneous::test_split_data_local\n  /app/repo_to_process/stellargraph/data/edge_splitter.py:377: RuntimeWarning: Using default sampling probabilities (distance from source node): [0.0, 0.25, 0.5, 0.25]\n    edge_data_ids, edge_data_labels = self._train_test_split_homogeneous(\n\ntests/data/test_edge_splitter.py::TestEdgeSplitterHeterogeneous::test_split_data_by_edge_type_and_attribute\ntests/data/test_edge_splitter.py::TestEdgeSplitterHeterogeneous::test_split_data_by_edge_type\n  /app/repo_to_process/stellargraph/data/edge_splitter.py:368: RuntimeWarning: Using default sampling probabilities (distance from source node): [0.0, 0.25, 0.5, 0.25]\n    edge_data_ids, edge_data_labels = self._train_test_split_heterogeneous(\n\ntests/data/test_heterogeneous_breadth_first_walker.py::TestSampledHeterogeneousBreadthFirstWalk::test_parameter_checking\n  /app/repo_to_process/stellargraph/data/explorer.py:773: RuntimeWarning: No root node IDs given. An empty list will be returned as a result.\n    self._check_common_parameters(nodes, n, len(n_size), seed)\n\ntests/data/test_metapath_walker.py::TestMetaPathWalk::test_parameter_checking\n  /app/repo_to_process/tests/data/test_metapath_walker.py:155: RuntimeWarning: No root node IDs given. An empty list will be returned as a result.\n    walks = mrw.run(nodes=[], n=n, length=length, metapaths=metapaths, seed=seed)\n\ntests/data/test_uniform_random_walker.py::TestUniformRandomWalk::test_parameter_checking\n  /app/repo_to_process/tests/data/test_uniform_random_walker.py:75: RuntimeWarning: No root node IDs given. An empty list will be returned as a result.\n    subgraph = urw.run(nodes=nodes, n=n, length=length, seed=None)\n\ntests/datasets/test_datasets.py::test_dataset_download[METR_LA]\n  /app/repo_to_process/tests/datasets/test_datasets.py:32: ExperimentalWarning: METR_LA is experimental: tests and documentation missing (see: https://github.com/stellargraph/stellargraph/issues/1303). It may be difficult to use and may have major changes at any time.\n    dataset_class().download(ignore_cache=True)\n\ntests/layer/test_appnp.py: 6 warnings\ntests/layer/test_cluster_gcn.py: 1 warning\ntests/layer/test_cluster_models.py: 3 warnings\ntests/layer/test_gcn.py: 4 warnings\ntests/layer/test_graph_attention.py: 2 warnings\ntests/layer/test_graph_classification.py: 1 warning\ntests/layer/test_ppnp.py: 1 warning\n  /usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n    self._warn_if_super_not_called()\n\ntests/layer/test_attri2vec.py::test_attri2vec_constructor\ntests/layer/test_attri2vec.py::test_attri2vec_apply\ntests/layer/test_attri2vec.py::test_attri2vec_serialize\ntests/layer/test_attri2vec.py::test_attri2vec_save_load\ntests/layer/test_node2vec.py::test_node2vec_constructor\ntests/layer/test_node2vec.py::test_node2vec_apply\ntests/layer/test_node2vec.py::test_node2vec_serialize\ntests/layer/test_node2vec.py::test_node2vec_save_load\n  /usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n    warnings.warn(\n\ntests/layer/test_gcn_lstm.py::test_gcn_lstm_model_parameters\n  /app/repo_to_process/tests/layer/test_gcn_lstm.py:56: ExperimentalWarning: GCN_LSTM is experimental: Lack of unit tests and code refinement (see: https://github.com/stellargraph/stellargraph/issues/1132, https://github.com/stellargraph/stellargraph/issues/1526, https://github.com/stellargraph/stellargraph/issues/1564). It may be difficult to use and may have major changes at any time.\n    gcn_lstm_model = GCN_LSTM(\n\ntests/layer/test_gcn_lstm.py::test_gcn_lstm_activations\n  /app/repo_to_process/tests/layer/test_gcn_lstm.py:74: ExperimentalWarning: GCN_LSTM is experimental: Lack of unit tests and code refinement (see: https://github.com/stellargraph/stellargraph/issues/1132, https://github.com/stellargraph/stellargraph/issues/1526, https://github.com/stellargraph/stellargraph/issues/1564). It may be difficult to use and may have major changes at any time.\n    gcn_lstm_model = GCN_LSTM(\n\ntests/layer/test_gcn_lstm.py::test_gcn_lstm_activations\n  /app/repo_to_process/tests/layer/test_gcn_lstm.py:84: ExperimentalWarning: GCN_LSTM is experimental: Lack of unit tests and code refinement (see: https://github.com/stellargraph/stellargraph/issues/1132, https://github.com/stellargraph/stellargraph/issues/1526, https://github.com/stellargraph/stellargraph/issues/1564). It may be difficult to use and may have major changes at any time.\n    gcn_lstm_model = GCN_LSTM(\n\ntests/layer/test_gcn_lstm.py::test_lstm_return_sequences\n  /app/repo_to_process/tests/layer/test_gcn_lstm.py:98: ExperimentalWarning: GCN_LSTM is experimental: Lack of unit tests and code refinement (see: https://github.com/stellargraph/stellargraph/issues/1132, https://github.com/stellargraph/stellargraph/issues/1526, https://github.com/stellargraph/stellargraph/issues/1564). It may be difficult to use and may have major changes at any time.\n    gcn_lstm_model = GCN_LSTM(\n\ntests/layer/test_gcn_lstm.py::test_gcn_lstm_layers\n  /app/repo_to_process/tests/layer/test_gcn_lstm.py:114: ExperimentalWarning: GCN_LSTM is experimental: Lack of unit tests and code refinement (see: https://github.com/stellargraph/stellargraph/issues/1132, https://github.com/stellargraph/stellargraph/issues/1526, https://github.com/stellargraph/stellargraph/issues/1564). It may be difficult to use and may have major changes at any time.\n    gcn_lstm_model = GCN_LSTM(\n\ntests/layer/test_gcn_lstm.py::test_gcn_lstm_model_input_output\n  /app/repo_to_process/tests/layer/test_gcn_lstm.py:130: ExperimentalWarning: GCN_LSTM is experimental: Lack of unit tests and code refinement (see: https://github.com/stellargraph/stellargraph/issues/1132, https://github.com/stellargraph/stellargraph/issues/1526, https://github.com/stellargraph/stellargraph/issues/1564). It may be difficult to use and may have major changes at any time.\n    gcn_lstm_model = GCN_LSTM(\n\ntests/layer/test_gcn_lstm.py::test_gcn_lstm_model\n  /app/repo_to_process/tests/layer/test_gcn_lstm.py:149: ExperimentalWarning: GCN_LSTM is experimental: Lack of unit tests and code refinement (see: https://github.com/stellargraph/stellargraph/issues/1132, https://github.com/stellargraph/stellargraph/issues/1526, https://github.com/stellargraph/stellargraph/issues/1564). It may be difficult to use and may have major changes at any time.\n    gcn_lstm_model = GCN_LSTM(\n\ntests/layer/test_gcn_lstm.py::test_gcn_lstm_model_prediction\n  /app/repo_to_process/tests/layer/test_gcn_lstm.py:173: ExperimentalWarning: GCN_LSTM is experimental: Lack of unit tests and code refinement (see: https://github.com/stellargraph/stellargraph/issues/1132, https://github.com/stellargraph/stellargraph/issues/1526, https://github.com/stellargraph/stellargraph/issues/1564). It may be difficult to use and may have major changes at any time.\n    gcn_lstm_model = GCN_LSTM(\n\ntests/layer/test_graph_attention.py::Test_GraphAttention::test_apply_concat\ntests/layer/test_graph_attention.py::Test_GraphAttention::test_apply_average\ntests/layer/test_graph_attention.py::Test_GraphAttention::test_apply_average_with_neighbours\ntests/layer/test_graph_attention.py::Test_GraphAttentionSparse::test_apply_concat\ntests/layer/test_graph_attention.py::Test_GraphAttentionSparse::test_apply_average\ntests/layer/test_graph_attention.py::Test_GraphAttentionSparse::test_apply_average_with_neighbours\n  /usr/local/lib/python3.10/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n    warnings.warn(\n\ntests/layer/test_hinsage.py::test_mean_hin_agg_constructor_1\n  /usr/local/lib/python3.10/dist-packages/keras/src/activations/__init__.py:78: UserWarning: The object being serialized includes a `lambda`. This is unsafe. In order to reload the object, you will have to pass `safe_mode=False` to the loading function. Please avoid using `lambda` in the future, and use named Python functions instead. This is the `lambda` being serialized:     agg = MeanHinAggregator(output_dim=2, bias=True, act=lambda x: x + 1)\n  \n    fn_config = serialization_lib.serialize_keras_object(activation)\n\ntests/layer/test_knowledge_graph.py::test_rotate\n  /app/repo_to_process/tests/layer/test_knowledge_graph.py:180: ExperimentalWarning: RotatE is experimental: demo and documentation is missing (see: https://github.com/stellargraph/stellargraph/issues/1549, https://github.com/stellargraph/stellargraph/issues/1550). It may be difficult to use and may have major changes at any time.\n    rotate_model = RotatE(\n\ntests/layer/test_knowledge_graph.py::test_rote_roth[RotE]\n  /app/repo_to_process/tests/layer/test_knowledge_graph.py:240: ExperimentalWarning: RotE is experimental: demo is missing (see: https://github.com/stellargraph/stellargraph/issues/1664). It may be difficult to use and may have major changes at any time.\n    rot_model = model_class(gen, 6, embeddings_initializer=init)\n\ntests/layer/test_knowledge_graph.py::test_rote_roth[RotH]\n  /app/repo_to_process/tests/layer/test_knowledge_graph.py:240: ExperimentalWarning: RotH is experimental: demo is missing (see: https://github.com/stellargraph/stellargraph/issues/1664). It may be difficult to use and may have major changes at any time.\n    rot_model = model_class(gen, 6, embeddings_initializer=init)\n\ntests/layer/test_knowledge_graph.py::test_model_rankings[ComplEx]\ntests/layer/test_knowledge_graph.py::test_model_rankings[DistMult]\ntests/layer/test_knowledge_graph.py::test_model_rankings[RotatE]\ntests/layer/test_knowledge_graph.py::test_model_rankings[RotH]\ntests/layer/test_knowledge_graph.py::test_model_rankings[RotE]\n  /app/repo_to_process/tests/layer/test_knowledge_graph.py:321: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n    every_edge_df.groupby(\"label\").apply(lambda df: df.sample(n=1)).droplevel(0)\n\ntests/layer/test_knowledge_graph.py::test_model_rankings[RotatE]\n  /app/repo_to_process/tests/layer/test_knowledge_graph.py:340: ExperimentalWarning: RotatE is experimental: demo and documentation is missing (see: https://github.com/stellargraph/stellargraph/issues/1549, https://github.com/stellargraph/stellargraph/issues/1550). It may be difficult to use and may have major changes at any time.\n    sg_model = model_maker(gen, embedding_dimension=6)\n\ntests/layer/test_knowledge_graph.py::test_model_rankings[RotH]\n  /app/repo_to_process/tests/layer/test_knowledge_graph.py:340: ExperimentalWarning: RotH is experimental: demo is missing (see: https://github.com/stellargraph/stellargraph/issues/1664). It may be difficult to use and may have major changes at any time.\n    sg_model = model_maker(gen, embedding_dimension=6)\n\ntests/layer/test_knowledge_graph.py::test_model_rankings[RotE]\n  /app/repo_to_process/tests/layer/test_knowledge_graph.py:340: ExperimentalWarning: RotE is experimental: demo is missing (see: https://github.com/stellargraph/stellargraph/issues/1664). It may be difficult to use and may have major changes at any time.\n    sg_model = model_maker(gen, embedding_dimension=6)\n\ntests/layer/test_knowledge_graph.py::test_save_load[RotatE]\n  /app/repo_to_process/tests/layer/test_knowledge_graph.py:508: ExperimentalWarning: RotatE is experimental: demo and documentation is missing (see: https://github.com/stellargraph/stellargraph/issues/1549, https://github.com/stellargraph/stellargraph/issues/1550). It may be difficult to use and may have major changes at any time.\n    sg_model = model_maker(gen, embedding_dimension=6)\n\ntests/layer/test_knowledge_graph.py::test_save_load[RotH]\n  /app/repo_to_process/tests/layer/test_knowledge_graph.py:508: ExperimentalWarning: RotH is experimental: demo is missing (see: https://github.com/stellargraph/stellargraph/issues/1664). It may be difficult to use and may have major changes at any time.\n    sg_model = model_maker(gen, embedding_dimension=6)\n\ntests/layer/test_knowledge_graph.py::test_save_load[RotE]\n  /app/repo_to_process/tests/layer/test_knowledge_graph.py:508: ExperimentalWarning: RotE is experimental: demo is missing (see: https://github.com/stellargraph/stellargraph/issues/1664). It may be difficult to use and may have major changes at any time.\n    sg_model = model_maker(gen, embedding_dimension=6)\n\ntests/layer/test_misc.py::test_deprecated_model_functions\ntests/layer/test_misc.py::test_deprecated_model_functions\n  /app/repo_to_process/stellargraph/layer/gcn.py:491: UserWarning: Link model requested but a generator not supporting links was supplied.\n    warnings.warn(\n\ntests/layer/test_misc.py::test_deprecated_model_functions\ntests/layer/test_misc.py::test_deprecated_model_functions\n  /app/repo_to_process/stellargraph/layer/graph_attention.py:940: UserWarning: Link model requested but a generator not supporting links was supplied.\n    warnings.warn(\n\ntests/layer/test_misc.py::test_deprecated_model_functions\ntests/layer/test_misc.py::test_deprecated_model_functions\n  /app/repo_to_process/stellargraph/layer/ppnp.py:354: UserWarning: Link model requested but a generator not supporting links was supplied.\n    warnings.warn(\n\ntests/layer/test_misc.py::test_deprecated_model_functions\ntests/layer/test_misc.py::test_deprecated_model_functions\n  /app/repo_to_process/stellargraph/layer/appnp.py:422: UserWarning: Link model requested but a generator not supporting links was supplied.\n    warnings.warn(\n\ntests/layer/test_misc.py::test_deprecated_model_functions\n  /app/repo_to_process/tests/layer/test_misc.py:170: DeprecationWarning: The 'corrupted_generator' parameter should be set to an instance of `CorruptedGenerator`, because the support for specific algorithms is being replaced by a more general form\n    sg_model = DeepGraphInfomax(sg_model)\n\ntests/layer/test_sort_pooling.py::test_sorting_padding\n  /usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:970: UserWarning: Layer 'sort_pooling_1' (of type SortPooling) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n    warnings.warn(\n\ntests/layer/test_sort_pooling.py::test_sorting_padding\n  /usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:970: UserWarning: Layer 'sort_pooling_2' (of type SortPooling) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n    warnings.warn(\n\ntests/layer/test_sort_pooling.py::test_sorting_truncation\n  /usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:970: UserWarning: Layer 'sort_pooling_3' (of type SortPooling) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n    warnings.warn(\n\ntests/layer/test_sort_pooling.py::test_sorting_truncation\n  /usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:970: UserWarning: Layer 'sort_pooling_4' (of type SortPooling) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n    warnings.warn(\n\ntests/layer/test_sort_pooling.py::test_sorting_negative_values\n  /usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:970: UserWarning: Layer 'sort_pooling_5' (of type SortPooling) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n    warnings.warn(\n\ntests/layer/test_sort_pooling.py::test_mask\n  /usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:970: UserWarning: Layer 'sort_pooling_6' (of type SortPooling) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n    warnings.warn(\n\ntests/layer/test_sort_pooling.py::test_mask\n  /usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:970: UserWarning: Layer 'sort_pooling_7' (of type SortPooling) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n    warnings.warn(\n\ntests/layer/test_sort_pooling.py::test_flatten_output\n  /usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:970: UserWarning: Layer 'sort_pooling_8' (of type SortPooling) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n    warnings.warn(\n\ntests/layer/test_watch_your_step.py::test_AttentiveWalk\n  /usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/core.py:171: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments.\n    return np.array(x)\n\ntests/mapper/test_knowledge_graph.py: 13 warnings\n  /usr/lib/python3.10/random.py:125: DeprecationWarning: Seeding based on hashing is deprecated\n  since Python 3.9 and will be removed in a subsequent version. The only \n  supported seed types are: None, int, float, str, bytes, and bytearray.\n    self.seed(x)\n\ntests/reproducibility/test_deep_graph_infomax.py::test_dgi[False-GCN]\ntests/reproducibility/test_deep_graph_infomax.py::test_dgi[False-APPNP]\ntests/reproducibility/test_deep_graph_infomax.py::test_dgi[False-GAT]\ntests/reproducibility/test_deep_graph_infomax.py::test_dgi[False-PPNP]\ntests/reproducibility/test_deep_graph_infomax.py::test_dgi[True-GCN]\ntests/reproducibility/test_deep_graph_infomax.py::test_dgi[True-APPNP]\ntests/reproducibility/test_deep_graph_infomax.py::test_dgi[True-GAT]\n  /app/repo_to_process/tests/reproducibility/test_deep_graph_infomax.py:37: DeprecationWarning: The 'corrupted_generator' parameter should be set to an instance of `CorruptedGenerator`, because the support for specific algorithms is being replaced by a more general form\n    infomax = DeepGraphInfomax(base_model)\n\ntests/test_calibration.py::test_temperature_scaling_fit_predict\n  /usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n    y = column_or_1d(y, warn=True)\n\ntests/test_losses.py::test_graph_log_likelihood\n  /app/repo_to_process/tests/test_losses.py:35: ExperimentalWarning: graph_log_likelihood is experimental: lack of unit tests (see: https://github.com/stellargraph/stellargraph/issues/804). It may be difficult to use and may have major changes at any time.\n    actual_loss = graph_log_likelihood(batch_adj, wys_output).numpy()[0]\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n=========================== short test summary info ============================\nFAILED scripts/test_demos.py::test_notebooks - FileNotFoundError: [Errno 2] N...\nFAILED tests/core/test_graph.py::test_graph_constructor_extra_nodes_in_edges\nFAILED tests/core/test_graph.py::test_to_networkx_deprecation - TypeError: ex...\nFAILED tests/core/test_graph.py::test_neighbors_weighted_hin[True-True] - Att...\nFAILED tests/core/test_graph.py::test_neighbors_weighted_hin[True-False] - At...\nFAILED tests/core/test_graph.py::test_neighbors_weighted_hin[False-True] - At...\nFAILED tests/core/test_graph.py::test_neighbors_weighted_hin[False-False] - A...\nFAILED tests/core/test_graph.py::test_neighbors_unweighted_hom[True-True] - A...\nFAILED tests/core/test_graph.py::test_neighbors_unweighted_hom[True-False] - ...\nFAILED tests/core/test_graph.py::test_neighbors_unweighted_hom[False-True] - ...\nFAILED tests/core/test_graph.py::test_neighbors_unweighted_hom[False-False]\nFAILED tests/core/test_graph.py::test_undirected_hin_neighbor_methods[True]\nFAILED tests/core/test_graph.py::test_undirected_hin_neighbor_methods[False]\nFAILED tests/core/test_graph.py::test_isolated_node_neighbor_methods[False-True]\nFAILED tests/core/test_graph.py::test_isolated_node_neighbor_methods[False-False]\nFAILED tests/core/test_graph.py::test_isolated_node_neighbor_methods[True-True]\nFAILED tests/core/test_graph.py::test_isolated_node_neighbor_methods[True-False]\nFAILED tests/core/test_graph.py::test_edge_weights_undirected[True] - Attribu...\nFAILED tests/core/test_graph.py::test_edge_weights_undirected[False] - Attrib...\nFAILED tests/core/test_graph.py::test_node_degrees[True] - AttributeError: `n...\nFAILED tests/core/test_graph.py::test_node_degrees[False] - AttributeError: `...\nFAILED tests/core/test_graph.py::test_correct_adjacency_list_type - Attribute...\nFAILED tests/core/test_utils.py::test_smart_array_index_empty - assert 0 > 0\nFAILED tests/data/test_biased_random_walker.py::TestBiasedWeightedRandomWalk::test_init_parameters\nFAILED tests/data/test_biased_random_walker.py::TestBiasedWeightedRandomWalk::test_identity_unweighted_weighted_1_walks\nFAILED tests/data/test_biased_random_walker.py::TestBiasedWeightedRandomWalk::test_weighted_walks\nFAILED tests/data/test_biased_random_walker.py::TestBiasedWeightedRandomWalk::test_weighted_graph_label\nFAILED tests/data/test_biased_random_walker.py::TestBiasedRandomWalk::test_parameter_checking\nFAILED tests/data/test_biased_random_walker.py::TestBiasedRandomWalk::test_walk_generation_single_root_node\nFAILED tests/data/test_biased_random_walker.py::TestBiasedRandomWalk::test_walk_generation_many_root_nodes\nFAILED tests/data/test_biased_random_walker.py::TestBiasedRandomWalk::test_walk_generation_loner_root_node\nFAILED tests/data/test_biased_random_walker.py::TestBiasedRandomWalk::test_walk_generation_self_loner_root_node\nFAILED tests/data/test_biased_random_walker.py::TestBiasedRandomWalk::test_walk_biases\nFAILED tests/data/test_breadth_first_walker.py::TestBreadthFirstWalk::test_walk_generation_single_root_node_loner\nFAILED tests/data/test_breadth_first_walker.py::TestBreadthFirstWalk::test_directed_walk_generation_single_root_node\nFAILED tests/data/test_breadth_first_walker.py::TestBreadthFirstWalk::test_walk_generation_single_root_node_self_loner\nFAILED tests/data/test_breadth_first_walker.py::TestBreadthFirstWalk::test_walk_generation_single_root_node\nFAILED tests/data/test_breadth_first_walker.py::TestBreadthFirstWalk::test_walk_generation_many_root_nodes\nFAILED tests/data/test_breadth_first_walker.py::TestBreadthFirstWalk::test_walk_generation_number_of_walks_per_root_nodes\nFAILED tests/data/test_breadth_first_walker.py::TestBreadthFirstWalk::test_fixed_random_seed\nFAILED tests/data/test_breadth_first_walker.py::TestBreadthFirstWalk::test_weighted\nFAILED tests/data/test_breadth_first_walker.py::TestBreadthFirstWalk::test_weighted_all_zero\nFAILED tests/data/test_metapath_walker.py::TestMetaPathWalk::test_walk_generation_single_root_node_loner\nFAILED tests/data/test_metapath_walker.py::TestMetaPathWalk::test_walk_generation_single_root_node_self_loner\nFAILED tests/data/test_metapath_walker.py::TestMetaPathWalk::test_walk_generation_single_root_node\nFAILED tests/data/test_metapath_walker.py::TestMetaPathWalk::test_walk_generation_many_root_nodes\nFAILED tests/data/test_metapath_walker.py::TestMetaPathWalk::test_init_parameters\nFAILED tests/data/test_temporal_random_walker.py::test_temporal_walks - Attri...\nFAILED tests/data/test_temporal_random_walker.py::test_not_progressing_enough\nFAILED tests/data/test_temporal_random_walker.py::test_cw_size_and_walk_length[2]\nFAILED tests/data/test_temporal_random_walker.py::test_init_parameters - Attr...\nFAILED tests/data/test_uniform_random_walker.py::TestUniformRandomWalk::test_walk_generation_single_root_node\nFAILED tests/data/test_uniform_random_walker.py::TestUniformRandomWalk::test_walk_generation_many_root_nodes\nFAILED tests/data/test_uniform_random_walker.py::TestUniformRandomWalk::test_walk_generation_loner_root_node\nFAILED tests/data/test_uniform_random_walker.py::TestUniformRandomWalk::test_walk_generation_self_loner_root_node\nFAILED tests/data/test_uniform_random_walker.py::TestUniformRandomWalk::test_init_parameters\nFAILED tests/data/test_unsupervised_sampler.py::test_run_batch_sizes - Attrib...\nFAILED tests/data/test_unsupervised_sampler.py::test_run_context_pairs - Attr...\nFAILED tests/data/test_unsupervised_sampler.py::test_walker_uniform_random - ...\nFAILED tests/data/test_unsupervised_sampler.py::test_walker_custom - Attribut...\nFAILED tests/datasets/test_datasets.py::test_dataset_download[MUTAG] - urllib...\nFAILED tests/datasets/test_datasets.py::test_dataset_download[PROTEINS] - url...\nFAILED tests/datasets/test_datasets.py::test_mutag_load - urllib.error.HTTPEr...\nFAILED tests/datasets/test_datasets.py::test_proteins_load - urllib.error.HTT...\nFAILED tests/datasets/test_datasets.py::test_movielens_load - TypeError: OneH...\nFAILED tests/datasets/test_datasets.py::test_aifb_load - ModuleNotFoundError:...\nFAILED tests/interpretability/test_saliency_maps_gat.py::test_ig_saliency_map\nFAILED tests/interpretability/test_saliency_maps_gcn.py::test_ig_saliency_map\nFAILED tests/interpretability/test_saliency_maps_gcn.py::test_saliency_init_parameters\nFAILED tests/layer/test_appnp.py::test_APPNP_apply_dense - ValueError: When p...\nFAILED tests/layer/test_appnp.py::test_APPNP_apply_sparse - ValueError: When ...\nFAILED tests/layer/test_appnp.py::test_APPNP_linkmodel_apply_dense - ValueErr...\nFAILED tests/layer/test_appnp.py::test_APPNP_linkmodel_apply_sparse - ValueEr...\nFAILED tests/layer/test_appnp.py::test_APPNP_apply_propagate_model_dense - Va...\nFAILED tests/layer/test_appnp.py::test_APPNP_apply_propagate_model_sparse - V...\nFAILED tests/layer/test_appnp.py::test_APPNP_save_load[False] - ValueError: I...\nFAILED tests/layer/test_attri2vec.py::test_attri2vec_serialize - ValueError: ...\nFAILED tests/layer/test_attri2vec.py::test_attri2vec_save_load - ValueError: ...\nFAILED tests/layer/test_cluster_gcn.py::test_ClusterGCN_apply - ValueError: W...\nFAILED tests/layer/test_cluster_gcn.py::test_ClusterGCN_save_load - ValueErro...\nFAILED tests/layer/test_cluster_models.py::test_fullbatch_cluster_models[APPNP]\nFAILED tests/layer/test_cluster_models.py::test_fullbatch_cluster_models[GAT]\nFAILED tests/layer/test_cluster_models.py::test_fullbatch_cluster_models[GCN]\nFAILED tests/layer/test_deep_graph_infomax.py::test_dgi[False-GCN] - ValueErr...\nFAILED tests/layer/test_deep_graph_infomax.py::test_dgi[False-APPNP] - ValueE...\nFAILED tests/layer/test_deep_graph_infomax.py::test_dgi[False-GAT] - ValueErr...\nFAILED tests/layer/test_deep_graph_infomax.py::test_dgi[False-PPNP] - ValueEr...\nFAILED tests/layer/test_deep_graph_infomax.py::test_dgi[False-GraphSAGE] - At...\nFAILED tests/layer/test_deep_graph_infomax.py::test_dgi[False-DirectedGraphSAGE]\nFAILED tests/layer/test_deep_graph_infomax.py::test_dgi[False-HinSAGE] - Valu...\nFAILED tests/layer/test_deep_graph_infomax.py::test_dgi[False-RGCN] - ValueEr...\nFAILED tests/layer/test_deep_graph_infomax.py::test_dgi[True-GCN] - ValueErro...\nFAILED tests/layer/test_deep_graph_infomax.py::test_dgi[True-APPNP] - ValueEr...\nFAILED tests/layer/test_deep_graph_infomax.py::test_dgi[True-GAT] - ValueErro...\nFAILED tests/layer/test_deep_graph_infomax.py::test_dgi[True-RGCN] - ValueErr...\nFAILED tests/layer/test_deep_graph_infomax.py::test_dgi_stateful - ValueError...\nFAILED tests/layer/test_deep_graph_infomax.py::test_dgi_save_load[GCN] - Valu...\nFAILED tests/layer/test_deep_graph_infomax.py::test_dgi_save_load[GraphSAGE]\nFAILED tests/layer/test_gcn.py::test_GraphConvolution_sparse - Failed: DID NO...\nFAILED tests/layer/test_gcn.py::test_GCN_apply_dense - ValueError: When passi...\nFAILED tests/layer/test_gcn.py::test_GCN_apply_sparse - ValueError: When pass...\nFAILED tests/layer/test_gcn.py::test_GCN_linkmodel_apply_dense - ValueError: ...\nFAILED tests/layer/test_gcn.py::test_GCN_linkmodel_apply_sparse - ValueError:...\nFAILED tests/layer/test_gcn.py::test_gcn_save_load[False] - ValueError: Inval...\nFAILED tests/layer/test_gcn_lstm.py::test_gcn_lstm_model_input_output - Value...\nFAILED tests/layer/test_gcn_lstm.py::test_gcn_lstm_model - ValueError: A Kera...\nFAILED tests/layer/test_gcn_lstm.py::test_gcn_lstm_model_prediction - ValueEr...\nFAILED tests/layer/test_graph_attention.py::Test_GraphAttention::test_apply_average\nFAILED tests/layer/test_graph_attention.py::Test_GraphAttention::test_apply_average_with_neighbours\nFAILED tests/layer/test_graph_attention.py::Test_GAT::test_gat_build_l2norm\nFAILED tests/layer/test_graph_attention.py::Test_GAT::test_gat_build_no_norm\nFAILED tests/layer/test_graph_attention.py::Test_GAT::test_gat_serialize - Va...\nFAILED tests/layer/test_graph_attention.py::Test_GAT::test_save_load - ValueE...\nFAILED tests/layer/test_graph_classification.py::test_stateful - TypeError: `...\nFAILED tests/layer/test_graph_classification.py::test_pooling[default] - Valu...\nFAILED tests/layer/test_graph_classification.py::test_pooling[custom] - Value...\nFAILED tests/layer/test_graph_classification.py::test_pool_all_layers - Value...\nFAILED tests/layer/test_graph_classification.py::test_dgcnn_smoke - ValueErro...\nFAILED tests/layer/test_graph_classification.py::test_save_load - ValueError:...\nFAILED tests/layer/test_graphsage.py::test_graphsage_constructor - AttributeE...\nFAILED tests/layer/test_graphsage.py::test_graphsage_constructor_passing_aggregator\nFAILED tests/layer/test_graphsage.py::test_graphsage_constructor_1 - Attribut...\nFAILED tests/layer/test_graphsage.py::test_graphsage_apply - AttributeError: ...\nFAILED tests/layer/test_graphsage.py::test_graphsage_apply_1 - AttributeError...\nFAILED tests/layer/test_graphsage.py::test_graphsage_serialize - AttributeErr...\nFAILED tests/layer/test_graphsage.py::test_graphsage_zero_neighbours - Attrib...\nFAILED tests/layer/test_graphsage.py::test_graphsage_passing_activations - At...\nFAILED tests/layer/test_graphsage.py::test_graphsage_passing_regularisers - A...\nFAILED tests/layer/test_graphsage.py::test_kernel_and_bias_defaults - Attribu...\nFAILED tests/layer/test_graphsage.py::test_graphsage_save_load - AttributeErr...\nFAILED tests/layer/test_hinsage.py::test_mean_hin_agg_constructor_1 - Asserti...\nFAILED tests/layer/test_hinsage.py::test_hinsage_serialize - ValueError: The ...\nFAILED tests/layer/test_hinsage.py::test_hinsage_save_load - ValueError: Inva...\nFAILED tests/layer/test_knowledge_graph.py::test_complex[uniform] - ValueErro...\nFAILED tests/layer/test_knowledge_graph.py::test_complex[self-adversarial] - ...\nFAILED tests/layer/test_knowledge_graph.py::test_distmult - ValueError: Canno...\nFAILED tests/layer/test_knowledge_graph.py::test_rotate - ValueError: Cannot ...\nFAILED tests/layer/test_knowledge_graph.py::test_rote_roth[RotE] - ValueError...\nFAILED tests/layer/test_knowledge_graph.py::test_rote_roth[RotH] - ValueError...\nFAILED tests/layer/test_knowledge_graph.py::test_model_rankings[ComplEx] - Va...\nFAILED tests/layer/test_knowledge_graph.py::test_model_rankings[DistMult] - V...\nFAILED tests/layer/test_knowledge_graph.py::test_model_rankings[RotatE] - Val...\nFAILED tests/layer/test_knowledge_graph.py::test_model_rankings[RotH] - Value...\nFAILED tests/layer/test_knowledge_graph.py::test_model_rankings[RotE] - Value...\nFAILED tests/layer/test_knowledge_graph.py::test_save_load[ComplEx] - ValueEr...\nFAILED tests/layer/test_knowledge_graph.py::test_save_load[DistMult] - ValueE...\nFAILED tests/layer/test_knowledge_graph.py::test_save_load[RotatE] - ValueErr...\nFAILED tests/layer/test_knowledge_graph.py::test_save_load[RotH] - ValueError...\nFAILED tests/layer/test_knowledge_graph.py::test_save_load[RotE] - ValueError...\nFAILED tests/layer/test_misc.py::test_gather_indices - AttributeError: module...\nFAILED tests/layer/test_misc.py::test_deprecated_model_functions - ValueError...\nFAILED tests/layer/test_node2vec.py::test_node2vec_save_load - ValueError: In...\nFAILED tests/layer/test_ppnp.py::test_PPNP_apply_dense - ValueError: When pas...\nFAILED tests/layer/test_ppnp.py::test_PPNP_save_load - ValueError: Invalid fi...\nFAILED tests/layer/test_rgcn.py::test_RelationalGraphConvolution_sparse - Val...\nFAILED tests/layer/test_rgcn.py::test_RelationalGraphConvolution_dense - Valu...\nFAILED tests/layer/test_rgcn.py::test_RGCN_apply_sparse - ValueError: Excepti...\nFAILED tests/layer/test_rgcn.py::test_RGCN_apply_dense - ValueError: Exceptio...\nFAILED tests/layer/test_rgcn.py::test_RGCN_apply_sparse_directed - ValueError...\nFAILED tests/layer/test_rgcn.py::test_RGCN_apply_dense_directed - ValueError:...\nFAILED tests/layer/test_rgcn.py::test_RGCN_save_load[False-0] - ValueError: E...\nFAILED tests/layer/test_rgcn.py::test_RGCN_save_load[False-10] - ValueError: ...\nFAILED tests/layer/test_watch_your_step.py::test_AttentiveWalk - ValueError: ...\nFAILED tests/layer/test_watch_your_step.py::test_WatchYourStep[False] - TypeE...\nFAILED tests/layer/test_watch_your_step.py::test_WatchYourStep[True] - TypeEr...\nFAILED tests/layer/test_watch_your_step.py::test_WatchYourStep_embeddings - T...\nFAILED tests/layer/test_watch_your_step.py::test_WatchYourStep_save_load - Ty...\nFAILED tests/mapper/test_corrupted.py::test_corrupted_invalid_index - Attribu...\nFAILED tests/mapper/test_corrupted.py::test_corrupted_groups[default] - Attri...\nFAILED tests/mapper/test_corrupted.py::test_corrupted_groups[override] - Attr...\nFAILED tests/mapper/test_corrupted.py::test_corrupted_batching[1] - Attribute...\nFAILED tests/mapper/test_corrupted.py::test_corrupted_batching[2] - Attribute...\nFAILED tests/mapper/test_corrupted.py::test_corrupted_batching[3] - Attribute...\nFAILED tests/mapper/test_corrupted.py::test_corrupt_full_batch_generator[True-10]\nFAILED tests/mapper/test_corrupted.py::test_corrupt_full_batch_generator[True-20]\nFAILED tests/mapper/test_corrupted.py::test_corrupt_full_batch_generator[False-10]\nFAILED tests/mapper/test_corrupted.py::test_corrupt_full_batch_generator[False-20]\nFAILED tests/mapper/test_corrupted.py::test_corrupt_graphsage_generator[True]\nFAILED tests/mapper/test_corrupted.py::test_corrupt_graphsage_generator[False]\nFAILED tests/mapper/test_link_mappers.py::Test_GraphSAGELinkGenerator::test_GraphSAGELinkGenerator_1\nFAILED tests/mapper/test_link_mappers.py::Test_GraphSAGELinkGenerator::test_GraphSAGELinkGenerator_shuffle\nFAILED tests/mapper/test_link_mappers.py::Test_GraphSAGELinkGenerator::test_GraphSAGELinkGenerator_zero_samples\nFAILED tests/mapper/test_link_mappers.py::Test_GraphSAGELinkGenerator::test_GraphSAGELinkGenerator_no_targets\nFAILED tests/mapper/test_link_mappers.py::Test_GraphSAGELinkGenerator::test_GraphSAGELinkGenerator_isolates\nFAILED tests/mapper/test_link_mappers.py::Test_GraphSAGELinkGenerator::test_GraphSAGELinkGenerator_unsupervisedSampler_flow\nFAILED tests/mapper/test_link_mappers.py::Test_GraphSAGELinkGenerator::test_GraphSAGELinkGenerator_unsupervisedSampler_sample_generation\nFAILED tests/mapper/test_link_mappers.py::Test_GraphSAGELinkGenerator::test_weighted\nFAILED tests/mapper/test_link_mappers.py::Test_HinSAGELinkGenerator::test_HinSAGELinkGenerator_homogeneous_inference\nFAILED tests/mapper/test_link_mappers.py::Test_Attri2VecLinkGenerator::test_Attri2VecLinkGenerator_unsupervisedSampler_flow\nFAILED tests/mapper/test_link_mappers.py::Test_Attri2VecLinkGenerator::test_Attri2VecLinkGenerator_unsupervisedSampler_sample_generation\nFAILED tests/mapper/test_link_mappers.py::Test_Node2VecLinkGenerator::test_Node2VecLinkGenerator_unsupervisedSampler_flow\nFAILED tests/mapper/test_link_mappers.py::Test_Node2VecLinkGenerator::test_Node2VecLinkGenerator_unsupervisedSampler_sample_generation\nFAILED tests/mapper/test_link_mappers.py::Test_DirectedGraphSAGELinkGenerator::test_unsupervisedSampler_flow\nFAILED tests/mapper/test_link_mappers.py::Test_DirectedGraphSAGELinkGenerator::test_unsupervisedSampler_sample_generation\nFAILED tests/mapper/test_node_mappers.py::test_nodemapper_1 - AttributeError:...\nFAILED tests/mapper/test_node_mappers.py::test_nodemapper_shuffle[True] - Att...\nFAILED tests/mapper/test_node_mappers.py::test_nodemapper_shuffle[False] - At...\nFAILED tests/mapper/test_node_mappers.py::test_nodemapper_with_labels - Attri...\nFAILED tests/mapper/test_node_mappers.py::test_nodemapper_zero_samples - Attr...\nFAILED tests/mapper/test_node_mappers.py::test_nodemapper_isolated_nodes - At...\nFAILED tests/mapper/test_node_mappers.py::test_nodemapper_weighted - Attribut...\nFAILED tests/mapper/test_node_mappers.py::test_hinsage_homogeneous_inference\nFAILED tests/mapper/test_sliding.py::test_sliding_generator_flow_invalid - At...\nFAILED tests/mapper/test_sliding.py::test_feat_getter - AttributeError: modul...\nFAILED tests/mapper/test_sliding.py::test_sliding_sequence_no_targets[uni] - ...\nFAILED tests/mapper/test_sliding.py::test_sliding_sequence_no_targets[multi]\nFAILED tests/mapper/test_sliding.py::test_sliding_sequence_targets[uni] - Att...\nFAILED tests/mapper/test_sliding.py::test_sliding_sequence_targets[multi] - A...\nFAILED tests/mapper/test_sliding.py::test_sliding_sequence_subslice - Attribu...\nFAILED tests/reproducibility/test_deep_graph_infomax.py::test_dgi[False-GCN]\nFAILED tests/reproducibility/test_deep_graph_infomax.py::test_dgi[False-APPNP]\nFAILED tests/reproducibility/test_deep_graph_infomax.py::test_dgi[False-GAT]\nFAILED tests/reproducibility/test_deep_graph_infomax.py::test_dgi[False-PPNP]\nFAILED tests/reproducibility/test_deep_graph_infomax.py::test_dgi[True-GCN]\nFAILED tests/reproducibility/test_deep_graph_infomax.py::test_dgi[True-APPNP]\nFAILED tests/reproducibility/test_deep_graph_infomax.py::test_dgi[True-GAT]\nFAILED tests/reproducibility/test_graphsage.py::test_unsupervised[True] - Att...\nFAILED tests/reproducibility/test_graphsage.py::test_unsupervised[False] - At...\nFAILED tests/reproducibility/test_graphsage.py::test_nai[True] - AttributeErr...\nFAILED tests/reproducibility/test_graphsage.py::test_nai[False] - AttributeEr...\nFAILED tests/reproducibility/test_graphsage.py::test_link_prediction[True] - ...\nFAILED tests/reproducibility/test_graphsage.py::test_link_prediction[False]\nFAILED tests/test_calibration.py::test_isotonic_calibration_fit_predict - Typ...\nFAILED tests/test_ensemble.py::test_ensemble_init_parameters - AttributeError...\nFAILED tests/test_ensemble.py::test_compile - AttributeError: module 'numpy' ...\nFAILED tests/test_ensemble.py::test_Ensemble_fit - AttributeError: module 'nu...\nFAILED tests/test_ensemble.py::test_BaggingEnsemble_fit - AttributeError: mod...\nFAILED tests/test_ensemble.py::test_evaluate - AttributeError: module 'numpy'...\nFAILED tests/test_ensemble.py::test_predict - AttributeError: module 'numpy' ...\nFAILED tests/test_ensemble.py::test_evaluate_link_prediction - AttributeError...\nFAILED tests/test_ensemble.py::test_predict_link_prediction - AttributeError:...\nFAILED tests/test_ensemble.py::test_deprecated_methods - TypeError: Trainer.c...\nFAILED tests/utils/test_hyperbolic.py::test_poincare_ball_distance_self - Ass...\nERROR tests/core/test_element_data.py::test_benchmark_external_id_index_from_iloc\nERROR tests/core/test_graph.py::test_benchmark_graph_schema[1]\nERROR tests/core/test_graph.py::test_benchmark_graph_schema[4]\nERROR tests/core/test_graph.py::test_benchmark_get_neighbours[False]\nERROR tests/core/test_graph.py::test_benchmark_get_neighbours[True]\nERROR tests/core/test_graph.py::test_benchmark_get_features[10-infer-1-None]\nERROR tests/core/test_graph.py::test_benchmark_get_features[10-infer-1-False]\nERROR tests/core/test_graph.py::test_benchmark_get_features[10-infer-1-True]\nERROR tests/core/test_graph.py::test_benchmark_get_features[10-infer-4-None]\nERROR tests/core/test_graph.py::test_benchmark_get_features[10-infer-4-False]\nERROR tests/core/test_graph.py::test_benchmark_get_features[10-infer-4-True]\nERROR tests/core/test_graph.py::test_benchmark_get_features[10-specify-1-None]\nERROR tests/core/test_graph.py::test_benchmark_get_features[10-specify-1-False]\nERROR tests/core/test_graph.py::test_benchmark_get_features[10-specify-1-True]\nERROR tests/core/test_graph.py::test_benchmark_get_features[10-specify-4-None]\nERROR tests/core/test_graph.py::test_benchmark_get_features[10-specify-4-False]\nERROR tests/core/test_graph.py::test_benchmark_get_features[10-specify-4-True]\nERROR tests/core/test_graph.py::test_benchmark_get_features[1000-infer-1-None]\nERROR tests/core/test_graph.py::test_benchmark_get_features[1000-infer-1-False]\nERROR tests/core/test_graph.py::test_benchmark_get_features[1000-infer-1-True]\nERROR tests/core/test_graph.py::test_benchmark_get_features[1000-infer-4-None]\nERROR tests/core/test_graph.py::test_benchmark_get_features[1000-infer-4-False]\nERROR tests/core/test_graph.py::test_benchmark_get_features[1000-infer-4-True]\nERROR tests/core/test_graph.py::test_benchmark_get_features[1000-specify-1-None]\nERROR tests/core/test_graph.py::test_benchmark_get_features[1000-specify-1-False]\nERROR tests/core/test_graph.py::test_benchmark_get_features[1000-specify-1-True]\nERROR tests/core/test_graph.py::test_benchmark_get_features[1000-specify-4-None]\nERROR tests/core/test_graph.py::test_benchmark_get_features[1000-specify-4-False]\nERROR tests/core/test_graph.py::test_benchmark_get_features[1000-specify-4-True]\nERROR tests/core/test_graph.py::test_benchmark_creation[None-0-0-pandas]\nERROR tests/core/test_graph.py::test_benchmark_creation[None-0-0-rowframe]\nERROR tests/core/test_graph.py::test_benchmark_creation[None-1000-5000-pandas]\nERROR tests/core/test_graph.py::test_benchmark_creation[None-1000-5000-rowframe]\nERROR tests/core/test_graph.py::test_benchmark_creation[None-20000-100000-pandas]\nERROR tests/core/test_graph.py::test_benchmark_creation[None-20000-100000-rowframe]\nERROR tests/core/test_graph.py::test_benchmark_creation[100-0-0-pandas]\nERROR tests/core/test_graph.py::test_benchmark_creation[100-0-0-rowframe]\nERROR tests/core/test_graph.py::test_benchmark_creation[100-1000-5000-pandas]\nERROR tests/core/test_graph.py::test_benchmark_creation[100-1000-5000-rowframe]\nERROR tests/core/test_graph.py::test_benchmark_creation[100-20000-100000-pandas]\nERROR tests/core/test_graph.py::test_benchmark_creation[100-20000-100000-rowframe]\nERROR tests/core/test_graph.py::test_allocation_benchmark_creation[None-0-0-pandas]\nERROR tests/core/test_graph.py::test_allocation_benchmark_creation[None-0-0-rowframe]\nERROR tests/core/test_graph.py::test_allocation_benchmark_creation[None-100-200-pandas]\nERROR tests/core/test_graph.py::test_allocation_benchmark_creation[None-100-200-rowframe]\nERROR tests/core/test_graph.py::test_allocation_benchmark_creation[None-1000-5000-pandas]\nERROR tests/core/test_graph.py::test_allocation_benchmark_creation[None-1000-5000-rowframe]\nERROR tests/core/test_graph.py::test_allocation_benchmark_creation[100-0-0-pandas]\nERROR tests/core/test_graph.py::test_allocation_benchmark_creation[100-0-0-rowframe]\nERROR tests/core/test_graph.py::test_allocation_benchmark_creation[100-100-200-pandas]\nERROR tests/core/test_graph.py::test_allocation_benchmark_creation[100-100-200-rowframe]\nERROR tests/core/test_graph.py::test_allocation_benchmark_creation[100-1000-5000-pandas]\nERROR tests/core/test_graph.py::test_allocation_benchmark_creation[100-1000-5000-rowframe]\nERROR tests/core/test_graph.py::test_allocation_benchmark_creation_peak[None-0-0-pandas]\nERROR tests/core/test_graph.py::test_allocation_benchmark_creation_peak[None-0-0-rowframe]\nERROR tests/core/test_graph.py::test_allocation_benchmark_creation_peak[None-100-200-pandas]\nERROR tests/core/test_graph.py::test_allocation_benchmark_creation_peak[None-100-200-rowframe]\nERROR tests/core/test_graph.py::test_allocation_benchmark_creation_peak[None-1000-5000-pandas]\nERROR tests/core/test_graph.py::test_allocation_benchmark_creation_peak[None-1000-5000-rowframe]\nERROR tests/core/test_graph.py::test_allocation_benchmark_creation_peak[100-0-0-pandas]\nERROR tests/core/test_graph.py::test_allocation_benchmark_creation_peak[100-0-0-rowframe]\nERROR tests/core/test_graph.py::test_allocation_benchmark_creation_peak[100-100-200-pandas]\nERROR tests/core/test_graph.py::test_allocation_benchmark_creation_peak[100-100-200-rowframe]\nERROR tests/core/test_graph.py::test_allocation_benchmark_creation_peak[100-1000-5000-pandas]\nERROR tests/core/test_graph.py::test_allocation_benchmark_creation_peak[100-1000-5000-rowframe]\nERROR tests/core/test_graph.py::test_benchmark_adj_list[directed-100-200]\nERROR tests/core/test_graph.py::test_benchmark_adj_list[directed-1000-5000]\nERROR tests/core/test_graph.py::test_benchmark_adj_list[directed-20000-100000]\nERROR tests/core/test_graph.py::test_benchmark_adj_list[undirected-100-200]\nERROR tests/core/test_graph.py::test_benchmark_adj_list[undirected-1000-5000]\nERROR tests/core/test_graph.py::test_benchmark_adj_list[undirected-20000-100000]\nERROR tests/core/test_graph.py::test_allocation_benchmark_adj_list[directed-100-200]\nERROR tests/core/test_graph.py::test_allocation_benchmark_adj_list[directed-1000-5000]\nERROR tests/core/test_graph.py::test_allocation_benchmark_adj_list[undirected-100-200]\nERROR tests/core/test_graph.py::test_allocation_benchmark_adj_list[undirected-1000-5000]\nERROR tests/core/test_graph.py::test_allocation_benchmark_adj_list_peak[directed-100-200]\nERROR tests/core/test_graph.py::test_allocation_benchmark_adj_list_peak[directed-1000-5000]\nERROR tests/core/test_graph.py::test_allocation_benchmark_adj_list_peak[undirected-100-200]\nERROR tests/core/test_graph.py::test_allocation_benchmark_adj_list_peak[undirected-1000-5000]\nERROR tests/core/test_graph.py::test_benchmark_to_adjacency_matrix[False]\nERROR tests/core/test_graph.py::test_benchmark_to_adjacency_matrix[True]\nERROR tests/data/test_biased_random_walker.py::TestBiasedWeightedRandomWalk::test_benchmark_biasedweightedrandomwalk\nERROR tests/data/test_biased_random_walker.py::TestBiasedRandomWalk::test_benchmark_biasedrandomwalk\nERROR tests/data/test_breadth_first_walker.py::TestBreadthFirstWalk::test_benchmark_bfs_walk[False]\nERROR tests/data/test_breadth_first_walker.py::TestBreadthFirstWalk::test_benchmark_bfs_walk[True]\nERROR tests/data/test_directed_breadth_first_sampler.py::TestDirectedBreadthFirstNeighbours::test_benchmark_bfs_walk[False]\nERROR tests/data/test_directed_breadth_first_sampler.py::TestDirectedBreadthFirstNeighbours::test_benchmark_bfs_walk[True]\nERROR tests/data/test_heterogeneous_breadth_first_walker.py::TestSampledHeterogeneousBreadthFirstWalk::test_benchmark_sampledheterogeneousbreadthfirstwalk\nERROR tests/data/test_metapath_walker.py::TestMetaPathWalk::test_benchmark_uniformrandommetapathwalk\nERROR tests/data/test_uniform_random_walker.py::TestUniformRandomWalk::test_benchmark_uniformrandomwalk\nERROR tests/layer/test_gcn_lstm.py::test_gcn_lstm_generator[univariate] - Att...\nERROR tests/layer/test_gcn_lstm.py::test_gcn_lstm_generator[multivariate] - A...\nERROR tests/layer/test_gcn_lstm.py::test_gcn_lstm_save_load[univariate] - Att...\nERROR tests/layer/test_gcn_lstm.py::test_gcn_lstm_save_load[multivariate] - A...\nERROR tests/mapper/test_benchmark_generators.py::test_benchmark_setup_generator_small\nERROR tests/mapper/test_benchmark_generators.py::test_benchmark_setup_generator_large\nERROR tests/mapper/test_benchmark_generators.py::test_benchmark_link_generator_small\nERROR tests/mapper/test_benchmark_generators.py::test_benchmark_link_generator_large\nERROR tests/mapper/test_benchmark_generators.py::test_benchmark_node_generator_small\nERROR tests/mapper/test_benchmark_generators.py::test_benchmark_node_generator_large\nERROR tests/mapper/test_cluster_gcn_node_mapper.py::test_benchmark_ClusterGCN_generator[1]\nERROR tests/mapper/test_cluster_gcn_node_mapper.py::test_benchmark_ClusterGCN_generator[2]\nERROR tests/mapper/test_cluster_gcn_node_mapper.py::test_benchmark_ClusterGCN_generator[10]\n= 233 failed, 556 passed, 6 skipped, 4 xfailed, 2 xpassed, 136 warnings, 103 errors in 454.31s (0:07:34) =\n",
    "stderr": "",
    "execution_time": 455.6095538139343
  }
]