{"task_id": "statsmodels_111", "reponame": "statsmodels", "testpath": "statsmodels/robust/tests/test_covariance.py", "testname": "test_covariance.py", "funcname": "test_tyler", "imports": ["import os", "import numpy as np", "from scipy import linalg", "from numpy.testing import assert_allclose, assert_equal", "import pandas as pd", "from statsmodels import robust", "import statsmodels.robust.norms as robnorms", "import statsmodels.robust.covariance as robcov", "import statsmodels.robust.scale as robscale", "from .results import results_cov as res_cov"], "code": "def test_tyler():\n    res2 = np.array([[1.277856643343122, 0.298374848328023, 0.732491311584908, 0.232045093295329], [0.298374848328023, 1.743589223324287, 1.220675037619406, 0.212549156887607], [0.732491311584907, 1.220675037619407, 2.417486791841682, 0.295767635758891], [0.232045093295329, 0.212549156887607, 0.295767635758891, 0.409157014373402]])\n    center = np.array([1.5583333333333333, 1.8033333333333335, 1.66, (- 0.0866666666666667)])\n    k_vars = len(center)\n    res1 = robcov.cov_tyler((dta_hbk.to_numpy() - center), normalize='trace')\n    assert_allclose(np.trace(res1.cov), k_vars, rtol=1e-13)\n    cov_det = (res1.cov / (np.linalg.det(res1.cov) ** (1.0 / k_vars)))\n    assert_allclose(cov_det, res2, rtol=1e-11)\n    assert (res1.n_iter == 55)\n    res1 = robcov.cov_tyler((dta_hbk.to_numpy() - center), normalize='det')\n    assert_allclose(np.linalg.det(res1.cov), 1, rtol=1e-13)\n    assert_allclose(res1.cov, res2, rtol=1e-11)\n    assert (res1.n_iter == 55)\n    res1 = robcov.cov_tyler((dta_hbk.to_numpy() - center), normalize='normal')\n    cov_det = (res1.cov / (np.linalg.det(res1.cov) ** (1.0 / k_vars)))\n    assert_allclose(cov_det, res2, rtol=1e-11)\n    assert (res1.n_iter == 55)\n    res1 = robcov.cov_tyler((dta_hbk.to_numpy() - center))\n    cov_det = (res1.cov / (np.linalg.det(res1.cov) ** (1.0 / k_vars)))\n    assert_allclose(cov_det, res2, rtol=1e-11)\n    assert (res1.n_iter == 55)", "masked_code": "def test_tyler():\n    res2 = np.array([[1.277856643343122, 0.298374848328023, 0.732491311584908, 0.232045093295329], [0.298374848328023, 1.743589223324287, 1.220675037619406, 0.212549156887607], [0.732491311584907, 1.220675037619407, 2.417486791841682, 0.295767635758891], [0.232045093295329, 0.212549156887607, 0.295767635758891, 0.409157014373402]])\n    center = np.array([1.5583333333333333, 1.8033333333333335, 1.66, (- 0.0866666666666667)])\n    k_vars = len(center)\n    res1 = robcov.cov_tyler((dta_hbk.to_numpy() - center), normalize='trace')\n    assert_allclose(np.trace(res1.cov), k_vars, rtol=1e-13)\n    cov_det = (res1.cov / (np.linalg.det(res1.cov) ** (1.0 / k_vars)))\n    assert_allclose(cov_det, res2, rtol=1e-11)\n    assert (res1.n_iter == '???')\n    res1 = robcov.cov_tyler((dta_hbk.to_numpy() - center), normalize='det')\n    assert_allclose(np.linalg.det(res1.cov), 1, rtol=1e-13)\n    assert_allclose(res1.cov, res2, rtol=1e-11)\n    assert (res1.n_iter == 55)\n    res1 = robcov.cov_tyler((dta_hbk.to_numpy() - center), normalize='normal')\n    cov_det = (res1.cov / (np.linalg.det(res1.cov) ** (1.0 / k_vars)))\n    assert_allclose(cov_det, res2, rtol=1e-11)\n    assert (res1.n_iter == 55)\n    res1 = robcov.cov_tyler((dta_hbk.to_numpy() - center))\n    cov_det = (res1.cov / (np.linalg.det(res1.cov) ** (1.0 / k_vars)))\n    assert_allclose(cov_det, res2, rtol=1e-11)\n    assert (res1.n_iter == 55)", "ground_truth": "55", "quality_analysis": {"complexity_score": 3, "left_complexity": 2, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}, "classname": null}
{"task_id": "statsmodels_112", "reponame": "statsmodels", "testpath": "statsmodels/robust/tests/test_covariance.py", "testname": "test_covariance.py", "funcname": "test_tyler", "imports": ["import os", "import numpy as np", "from scipy import linalg", "from numpy.testing import assert_allclose, assert_equal", "import pandas as pd", "from statsmodels import robust", "import statsmodels.robust.norms as robnorms", "import statsmodels.robust.covariance as robcov", "import statsmodels.robust.scale as robscale", "from .results import results_cov as res_cov"], "code": "def test_tyler():\n    res2 = np.array([[1.277856643343122, 0.298374848328023, 0.732491311584908, 0.232045093295329], [0.298374848328023, 1.743589223324287, 1.220675037619406, 0.212549156887607], [0.732491311584907, 1.220675037619407, 2.417486791841682, 0.295767635758891], [0.232045093295329, 0.212549156887607, 0.295767635758891, 0.409157014373402]])\n    center = np.array([1.5583333333333333, 1.8033333333333335, 1.66, (- 0.0866666666666667)])\n    k_vars = len(center)\n    res1 = robcov.cov_tyler((dta_hbk.to_numpy() - center), normalize='trace')\n    assert_allclose(np.trace(res1.cov), k_vars, rtol=1e-13)\n    cov_det = (res1.cov / (np.linalg.det(res1.cov) ** (1.0 / k_vars)))\n    assert_allclose(cov_det, res2, rtol=1e-11)\n    assert (res1.n_iter == 55)\n    res1 = robcov.cov_tyler((dta_hbk.to_numpy() - center), normalize='det')\n    assert_allclose(np.linalg.det(res1.cov), 1, rtol=1e-13)\n    assert_allclose(res1.cov, res2, rtol=1e-11)\n    assert (res1.n_iter == 55)\n    res1 = robcov.cov_tyler((dta_hbk.to_numpy() - center), normalize='normal')\n    cov_det = (res1.cov / (np.linalg.det(res1.cov) ** (1.0 / k_vars)))\n    assert_allclose(cov_det, res2, rtol=1e-11)\n    assert (res1.n_iter == 55)\n    res1 = robcov.cov_tyler((dta_hbk.to_numpy() - center))\n    cov_det = (res1.cov / (np.linalg.det(res1.cov) ** (1.0 / k_vars)))\n    assert_allclose(cov_det, res2, rtol=1e-11)\n    assert (res1.n_iter == 55)", "masked_code": "def test_tyler():\n    res2 = np.array([[1.277856643343122, 0.298374848328023, 0.732491311584908, 0.232045093295329], [0.298374848328023, 1.743589223324287, 1.220675037619406, 0.212549156887607], [0.732491311584907, 1.220675037619407, 2.417486791841682, 0.295767635758891], [0.232045093295329, 0.212549156887607, 0.295767635758891, 0.409157014373402]])\n    center = np.array([1.5583333333333333, 1.8033333333333335, 1.66, (- 0.0866666666666667)])\n    k_vars = len(center)\n    res1 = robcov.cov_tyler((dta_hbk.to_numpy() - center), normalize='trace')\n    assert_allclose(np.trace(res1.cov), k_vars, rtol=1e-13)\n    cov_det = (res1.cov / (np.linalg.det(res1.cov) ** (1.0 / k_vars)))\n    assert_allclose(cov_det, res2, rtol=1e-11)\n    assert (res1.n_iter == 55)\n    res1 = robcov.cov_tyler((dta_hbk.to_numpy() - center), normalize='det')\n    assert_allclose(np.linalg.det(res1.cov), 1, rtol=1e-13)\n    assert_allclose(res1.cov, res2, rtol=1e-11)\n    assert (res1.n_iter == '???')\n    res1 = robcov.cov_tyler((dta_hbk.to_numpy() - center), normalize='normal')\n    cov_det = (res1.cov / (np.linalg.det(res1.cov) ** (1.0 / k_vars)))\n    assert_allclose(cov_det, res2, rtol=1e-11)\n    assert (res1.n_iter == 55)\n    res1 = robcov.cov_tyler((dta_hbk.to_numpy() - center))\n    cov_det = (res1.cov / (np.linalg.det(res1.cov) ** (1.0 / k_vars)))\n    assert_allclose(cov_det, res2, rtol=1e-11)\n    assert (res1.n_iter == 55)", "ground_truth": "55", "quality_analysis": {"complexity_score": 3, "left_complexity": 2, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}, "classname": null}
{"task_id": "statsmodels_113", "reponame": "statsmodels", "testpath": "statsmodels/robust/tests/test_covariance.py", "testname": "test_covariance.py", "funcname": "test_tyler", "imports": ["import os", "import numpy as np", "from scipy import linalg", "from numpy.testing import assert_allclose, assert_equal", "import pandas as pd", "from statsmodels import robust", "import statsmodels.robust.norms as robnorms", "import statsmodels.robust.covariance as robcov", "import statsmodels.robust.scale as robscale", "from .results import results_cov as res_cov"], "code": "def test_tyler():\n    res2 = np.array([[1.277856643343122, 0.298374848328023, 0.732491311584908, 0.232045093295329], [0.298374848328023, 1.743589223324287, 1.220675037619406, 0.212549156887607], [0.732491311584907, 1.220675037619407, 2.417486791841682, 0.295767635758891], [0.232045093295329, 0.212549156887607, 0.295767635758891, 0.409157014373402]])\n    center = np.array([1.5583333333333333, 1.8033333333333335, 1.66, (- 0.0866666666666667)])\n    k_vars = len(center)\n    res1 = robcov.cov_tyler((dta_hbk.to_numpy() - center), normalize='trace')\n    assert_allclose(np.trace(res1.cov), k_vars, rtol=1e-13)\n    cov_det = (res1.cov / (np.linalg.det(res1.cov) ** (1.0 / k_vars)))\n    assert_allclose(cov_det, res2, rtol=1e-11)\n    assert (res1.n_iter == 55)\n    res1 = robcov.cov_tyler((dta_hbk.to_numpy() - center), normalize='det')\n    assert_allclose(np.linalg.det(res1.cov), 1, rtol=1e-13)\n    assert_allclose(res1.cov, res2, rtol=1e-11)\n    assert (res1.n_iter == 55)\n    res1 = robcov.cov_tyler((dta_hbk.to_numpy() - center), normalize='normal')\n    cov_det = (res1.cov / (np.linalg.det(res1.cov) ** (1.0 / k_vars)))\n    assert_allclose(cov_det, res2, rtol=1e-11)\n    assert (res1.n_iter == 55)\n    res1 = robcov.cov_tyler((dta_hbk.to_numpy() - center))\n    cov_det = (res1.cov / (np.linalg.det(res1.cov) ** (1.0 / k_vars)))\n    assert_allclose(cov_det, res2, rtol=1e-11)\n    assert (res1.n_iter == 55)", "masked_code": "def test_tyler():\n    res2 = np.array([[1.277856643343122, 0.298374848328023, 0.732491311584908, 0.232045093295329], [0.298374848328023, 1.743589223324287, 1.220675037619406, 0.212549156887607], [0.732491311584907, 1.220675037619407, 2.417486791841682, 0.295767635758891], [0.232045093295329, 0.212549156887607, 0.295767635758891, 0.409157014373402]])\n    center = np.array([1.5583333333333333, 1.8033333333333335, 1.66, (- 0.0866666666666667)])\n    k_vars = len(center)\n    res1 = robcov.cov_tyler((dta_hbk.to_numpy() - center), normalize='trace')\n    assert_allclose(np.trace(res1.cov), k_vars, rtol=1e-13)\n    cov_det = (res1.cov / (np.linalg.det(res1.cov) ** (1.0 / k_vars)))\n    assert_allclose(cov_det, res2, rtol=1e-11)\n    assert (res1.n_iter == 55)\n    res1 = robcov.cov_tyler((dta_hbk.to_numpy() - center), normalize='det')\n    assert_allclose(np.linalg.det(res1.cov), 1, rtol=1e-13)\n    assert_allclose(res1.cov, res2, rtol=1e-11)\n    assert (res1.n_iter == 55)\n    res1 = robcov.cov_tyler((dta_hbk.to_numpy() - center), normalize='normal')\n    cov_det = (res1.cov / (np.linalg.det(res1.cov) ** (1.0 / k_vars)))\n    assert_allclose(cov_det, res2, rtol=1e-11)\n    assert (res1.n_iter == '???')\n    res1 = robcov.cov_tyler((dta_hbk.to_numpy() - center))\n    cov_det = (res1.cov / (np.linalg.det(res1.cov) ** (1.0 / k_vars)))\n    assert_allclose(cov_det, res2, rtol=1e-11)\n    assert (res1.n_iter == 55)", "ground_truth": "55", "quality_analysis": {"complexity_score": 3, "left_complexity": 2, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}, "classname": null}
{"task_id": "statsmodels_114", "reponame": "statsmodels", "testpath": "statsmodels/robust/tests/test_covariance.py", "testname": "test_covariance.py", "funcname": "test_tyler", "imports": ["import os", "import numpy as np", "from scipy import linalg", "from numpy.testing import assert_allclose, assert_equal", "import pandas as pd", "from statsmodels import robust", "import statsmodels.robust.norms as robnorms", "import statsmodels.robust.covariance as robcov", "import statsmodels.robust.scale as robscale", "from .results import results_cov as res_cov"], "code": "def test_tyler():\n    res2 = np.array([[1.277856643343122, 0.298374848328023, 0.732491311584908, 0.232045093295329], [0.298374848328023, 1.743589223324287, 1.220675037619406, 0.212549156887607], [0.732491311584907, 1.220675037619407, 2.417486791841682, 0.295767635758891], [0.232045093295329, 0.212549156887607, 0.295767635758891, 0.409157014373402]])\n    center = np.array([1.5583333333333333, 1.8033333333333335, 1.66, (- 0.0866666666666667)])\n    k_vars = len(center)\n    res1 = robcov.cov_tyler((dta_hbk.to_numpy() - center), normalize='trace')\n    assert_allclose(np.trace(res1.cov), k_vars, rtol=1e-13)\n    cov_det = (res1.cov / (np.linalg.det(res1.cov) ** (1.0 / k_vars)))\n    assert_allclose(cov_det, res2, rtol=1e-11)\n    assert (res1.n_iter == 55)\n    res1 = robcov.cov_tyler((dta_hbk.to_numpy() - center), normalize='det')\n    assert_allclose(np.linalg.det(res1.cov), 1, rtol=1e-13)\n    assert_allclose(res1.cov, res2, rtol=1e-11)\n    assert (res1.n_iter == 55)\n    res1 = robcov.cov_tyler((dta_hbk.to_numpy() - center), normalize='normal')\n    cov_det = (res1.cov / (np.linalg.det(res1.cov) ** (1.0 / k_vars)))\n    assert_allclose(cov_det, res2, rtol=1e-11)\n    assert (res1.n_iter == 55)\n    res1 = robcov.cov_tyler((dta_hbk.to_numpy() - center))\n    cov_det = (res1.cov / (np.linalg.det(res1.cov) ** (1.0 / k_vars)))\n    assert_allclose(cov_det, res2, rtol=1e-11)\n    assert (res1.n_iter == 55)", "masked_code": "def test_tyler():\n    res2 = np.array([[1.277856643343122, 0.298374848328023, 0.732491311584908, 0.232045093295329], [0.298374848328023, 1.743589223324287, 1.220675037619406, 0.212549156887607], [0.732491311584907, 1.220675037619407, 2.417486791841682, 0.295767635758891], [0.232045093295329, 0.212549156887607, 0.295767635758891, 0.409157014373402]])\n    center = np.array([1.5583333333333333, 1.8033333333333335, 1.66, (- 0.0866666666666667)])\n    k_vars = len(center)\n    res1 = robcov.cov_tyler((dta_hbk.to_numpy() - center), normalize='trace')\n    assert_allclose(np.trace(res1.cov), k_vars, rtol=1e-13)\n    cov_det = (res1.cov / (np.linalg.det(res1.cov) ** (1.0 / k_vars)))\n    assert_allclose(cov_det, res2, rtol=1e-11)\n    assert (res1.n_iter == 55)\n    res1 = robcov.cov_tyler((dta_hbk.to_numpy() - center), normalize='det')\n    assert_allclose(np.linalg.det(res1.cov), 1, rtol=1e-13)\n    assert_allclose(res1.cov, res2, rtol=1e-11)\n    assert (res1.n_iter == 55)\n    res1 = robcov.cov_tyler((dta_hbk.to_numpy() - center), normalize='normal')\n    cov_det = (res1.cov / (np.linalg.det(res1.cov) ** (1.0 / k_vars)))\n    assert_allclose(cov_det, res2, rtol=1e-11)\n    assert (res1.n_iter == 55)\n    res1 = robcov.cov_tyler((dta_hbk.to_numpy() - center))\n    cov_det = (res1.cov / (np.linalg.det(res1.cov) ** (1.0 / k_vars)))\n    assert_allclose(cov_det, res2, rtol=1e-11)\n    assert (res1.n_iter == '???')", "ground_truth": "55", "quality_analysis": {"complexity_score": 3, "left_complexity": 2, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}, "classname": null}
{"task_id": "statsmodels_206", "reponame": "statsmodels", "testpath": "statsmodels/tsa/statespace/tests/test_exponential_smoothing.py", "testname": "test_exponential_smoothing.py", "funcname": "test_parameterless_model", "imports": ["import numpy as np", "import pandas as pd", "import os", "import pytest", "from numpy.testing import assert_, assert_equal, assert_allclose", "from statsmodels.tsa.statespace.exponential_smoothing import ExponentialSmoothing"], "code": "def test_parameterless_model(reset_randomstate):\n    x = np.cumsum(np.random.standard_normal(1000))\n    ses = ExponentialSmoothing(x, initial_level=x[0], initialization_method='known')\n    with ses.fix_params({'smoothing_level': 0.5}):\n        res = ses.fit()\n    assert np.isnan(res.bse).all()\n    assert (res.fixed_params == ['smoothing_level'])", "masked_code": "def test_parameterless_model(reset_randomstate):\n    x = np.cumsum(np.random.standard_normal(1000))\n    ses = ExponentialSmoothing(x, initial_level=x[0], initialization_method='known')\n    with ses.fix_params({'smoothing_level': 0.5}):\n        res = ses.fit()\n    assert np.isnan(res.bse).all()\n    assert (res.fixed_params == '???')", "ground_truth": "['smoothing_level']", "quality_analysis": {"complexity_score": 5, "left_complexity": 2, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}, "classname": null}
{"task_id": "statsmodels_29", "reponame": "statsmodels", "testpath": "statsmodels/formula/tests/test_formula.py", "testname": "test_formula.py", "funcname": "test_endog_names", "imports": ["from statsmodels.compat.pandas import assert_series_equal", "import contextlib", "from io import StringIO", "import warnings", "import numpy as np", "import numpy.testing as npt", "import pandas as pd", "import pytest", "from statsmodels.datasets import cpunish", "from statsmodels.datasets.longley import load, load_pandas", "import statsmodels.formula", "from statsmodels.formula._manager import FormulaManager", "from statsmodels.formula.api import ols", "from statsmodels.formula.formulatools import make_hypotheses_matrices", "from statsmodels.tools import add_constant", "from statsmodels.tools.testing import assert_equal"], "code": "def test_endog_names(self):\n    assert (self.model.endog_names == 'TOTEMP')", "masked_code": "def test_endog_names(self):\n    assert (self.model.endog_names == '???')", "ground_truth": "'TOTEMP'", "quality_analysis": {"complexity_score": 3, "left_complexity": 2, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}, "classname": "CheckFormulaOLS"}
{"task_id": "statsmodels_30", "reponame": "statsmodels", "testpath": "statsmodels/formula/tests/test_formula.py", "testname": "test_formula.py", "funcname": "test_exog_names", "imports": ["from statsmodels.compat.pandas import assert_series_equal", "import contextlib", "from io import StringIO", "import warnings", "import numpy as np", "import numpy.testing as npt", "import pandas as pd", "import pytest", "from statsmodels.datasets import cpunish", "from statsmodels.datasets.longley import load, load_pandas", "import statsmodels.formula", "from statsmodels.formula._manager import FormulaManager", "from statsmodels.formula.api import ols", "from statsmodels.formula.formulatools import make_hypotheses_matrices", "from statsmodels.tools import add_constant", "from statsmodels.tools.testing import assert_equal"], "code": "def test_exog_names(self):\n    assert (self.model.exog_names == ['Intercept', 'GNPDEFL', 'GNP', 'UNEMP', 'ARMED', 'POP', 'YEAR'])", "masked_code": "def test_exog_names(self):\n    assert (self.model.exog_names == '???')", "ground_truth": "['Intercept', 'GNPDEFL', 'GNP', 'UNEMP', 'ARMED', 'POP', 'YEAR']", "quality_analysis": {"complexity_score": 11, "left_complexity": 2, "right_complexity": 9, "is_quality": true, "reason": "High quality assertion"}, "classname": "CheckFormulaOLS"}
{"task_id": "statsmodels_28", "reponame": "statsmodels", "testpath": "statsmodels/formula/tests/test_formula.py", "testname": "test_formula.py", "funcname": "test_formula_predict_series_exog", "imports": ["from statsmodels.compat.pandas import assert_series_equal", "import contextlib", "from io import StringIO", "import warnings", "import numpy as np", "import numpy.testing as npt", "import pandas as pd", "import pytest", "from statsmodels.datasets import cpunish", "from statsmodels.datasets.longley import load, load_pandas", "import statsmodels.formula", "from statsmodels.formula._manager import FormulaManager", "from statsmodels.formula.api import ols", "from statsmodels.formula.formulatools import make_hypotheses_matrices", "from statsmodels.tools import add_constant", "from statsmodels.tools.testing import assert_equal"], "code": "def test_formula_predict_series_exog():\n    x = np.random.standard_normal((1000, 2))\n    data_full = pd.DataFrame(x, columns=['y', 'x'])\n    data = data_full.iloc[:500]\n    res = ols(formula='y ~ x', data=data).fit()\n    oos = data_full.iloc[500:]['x']\n    prediction = res.get_prediction(oos)\n    assert (prediction.predicted_mean.shape[0] == 500)", "masked_code": "def test_formula_predict_series_exog():\n    x = np.random.standard_normal((1000, 2))\n    data_full = pd.DataFrame(x, columns=['y', 'x'])\n    data = data_full.iloc[:500]\n    res = ols(formula='y ~ x', data=data).fit()\n    oos = data_full.iloc[500:]['x']\n    prediction = res.get_prediction(oos)\n    assert (prediction.predicted_mean.shape[0] == '???')", "ground_truth": "500", "quality_analysis": {"complexity_score": 7, "left_complexity": 6, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}, "classname": null}
{"task_id": "statsmodels_79", "reponame": "statsmodels", "testpath": "statsmodels/miscmodels/tests/test_generic_mle.py", "testname": "test_generic_mle.py", "funcname": "test_df", "imports": ["import numpy as np", "from scipy import stats", "from statsmodels.base.model import GenericLikelihoodModel", "from numpy.testing import assert_array_less, assert_almost_equal, assert_allclose"], "code": "def test_df(self):\n    res = self.res1\n    k_extra = getattr(self, 'k_extra', 0)\n    if (res.model.exog is not None):\n        (nobs, k_vars) = res.model.exog.shape\n        k_constant = 1\n    else:\n        (nobs, k_vars) = (res.model.endog.shape[0], 0)\n        k_constant = 0\n    assert (res.df_resid == ((nobs - k_vars) - k_extra))\n    assert (res.df_model == (k_vars - k_constant))\n    assert (len(res.params) == (k_vars + k_extra))", "masked_code": "def test_df(self):\n    res = self.res1\n    k_extra = getattr(self, 'k_extra', 0)\n    if (res.model.exog is not None):\n        (nobs, k_vars) = res.model.exog.shape\n        k_constant = 1\n    else:\n        (nobs, k_vars) = (res.model.endog.shape[0], 0)\n        k_constant = 0\n    assert (res.df_resid == '???')\n    assert (res.df_model == (k_vars - k_constant))\n    assert (len(res.params) == (k_vars + k_extra))", "ground_truth": "((nobs - k_vars) - k_extra)", "quality_analysis": {"complexity_score": 9, "left_complexity": 2, "right_complexity": 7, "is_quality": true, "reason": "High quality assertion"}, "classname": "CheckGenericMixin"}
{"task_id": "statsmodels_80", "reponame": "statsmodels", "testpath": "statsmodels/miscmodels/tests/test_generic_mle.py", "testname": "test_generic_mle.py", "funcname": "test_df", "imports": ["import numpy as np", "from scipy import stats", "from statsmodels.base.model import GenericLikelihoodModel", "from numpy.testing import assert_array_less, assert_almost_equal, assert_allclose"], "code": "def test_df(self):\n    res = self.res1\n    k_extra = getattr(self, 'k_extra', 0)\n    if (res.model.exog is not None):\n        (nobs, k_vars) = res.model.exog.shape\n        k_constant = 1\n    else:\n        (nobs, k_vars) = (res.model.endog.shape[0], 0)\n        k_constant = 0\n    assert (res.df_resid == ((nobs - k_vars) - k_extra))\n    assert (res.df_model == (k_vars - k_constant))\n    assert (len(res.params) == (k_vars + k_extra))", "masked_code": "def test_df(self):\n    res = self.res1\n    k_extra = getattr(self, 'k_extra', 0)\n    if (res.model.exog is not None):\n        (nobs, k_vars) = res.model.exog.shape\n        k_constant = 1\n    else:\n        (nobs, k_vars) = (res.model.endog.shape[0], 0)\n        k_constant = 0\n    assert (res.df_resid == ((nobs - k_vars) - k_extra))\n    assert (res.df_model == '???')\n    assert (len(res.params) == (k_vars + k_extra))", "ground_truth": "(k_vars - k_constant)", "quality_analysis": {"complexity_score": 6, "left_complexity": 2, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}, "classname": "CheckGenericMixin"}
{"task_id": "statsmodels_82", "reponame": "statsmodels", "testpath": "statsmodels/miscmodels/tests/test_generic_mle.py", "testname": "test_generic_mle.py", "funcname": "test_fit", "imports": ["import numpy as np", "from scipy import stats", "from statsmodels.base.model import GenericLikelihoodModel", "from numpy.testing import assert_array_less, assert_almost_equal, assert_allclose"], "code": "def test_fit(self):\n    np.random.seed(42)\n    llh_noexog = TwoPeakLLHNoExog(self.X, signal=self.pdf_a, background=self.pdf_b)\n    res = llh_noexog.fit()\n    assert_allclose(res.params, self.params, rtol=0.1)\n    assert (res.df_resid == 248)\n    assert (res.df_model == 0)\n    res_bs = res.bootstrap(nrep=50)\n    assert_allclose(res_bs[2].mean(0), self.params, rtol=0.1)\n    res.summary()", "masked_code": "def test_fit(self):\n    np.random.seed(42)\n    llh_noexog = TwoPeakLLHNoExog(self.X, signal=self.pdf_a, background=self.pdf_b)\n    res = llh_noexog.fit()\n    assert_allclose(res.params, self.params, rtol=0.1)\n    assert (res.df_resid == '???')\n    assert (res.df_model == 0)\n    res_bs = res.bootstrap(nrep=50)\n    assert_allclose(res_bs[2].mean(0), self.params, rtol=0.1)\n    res.summary()", "ground_truth": "248", "quality_analysis": {"complexity_score": 3, "left_complexity": 2, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}, "classname": "TestTwoPeakLLHNoExog"}
{"task_id": "statsmodels_70", "reponame": "statsmodels", "testpath": "statsmodels/graphics/tests/test_gofplots.py", "testname": "test_gofplots.py", "funcname": "test_fit_params", "imports": ["from statsmodels.compat.python import PYTHON_IMPL_WASM", "import numpy as np", "import numpy.testing as nptest", "from numpy.testing import assert_equal", "import pytest", "from scipy import stats", "import statsmodels.api as sm", "from statsmodels.graphics import gofplots", "from statsmodels.graphics.gofplots import ProbPlot, qqline, qqplot, qqplot_2samples", "from statsmodels.graphics.utils import _import_mpl"], "code": "def test_fit_params(self):\n    assert (self.prbplt.fit_params[(- 2)] == self.prbplt.loc)\n    assert (self.prbplt.fit_params[(- 1)] == self.prbplt.scale)", "masked_code": "def test_fit_params(self):\n    assert (self.prbplt.fit_params[(- 2)] == '???')\n    assert (self.prbplt.fit_params[(- 1)] == self.prbplt.scale)", "ground_truth": "self.prbplt.loc", "quality_analysis": {"complexity_score": 10, "left_complexity": 8, "right_complexity": 2, "is_quality": true, "reason": "High quality assertion"}, "classname": "BaseProbplotMixin"}
{"task_id": "statsmodels_71", "reponame": "statsmodels", "testpath": "statsmodels/graphics/tests/test_gofplots.py", "testname": "test_gofplots.py", "funcname": "test_fit_params", "imports": ["from statsmodels.compat.python import PYTHON_IMPL_WASM", "import numpy as np", "import numpy.testing as nptest", "from numpy.testing import assert_equal", "import pytest", "from scipy import stats", "import statsmodels.api as sm", "from statsmodels.graphics import gofplots", "from statsmodels.graphics.gofplots import ProbPlot, qqline, qqplot, qqplot_2samples", "from statsmodels.graphics.utils import _import_mpl"], "code": "def test_fit_params(self):\n    assert (self.prbplt.fit_params[(- 2)] == self.prbplt.loc)\n    assert (self.prbplt.fit_params[(- 1)] == self.prbplt.scale)", "masked_code": "def test_fit_params(self):\n    assert (self.prbplt.fit_params[(- 2)] == self.prbplt.loc)\n    assert (self.prbplt.fit_params[(- 1)] == '???')", "ground_truth": "self.prbplt.scale", "quality_analysis": {"complexity_score": 10, "left_complexity": 8, "right_complexity": 2, "is_quality": true, "reason": "High quality assertion"}, "classname": "BaseProbplotMixin"}
{"task_id": "statsmodels_72", "reponame": "statsmodels", "testpath": "statsmodels/graphics/tests/test_gofplots.py", "testname": "test_gofplots.py", "funcname": "test_loc_set", "imports": ["from statsmodels.compat.python import PYTHON_IMPL_WASM", "import numpy as np", "import numpy.testing as nptest", "from numpy.testing import assert_equal", "import pytest", "from scipy import stats", "import statsmodels.api as sm", "from statsmodels.graphics import gofplots", "from statsmodels.graphics.gofplots import ProbPlot, qqline, qqplot, qqplot_2samples", "from statsmodels.graphics.utils import _import_mpl"], "code": "def test_loc_set(self):\n    assert (self.prbplt.loc == 8.5)", "masked_code": "def test_loc_set(self):\n    assert (self.prbplt.loc == '???')", "ground_truth": "8.5", "quality_analysis": {"complexity_score": 3, "left_complexity": 2, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}, "classname": "TestProbPlotRandomNormalLocScaleDist"}
{"task_id": "statsmodels_74", "reponame": "statsmodels", "testpath": "statsmodels/graphics/tests/test_gofplots.py", "testname": "test_gofplots.py", "funcname": "test_loc_set", "imports": ["from statsmodels.compat.python import PYTHON_IMPL_WASM", "import numpy as np", "import numpy.testing as nptest", "from numpy.testing import assert_equal", "import pytest", "from scipy import stats", "import statsmodels.api as sm", "from statsmodels.graphics import gofplots", "from statsmodels.graphics.gofplots import ProbPlot, qqline, qqplot, qqplot_2samples", "from statsmodels.graphics.utils import _import_mpl"], "code": "def test_loc_set(self):\n    assert (self.prbplt.loc == 8)", "masked_code": "def test_loc_set(self):\n    assert (self.prbplt.loc == '???')", "ground_truth": "8", "quality_analysis": {"complexity_score": 3, "left_complexity": 2, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}, "classname": "TestProbPlotRandomNormalLocScaleDist"}
{"task_id": "statsmodels_76", "reponame": "statsmodels", "testpath": "statsmodels/graphics/tests/test_gofplots.py", "testname": "test_gofplots.py", "funcname": "test_loc_set_in_dist", "imports": ["from statsmodels.compat.python import PYTHON_IMPL_WASM", "import numpy as np", "import numpy.testing as nptest", "from numpy.testing import assert_equal", "import pytest", "from scipy import stats", "import statsmodels.api as sm", "from statsmodels.graphics import gofplots", "from statsmodels.graphics.gofplots import ProbPlot, qqline, qqplot, qqplot_2samples", "from statsmodels.graphics.utils import _import_mpl"], "code": "def test_loc_set_in_dist(self):\n    assert (self.prbplt.dist.mean() == 8.0)", "masked_code": "def test_loc_set_in_dist(self):\n    assert (self.prbplt.dist.mean() == '???')", "ground_truth": "8.0", "quality_analysis": {"complexity_score": 4, "left_complexity": 3, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}, "classname": "TestProbPlotRandomNormalLocScaleDist"}
{"task_id": "statsmodels_69", "reponame": "statsmodels", "testpath": "statsmodels/graphics/tests/test_gofplots.py", "testname": "test_gofplots.py", "funcname": "test_qqplot_2samples_kwargs", "imports": ["from statsmodels.compat.python import PYTHON_IMPL_WASM", "import numpy as np", "import numpy.testing as nptest", "from numpy.testing import assert_equal", "import pytest", "from scipy import stats", "import statsmodels.api as sm", "from statsmodels.graphics import gofplots", "from statsmodels.graphics.gofplots import ProbPlot, qqline, qqplot, qqplot_2samples", "from statsmodels.graphics.utils import _import_mpl"], "code": "@pytest.mark.matplotlib\ndef test_qqplot_2samples_kwargs(close_figures):\n    data1 = np.random.normal(0, 1, 100)\n    data2 = np.random.normal(0, 1, 100)\n    fig_with_kwarg = qqplot_2samples(data1, data2, color='cyan')\n    ax = fig_with_kwarg.get_axes()[0]\n    scatter = ax.get_children()[0]\n    assert (scatter.get_color() == 'cyan')\n    fig_without_kwarg = qqplot_2samples(data1, data2)\n    ax_default = fig_without_kwarg.get_axes()[0]\n    scatter_default = ax_default.get_children()[0]\n    assert (scatter_default.get_color() != 'cyan')", "masked_code": "@pytest.mark.matplotlib\ndef test_qqplot_2samples_kwargs(close_figures):\n    data1 = np.random.normal(0, 1, 100)\n    data2 = np.random.normal(0, 1, 100)\n    fig_with_kwarg = qqplot_2samples(data1, data2, color='cyan')\n    ax = fig_with_kwarg.get_axes()[0]\n    scatter = ax.get_children()[0]\n    assert (scatter.get_color() == '???')\n    fig_without_kwarg = qqplot_2samples(data1, data2)\n    ax_default = fig_without_kwarg.get_axes()[0]\n    scatter_default = ax_default.get_children()[0]\n    assert (scatter_default.get_color() != 'cyan')", "ground_truth": "'cyan'", "quality_analysis": {"complexity_score": 4, "left_complexity": 3, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}, "classname": null}
{"task_id": "statsmodels_67", "reponame": "statsmodels", "testpath": "statsmodels/graphics/tests/test_gofplots.py", "testname": "test_gofplots.py", "funcname": "test_qqplot_2samples_labels", "imports": ["from statsmodels.compat.python import PYTHON_IMPL_WASM", "import numpy as np", "import numpy.testing as nptest", "from numpy.testing import assert_equal", "import pytest", "from scipy import stats", "import statsmodels.api as sm", "from statsmodels.graphics import gofplots", "from statsmodels.graphics.gofplots import ProbPlot, qqline, qqplot, qqplot_2samples", "from statsmodels.graphics.utils import _import_mpl"], "code": "@pytest.mark.matplotlib\ndef test_qqplot_2samples_labels():\n    try:\n        import matplotlib.pyplot as plt\n    except ImportError:\n        pass\n    data1 = np.random.normal(0, 1, 100)\n    data2 = np.random.normal(0, 1, 100)\n    fig = qqplot_2samples(data1, data2, xlabel='Sample 1', ylabel='Sample 2')\n    ax = fig.get_axes()[0]\n    assert (ax.get_xlabel() == 'Sample 1')\n    assert (ax.get_ylabel() == 'Sample 2')\n    plt.close(ax.figure)", "masked_code": "@pytest.mark.matplotlib\ndef test_qqplot_2samples_labels():\n    try:\n        import matplotlib.pyplot as plt\n    except ImportError:\n        pass\n    data1 = np.random.normal(0, 1, 100)\n    data2 = np.random.normal(0, 1, 100)\n    fig = qqplot_2samples(data1, data2, xlabel='Sample 1', ylabel='Sample 2')\n    ax = fig.get_axes()[0]\n    assert (ax.get_xlabel() == '???')\n    assert (ax.get_ylabel() == 'Sample 2')\n    plt.close(ax.figure)", "ground_truth": "'Sample 1'", "quality_analysis": {"complexity_score": 4, "left_complexity": 3, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}, "classname": null}
{"task_id": "statsmodels_68", "reponame": "statsmodels", "testpath": "statsmodels/graphics/tests/test_gofplots.py", "testname": "test_gofplots.py", "funcname": "test_qqplot_2samples_labels", "imports": ["from statsmodels.compat.python import PYTHON_IMPL_WASM", "import numpy as np", "import numpy.testing as nptest", "from numpy.testing import assert_equal", "import pytest", "from scipy import stats", "import statsmodels.api as sm", "from statsmodels.graphics import gofplots", "from statsmodels.graphics.gofplots import ProbPlot, qqline, qqplot, qqplot_2samples", "from statsmodels.graphics.utils import _import_mpl"], "code": "@pytest.mark.matplotlib\ndef test_qqplot_2samples_labels():\n    try:\n        import matplotlib.pyplot as plt\n    except ImportError:\n        pass\n    data1 = np.random.normal(0, 1, 100)\n    data2 = np.random.normal(0, 1, 100)\n    fig = qqplot_2samples(data1, data2, xlabel='Sample 1', ylabel='Sample 2')\n    ax = fig.get_axes()[0]\n    assert (ax.get_xlabel() == 'Sample 1')\n    assert (ax.get_ylabel() == 'Sample 2')\n    plt.close(ax.figure)", "masked_code": "@pytest.mark.matplotlib\ndef test_qqplot_2samples_labels():\n    try:\n        import matplotlib.pyplot as plt\n    except ImportError:\n        pass\n    data1 = np.random.normal(0, 1, 100)\n    data2 = np.random.normal(0, 1, 100)\n    fig = qqplot_2samples(data1, data2, xlabel='Sample 1', ylabel='Sample 2')\n    ax = fig.get_axes()[0]\n    assert (ax.get_xlabel() == 'Sample 1')\n    assert (ax.get_ylabel() == '???')\n    plt.close(ax.figure)", "ground_truth": "'Sample 2'", "quality_analysis": {"complexity_score": 4, "left_complexity": 3, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}, "classname": null}
{"task_id": "statsmodels_73", "reponame": "statsmodels", "testpath": "statsmodels/graphics/tests/test_gofplots.py", "testname": "test_gofplots.py", "funcname": "test_scale_set", "imports": ["from statsmodels.compat.python import PYTHON_IMPL_WASM", "import numpy as np", "import numpy.testing as nptest", "from numpy.testing import assert_equal", "import pytest", "from scipy import stats", "import statsmodels.api as sm", "from statsmodels.graphics import gofplots", "from statsmodels.graphics.gofplots import ProbPlot, qqline, qqplot, qqplot_2samples", "from statsmodels.graphics.utils import _import_mpl"], "code": "def test_scale_set(self):\n    assert (self.prbplt.scale == 3.0)", "masked_code": "def test_scale_set(self):\n    assert (self.prbplt.scale == '???')", "ground_truth": "3.0", "quality_analysis": {"complexity_score": 3, "left_complexity": 2, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}, "classname": "TestProbPlotRandomNormalLocScaleDist"}
{"task_id": "statsmodels_75", "reponame": "statsmodels", "testpath": "statsmodels/graphics/tests/test_gofplots.py", "testname": "test_gofplots.py", "funcname": "test_scale_set", "imports": ["from statsmodels.compat.python import PYTHON_IMPL_WASM", "import numpy as np", "import numpy.testing as nptest", "from numpy.testing import assert_equal", "import pytest", "from scipy import stats", "import statsmodels.api as sm", "from statsmodels.graphics import gofplots", "from statsmodels.graphics.gofplots import ProbPlot, qqline, qqplot, qqplot_2samples", "from statsmodels.graphics.utils import _import_mpl"], "code": "def test_scale_set(self):\n    assert (self.prbplt.scale == 3)", "masked_code": "def test_scale_set(self):\n    assert (self.prbplt.scale == '???')", "ground_truth": "3", "quality_analysis": {"complexity_score": 3, "left_complexity": 2, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}, "classname": "TestProbPlotRandomNormalLocScaleDist"}
{"task_id": "statsmodels_77", "reponame": "statsmodels", "testpath": "statsmodels/graphics/tests/test_gofplots.py", "testname": "test_gofplots.py", "funcname": "test_scale_set_in_dist", "imports": ["from statsmodels.compat.python import PYTHON_IMPL_WASM", "import numpy as np", "import numpy.testing as nptest", "from numpy.testing import assert_equal", "import pytest", "from scipy import stats", "import statsmodels.api as sm", "from statsmodels.graphics import gofplots", "from statsmodels.graphics.gofplots import ProbPlot, qqline, qqplot, qqplot_2samples", "from statsmodels.graphics.utils import _import_mpl"], "code": "def test_scale_set_in_dist(self):\n    assert (self.prbplt.dist.var() == 9.0)", "masked_code": "def test_scale_set_in_dist(self):\n    assert (self.prbplt.dist.var() == '???')", "ground_truth": "9.0", "quality_analysis": {"complexity_score": 4, "left_complexity": 3, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}, "classname": "TestProbPlotRandomNormalLocScaleDist"}
{"task_id": "statsmodels_198", "reponame": "statsmodels", "testpath": "statsmodels/tsa/holtwinters/tests/test_holtwinters.py", "testname": "test_holtwinters.py", "funcname": "test_fixed_basic", "imports": ["from statsmodels.compat.pandas import MONTH_END", "from statsmodels.compat.pytest import pytest_warns", "import os", "import re", "import warnings", "import numpy as np", "from numpy.testing import assert_allclose, assert_almost_equal", "import pandas as pd", "import pytest", "import scipy.stats", "from statsmodels.tools.sm_exceptions import ValueWarning", "from statsmodels.tsa.holtwinters import PY_SMOOTHERS, SMOOTHERS, ExponentialSmoothing, Holt, SimpleExpSmoothing", "from statsmodels.tsa.holtwinters._exponential_smoothers import HoltWintersArgs, _test_to_restricted", "from statsmodels.tsa.holtwinters._smoothers import HoltWintersArgs as PyHoltWintersArgs, to_restricted, to_unrestricted"], "code": "def test_fixed_basic(ses):\n    mod = ExponentialSmoothing(ses, initialization_method='estimated')\n    with mod.fix_params({'smoothing_level': 0.3}):\n        res = mod.fit()\n    assert (res.params['smoothing_level'] == 0.3)\n    assert isinstance(res.summary().as_text(), str)\n    mod = ExponentialSmoothing(ses, trend='add', damped_trend=True, initialization_method='estimated')\n    with mod.fix_params({'damping_trend': 0.98}):\n        res = mod.fit()\n    assert (res.params['damping_trend'] == 0.98)\n    assert isinstance(res.summary().as_text(), str)\n    mod = ExponentialSmoothing(ses, trend='add', seasonal='add', initialization_method='estimated')\n    with mod.fix_params({'smoothing_seasonal': 0.1, 'smoothing_level': 0.2}):\n        res = mod.fit()\n    assert (res.params['smoothing_seasonal'] == 0.1)\n    assert (res.params['smoothing_level'] == 0.2)\n    assert isinstance(res.summary().as_text(), str)", "masked_code": "def test_fixed_basic(ses):\n    mod = ExponentialSmoothing(ses, initialization_method='estimated')\n    with mod.fix_params({'smoothing_level': 0.3}):\n        res = mod.fit()\n    assert (res.params['smoothing_level'] == '???')\n    assert isinstance(res.summary().as_text(), str)\n    mod = ExponentialSmoothing(ses, trend='add', damped_trend=True, initialization_method='estimated')\n    with mod.fix_params({'damping_trend': 0.98}):\n        res = mod.fit()\n    assert (res.params['damping_trend'] == 0.98)\n    assert isinstance(res.summary().as_text(), str)\n    mod = ExponentialSmoothing(ses, trend='add', seasonal='add', initialization_method='estimated')\n    with mod.fix_params({'smoothing_seasonal': 0.1, 'smoothing_level': 0.2}):\n        res = mod.fit()\n    assert (res.params['smoothing_seasonal'] == 0.1)\n    assert (res.params['smoothing_level'] == 0.2)\n    assert isinstance(res.summary().as_text(), str)", "ground_truth": "0.3", "quality_analysis": {"complexity_score": 7, "left_complexity": 6, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}, "classname": null}
{"task_id": "statsmodels_199", "reponame": "statsmodels", "testpath": "statsmodels/tsa/holtwinters/tests/test_holtwinters.py", "testname": "test_holtwinters.py", "funcname": "test_fixed_basic", "imports": ["from statsmodels.compat.pandas import MONTH_END", "from statsmodels.compat.pytest import pytest_warns", "import os", "import re", "import warnings", "import numpy as np", "from numpy.testing import assert_allclose, assert_almost_equal", "import pandas as pd", "import pytest", "import scipy.stats", "from statsmodels.tools.sm_exceptions import ValueWarning", "from statsmodels.tsa.holtwinters import PY_SMOOTHERS, SMOOTHERS, ExponentialSmoothing, Holt, SimpleExpSmoothing", "from statsmodels.tsa.holtwinters._exponential_smoothers import HoltWintersArgs, _test_to_restricted", "from statsmodels.tsa.holtwinters._smoothers import HoltWintersArgs as PyHoltWintersArgs, to_restricted, to_unrestricted"], "code": "def test_fixed_basic(ses):\n    mod = ExponentialSmoothing(ses, initialization_method='estimated')\n    with mod.fix_params({'smoothing_level': 0.3}):\n        res = mod.fit()\n    assert (res.params['smoothing_level'] == 0.3)\n    assert isinstance(res.summary().as_text(), str)\n    mod = ExponentialSmoothing(ses, trend='add', damped_trend=True, initialization_method='estimated')\n    with mod.fix_params({'damping_trend': 0.98}):\n        res = mod.fit()\n    assert (res.params['damping_trend'] == 0.98)\n    assert isinstance(res.summary().as_text(), str)\n    mod = ExponentialSmoothing(ses, trend='add', seasonal='add', initialization_method='estimated')\n    with mod.fix_params({'smoothing_seasonal': 0.1, 'smoothing_level': 0.2}):\n        res = mod.fit()\n    assert (res.params['smoothing_seasonal'] == 0.1)\n    assert (res.params['smoothing_level'] == 0.2)\n    assert isinstance(res.summary().as_text(), str)", "masked_code": "def test_fixed_basic(ses):\n    mod = ExponentialSmoothing(ses, initialization_method='estimated')\n    with mod.fix_params({'smoothing_level': 0.3}):\n        res = mod.fit()\n    assert (res.params['smoothing_level'] == 0.3)\n    assert isinstance(res.summary().as_text(), str)\n    mod = ExponentialSmoothing(ses, trend='add', damped_trend=True, initialization_method='estimated')\n    with mod.fix_params({'damping_trend': 0.98}):\n        res = mod.fit()\n    assert (res.params['damping_trend'] == '???')\n    assert isinstance(res.summary().as_text(), str)\n    mod = ExponentialSmoothing(ses, trend='add', seasonal='add', initialization_method='estimated')\n    with mod.fix_params({'smoothing_seasonal': 0.1, 'smoothing_level': 0.2}):\n        res = mod.fit()\n    assert (res.params['smoothing_seasonal'] == 0.1)\n    assert (res.params['smoothing_level'] == 0.2)\n    assert isinstance(res.summary().as_text(), str)", "ground_truth": "0.98", "quality_analysis": {"complexity_score": 7, "left_complexity": 6, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}, "classname": null}
{"task_id": "statsmodels_200", "reponame": "statsmodels", "testpath": "statsmodels/tsa/holtwinters/tests/test_holtwinters.py", "testname": "test_holtwinters.py", "funcname": "test_fixed_basic", "imports": ["from statsmodels.compat.pandas import MONTH_END", "from statsmodels.compat.pytest import pytest_warns", "import os", "import re", "import warnings", "import numpy as np", "from numpy.testing import assert_allclose, assert_almost_equal", "import pandas as pd", "import pytest", "import scipy.stats", "from statsmodels.tools.sm_exceptions import ValueWarning", "from statsmodels.tsa.holtwinters import PY_SMOOTHERS, SMOOTHERS, ExponentialSmoothing, Holt, SimpleExpSmoothing", "from statsmodels.tsa.holtwinters._exponential_smoothers import HoltWintersArgs, _test_to_restricted", "from statsmodels.tsa.holtwinters._smoothers import HoltWintersArgs as PyHoltWintersArgs, to_restricted, to_unrestricted"], "code": "def test_fixed_basic(ses):\n    mod = ExponentialSmoothing(ses, initialization_method='estimated')\n    with mod.fix_params({'smoothing_level': 0.3}):\n        res = mod.fit()\n    assert (res.params['smoothing_level'] == 0.3)\n    assert isinstance(res.summary().as_text(), str)\n    mod = ExponentialSmoothing(ses, trend='add', damped_trend=True, initialization_method='estimated')\n    with mod.fix_params({'damping_trend': 0.98}):\n        res = mod.fit()\n    assert (res.params['damping_trend'] == 0.98)\n    assert isinstance(res.summary().as_text(), str)\n    mod = ExponentialSmoothing(ses, trend='add', seasonal='add', initialization_method='estimated')\n    with mod.fix_params({'smoothing_seasonal': 0.1, 'smoothing_level': 0.2}):\n        res = mod.fit()\n    assert (res.params['smoothing_seasonal'] == 0.1)\n    assert (res.params['smoothing_level'] == 0.2)\n    assert isinstance(res.summary().as_text(), str)", "masked_code": "def test_fixed_basic(ses):\n    mod = ExponentialSmoothing(ses, initialization_method='estimated')\n    with mod.fix_params({'smoothing_level': 0.3}):\n        res = mod.fit()\n    assert (res.params['smoothing_level'] == 0.3)\n    assert isinstance(res.summary().as_text(), str)\n    mod = ExponentialSmoothing(ses, trend='add', damped_trend=True, initialization_method='estimated')\n    with mod.fix_params({'damping_trend': 0.98}):\n        res = mod.fit()\n    assert (res.params['damping_trend'] == 0.98)\n    assert isinstance(res.summary().as_text(), str)\n    mod = ExponentialSmoothing(ses, trend='add', seasonal='add', initialization_method='estimated')\n    with mod.fix_params({'smoothing_seasonal': 0.1, 'smoothing_level': 0.2}):\n        res = mod.fit()\n    assert (res.params['smoothing_seasonal'] == '???')\n    assert (res.params['smoothing_level'] == 0.2)\n    assert isinstance(res.summary().as_text(), str)", "ground_truth": "0.1", "quality_analysis": {"complexity_score": 7, "left_complexity": 6, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}, "classname": null}
{"task_id": "statsmodels_201", "reponame": "statsmodels", "testpath": "statsmodels/tsa/holtwinters/tests/test_holtwinters.py", "testname": "test_holtwinters.py", "funcname": "test_fixed_basic", "imports": ["from statsmodels.compat.pandas import MONTH_END", "from statsmodels.compat.pytest import pytest_warns", "import os", "import re", "import warnings", "import numpy as np", "from numpy.testing import assert_allclose, assert_almost_equal", "import pandas as pd", "import pytest", "import scipy.stats", "from statsmodels.tools.sm_exceptions import ValueWarning", "from statsmodels.tsa.holtwinters import PY_SMOOTHERS, SMOOTHERS, ExponentialSmoothing, Holt, SimpleExpSmoothing", "from statsmodels.tsa.holtwinters._exponential_smoothers import HoltWintersArgs, _test_to_restricted", "from statsmodels.tsa.holtwinters._smoothers import HoltWintersArgs as PyHoltWintersArgs, to_restricted, to_unrestricted"], "code": "def test_fixed_basic(ses):\n    mod = ExponentialSmoothing(ses, initialization_method='estimated')\n    with mod.fix_params({'smoothing_level': 0.3}):\n        res = mod.fit()\n    assert (res.params['smoothing_level'] == 0.3)\n    assert isinstance(res.summary().as_text(), str)\n    mod = ExponentialSmoothing(ses, trend='add', damped_trend=True, initialization_method='estimated')\n    with mod.fix_params({'damping_trend': 0.98}):\n        res = mod.fit()\n    assert (res.params['damping_trend'] == 0.98)\n    assert isinstance(res.summary().as_text(), str)\n    mod = ExponentialSmoothing(ses, trend='add', seasonal='add', initialization_method='estimated')\n    with mod.fix_params({'smoothing_seasonal': 0.1, 'smoothing_level': 0.2}):\n        res = mod.fit()\n    assert (res.params['smoothing_seasonal'] == 0.1)\n    assert (res.params['smoothing_level'] == 0.2)\n    assert isinstance(res.summary().as_text(), str)", "masked_code": "def test_fixed_basic(ses):\n    mod = ExponentialSmoothing(ses, initialization_method='estimated')\n    with mod.fix_params({'smoothing_level': 0.3}):\n        res = mod.fit()\n    assert (res.params['smoothing_level'] == 0.3)\n    assert isinstance(res.summary().as_text(), str)\n    mod = ExponentialSmoothing(ses, trend='add', damped_trend=True, initialization_method='estimated')\n    with mod.fix_params({'damping_trend': 0.98}):\n        res = mod.fit()\n    assert (res.params['damping_trend'] == 0.98)\n    assert isinstance(res.summary().as_text(), str)\n    mod = ExponentialSmoothing(ses, trend='add', seasonal='add', initialization_method='estimated')\n    with mod.fix_params({'smoothing_seasonal': 0.1, 'smoothing_level': 0.2}):\n        res = mod.fit()\n    assert (res.params['smoothing_seasonal'] == 0.1)\n    assert (res.params['smoothing_level'] == '???')\n    assert isinstance(res.summary().as_text(), str)", "ground_truth": "0.2", "quality_analysis": {"complexity_score": 7, "left_complexity": 6, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}, "classname": null}
{"task_id": "statsmodels_203", "reponame": "statsmodels", "testpath": "statsmodels/tsa/holtwinters/tests/test_holtwinters.py", "testname": "test_holtwinters.py", "funcname": "test_forecast_1_simulation", "imports": ["from statsmodels.compat.pandas import MONTH_END", "from statsmodels.compat.pytest import pytest_warns", "import os", "import re", "import warnings", "import numpy as np", "from numpy.testing import assert_allclose, assert_almost_equal", "import pandas as pd", "import pytest", "import scipy.stats", "from statsmodels.tools.sm_exceptions import ValueWarning", "from statsmodels.tsa.holtwinters import PY_SMOOTHERS, SMOOTHERS, ExponentialSmoothing, Holt, SimpleExpSmoothing", "from statsmodels.tsa.holtwinters._exponential_smoothers import HoltWintersArgs, _test_to_restricted", "from statsmodels.tsa.holtwinters._smoothers import HoltWintersArgs as PyHoltWintersArgs, to_restricted, to_unrestricted"], "code": "@pytest.mark.parametrize('repetitions', [1, 10])\n@pytest.mark.parametrize('random_errors', [None, 'bootstrap'])\ndef test_forecast_1_simulation(austourists, random_errors, repetitions):\n    fit = ExponentialSmoothing(austourists, seasonal_periods=4, trend='add', seasonal='add', damped_trend=True, initialization_method='estimated').fit()\n    sim = fit.simulate(1, anchor=0, random_errors=random_errors, repetitions=repetitions)\n    expected_shape = ((1,) if (repetitions == 1) else (1, repetitions))\n    assert (sim.shape == expected_shape)\n    sim = fit.simulate(10, anchor=0, random_errors=random_errors, repetitions=repetitions)\n    expected_shape = ((10,) if (repetitions == 1) else (10, repetitions))\n    assert (sim.shape == expected_shape)", "masked_code": "@pytest.mark.parametrize('repetitions', [1, 10])\n@pytest.mark.parametrize('random_errors', [None, 'bootstrap'])\ndef test_forecast_1_simulation(austourists, random_errors, repetitions):\n    fit = ExponentialSmoothing(austourists, seasonal_periods=4, trend='add', seasonal='add', damped_trend=True, initialization_method='estimated').fit()\n    sim = fit.simulate(1, anchor=0, random_errors=random_errors, repetitions=repetitions)\n    expected_shape = ((1,) if (repetitions == 1) else (1, repetitions))\n    assert (sim.shape == '???')\n    sim = fit.simulate(10, anchor=0, random_errors=random_errors, repetitions=repetitions)\n    expected_shape = ((10,) if (repetitions == 1) else (10, repetitions))\n    assert (sim.shape == expected_shape)", "ground_truth": "expected_shape", "quality_analysis": {"complexity_score": 3, "left_complexity": 2, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}, "classname": null}
{"task_id": "statsmodels_204", "reponame": "statsmodels", "testpath": "statsmodels/tsa/holtwinters/tests/test_holtwinters.py", "testname": "test_holtwinters.py", "funcname": "test_forecast_1_simulation", "imports": ["from statsmodels.compat.pandas import MONTH_END", "from statsmodels.compat.pytest import pytest_warns", "import os", "import re", "import warnings", "import numpy as np", "from numpy.testing import assert_allclose, assert_almost_equal", "import pandas as pd", "import pytest", "import scipy.stats", "from statsmodels.tools.sm_exceptions import ValueWarning", "from statsmodels.tsa.holtwinters import PY_SMOOTHERS, SMOOTHERS, ExponentialSmoothing, Holt, SimpleExpSmoothing", "from statsmodels.tsa.holtwinters._exponential_smoothers import HoltWintersArgs, _test_to_restricted", "from statsmodels.tsa.holtwinters._smoothers import HoltWintersArgs as PyHoltWintersArgs, to_restricted, to_unrestricted"], "code": "@pytest.mark.parametrize('repetitions', [1, 10])\n@pytest.mark.parametrize('random_errors', [None, 'bootstrap'])\ndef test_forecast_1_simulation(austourists, random_errors, repetitions):\n    fit = ExponentialSmoothing(austourists, seasonal_periods=4, trend='add', seasonal='add', damped_trend=True, initialization_method='estimated').fit()\n    sim = fit.simulate(1, anchor=0, random_errors=random_errors, repetitions=repetitions)\n    expected_shape = ((1,) if (repetitions == 1) else (1, repetitions))\n    assert (sim.shape == expected_shape)\n    sim = fit.simulate(10, anchor=0, random_errors=random_errors, repetitions=repetitions)\n    expected_shape = ((10,) if (repetitions == 1) else (10, repetitions))\n    assert (sim.shape == expected_shape)", "masked_code": "@pytest.mark.parametrize('repetitions', [1, 10])\n@pytest.mark.parametrize('random_errors', [None, 'bootstrap'])\ndef test_forecast_1_simulation(austourists, random_errors, repetitions):\n    fit = ExponentialSmoothing(austourists, seasonal_periods=4, trend='add', seasonal='add', damped_trend=True, initialization_method='estimated').fit()\n    sim = fit.simulate(1, anchor=0, random_errors=random_errors, repetitions=repetitions)\n    expected_shape = ((1,) if (repetitions == 1) else (1, repetitions))\n    assert (sim.shape == expected_shape)\n    sim = fit.simulate(10, anchor=0, random_errors=random_errors, repetitions=repetitions)\n    expected_shape = ((10,) if (repetitions == 1) else (10, repetitions))\n    assert (sim.shape == '???')", "ground_truth": "expected_shape", "quality_analysis": {"complexity_score": 3, "left_complexity": 2, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}, "classname": null}
{"task_id": "statsmodels_196", "reponame": "statsmodels", "testpath": "statsmodels/tsa/holtwinters/tests/test_holtwinters.py", "testname": "test_holtwinters.py", "funcname": "test_forecast_index", "imports": ["from statsmodels.compat.pandas import MONTH_END", "from statsmodels.compat.pytest import pytest_warns", "import os", "import re", "import warnings", "import numpy as np", "from numpy.testing import assert_allclose, assert_almost_equal", "import pandas as pd", "import pytest", "import scipy.stats", "from statsmodels.tools.sm_exceptions import ValueWarning", "from statsmodels.tsa.holtwinters import PY_SMOOTHERS, SMOOTHERS, ExponentialSmoothing, Holt, SimpleExpSmoothing", "from statsmodels.tsa.holtwinters._exponential_smoothers import HoltWintersArgs, _test_to_restricted", "from statsmodels.tsa.holtwinters._smoothers import HoltWintersArgs as PyHoltWintersArgs, to_restricted, to_unrestricted"], "code": "@pytest.mark.parametrize('ix', [10, 100, 1000, 2000])\ndef test_forecast_index(ix):\n    ts_1 = pd.Series([85601, 89662, 85122, 84400, 78250, 84434, 71072, 70357, 72635, 73210], index=range(ix, (ix + 10)))\n    model = ExponentialSmoothing(ts_1, trend='add', damped_trend=False).fit()\n    index = model.forecast(steps=10).index\n    assert (index[0] == (ix + 10))\n    assert (index[(- 1)] == (ix + 19))", "masked_code": "@pytest.mark.parametrize('ix', [10, 100, 1000, 2000])\ndef test_forecast_index(ix):\n    ts_1 = pd.Series([85601, 89662, 85122, 84400, 78250, 84434, 71072, 70357, 72635, 73210], index=range(ix, (ix + 10)))\n    model = ExponentialSmoothing(ts_1, trend='add', damped_trend=False).fit()\n    index = model.forecast(steps=10).index\n    assert (index[0] == '???')\n    assert (index[(- 1)] == (ix + 19))", "ground_truth": "(ix + 10)", "quality_analysis": {"complexity_score": 9, "left_complexity": 5, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}, "classname": null}
{"task_id": "statsmodels_197", "reponame": "statsmodels", "testpath": "statsmodels/tsa/holtwinters/tests/test_holtwinters.py", "testname": "test_holtwinters.py", "funcname": "test_forecast_index", "imports": ["from statsmodels.compat.pandas import MONTH_END", "from statsmodels.compat.pytest import pytest_warns", "import os", "import re", "import warnings", "import numpy as np", "from numpy.testing import assert_allclose, assert_almost_equal", "import pandas as pd", "import pytest", "import scipy.stats", "from statsmodels.tools.sm_exceptions import ValueWarning", "from statsmodels.tsa.holtwinters import PY_SMOOTHERS, SMOOTHERS, ExponentialSmoothing, Holt, SimpleExpSmoothing", "from statsmodels.tsa.holtwinters._exponential_smoothers import HoltWintersArgs, _test_to_restricted", "from statsmodels.tsa.holtwinters._smoothers import HoltWintersArgs as PyHoltWintersArgs, to_restricted, to_unrestricted"], "code": "@pytest.mark.parametrize('ix', [10, 100, 1000, 2000])\ndef test_forecast_index(ix):\n    ts_1 = pd.Series([85601, 89662, 85122, 84400, 78250, 84434, 71072, 70357, 72635, 73210], index=range(ix, (ix + 10)))\n    model = ExponentialSmoothing(ts_1, trend='add', damped_trend=False).fit()\n    index = model.forecast(steps=10).index\n    assert (index[0] == (ix + 10))\n    assert (index[(- 1)] == (ix + 19))", "masked_code": "@pytest.mark.parametrize('ix', [10, 100, 1000, 2000])\ndef test_forecast_index(ix):\n    ts_1 = pd.Series([85601, 89662, 85122, 84400, 78250, 84434, 71072, 70357, 72635, 73210], index=range(ix, (ix + 10)))\n    model = ExponentialSmoothing(ts_1, trend='add', damped_trend=False).fit()\n    index = model.forecast(steps=10).index\n    assert (index[0] == (ix + 10))\n    assert (index[(- 1)] == '???')", "ground_truth": "(ix + 19)", "quality_analysis": {"complexity_score": 11, "left_complexity": 7, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}, "classname": null}
{"task_id": "statsmodels_205", "reponame": "statsmodels", "testpath": "statsmodels/tsa/holtwinters/tests/test_holtwinters.py", "testname": "test_holtwinters.py", "funcname": "test_invalid_index", "imports": ["from statsmodels.compat.pandas import MONTH_END", "from statsmodels.compat.pytest import pytest_warns", "import os", "import re", "import warnings", "import numpy as np", "from numpy.testing import assert_allclose, assert_almost_equal", "import pandas as pd", "import pytest", "import scipy.stats", "from statsmodels.tools.sm_exceptions import ValueWarning", "from statsmodels.tsa.holtwinters import PY_SMOOTHERS, SMOOTHERS, ExponentialSmoothing, Holt, SimpleExpSmoothing", "from statsmodels.tsa.holtwinters._exponential_smoothers import HoltWintersArgs, _test_to_restricted", "from statsmodels.tsa.holtwinters._smoothers import HoltWintersArgs as PyHoltWintersArgs, to_restricted, to_unrestricted"], "code": "def test_invalid_index(reset_randomstate):\n    y = np.random.standard_normal((12 * 200))\n    df_y = pd.DataFrame(data=y)\n    df_y.index.freq = 'd'\n    model = ExponentialSmoothing(df_y, seasonal_periods=12, trend='add', seasonal='add', initialization_method='heuristic')\n    fitted = model.fit(optimized=True, use_brute=True)\n    fcast = fitted.forecast(steps=157200)\n    assert (fcast.shape[0] == 157200)\n    index = pd.date_range('2020-01-01', periods=(2 * y.shape[0]))\n    index = np.random.choice(index, size=df_y.shape[0], replace=False)\n    index = sorted(index)\n    df_y.index = index\n    assert isinstance(df_y.index, pd.DatetimeIndex)\n    assert (df_y.index.freq is None)\n    assert (df_y.index.inferred_freq is None)\n    with pytest.warns(ValueWarning, match='A date index has been provided'):\n        model = ExponentialSmoothing(df_y, seasonal_periods=12, trend='add', seasonal='add', initialization_method='heuristic')\n    fitted = model.fit(optimized=True, use_brute=True)\n    with pytest.warns(FutureWarning, match='No supported'):\n        fitted.forecast(steps=157200)", "masked_code": "def test_invalid_index(reset_randomstate):\n    y = np.random.standard_normal((12 * 200))\n    df_y = pd.DataFrame(data=y)\n    df_y.index.freq = 'd'\n    model = ExponentialSmoothing(df_y, seasonal_periods=12, trend='add', seasonal='add', initialization_method='heuristic')\n    fitted = model.fit(optimized=True, use_brute=True)\n    fcast = fitted.forecast(steps=157200)\n    assert (fcast.shape[0] == '???')\n    index = pd.date_range('2020-01-01', periods=(2 * y.shape[0]))\n    index = np.random.choice(index, size=df_y.shape[0], replace=False)\n    index = sorted(index)\n    df_y.index = index\n    assert isinstance(df_y.index, pd.DatetimeIndex)\n    assert (df_y.index.freq is None)\n    assert (df_y.index.inferred_freq is None)\n    with pytest.warns(ValueWarning, match='A date index has been provided'):\n        model = ExponentialSmoothing(df_y, seasonal_periods=12, trend='add', seasonal='add', initialization_method='heuristic')\n    fitted = model.fit(optimized=True, use_brute=True)\n    with pytest.warns(FutureWarning, match='No supported'):\n        fitted.forecast(steps=157200)", "ground_truth": "157200", "quality_analysis": {"complexity_score": 7, "left_complexity": 6, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}, "classname": null}
{"task_id": "statsmodels_39", "reponame": "statsmodels", "testpath": "statsmodels/formula/tests/test_manager.py", "testname": "test_manager.py", "funcname": "test_default_value", "imports": ["import numpy as np", "import pandas as pd", "import pytest", "import statsmodels.formula", "from statsmodels.formula._manager import FormulaManager, LinearConstraintValues"], "code": "def test_default_value():\n    from statsmodels.formula._manager import _Default, _NoDefault\n    assert isinstance(_NoDefault, _Default)\n    _NoDefault.__str__()\n    assert (str(_NoDefault) == '<no default value>')\n    assert (repr(_NoDefault) == '<no default value>')", "masked_code": "def test_default_value():\n    from statsmodels.formula._manager import _Default, _NoDefault\n    assert isinstance(_NoDefault, _Default)\n    _NoDefault.__str__()\n    assert (str(_NoDefault) == '???')\n    assert (repr(_NoDefault) == '<no default value>')", "ground_truth": "'<no default value>'", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}, "classname": null}
{"task_id": "statsmodels_40", "reponame": "statsmodels", "testpath": "statsmodels/formula/tests/test_manager.py", "testname": "test_manager.py", "funcname": "test_default_value", "imports": ["import numpy as np", "import pandas as pd", "import pytest", "import statsmodels.formula", "from statsmodels.formula._manager import FormulaManager, LinearConstraintValues"], "code": "def test_default_value():\n    from statsmodels.formula._manager import _Default, _NoDefault\n    assert isinstance(_NoDefault, _Default)\n    _NoDefault.__str__()\n    assert (str(_NoDefault) == '<no default value>')\n    assert (repr(_NoDefault) == '<no default value>')", "masked_code": "def test_default_value():\n    from statsmodels.formula._manager import _Default, _NoDefault\n    assert isinstance(_NoDefault, _Default)\n    _NoDefault.__str__()\n    assert (str(_NoDefault) == '<no default value>')\n    assert (repr(_NoDefault) == '???')", "ground_truth": "'<no default value>'", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}, "classname": null}
{"task_id": "statsmodels_38", "reponame": "statsmodels", "testpath": "statsmodels/formula/tests/test_manager.py", "testname": "test_manager.py", "funcname": "test_engine", "imports": ["import numpy as np", "import pandas as pd", "import pytest", "import statsmodels.formula", "from statsmodels.formula._manager import FormulaManager, LinearConstraintValues"], "code": "def test_engine(engine):\n    mgr = FormulaManager(engine=engine)\n    assert (mgr.engine == engine)\n    with pytest.raises(ValueError):\n        FormulaManager(engine='other')", "masked_code": "def test_engine(engine):\n    mgr = FormulaManager(engine=engine)\n    assert (mgr.engine == '???')\n    with pytest.raises(ValueError):\n        FormulaManager(engine='other')", "ground_truth": "engine", "quality_analysis": {"complexity_score": 3, "left_complexity": 2, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}, "classname": null}
{"task_id": "statsmodels_31", "reponame": "statsmodels", "testpath": "statsmodels/formula/tests/test_manager.py", "testname": "test_manager.py", "funcname": "test_engine_options_engine", "imports": ["import numpy as np", "import pandas as pd", "import pytest", "import statsmodels.formula", "from statsmodels.formula._manager import FormulaManager, LinearConstraintValues"], "code": "def test_engine_options_engine(engine):\n    default = statsmodels.formula.options.formula_engine\n    assert (default in ('patsy', 'formulaic'))\n    statsmodels.formula.options.formula_engine = engine\n    mgr = FormulaManager()\n    assert (mgr.engine == engine)\n    if HAS_FORMULAIC:\n        statsmodels.formula.options.formula_engine = 'formulaic'\n        mgr = FormulaManager()\n        assert (mgr.engine == 'formulaic')\n        if HAS_PATSY:\n            mgr = FormulaManager(engine='patsy')\n            assert (mgr.engine == 'patsy')\n    statsmodels.formula.options.formula_engine = default", "masked_code": "def test_engine_options_engine(engine):\n    default = statsmodels.formula.options.formula_engine\n    assert (default in ('patsy', 'formulaic'))\n    statsmodels.formula.options.formula_engine = engine\n    mgr = FormulaManager()\n    assert (mgr.engine == '???')\n    if HAS_FORMULAIC:\n        statsmodels.formula.options.formula_engine = 'formulaic'\n        mgr = FormulaManager()\n        assert (mgr.engine == 'formulaic')\n        if HAS_PATSY:\n            mgr = FormulaManager(engine='patsy')\n            assert (mgr.engine == 'patsy')\n    statsmodels.formula.options.formula_engine = default", "ground_truth": "engine", "quality_analysis": {"complexity_score": 3, "left_complexity": 2, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}, "classname": null}
{"task_id": "statsmodels_32", "reponame": "statsmodels", "testpath": "statsmodels/formula/tests/test_manager.py", "testname": "test_manager.py", "funcname": "test_engine_options_engine", "imports": ["import numpy as np", "import pandas as pd", "import pytest", "import statsmodels.formula", "from statsmodels.formula._manager import FormulaManager, LinearConstraintValues"], "code": "def test_engine_options_engine(engine):\n    default = statsmodels.formula.options.formula_engine\n    assert (default in ('patsy', 'formulaic'))\n    statsmodels.formula.options.formula_engine = engine\n    mgr = FormulaManager()\n    assert (mgr.engine == engine)\n    if HAS_FORMULAIC:\n        statsmodels.formula.options.formula_engine = 'formulaic'\n        mgr = FormulaManager()\n        assert (mgr.engine == 'formulaic')\n        if HAS_PATSY:\n            mgr = FormulaManager(engine='patsy')\n            assert (mgr.engine == 'patsy')\n    statsmodels.formula.options.formula_engine = default", "masked_code": "def test_engine_options_engine(engine):\n    default = statsmodels.formula.options.formula_engine\n    assert (default in ('patsy', 'formulaic'))\n    statsmodels.formula.options.formula_engine = engine\n    mgr = FormulaManager()\n    assert (mgr.engine == engine)\n    if HAS_FORMULAIC:\n        statsmodels.formula.options.formula_engine = 'formulaic'\n        mgr = FormulaManager()\n        assert (mgr.engine == '???')\n        if HAS_PATSY:\n            mgr = FormulaManager(engine='patsy')\n            assert (mgr.engine == 'patsy')\n    statsmodels.formula.options.formula_engine = default", "ground_truth": "'formulaic'", "quality_analysis": {"complexity_score": 3, "left_complexity": 2, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}, "classname": null}
{"task_id": "statsmodels_33", "reponame": "statsmodels", "testpath": "statsmodels/formula/tests/test_manager.py", "testname": "test_manager.py", "funcname": "test_engine_options_engine", "imports": ["import numpy as np", "import pandas as pd", "import pytest", "import statsmodels.formula", "from statsmodels.formula._manager import FormulaManager, LinearConstraintValues"], "code": "def test_engine_options_engine(engine):\n    default = statsmodels.formula.options.formula_engine\n    assert (default in ('patsy', 'formulaic'))\n    statsmodels.formula.options.formula_engine = engine\n    mgr = FormulaManager()\n    assert (mgr.engine == engine)\n    if HAS_FORMULAIC:\n        statsmodels.formula.options.formula_engine = 'formulaic'\n        mgr = FormulaManager()\n        assert (mgr.engine == 'formulaic')\n        if HAS_PATSY:\n            mgr = FormulaManager(engine='patsy')\n            assert (mgr.engine == 'patsy')\n    statsmodels.formula.options.formula_engine = default", "masked_code": "def test_engine_options_engine(engine):\n    default = statsmodels.formula.options.formula_engine\n    assert (default in ('patsy', 'formulaic'))\n    statsmodels.formula.options.formula_engine = engine\n    mgr = FormulaManager()\n    assert (mgr.engine == engine)\n    if HAS_FORMULAIC:\n        statsmodels.formula.options.formula_engine = 'formulaic'\n        mgr = FormulaManager()\n        assert (mgr.engine == 'formulaic')\n        if HAS_PATSY:\n            mgr = FormulaManager(engine='patsy')\n            assert (mgr.engine == '???')\n    statsmodels.formula.options.formula_engine = default", "ground_truth": "'patsy'", "quality_analysis": {"complexity_score": 3, "left_complexity": 2, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}, "classname": null}
{"task_id": "statsmodels_34", "reponame": "statsmodels", "testpath": "statsmodels/formula/tests/test_manager.py", "testname": "test_manager.py", "funcname": "test_engine_options_order", "imports": ["import numpy as np", "import pandas as pd", "import pytest", "import statsmodels.formula", "from statsmodels.formula._manager import FormulaManager, LinearConstraintValues"], "code": "@pytest.mark.parametrize('ordering', ['degree', 'sort', 'none', 'legacy'])\ndef test_engine_options_order(ordering):\n    default = statsmodels.formula.options.ordering\n    assert (default in ('degree', 'sort', 'none', 'legacy'))\n    statsmodels.formula.options.ordering = ordering\n    assert (statsmodels.formula.options.ordering == ordering)\n    statsmodels.formula.options.ordering = default\n    with pytest.raises(ValueError):\n        statsmodels.formula.options.ordering = 'unknown'", "masked_code": "@pytest.mark.parametrize('ordering', ['degree', 'sort', 'none', 'legacy'])\ndef test_engine_options_order(ordering):\n    default = statsmodels.formula.options.ordering\n    assert (default in ('degree', 'sort', 'none', 'legacy'))\n    statsmodels.formula.options.ordering = ordering\n    assert (statsmodels.formula.options.ordering == '???')\n    statsmodels.formula.options.ordering = default\n    with pytest.raises(ValueError):\n        statsmodels.formula.options.ordering = 'unknown'", "ground_truth": "ordering", "quality_analysis": {"complexity_score": 3, "left_complexity": 2, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}, "classname": null}
{"task_id": "statsmodels_35", "reponame": "statsmodels", "testpath": "statsmodels/formula/tests/test_manager.py", "testname": "test_manager.py", "funcname": "test_engine_options_order_effect", "imports": ["import numpy as np", "import pandas as pd", "import pytest", "import statsmodels.formula", "from statsmodels.formula._manager import FormulaManager, LinearConstraintValues"], "code": "@require_formulaic\ndef test_engine_options_order_effect(data):\n    default = statsmodels.formula.options.ordering\n    statsmodels.formula.options.ordering = 'degree'\n    mgr = FormulaManager(engine='formulaic')\n    (_, rhs0) = mgr.get_matrices('y ~ 1 + x + z + c', data)\n    statsmodels.formula.options.ordering = 'sort'\n    (_, rhs1) = mgr.get_matrices('y ~ 1 + x + z + c', data)\n    statsmodels.formula.options.ordering = 'none'\n    (_, rhs2) = mgr.get_matrices('y ~ 1 + x + c + z', data)\n    assert (len(rhs0.columns) == 4)\n    assert (len(rhs1.columns) == 4)\n    assert (len(rhs2.columns) == 4)\n    assert (list(rhs0.columns) != list(rhs1.columns))\n    assert (list(rhs0.columns) != list(rhs2.columns))\n    assert (list(rhs1.columns) != list(rhs2.columns))\n    statsmodels.formula.options.ordering = default", "masked_code": "@require_formulaic\ndef test_engine_options_order_effect(data):\n    default = statsmodels.formula.options.ordering\n    statsmodels.formula.options.ordering = 'degree'\n    mgr = FormulaManager(engine='formulaic')\n    (_, rhs0) = mgr.get_matrices('y ~ 1 + x + z + c', data)\n    statsmodels.formula.options.ordering = 'sort'\n    (_, rhs1) = mgr.get_matrices('y ~ 1 + x + z + c', data)\n    statsmodels.formula.options.ordering = 'none'\n    (_, rhs2) = mgr.get_matrices('y ~ 1 + x + c + z', data)\n    assert (len(rhs0.columns) == '???')\n    assert (len(rhs1.columns) == 4)\n    assert (len(rhs2.columns) == 4)\n    assert (list(rhs0.columns) != list(rhs1.columns))\n    assert (list(rhs0.columns) != list(rhs2.columns))\n    assert (list(rhs1.columns) != list(rhs2.columns))\n    statsmodels.formula.options.ordering = default", "ground_truth": "4", "quality_analysis": {"complexity_score": 6, "left_complexity": 5, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}, "classname": null}
{"task_id": "statsmodels_36", "reponame": "statsmodels", "testpath": "statsmodels/formula/tests/test_manager.py", "testname": "test_manager.py", "funcname": "test_engine_options_order_effect", "imports": ["import numpy as np", "import pandas as pd", "import pytest", "import statsmodels.formula", "from statsmodels.formula._manager import FormulaManager, LinearConstraintValues"], "code": "@require_formulaic\ndef test_engine_options_order_effect(data):\n    default = statsmodels.formula.options.ordering\n    statsmodels.formula.options.ordering = 'degree'\n    mgr = FormulaManager(engine='formulaic')\n    (_, rhs0) = mgr.get_matrices('y ~ 1 + x + z + c', data)\n    statsmodels.formula.options.ordering = 'sort'\n    (_, rhs1) = mgr.get_matrices('y ~ 1 + x + z + c', data)\n    statsmodels.formula.options.ordering = 'none'\n    (_, rhs2) = mgr.get_matrices('y ~ 1 + x + c + z', data)\n    assert (len(rhs0.columns) == 4)\n    assert (len(rhs1.columns) == 4)\n    assert (len(rhs2.columns) == 4)\n    assert (list(rhs0.columns) != list(rhs1.columns))\n    assert (list(rhs0.columns) != list(rhs2.columns))\n    assert (list(rhs1.columns) != list(rhs2.columns))\n    statsmodels.formula.options.ordering = default", "masked_code": "@require_formulaic\ndef test_engine_options_order_effect(data):\n    default = statsmodels.formula.options.ordering\n    statsmodels.formula.options.ordering = 'degree'\n    mgr = FormulaManager(engine='formulaic')\n    (_, rhs0) = mgr.get_matrices('y ~ 1 + x + z + c', data)\n    statsmodels.formula.options.ordering = 'sort'\n    (_, rhs1) = mgr.get_matrices('y ~ 1 + x + z + c', data)\n    statsmodels.formula.options.ordering = 'none'\n    (_, rhs2) = mgr.get_matrices('y ~ 1 + x + c + z', data)\n    assert (len(rhs0.columns) == 4)\n    assert (len(rhs1.columns) == '???')\n    assert (len(rhs2.columns) == 4)\n    assert (list(rhs0.columns) != list(rhs1.columns))\n    assert (list(rhs0.columns) != list(rhs2.columns))\n    assert (list(rhs1.columns) != list(rhs2.columns))\n    statsmodels.formula.options.ordering = default", "ground_truth": "4", "quality_analysis": {"complexity_score": 6, "left_complexity": 5, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}, "classname": null}
{"task_id": "statsmodels_37", "reponame": "statsmodels", "testpath": "statsmodels/formula/tests/test_manager.py", "testname": "test_manager.py", "funcname": "test_engine_options_order_effect", "imports": ["import numpy as np", "import pandas as pd", "import pytest", "import statsmodels.formula", "from statsmodels.formula._manager import FormulaManager, LinearConstraintValues"], "code": "@require_formulaic\ndef test_engine_options_order_effect(data):\n    default = statsmodels.formula.options.ordering\n    statsmodels.formula.options.ordering = 'degree'\n    mgr = FormulaManager(engine='formulaic')\n    (_, rhs0) = mgr.get_matrices('y ~ 1 + x + z + c', data)\n    statsmodels.formula.options.ordering = 'sort'\n    (_, rhs1) = mgr.get_matrices('y ~ 1 + x + z + c', data)\n    statsmodels.formula.options.ordering = 'none'\n    (_, rhs2) = mgr.get_matrices('y ~ 1 + x + c + z', data)\n    assert (len(rhs0.columns) == 4)\n    assert (len(rhs1.columns) == 4)\n    assert (len(rhs2.columns) == 4)\n    assert (list(rhs0.columns) != list(rhs1.columns))\n    assert (list(rhs0.columns) != list(rhs2.columns))\n    assert (list(rhs1.columns) != list(rhs2.columns))\n    statsmodels.formula.options.ordering = default", "masked_code": "@require_formulaic\ndef test_engine_options_order_effect(data):\n    default = statsmodels.formula.options.ordering\n    statsmodels.formula.options.ordering = 'degree'\n    mgr = FormulaManager(engine='formulaic')\n    (_, rhs0) = mgr.get_matrices('y ~ 1 + x + z + c', data)\n    statsmodels.formula.options.ordering = 'sort'\n    (_, rhs1) = mgr.get_matrices('y ~ 1 + x + z + c', data)\n    statsmodels.formula.options.ordering = 'none'\n    (_, rhs2) = mgr.get_matrices('y ~ 1 + x + c + z', data)\n    assert (len(rhs0.columns) == 4)\n    assert (len(rhs1.columns) == 4)\n    assert (len(rhs2.columns) == '???')\n    assert (list(rhs0.columns) != list(rhs1.columns))\n    assert (list(rhs0.columns) != list(rhs2.columns))\n    assert (list(rhs1.columns) != list(rhs2.columns))\n    statsmodels.formula.options.ordering = default", "ground_truth": "4", "quality_analysis": {"complexity_score": 6, "left_complexity": 5, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}, "classname": null}
{"task_id": "statsmodels_43", "reponame": "statsmodels", "testpath": "statsmodels/formula/tests/test_manager.py", "testname": "test_manager.py", "funcname": "test_get_na_action", "imports": ["import numpy as np", "import pandas as pd", "import pytest", "import statsmodels.formula", "from statsmodels.formula._manager import FormulaManager, LinearConstraintValues"], "code": "def test_get_na_action(engine, data):\n    mgr = FormulaManager(engine=engine)\n    result = mgr.get_na_action('drop')\n    if (engine == 'patsy'):\n        assert (result.on_NA == 'drop')\n        assert (result.NA_types == ('None', 'NaN'))\n    else:\n        assert (result == 'drop')\n    result = mgr.get_na_action(action='raise', types=['None'])\n    if (engine == 'patsy'):\n        assert (result.on_NA == 'raise')\n        assert (result.NA_types == ('None',))\n    else:\n        assert (result == 'raise')", "masked_code": "def test_get_na_action(engine, data):\n    mgr = FormulaManager(engine=engine)\n    result = mgr.get_na_action('drop')\n    if (engine == 'patsy'):\n        assert (result.on_NA == '???')\n        assert (result.NA_types == ('None', 'NaN'))\n    else:\n        assert (result == 'drop')\n    result = mgr.get_na_action(action='raise', types=['None'])\n    if (engine == 'patsy'):\n        assert (result.on_NA == 'raise')\n        assert (result.NA_types == ('None',))\n    else:\n        assert (result == 'raise')", "ground_truth": "'drop'", "quality_analysis": {"complexity_score": 3, "left_complexity": 2, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}, "classname": null}
{"task_id": "statsmodels_44", "reponame": "statsmodels", "testpath": "statsmodels/formula/tests/test_manager.py", "testname": "test_manager.py", "funcname": "test_get_na_action", "imports": ["import numpy as np", "import pandas as pd", "import pytest", "import statsmodels.formula", "from statsmodels.formula._manager import FormulaManager, LinearConstraintValues"], "code": "def test_get_na_action(engine, data):\n    mgr = FormulaManager(engine=engine)\n    result = mgr.get_na_action('drop')\n    if (engine == 'patsy'):\n        assert (result.on_NA == 'drop')\n        assert (result.NA_types == ('None', 'NaN'))\n    else:\n        assert (result == 'drop')\n    result = mgr.get_na_action(action='raise', types=['None'])\n    if (engine == 'patsy'):\n        assert (result.on_NA == 'raise')\n        assert (result.NA_types == ('None',))\n    else:\n        assert (result == 'raise')", "masked_code": "def test_get_na_action(engine, data):\n    mgr = FormulaManager(engine=engine)\n    result = mgr.get_na_action('drop')\n    if (engine == 'patsy'):\n        assert (result.on_NA == 'drop')\n        assert (result.NA_types == '???')\n    else:\n        assert (result == 'drop')\n    result = mgr.get_na_action(action='raise', types=['None'])\n    if (engine == 'patsy'):\n        assert (result.on_NA == 'raise')\n        assert (result.NA_types == ('None',))\n    else:\n        assert (result == 'raise')", "ground_truth": "('None', 'NaN')", "quality_analysis": {"complexity_score": 6, "left_complexity": 2, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}, "classname": null}
{"task_id": "statsmodels_45", "reponame": "statsmodels", "testpath": "statsmodels/formula/tests/test_manager.py", "testname": "test_manager.py", "funcname": "test_get_na_action", "imports": ["import numpy as np", "import pandas as pd", "import pytest", "import statsmodels.formula", "from statsmodels.formula._manager import FormulaManager, LinearConstraintValues"], "code": "def test_get_na_action(engine, data):\n    mgr = FormulaManager(engine=engine)\n    result = mgr.get_na_action('drop')\n    if (engine == 'patsy'):\n        assert (result.on_NA == 'drop')\n        assert (result.NA_types == ('None', 'NaN'))\n    else:\n        assert (result == 'drop')\n    result = mgr.get_na_action(action='raise', types=['None'])\n    if (engine == 'patsy'):\n        assert (result.on_NA == 'raise')\n        assert (result.NA_types == ('None',))\n    else:\n        assert (result == 'raise')", "masked_code": "def test_get_na_action(engine, data):\n    mgr = FormulaManager(engine=engine)\n    result = mgr.get_na_action('drop')\n    if (engine == 'patsy'):\n        assert (result.on_NA == 'drop')\n        assert (result.NA_types == ('None', 'NaN'))\n    else:\n        assert (result == 'drop')\n    result = mgr.get_na_action(action='raise', types=['None'])\n    if (engine == 'patsy'):\n        assert (result.on_NA == '???')\n        assert (result.NA_types == ('None',))\n    else:\n        assert (result == 'raise')", "ground_truth": "'raise'", "quality_analysis": {"complexity_score": 3, "left_complexity": 2, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}, "classname": null}
{"task_id": "statsmodels_46", "reponame": "statsmodels", "testpath": "statsmodels/formula/tests/test_manager.py", "testname": "test_manager.py", "funcname": "test_get_na_action", "imports": ["import numpy as np", "import pandas as pd", "import pytest", "import statsmodels.formula", "from statsmodels.formula._manager import FormulaManager, LinearConstraintValues"], "code": "def test_get_na_action(engine, data):\n    mgr = FormulaManager(engine=engine)\n    result = mgr.get_na_action('drop')\n    if (engine == 'patsy'):\n        assert (result.on_NA == 'drop')\n        assert (result.NA_types == ('None', 'NaN'))\n    else:\n        assert (result == 'drop')\n    result = mgr.get_na_action(action='raise', types=['None'])\n    if (engine == 'patsy'):\n        assert (result.on_NA == 'raise')\n        assert (result.NA_types == ('None',))\n    else:\n        assert (result == 'raise')", "masked_code": "def test_get_na_action(engine, data):\n    mgr = FormulaManager(engine=engine)\n    result = mgr.get_na_action('drop')\n    if (engine == 'patsy'):\n        assert (result.on_NA == 'drop')\n        assert (result.NA_types == ('None', 'NaN'))\n    else:\n        assert (result == 'drop')\n    result = mgr.get_na_action(action='raise', types=['None'])\n    if (engine == 'patsy'):\n        assert (result.on_NA == 'raise')\n        assert (result.NA_types == '???')\n    else:\n        assert (result == 'raise')", "ground_truth": "('None',)", "quality_analysis": {"complexity_score": 5, "left_complexity": 2, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}, "classname": null}
{"task_id": "statsmodels_41", "reponame": "statsmodels", "testpath": "statsmodels/formula/tests/test_manager.py", "testname": "test_manager.py", "funcname": "test_get_spec", "imports": ["import numpy as np", "import pandas as pd", "import pytest", "import statsmodels.formula", "from statsmodels.formula._manager import FormulaManager, LinearConstraintValues"], "code": "def test_get_spec(engine):\n    mgr = FormulaManager(engine=engine)\n    spec = mgr.get_spec('y ~ 1 + x + z')\n    if (engine == 'patsy'):\n        assert isinstance(spec, patsy.desc.ModelDesc)\n        assert (len(spec.lhs_termlist) == 1)\n        assert (len(spec.rhs_termlist) == 3)\n    else:\n        assert isinstance(spec, formulaic.formula.Formula)\n        assert (len(spec.lhs) == 1)\n        assert (len(spec.rhs) == 3)", "masked_code": "def test_get_spec(engine):\n    mgr = FormulaManager(engine=engine)\n    spec = mgr.get_spec('y ~ 1 + x + z')\n    if (engine == 'patsy'):\n        assert isinstance(spec, patsy.desc.ModelDesc)\n        assert (len(spec.lhs_termlist) == 1)\n        assert (len(spec.rhs_termlist) == '???')\n    else:\n        assert isinstance(spec, formulaic.formula.Formula)\n        assert (len(spec.lhs) == 1)\n        assert (len(spec.rhs) == 3)", "ground_truth": "3", "quality_analysis": {"complexity_score": 6, "left_complexity": 5, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}, "classname": null}
{"task_id": "statsmodels_42", "reponame": "statsmodels", "testpath": "statsmodels/formula/tests/test_manager.py", "testname": "test_manager.py", "funcname": "test_get_spec", "imports": ["import numpy as np", "import pandas as pd", "import pytest", "import statsmodels.formula", "from statsmodels.formula._manager import FormulaManager, LinearConstraintValues"], "code": "def test_get_spec(engine):\n    mgr = FormulaManager(engine=engine)\n    spec = mgr.get_spec('y ~ 1 + x + z')\n    if (engine == 'patsy'):\n        assert isinstance(spec, patsy.desc.ModelDesc)\n        assert (len(spec.lhs_termlist) == 1)\n        assert (len(spec.rhs_termlist) == 3)\n    else:\n        assert isinstance(spec, formulaic.formula.Formula)\n        assert (len(spec.lhs) == 1)\n        assert (len(spec.rhs) == 3)", "masked_code": "def test_get_spec(engine):\n    mgr = FormulaManager(engine=engine)\n    spec = mgr.get_spec('y ~ 1 + x + z')\n    if (engine == 'patsy'):\n        assert isinstance(spec, patsy.desc.ModelDesc)\n        assert (len(spec.lhs_termlist) == 1)\n        assert (len(spec.rhs_termlist) == 3)\n    else:\n        assert isinstance(spec, formulaic.formula.Formula)\n        assert (len(spec.lhs) == 1)\n        assert (len(spec.rhs) == '???')", "ground_truth": "3", "quality_analysis": {"complexity_score": 6, "left_complexity": 5, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}, "classname": null}
{"task_id": "statsmodels_51", "reponame": "statsmodels", "testpath": "statsmodels/formula/tests/test_manager.py", "testname": "test_manager.py", "funcname": "test_get_term_name_slices", "imports": ["import numpy as np", "import pandas as pd", "import pytest", "import statsmodels.formula", "from statsmodels.formula._manager import FormulaManager, LinearConstraintValues"], "code": "def test_get_term_name_slices(engine, data):\n    mgr = FormulaManager(engine=engine)\n    fmla = 'y ~ 1 + x + z + c'\n    (lhs, rhs) = mgr.get_matrices(fmla, data)\n    slices = mgr.get_term_name_slices(rhs)\n    for (i, key) in enumerate(slices):\n        assert (slices[key] == slice(i, (i + 1), None))\n    slices = mgr.get_term_name_slices(mgr.get_model_spec(rhs))\n    for (i, key) in enumerate(slices):\n        assert (slices[key] == slice(i, (i + 1), None))", "masked_code": "def test_get_term_name_slices(engine, data):\n    mgr = FormulaManager(engine=engine)\n    fmla = 'y ~ 1 + x + z + c'\n    (lhs, rhs) = mgr.get_matrices(fmla, data)\n    slices = mgr.get_term_name_slices(rhs)\n    for (i, key) in enumerate(slices):\n        assert (slices[key] == '???')\n    slices = mgr.get_term_name_slices(mgr.get_model_spec(rhs))\n    for (i, key) in enumerate(slices):\n        assert (slices[key] == slice(i, (i + 1), None))", "ground_truth": "slice(i, (i + 1), None)", "quality_analysis": {"complexity_score": 14, "left_complexity": 5, "right_complexity": 9, "is_quality": true, "reason": "High quality assertion"}, "classname": null}
{"task_id": "statsmodels_52", "reponame": "statsmodels", "testpath": "statsmodels/formula/tests/test_manager.py", "testname": "test_manager.py", "funcname": "test_get_term_name_slices", "imports": ["import numpy as np", "import pandas as pd", "import pytest", "import statsmodels.formula", "from statsmodels.formula._manager import FormulaManager, LinearConstraintValues"], "code": "def test_get_term_name_slices(engine, data):\n    mgr = FormulaManager(engine=engine)\n    fmla = 'y ~ 1 + x + z + c'\n    (lhs, rhs) = mgr.get_matrices(fmla, data)\n    slices = mgr.get_term_name_slices(rhs)\n    for (i, key) in enumerate(slices):\n        assert (slices[key] == slice(i, (i + 1), None))\n    slices = mgr.get_term_name_slices(mgr.get_model_spec(rhs))\n    for (i, key) in enumerate(slices):\n        assert (slices[key] == slice(i, (i + 1), None))", "masked_code": "def test_get_term_name_slices(engine, data):\n    mgr = FormulaManager(engine=engine)\n    fmla = 'y ~ 1 + x + z + c'\n    (lhs, rhs) = mgr.get_matrices(fmla, data)\n    slices = mgr.get_term_name_slices(rhs)\n    for (i, key) in enumerate(slices):\n        assert (slices[key] == slice(i, (i + 1), None))\n    slices = mgr.get_term_name_slices(mgr.get_model_spec(rhs))\n    for (i, key) in enumerate(slices):\n        assert (slices[key] == '???')", "ground_truth": "slice(i, (i + 1), None)", "quality_analysis": {"complexity_score": 14, "left_complexity": 5, "right_complexity": 9, "is_quality": true, "reason": "High quality assertion"}, "classname": null}
{"task_id": "statsmodels_53", "reponame": "statsmodels", "testpath": "statsmodels/formula/tests/test_manager.py", "testname": "test_manager.py", "funcname": "test_legacy_orderer", "imports": ["import numpy as np", "import pandas as pd", "import pytest", "import statsmodels.formula", "from statsmodels.formula._manager import FormulaManager, LinearConstraintValues"], "code": "@require_formulaic\n@require_patsy\ndef test_legacy_orderer(formula):\n    np.random.seed(0)\n    n = 100\n    data = pd.DataFrame({'y': np.random.standard_normal(n), 'a': np.random.standard_normal(n), 'b': np.random.standard_normal(n), 'c': np.random.standard_normal(n), 'd': pd.Series(np.random.choice(['a', 'b', 'c'], size=n), dtype='category'), 'e': pd.Series(np.random.choice(['a', 'b', 'c'], size=n), dtype='category'), 'f': pd.Series(np.random.choice(['a', 'b', 'c'], size=n), dtype='category')})\n    mgr = FormulaManager(engine='formulaic')\n    ordered_formula = mgr._legacy_orderer(formula, data, 0)\n    mm = mgr.get_matrices(ordered_formula, data)\n    (_, patsy_rhs) = patsy.dmatrices(formula, data, return_type='dataframe')\n    index = list(patsy_rhs.columns)\n    patsy_rhs.columns = index\n    assert (list(mm[1].columns) == list(patsy_rhs.columns))", "masked_code": "@require_formulaic\n@require_patsy\ndef test_legacy_orderer(formula):\n    np.random.seed(0)\n    n = 100\n    data = pd.DataFrame({'y': np.random.standard_normal(n), 'a': np.random.standard_normal(n), 'b': np.random.standard_normal(n), 'c': np.random.standard_normal(n), 'd': pd.Series(np.random.choice(['a', 'b', 'c'], size=n), dtype='category'), 'e': pd.Series(np.random.choice(['a', 'b', 'c'], size=n), dtype='category'), 'f': pd.Series(np.random.choice(['a', 'b', 'c'], size=n), dtype='category')})\n    mgr = FormulaManager(engine='formulaic')\n    ordered_formula = mgr._legacy_orderer(formula, data, 0)\n    mm = mgr.get_matrices(ordered_formula, data)\n    (_, patsy_rhs) = patsy.dmatrices(formula, data, return_type='dataframe')\n    index = list(patsy_rhs.columns)\n    patsy_rhs.columns = index\n    assert (list(mm[1].columns) == '???')", "ground_truth": "list(patsy_rhs.columns)", "quality_analysis": {"complexity_score": 10, "left_complexity": 5, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}, "classname": null}
{"task_id": "statsmodels_47", "reponame": "statsmodels", "testpath": "statsmodels/formula/tests/test_manager.py", "testname": "test_manager.py", "funcname": "test_na_action", "imports": ["import numpy as np", "import pandas as pd", "import pytest", "import statsmodels.formula", "from statsmodels.formula._manager import FormulaManager, LinearConstraintValues"], "code": "def test_na_action(engine, data):\n    mgr = FormulaManager(engine=engine)\n    fmla = 'y ~ 1 + x + z'\n    missing = data.copy()\n    missing.iloc[(::3, 1)] = np.nan\n    dropper = mgr.get_na_action('drop')\n    (lhs, rhs) = mgr.get_matrices(fmla, missing, na_action=dropper)\n    assert (rhs.shape[0] == lhs.shape[0])\n    assert (rhs.shape[0] == 4)\n    raiser = mgr.get_na_action('raise')\n    if (engine == 'patsy'):\n        exception = patsy.PatsyError\n    else:\n        exception = ValueError\n    with pytest.raises(exception):\n        mgr.get_matrices(fmla, missing, na_action=raiser)\n    if (engine == 'patsy'):\n        return\n    ignorer = mgr.get_na_action('ignore')\n    (lhs, rhs) = mgr.get_matrices(fmla, missing, na_action=ignorer)\n    assert (lhs.shape[0] == rhs.shape[0])\n    assert (rhs.shape[0] == missing.shape[0])", "masked_code": "def test_na_action(engine, data):\n    mgr = FormulaManager(engine=engine)\n    fmla = 'y ~ 1 + x + z'\n    missing = data.copy()\n    missing.iloc[(::3, 1)] = np.nan\n    dropper = mgr.get_na_action('drop')\n    (lhs, rhs) = mgr.get_matrices(fmla, missing, na_action=dropper)\n    assert (rhs.shape[0] == '???')\n    assert (rhs.shape[0] == 4)\n    raiser = mgr.get_na_action('raise')\n    if (engine == 'patsy'):\n        exception = patsy.PatsyError\n    else:\n        exception = ValueError\n    with pytest.raises(exception):\n        mgr.get_matrices(fmla, missing, na_action=raiser)\n    if (engine == 'patsy'):\n        return\n    ignorer = mgr.get_na_action('ignore')\n    (lhs, rhs) = mgr.get_matrices(fmla, missing, na_action=ignorer)\n    assert (lhs.shape[0] == rhs.shape[0])\n    assert (rhs.shape[0] == missing.shape[0])", "ground_truth": "lhs.shape[0]", "quality_analysis": {"complexity_score": 12, "left_complexity": 6, "right_complexity": 6, "is_quality": true, "reason": "High quality assertion"}, "classname": null}
{"task_id": "statsmodels_48", "reponame": "statsmodels", "testpath": "statsmodels/formula/tests/test_manager.py", "testname": "test_manager.py", "funcname": "test_na_action", "imports": ["import numpy as np", "import pandas as pd", "import pytest", "import statsmodels.formula", "from statsmodels.formula._manager import FormulaManager, LinearConstraintValues"], "code": "def test_na_action(engine, data):\n    mgr = FormulaManager(engine=engine)\n    fmla = 'y ~ 1 + x + z'\n    missing = data.copy()\n    missing.iloc[(::3, 1)] = np.nan\n    dropper = mgr.get_na_action('drop')\n    (lhs, rhs) = mgr.get_matrices(fmla, missing, na_action=dropper)\n    assert (rhs.shape[0] == lhs.shape[0])\n    assert (rhs.shape[0] == 4)\n    raiser = mgr.get_na_action('raise')\n    if (engine == 'patsy'):\n        exception = patsy.PatsyError\n    else:\n        exception = ValueError\n    with pytest.raises(exception):\n        mgr.get_matrices(fmla, missing, na_action=raiser)\n    if (engine == 'patsy'):\n        return\n    ignorer = mgr.get_na_action('ignore')\n    (lhs, rhs) = mgr.get_matrices(fmla, missing, na_action=ignorer)\n    assert (lhs.shape[0] == rhs.shape[0])\n    assert (rhs.shape[0] == missing.shape[0])", "masked_code": "def test_na_action(engine, data):\n    mgr = FormulaManager(engine=engine)\n    fmla = 'y ~ 1 + x + z'\n    missing = data.copy()\n    missing.iloc[(::3, 1)] = np.nan\n    dropper = mgr.get_na_action('drop')\n    (lhs, rhs) = mgr.get_matrices(fmla, missing, na_action=dropper)\n    assert (rhs.shape[0] == lhs.shape[0])\n    assert (rhs.shape[0] == '???')\n    raiser = mgr.get_na_action('raise')\n    if (engine == 'patsy'):\n        exception = patsy.PatsyError\n    else:\n        exception = ValueError\n    with pytest.raises(exception):\n        mgr.get_matrices(fmla, missing, na_action=raiser)\n    if (engine == 'patsy'):\n        return\n    ignorer = mgr.get_na_action('ignore')\n    (lhs, rhs) = mgr.get_matrices(fmla, missing, na_action=ignorer)\n    assert (lhs.shape[0] == rhs.shape[0])\n    assert (rhs.shape[0] == missing.shape[0])", "ground_truth": "4", "quality_analysis": {"complexity_score": 7, "left_complexity": 6, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}, "classname": null}
{"task_id": "statsmodels_115", "reponame": "statsmodels", "testpath": "statsmodels/robust/tests/test_norms.py", "testname": "test_norms.py", "funcname": "test_norm", "imports": ["import pytest", "import numpy as np", "from numpy.testing import assert_allclose", "from statsmodels.robust import norms", "from statsmodels.tools.numdiff import _approx_fprime_scalar", "from .results import results_norms as res_r"], "code": "@pytest.mark.parametrize('dtype', dtypes)\n@pytest.mark.parametrize('case', cases)\ndef test_norm(case, dtype):\n    (ncls, args, res) = case\n    if ((ncls in [norms.HuberT]) and (dtype == np.complex128)):\n        return\n    norm = ncls(*args)\n    x = np.array([(- 9), (- 6), (- 2), (- 1), 0, 1, 2, 6, 9], dtype=dtype)\n    weights = norm.weights(x)\n    rho = norm.rho(x)\n    psi = norm.psi(x)\n    psi_deriv = norm.psi_deriv(x)\n    assert_allclose(weights, res.weights, rtol=1e-12, atol=1e-20)\n    assert_allclose(rho, res.rho, rtol=1e-12, atol=1e-20)\n    assert_allclose(psi, res.psi, rtol=1e-12, atol=1e-20)\n    assert_allclose(psi_deriv, res.psi_deriv, rtol=1e-12, atol=1e-20)\n    dtype2 = np.promote_types(dtype, 'float')\n    assert (weights.dtype == dtype2)\n    assert (rho.dtype == dtype2)\n    assert (psi.dtype == dtype2)\n    assert (psi_deriv.dtype == dtype2)\n    psid = _approx_fprime_scalar(x, norm.rho)\n    assert_allclose(psid, res.psi, rtol=1e-06, atol=1e-08)\n    psidd = _approx_fprime_scalar(x, norm.psi)\n    assert_allclose(psidd, res.psi_deriv, rtol=1e-06, atol=1e-08)\n    methods = ['weights', 'rho', 'psi', 'psi_deriv']\n    for meth in methods:\n        resm = [getattr(norm, meth)(xi) for xi in x]\n        assert_allclose(resm, getattr(res, meth))", "masked_code": "@pytest.mark.parametrize('dtype', dtypes)\n@pytest.mark.parametrize('case', cases)\ndef test_norm(case, dtype):\n    (ncls, args, res) = case\n    if ((ncls in [norms.HuberT]) and (dtype == np.complex128)):\n        return\n    norm = ncls(*args)\n    x = np.array([(- 9), (- 6), (- 2), (- 1), 0, 1, 2, 6, 9], dtype=dtype)\n    weights = norm.weights(x)\n    rho = norm.rho(x)\n    psi = norm.psi(x)\n    psi_deriv = norm.psi_deriv(x)\n    assert_allclose(weights, res.weights, rtol=1e-12, atol=1e-20)\n    assert_allclose(rho, res.rho, rtol=1e-12, atol=1e-20)\n    assert_allclose(psi, res.psi, rtol=1e-12, atol=1e-20)\n    assert_allclose(psi_deriv, res.psi_deriv, rtol=1e-12, atol=1e-20)\n    dtype2 = np.promote_types(dtype, 'float')\n    assert (weights.dtype == '???')\n    assert (rho.dtype == dtype2)\n    assert (psi.dtype == dtype2)\n    assert (psi_deriv.dtype == dtype2)\n    psid = _approx_fprime_scalar(x, norm.rho)\n    assert_allclose(psid, res.psi, rtol=1e-06, atol=1e-08)\n    psidd = _approx_fprime_scalar(x, norm.psi)\n    assert_allclose(psidd, res.psi_deriv, rtol=1e-06, atol=1e-08)\n    methods = ['weights', 'rho', 'psi', 'psi_deriv']\n    for meth in methods:\n        resm = [getattr(norm, meth)(xi) for xi in x]\n        assert_allclose(resm, getattr(res, meth))", "ground_truth": "dtype2", "quality_analysis": {"complexity_score": 3, "left_complexity": 2, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}, "classname": null}
{"task_id": "statsmodels_116", "reponame": "statsmodels", "testpath": "statsmodels/robust/tests/test_norms.py", "testname": "test_norms.py", "funcname": "test_norm", "imports": ["import pytest", "import numpy as np", "from numpy.testing import assert_allclose", "from statsmodels.robust import norms", "from statsmodels.tools.numdiff import _approx_fprime_scalar", "from .results import results_norms as res_r"], "code": "@pytest.mark.parametrize('dtype', dtypes)\n@pytest.mark.parametrize('case', cases)\ndef test_norm(case, dtype):\n    (ncls, args, res) = case\n    if ((ncls in [norms.HuberT]) and (dtype == np.complex128)):\n        return\n    norm = ncls(*args)\n    x = np.array([(- 9), (- 6), (- 2), (- 1), 0, 1, 2, 6, 9], dtype=dtype)\n    weights = norm.weights(x)\n    rho = norm.rho(x)\n    psi = norm.psi(x)\n    psi_deriv = norm.psi_deriv(x)\n    assert_allclose(weights, res.weights, rtol=1e-12, atol=1e-20)\n    assert_allclose(rho, res.rho, rtol=1e-12, atol=1e-20)\n    assert_allclose(psi, res.psi, rtol=1e-12, atol=1e-20)\n    assert_allclose(psi_deriv, res.psi_deriv, rtol=1e-12, atol=1e-20)\n    dtype2 = np.promote_types(dtype, 'float')\n    assert (weights.dtype == dtype2)\n    assert (rho.dtype == dtype2)\n    assert (psi.dtype == dtype2)\n    assert (psi_deriv.dtype == dtype2)\n    psid = _approx_fprime_scalar(x, norm.rho)\n    assert_allclose(psid, res.psi, rtol=1e-06, atol=1e-08)\n    psidd = _approx_fprime_scalar(x, norm.psi)\n    assert_allclose(psidd, res.psi_deriv, rtol=1e-06, atol=1e-08)\n    methods = ['weights', 'rho', 'psi', 'psi_deriv']\n    for meth in methods:\n        resm = [getattr(norm, meth)(xi) for xi in x]\n        assert_allclose(resm, getattr(res, meth))", "masked_code": "@pytest.mark.parametrize('dtype', dtypes)\n@pytest.mark.parametrize('case', cases)\ndef test_norm(case, dtype):\n    (ncls, args, res) = case\n    if ((ncls in [norms.HuberT]) and (dtype == np.complex128)):\n        return\n    norm = ncls(*args)\n    x = np.array([(- 9), (- 6), (- 2), (- 1), 0, 1, 2, 6, 9], dtype=dtype)\n    weights = norm.weights(x)\n    rho = norm.rho(x)\n    psi = norm.psi(x)\n    psi_deriv = norm.psi_deriv(x)\n    assert_allclose(weights, res.weights, rtol=1e-12, atol=1e-20)\n    assert_allclose(rho, res.rho, rtol=1e-12, atol=1e-20)\n    assert_allclose(psi, res.psi, rtol=1e-12, atol=1e-20)\n    assert_allclose(psi_deriv, res.psi_deriv, rtol=1e-12, atol=1e-20)\n    dtype2 = np.promote_types(dtype, 'float')\n    assert (weights.dtype == dtype2)\n    assert (rho.dtype == '???')\n    assert (psi.dtype == dtype2)\n    assert (psi_deriv.dtype == dtype2)\n    psid = _approx_fprime_scalar(x, norm.rho)\n    assert_allclose(psid, res.psi, rtol=1e-06, atol=1e-08)\n    psidd = _approx_fprime_scalar(x, norm.psi)\n    assert_allclose(psidd, res.psi_deriv, rtol=1e-06, atol=1e-08)\n    methods = ['weights', 'rho', 'psi', 'psi_deriv']\n    for meth in methods:\n        resm = [getattr(norm, meth)(xi) for xi in x]\n        assert_allclose(resm, getattr(res, meth))", "ground_truth": "dtype2", "quality_analysis": {"complexity_score": 3, "left_complexity": 2, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}, "classname": null}
{"task_id": "statsmodels_117", "reponame": "statsmodels", "testpath": "statsmodels/robust/tests/test_norms.py", "testname": "test_norms.py", "funcname": "test_norm", "imports": ["import pytest", "import numpy as np", "from numpy.testing import assert_allclose", "from statsmodels.robust import norms", "from statsmodels.tools.numdiff import _approx_fprime_scalar", "from .results import results_norms as res_r"], "code": "@pytest.mark.parametrize('dtype', dtypes)\n@pytest.mark.parametrize('case', cases)\ndef test_norm(case, dtype):\n    (ncls, args, res) = case\n    if ((ncls in [norms.HuberT]) and (dtype == np.complex128)):\n        return\n    norm = ncls(*args)\n    x = np.array([(- 9), (- 6), (- 2), (- 1), 0, 1, 2, 6, 9], dtype=dtype)\n    weights = norm.weights(x)\n    rho = norm.rho(x)\n    psi = norm.psi(x)\n    psi_deriv = norm.psi_deriv(x)\n    assert_allclose(weights, res.weights, rtol=1e-12, atol=1e-20)\n    assert_allclose(rho, res.rho, rtol=1e-12, atol=1e-20)\n    assert_allclose(psi, res.psi, rtol=1e-12, atol=1e-20)\n    assert_allclose(psi_deriv, res.psi_deriv, rtol=1e-12, atol=1e-20)\n    dtype2 = np.promote_types(dtype, 'float')\n    assert (weights.dtype == dtype2)\n    assert (rho.dtype == dtype2)\n    assert (psi.dtype == dtype2)\n    assert (psi_deriv.dtype == dtype2)\n    psid = _approx_fprime_scalar(x, norm.rho)\n    assert_allclose(psid, res.psi, rtol=1e-06, atol=1e-08)\n    psidd = _approx_fprime_scalar(x, norm.psi)\n    assert_allclose(psidd, res.psi_deriv, rtol=1e-06, atol=1e-08)\n    methods = ['weights', 'rho', 'psi', 'psi_deriv']\n    for meth in methods:\n        resm = [getattr(norm, meth)(xi) for xi in x]\n        assert_allclose(resm, getattr(res, meth))", "masked_code": "@pytest.mark.parametrize('dtype', dtypes)\n@pytest.mark.parametrize('case', cases)\ndef test_norm(case, dtype):\n    (ncls, args, res) = case\n    if ((ncls in [norms.HuberT]) and (dtype == np.complex128)):\n        return\n    norm = ncls(*args)\n    x = np.array([(- 9), (- 6), (- 2), (- 1), 0, 1, 2, 6, 9], dtype=dtype)\n    weights = norm.weights(x)\n    rho = norm.rho(x)\n    psi = norm.psi(x)\n    psi_deriv = norm.psi_deriv(x)\n    assert_allclose(weights, res.weights, rtol=1e-12, atol=1e-20)\n    assert_allclose(rho, res.rho, rtol=1e-12, atol=1e-20)\n    assert_allclose(psi, res.psi, rtol=1e-12, atol=1e-20)\n    assert_allclose(psi_deriv, res.psi_deriv, rtol=1e-12, atol=1e-20)\n    dtype2 = np.promote_types(dtype, 'float')\n    assert (weights.dtype == dtype2)\n    assert (rho.dtype == dtype2)\n    assert (psi.dtype == '???')\n    assert (psi_deriv.dtype == dtype2)\n    psid = _approx_fprime_scalar(x, norm.rho)\n    assert_allclose(psid, res.psi, rtol=1e-06, atol=1e-08)\n    psidd = _approx_fprime_scalar(x, norm.psi)\n    assert_allclose(psidd, res.psi_deriv, rtol=1e-06, atol=1e-08)\n    methods = ['weights', 'rho', 'psi', 'psi_deriv']\n    for meth in methods:\n        resm = [getattr(norm, meth)(xi) for xi in x]\n        assert_allclose(resm, getattr(res, meth))", "ground_truth": "dtype2", "quality_analysis": {"complexity_score": 3, "left_complexity": 2, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}, "classname": null}
{"task_id": "statsmodels_118", "reponame": "statsmodels", "testpath": "statsmodels/robust/tests/test_norms.py", "testname": "test_norms.py", "funcname": "test_norm", "imports": ["import pytest", "import numpy as np", "from numpy.testing import assert_allclose", "from statsmodels.robust import norms", "from statsmodels.tools.numdiff import _approx_fprime_scalar", "from .results import results_norms as res_r"], "code": "@pytest.mark.parametrize('dtype', dtypes)\n@pytest.mark.parametrize('case', cases)\ndef test_norm(case, dtype):\n    (ncls, args, res) = case\n    if ((ncls in [norms.HuberT]) and (dtype == np.complex128)):\n        return\n    norm = ncls(*args)\n    x = np.array([(- 9), (- 6), (- 2), (- 1), 0, 1, 2, 6, 9], dtype=dtype)\n    weights = norm.weights(x)\n    rho = norm.rho(x)\n    psi = norm.psi(x)\n    psi_deriv = norm.psi_deriv(x)\n    assert_allclose(weights, res.weights, rtol=1e-12, atol=1e-20)\n    assert_allclose(rho, res.rho, rtol=1e-12, atol=1e-20)\n    assert_allclose(psi, res.psi, rtol=1e-12, atol=1e-20)\n    assert_allclose(psi_deriv, res.psi_deriv, rtol=1e-12, atol=1e-20)\n    dtype2 = np.promote_types(dtype, 'float')\n    assert (weights.dtype == dtype2)\n    assert (rho.dtype == dtype2)\n    assert (psi.dtype == dtype2)\n    assert (psi_deriv.dtype == dtype2)\n    psid = _approx_fprime_scalar(x, norm.rho)\n    assert_allclose(psid, res.psi, rtol=1e-06, atol=1e-08)\n    psidd = _approx_fprime_scalar(x, norm.psi)\n    assert_allclose(psidd, res.psi_deriv, rtol=1e-06, atol=1e-08)\n    methods = ['weights', 'rho', 'psi', 'psi_deriv']\n    for meth in methods:\n        resm = [getattr(norm, meth)(xi) for xi in x]\n        assert_allclose(resm, getattr(res, meth))", "masked_code": "@pytest.mark.parametrize('dtype', dtypes)\n@pytest.mark.parametrize('case', cases)\ndef test_norm(case, dtype):\n    (ncls, args, res) = case\n    if ((ncls in [norms.HuberT]) and (dtype == np.complex128)):\n        return\n    norm = ncls(*args)\n    x = np.array([(- 9), (- 6), (- 2), (- 1), 0, 1, 2, 6, 9], dtype=dtype)\n    weights = norm.weights(x)\n    rho = norm.rho(x)\n    psi = norm.psi(x)\n    psi_deriv = norm.psi_deriv(x)\n    assert_allclose(weights, res.weights, rtol=1e-12, atol=1e-20)\n    assert_allclose(rho, res.rho, rtol=1e-12, atol=1e-20)\n    assert_allclose(psi, res.psi, rtol=1e-12, atol=1e-20)\n    assert_allclose(psi_deriv, res.psi_deriv, rtol=1e-12, atol=1e-20)\n    dtype2 = np.promote_types(dtype, 'float')\n    assert (weights.dtype == dtype2)\n    assert (rho.dtype == dtype2)\n    assert (psi.dtype == dtype2)\n    assert (psi_deriv.dtype == '???')\n    psid = _approx_fprime_scalar(x, norm.rho)\n    assert_allclose(psid, res.psi, rtol=1e-06, atol=1e-08)\n    psidd = _approx_fprime_scalar(x, norm.psi)\n    assert_allclose(psidd, res.psi_deriv, rtol=1e-06, atol=1e-08)\n    methods = ['weights', 'rho', 'psi', 'psi_deriv']\n    for meth in methods:\n        resm = [getattr(norm, meth)(xi) for xi in x]\n        assert_allclose(resm, getattr(res, meth))", "ground_truth": "dtype2", "quality_analysis": {"complexity_score": 3, "left_complexity": 2, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}, "classname": null}
{"task_id": "statsmodels_119", "reponame": "statsmodels", "testpath": "statsmodels/stats/tests/test_pairwise.py", "testname": "test_pairwise.py", "funcname": "test_table_names_custom_group_order", "imports": ["from io import BytesIO", "import warnings", "import numpy as np", "import pandas as pd", "import pytest", "from numpy.testing import assert_, assert_allclose, assert_almost_equal, assert_equal, assert_raises", "from statsmodels.compat.python import asbytes", "from statsmodels.stats.libqsturng import qsturng", "from statsmodels.stats.multicomp import tukeyhsd, pairwise_tukeyhsd, MultiComparison"], "code": "def test_table_names_custom_group_order(self):\n    mc = MultiComparison(self.endog, self.groups, group_order=[b'physical', b'medical', b'mental'])\n    res = mc.tukeyhsd(alpha=self.alpha)\n    t = res._results_table\n    expected_order = [(b'physical', b'medical'), (b'physical', b'mental'), (b'medical', b'mental')]\n    for i in range(1, 4):\n        first_group = t[i][0].data\n        second_group = t[i][1].data\n        assert_(((first_group, second_group) == expected_order[(i - 1)]))\n    frame = res.summary_frame()\n    assert_equal(frame['p-adj'], res.pvalues)\n    assert_equal(frame['meandiff'], res.meandiffs)\n    group_t = [b'medical', b'mental', b'mental']\n    group_c = [b'physical', b'physical', b'medical']\n    assert (frame['group_t'].to_list() == group_t)\n    assert (frame['group_c'].to_list() == group_c)", "masked_code": "def test_table_names_custom_group_order(self):\n    mc = MultiComparison(self.endog, self.groups, group_order=[b'physical', b'medical', b'mental'])\n    res = mc.tukeyhsd(alpha=self.alpha)\n    t = res._results_table\n    expected_order = [(b'physical', b'medical'), (b'physical', b'mental'), (b'medical', b'mental')]\n    for i in range(1, 4):\n        first_group = t[i][0].data\n        second_group = t[i][1].data\n        assert_(((first_group, second_group) == expected_order[(i - 1)]))\n    frame = res.summary_frame()\n    assert_equal(frame['p-adj'], res.pvalues)\n    assert_equal(frame['meandiff'], res.meandiffs)\n    group_t = [b'medical', b'mental', b'mental']\n    group_c = [b'physical', b'physical', b'medical']\n    assert (frame['group_t'].to_list() == '???')\n    assert (frame['group_c'].to_list() == group_c)", "ground_truth": "group_t", "quality_analysis": {"complexity_score": 4, "left_complexity": 3, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}, "classname": "TestTuckeyHSD2"}
{"task_id": "statsmodels_120", "reponame": "statsmodels", "testpath": "statsmodels/stats/tests/test_pairwise.py", "testname": "test_pairwise.py", "funcname": "test_table_names_custom_group_order", "imports": ["from io import BytesIO", "import warnings", "import numpy as np", "import pandas as pd", "import pytest", "from numpy.testing import assert_, assert_allclose, assert_almost_equal, assert_equal, assert_raises", "from statsmodels.compat.python import asbytes", "from statsmodels.stats.libqsturng import qsturng", "from statsmodels.stats.multicomp import tukeyhsd, pairwise_tukeyhsd, MultiComparison"], "code": "def test_table_names_custom_group_order(self):\n    mc = MultiComparison(self.endog, self.groups, group_order=[b'physical', b'medical', b'mental'])\n    res = mc.tukeyhsd(alpha=self.alpha)\n    t = res._results_table\n    expected_order = [(b'physical', b'medical'), (b'physical', b'mental'), (b'medical', b'mental')]\n    for i in range(1, 4):\n        first_group = t[i][0].data\n        second_group = t[i][1].data\n        assert_(((first_group, second_group) == expected_order[(i - 1)]))\n    frame = res.summary_frame()\n    assert_equal(frame['p-adj'], res.pvalues)\n    assert_equal(frame['meandiff'], res.meandiffs)\n    group_t = [b'medical', b'mental', b'mental']\n    group_c = [b'physical', b'physical', b'medical']\n    assert (frame['group_t'].to_list() == group_t)\n    assert (frame['group_c'].to_list() == group_c)", "masked_code": "def test_table_names_custom_group_order(self):\n    mc = MultiComparison(self.endog, self.groups, group_order=[b'physical', b'medical', b'mental'])\n    res = mc.tukeyhsd(alpha=self.alpha)\n    t = res._results_table\n    expected_order = [(b'physical', b'medical'), (b'physical', b'mental'), (b'medical', b'mental')]\n    for i in range(1, 4):\n        first_group = t[i][0].data\n        second_group = t[i][1].data\n        assert_(((first_group, second_group) == expected_order[(i - 1)]))\n    frame = res.summary_frame()\n    assert_equal(frame['p-adj'], res.pvalues)\n    assert_equal(frame['meandiff'], res.meandiffs)\n    group_t = [b'medical', b'mental', b'mental']\n    group_c = [b'physical', b'physical', b'medical']\n    assert (frame['group_t'].to_list() == group_t)\n    assert (frame['group_c'].to_list() == '???')", "ground_truth": "group_c", "quality_analysis": {"complexity_score": 4, "left_complexity": 3, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}, "classname": "TestTuckeyHSD2"}
{"task_id": "statsmodels_100", "reponame": "statsmodels", "testpath": "statsmodels/multivariate/tests/test_pca.py", "testname": "test_pca.py", "funcname": "test_too_many_missing", "imports": ["from statsmodels.compat.platform import PLATFORM_WIN32", "import warnings", "import numpy as np", "from numpy.testing import assert_allclose, assert_equal, assert_raises", "import pandas as pd", "import pytest", "from statsmodels.multivariate.pca import PCA, pca", "from statsmodels.multivariate.tests.results.datamlw import data, princomp1, princomp2", "from statsmodels.tools.sm_exceptions import EstimationWarning"], "code": "def test_too_many_missing(reset_randomstate):\n    data = np.random.standard_normal((200, 50))\n    data[(0, :(- 3))] = np.nan\n    with pytest.raises(ValueError):\n        PCA(data, ncomp=5, missing='drop-col')\n    p = PCA(data, missing='drop-min')\n    assert (max(p.factors.shape) == (max(data.shape) - 1))", "masked_code": "def test_too_many_missing(reset_randomstate):\n    data = np.random.standard_normal((200, 50))\n    data[(0, :(- 3))] = np.nan\n    with pytest.raises(ValueError):\n        PCA(data, ncomp=5, missing='drop-col')\n    p = PCA(data, missing='drop-min')\n    assert (max(p.factors.shape) == '???')", "ground_truth": "(max(data.shape) - 1)", "quality_analysis": {"complexity_score": 13, "left_complexity": 5, "right_complexity": 8, "is_quality": true, "reason": "High quality assertion"}, "classname": null}
{"task_id": "statsmodels_92", "reponame": "statsmodels", "testpath": "statsmodels/miscmodels/tests/test_poisson.py", "testname": "test_poisson.py", "funcname": "test_df", "imports": ["import pytest", "import numpy as np", "from numpy.testing import assert_almost_equal", "from scipy import stats", "import statsmodels.api as sm", "from statsmodels.miscmodels.count import PoissonGMLE, PoissonOffsetGMLE, PoissonZiGMLE", "from statsmodels.discrete.discrete_model import Poisson", "from statsmodels.tools.sm_exceptions import ValueWarning"], "code": "def test_df(self):\n    res = self.res\n    k_extra = getattr(self, 'k_extra', 0)\n    (nobs, k_vars) = res.model.exog.shape\n    assert (res.df_resid == ((nobs - k_vars) - k_extra))\n    assert (res.df_model == (k_vars - 1))\n    assert (len(res.params) == (k_vars + k_extra))", "masked_code": "def test_df(self):\n    res = self.res\n    k_extra = getattr(self, 'k_extra', 0)\n    (nobs, k_vars) = res.model.exog.shape\n    assert (res.df_resid == '???')\n    assert (res.df_model == (k_vars - 1))\n    assert (len(res.params) == (k_vars + k_extra))", "ground_truth": "((nobs - k_vars) - k_extra)", "quality_analysis": {"complexity_score": 9, "left_complexity": 2, "right_complexity": 7, "is_quality": true, "reason": "High quality assertion"}, "classname": "CompareMixin"}
{"task_id": "statsmodels_93", "reponame": "statsmodels", "testpath": "statsmodels/miscmodels/tests/test_poisson.py", "testname": "test_poisson.py", "funcname": "test_df", "imports": ["import pytest", "import numpy as np", "from numpy.testing import assert_almost_equal", "from scipy import stats", "import statsmodels.api as sm", "from statsmodels.miscmodels.count import PoissonGMLE, PoissonOffsetGMLE, PoissonZiGMLE", "from statsmodels.discrete.discrete_model import Poisson", "from statsmodels.tools.sm_exceptions import ValueWarning"], "code": "def test_df(self):\n    res = self.res\n    k_extra = getattr(self, 'k_extra', 0)\n    (nobs, k_vars) = res.model.exog.shape\n    assert (res.df_resid == ((nobs - k_vars) - k_extra))\n    assert (res.df_model == (k_vars - 1))\n    assert (len(res.params) == (k_vars + k_extra))", "masked_code": "def test_df(self):\n    res = self.res\n    k_extra = getattr(self, 'k_extra', 0)\n    (nobs, k_vars) = res.model.exog.shape\n    assert (res.df_resid == ((nobs - k_vars) - k_extra))\n    assert (res.df_model == '???')\n    assert (len(res.params) == (k_vars + k_extra))", "ground_truth": "(k_vars - 1)", "quality_analysis": {"complexity_score": 6, "left_complexity": 2, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}, "classname": "CompareMixin"}
{"task_id": "statsmodels_94", "reponame": "statsmodels", "testpath": "statsmodels/miscmodels/tests/test_poisson.py", "testname": "test_poisson.py", "funcname": "test_df", "imports": ["import pytest", "import numpy as np", "from numpy.testing import assert_almost_equal", "from scipy import stats", "import statsmodels.api as sm", "from statsmodels.miscmodels.count import PoissonGMLE, PoissonOffsetGMLE, PoissonZiGMLE", "from statsmodels.discrete.discrete_model import Poisson", "from statsmodels.tools.sm_exceptions import ValueWarning"], "code": "def test_df(self):\n    res = self.res\n    k_extra = getattr(self, 'k_extra', 0)\n    (nobs, k_vars) = res.model.exog.shape\n    assert (res.df_resid == ((nobs - k_vars) - k_extra))\n    assert (res.df_model == (k_vars - 1))\n    assert (len(res.params) == (k_vars + k_extra))", "masked_code": "def test_df(self):\n    res = self.res\n    k_extra = getattr(self, 'k_extra', 0)\n    (nobs, k_vars) = res.model.exog.shape\n    assert (res.df_resid == ((nobs - k_vars) - k_extra))\n    assert (res.df_model == (k_vars - 1))\n    assert (len(res.params) == '???')", "ground_truth": "(k_vars + k_extra)", "quality_analysis": {"complexity_score": 9, "left_complexity": 5, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}, "classname": "CompareMixin"}
{"task_id": "statsmodels_103", "reponame": "statsmodels", "testpath": "statsmodels/regression/tests/test_quantile_regression.py", "testname": "test_quantile_regression.py", "funcname": "test_collinear_matrix", "imports": ["import numpy as np", "from numpy.testing import assert_allclose, assert_almost_equal, assert_equal", "import scipy.stats", "import statsmodels.api as sm", "from statsmodels.formula._manager import FormulaManager", "from statsmodels.regression.quantile_regression import QuantReg", "from .results.results_quantile_regression import Rquantreg, biweight_bofinger, biweight_chamberlain, biweight_hsheather, cosine_bofinger, cosine_chamberlain, cosine_hsheather, epan2_bofinger, epan2_chamberlain, epan2_hsheather, epanechnikov_hsheather_q75, gaussian_bofinger, gaussian_chamberlain, gaussian_hsheather, parzen_bofinger, parzen_chamberlain, parzen_hsheather"], "code": "def test_collinear_matrix():\n    X = np.array([[1, 0, 0.5], [1, 0, 0.8], [1, 0, 1.5], [1, 0, 0.25]], dtype=np.float64)\n    y = np.array([0, 1, 2, 3], dtype=np.float64)\n    res_collinear = QuantReg(y, X).fit(0.5)\n    assert (len(res_collinear.params) == X.shape[1])", "masked_code": "def test_collinear_matrix():\n    X = np.array([[1, 0, 0.5], [1, 0, 0.8], [1, 0, 1.5], [1, 0, 0.25]], dtype=np.float64)\n    y = np.array([0, 1, 2, 3], dtype=np.float64)\n    res_collinear = QuantReg(y, X).fit(0.5)\n    assert (len(res_collinear.params) == '???')", "ground_truth": "X.shape[1]", "quality_analysis": {"complexity_score": 11, "left_complexity": 5, "right_complexity": 6, "is_quality": true, "reason": "High quality assertion"}, "classname": null}
{"task_id": "statsmodels_104", "reponame": "statsmodels", "testpath": "statsmodels/regression/tests/test_quantile_regression.py", "testname": "test_quantile_regression.py", "funcname": "test_nontrivial_singular_matrix", "imports": ["import numpy as np", "from numpy.testing import assert_allclose, assert_almost_equal, assert_equal", "import scipy.stats", "import statsmodels.api as sm", "from statsmodels.formula._manager import FormulaManager", "from statsmodels.regression.quantile_regression import QuantReg", "from .results.results_quantile_regression import Rquantreg, biweight_bofinger, biweight_chamberlain, biweight_hsheather, cosine_bofinger, cosine_chamberlain, cosine_hsheather, epan2_bofinger, epan2_chamberlain, epan2_hsheather, epanechnikov_hsheather_q75, gaussian_bofinger, gaussian_chamberlain, gaussian_hsheather, parzen_bofinger, parzen_chamberlain, parzen_hsheather"], "code": "def test_nontrivial_singular_matrix():\n    x_one = np.random.random(1000)\n    x_two = (np.random.random(1000) * 10)\n    x_three = np.random.random(1000)\n    intercept = np.ones(1000)\n    y = (np.random.random(1000) * 5)\n    X = np.column_stack((intercept, x_one, x_two, x_three, x_one))\n    assert (np.linalg.matrix_rank(X) < X.shape[1])\n    res_singular = QuantReg(y, X).fit(0.5)\n    assert (len(res_singular.params) == X.shape[1])\n    assert (np.linalg.matrix_rank(res_singular.cov_params()) == (X.shape[1] - 1))\n    res_ns = QuantReg(y, X[(:, :(- 1))]).fit(0.5)\n    assert_allclose(res_singular.fittedvalues, res_ns.fittedvalues, rtol=0.01)", "masked_code": "def test_nontrivial_singular_matrix():\n    x_one = np.random.random(1000)\n    x_two = (np.random.random(1000) * 10)\n    x_three = np.random.random(1000)\n    intercept = np.ones(1000)\n    y = (np.random.random(1000) * 5)\n    X = np.column_stack((intercept, x_one, x_two, x_three, x_one))\n    assert (np.linalg.matrix_rank(X) < X.shape[1])\n    res_singular = QuantReg(y, X).fit(0.5)\n    assert (len(res_singular.params) == '???')\n    assert (np.linalg.matrix_rank(res_singular.cov_params()) == (X.shape[1] - 1))\n    res_ns = QuantReg(y, X[(:, :(- 1))]).fit(0.5)\n    assert_allclose(res_singular.fittedvalues, res_ns.fittedvalues, rtol=0.01)", "ground_truth": "X.shape[1]", "quality_analysis": {"complexity_score": 11, "left_complexity": 5, "right_complexity": 6, "is_quality": true, "reason": "High quality assertion"}, "classname": null}
{"task_id": "statsmodels_105", "reponame": "statsmodels", "testpath": "statsmodels/regression/tests/test_quantile_regression.py", "testname": "test_quantile_regression.py", "funcname": "test_nontrivial_singular_matrix", "imports": ["import numpy as np", "from numpy.testing import assert_allclose, assert_almost_equal, assert_equal", "import scipy.stats", "import statsmodels.api as sm", "from statsmodels.formula._manager import FormulaManager", "from statsmodels.regression.quantile_regression import QuantReg", "from .results.results_quantile_regression import Rquantreg, biweight_bofinger, biweight_chamberlain, biweight_hsheather, cosine_bofinger, cosine_chamberlain, cosine_hsheather, epan2_bofinger, epan2_chamberlain, epan2_hsheather, epanechnikov_hsheather_q75, gaussian_bofinger, gaussian_chamberlain, gaussian_hsheather, parzen_bofinger, parzen_chamberlain, parzen_hsheather"], "code": "def test_nontrivial_singular_matrix():\n    x_one = np.random.random(1000)\n    x_two = (np.random.random(1000) * 10)\n    x_three = np.random.random(1000)\n    intercept = np.ones(1000)\n    y = (np.random.random(1000) * 5)\n    X = np.column_stack((intercept, x_one, x_two, x_three, x_one))\n    assert (np.linalg.matrix_rank(X) < X.shape[1])\n    res_singular = QuantReg(y, X).fit(0.5)\n    assert (len(res_singular.params) == X.shape[1])\n    assert (np.linalg.matrix_rank(res_singular.cov_params()) == (X.shape[1] - 1))\n    res_ns = QuantReg(y, X[(:, :(- 1))]).fit(0.5)\n    assert_allclose(res_singular.fittedvalues, res_ns.fittedvalues, rtol=0.01)", "masked_code": "def test_nontrivial_singular_matrix():\n    x_one = np.random.random(1000)\n    x_two = (np.random.random(1000) * 10)\n    x_three = np.random.random(1000)\n    intercept = np.ones(1000)\n    y = (np.random.random(1000) * 5)\n    X = np.column_stack((intercept, x_one, x_two, x_three, x_one))\n    assert (np.linalg.matrix_rank(X) < X.shape[1])\n    res_singular = QuantReg(y, X).fit(0.5)\n    assert (len(res_singular.params) == X.shape[1])\n    assert (np.linalg.matrix_rank(res_singular.cov_params()) == '???')\n    res_ns = QuantReg(y, X[(:, :(- 1))]).fit(0.5)\n    assert_allclose(res_singular.fittedvalues, res_ns.fittedvalues, rtol=0.01)", "ground_truth": "(X.shape[1] - 1)", "quality_analysis": {"complexity_score": 15, "left_complexity": 6, "right_complexity": 9, "is_quality": true, "reason": "High quality assertion"}, "classname": null}
{"task_id": "statsmodels_109", "reponame": "statsmodels", "testpath": "statsmodels/regression/tests/test_rolling.py", "testname": "test_rolling.py", "funcname": "test_against_wls_inference", "imports": ["from io import BytesIO", "from itertools import product", "import warnings", "import numpy as np", "import pandas as pd", "import pytest", "from numpy.testing import assert_allclose, assert_array_equal", "from statsmodels import tools", "from statsmodels.regression.linear_model import WLS", "from statsmodels.regression.rolling import RollingWLS, RollingOLS"], "code": "@pytest.mark.parametrize('cov_type', ['nonrobust', 'HC0'])\n@pytest.mark.parametrize('use_t', [None, True, False])\ndef test_against_wls_inference(data, use_t, cov_type):\n    (y, x, w) = data\n    mod = RollingWLS(y, x, window=100, weights=w)\n    res = mod.fit(use_t=use_t, cov_type=cov_type)\n    ci = res.conf_int()\n    res.cov_params()\n    for i in range(100, y.shape[0]):\n        _y = get_sub(y, i, 100)\n        _x = get_sub(x, i, 100)\n        wls = WLS(_y, _x, missing='drop').fit(use_t=use_t, cov_type=cov_type)\n        assert_allclose(get_single(res.tvalues, (i - 1)), wls.tvalues)\n        assert_allclose(get_single(res.bse, (i - 1)), wls.bse)\n        assert_allclose(get_single(res.pvalues, (i - 1)), wls.pvalues, atol=1e-08)\n        assert_allclose(get_single(res.fvalue, (i - 1)), wls.fvalue)\n        with np.errstate(invalid='ignore'):\n            assert_allclose(get_single(res.f_pvalue, (i - 1)), wls.f_pvalue, atol=1e-08)\n        assert (res.cov_type == wls.cov_type)\n        assert (res.use_t == wls.use_t)\n        wls_ci = wls.conf_int()\n        if isinstance(ci, pd.DataFrame):\n            ci_val = ci.iloc[(i - 1)]\n            ci_val = np.asarray(ci_val).reshape(((- 1), 2))\n        else:\n            ci_val = ci[(i - 1)].T\n        assert_allclose(ci_val, wls_ci)", "masked_code": "@pytest.mark.parametrize('cov_type', ['nonrobust', 'HC0'])\n@pytest.mark.parametrize('use_t', [None, True, False])\ndef test_against_wls_inference(data, use_t, cov_type):\n    (y, x, w) = data\n    mod = RollingWLS(y, x, window=100, weights=w)\n    res = mod.fit(use_t=use_t, cov_type=cov_type)\n    ci = res.conf_int()\n    res.cov_params()\n    for i in range(100, y.shape[0]):\n        _y = get_sub(y, i, 100)\n        _x = get_sub(x, i, 100)\n        wls = WLS(_y, _x, missing='drop').fit(use_t=use_t, cov_type=cov_type)\n        assert_allclose(get_single(res.tvalues, (i - 1)), wls.tvalues)\n        assert_allclose(get_single(res.bse, (i - 1)), wls.bse)\n        assert_allclose(get_single(res.pvalues, (i - 1)), wls.pvalues, atol=1e-08)\n        assert_allclose(get_single(res.fvalue, (i - 1)), wls.fvalue)\n        with np.errstate(invalid='ignore'):\n            assert_allclose(get_single(res.f_pvalue, (i - 1)), wls.f_pvalue, atol=1e-08)\n        assert (res.cov_type == '???')\n        assert (res.use_t == wls.use_t)\n        wls_ci = wls.conf_int()\n        if isinstance(ci, pd.DataFrame):\n            ci_val = ci.iloc[(i - 1)]\n            ci_val = np.asarray(ci_val).reshape(((- 1), 2))\n        else:\n            ci_val = ci[(i - 1)].T\n        assert_allclose(ci_val, wls_ci)", "ground_truth": "wls.cov_type", "quality_analysis": {"complexity_score": 4, "left_complexity": 2, "right_complexity": 2, "is_quality": true, "reason": "High quality assertion"}, "classname": null}
{"task_id": "statsmodels_110", "reponame": "statsmodels", "testpath": "statsmodels/regression/tests/test_rolling.py", "testname": "test_rolling.py", "funcname": "test_against_wls_inference", "imports": ["from io import BytesIO", "from itertools import product", "import warnings", "import numpy as np", "import pandas as pd", "import pytest", "from numpy.testing import assert_allclose, assert_array_equal", "from statsmodels import tools", "from statsmodels.regression.linear_model import WLS", "from statsmodels.regression.rolling import RollingWLS, RollingOLS"], "code": "@pytest.mark.parametrize('cov_type', ['nonrobust', 'HC0'])\n@pytest.mark.parametrize('use_t', [None, True, False])\ndef test_against_wls_inference(data, use_t, cov_type):\n    (y, x, w) = data\n    mod = RollingWLS(y, x, window=100, weights=w)\n    res = mod.fit(use_t=use_t, cov_type=cov_type)\n    ci = res.conf_int()\n    res.cov_params()\n    for i in range(100, y.shape[0]):\n        _y = get_sub(y, i, 100)\n        _x = get_sub(x, i, 100)\n        wls = WLS(_y, _x, missing='drop').fit(use_t=use_t, cov_type=cov_type)\n        assert_allclose(get_single(res.tvalues, (i - 1)), wls.tvalues)\n        assert_allclose(get_single(res.bse, (i - 1)), wls.bse)\n        assert_allclose(get_single(res.pvalues, (i - 1)), wls.pvalues, atol=1e-08)\n        assert_allclose(get_single(res.fvalue, (i - 1)), wls.fvalue)\n        with np.errstate(invalid='ignore'):\n            assert_allclose(get_single(res.f_pvalue, (i - 1)), wls.f_pvalue, atol=1e-08)\n        assert (res.cov_type == wls.cov_type)\n        assert (res.use_t == wls.use_t)\n        wls_ci = wls.conf_int()\n        if isinstance(ci, pd.DataFrame):\n            ci_val = ci.iloc[(i - 1)]\n            ci_val = np.asarray(ci_val).reshape(((- 1), 2))\n        else:\n            ci_val = ci[(i - 1)].T\n        assert_allclose(ci_val, wls_ci)", "masked_code": "@pytest.mark.parametrize('cov_type', ['nonrobust', 'HC0'])\n@pytest.mark.parametrize('use_t', [None, True, False])\ndef test_against_wls_inference(data, use_t, cov_type):\n    (y, x, w) = data\n    mod = RollingWLS(y, x, window=100, weights=w)\n    res = mod.fit(use_t=use_t, cov_type=cov_type)\n    ci = res.conf_int()\n    res.cov_params()\n    for i in range(100, y.shape[0]):\n        _y = get_sub(y, i, 100)\n        _x = get_sub(x, i, 100)\n        wls = WLS(_y, _x, missing='drop').fit(use_t=use_t, cov_type=cov_type)\n        assert_allclose(get_single(res.tvalues, (i - 1)), wls.tvalues)\n        assert_allclose(get_single(res.bse, (i - 1)), wls.bse)\n        assert_allclose(get_single(res.pvalues, (i - 1)), wls.pvalues, atol=1e-08)\n        assert_allclose(get_single(res.fvalue, (i - 1)), wls.fvalue)\n        with np.errstate(invalid='ignore'):\n            assert_allclose(get_single(res.f_pvalue, (i - 1)), wls.f_pvalue, atol=1e-08)\n        assert (res.cov_type == wls.cov_type)\n        assert (res.use_t == '???')\n        wls_ci = wls.conf_int()\n        if isinstance(ci, pd.DataFrame):\n            ci_val = ci.iloc[(i - 1)]\n            ci_val = np.asarray(ci_val).reshape(((- 1), 2))\n        else:\n            ci_val = ci[(i - 1)].T\n        assert_allclose(ci_val, wls_ci)", "ground_truth": "wls.use_t", "quality_analysis": {"complexity_score": 4, "left_complexity": 2, "right_complexity": 2, "is_quality": true, "reason": "High quality assertion"}, "classname": null}
{"task_id": "statsmodels_78", "reponame": "statsmodels", "testpath": "statsmodels/imputation/tests/test_ros.py", "testname": "test_ros.py", "funcname": "test_no_NDs", "imports": ["from statsmodels.compat.pandas import assert_series_equal, assert_frame_equal", "from io import StringIO", "from textwrap import dedent", "import numpy as np", "import numpy.testing as npt", "import numpy", "from numpy.testing import assert_equal", "import pandas", "import pytest", "from statsmodels.imputation import ros"], "code": "def test_no_NDs(self):\n    _df = self.df.copy()\n    _df['qual'] = False\n    result = ros.cohn_numbers(_df, observations='conc', censorship='qual')\n    assert (result.shape == (0, 6))", "masked_code": "def test_no_NDs(self):\n    _df = self.df.copy()\n    _df['qual'] = False\n    result = ros.cohn_numbers(_df, observations='conc', censorship='qual')\n    assert (result.shape == '???')", "ground_truth": "(0, 6)", "quality_analysis": {"complexity_score": 6, "left_complexity": 2, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}, "classname": "Test_cohn_numbers"}
{"task_id": "statsmodels_221", "reponame": "statsmodels", "testpath": "statsmodels/tsa/stl/tests/test_stl.py", "testname": "test_stl.py", "funcname": "test_default_trend", "imports": ["from statsmodels.compat.pandas import MONTH_END", "import os", "import pickle", "import numpy as np", "from numpy.testing import assert_allclose", "import pandas as pd", "import pytest", "from statsmodels.datasets import co2", "from statsmodels.tsa.seasonal import STL, DecomposeResult"], "code": "def test_default_trend(default_kwargs):\n    (class_kwargs, _, _) = _to_class_kwargs(default_kwargs)\n    class_kwargs['seasonal'] = 17\n    class_kwargs['trend'] = None\n    mod = STL(**class_kwargs)\n    period = class_kwargs['period']\n    seasonal = class_kwargs['seasonal']\n    expected = int(np.ceil(((1.5 * period) / (1 - (1.5 / seasonal)))))\n    expected += (1 if ((expected % 2) == 0) else 0)\n    assert (mod.config['trend'] == expected)\n    class_kwargs['seasonal'] = 7\n    mod = STL(**class_kwargs)\n    period = class_kwargs['period']\n    seasonal = class_kwargs['seasonal']\n    expected = int(np.ceil(((1.5 * period) / (1 - (1.5 / seasonal)))))\n    expected += (1 if ((expected % 2) == 0) else 0)\n    assert (mod.config['trend'] == expected)", "masked_code": "def test_default_trend(default_kwargs):\n    (class_kwargs, _, _) = _to_class_kwargs(default_kwargs)\n    class_kwargs['seasonal'] = 17\n    class_kwargs['trend'] = None\n    mod = STL(**class_kwargs)\n    period = class_kwargs['period']\n    seasonal = class_kwargs['seasonal']\n    expected = int(np.ceil(((1.5 * period) / (1 - (1.5 / seasonal)))))\n    expected += (1 if ((expected % 2) == 0) else 0)\n    assert (mod.config['trend'] == '???')\n    class_kwargs['seasonal'] = 7\n    mod = STL(**class_kwargs)\n    period = class_kwargs['period']\n    seasonal = class_kwargs['seasonal']\n    expected = int(np.ceil(((1.5 * period) / (1 - (1.5 / seasonal)))))\n    expected += (1 if ((expected % 2) == 0) else 0)\n    assert (mod.config['trend'] == expected)", "ground_truth": "expected", "quality_analysis": {"complexity_score": 7, "left_complexity": 6, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}, "classname": null}
{"task_id": "statsmodels_222", "reponame": "statsmodels", "testpath": "statsmodels/tsa/stl/tests/test_stl.py", "testname": "test_stl.py", "funcname": "test_default_trend", "imports": ["from statsmodels.compat.pandas import MONTH_END", "import os", "import pickle", "import numpy as np", "from numpy.testing import assert_allclose", "import pandas as pd", "import pytest", "from statsmodels.datasets import co2", "from statsmodels.tsa.seasonal import STL, DecomposeResult"], "code": "def test_default_trend(default_kwargs):\n    (class_kwargs, _, _) = _to_class_kwargs(default_kwargs)\n    class_kwargs['seasonal'] = 17\n    class_kwargs['trend'] = None\n    mod = STL(**class_kwargs)\n    period = class_kwargs['period']\n    seasonal = class_kwargs['seasonal']\n    expected = int(np.ceil(((1.5 * period) / (1 - (1.5 / seasonal)))))\n    expected += (1 if ((expected % 2) == 0) else 0)\n    assert (mod.config['trend'] == expected)\n    class_kwargs['seasonal'] = 7\n    mod = STL(**class_kwargs)\n    period = class_kwargs['period']\n    seasonal = class_kwargs['seasonal']\n    expected = int(np.ceil(((1.5 * period) / (1 - (1.5 / seasonal)))))\n    expected += (1 if ((expected % 2) == 0) else 0)\n    assert (mod.config['trend'] == expected)", "masked_code": "def test_default_trend(default_kwargs):\n    (class_kwargs, _, _) = _to_class_kwargs(default_kwargs)\n    class_kwargs['seasonal'] = 17\n    class_kwargs['trend'] = None\n    mod = STL(**class_kwargs)\n    period = class_kwargs['period']\n    seasonal = class_kwargs['seasonal']\n    expected = int(np.ceil(((1.5 * period) / (1 - (1.5 / seasonal)))))\n    expected += (1 if ((expected % 2) == 0) else 0)\n    assert (mod.config['trend'] == expected)\n    class_kwargs['seasonal'] = 7\n    mod = STL(**class_kwargs)\n    period = class_kwargs['period']\n    seasonal = class_kwargs['seasonal']\n    expected = int(np.ceil(((1.5 * period) / (1 - (1.5 / seasonal)))))\n    expected += (1 if ((expected % 2) == 0) else 0)\n    assert (mod.config['trend'] == '???')", "ground_truth": "expected", "quality_analysis": {"complexity_score": 7, "left_complexity": 6, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}, "classname": null}
{"task_id": "statsmodels_223", "reponame": "statsmodels", "testpath": "statsmodels/tsa/stl/tests/test_stl.py", "testname": "test_stl.py", "funcname": "test_pickle", "imports": ["from statsmodels.compat.pandas import MONTH_END", "import os", "import pickle", "import numpy as np", "from numpy.testing import assert_allclose", "import pandas as pd", "import pytest", "from statsmodels.datasets import co2", "from statsmodels.tsa.seasonal import STL, DecomposeResult"], "code": "def test_pickle(default_kwargs):\n    (class_kwargs, outer, inner) = _to_class_kwargs(default_kwargs)\n    mod = STL(**class_kwargs)\n    res = mod.fit()\n    pkl = pickle.dumps(mod)\n    reloaded = pickle.loads(pkl)\n    res2 = reloaded.fit()\n    assert_allclose(res.trend, res2.trend)\n    assert_allclose(res.seasonal, res2.seasonal)\n    assert (mod.config == reloaded.config)", "masked_code": "def test_pickle(default_kwargs):\n    (class_kwargs, outer, inner) = _to_class_kwargs(default_kwargs)\n    mod = STL(**class_kwargs)\n    res = mod.fit()\n    pkl = pickle.dumps(mod)\n    reloaded = pickle.loads(pkl)\n    res2 = reloaded.fit()\n    assert_allclose(res.trend, res2.trend)\n    assert_allclose(res.seasonal, res2.seasonal)\n    assert (mod.config == '???')", "ground_truth": "reloaded.config", "quality_analysis": {"complexity_score": 4, "left_complexity": 2, "right_complexity": 2, "is_quality": true, "reason": "High quality assertion"}, "classname": null}
{"task_id": "statsmodels_158", "reponame": "statsmodels", "testpath": "statsmodels/treatment/tests/test_teffects.py", "testname": "test_teffects.py", "funcname": "test_aux", "imports": ["import os", "import numpy as np", "from numpy.testing import assert_allclose", "import pandas as pd", "import pytest", "from statsmodels.regression.linear_model import OLS", "from statsmodels.discrete.discrete_model import Probit", "from statsmodels.treatment.treatment_effects import TreatmentEffect", "from .results import results_teffects as res_st"], "code": "def test_aux(self):\n    prob = res_probit.predict()\n    assert (prob.shape == (4642,))", "masked_code": "def test_aux(self):\n    prob = res_probit.predict()\n    assert (prob.shape == '???')", "ground_truth": "(4642,)", "quality_analysis": {"complexity_score": 5, "left_complexity": 2, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}, "classname": "TestTEffects"}
{"task_id": "statsmodels_192", "reponame": "statsmodels", "testpath": "statsmodels/tsa/forecasting/tests/test_theta.py", "testname": "test_theta.py", "funcname": "test_auto", "imports": ["from itertools import product", "import numpy as np", "import pandas as pd", "import pytest", "from statsmodels.tsa.forecasting.theta import ThetaModel"], "code": "def test_auto(reset_randomstate):\n    m = 250\n    e = np.random.standard_normal(m)\n    s = (10 * np.sin(np.linspace(0, np.pi, 12)))\n    s = np.tile(s, ((m // 12) + 1))[:m]\n    idx = pd.period_range('2000-01-01', freq='M', periods=m)\n    x = (e + s)\n    y = pd.DataFrame(((10 + x) - x.min()), index=idx)\n    tm = ThetaModel(y, method='auto')\n    assert (tm.method == 'mul')\n    res = tm.fit()\n    tm = ThetaModel(y, method='mul')\n    assert (tm.method == 'mul')\n    res2 = tm.fit()\n    np.testing.assert_allclose(res.params, res2.params)\n    tm = ThetaModel((y - y.mean()), method='auto')\n    assert (tm.method == 'add')\n    res3 = tm.fit()\n    assert (not np.allclose(res.params, res3.params))", "masked_code": "def test_auto(reset_randomstate):\n    m = 250\n    e = np.random.standard_normal(m)\n    s = (10 * np.sin(np.linspace(0, np.pi, 12)))\n    s = np.tile(s, ((m // 12) + 1))[:m]\n    idx = pd.period_range('2000-01-01', freq='M', periods=m)\n    x = (e + s)\n    y = pd.DataFrame(((10 + x) - x.min()), index=idx)\n    tm = ThetaModel(y, method='auto')\n    assert (tm.method == '???')\n    res = tm.fit()\n    tm = ThetaModel(y, method='mul')\n    assert (tm.method == 'mul')\n    res2 = tm.fit()\n    np.testing.assert_allclose(res.params, res2.params)\n    tm = ThetaModel((y - y.mean()), method='auto')\n    assert (tm.method == 'add')\n    res3 = tm.fit()\n    assert (not np.allclose(res.params, res3.params))", "ground_truth": "'mul'", "quality_analysis": {"complexity_score": 3, "left_complexity": 2, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}, "classname": null}
{"task_id": "statsmodels_193", "reponame": "statsmodels", "testpath": "statsmodels/tsa/forecasting/tests/test_theta.py", "testname": "test_theta.py", "funcname": "test_auto", "imports": ["from itertools import product", "import numpy as np", "import pandas as pd", "import pytest", "from statsmodels.tsa.forecasting.theta import ThetaModel"], "code": "def test_auto(reset_randomstate):\n    m = 250\n    e = np.random.standard_normal(m)\n    s = (10 * np.sin(np.linspace(0, np.pi, 12)))\n    s = np.tile(s, ((m // 12) + 1))[:m]\n    idx = pd.period_range('2000-01-01', freq='M', periods=m)\n    x = (e + s)\n    y = pd.DataFrame(((10 + x) - x.min()), index=idx)\n    tm = ThetaModel(y, method='auto')\n    assert (tm.method == 'mul')\n    res = tm.fit()\n    tm = ThetaModel(y, method='mul')\n    assert (tm.method == 'mul')\n    res2 = tm.fit()\n    np.testing.assert_allclose(res.params, res2.params)\n    tm = ThetaModel((y - y.mean()), method='auto')\n    assert (tm.method == 'add')\n    res3 = tm.fit()\n    assert (not np.allclose(res.params, res3.params))", "masked_code": "def test_auto(reset_randomstate):\n    m = 250\n    e = np.random.standard_normal(m)\n    s = (10 * np.sin(np.linspace(0, np.pi, 12)))\n    s = np.tile(s, ((m // 12) + 1))[:m]\n    idx = pd.period_range('2000-01-01', freq='M', periods=m)\n    x = (e + s)\n    y = pd.DataFrame(((10 + x) - x.min()), index=idx)\n    tm = ThetaModel(y, method='auto')\n    assert (tm.method == 'mul')\n    res = tm.fit()\n    tm = ThetaModel(y, method='mul')\n    assert (tm.method == '???')\n    res2 = tm.fit()\n    np.testing.assert_allclose(res.params, res2.params)\n    tm = ThetaModel((y - y.mean()), method='auto')\n    assert (tm.method == 'add')\n    res3 = tm.fit()\n    assert (not np.allclose(res.params, res3.params))", "ground_truth": "'mul'", "quality_analysis": {"complexity_score": 3, "left_complexity": 2, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}, "classname": null}
{"task_id": "statsmodels_194", "reponame": "statsmodels", "testpath": "statsmodels/tsa/forecasting/tests/test_theta.py", "testname": "test_theta.py", "funcname": "test_auto", "imports": ["from itertools import product", "import numpy as np", "import pandas as pd", "import pytest", "from statsmodels.tsa.forecasting.theta import ThetaModel"], "code": "def test_auto(reset_randomstate):\n    m = 250\n    e = np.random.standard_normal(m)\n    s = (10 * np.sin(np.linspace(0, np.pi, 12)))\n    s = np.tile(s, ((m // 12) + 1))[:m]\n    idx = pd.period_range('2000-01-01', freq='M', periods=m)\n    x = (e + s)\n    y = pd.DataFrame(((10 + x) - x.min()), index=idx)\n    tm = ThetaModel(y, method='auto')\n    assert (tm.method == 'mul')\n    res = tm.fit()\n    tm = ThetaModel(y, method='mul')\n    assert (tm.method == 'mul')\n    res2 = tm.fit()\n    np.testing.assert_allclose(res.params, res2.params)\n    tm = ThetaModel((y - y.mean()), method='auto')\n    assert (tm.method == 'add')\n    res3 = tm.fit()\n    assert (not np.allclose(res.params, res3.params))", "masked_code": "def test_auto(reset_randomstate):\n    m = 250\n    e = np.random.standard_normal(m)\n    s = (10 * np.sin(np.linspace(0, np.pi, 12)))\n    s = np.tile(s, ((m // 12) + 1))[:m]\n    idx = pd.period_range('2000-01-01', freq='M', periods=m)\n    x = (e + s)\n    y = pd.DataFrame(((10 + x) - x.min()), index=idx)\n    tm = ThetaModel(y, method='auto')\n    assert (tm.method == 'mul')\n    res = tm.fit()\n    tm = ThetaModel(y, method='mul')\n    assert (tm.method == 'mul')\n    res2 = tm.fit()\n    np.testing.assert_allclose(res.params, res2.params)\n    tm = ThetaModel((y - y.mean()), method='auto')\n    assert (tm.method == '???')\n    res3 = tm.fit()\n    assert (not np.allclose(res.params, res3.params))", "ground_truth": "'add'", "quality_analysis": {"complexity_score": 3, "left_complexity": 2, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}, "classname": null}
{"task_id": "statsmodels_273", "reponame": "statsmodels", "testpath": "statsmodels/tsa/tests/test_tsa_tools.py", "testname": "test_tsa_tools.py", "funcname": "test_range_index_columns", "imports": ["from statsmodels.compat.pandas import PD_LT_2_2_0, QUARTER_END, YEAR_END, assert_frame_equal, assert_series_equal", "import numpy as np", "from numpy.testing import assert_array_almost_equal, assert_array_equal, assert_equal, assert_raises", "import pandas as pd", "from pandas.tseries.frequencies import to_offset", "import pytest", "from statsmodels import regression", "from statsmodels.datasets import macrodata", "from statsmodels.tsa import stattools", "from statsmodels.tsa.tests.results import savedrvs", "from statsmodels.tsa.tests.results.datamlw_tls import mlacf, mlccf, mlpacf, mlywar", "import statsmodels.tsa.tsatools as tools", "from statsmodels.tsa.tsatools import vec, vech"], "code": "def test_range_index_columns(self):\n    df = pd.DataFrame(np.arange(200).reshape(((- 1), 2)))\n    df.columns = pd.RangeIndex(2)\n    result = stattools.lagmat(df, maxlag=2, use_pandas=True)\n    assert (result.shape == (100, 4))\n    assert (list(result.columns) == ['0.L.1', '1.L.1', '0.L.2', '1.L.2'])", "masked_code": "def test_range_index_columns(self):\n    df = pd.DataFrame(np.arange(200).reshape(((- 1), 2)))\n    df.columns = pd.RangeIndex(2)\n    result = stattools.lagmat(df, maxlag=2, use_pandas=True)\n    assert (result.shape == '???')\n    assert (list(result.columns) == ['0.L.1', '1.L.1', '0.L.2', '1.L.2'])", "ground_truth": "(100, 4)", "quality_analysis": {"complexity_score": 6, "left_complexity": 2, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}, "classname": "TestLagmat"}
{"task_id": "statsmodels_274", "reponame": "statsmodels", "testpath": "statsmodels/tsa/tests/test_tsa_tools.py", "testname": "test_tsa_tools.py", "funcname": "test_range_index_columns", "imports": ["from statsmodels.compat.pandas import PD_LT_2_2_0, QUARTER_END, YEAR_END, assert_frame_equal, assert_series_equal", "import numpy as np", "from numpy.testing import assert_array_almost_equal, assert_array_equal, assert_equal, assert_raises", "import pandas as pd", "from pandas.tseries.frequencies import to_offset", "import pytest", "from statsmodels import regression", "from statsmodels.datasets import macrodata", "from statsmodels.tsa import stattools", "from statsmodels.tsa.tests.results import savedrvs", "from statsmodels.tsa.tests.results.datamlw_tls import mlacf, mlccf, mlpacf, mlywar", "import statsmodels.tsa.tsatools as tools", "from statsmodels.tsa.tsatools import vec, vech"], "code": "def test_range_index_columns(self):\n    df = pd.DataFrame(np.arange(200).reshape(((- 1), 2)))\n    df.columns = pd.RangeIndex(2)\n    result = stattools.lagmat(df, maxlag=2, use_pandas=True)\n    assert (result.shape == (100, 4))\n    assert (list(result.columns) == ['0.L.1', '1.L.1', '0.L.2', '1.L.2'])", "masked_code": "def test_range_index_columns(self):\n    df = pd.DataFrame(np.arange(200).reshape(((- 1), 2)))\n    df.columns = pd.RangeIndex(2)\n    result = stattools.lagmat(df, maxlag=2, use_pandas=True)\n    assert (result.shape == (100, 4))\n    assert (list(result.columns) == '???')", "ground_truth": "['0.L.1', '1.L.1', '0.L.2', '1.L.2']", "quality_analysis": {"complexity_score": 11, "left_complexity": 5, "right_complexity": 6, "is_quality": true, "reason": "High quality assertion"}, "classname": "TestLagmat"}
{"task_id": "statsmodels_138", "reponame": "statsmodels", "testpath": "statsmodels/tools/validation/tests/test_validation.py", "testname": "test_validation.py", "funcname": "test_1d", "imports": ["from collections import OrderedDict", "import numpy as np", "import pandas as pd", "import pytest", "from statsmodels.tools.validation import array_like, PandasWrapper, bool_like, dict_like, float_like, int_like, string_like", "from statsmodels.tools.validation.validation import _right_squeeze"], "code": "def test_1d(self, use_pandas):\n    data = gen_data(1, use_pandas)\n    a = array_like(data, 'a')\n    assert (a.ndim == 1)\n    assert (a.shape == (10,))\n    assert (type(a) is np.ndarray)\n    a = array_like(data, 'a', ndim=1)\n    assert (a.ndim == 1)\n    a = array_like(data, 'a', shape=(10,))\n    assert (a.shape == (10,))\n    a = array_like(data, 'a', ndim=1, shape=(None,))\n    assert (a.ndim == 1)\n    a = array_like(data, 'a', ndim=2, shape=(10, 1))\n    assert (a.ndim == 2)\n    assert (a.shape == (10, 1))\n    with pytest.raises(ValueError, match='a is required to have shape'):\n        array_like(data, 'a', shape=(5,))", "masked_code": "def test_1d(self, use_pandas):\n    data = gen_data(1, use_pandas)\n    a = array_like(data, 'a')\n    assert (a.ndim == 1)\n    assert (a.shape == '???')\n    assert (type(a) is np.ndarray)\n    a = array_like(data, 'a', ndim=1)\n    assert (a.ndim == 1)\n    a = array_like(data, 'a', shape=(10,))\n    assert (a.shape == (10,))\n    a = array_like(data, 'a', ndim=1, shape=(None,))\n    assert (a.ndim == 1)\n    a = array_like(data, 'a', ndim=2, shape=(10, 1))\n    assert (a.ndim == 2)\n    assert (a.shape == (10, 1))\n    with pytest.raises(ValueError, match='a is required to have shape'):\n        array_like(data, 'a', shape=(5,))", "ground_truth": "(10,)", "quality_analysis": {"complexity_score": 5, "left_complexity": 2, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}, "classname": "TestArrayLike"}
{"task_id": "statsmodels_139", "reponame": "statsmodels", "testpath": "statsmodels/tools/validation/tests/test_validation.py", "testname": "test_validation.py", "funcname": "test_1d", "imports": ["from collections import OrderedDict", "import numpy as np", "import pandas as pd", "import pytest", "from statsmodels.tools.validation import array_like, PandasWrapper, bool_like, dict_like, float_like, int_like, string_like", "from statsmodels.tools.validation.validation import _right_squeeze"], "code": "def test_1d(self, use_pandas):\n    data = gen_data(1, use_pandas)\n    a = array_like(data, 'a')\n    assert (a.ndim == 1)\n    assert (a.shape == (10,))\n    assert (type(a) is np.ndarray)\n    a = array_like(data, 'a', ndim=1)\n    assert (a.ndim == 1)\n    a = array_like(data, 'a', shape=(10,))\n    assert (a.shape == (10,))\n    a = array_like(data, 'a', ndim=1, shape=(None,))\n    assert (a.ndim == 1)\n    a = array_like(data, 'a', ndim=2, shape=(10, 1))\n    assert (a.ndim == 2)\n    assert (a.shape == (10, 1))\n    with pytest.raises(ValueError, match='a is required to have shape'):\n        array_like(data, 'a', shape=(5,))", "masked_code": "def test_1d(self, use_pandas):\n    data = gen_data(1, use_pandas)\n    a = array_like(data, 'a')\n    assert (a.ndim == 1)\n    assert (a.shape == (10,))\n    assert (type(a) is np.ndarray)\n    a = array_like(data, 'a', ndim=1)\n    assert (a.ndim == 1)\n    a = array_like(data, 'a', shape=(10,))\n    assert (a.shape == '???')\n    a = array_like(data, 'a', ndim=1, shape=(None,))\n    assert (a.ndim == 1)\n    a = array_like(data, 'a', ndim=2, shape=(10, 1))\n    assert (a.ndim == 2)\n    assert (a.shape == (10, 1))\n    with pytest.raises(ValueError, match='a is required to have shape'):\n        array_like(data, 'a', shape=(5,))", "ground_truth": "(10,)", "quality_analysis": {"complexity_score": 5, "left_complexity": 2, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}, "classname": "TestArrayLike"}
{"task_id": "statsmodels_140", "reponame": "statsmodels", "testpath": "statsmodels/tools/validation/tests/test_validation.py", "testname": "test_validation.py", "funcname": "test_1d", "imports": ["from collections import OrderedDict", "import numpy as np", "import pandas as pd", "import pytest", "from statsmodels.tools.validation import array_like, PandasWrapper, bool_like, dict_like, float_like, int_like, string_like", "from statsmodels.tools.validation.validation import _right_squeeze"], "code": "def test_1d(self, use_pandas):\n    data = gen_data(1, use_pandas)\n    a = array_like(data, 'a')\n    assert (a.ndim == 1)\n    assert (a.shape == (10,))\n    assert (type(a) is np.ndarray)\n    a = array_like(data, 'a', ndim=1)\n    assert (a.ndim == 1)\n    a = array_like(data, 'a', shape=(10,))\n    assert (a.shape == (10,))\n    a = array_like(data, 'a', ndim=1, shape=(None,))\n    assert (a.ndim == 1)\n    a = array_like(data, 'a', ndim=2, shape=(10, 1))\n    assert (a.ndim == 2)\n    assert (a.shape == (10, 1))\n    with pytest.raises(ValueError, match='a is required to have shape'):\n        array_like(data, 'a', shape=(5,))", "masked_code": "def test_1d(self, use_pandas):\n    data = gen_data(1, use_pandas)\n    a = array_like(data, 'a')\n    assert (a.ndim == 1)\n    assert (a.shape == (10,))\n    assert (type(a) is np.ndarray)\n    a = array_like(data, 'a', ndim=1)\n    assert (a.ndim == 1)\n    a = array_like(data, 'a', shape=(10,))\n    assert (a.shape == (10,))\n    a = array_like(data, 'a', ndim=1, shape=(None,))\n    assert (a.ndim == 1)\n    a = array_like(data, 'a', ndim=2, shape=(10, 1))\n    assert (a.ndim == 2)\n    assert (a.shape == '???')\n    with pytest.raises(ValueError, match='a is required to have shape'):\n        array_like(data, 'a', shape=(5,))", "ground_truth": "(10, 1)", "quality_analysis": {"complexity_score": 6, "left_complexity": 2, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}, "classname": "TestArrayLike"}
{"task_id": "statsmodels_141", "reponame": "statsmodels", "testpath": "statsmodels/tools/validation/tests/test_validation.py", "testname": "test_validation.py", "funcname": "test_2d", "imports": ["from collections import OrderedDict", "import numpy as np", "import pandas as pd", "import pytest", "from statsmodels.tools.validation import array_like, PandasWrapper, bool_like, dict_like, float_like, int_like, string_like", "from statsmodels.tools.validation.validation import _right_squeeze"], "code": "def test_2d(self, use_pandas):\n    data = gen_data(2, use_pandas)\n    a = array_like(data, 'a', ndim=2)\n    assert (a.ndim == 2)\n    assert (a.shape == (20, 10))\n    assert (type(a) is np.ndarray)\n    a = array_like(data, 'a', ndim=2)\n    assert (a.ndim == 2)\n    a = array_like(data, 'a', ndim=2, shape=(20, None))\n    assert (a.shape == (20, 10))\n    a = array_like(data, 'a', ndim=2, shape=(20,))\n    assert (a.shape == (20, 10))\n    a = array_like(data, 'a', ndim=2, shape=(None, 10))\n    assert (a.shape == (20, 10))\n    a = array_like(data, 'a', ndim=2, shape=(None, None))\n    assert (a.ndim == 2)\n    a = array_like(data, 'a', ndim=3)\n    assert (a.ndim == 3)\n    assert (a.shape == (20, 10, 1))\n    with pytest.raises(ValueError, match='a is required to have shape'):\n        array_like(data, 'a', ndim=2, shape=(10,))\n    with pytest.raises(ValueError, match='a is required to have shape'):\n        array_like(data, 'a', ndim=2, shape=(20, 20))\n    with pytest.raises(ValueError, match='a is required to have shape'):\n        array_like(data, 'a', ndim=2, shape=(None, 20))\n    match = 'a is required to have ndim 1 but has ndim 2'\n    with pytest.raises(ValueError, match=match):\n        array_like(data, 'a', ndim=1)\n    match = 'a must have ndim <= 1'\n    with pytest.raises(ValueError, match=match):\n        array_like(data, 'a', maxdim=1)", "masked_code": "def test_2d(self, use_pandas):\n    data = gen_data(2, use_pandas)\n    a = array_like(data, 'a', ndim=2)\n    assert (a.ndim == 2)\n    assert (a.shape == '???')\n    assert (type(a) is np.ndarray)\n    a = array_like(data, 'a', ndim=2)\n    assert (a.ndim == 2)\n    a = array_like(data, 'a', ndim=2, shape=(20, None))\n    assert (a.shape == (20, 10))\n    a = array_like(data, 'a', ndim=2, shape=(20,))\n    assert (a.shape == (20, 10))\n    a = array_like(data, 'a', ndim=2, shape=(None, 10))\n    assert (a.shape == (20, 10))\n    a = array_like(data, 'a', ndim=2, shape=(None, None))\n    assert (a.ndim == 2)\n    a = array_like(data, 'a', ndim=3)\n    assert (a.ndim == 3)\n    assert (a.shape == (20, 10, 1))\n    with pytest.raises(ValueError, match='a is required to have shape'):\n        array_like(data, 'a', ndim=2, shape=(10,))\n    with pytest.raises(ValueError, match='a is required to have shape'):\n        array_like(data, 'a', ndim=2, shape=(20, 20))\n    with pytest.raises(ValueError, match='a is required to have shape'):\n        array_like(data, 'a', ndim=2, shape=(None, 20))\n    match = 'a is required to have ndim 1 but has ndim 2'\n    with pytest.raises(ValueError, match=match):\n        array_like(data, 'a', ndim=1)\n    match = 'a must have ndim <= 1'\n    with pytest.raises(ValueError, match=match):\n        array_like(data, 'a', maxdim=1)", "ground_truth": "(20, 10)", "quality_analysis": {"complexity_score": 6, "left_complexity": 2, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}, "classname": "TestArrayLike"}
{"task_id": "statsmodels_142", "reponame": "statsmodels", "testpath": "statsmodels/tools/validation/tests/test_validation.py", "testname": "test_validation.py", "funcname": "test_2d", "imports": ["from collections import OrderedDict", "import numpy as np", "import pandas as pd", "import pytest", "from statsmodels.tools.validation import array_like, PandasWrapper, bool_like, dict_like, float_like, int_like, string_like", "from statsmodels.tools.validation.validation import _right_squeeze"], "code": "def test_2d(self, use_pandas):\n    data = gen_data(2, use_pandas)\n    a = array_like(data, 'a', ndim=2)\n    assert (a.ndim == 2)\n    assert (a.shape == (20, 10))\n    assert (type(a) is np.ndarray)\n    a = array_like(data, 'a', ndim=2)\n    assert (a.ndim == 2)\n    a = array_like(data, 'a', ndim=2, shape=(20, None))\n    assert (a.shape == (20, 10))\n    a = array_like(data, 'a', ndim=2, shape=(20,))\n    assert (a.shape == (20, 10))\n    a = array_like(data, 'a', ndim=2, shape=(None, 10))\n    assert (a.shape == (20, 10))\n    a = array_like(data, 'a', ndim=2, shape=(None, None))\n    assert (a.ndim == 2)\n    a = array_like(data, 'a', ndim=3)\n    assert (a.ndim == 3)\n    assert (a.shape == (20, 10, 1))\n    with pytest.raises(ValueError, match='a is required to have shape'):\n        array_like(data, 'a', ndim=2, shape=(10,))\n    with pytest.raises(ValueError, match='a is required to have shape'):\n        array_like(data, 'a', ndim=2, shape=(20, 20))\n    with pytest.raises(ValueError, match='a is required to have shape'):\n        array_like(data, 'a', ndim=2, shape=(None, 20))\n    match = 'a is required to have ndim 1 but has ndim 2'\n    with pytest.raises(ValueError, match=match):\n        array_like(data, 'a', ndim=1)\n    match = 'a must have ndim <= 1'\n    with pytest.raises(ValueError, match=match):\n        array_like(data, 'a', maxdim=1)", "masked_code": "def test_2d(self, use_pandas):\n    data = gen_data(2, use_pandas)\n    a = array_like(data, 'a', ndim=2)\n    assert (a.ndim == 2)\n    assert (a.shape == (20, 10))\n    assert (type(a) is np.ndarray)\n    a = array_like(data, 'a', ndim=2)\n    assert (a.ndim == 2)\n    a = array_like(data, 'a', ndim=2, shape=(20, None))\n    assert (a.shape == '???')\n    a = array_like(data, 'a', ndim=2, shape=(20,))\n    assert (a.shape == (20, 10))\n    a = array_like(data, 'a', ndim=2, shape=(None, 10))\n    assert (a.shape == (20, 10))\n    a = array_like(data, 'a', ndim=2, shape=(None, None))\n    assert (a.ndim == 2)\n    a = array_like(data, 'a', ndim=3)\n    assert (a.ndim == 3)\n    assert (a.shape == (20, 10, 1))\n    with pytest.raises(ValueError, match='a is required to have shape'):\n        array_like(data, 'a', ndim=2, shape=(10,))\n    with pytest.raises(ValueError, match='a is required to have shape'):\n        array_like(data, 'a', ndim=2, shape=(20, 20))\n    with pytest.raises(ValueError, match='a is required to have shape'):\n        array_like(data, 'a', ndim=2, shape=(None, 20))\n    match = 'a is required to have ndim 1 but has ndim 2'\n    with pytest.raises(ValueError, match=match):\n        array_like(data, 'a', ndim=1)\n    match = 'a must have ndim <= 1'\n    with pytest.raises(ValueError, match=match):\n        array_like(data, 'a', maxdim=1)", "ground_truth": "(20, 10)", "quality_analysis": {"complexity_score": 6, "left_complexity": 2, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}, "classname": "TestArrayLike"}
{"task_id": "statsmodels_143", "reponame": "statsmodels", "testpath": "statsmodels/tools/validation/tests/test_validation.py", "testname": "test_validation.py", "funcname": "test_2d", "imports": ["from collections import OrderedDict", "import numpy as np", "import pandas as pd", "import pytest", "from statsmodels.tools.validation import array_like, PandasWrapper, bool_like, dict_like, float_like, int_like, string_like", "from statsmodels.tools.validation.validation import _right_squeeze"], "code": "def test_2d(self, use_pandas):\n    data = gen_data(2, use_pandas)\n    a = array_like(data, 'a', ndim=2)\n    assert (a.ndim == 2)\n    assert (a.shape == (20, 10))\n    assert (type(a) is np.ndarray)\n    a = array_like(data, 'a', ndim=2)\n    assert (a.ndim == 2)\n    a = array_like(data, 'a', ndim=2, shape=(20, None))\n    assert (a.shape == (20, 10))\n    a = array_like(data, 'a', ndim=2, shape=(20,))\n    assert (a.shape == (20, 10))\n    a = array_like(data, 'a', ndim=2, shape=(None, 10))\n    assert (a.shape == (20, 10))\n    a = array_like(data, 'a', ndim=2, shape=(None, None))\n    assert (a.ndim == 2)\n    a = array_like(data, 'a', ndim=3)\n    assert (a.ndim == 3)\n    assert (a.shape == (20, 10, 1))\n    with pytest.raises(ValueError, match='a is required to have shape'):\n        array_like(data, 'a', ndim=2, shape=(10,))\n    with pytest.raises(ValueError, match='a is required to have shape'):\n        array_like(data, 'a', ndim=2, shape=(20, 20))\n    with pytest.raises(ValueError, match='a is required to have shape'):\n        array_like(data, 'a', ndim=2, shape=(None, 20))\n    match = 'a is required to have ndim 1 but has ndim 2'\n    with pytest.raises(ValueError, match=match):\n        array_like(data, 'a', ndim=1)\n    match = 'a must have ndim <= 1'\n    with pytest.raises(ValueError, match=match):\n        array_like(data, 'a', maxdim=1)", "masked_code": "def test_2d(self, use_pandas):\n    data = gen_data(2, use_pandas)\n    a = array_like(data, 'a', ndim=2)\n    assert (a.ndim == 2)\n    assert (a.shape == (20, 10))\n    assert (type(a) is np.ndarray)\n    a = array_like(data, 'a', ndim=2)\n    assert (a.ndim == 2)\n    a = array_like(data, 'a', ndim=2, shape=(20, None))\n    assert (a.shape == (20, 10))\n    a = array_like(data, 'a', ndim=2, shape=(20,))\n    assert (a.shape == '???')\n    a = array_like(data, 'a', ndim=2, shape=(None, 10))\n    assert (a.shape == (20, 10))\n    a = array_like(data, 'a', ndim=2, shape=(None, None))\n    assert (a.ndim == 2)\n    a = array_like(data, 'a', ndim=3)\n    assert (a.ndim == 3)\n    assert (a.shape == (20, 10, 1))\n    with pytest.raises(ValueError, match='a is required to have shape'):\n        array_like(data, 'a', ndim=2, shape=(10,))\n    with pytest.raises(ValueError, match='a is required to have shape'):\n        array_like(data, 'a', ndim=2, shape=(20, 20))\n    with pytest.raises(ValueError, match='a is required to have shape'):\n        array_like(data, 'a', ndim=2, shape=(None, 20))\n    match = 'a is required to have ndim 1 but has ndim 2'\n    with pytest.raises(ValueError, match=match):\n        array_like(data, 'a', ndim=1)\n    match = 'a must have ndim <= 1'\n    with pytest.raises(ValueError, match=match):\n        array_like(data, 'a', maxdim=1)", "ground_truth": "(20, 10)", "quality_analysis": {"complexity_score": 6, "left_complexity": 2, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}, "classname": "TestArrayLike"}
{"task_id": "statsmodels_144", "reponame": "statsmodels", "testpath": "statsmodels/tools/validation/tests/test_validation.py", "testname": "test_validation.py", "funcname": "test_2d", "imports": ["from collections import OrderedDict", "import numpy as np", "import pandas as pd", "import pytest", "from statsmodels.tools.validation import array_like, PandasWrapper, bool_like, dict_like, float_like, int_like, string_like", "from statsmodels.tools.validation.validation import _right_squeeze"], "code": "def test_2d(self, use_pandas):\n    data = gen_data(2, use_pandas)\n    a = array_like(data, 'a', ndim=2)\n    assert (a.ndim == 2)\n    assert (a.shape == (20, 10))\n    assert (type(a) is np.ndarray)\n    a = array_like(data, 'a', ndim=2)\n    assert (a.ndim == 2)\n    a = array_like(data, 'a', ndim=2, shape=(20, None))\n    assert (a.shape == (20, 10))\n    a = array_like(data, 'a', ndim=2, shape=(20,))\n    assert (a.shape == (20, 10))\n    a = array_like(data, 'a', ndim=2, shape=(None, 10))\n    assert (a.shape == (20, 10))\n    a = array_like(data, 'a', ndim=2, shape=(None, None))\n    assert (a.ndim == 2)\n    a = array_like(data, 'a', ndim=3)\n    assert (a.ndim == 3)\n    assert (a.shape == (20, 10, 1))\n    with pytest.raises(ValueError, match='a is required to have shape'):\n        array_like(data, 'a', ndim=2, shape=(10,))\n    with pytest.raises(ValueError, match='a is required to have shape'):\n        array_like(data, 'a', ndim=2, shape=(20, 20))\n    with pytest.raises(ValueError, match='a is required to have shape'):\n        array_like(data, 'a', ndim=2, shape=(None, 20))\n    match = 'a is required to have ndim 1 but has ndim 2'\n    with pytest.raises(ValueError, match=match):\n        array_like(data, 'a', ndim=1)\n    match = 'a must have ndim <= 1'\n    with pytest.raises(ValueError, match=match):\n        array_like(data, 'a', maxdim=1)", "masked_code": "def test_2d(self, use_pandas):\n    data = gen_data(2, use_pandas)\n    a = array_like(data, 'a', ndim=2)\n    assert (a.ndim == 2)\n    assert (a.shape == (20, 10))\n    assert (type(a) is np.ndarray)\n    a = array_like(data, 'a', ndim=2)\n    assert (a.ndim == 2)\n    a = array_like(data, 'a', ndim=2, shape=(20, None))\n    assert (a.shape == (20, 10))\n    a = array_like(data, 'a', ndim=2, shape=(20,))\n    assert (a.shape == (20, 10))\n    a = array_like(data, 'a', ndim=2, shape=(None, 10))\n    assert (a.shape == '???')\n    a = array_like(data, 'a', ndim=2, shape=(None, None))\n    assert (a.ndim == 2)\n    a = array_like(data, 'a', ndim=3)\n    assert (a.ndim == 3)\n    assert (a.shape == (20, 10, 1))\n    with pytest.raises(ValueError, match='a is required to have shape'):\n        array_like(data, 'a', ndim=2, shape=(10,))\n    with pytest.raises(ValueError, match='a is required to have shape'):\n        array_like(data, 'a', ndim=2, shape=(20, 20))\n    with pytest.raises(ValueError, match='a is required to have shape'):\n        array_like(data, 'a', ndim=2, shape=(None, 20))\n    match = 'a is required to have ndim 1 but has ndim 2'\n    with pytest.raises(ValueError, match=match):\n        array_like(data, 'a', ndim=1)\n    match = 'a must have ndim <= 1'\n    with pytest.raises(ValueError, match=match):\n        array_like(data, 'a', maxdim=1)", "ground_truth": "(20, 10)", "quality_analysis": {"complexity_score": 6, "left_complexity": 2, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}, "classname": "TestArrayLike"}
{"task_id": "statsmodels_145", "reponame": "statsmodels", "testpath": "statsmodels/tools/validation/tests/test_validation.py", "testname": "test_validation.py", "funcname": "test_2d", "imports": ["from collections import OrderedDict", "import numpy as np", "import pandas as pd", "import pytest", "from statsmodels.tools.validation import array_like, PandasWrapper, bool_like, dict_like, float_like, int_like, string_like", "from statsmodels.tools.validation.validation import _right_squeeze"], "code": "def test_2d(self, use_pandas):\n    data = gen_data(2, use_pandas)\n    a = array_like(data, 'a', ndim=2)\n    assert (a.ndim == 2)\n    assert (a.shape == (20, 10))\n    assert (type(a) is np.ndarray)\n    a = array_like(data, 'a', ndim=2)\n    assert (a.ndim == 2)\n    a = array_like(data, 'a', ndim=2, shape=(20, None))\n    assert (a.shape == (20, 10))\n    a = array_like(data, 'a', ndim=2, shape=(20,))\n    assert (a.shape == (20, 10))\n    a = array_like(data, 'a', ndim=2, shape=(None, 10))\n    assert (a.shape == (20, 10))\n    a = array_like(data, 'a', ndim=2, shape=(None, None))\n    assert (a.ndim == 2)\n    a = array_like(data, 'a', ndim=3)\n    assert (a.ndim == 3)\n    assert (a.shape == (20, 10, 1))\n    with pytest.raises(ValueError, match='a is required to have shape'):\n        array_like(data, 'a', ndim=2, shape=(10,))\n    with pytest.raises(ValueError, match='a is required to have shape'):\n        array_like(data, 'a', ndim=2, shape=(20, 20))\n    with pytest.raises(ValueError, match='a is required to have shape'):\n        array_like(data, 'a', ndim=2, shape=(None, 20))\n    match = 'a is required to have ndim 1 but has ndim 2'\n    with pytest.raises(ValueError, match=match):\n        array_like(data, 'a', ndim=1)\n    match = 'a must have ndim <= 1'\n    with pytest.raises(ValueError, match=match):\n        array_like(data, 'a', maxdim=1)", "masked_code": "def test_2d(self, use_pandas):\n    data = gen_data(2, use_pandas)\n    a = array_like(data, 'a', ndim=2)\n    assert (a.ndim == 2)\n    assert (a.shape == (20, 10))\n    assert (type(a) is np.ndarray)\n    a = array_like(data, 'a', ndim=2)\n    assert (a.ndim == 2)\n    a = array_like(data, 'a', ndim=2, shape=(20, None))\n    assert (a.shape == (20, 10))\n    a = array_like(data, 'a', ndim=2, shape=(20,))\n    assert (a.shape == (20, 10))\n    a = array_like(data, 'a', ndim=2, shape=(None, 10))\n    assert (a.shape == (20, 10))\n    a = array_like(data, 'a', ndim=2, shape=(None, None))\n    assert (a.ndim == 2)\n    a = array_like(data, 'a', ndim=3)\n    assert (a.ndim == '???')\n    assert (a.shape == (20, 10, 1))\n    with pytest.raises(ValueError, match='a is required to have shape'):\n        array_like(data, 'a', ndim=2, shape=(10,))\n    with pytest.raises(ValueError, match='a is required to have shape'):\n        array_like(data, 'a', ndim=2, shape=(20, 20))\n    with pytest.raises(ValueError, match='a is required to have shape'):\n        array_like(data, 'a', ndim=2, shape=(None, 20))\n    match = 'a is required to have ndim 1 but has ndim 2'\n    with pytest.raises(ValueError, match=match):\n        array_like(data, 'a', ndim=1)\n    match = 'a must have ndim <= 1'\n    with pytest.raises(ValueError, match=match):\n        array_like(data, 'a', maxdim=1)", "ground_truth": "3", "quality_analysis": {"complexity_score": 3, "left_complexity": 2, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}, "classname": "TestArrayLike"}
{"task_id": "statsmodels_146", "reponame": "statsmodels", "testpath": "statsmodels/tools/validation/tests/test_validation.py", "testname": "test_validation.py", "funcname": "test_2d", "imports": ["from collections import OrderedDict", "import numpy as np", "import pandas as pd", "import pytest", "from statsmodels.tools.validation import array_like, PandasWrapper, bool_like, dict_like, float_like, int_like, string_like", "from statsmodels.tools.validation.validation import _right_squeeze"], "code": "def test_2d(self, use_pandas):\n    data = gen_data(2, use_pandas)\n    a = array_like(data, 'a', ndim=2)\n    assert (a.ndim == 2)\n    assert (a.shape == (20, 10))\n    assert (type(a) is np.ndarray)\n    a = array_like(data, 'a', ndim=2)\n    assert (a.ndim == 2)\n    a = array_like(data, 'a', ndim=2, shape=(20, None))\n    assert (a.shape == (20, 10))\n    a = array_like(data, 'a', ndim=2, shape=(20,))\n    assert (a.shape == (20, 10))\n    a = array_like(data, 'a', ndim=2, shape=(None, 10))\n    assert (a.shape == (20, 10))\n    a = array_like(data, 'a', ndim=2, shape=(None, None))\n    assert (a.ndim == 2)\n    a = array_like(data, 'a', ndim=3)\n    assert (a.ndim == 3)\n    assert (a.shape == (20, 10, 1))\n    with pytest.raises(ValueError, match='a is required to have shape'):\n        array_like(data, 'a', ndim=2, shape=(10,))\n    with pytest.raises(ValueError, match='a is required to have shape'):\n        array_like(data, 'a', ndim=2, shape=(20, 20))\n    with pytest.raises(ValueError, match='a is required to have shape'):\n        array_like(data, 'a', ndim=2, shape=(None, 20))\n    match = 'a is required to have ndim 1 but has ndim 2'\n    with pytest.raises(ValueError, match=match):\n        array_like(data, 'a', ndim=1)\n    match = 'a must have ndim <= 1'\n    with pytest.raises(ValueError, match=match):\n        array_like(data, 'a', maxdim=1)", "masked_code": "def test_2d(self, use_pandas):\n    data = gen_data(2, use_pandas)\n    a = array_like(data, 'a', ndim=2)\n    assert (a.ndim == 2)\n    assert (a.shape == (20, 10))\n    assert (type(a) is np.ndarray)\n    a = array_like(data, 'a', ndim=2)\n    assert (a.ndim == 2)\n    a = array_like(data, 'a', ndim=2, shape=(20, None))\n    assert (a.shape == (20, 10))\n    a = array_like(data, 'a', ndim=2, shape=(20,))\n    assert (a.shape == (20, 10))\n    a = array_like(data, 'a', ndim=2, shape=(None, 10))\n    assert (a.shape == (20, 10))\n    a = array_like(data, 'a', ndim=2, shape=(None, None))\n    assert (a.ndim == 2)\n    a = array_like(data, 'a', ndim=3)\n    assert (a.ndim == 3)\n    assert (a.shape == '???')\n    with pytest.raises(ValueError, match='a is required to have shape'):\n        array_like(data, 'a', ndim=2, shape=(10,))\n    with pytest.raises(ValueError, match='a is required to have shape'):\n        array_like(data, 'a', ndim=2, shape=(20, 20))\n    with pytest.raises(ValueError, match='a is required to have shape'):\n        array_like(data, 'a', ndim=2, shape=(None, 20))\n    match = 'a is required to have ndim 1 but has ndim 2'\n    with pytest.raises(ValueError, match=match):\n        array_like(data, 'a', ndim=1)\n    match = 'a must have ndim <= 1'\n    with pytest.raises(ValueError, match=match):\n        array_like(data, 'a', maxdim=1)", "ground_truth": "(20, 10, 1)", "quality_analysis": {"complexity_score": 7, "left_complexity": 2, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}, "classname": "TestArrayLike"}
{"task_id": "statsmodels_147", "reponame": "statsmodels", "testpath": "statsmodels/tools/validation/tests/test_validation.py", "testname": "test_validation.py", "funcname": "test_3d", "imports": ["from collections import OrderedDict", "import numpy as np", "import pandas as pd", "import pytest", "from statsmodels.tools.validation import array_like, PandasWrapper, bool_like, dict_like, float_like, int_like, string_like", "from statsmodels.tools.validation.validation import _right_squeeze"], "code": "def test_3d(self):\n    data = gen_data(3, False)\n    a = array_like(data, 'a', ndim=3)\n    assert (a.shape == (5, 6, 7))\n    assert (a.ndim == 3)\n    assert (type(a) is np.ndarray)\n    a = array_like(data, 'a', ndim=3, shape=(5, None, 7))\n    assert (a.shape == (5, 6, 7))\n    a = array_like(data, 'a', ndim=3, shape=(None, None, 7))\n    assert (a.shape == (5, 6, 7))\n    a = array_like(data, 'a', ndim=5)\n    assert (a.shape == (5, 6, 7, 1, 1))\n    with pytest.raises(ValueError, match='a is required to have shape'):\n        array_like(data, 'a', ndim=3, shape=(10,))\n    with pytest.raises(ValueError, match='a is required to have shape'):\n        array_like(data, 'a', ndim=3, shape=(None, None, 5))\n    match = 'a is required to have ndim 2 but has ndim 3'\n    with pytest.raises(ValueError, match=match):\n        array_like(data, 'a', ndim=2)\n    match = 'a must have ndim <= 1'\n    with pytest.raises(ValueError, match=match):\n        array_like(data, 'a', maxdim=1)\n    match = 'a must have ndim <= 2'\n    with pytest.raises(ValueError, match=match):\n        array_like(data, 'a', maxdim=2)", "masked_code": "def test_3d(self):\n    data = gen_data(3, False)\n    a = array_like(data, 'a', ndim=3)\n    assert (a.shape == '???')\n    assert (a.ndim == 3)\n    assert (type(a) is np.ndarray)\n    a = array_like(data, 'a', ndim=3, shape=(5, None, 7))\n    assert (a.shape == (5, 6, 7))\n    a = array_like(data, 'a', ndim=3, shape=(None, None, 7))\n    assert (a.shape == (5, 6, 7))\n    a = array_like(data, 'a', ndim=5)\n    assert (a.shape == (5, 6, 7, 1, 1))\n    with pytest.raises(ValueError, match='a is required to have shape'):\n        array_like(data, 'a', ndim=3, shape=(10,))\n    with pytest.raises(ValueError, match='a is required to have shape'):\n        array_like(data, 'a', ndim=3, shape=(None, None, 5))\n    match = 'a is required to have ndim 2 but has ndim 3'\n    with pytest.raises(ValueError, match=match):\n        array_like(data, 'a', ndim=2)\n    match = 'a must have ndim <= 1'\n    with pytest.raises(ValueError, match=match):\n        array_like(data, 'a', maxdim=1)\n    match = 'a must have ndim <= 2'\n    with pytest.raises(ValueError, match=match):\n        array_like(data, 'a', maxdim=2)", "ground_truth": "(5, 6, 7)", "quality_analysis": {"complexity_score": 7, "left_complexity": 2, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}, "classname": "TestArrayLike"}
{"task_id": "statsmodels_148", "reponame": "statsmodels", "testpath": "statsmodels/tools/validation/tests/test_validation.py", "testname": "test_validation.py", "funcname": "test_3d", "imports": ["from collections import OrderedDict", "import numpy as np", "import pandas as pd", "import pytest", "from statsmodels.tools.validation import array_like, PandasWrapper, bool_like, dict_like, float_like, int_like, string_like", "from statsmodels.tools.validation.validation import _right_squeeze"], "code": "def test_3d(self):\n    data = gen_data(3, False)\n    a = array_like(data, 'a', ndim=3)\n    assert (a.shape == (5, 6, 7))\n    assert (a.ndim == 3)\n    assert (type(a) is np.ndarray)\n    a = array_like(data, 'a', ndim=3, shape=(5, None, 7))\n    assert (a.shape == (5, 6, 7))\n    a = array_like(data, 'a', ndim=3, shape=(None, None, 7))\n    assert (a.shape == (5, 6, 7))\n    a = array_like(data, 'a', ndim=5)\n    assert (a.shape == (5, 6, 7, 1, 1))\n    with pytest.raises(ValueError, match='a is required to have shape'):\n        array_like(data, 'a', ndim=3, shape=(10,))\n    with pytest.raises(ValueError, match='a is required to have shape'):\n        array_like(data, 'a', ndim=3, shape=(None, None, 5))\n    match = 'a is required to have ndim 2 but has ndim 3'\n    with pytest.raises(ValueError, match=match):\n        array_like(data, 'a', ndim=2)\n    match = 'a must have ndim <= 1'\n    with pytest.raises(ValueError, match=match):\n        array_like(data, 'a', maxdim=1)\n    match = 'a must have ndim <= 2'\n    with pytest.raises(ValueError, match=match):\n        array_like(data, 'a', maxdim=2)", "masked_code": "def test_3d(self):\n    data = gen_data(3, False)\n    a = array_like(data, 'a', ndim=3)\n    assert (a.shape == (5, 6, 7))\n    assert (a.ndim == '???')\n    assert (type(a) is np.ndarray)\n    a = array_like(data, 'a', ndim=3, shape=(5, None, 7))\n    assert (a.shape == (5, 6, 7))\n    a = array_like(data, 'a', ndim=3, shape=(None, None, 7))\n    assert (a.shape == (5, 6, 7))\n    a = array_like(data, 'a', ndim=5)\n    assert (a.shape == (5, 6, 7, 1, 1))\n    with pytest.raises(ValueError, match='a is required to have shape'):\n        array_like(data, 'a', ndim=3, shape=(10,))\n    with pytest.raises(ValueError, match='a is required to have shape'):\n        array_like(data, 'a', ndim=3, shape=(None, None, 5))\n    match = 'a is required to have ndim 2 but has ndim 3'\n    with pytest.raises(ValueError, match=match):\n        array_like(data, 'a', ndim=2)\n    match = 'a must have ndim <= 1'\n    with pytest.raises(ValueError, match=match):\n        array_like(data, 'a', maxdim=1)\n    match = 'a must have ndim <= 2'\n    with pytest.raises(ValueError, match=match):\n        array_like(data, 'a', maxdim=2)", "ground_truth": "3", "quality_analysis": {"complexity_score": 3, "left_complexity": 2, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}, "classname": "TestArrayLike"}
{"task_id": "statsmodels_149", "reponame": "statsmodels", "testpath": "statsmodels/tools/validation/tests/test_validation.py", "testname": "test_validation.py", "funcname": "test_3d", "imports": ["from collections import OrderedDict", "import numpy as np", "import pandas as pd", "import pytest", "from statsmodels.tools.validation import array_like, PandasWrapper, bool_like, dict_like, float_like, int_like, string_like", "from statsmodels.tools.validation.validation import _right_squeeze"], "code": "def test_3d(self):\n    data = gen_data(3, False)\n    a = array_like(data, 'a', ndim=3)\n    assert (a.shape == (5, 6, 7))\n    assert (a.ndim == 3)\n    assert (type(a) is np.ndarray)\n    a = array_like(data, 'a', ndim=3, shape=(5, None, 7))\n    assert (a.shape == (5, 6, 7))\n    a = array_like(data, 'a', ndim=3, shape=(None, None, 7))\n    assert (a.shape == (5, 6, 7))\n    a = array_like(data, 'a', ndim=5)\n    assert (a.shape == (5, 6, 7, 1, 1))\n    with pytest.raises(ValueError, match='a is required to have shape'):\n        array_like(data, 'a', ndim=3, shape=(10,))\n    with pytest.raises(ValueError, match='a is required to have shape'):\n        array_like(data, 'a', ndim=3, shape=(None, None, 5))\n    match = 'a is required to have ndim 2 but has ndim 3'\n    with pytest.raises(ValueError, match=match):\n        array_like(data, 'a', ndim=2)\n    match = 'a must have ndim <= 1'\n    with pytest.raises(ValueError, match=match):\n        array_like(data, 'a', maxdim=1)\n    match = 'a must have ndim <= 2'\n    with pytest.raises(ValueError, match=match):\n        array_like(data, 'a', maxdim=2)", "masked_code": "def test_3d(self):\n    data = gen_data(3, False)\n    a = array_like(data, 'a', ndim=3)\n    assert (a.shape == (5, 6, 7))\n    assert (a.ndim == 3)\n    assert (type(a) is np.ndarray)\n    a = array_like(data, 'a', ndim=3, shape=(5, None, 7))\n    assert (a.shape == '???')\n    a = array_like(data, 'a', ndim=3, shape=(None, None, 7))\n    assert (a.shape == (5, 6, 7))\n    a = array_like(data, 'a', ndim=5)\n    assert (a.shape == (5, 6, 7, 1, 1))\n    with pytest.raises(ValueError, match='a is required to have shape'):\n        array_like(data, 'a', ndim=3, shape=(10,))\n    with pytest.raises(ValueError, match='a is required to have shape'):\n        array_like(data, 'a', ndim=3, shape=(None, None, 5))\n    match = 'a is required to have ndim 2 but has ndim 3'\n    with pytest.raises(ValueError, match=match):\n        array_like(data, 'a', ndim=2)\n    match = 'a must have ndim <= 1'\n    with pytest.raises(ValueError, match=match):\n        array_like(data, 'a', maxdim=1)\n    match = 'a must have ndim <= 2'\n    with pytest.raises(ValueError, match=match):\n        array_like(data, 'a', maxdim=2)", "ground_truth": "(5, 6, 7)", "quality_analysis": {"complexity_score": 7, "left_complexity": 2, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}, "classname": "TestArrayLike"}
{"task_id": "statsmodels_150", "reponame": "statsmodels", "testpath": "statsmodels/tools/validation/tests/test_validation.py", "testname": "test_validation.py", "funcname": "test_3d", "imports": ["from collections import OrderedDict", "import numpy as np", "import pandas as pd", "import pytest", "from statsmodels.tools.validation import array_like, PandasWrapper, bool_like, dict_like, float_like, int_like, string_like", "from statsmodels.tools.validation.validation import _right_squeeze"], "code": "def test_3d(self):\n    data = gen_data(3, False)\n    a = array_like(data, 'a', ndim=3)\n    assert (a.shape == (5, 6, 7))\n    assert (a.ndim == 3)\n    assert (type(a) is np.ndarray)\n    a = array_like(data, 'a', ndim=3, shape=(5, None, 7))\n    assert (a.shape == (5, 6, 7))\n    a = array_like(data, 'a', ndim=3, shape=(None, None, 7))\n    assert (a.shape == (5, 6, 7))\n    a = array_like(data, 'a', ndim=5)\n    assert (a.shape == (5, 6, 7, 1, 1))\n    with pytest.raises(ValueError, match='a is required to have shape'):\n        array_like(data, 'a', ndim=3, shape=(10,))\n    with pytest.raises(ValueError, match='a is required to have shape'):\n        array_like(data, 'a', ndim=3, shape=(None, None, 5))\n    match = 'a is required to have ndim 2 but has ndim 3'\n    with pytest.raises(ValueError, match=match):\n        array_like(data, 'a', ndim=2)\n    match = 'a must have ndim <= 1'\n    with pytest.raises(ValueError, match=match):\n        array_like(data, 'a', maxdim=1)\n    match = 'a must have ndim <= 2'\n    with pytest.raises(ValueError, match=match):\n        array_like(data, 'a', maxdim=2)", "masked_code": "def test_3d(self):\n    data = gen_data(3, False)\n    a = array_like(data, 'a', ndim=3)\n    assert (a.shape == (5, 6, 7))\n    assert (a.ndim == 3)\n    assert (type(a) is np.ndarray)\n    a = array_like(data, 'a', ndim=3, shape=(5, None, 7))\n    assert (a.shape == (5, 6, 7))\n    a = array_like(data, 'a', ndim=3, shape=(None, None, 7))\n    assert (a.shape == '???')\n    a = array_like(data, 'a', ndim=5)\n    assert (a.shape == (5, 6, 7, 1, 1))\n    with pytest.raises(ValueError, match='a is required to have shape'):\n        array_like(data, 'a', ndim=3, shape=(10,))\n    with pytest.raises(ValueError, match='a is required to have shape'):\n        array_like(data, 'a', ndim=3, shape=(None, None, 5))\n    match = 'a is required to have ndim 2 but has ndim 3'\n    with pytest.raises(ValueError, match=match):\n        array_like(data, 'a', ndim=2)\n    match = 'a must have ndim <= 1'\n    with pytest.raises(ValueError, match=match):\n        array_like(data, 'a', maxdim=1)\n    match = 'a must have ndim <= 2'\n    with pytest.raises(ValueError, match=match):\n        array_like(data, 'a', maxdim=2)", "ground_truth": "(5, 6, 7)", "quality_analysis": {"complexity_score": 7, "left_complexity": 2, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}, "classname": "TestArrayLike"}
{"task_id": "statsmodels_151", "reponame": "statsmodels", "testpath": "statsmodels/tools/validation/tests/test_validation.py", "testname": "test_validation.py", "funcname": "test_3d", "imports": ["from collections import OrderedDict", "import numpy as np", "import pandas as pd", "import pytest", "from statsmodels.tools.validation import array_like, PandasWrapper, bool_like, dict_like, float_like, int_like, string_like", "from statsmodels.tools.validation.validation import _right_squeeze"], "code": "def test_3d(self):\n    data = gen_data(3, False)\n    a = array_like(data, 'a', ndim=3)\n    assert (a.shape == (5, 6, 7))\n    assert (a.ndim == 3)\n    assert (type(a) is np.ndarray)\n    a = array_like(data, 'a', ndim=3, shape=(5, None, 7))\n    assert (a.shape == (5, 6, 7))\n    a = array_like(data, 'a', ndim=3, shape=(None, None, 7))\n    assert (a.shape == (5, 6, 7))\n    a = array_like(data, 'a', ndim=5)\n    assert (a.shape == (5, 6, 7, 1, 1))\n    with pytest.raises(ValueError, match='a is required to have shape'):\n        array_like(data, 'a', ndim=3, shape=(10,))\n    with pytest.raises(ValueError, match='a is required to have shape'):\n        array_like(data, 'a', ndim=3, shape=(None, None, 5))\n    match = 'a is required to have ndim 2 but has ndim 3'\n    with pytest.raises(ValueError, match=match):\n        array_like(data, 'a', ndim=2)\n    match = 'a must have ndim <= 1'\n    with pytest.raises(ValueError, match=match):\n        array_like(data, 'a', maxdim=1)\n    match = 'a must have ndim <= 2'\n    with pytest.raises(ValueError, match=match):\n        array_like(data, 'a', maxdim=2)", "masked_code": "def test_3d(self):\n    data = gen_data(3, False)\n    a = array_like(data, 'a', ndim=3)\n    assert (a.shape == (5, 6, 7))\n    assert (a.ndim == 3)\n    assert (type(a) is np.ndarray)\n    a = array_like(data, 'a', ndim=3, shape=(5, None, 7))\n    assert (a.shape == (5, 6, 7))\n    a = array_like(data, 'a', ndim=3, shape=(None, None, 7))\n    assert (a.shape == (5, 6, 7))\n    a = array_like(data, 'a', ndim=5)\n    assert (a.shape == '???')\n    with pytest.raises(ValueError, match='a is required to have shape'):\n        array_like(data, 'a', ndim=3, shape=(10,))\n    with pytest.raises(ValueError, match='a is required to have shape'):\n        array_like(data, 'a', ndim=3, shape=(None, None, 5))\n    match = 'a is required to have ndim 2 but has ndim 3'\n    with pytest.raises(ValueError, match=match):\n        array_like(data, 'a', ndim=2)\n    match = 'a must have ndim <= 1'\n    with pytest.raises(ValueError, match=match):\n        array_like(data, 'a', maxdim=1)\n    match = 'a must have ndim <= 2'\n    with pytest.raises(ValueError, match=match):\n        array_like(data, 'a', maxdim=2)", "ground_truth": "(5, 6, 7, 1, 1)", "quality_analysis": {"complexity_score": 9, "left_complexity": 2, "right_complexity": 7, "is_quality": true, "reason": "High quality assertion"}, "classname": "TestArrayLike"}
{"task_id": "statsmodels_156", "reponame": "statsmodels", "testpath": "statsmodels/tools/validation/tests/test_validation.py", "testname": "test_validation.py", "funcname": "test_dtype", "imports": ["from collections import OrderedDict", "import numpy as np", "import pandas as pd", "import pytest", "from statsmodels.tools.validation import array_like, PandasWrapper, bool_like, dict_like, float_like, int_like, string_like", "from statsmodels.tools.validation.validation import _right_squeeze"], "code": "def test_dtype(self):\n    x = np.arange(10)\n    a = array_like(x, 'a', dtype=np.float32)\n    assert (a.dtype == np.float32)\n    a = array_like(x, 'a', dtype=np.uint8)\n    assert (a.dtype == np.uint8)", "masked_code": "def test_dtype(self):\n    x = np.arange(10)\n    a = array_like(x, 'a', dtype=np.float32)\n    assert (a.dtype == '???')\n    a = array_like(x, 'a', dtype=np.uint8)\n    assert (a.dtype == np.uint8)", "ground_truth": "np.float32", "quality_analysis": {"complexity_score": 4, "left_complexity": 2, "right_complexity": 2, "is_quality": true, "reason": "High quality assertion"}, "classname": "TestArrayLike"}
{"task_id": "statsmodels_157", "reponame": "statsmodels", "testpath": "statsmodels/tools/validation/tests/test_validation.py", "testname": "test_validation.py", "funcname": "test_dtype", "imports": ["from collections import OrderedDict", "import numpy as np", "import pandas as pd", "import pytest", "from statsmodels.tools.validation import array_like, PandasWrapper, bool_like, dict_like, float_like, int_like, string_like", "from statsmodels.tools.validation.validation import _right_squeeze"], "code": "def test_dtype(self):\n    x = np.arange(10)\n    a = array_like(x, 'a', dtype=np.float32)\n    assert (a.dtype == np.float32)\n    a = array_like(x, 'a', dtype=np.uint8)\n    assert (a.dtype == np.uint8)", "masked_code": "def test_dtype(self):\n    x = np.arange(10)\n    a = array_like(x, 'a', dtype=np.float32)\n    assert (a.dtype == np.float32)\n    a = array_like(x, 'a', dtype=np.uint8)\n    assert (a.dtype == '???')", "ground_truth": "np.uint8", "quality_analysis": {"complexity_score": 4, "left_complexity": 2, "right_complexity": 2, "is_quality": true, "reason": "High quality assertion"}, "classname": "TestArrayLike"}
{"task_id": "statsmodels_130", "reponame": "statsmodels", "testpath": "statsmodels/tools/validation/tests/test_validation.py", "testname": "test_validation.py", "funcname": "test_right_squeeze", "imports": ["from collections import OrderedDict", "import numpy as np", "import pandas as pd", "import pytest", "from statsmodels.tools.validation import array_like, PandasWrapper, bool_like, dict_like, float_like, int_like, string_like", "from statsmodels.tools.validation.validation import _right_squeeze"], "code": "def test_right_squeeze():\n    x = np.empty((10, 1, 10))\n    y = _right_squeeze(x)\n    assert (y.shape == (10, 1, 10))\n    x = np.empty((10, 10, 1))\n    y = _right_squeeze(x)\n    assert (y.shape == (10, 10))\n    x = np.empty((10, 10, 1, 1, 1, 1, 1))\n    y = _right_squeeze(x)\n    assert (y.shape == (10, 10))\n    x = np.empty((10, 1, 10, 1, 1, 1, 1, 1))\n    y = _right_squeeze(x)\n    assert (y.shape == (10, 1, 10))", "masked_code": "def test_right_squeeze():\n    x = np.empty((10, 1, 10))\n    y = _right_squeeze(x)\n    assert (y.shape == '???')\n    x = np.empty((10, 10, 1))\n    y = _right_squeeze(x)\n    assert (y.shape == (10, 10))\n    x = np.empty((10, 10, 1, 1, 1, 1, 1))\n    y = _right_squeeze(x)\n    assert (y.shape == (10, 10))\n    x = np.empty((10, 1, 10, 1, 1, 1, 1, 1))\n    y = _right_squeeze(x)\n    assert (y.shape == (10, 1, 10))", "ground_truth": "(10, 1, 10)", "quality_analysis": {"complexity_score": 7, "left_complexity": 2, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}, "classname": null}
{"task_id": "statsmodels_131", "reponame": "statsmodels", "testpath": "statsmodels/tools/validation/tests/test_validation.py", "testname": "test_validation.py", "funcname": "test_right_squeeze", "imports": ["from collections import OrderedDict", "import numpy as np", "import pandas as pd", "import pytest", "from statsmodels.tools.validation import array_like, PandasWrapper, bool_like, dict_like, float_like, int_like, string_like", "from statsmodels.tools.validation.validation import _right_squeeze"], "code": "def test_right_squeeze():\n    x = np.empty((10, 1, 10))\n    y = _right_squeeze(x)\n    assert (y.shape == (10, 1, 10))\n    x = np.empty((10, 10, 1))\n    y = _right_squeeze(x)\n    assert (y.shape == (10, 10))\n    x = np.empty((10, 10, 1, 1, 1, 1, 1))\n    y = _right_squeeze(x)\n    assert (y.shape == (10, 10))\n    x = np.empty((10, 1, 10, 1, 1, 1, 1, 1))\n    y = _right_squeeze(x)\n    assert (y.shape == (10, 1, 10))", "masked_code": "def test_right_squeeze():\n    x = np.empty((10, 1, 10))\n    y = _right_squeeze(x)\n    assert (y.shape == (10, 1, 10))\n    x = np.empty((10, 10, 1))\n    y = _right_squeeze(x)\n    assert (y.shape == '???')\n    x = np.empty((10, 10, 1, 1, 1, 1, 1))\n    y = _right_squeeze(x)\n    assert (y.shape == (10, 10))\n    x = np.empty((10, 1, 10, 1, 1, 1, 1, 1))\n    y = _right_squeeze(x)\n    assert (y.shape == (10, 1, 10))", "ground_truth": "(10, 10)", "quality_analysis": {"complexity_score": 6, "left_complexity": 2, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}, "classname": null}
{"task_id": "statsmodels_132", "reponame": "statsmodels", "testpath": "statsmodels/tools/validation/tests/test_validation.py", "testname": "test_validation.py", "funcname": "test_right_squeeze", "imports": ["from collections import OrderedDict", "import numpy as np", "import pandas as pd", "import pytest", "from statsmodels.tools.validation import array_like, PandasWrapper, bool_like, dict_like, float_like, int_like, string_like", "from statsmodels.tools.validation.validation import _right_squeeze"], "code": "def test_right_squeeze():\n    x = np.empty((10, 1, 10))\n    y = _right_squeeze(x)\n    assert (y.shape == (10, 1, 10))\n    x = np.empty((10, 10, 1))\n    y = _right_squeeze(x)\n    assert (y.shape == (10, 10))\n    x = np.empty((10, 10, 1, 1, 1, 1, 1))\n    y = _right_squeeze(x)\n    assert (y.shape == (10, 10))\n    x = np.empty((10, 1, 10, 1, 1, 1, 1, 1))\n    y = _right_squeeze(x)\n    assert (y.shape == (10, 1, 10))", "masked_code": "def test_right_squeeze():\n    x = np.empty((10, 1, 10))\n    y = _right_squeeze(x)\n    assert (y.shape == (10, 1, 10))\n    x = np.empty((10, 10, 1))\n    y = _right_squeeze(x)\n    assert (y.shape == (10, 10))\n    x = np.empty((10, 10, 1, 1, 1, 1, 1))\n    y = _right_squeeze(x)\n    assert (y.shape == '???')\n    x = np.empty((10, 1, 10, 1, 1, 1, 1, 1))\n    y = _right_squeeze(x)\n    assert (y.shape == (10, 1, 10))", "ground_truth": "(10, 10)", "quality_analysis": {"complexity_score": 6, "left_complexity": 2, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}, "classname": null}
{"task_id": "statsmodels_152", "reponame": "statsmodels", "testpath": "statsmodels/tools/validation/tests/test_validation.py", "testname": "test_validation.py", "funcname": "test_right_squeeze_and_pad", "imports": ["from collections import OrderedDict", "import numpy as np", "import pandas as pd", "import pytest", "from statsmodels.tools.validation import array_like, PandasWrapper, bool_like, dict_like, float_like, int_like, string_like", "from statsmodels.tools.validation.validation import _right_squeeze"], "code": "def test_right_squeeze_and_pad(self):\n    data = np.empty((2, 1, 2))\n    a = array_like(data, 'a', ndim=3)\n    assert (a.shape == (2, 1, 2))\n    data = np.empty(2)\n    a = array_like(data, 'a', ndim=3)\n    assert (a.shape == (2, 1, 1))\n    data = np.empty((2, 1))\n    a = array_like(data, 'a', ndim=3)\n    assert (a.shape == (2, 1, 1))\n    data = np.empty((2, 1, 1, 1))\n    a = array_like(data, 'a', ndim=3)\n    assert (a.shape == (2, 1, 1))\n    data = np.empty((2, 1, 1, 2, 1, 1))\n    with pytest.raises(ValueError):\n        array_like(data, 'a', ndim=3)", "masked_code": "def test_right_squeeze_and_pad(self):\n    data = np.empty((2, 1, 2))\n    a = array_like(data, 'a', ndim=3)\n    assert (a.shape == '???')\n    data = np.empty(2)\n    a = array_like(data, 'a', ndim=3)\n    assert (a.shape == (2, 1, 1))\n    data = np.empty((2, 1))\n    a = array_like(data, 'a', ndim=3)\n    assert (a.shape == (2, 1, 1))\n    data = np.empty((2, 1, 1, 1))\n    a = array_like(data, 'a', ndim=3)\n    assert (a.shape == (2, 1, 1))\n    data = np.empty((2, 1, 1, 2, 1, 1))\n    with pytest.raises(ValueError):\n        array_like(data, 'a', ndim=3)", "ground_truth": "(2, 1, 2)", "quality_analysis": {"complexity_score": 7, "left_complexity": 2, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}, "classname": "TestArrayLike"}
{"task_id": "statsmodels_153", "reponame": "statsmodels", "testpath": "statsmodels/tools/validation/tests/test_validation.py", "testname": "test_validation.py", "funcname": "test_right_squeeze_and_pad", "imports": ["from collections import OrderedDict", "import numpy as np", "import pandas as pd", "import pytest", "from statsmodels.tools.validation import array_like, PandasWrapper, bool_like, dict_like, float_like, int_like, string_like", "from statsmodels.tools.validation.validation import _right_squeeze"], "code": "def test_right_squeeze_and_pad(self):\n    data = np.empty((2, 1, 2))\n    a = array_like(data, 'a', ndim=3)\n    assert (a.shape == (2, 1, 2))\n    data = np.empty(2)\n    a = array_like(data, 'a', ndim=3)\n    assert (a.shape == (2, 1, 1))\n    data = np.empty((2, 1))\n    a = array_like(data, 'a', ndim=3)\n    assert (a.shape == (2, 1, 1))\n    data = np.empty((2, 1, 1, 1))\n    a = array_like(data, 'a', ndim=3)\n    assert (a.shape == (2, 1, 1))\n    data = np.empty((2, 1, 1, 2, 1, 1))\n    with pytest.raises(ValueError):\n        array_like(data, 'a', ndim=3)", "masked_code": "def test_right_squeeze_and_pad(self):\n    data = np.empty((2, 1, 2))\n    a = array_like(data, 'a', ndim=3)\n    assert (a.shape == (2, 1, 2))\n    data = np.empty(2)\n    a = array_like(data, 'a', ndim=3)\n    assert (a.shape == '???')\n    data = np.empty((2, 1))\n    a = array_like(data, 'a', ndim=3)\n    assert (a.shape == (2, 1, 1))\n    data = np.empty((2, 1, 1, 1))\n    a = array_like(data, 'a', ndim=3)\n    assert (a.shape == (2, 1, 1))\n    data = np.empty((2, 1, 1, 2, 1, 1))\n    with pytest.raises(ValueError):\n        array_like(data, 'a', ndim=3)", "ground_truth": "(2, 1, 1)", "quality_analysis": {"complexity_score": 7, "left_complexity": 2, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}, "classname": "TestArrayLike"}
{"task_id": "statsmodels_154", "reponame": "statsmodels", "testpath": "statsmodels/tools/validation/tests/test_validation.py", "testname": "test_validation.py", "funcname": "test_right_squeeze_and_pad", "imports": ["from collections import OrderedDict", "import numpy as np", "import pandas as pd", "import pytest", "from statsmodels.tools.validation import array_like, PandasWrapper, bool_like, dict_like, float_like, int_like, string_like", "from statsmodels.tools.validation.validation import _right_squeeze"], "code": "def test_right_squeeze_and_pad(self):\n    data = np.empty((2, 1, 2))\n    a = array_like(data, 'a', ndim=3)\n    assert (a.shape == (2, 1, 2))\n    data = np.empty(2)\n    a = array_like(data, 'a', ndim=3)\n    assert (a.shape == (2, 1, 1))\n    data = np.empty((2, 1))\n    a = array_like(data, 'a', ndim=3)\n    assert (a.shape == (2, 1, 1))\n    data = np.empty((2, 1, 1, 1))\n    a = array_like(data, 'a', ndim=3)\n    assert (a.shape == (2, 1, 1))\n    data = np.empty((2, 1, 1, 2, 1, 1))\n    with pytest.raises(ValueError):\n        array_like(data, 'a', ndim=3)", "masked_code": "def test_right_squeeze_and_pad(self):\n    data = np.empty((2, 1, 2))\n    a = array_like(data, 'a', ndim=3)\n    assert (a.shape == (2, 1, 2))\n    data = np.empty(2)\n    a = array_like(data, 'a', ndim=3)\n    assert (a.shape == (2, 1, 1))\n    data = np.empty((2, 1))\n    a = array_like(data, 'a', ndim=3)\n    assert (a.shape == '???')\n    data = np.empty((2, 1, 1, 1))\n    a = array_like(data, 'a', ndim=3)\n    assert (a.shape == (2, 1, 1))\n    data = np.empty((2, 1, 1, 2, 1, 1))\n    with pytest.raises(ValueError):\n        array_like(data, 'a', ndim=3)", "ground_truth": "(2, 1, 1)", "quality_analysis": {"complexity_score": 7, "left_complexity": 2, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}, "classname": "TestArrayLike"}
{"task_id": "statsmodels_134", "reponame": "statsmodels", "testpath": "statsmodels/tools/validation/tests/test_validation.py", "testname": "test_validation.py", "funcname": "test_wrap_pandas_append", "imports": ["from collections import OrderedDict", "import numpy as np", "import pandas as pd", "import pytest", "from statsmodels.tools.validation import array_like, PandasWrapper, bool_like, dict_like, float_like, int_like, string_like", "from statsmodels.tools.validation.validation import _right_squeeze"], "code": "def test_wrap_pandas_append():\n    a = gen_data(1, True)\n    a.name = 'apple'\n    b = gen_data(1, False)\n    wrapped = PandasWrapper(a).wrap(b, append='appended')\n    expected = 'apple_appended'\n    assert (wrapped.name == expected)\n    a = gen_data(2, True)\n    a.columns = [('apple_' + str(i)) for i in range(a.shape[1])]\n    b = gen_data(2, False)\n    wrapped = PandasWrapper(a).wrap(b, append='appended')\n    expected = [(c + '_appended') for c in a.columns]\n    assert (list(wrapped.columns) == expected)", "masked_code": "def test_wrap_pandas_append():\n    a = gen_data(1, True)\n    a.name = 'apple'\n    b = gen_data(1, False)\n    wrapped = PandasWrapper(a).wrap(b, append='appended')\n    expected = 'apple_appended'\n    assert (wrapped.name == '???')\n    a = gen_data(2, True)\n    a.columns = [('apple_' + str(i)) for i in range(a.shape[1])]\n    b = gen_data(2, False)\n    wrapped = PandasWrapper(a).wrap(b, append='appended')\n    expected = [(c + '_appended') for c in a.columns]\n    assert (list(wrapped.columns) == expected)", "ground_truth": "expected", "quality_analysis": {"complexity_score": 3, "left_complexity": 2, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}, "classname": null}
{"task_id": "statsmodels_135", "reponame": "statsmodels", "testpath": "statsmodels/tools/validation/tests/test_validation.py", "testname": "test_validation.py", "funcname": "test_wrap_pandas_append", "imports": ["from collections import OrderedDict", "import numpy as np", "import pandas as pd", "import pytest", "from statsmodels.tools.validation import array_like, PandasWrapper, bool_like, dict_like, float_like, int_like, string_like", "from statsmodels.tools.validation.validation import _right_squeeze"], "code": "def test_wrap_pandas_append():\n    a = gen_data(1, True)\n    a.name = 'apple'\n    b = gen_data(1, False)\n    wrapped = PandasWrapper(a).wrap(b, append='appended')\n    expected = 'apple_appended'\n    assert (wrapped.name == expected)\n    a = gen_data(2, True)\n    a.columns = [('apple_' + str(i)) for i in range(a.shape[1])]\n    b = gen_data(2, False)\n    wrapped = PandasWrapper(a).wrap(b, append='appended')\n    expected = [(c + '_appended') for c in a.columns]\n    assert (list(wrapped.columns) == expected)", "masked_code": "def test_wrap_pandas_append():\n    a = gen_data(1, True)\n    a.name = 'apple'\n    b = gen_data(1, False)\n    wrapped = PandasWrapper(a).wrap(b, append='appended')\n    expected = 'apple_appended'\n    assert (wrapped.name == expected)\n    a = gen_data(2, True)\n    a.columns = [('apple_' + str(i)) for i in range(a.shape[1])]\n    b = gen_data(2, False)\n    wrapped = PandasWrapper(a).wrap(b, append='appended')\n    expected = [(c + '_appended') for c in a.columns]\n    assert (list(wrapped.columns) == '???')", "ground_truth": "expected", "quality_analysis": {"complexity_score": 6, "left_complexity": 5, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}, "classname": null}
{"task_id": "statsmodels_136", "reponame": "statsmodels", "testpath": "statsmodels/tools/validation/tests/test_validation.py", "testname": "test_validation.py", "funcname": "test_wrap_pandas_append_non_string", "imports": ["from collections import OrderedDict", "import numpy as np", "import pandas as pd", "import pytest", "from statsmodels.tools.validation import array_like, PandasWrapper, bool_like, dict_like, float_like, int_like, string_like", "from statsmodels.tools.validation.validation import _right_squeeze"], "code": "def test_wrap_pandas_append_non_string():\n    a = gen_data(1, True)\n    a.name = 7\n    b = gen_data(1, False)\n    wrapped = PandasWrapper(a).wrap(b, append='appended')\n    expected = '7_appended'\n    assert (wrapped.name == expected)\n    a = gen_data(2, True)\n    a.columns = [i for i in range(a.shape[1])]\n    b = gen_data(2, False)\n    wrapped = PandasWrapper(a).wrap(b, append='appended')\n    expected = [f'{c}_appended' for c in a.columns]\n    assert (list(wrapped.columns) == expected)", "masked_code": "def test_wrap_pandas_append_non_string():\n    a = gen_data(1, True)\n    a.name = 7\n    b = gen_data(1, False)\n    wrapped = PandasWrapper(a).wrap(b, append='appended')\n    expected = '7_appended'\n    assert (wrapped.name == '???')\n    a = gen_data(2, True)\n    a.columns = [i for i in range(a.shape[1])]\n    b = gen_data(2, False)\n    wrapped = PandasWrapper(a).wrap(b, append='appended')\n    expected = [f'{c}_appended' for c in a.columns]\n    assert (list(wrapped.columns) == expected)", "ground_truth": "expected", "quality_analysis": {"complexity_score": 3, "left_complexity": 2, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}, "classname": null}
{"task_id": "statsmodels_137", "reponame": "statsmodels", "testpath": "statsmodels/tools/validation/tests/test_validation.py", "testname": "test_validation.py", "funcname": "test_wrap_pandas_append_non_string", "imports": ["from collections import OrderedDict", "import numpy as np", "import pandas as pd", "import pytest", "from statsmodels.tools.validation import array_like, PandasWrapper, bool_like, dict_like, float_like, int_like, string_like", "from statsmodels.tools.validation.validation import _right_squeeze"], "code": "def test_wrap_pandas_append_non_string():\n    a = gen_data(1, True)\n    a.name = 7\n    b = gen_data(1, False)\n    wrapped = PandasWrapper(a).wrap(b, append='appended')\n    expected = '7_appended'\n    assert (wrapped.name == expected)\n    a = gen_data(2, True)\n    a.columns = [i for i in range(a.shape[1])]\n    b = gen_data(2, False)\n    wrapped = PandasWrapper(a).wrap(b, append='appended')\n    expected = [f'{c}_appended' for c in a.columns]\n    assert (list(wrapped.columns) == expected)", "masked_code": "def test_wrap_pandas_append_non_string():\n    a = gen_data(1, True)\n    a.name = 7\n    b = gen_data(1, False)\n    wrapped = PandasWrapper(a).wrap(b, append='appended')\n    expected = '7_appended'\n    assert (wrapped.name == expected)\n    a = gen_data(2, True)\n    a.columns = [i for i in range(a.shape[1])]\n    b = gen_data(2, False)\n    wrapped = PandasWrapper(a).wrap(b, append='appended')\n    expected = [f'{c}_appended' for c in a.columns]\n    assert (list(wrapped.columns) == '???')", "ground_truth": "expected", "quality_analysis": {"complexity_score": 6, "left_complexity": 5, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}, "classname": null}
{"task_id": "statsmodels_125", "reponame": "statsmodels", "testpath": "statsmodels/tests/test_x13.py", "testname": "test_x13.py", "funcname": "test_make_var_names", "imports": ["import pandas as pd", "from statsmodels.tsa.x13 import _make_var_names"], "code": "def test_make_var_names():\n    exog = pd.Series([1, 2, 3], name='abc')\n    assert (_make_var_names(exog) == exog.name)", "masked_code": "def test_make_var_names():\n    exog = pd.Series([1, 2, 3], name='abc')\n    assert (_make_var_names(exog) == '???')", "ground_truth": "exog.name", "quality_analysis": {"complexity_score": 6, "left_complexity": 4, "right_complexity": 2, "is_quality": true, "reason": "High quality assertion"}, "classname": null}
