{"task_id": "stellargraph_0", "reponame": "stellargraph", "testpath": "tests/test_aaa_on_gpu.py", "testname": "test_aaa_on_gpu.py", "classname": null, "funcname": "test_on_gpu_when_requested", "imports": ["import os", "import tensorflow as tf", "import pytest", "from . import require_gpu"], "code": "@pytest.mark.skipif((not require_gpu), reason='STELLARGRAPH_MUST_USE_GPU is not set to 1, so a GPU does not have to be used')\ndef test_on_gpu_when_requested():\n    tf.debugging.set_log_device_placement(True)\n    a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n    b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n    c = tf.matmul(a, b)\n    assert (c.numpy().shape == (2, 2))\n    assert tf.config.list_physical_devices('GPU')", "masked_code": "@pytest.mark.skipif((not require_gpu), reason='STELLARGRAPH_MUST_USE_GPU is not set to 1, so a GPU does not have to be used')\ndef test_on_gpu_when_requested():\n    tf.debugging.set_log_device_placement(True)\n    a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n    b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n    c = tf.matmul(a, b)\n    assert (c.numpy().shape == '???')\n    assert tf.config.list_physical_devices('GPU')", "ground_truth": "(2, 2)", "quality_analysis": {"complexity_score": 6, "left_complexity": 2, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_1", "reponame": "stellargraph", "testpath": "tests/test_calibration.py", "testname": "test_calibration.py", "classname": null, "funcname": "test_temperature_scaling_fit_predict", "imports": ["import pytest", "import numpy as np", "from stellargraph.calibration import *"], "code": "def test_temperature_scaling_fit_predict():\n    x_train = np.array([[1, 1], [2, 3.5]])\n    y_train = np.array([[0.9, 0.1], [0.2, 0.8]])\n    x_val = np.array([[0, 2]])\n    y_val = np.array([[0.8, 0.2]])\n    ts = TemperatureCalibration(epochs=2000)\n    assert (ts.epochs == 2000)\n    assert (ts.temperature == 1.0)\n    assert (len(ts.history) == 0)\n    assert (ts.n_classes is None)\n    ts.fit(x_train=x_train, y_train=y_train)\n    assert (ts.temperature != 1.0)\n    assert (len(ts.history) == 2000)\n    assert (ts.n_classes == 2)\n    ts = TemperatureCalibration(epochs=5000)\n    assert (ts.epochs == 5000)\n    ts.fit(x_train=x_train, y_train=y_train, x_val=x_val, y_val=y_val)\n    assert (ts.temperature > 0.0)\n    assert (len(ts.history) < 5000)\n    assert (ts.n_classes == 2)\n    x_test = np.array([[0, 1]])\n    y_pred = ts.predict(x=x_test)\n    assert (y_pred.shape == (1, 2))\n    assert (np.sum(y_pred) == pytest.approx(1.0))\n    assert (y_pred[(0, 1)] > y_pred[(0, 0)])\n    x_train = np.array([1, 3.5])\n    y_train = np.array([1, 0])\n    ts = TemperatureCalibration()\n    ts.fit(x_train=x_train, y_train=y_train)\n    assert (ts.n_classes == 1)\n    x_test = np.array([[0.7]])\n    y_pred = ts.predict(x=x_test)\n    assert (y_pred.shape == (1, 1))", "masked_code": "def test_temperature_scaling_fit_predict():\n    x_train = np.array([[1, 1], [2, 3.5]])\n    y_train = np.array([[0.9, 0.1], [0.2, 0.8]])\n    x_val = np.array([[0, 2]])\n    y_val = np.array([[0.8, 0.2]])\n    ts = TemperatureCalibration(epochs=2000)\n    assert (ts.epochs == '???')\n    assert (ts.temperature == 1.0)\n    assert (len(ts.history) == 0)\n    assert (ts.n_classes is None)\n    ts.fit(x_train=x_train, y_train=y_train)\n    assert (ts.temperature != 1.0)\n    assert (len(ts.history) == 2000)\n    assert (ts.n_classes == 2)\n    ts = TemperatureCalibration(epochs=5000)\n    assert (ts.epochs == 5000)\n    ts.fit(x_train=x_train, y_train=y_train, x_val=x_val, y_val=y_val)\n    assert (ts.temperature > 0.0)\n    assert (len(ts.history) < 5000)\n    assert (ts.n_classes == 2)\n    x_test = np.array([[0, 1]])\n    y_pred = ts.predict(x=x_test)\n    assert (y_pred.shape == (1, 2))\n    assert (np.sum(y_pred) == pytest.approx(1.0))\n    assert (y_pred[(0, 1)] > y_pred[(0, 0)])\n    x_train = np.array([1, 3.5])\n    y_train = np.array([1, 0])\n    ts = TemperatureCalibration()\n    ts.fit(x_train=x_train, y_train=y_train)\n    assert (ts.n_classes == 1)\n    x_test = np.array([[0.7]])\n    y_pred = ts.predict(x=x_test)\n    assert (y_pred.shape == (1, 1))", "ground_truth": "2000", "quality_analysis": {"complexity_score": 3, "left_complexity": 2, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_2", "reponame": "stellargraph", "testpath": "tests/test_calibration.py", "testname": "test_calibration.py", "classname": null, "funcname": "test_temperature_scaling_fit_predict", "imports": ["import pytest", "import numpy as np", "from stellargraph.calibration import *"], "code": "def test_temperature_scaling_fit_predict():\n    x_train = np.array([[1, 1], [2, 3.5]])\n    y_train = np.array([[0.9, 0.1], [0.2, 0.8]])\n    x_val = np.array([[0, 2]])\n    y_val = np.array([[0.8, 0.2]])\n    ts = TemperatureCalibration(epochs=2000)\n    assert (ts.epochs == 2000)\n    assert (ts.temperature == 1.0)\n    assert (len(ts.history) == 0)\n    assert (ts.n_classes is None)\n    ts.fit(x_train=x_train, y_train=y_train)\n    assert (ts.temperature != 1.0)\n    assert (len(ts.history) == 2000)\n    assert (ts.n_classes == 2)\n    ts = TemperatureCalibration(epochs=5000)\n    assert (ts.epochs == 5000)\n    ts.fit(x_train=x_train, y_train=y_train, x_val=x_val, y_val=y_val)\n    assert (ts.temperature > 0.0)\n    assert (len(ts.history) < 5000)\n    assert (ts.n_classes == 2)\n    x_test = np.array([[0, 1]])\n    y_pred = ts.predict(x=x_test)\n    assert (y_pred.shape == (1, 2))\n    assert (np.sum(y_pred) == pytest.approx(1.0))\n    assert (y_pred[(0, 1)] > y_pred[(0, 0)])\n    x_train = np.array([1, 3.5])\n    y_train = np.array([1, 0])\n    ts = TemperatureCalibration()\n    ts.fit(x_train=x_train, y_train=y_train)\n    assert (ts.n_classes == 1)\n    x_test = np.array([[0.7]])\n    y_pred = ts.predict(x=x_test)\n    assert (y_pred.shape == (1, 1))", "masked_code": "def test_temperature_scaling_fit_predict():\n    x_train = np.array([[1, 1], [2, 3.5]])\n    y_train = np.array([[0.9, 0.1], [0.2, 0.8]])\n    x_val = np.array([[0, 2]])\n    y_val = np.array([[0.8, 0.2]])\n    ts = TemperatureCalibration(epochs=2000)\n    assert (ts.epochs == 2000)\n    assert (ts.temperature == 1.0)\n    assert (len(ts.history) == 0)\n    assert (ts.n_classes is None)\n    ts.fit(x_train=x_train, y_train=y_train)\n    assert (ts.temperature != 1.0)\n    assert (len(ts.history) == '???')\n    assert (ts.n_classes == 2)\n    ts = TemperatureCalibration(epochs=5000)\n    assert (ts.epochs == 5000)\n    ts.fit(x_train=x_train, y_train=y_train, x_val=x_val, y_val=y_val)\n    assert (ts.temperature > 0.0)\n    assert (len(ts.history) < 5000)\n    assert (ts.n_classes == 2)\n    x_test = np.array([[0, 1]])\n    y_pred = ts.predict(x=x_test)\n    assert (y_pred.shape == (1, 2))\n    assert (np.sum(y_pred) == pytest.approx(1.0))\n    assert (y_pred[(0, 1)] > y_pred[(0, 0)])\n    x_train = np.array([1, 3.5])\n    y_train = np.array([1, 0])\n    ts = TemperatureCalibration()\n    ts.fit(x_train=x_train, y_train=y_train)\n    assert (ts.n_classes == 1)\n    x_test = np.array([[0.7]])\n    y_pred = ts.predict(x=x_test)\n    assert (y_pred.shape == (1, 1))", "ground_truth": "2000", "quality_analysis": {"complexity_score": 6, "left_complexity": 5, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_3", "reponame": "stellargraph", "testpath": "tests/test_calibration.py", "testname": "test_calibration.py", "classname": null, "funcname": "test_temperature_scaling_fit_predict", "imports": ["import pytest", "import numpy as np", "from stellargraph.calibration import *"], "code": "def test_temperature_scaling_fit_predict():\n    x_train = np.array([[1, 1], [2, 3.5]])\n    y_train = np.array([[0.9, 0.1], [0.2, 0.8]])\n    x_val = np.array([[0, 2]])\n    y_val = np.array([[0.8, 0.2]])\n    ts = TemperatureCalibration(epochs=2000)\n    assert (ts.epochs == 2000)\n    assert (ts.temperature == 1.0)\n    assert (len(ts.history) == 0)\n    assert (ts.n_classes is None)\n    ts.fit(x_train=x_train, y_train=y_train)\n    assert (ts.temperature != 1.0)\n    assert (len(ts.history) == 2000)\n    assert (ts.n_classes == 2)\n    ts = TemperatureCalibration(epochs=5000)\n    assert (ts.epochs == 5000)\n    ts.fit(x_train=x_train, y_train=y_train, x_val=x_val, y_val=y_val)\n    assert (ts.temperature > 0.0)\n    assert (len(ts.history) < 5000)\n    assert (ts.n_classes == 2)\n    x_test = np.array([[0, 1]])\n    y_pred = ts.predict(x=x_test)\n    assert (y_pred.shape == (1, 2))\n    assert (np.sum(y_pred) == pytest.approx(1.0))\n    assert (y_pred[(0, 1)] > y_pred[(0, 0)])\n    x_train = np.array([1, 3.5])\n    y_train = np.array([1, 0])\n    ts = TemperatureCalibration()\n    ts.fit(x_train=x_train, y_train=y_train)\n    assert (ts.n_classes == 1)\n    x_test = np.array([[0.7]])\n    y_pred = ts.predict(x=x_test)\n    assert (y_pred.shape == (1, 1))", "masked_code": "def test_temperature_scaling_fit_predict():\n    x_train = np.array([[1, 1], [2, 3.5]])\n    y_train = np.array([[0.9, 0.1], [0.2, 0.8]])\n    x_val = np.array([[0, 2]])\n    y_val = np.array([[0.8, 0.2]])\n    ts = TemperatureCalibration(epochs=2000)\n    assert (ts.epochs == 2000)\n    assert (ts.temperature == 1.0)\n    assert (len(ts.history) == 0)\n    assert (ts.n_classes is None)\n    ts.fit(x_train=x_train, y_train=y_train)\n    assert (ts.temperature != 1.0)\n    assert (len(ts.history) == 2000)\n    assert (ts.n_classes == 2)\n    ts = TemperatureCalibration(epochs=5000)\n    assert (ts.epochs == '???')\n    ts.fit(x_train=x_train, y_train=y_train, x_val=x_val, y_val=y_val)\n    assert (ts.temperature > 0.0)\n    assert (len(ts.history) < 5000)\n    assert (ts.n_classes == 2)\n    x_test = np.array([[0, 1]])\n    y_pred = ts.predict(x=x_test)\n    assert (y_pred.shape == (1, 2))\n    assert (np.sum(y_pred) == pytest.approx(1.0))\n    assert (y_pred[(0, 1)] > y_pred[(0, 0)])\n    x_train = np.array([1, 3.5])\n    y_train = np.array([1, 0])\n    ts = TemperatureCalibration()\n    ts.fit(x_train=x_train, y_train=y_train)\n    assert (ts.n_classes == 1)\n    x_test = np.array([[0.7]])\n    y_pred = ts.predict(x=x_test)\n    assert (y_pred.shape == (1, 1))", "ground_truth": "5000", "quality_analysis": {"complexity_score": 3, "left_complexity": 2, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_4", "reponame": "stellargraph", "testpath": "tests/test_calibration.py", "testname": "test_calibration.py", "classname": null, "funcname": "test_temperature_scaling_fit_predict", "imports": ["import pytest", "import numpy as np", "from stellargraph.calibration import *"], "code": "def test_temperature_scaling_fit_predict():\n    x_train = np.array([[1, 1], [2, 3.5]])\n    y_train = np.array([[0.9, 0.1], [0.2, 0.8]])\n    x_val = np.array([[0, 2]])\n    y_val = np.array([[0.8, 0.2]])\n    ts = TemperatureCalibration(epochs=2000)\n    assert (ts.epochs == 2000)\n    assert (ts.temperature == 1.0)\n    assert (len(ts.history) == 0)\n    assert (ts.n_classes is None)\n    ts.fit(x_train=x_train, y_train=y_train)\n    assert (ts.temperature != 1.0)\n    assert (len(ts.history) == 2000)\n    assert (ts.n_classes == 2)\n    ts = TemperatureCalibration(epochs=5000)\n    assert (ts.epochs == 5000)\n    ts.fit(x_train=x_train, y_train=y_train, x_val=x_val, y_val=y_val)\n    assert (ts.temperature > 0.0)\n    assert (len(ts.history) < 5000)\n    assert (ts.n_classes == 2)\n    x_test = np.array([[0, 1]])\n    y_pred = ts.predict(x=x_test)\n    assert (y_pred.shape == (1, 2))\n    assert (np.sum(y_pred) == pytest.approx(1.0))\n    assert (y_pred[(0, 1)] > y_pred[(0, 0)])\n    x_train = np.array([1, 3.5])\n    y_train = np.array([1, 0])\n    ts = TemperatureCalibration()\n    ts.fit(x_train=x_train, y_train=y_train)\n    assert (ts.n_classes == 1)\n    x_test = np.array([[0.7]])\n    y_pred = ts.predict(x=x_test)\n    assert (y_pred.shape == (1, 1))", "masked_code": "def test_temperature_scaling_fit_predict():\n    x_train = np.array([[1, 1], [2, 3.5]])\n    y_train = np.array([[0.9, 0.1], [0.2, 0.8]])\n    x_val = np.array([[0, 2]])\n    y_val = np.array([[0.8, 0.2]])\n    ts = TemperatureCalibration(epochs=2000)\n    assert (ts.epochs == 2000)\n    assert (ts.temperature == 1.0)\n    assert (len(ts.history) == 0)\n    assert (ts.n_classes is None)\n    ts.fit(x_train=x_train, y_train=y_train)\n    assert (ts.temperature != 1.0)\n    assert (len(ts.history) == 2000)\n    assert (ts.n_classes == 2)\n    ts = TemperatureCalibration(epochs=5000)\n    assert (ts.epochs == 5000)\n    ts.fit(x_train=x_train, y_train=y_train, x_val=x_val, y_val=y_val)\n    assert (ts.temperature > 0.0)\n    assert (len(ts.history) < 5000)\n    assert (ts.n_classes == 2)\n    x_test = np.array([[0, 1]])\n    y_pred = ts.predict(x=x_test)\n    assert (y_pred.shape == '???')\n    assert (np.sum(y_pred) == pytest.approx(1.0))\n    assert (y_pred[(0, 1)] > y_pred[(0, 0)])\n    x_train = np.array([1, 3.5])\n    y_train = np.array([1, 0])\n    ts = TemperatureCalibration()\n    ts.fit(x_train=x_train, y_train=y_train)\n    assert (ts.n_classes == 1)\n    x_test = np.array([[0.7]])\n    y_pred = ts.predict(x=x_test)\n    assert (y_pred.shape == (1, 1))", "ground_truth": "(1, 2)", "quality_analysis": {"complexity_score": 6, "left_complexity": 2, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_5", "reponame": "stellargraph", "testpath": "tests/test_calibration.py", "testname": "test_calibration.py", "classname": null, "funcname": "test_temperature_scaling_fit_predict", "imports": ["import pytest", "import numpy as np", "from stellargraph.calibration import *"], "code": "def test_temperature_scaling_fit_predict():\n    x_train = np.array([[1, 1], [2, 3.5]])\n    y_train = np.array([[0.9, 0.1], [0.2, 0.8]])\n    x_val = np.array([[0, 2]])\n    y_val = np.array([[0.8, 0.2]])\n    ts = TemperatureCalibration(epochs=2000)\n    assert (ts.epochs == 2000)\n    assert (ts.temperature == 1.0)\n    assert (len(ts.history) == 0)\n    assert (ts.n_classes is None)\n    ts.fit(x_train=x_train, y_train=y_train)\n    assert (ts.temperature != 1.0)\n    assert (len(ts.history) == 2000)\n    assert (ts.n_classes == 2)\n    ts = TemperatureCalibration(epochs=5000)\n    assert (ts.epochs == 5000)\n    ts.fit(x_train=x_train, y_train=y_train, x_val=x_val, y_val=y_val)\n    assert (ts.temperature > 0.0)\n    assert (len(ts.history) < 5000)\n    assert (ts.n_classes == 2)\n    x_test = np.array([[0, 1]])\n    y_pred = ts.predict(x=x_test)\n    assert (y_pred.shape == (1, 2))\n    assert (np.sum(y_pred) == pytest.approx(1.0))\n    assert (y_pred[(0, 1)] > y_pred[(0, 0)])\n    x_train = np.array([1, 3.5])\n    y_train = np.array([1, 0])\n    ts = TemperatureCalibration()\n    ts.fit(x_train=x_train, y_train=y_train)\n    assert (ts.n_classes == 1)\n    x_test = np.array([[0.7]])\n    y_pred = ts.predict(x=x_test)\n    assert (y_pred.shape == (1, 1))", "masked_code": "def test_temperature_scaling_fit_predict():\n    x_train = np.array([[1, 1], [2, 3.5]])\n    y_train = np.array([[0.9, 0.1], [0.2, 0.8]])\n    x_val = np.array([[0, 2]])\n    y_val = np.array([[0.8, 0.2]])\n    ts = TemperatureCalibration(epochs=2000)\n    assert (ts.epochs == 2000)\n    assert (ts.temperature == 1.0)\n    assert (len(ts.history) == 0)\n    assert (ts.n_classes is None)\n    ts.fit(x_train=x_train, y_train=y_train)\n    assert (ts.temperature != 1.0)\n    assert (len(ts.history) == 2000)\n    assert (ts.n_classes == 2)\n    ts = TemperatureCalibration(epochs=5000)\n    assert (ts.epochs == 5000)\n    ts.fit(x_train=x_train, y_train=y_train, x_val=x_val, y_val=y_val)\n    assert (ts.temperature > 0.0)\n    assert (len(ts.history) < 5000)\n    assert (ts.n_classes == 2)\n    x_test = np.array([[0, 1]])\n    y_pred = ts.predict(x=x_test)\n    assert (y_pred.shape == (1, 2))\n    assert (np.sum(y_pred) == '???')\n    assert (y_pred[(0, 1)] > y_pred[(0, 0)])\n    x_train = np.array([1, 3.5])\n    y_train = np.array([1, 0])\n    ts = TemperatureCalibration()\n    ts.fit(x_train=x_train, y_train=y_train)\n    assert (ts.n_classes == 1)\n    x_test = np.array([[0.7]])\n    y_pred = ts.predict(x=x_test)\n    assert (y_pred.shape == (1, 1))", "ground_truth": "pytest.approx(1.0)", "quality_analysis": {"complexity_score": 8, "left_complexity": 4, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_6", "reponame": "stellargraph", "testpath": "tests/test_calibration.py", "testname": "test_calibration.py", "classname": null, "funcname": "test_temperature_scaling_fit_predict", "imports": ["import pytest", "import numpy as np", "from stellargraph.calibration import *"], "code": "def test_temperature_scaling_fit_predict():\n    x_train = np.array([[1, 1], [2, 3.5]])\n    y_train = np.array([[0.9, 0.1], [0.2, 0.8]])\n    x_val = np.array([[0, 2]])\n    y_val = np.array([[0.8, 0.2]])\n    ts = TemperatureCalibration(epochs=2000)\n    assert (ts.epochs == 2000)\n    assert (ts.temperature == 1.0)\n    assert (len(ts.history) == 0)\n    assert (ts.n_classes is None)\n    ts.fit(x_train=x_train, y_train=y_train)\n    assert (ts.temperature != 1.0)\n    assert (len(ts.history) == 2000)\n    assert (ts.n_classes == 2)\n    ts = TemperatureCalibration(epochs=5000)\n    assert (ts.epochs == 5000)\n    ts.fit(x_train=x_train, y_train=y_train, x_val=x_val, y_val=y_val)\n    assert (ts.temperature > 0.0)\n    assert (len(ts.history) < 5000)\n    assert (ts.n_classes == 2)\n    x_test = np.array([[0, 1]])\n    y_pred = ts.predict(x=x_test)\n    assert (y_pred.shape == (1, 2))\n    assert (np.sum(y_pred) == pytest.approx(1.0))\n    assert (y_pred[(0, 1)] > y_pred[(0, 0)])\n    x_train = np.array([1, 3.5])\n    y_train = np.array([1, 0])\n    ts = TemperatureCalibration()\n    ts.fit(x_train=x_train, y_train=y_train)\n    assert (ts.n_classes == 1)\n    x_test = np.array([[0.7]])\n    y_pred = ts.predict(x=x_test)\n    assert (y_pred.shape == (1, 1))", "masked_code": "def test_temperature_scaling_fit_predict():\n    x_train = np.array([[1, 1], [2, 3.5]])\n    y_train = np.array([[0.9, 0.1], [0.2, 0.8]])\n    x_val = np.array([[0, 2]])\n    y_val = np.array([[0.8, 0.2]])\n    ts = TemperatureCalibration(epochs=2000)\n    assert (ts.epochs == 2000)\n    assert (ts.temperature == 1.0)\n    assert (len(ts.history) == 0)\n    assert (ts.n_classes is None)\n    ts.fit(x_train=x_train, y_train=y_train)\n    assert (ts.temperature != 1.0)\n    assert (len(ts.history) == 2000)\n    assert (ts.n_classes == 2)\n    ts = TemperatureCalibration(epochs=5000)\n    assert (ts.epochs == 5000)\n    ts.fit(x_train=x_train, y_train=y_train, x_val=x_val, y_val=y_val)\n    assert (ts.temperature > 0.0)\n    assert (len(ts.history) < 5000)\n    assert (ts.n_classes == 2)\n    x_test = np.array([[0, 1]])\n    y_pred = ts.predict(x=x_test)\n    assert (y_pred.shape == (1, 2))\n    assert (np.sum(y_pred) == pytest.approx(1.0))\n    assert (y_pred[(0, 1)] > y_pred[(0, 0)])\n    x_train = np.array([1, 3.5])\n    y_train = np.array([1, 0])\n    ts = TemperatureCalibration()\n    ts.fit(x_train=x_train, y_train=y_train)\n    assert (ts.n_classes == 1)\n    x_test = np.array([[0.7]])\n    y_pred = ts.predict(x=x_test)\n    assert (y_pred.shape == '???')", "ground_truth": "(1, 1)", "quality_analysis": {"complexity_score": 6, "left_complexity": 2, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_7", "reponame": "stellargraph", "testpath": "tests/test_calibration.py", "testname": "test_calibration.py", "classname": null, "funcname": "test_isotonic_calibration_fit_predict", "imports": ["import pytest", "import numpy as np", "from stellargraph.calibration import *"], "code": "def test_isotonic_calibration_fit_predict():\n    x_train = np.array([[1, 1], [2, 3.5]])\n    y_train = np.array([[0.9, 0.1], [0.2, 0.8]])\n    ic = IsotonicCalibration()\n    assert (len(ic.regressors) == 0)\n    ic.fit(x_train=x_train, y_train=y_train)\n    assert (ic.n_classes == 2)\n    x_test = np.array([[0, 1]])\n    y_pred = ic.predict(x=x_test)\n    assert (y_pred.shape == (1, 2))\n    assert (np.sum(y_pred) == pytest.approx(1.0))\n    x_train = np.array([0.1, 0.5, 0.2])\n    y_train = np.array([0.2, 0.55, 0.3])\n    ic = IsotonicCalibration()\n    assert (len(ic.regressors) == 0)\n    ic.fit(x_train=x_train, y_train=y_train)\n    assert (ic.n_classes == 1)\n    x_test = np.array([0.5, 0.1])\n    y_pred = ic.predict(x=x_test)\n    assert (y_pred.shape == (2, 1))", "masked_code": "def test_isotonic_calibration_fit_predict():\n    x_train = np.array([[1, 1], [2, 3.5]])\n    y_train = np.array([[0.9, 0.1], [0.2, 0.8]])\n    ic = IsotonicCalibration()\n    assert (len(ic.regressors) == 0)\n    ic.fit(x_train=x_train, y_train=y_train)\n    assert (ic.n_classes == 2)\n    x_test = np.array([[0, 1]])\n    y_pred = ic.predict(x=x_test)\n    assert (y_pred.shape == '???')\n    assert (np.sum(y_pred) == pytest.approx(1.0))\n    x_train = np.array([0.1, 0.5, 0.2])\n    y_train = np.array([0.2, 0.55, 0.3])\n    ic = IsotonicCalibration()\n    assert (len(ic.regressors) == 0)\n    ic.fit(x_train=x_train, y_train=y_train)\n    assert (ic.n_classes == 1)\n    x_test = np.array([0.5, 0.1])\n    y_pred = ic.predict(x=x_test)\n    assert (y_pred.shape == (2, 1))", "ground_truth": "(1, 2)", "quality_analysis": {"complexity_score": 6, "left_complexity": 2, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_8", "reponame": "stellargraph", "testpath": "tests/test_calibration.py", "testname": "test_calibration.py", "classname": null, "funcname": "test_isotonic_calibration_fit_predict", "imports": ["import pytest", "import numpy as np", "from stellargraph.calibration import *"], "code": "def test_isotonic_calibration_fit_predict():\n    x_train = np.array([[1, 1], [2, 3.5]])\n    y_train = np.array([[0.9, 0.1], [0.2, 0.8]])\n    ic = IsotonicCalibration()\n    assert (len(ic.regressors) == 0)\n    ic.fit(x_train=x_train, y_train=y_train)\n    assert (ic.n_classes == 2)\n    x_test = np.array([[0, 1]])\n    y_pred = ic.predict(x=x_test)\n    assert (y_pred.shape == (1, 2))\n    assert (np.sum(y_pred) == pytest.approx(1.0))\n    x_train = np.array([0.1, 0.5, 0.2])\n    y_train = np.array([0.2, 0.55, 0.3])\n    ic = IsotonicCalibration()\n    assert (len(ic.regressors) == 0)\n    ic.fit(x_train=x_train, y_train=y_train)\n    assert (ic.n_classes == 1)\n    x_test = np.array([0.5, 0.1])\n    y_pred = ic.predict(x=x_test)\n    assert (y_pred.shape == (2, 1))", "masked_code": "def test_isotonic_calibration_fit_predict():\n    x_train = np.array([[1, 1], [2, 3.5]])\n    y_train = np.array([[0.9, 0.1], [0.2, 0.8]])\n    ic = IsotonicCalibration()\n    assert (len(ic.regressors) == 0)\n    ic.fit(x_train=x_train, y_train=y_train)\n    assert (ic.n_classes == 2)\n    x_test = np.array([[0, 1]])\n    y_pred = ic.predict(x=x_test)\n    assert (y_pred.shape == (1, 2))\n    assert (np.sum(y_pred) == '???')\n    x_train = np.array([0.1, 0.5, 0.2])\n    y_train = np.array([0.2, 0.55, 0.3])\n    ic = IsotonicCalibration()\n    assert (len(ic.regressors) == 0)\n    ic.fit(x_train=x_train, y_train=y_train)\n    assert (ic.n_classes == 1)\n    x_test = np.array([0.5, 0.1])\n    y_pred = ic.predict(x=x_test)\n    assert (y_pred.shape == (2, 1))", "ground_truth": "pytest.approx(1.0)", "quality_analysis": {"complexity_score": 8, "left_complexity": 4, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_9", "reponame": "stellargraph", "testpath": "tests/test_calibration.py", "testname": "test_calibration.py", "classname": null, "funcname": "test_isotonic_calibration_fit_predict", "imports": ["import pytest", "import numpy as np", "from stellargraph.calibration import *"], "code": "def test_isotonic_calibration_fit_predict():\n    x_train = np.array([[1, 1], [2, 3.5]])\n    y_train = np.array([[0.9, 0.1], [0.2, 0.8]])\n    ic = IsotonicCalibration()\n    assert (len(ic.regressors) == 0)\n    ic.fit(x_train=x_train, y_train=y_train)\n    assert (ic.n_classes == 2)\n    x_test = np.array([[0, 1]])\n    y_pred = ic.predict(x=x_test)\n    assert (y_pred.shape == (1, 2))\n    assert (np.sum(y_pred) == pytest.approx(1.0))\n    x_train = np.array([0.1, 0.5, 0.2])\n    y_train = np.array([0.2, 0.55, 0.3])\n    ic = IsotonicCalibration()\n    assert (len(ic.regressors) == 0)\n    ic.fit(x_train=x_train, y_train=y_train)\n    assert (ic.n_classes == 1)\n    x_test = np.array([0.5, 0.1])\n    y_pred = ic.predict(x=x_test)\n    assert (y_pred.shape == (2, 1))", "masked_code": "def test_isotonic_calibration_fit_predict():\n    x_train = np.array([[1, 1], [2, 3.5]])\n    y_train = np.array([[0.9, 0.1], [0.2, 0.8]])\n    ic = IsotonicCalibration()\n    assert (len(ic.regressors) == 0)\n    ic.fit(x_train=x_train, y_train=y_train)\n    assert (ic.n_classes == 2)\n    x_test = np.array([[0, 1]])\n    y_pred = ic.predict(x=x_test)\n    assert (y_pred.shape == (1, 2))\n    assert (np.sum(y_pred) == pytest.approx(1.0))\n    x_train = np.array([0.1, 0.5, 0.2])\n    y_train = np.array([0.2, 0.55, 0.3])\n    ic = IsotonicCalibration()\n    assert (len(ic.regressors) == 0)\n    ic.fit(x_train=x_train, y_train=y_train)\n    assert (ic.n_classes == 1)\n    x_test = np.array([0.5, 0.1])\n    y_pred = ic.predict(x=x_test)\n    assert (y_pred.shape == '???')", "ground_truth": "(2, 1)", "quality_analysis": {"complexity_score": 6, "left_complexity": 2, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_10", "reponame": "stellargraph", "testpath": "tests/test_ensemble.py", "testname": "test_ensemble.py", "classname": null, "funcname": "test_ensemble_init_parameters", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "import tensorflow as tf", "from stellargraph import StellarGraph", "from stellargraph.layer import GraphSAGE, GCN, GAT, HinSAGE, link_classification, link_regression", "from stellargraph.mapper import GraphSAGENodeGenerator, FullBatchNodeGenerator, HinSAGENodeGenerator, GraphSAGELinkGenerator, HinSAGELinkGenerator", "from stellargraph.ensemble import Ensemble, BaggingEnsemble", "from tensorflow.keras import layers, Model", "from tensorflow.keras.optimizers import Adam", "from tensorflow.keras.losses import categorical_crossentropy, binary_crossentropy"], "code": "def test_ensemble_init_parameters():\n    tf.keras.backend.clear_session()\n    graph = example_graph_1(feature_size=10)\n    (base_model, keras_model, generator, train_gen) = create_graphSAGE_model(graph)\n    gnn_models = [create_graphSAGE_model(graph), create_HinSAGE_model(graph), create_graphSAGE_model(graph, link_prediction=True), create_HinSAGE_model(graph, link_prediction=True), create_GCN_model(graph), create_GAT_model(graph)]\n    for gnn_model in gnn_models:\n        base_model = gnn_model[0]\n        keras_model = gnn_model[1]\n        with pytest.raises(ValueError):\n            Ensemble(base_model, n_estimators=3, n_predictions=3)\n        with pytest.raises(ValueError):\n            Ensemble(keras_model, n_estimators=1, n_predictions=0)\n        with pytest.raises(ValueError):\n            Ensemble(keras_model, n_estimators=1, n_predictions=(- 3))\n        with pytest.raises(ValueError):\n            Ensemble(keras_model, n_estimators=1, n_predictions=1.7)\n        with pytest.raises(ValueError):\n            Ensemble(keras_model, n_estimators=0, n_predictions=11)\n        with pytest.raises(ValueError):\n            Ensemble(keras_model, n_estimators=(- 8), n_predictions=11)\n        with pytest.raises(ValueError):\n            Ensemble(keras_model, n_estimators=2.5, n_predictions=11)\n        ens = Ensemble(keras_model, n_estimators=7, n_predictions=10)\n        assert (len(ens.models) == 7)\n        assert (ens.n_estimators == 7)\n        assert (ens.n_predictions == 10)\n        with pytest.raises(ValueError):\n            BaggingEnsemble(base_model, n_estimators=3, n_predictions=3)\n        with pytest.raises(ValueError):\n            BaggingEnsemble(keras_model, n_estimators=1, n_predictions=0)\n        with pytest.raises(ValueError):\n            BaggingEnsemble(keras_model, n_estimators=1, n_predictions=(- 3))\n        with pytest.raises(ValueError):\n            BaggingEnsemble(keras_model, n_estimators=1, n_predictions=1.7)\n        with pytest.raises(ValueError):\n            BaggingEnsemble(keras_model, n_estimators=0, n_predictions=11)\n        with pytest.raises(ValueError):\n            BaggingEnsemble(keras_model, n_estimators=(- 8), n_predictions=11)\n        with pytest.raises(ValueError):\n            BaggingEnsemble(keras_model, n_estimators=2.5, n_predictions=11)\n        ens = BaggingEnsemble(keras_model, n_estimators=7, n_predictions=10)\n        assert (len(ens.models) == 7)\n        assert (ens.n_estimators == 7)\n        assert (ens.n_predictions == 10)", "masked_code": "def test_ensemble_init_parameters():\n    tf.keras.backend.clear_session()\n    graph = example_graph_1(feature_size=10)\n    (base_model, keras_model, generator, train_gen) = create_graphSAGE_model(graph)\n    gnn_models = [create_graphSAGE_model(graph), create_HinSAGE_model(graph), create_graphSAGE_model(graph, link_prediction=True), create_HinSAGE_model(graph, link_prediction=True), create_GCN_model(graph), create_GAT_model(graph)]\n    for gnn_model in gnn_models:\n        base_model = gnn_model[0]\n        keras_model = gnn_model[1]\n        with pytest.raises(ValueError):\n            Ensemble(base_model, n_estimators=3, n_predictions=3)\n        with pytest.raises(ValueError):\n            Ensemble(keras_model, n_estimators=1, n_predictions=0)\n        with pytest.raises(ValueError):\n            Ensemble(keras_model, n_estimators=1, n_predictions=(- 3))\n        with pytest.raises(ValueError):\n            Ensemble(keras_model, n_estimators=1, n_predictions=1.7)\n        with pytest.raises(ValueError):\n            Ensemble(keras_model, n_estimators=0, n_predictions=11)\n        with pytest.raises(ValueError):\n            Ensemble(keras_model, n_estimators=(- 8), n_predictions=11)\n        with pytest.raises(ValueError):\n            Ensemble(keras_model, n_estimators=2.5, n_predictions=11)\n        ens = Ensemble(keras_model, n_estimators=7, n_predictions=10)\n        assert (len(ens.models) == '???')\n        assert (ens.n_estimators == 7)\n        assert (ens.n_predictions == 10)\n        with pytest.raises(ValueError):\n            BaggingEnsemble(base_model, n_estimators=3, n_predictions=3)\n        with pytest.raises(ValueError):\n            BaggingEnsemble(keras_model, n_estimators=1, n_predictions=0)\n        with pytest.raises(ValueError):\n            BaggingEnsemble(keras_model, n_estimators=1, n_predictions=(- 3))\n        with pytest.raises(ValueError):\n            BaggingEnsemble(keras_model, n_estimators=1, n_predictions=1.7)\n        with pytest.raises(ValueError):\n            BaggingEnsemble(keras_model, n_estimators=0, n_predictions=11)\n        with pytest.raises(ValueError):\n            BaggingEnsemble(keras_model, n_estimators=(- 8), n_predictions=11)\n        with pytest.raises(ValueError):\n            BaggingEnsemble(keras_model, n_estimators=2.5, n_predictions=11)\n        ens = BaggingEnsemble(keras_model, n_estimators=7, n_predictions=10)\n        assert (len(ens.models) == 7)\n        assert (ens.n_estimators == 7)\n        assert (ens.n_predictions == 10)", "ground_truth": "7", "quality_analysis": {"complexity_score": 6, "left_complexity": 5, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_11", "reponame": "stellargraph", "testpath": "tests/test_ensemble.py", "testname": "test_ensemble.py", "classname": null, "funcname": "test_ensemble_init_parameters", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "import tensorflow as tf", "from stellargraph import StellarGraph", "from stellargraph.layer import GraphSAGE, GCN, GAT, HinSAGE, link_classification, link_regression", "from stellargraph.mapper import GraphSAGENodeGenerator, FullBatchNodeGenerator, HinSAGENodeGenerator, GraphSAGELinkGenerator, HinSAGELinkGenerator", "from stellargraph.ensemble import Ensemble, BaggingEnsemble", "from tensorflow.keras import layers, Model", "from tensorflow.keras.optimizers import Adam", "from tensorflow.keras.losses import categorical_crossentropy, binary_crossentropy"], "code": "def test_ensemble_init_parameters():\n    tf.keras.backend.clear_session()\n    graph = example_graph_1(feature_size=10)\n    (base_model, keras_model, generator, train_gen) = create_graphSAGE_model(graph)\n    gnn_models = [create_graphSAGE_model(graph), create_HinSAGE_model(graph), create_graphSAGE_model(graph, link_prediction=True), create_HinSAGE_model(graph, link_prediction=True), create_GCN_model(graph), create_GAT_model(graph)]\n    for gnn_model in gnn_models:\n        base_model = gnn_model[0]\n        keras_model = gnn_model[1]\n        with pytest.raises(ValueError):\n            Ensemble(base_model, n_estimators=3, n_predictions=3)\n        with pytest.raises(ValueError):\n            Ensemble(keras_model, n_estimators=1, n_predictions=0)\n        with pytest.raises(ValueError):\n            Ensemble(keras_model, n_estimators=1, n_predictions=(- 3))\n        with pytest.raises(ValueError):\n            Ensemble(keras_model, n_estimators=1, n_predictions=1.7)\n        with pytest.raises(ValueError):\n            Ensemble(keras_model, n_estimators=0, n_predictions=11)\n        with pytest.raises(ValueError):\n            Ensemble(keras_model, n_estimators=(- 8), n_predictions=11)\n        with pytest.raises(ValueError):\n            Ensemble(keras_model, n_estimators=2.5, n_predictions=11)\n        ens = Ensemble(keras_model, n_estimators=7, n_predictions=10)\n        assert (len(ens.models) == 7)\n        assert (ens.n_estimators == 7)\n        assert (ens.n_predictions == 10)\n        with pytest.raises(ValueError):\n            BaggingEnsemble(base_model, n_estimators=3, n_predictions=3)\n        with pytest.raises(ValueError):\n            BaggingEnsemble(keras_model, n_estimators=1, n_predictions=0)\n        with pytest.raises(ValueError):\n            BaggingEnsemble(keras_model, n_estimators=1, n_predictions=(- 3))\n        with pytest.raises(ValueError):\n            BaggingEnsemble(keras_model, n_estimators=1, n_predictions=1.7)\n        with pytest.raises(ValueError):\n            BaggingEnsemble(keras_model, n_estimators=0, n_predictions=11)\n        with pytest.raises(ValueError):\n            BaggingEnsemble(keras_model, n_estimators=(- 8), n_predictions=11)\n        with pytest.raises(ValueError):\n            BaggingEnsemble(keras_model, n_estimators=2.5, n_predictions=11)\n        ens = BaggingEnsemble(keras_model, n_estimators=7, n_predictions=10)\n        assert (len(ens.models) == 7)\n        assert (ens.n_estimators == 7)\n        assert (ens.n_predictions == 10)", "masked_code": "def test_ensemble_init_parameters():\n    tf.keras.backend.clear_session()\n    graph = example_graph_1(feature_size=10)\n    (base_model, keras_model, generator, train_gen) = create_graphSAGE_model(graph)\n    gnn_models = [create_graphSAGE_model(graph), create_HinSAGE_model(graph), create_graphSAGE_model(graph, link_prediction=True), create_HinSAGE_model(graph, link_prediction=True), create_GCN_model(graph), create_GAT_model(graph)]\n    for gnn_model in gnn_models:\n        base_model = gnn_model[0]\n        keras_model = gnn_model[1]\n        with pytest.raises(ValueError):\n            Ensemble(base_model, n_estimators=3, n_predictions=3)\n        with pytest.raises(ValueError):\n            Ensemble(keras_model, n_estimators=1, n_predictions=0)\n        with pytest.raises(ValueError):\n            Ensemble(keras_model, n_estimators=1, n_predictions=(- 3))\n        with pytest.raises(ValueError):\n            Ensemble(keras_model, n_estimators=1, n_predictions=1.7)\n        with pytest.raises(ValueError):\n            Ensemble(keras_model, n_estimators=0, n_predictions=11)\n        with pytest.raises(ValueError):\n            Ensemble(keras_model, n_estimators=(- 8), n_predictions=11)\n        with pytest.raises(ValueError):\n            Ensemble(keras_model, n_estimators=2.5, n_predictions=11)\n        ens = Ensemble(keras_model, n_estimators=7, n_predictions=10)\n        assert (len(ens.models) == 7)\n        assert (ens.n_estimators == '???')\n        assert (ens.n_predictions == 10)\n        with pytest.raises(ValueError):\n            BaggingEnsemble(base_model, n_estimators=3, n_predictions=3)\n        with pytest.raises(ValueError):\n            BaggingEnsemble(keras_model, n_estimators=1, n_predictions=0)\n        with pytest.raises(ValueError):\n            BaggingEnsemble(keras_model, n_estimators=1, n_predictions=(- 3))\n        with pytest.raises(ValueError):\n            BaggingEnsemble(keras_model, n_estimators=1, n_predictions=1.7)\n        with pytest.raises(ValueError):\n            BaggingEnsemble(keras_model, n_estimators=0, n_predictions=11)\n        with pytest.raises(ValueError):\n            BaggingEnsemble(keras_model, n_estimators=(- 8), n_predictions=11)\n        with pytest.raises(ValueError):\n            BaggingEnsemble(keras_model, n_estimators=2.5, n_predictions=11)\n        ens = BaggingEnsemble(keras_model, n_estimators=7, n_predictions=10)\n        assert (len(ens.models) == 7)\n        assert (ens.n_estimators == 7)\n        assert (ens.n_predictions == 10)", "ground_truth": "7", "quality_analysis": {"complexity_score": 3, "left_complexity": 2, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_12", "reponame": "stellargraph", "testpath": "tests/test_ensemble.py", "testname": "test_ensemble.py", "classname": null, "funcname": "test_ensemble_init_parameters", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "import tensorflow as tf", "from stellargraph import StellarGraph", "from stellargraph.layer import GraphSAGE, GCN, GAT, HinSAGE, link_classification, link_regression", "from stellargraph.mapper import GraphSAGENodeGenerator, FullBatchNodeGenerator, HinSAGENodeGenerator, GraphSAGELinkGenerator, HinSAGELinkGenerator", "from stellargraph.ensemble import Ensemble, BaggingEnsemble", "from tensorflow.keras import layers, Model", "from tensorflow.keras.optimizers import Adam", "from tensorflow.keras.losses import categorical_crossentropy, binary_crossentropy"], "code": "def test_ensemble_init_parameters():\n    tf.keras.backend.clear_session()\n    graph = example_graph_1(feature_size=10)\n    (base_model, keras_model, generator, train_gen) = create_graphSAGE_model(graph)\n    gnn_models = [create_graphSAGE_model(graph), create_HinSAGE_model(graph), create_graphSAGE_model(graph, link_prediction=True), create_HinSAGE_model(graph, link_prediction=True), create_GCN_model(graph), create_GAT_model(graph)]\n    for gnn_model in gnn_models:\n        base_model = gnn_model[0]\n        keras_model = gnn_model[1]\n        with pytest.raises(ValueError):\n            Ensemble(base_model, n_estimators=3, n_predictions=3)\n        with pytest.raises(ValueError):\n            Ensemble(keras_model, n_estimators=1, n_predictions=0)\n        with pytest.raises(ValueError):\n            Ensemble(keras_model, n_estimators=1, n_predictions=(- 3))\n        with pytest.raises(ValueError):\n            Ensemble(keras_model, n_estimators=1, n_predictions=1.7)\n        with pytest.raises(ValueError):\n            Ensemble(keras_model, n_estimators=0, n_predictions=11)\n        with pytest.raises(ValueError):\n            Ensemble(keras_model, n_estimators=(- 8), n_predictions=11)\n        with pytest.raises(ValueError):\n            Ensemble(keras_model, n_estimators=2.5, n_predictions=11)\n        ens = Ensemble(keras_model, n_estimators=7, n_predictions=10)\n        assert (len(ens.models) == 7)\n        assert (ens.n_estimators == 7)\n        assert (ens.n_predictions == 10)\n        with pytest.raises(ValueError):\n            BaggingEnsemble(base_model, n_estimators=3, n_predictions=3)\n        with pytest.raises(ValueError):\n            BaggingEnsemble(keras_model, n_estimators=1, n_predictions=0)\n        with pytest.raises(ValueError):\n            BaggingEnsemble(keras_model, n_estimators=1, n_predictions=(- 3))\n        with pytest.raises(ValueError):\n            BaggingEnsemble(keras_model, n_estimators=1, n_predictions=1.7)\n        with pytest.raises(ValueError):\n            BaggingEnsemble(keras_model, n_estimators=0, n_predictions=11)\n        with pytest.raises(ValueError):\n            BaggingEnsemble(keras_model, n_estimators=(- 8), n_predictions=11)\n        with pytest.raises(ValueError):\n            BaggingEnsemble(keras_model, n_estimators=2.5, n_predictions=11)\n        ens = BaggingEnsemble(keras_model, n_estimators=7, n_predictions=10)\n        assert (len(ens.models) == 7)\n        assert (ens.n_estimators == 7)\n        assert (ens.n_predictions == 10)", "masked_code": "def test_ensemble_init_parameters():\n    tf.keras.backend.clear_session()\n    graph = example_graph_1(feature_size=10)\n    (base_model, keras_model, generator, train_gen) = create_graphSAGE_model(graph)\n    gnn_models = [create_graphSAGE_model(graph), create_HinSAGE_model(graph), create_graphSAGE_model(graph, link_prediction=True), create_HinSAGE_model(graph, link_prediction=True), create_GCN_model(graph), create_GAT_model(graph)]\n    for gnn_model in gnn_models:\n        base_model = gnn_model[0]\n        keras_model = gnn_model[1]\n        with pytest.raises(ValueError):\n            Ensemble(base_model, n_estimators=3, n_predictions=3)\n        with pytest.raises(ValueError):\n            Ensemble(keras_model, n_estimators=1, n_predictions=0)\n        with pytest.raises(ValueError):\n            Ensemble(keras_model, n_estimators=1, n_predictions=(- 3))\n        with pytest.raises(ValueError):\n            Ensemble(keras_model, n_estimators=1, n_predictions=1.7)\n        with pytest.raises(ValueError):\n            Ensemble(keras_model, n_estimators=0, n_predictions=11)\n        with pytest.raises(ValueError):\n            Ensemble(keras_model, n_estimators=(- 8), n_predictions=11)\n        with pytest.raises(ValueError):\n            Ensemble(keras_model, n_estimators=2.5, n_predictions=11)\n        ens = Ensemble(keras_model, n_estimators=7, n_predictions=10)\n        assert (len(ens.models) == 7)\n        assert (ens.n_estimators == 7)\n        assert (ens.n_predictions == '???')\n        with pytest.raises(ValueError):\n            BaggingEnsemble(base_model, n_estimators=3, n_predictions=3)\n        with pytest.raises(ValueError):\n            BaggingEnsemble(keras_model, n_estimators=1, n_predictions=0)\n        with pytest.raises(ValueError):\n            BaggingEnsemble(keras_model, n_estimators=1, n_predictions=(- 3))\n        with pytest.raises(ValueError):\n            BaggingEnsemble(keras_model, n_estimators=1, n_predictions=1.7)\n        with pytest.raises(ValueError):\n            BaggingEnsemble(keras_model, n_estimators=0, n_predictions=11)\n        with pytest.raises(ValueError):\n            BaggingEnsemble(keras_model, n_estimators=(- 8), n_predictions=11)\n        with pytest.raises(ValueError):\n            BaggingEnsemble(keras_model, n_estimators=2.5, n_predictions=11)\n        ens = BaggingEnsemble(keras_model, n_estimators=7, n_predictions=10)\n        assert (len(ens.models) == 7)\n        assert (ens.n_estimators == 7)\n        assert (ens.n_predictions == 10)", "ground_truth": "10", "quality_analysis": {"complexity_score": 3, "left_complexity": 2, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_13", "reponame": "stellargraph", "testpath": "tests/test_ensemble.py", "testname": "test_ensemble.py", "classname": null, "funcname": "test_ensemble_init_parameters", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "import tensorflow as tf", "from stellargraph import StellarGraph", "from stellargraph.layer import GraphSAGE, GCN, GAT, HinSAGE, link_classification, link_regression", "from stellargraph.mapper import GraphSAGENodeGenerator, FullBatchNodeGenerator, HinSAGENodeGenerator, GraphSAGELinkGenerator, HinSAGELinkGenerator", "from stellargraph.ensemble import Ensemble, BaggingEnsemble", "from tensorflow.keras import layers, Model", "from tensorflow.keras.optimizers import Adam", "from tensorflow.keras.losses import categorical_crossentropy, binary_crossentropy"], "code": "def test_ensemble_init_parameters():\n    tf.keras.backend.clear_session()\n    graph = example_graph_1(feature_size=10)\n    (base_model, keras_model, generator, train_gen) = create_graphSAGE_model(graph)\n    gnn_models = [create_graphSAGE_model(graph), create_HinSAGE_model(graph), create_graphSAGE_model(graph, link_prediction=True), create_HinSAGE_model(graph, link_prediction=True), create_GCN_model(graph), create_GAT_model(graph)]\n    for gnn_model in gnn_models:\n        base_model = gnn_model[0]\n        keras_model = gnn_model[1]\n        with pytest.raises(ValueError):\n            Ensemble(base_model, n_estimators=3, n_predictions=3)\n        with pytest.raises(ValueError):\n            Ensemble(keras_model, n_estimators=1, n_predictions=0)\n        with pytest.raises(ValueError):\n            Ensemble(keras_model, n_estimators=1, n_predictions=(- 3))\n        with pytest.raises(ValueError):\n            Ensemble(keras_model, n_estimators=1, n_predictions=1.7)\n        with pytest.raises(ValueError):\n            Ensemble(keras_model, n_estimators=0, n_predictions=11)\n        with pytest.raises(ValueError):\n            Ensemble(keras_model, n_estimators=(- 8), n_predictions=11)\n        with pytest.raises(ValueError):\n            Ensemble(keras_model, n_estimators=2.5, n_predictions=11)\n        ens = Ensemble(keras_model, n_estimators=7, n_predictions=10)\n        assert (len(ens.models) == 7)\n        assert (ens.n_estimators == 7)\n        assert (ens.n_predictions == 10)\n        with pytest.raises(ValueError):\n            BaggingEnsemble(base_model, n_estimators=3, n_predictions=3)\n        with pytest.raises(ValueError):\n            BaggingEnsemble(keras_model, n_estimators=1, n_predictions=0)\n        with pytest.raises(ValueError):\n            BaggingEnsemble(keras_model, n_estimators=1, n_predictions=(- 3))\n        with pytest.raises(ValueError):\n            BaggingEnsemble(keras_model, n_estimators=1, n_predictions=1.7)\n        with pytest.raises(ValueError):\n            BaggingEnsemble(keras_model, n_estimators=0, n_predictions=11)\n        with pytest.raises(ValueError):\n            BaggingEnsemble(keras_model, n_estimators=(- 8), n_predictions=11)\n        with pytest.raises(ValueError):\n            BaggingEnsemble(keras_model, n_estimators=2.5, n_predictions=11)\n        ens = BaggingEnsemble(keras_model, n_estimators=7, n_predictions=10)\n        assert (len(ens.models) == 7)\n        assert (ens.n_estimators == 7)\n        assert (ens.n_predictions == 10)", "masked_code": "def test_ensemble_init_parameters():\n    tf.keras.backend.clear_session()\n    graph = example_graph_1(feature_size=10)\n    (base_model, keras_model, generator, train_gen) = create_graphSAGE_model(graph)\n    gnn_models = [create_graphSAGE_model(graph), create_HinSAGE_model(graph), create_graphSAGE_model(graph, link_prediction=True), create_HinSAGE_model(graph, link_prediction=True), create_GCN_model(graph), create_GAT_model(graph)]\n    for gnn_model in gnn_models:\n        base_model = gnn_model[0]\n        keras_model = gnn_model[1]\n        with pytest.raises(ValueError):\n            Ensemble(base_model, n_estimators=3, n_predictions=3)\n        with pytest.raises(ValueError):\n            Ensemble(keras_model, n_estimators=1, n_predictions=0)\n        with pytest.raises(ValueError):\n            Ensemble(keras_model, n_estimators=1, n_predictions=(- 3))\n        with pytest.raises(ValueError):\n            Ensemble(keras_model, n_estimators=1, n_predictions=1.7)\n        with pytest.raises(ValueError):\n            Ensemble(keras_model, n_estimators=0, n_predictions=11)\n        with pytest.raises(ValueError):\n            Ensemble(keras_model, n_estimators=(- 8), n_predictions=11)\n        with pytest.raises(ValueError):\n            Ensemble(keras_model, n_estimators=2.5, n_predictions=11)\n        ens = Ensemble(keras_model, n_estimators=7, n_predictions=10)\n        assert (len(ens.models) == 7)\n        assert (ens.n_estimators == 7)\n        assert (ens.n_predictions == 10)\n        with pytest.raises(ValueError):\n            BaggingEnsemble(base_model, n_estimators=3, n_predictions=3)\n        with pytest.raises(ValueError):\n            BaggingEnsemble(keras_model, n_estimators=1, n_predictions=0)\n        with pytest.raises(ValueError):\n            BaggingEnsemble(keras_model, n_estimators=1, n_predictions=(- 3))\n        with pytest.raises(ValueError):\n            BaggingEnsemble(keras_model, n_estimators=1, n_predictions=1.7)\n        with pytest.raises(ValueError):\n            BaggingEnsemble(keras_model, n_estimators=0, n_predictions=11)\n        with pytest.raises(ValueError):\n            BaggingEnsemble(keras_model, n_estimators=(- 8), n_predictions=11)\n        with pytest.raises(ValueError):\n            BaggingEnsemble(keras_model, n_estimators=2.5, n_predictions=11)\n        ens = BaggingEnsemble(keras_model, n_estimators=7, n_predictions=10)\n        assert (len(ens.models) == '???')\n        assert (ens.n_estimators == 7)\n        assert (ens.n_predictions == 10)", "ground_truth": "7", "quality_analysis": {"complexity_score": 6, "left_complexity": 5, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_14", "reponame": "stellargraph", "testpath": "tests/test_ensemble.py", "testname": "test_ensemble.py", "classname": null, "funcname": "test_ensemble_init_parameters", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "import tensorflow as tf", "from stellargraph import StellarGraph", "from stellargraph.layer import GraphSAGE, GCN, GAT, HinSAGE, link_classification, link_regression", "from stellargraph.mapper import GraphSAGENodeGenerator, FullBatchNodeGenerator, HinSAGENodeGenerator, GraphSAGELinkGenerator, HinSAGELinkGenerator", "from stellargraph.ensemble import Ensemble, BaggingEnsemble", "from tensorflow.keras import layers, Model", "from tensorflow.keras.optimizers import Adam", "from tensorflow.keras.losses import categorical_crossentropy, binary_crossentropy"], "code": "def test_ensemble_init_parameters():\n    tf.keras.backend.clear_session()\n    graph = example_graph_1(feature_size=10)\n    (base_model, keras_model, generator, train_gen) = create_graphSAGE_model(graph)\n    gnn_models = [create_graphSAGE_model(graph), create_HinSAGE_model(graph), create_graphSAGE_model(graph, link_prediction=True), create_HinSAGE_model(graph, link_prediction=True), create_GCN_model(graph), create_GAT_model(graph)]\n    for gnn_model in gnn_models:\n        base_model = gnn_model[0]\n        keras_model = gnn_model[1]\n        with pytest.raises(ValueError):\n            Ensemble(base_model, n_estimators=3, n_predictions=3)\n        with pytest.raises(ValueError):\n            Ensemble(keras_model, n_estimators=1, n_predictions=0)\n        with pytest.raises(ValueError):\n            Ensemble(keras_model, n_estimators=1, n_predictions=(- 3))\n        with pytest.raises(ValueError):\n            Ensemble(keras_model, n_estimators=1, n_predictions=1.7)\n        with pytest.raises(ValueError):\n            Ensemble(keras_model, n_estimators=0, n_predictions=11)\n        with pytest.raises(ValueError):\n            Ensemble(keras_model, n_estimators=(- 8), n_predictions=11)\n        with pytest.raises(ValueError):\n            Ensemble(keras_model, n_estimators=2.5, n_predictions=11)\n        ens = Ensemble(keras_model, n_estimators=7, n_predictions=10)\n        assert (len(ens.models) == 7)\n        assert (ens.n_estimators == 7)\n        assert (ens.n_predictions == 10)\n        with pytest.raises(ValueError):\n            BaggingEnsemble(base_model, n_estimators=3, n_predictions=3)\n        with pytest.raises(ValueError):\n            BaggingEnsemble(keras_model, n_estimators=1, n_predictions=0)\n        with pytest.raises(ValueError):\n            BaggingEnsemble(keras_model, n_estimators=1, n_predictions=(- 3))\n        with pytest.raises(ValueError):\n            BaggingEnsemble(keras_model, n_estimators=1, n_predictions=1.7)\n        with pytest.raises(ValueError):\n            BaggingEnsemble(keras_model, n_estimators=0, n_predictions=11)\n        with pytest.raises(ValueError):\n            BaggingEnsemble(keras_model, n_estimators=(- 8), n_predictions=11)\n        with pytest.raises(ValueError):\n            BaggingEnsemble(keras_model, n_estimators=2.5, n_predictions=11)\n        ens = BaggingEnsemble(keras_model, n_estimators=7, n_predictions=10)\n        assert (len(ens.models) == 7)\n        assert (ens.n_estimators == 7)\n        assert (ens.n_predictions == 10)", "masked_code": "def test_ensemble_init_parameters():\n    tf.keras.backend.clear_session()\n    graph = example_graph_1(feature_size=10)\n    (base_model, keras_model, generator, train_gen) = create_graphSAGE_model(graph)\n    gnn_models = [create_graphSAGE_model(graph), create_HinSAGE_model(graph), create_graphSAGE_model(graph, link_prediction=True), create_HinSAGE_model(graph, link_prediction=True), create_GCN_model(graph), create_GAT_model(graph)]\n    for gnn_model in gnn_models:\n        base_model = gnn_model[0]\n        keras_model = gnn_model[1]\n        with pytest.raises(ValueError):\n            Ensemble(base_model, n_estimators=3, n_predictions=3)\n        with pytest.raises(ValueError):\n            Ensemble(keras_model, n_estimators=1, n_predictions=0)\n        with pytest.raises(ValueError):\n            Ensemble(keras_model, n_estimators=1, n_predictions=(- 3))\n        with pytest.raises(ValueError):\n            Ensemble(keras_model, n_estimators=1, n_predictions=1.7)\n        with pytest.raises(ValueError):\n            Ensemble(keras_model, n_estimators=0, n_predictions=11)\n        with pytest.raises(ValueError):\n            Ensemble(keras_model, n_estimators=(- 8), n_predictions=11)\n        with pytest.raises(ValueError):\n            Ensemble(keras_model, n_estimators=2.5, n_predictions=11)\n        ens = Ensemble(keras_model, n_estimators=7, n_predictions=10)\n        assert (len(ens.models) == 7)\n        assert (ens.n_estimators == 7)\n        assert (ens.n_predictions == 10)\n        with pytest.raises(ValueError):\n            BaggingEnsemble(base_model, n_estimators=3, n_predictions=3)\n        with pytest.raises(ValueError):\n            BaggingEnsemble(keras_model, n_estimators=1, n_predictions=0)\n        with pytest.raises(ValueError):\n            BaggingEnsemble(keras_model, n_estimators=1, n_predictions=(- 3))\n        with pytest.raises(ValueError):\n            BaggingEnsemble(keras_model, n_estimators=1, n_predictions=1.7)\n        with pytest.raises(ValueError):\n            BaggingEnsemble(keras_model, n_estimators=0, n_predictions=11)\n        with pytest.raises(ValueError):\n            BaggingEnsemble(keras_model, n_estimators=(- 8), n_predictions=11)\n        with pytest.raises(ValueError):\n            BaggingEnsemble(keras_model, n_estimators=2.5, n_predictions=11)\n        ens = BaggingEnsemble(keras_model, n_estimators=7, n_predictions=10)\n        assert (len(ens.models) == 7)\n        assert (ens.n_estimators == '???')\n        assert (ens.n_predictions == 10)", "ground_truth": "7", "quality_analysis": {"complexity_score": 3, "left_complexity": 2, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_15", "reponame": "stellargraph", "testpath": "tests/test_ensemble.py", "testname": "test_ensemble.py", "classname": null, "funcname": "test_ensemble_init_parameters", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "import tensorflow as tf", "from stellargraph import StellarGraph", "from stellargraph.layer import GraphSAGE, GCN, GAT, HinSAGE, link_classification, link_regression", "from stellargraph.mapper import GraphSAGENodeGenerator, FullBatchNodeGenerator, HinSAGENodeGenerator, GraphSAGELinkGenerator, HinSAGELinkGenerator", "from stellargraph.ensemble import Ensemble, BaggingEnsemble", "from tensorflow.keras import layers, Model", "from tensorflow.keras.optimizers import Adam", "from tensorflow.keras.losses import categorical_crossentropy, binary_crossentropy"], "code": "def test_ensemble_init_parameters():\n    tf.keras.backend.clear_session()\n    graph = example_graph_1(feature_size=10)\n    (base_model, keras_model, generator, train_gen) = create_graphSAGE_model(graph)\n    gnn_models = [create_graphSAGE_model(graph), create_HinSAGE_model(graph), create_graphSAGE_model(graph, link_prediction=True), create_HinSAGE_model(graph, link_prediction=True), create_GCN_model(graph), create_GAT_model(graph)]\n    for gnn_model in gnn_models:\n        base_model = gnn_model[0]\n        keras_model = gnn_model[1]\n        with pytest.raises(ValueError):\n            Ensemble(base_model, n_estimators=3, n_predictions=3)\n        with pytest.raises(ValueError):\n            Ensemble(keras_model, n_estimators=1, n_predictions=0)\n        with pytest.raises(ValueError):\n            Ensemble(keras_model, n_estimators=1, n_predictions=(- 3))\n        with pytest.raises(ValueError):\n            Ensemble(keras_model, n_estimators=1, n_predictions=1.7)\n        with pytest.raises(ValueError):\n            Ensemble(keras_model, n_estimators=0, n_predictions=11)\n        with pytest.raises(ValueError):\n            Ensemble(keras_model, n_estimators=(- 8), n_predictions=11)\n        with pytest.raises(ValueError):\n            Ensemble(keras_model, n_estimators=2.5, n_predictions=11)\n        ens = Ensemble(keras_model, n_estimators=7, n_predictions=10)\n        assert (len(ens.models) == 7)\n        assert (ens.n_estimators == 7)\n        assert (ens.n_predictions == 10)\n        with pytest.raises(ValueError):\n            BaggingEnsemble(base_model, n_estimators=3, n_predictions=3)\n        with pytest.raises(ValueError):\n            BaggingEnsemble(keras_model, n_estimators=1, n_predictions=0)\n        with pytest.raises(ValueError):\n            BaggingEnsemble(keras_model, n_estimators=1, n_predictions=(- 3))\n        with pytest.raises(ValueError):\n            BaggingEnsemble(keras_model, n_estimators=1, n_predictions=1.7)\n        with pytest.raises(ValueError):\n            BaggingEnsemble(keras_model, n_estimators=0, n_predictions=11)\n        with pytest.raises(ValueError):\n            BaggingEnsemble(keras_model, n_estimators=(- 8), n_predictions=11)\n        with pytest.raises(ValueError):\n            BaggingEnsemble(keras_model, n_estimators=2.5, n_predictions=11)\n        ens = BaggingEnsemble(keras_model, n_estimators=7, n_predictions=10)\n        assert (len(ens.models) == 7)\n        assert (ens.n_estimators == 7)\n        assert (ens.n_predictions == 10)", "masked_code": "def test_ensemble_init_parameters():\n    tf.keras.backend.clear_session()\n    graph = example_graph_1(feature_size=10)\n    (base_model, keras_model, generator, train_gen) = create_graphSAGE_model(graph)\n    gnn_models = [create_graphSAGE_model(graph), create_HinSAGE_model(graph), create_graphSAGE_model(graph, link_prediction=True), create_HinSAGE_model(graph, link_prediction=True), create_GCN_model(graph), create_GAT_model(graph)]\n    for gnn_model in gnn_models:\n        base_model = gnn_model[0]\n        keras_model = gnn_model[1]\n        with pytest.raises(ValueError):\n            Ensemble(base_model, n_estimators=3, n_predictions=3)\n        with pytest.raises(ValueError):\n            Ensemble(keras_model, n_estimators=1, n_predictions=0)\n        with pytest.raises(ValueError):\n            Ensemble(keras_model, n_estimators=1, n_predictions=(- 3))\n        with pytest.raises(ValueError):\n            Ensemble(keras_model, n_estimators=1, n_predictions=1.7)\n        with pytest.raises(ValueError):\n            Ensemble(keras_model, n_estimators=0, n_predictions=11)\n        with pytest.raises(ValueError):\n            Ensemble(keras_model, n_estimators=(- 8), n_predictions=11)\n        with pytest.raises(ValueError):\n            Ensemble(keras_model, n_estimators=2.5, n_predictions=11)\n        ens = Ensemble(keras_model, n_estimators=7, n_predictions=10)\n        assert (len(ens.models) == 7)\n        assert (ens.n_estimators == 7)\n        assert (ens.n_predictions == 10)\n        with pytest.raises(ValueError):\n            BaggingEnsemble(base_model, n_estimators=3, n_predictions=3)\n        with pytest.raises(ValueError):\n            BaggingEnsemble(keras_model, n_estimators=1, n_predictions=0)\n        with pytest.raises(ValueError):\n            BaggingEnsemble(keras_model, n_estimators=1, n_predictions=(- 3))\n        with pytest.raises(ValueError):\n            BaggingEnsemble(keras_model, n_estimators=1, n_predictions=1.7)\n        with pytest.raises(ValueError):\n            BaggingEnsemble(keras_model, n_estimators=0, n_predictions=11)\n        with pytest.raises(ValueError):\n            BaggingEnsemble(keras_model, n_estimators=(- 8), n_predictions=11)\n        with pytest.raises(ValueError):\n            BaggingEnsemble(keras_model, n_estimators=2.5, n_predictions=11)\n        ens = BaggingEnsemble(keras_model, n_estimators=7, n_predictions=10)\n        assert (len(ens.models) == 7)\n        assert (ens.n_estimators == 7)\n        assert (ens.n_predictions == '???')", "ground_truth": "10", "quality_analysis": {"complexity_score": 3, "left_complexity": 2, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_16", "reponame": "stellargraph", "testpath": "tests/test_ensemble.py", "testname": "test_ensemble.py", "classname": null, "funcname": "test_evaluate", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "import tensorflow as tf", "from stellargraph import StellarGraph", "from stellargraph.layer import GraphSAGE, GCN, GAT, HinSAGE, link_classification, link_regression", "from stellargraph.mapper import GraphSAGENodeGenerator, FullBatchNodeGenerator, HinSAGENodeGenerator, GraphSAGELinkGenerator, HinSAGELinkGenerator", "from stellargraph.ensemble import Ensemble, BaggingEnsemble", "from tensorflow.keras import layers, Model", "from tensorflow.keras.optimizers import Adam", "from tensorflow.keras.losses import categorical_crossentropy, binary_crossentropy"], "code": "def test_evaluate():\n    tf.keras.backend.clear_session()\n    test_data = np.array([3, 4, 5])\n    test_targets = np.array([[1, 0], [0, 1], [0, 1]])\n    graph = example_graph_1(feature_size=5)\n    gnn_models = [create_graphSAGE_model(graph), create_HinSAGE_model(graph), create_GCN_model(graph), create_GAT_model(graph)]\n    for gnn_model in gnn_models:\n        keras_model = gnn_model[1]\n        generator = gnn_model[2]\n        ens = Ensemble(keras_model, n_estimators=2, n_predictions=1)\n        ens.compile(optimizer=Adam(), loss=categorical_crossentropy, weighted_metrics=['acc'])\n        with pytest.raises(ValueError):\n            ens.evaluate(generator=generator, test_data=test_data, test_targets=test_targets)\n        with pytest.raises(ValueError):\n            ens.evaluate(generator=generator, test_data=test_data, test_targets=None)\n        with pytest.raises(ValueError):\n            ens.evaluate(generator=generator.flow(test_data, test_targets), test_data=test_data, test_targets=test_targets)\n        (test_metrics_mean, test_metrics_std) = ens.evaluate(generator.flow(test_data, test_targets))\n        assert (len(test_metrics_mean) == len(test_metrics_std))\n        assert (len(test_metrics_mean.shape) == 1)\n        assert (len(test_metrics_std.shape) == 1)\n        ens = BaggingEnsemble(keras_model, n_estimators=2, n_predictions=1)\n        ens.compile(optimizer=Adam(), loss=categorical_crossentropy, weighted_metrics=['acc'])\n        with pytest.raises(ValueError):\n            ens.evaluate(generator=generator, test_data=test_data, test_targets=test_targets)\n        with pytest.raises(ValueError):\n            ens.evaluate(generator=generator, test_data=test_data, test_targets=None)\n        with pytest.raises(ValueError):\n            ens.evaluate(generator=generator.flow(test_data, test_targets), test_data=test_data, test_targets=test_targets)\n        (test_metrics_mean, test_metrics_std) = ens.evaluate(generator.flow(test_data, test_targets))\n        assert (len(test_metrics_mean) == len(test_metrics_std))\n        assert (len(test_metrics_mean.shape) == 1)\n        assert (len(test_metrics_std.shape) == 1)", "masked_code": "def test_evaluate():\n    tf.keras.backend.clear_session()\n    test_data = np.array([3, 4, 5])\n    test_targets = np.array([[1, 0], [0, 1], [0, 1]])\n    graph = example_graph_1(feature_size=5)\n    gnn_models = [create_graphSAGE_model(graph), create_HinSAGE_model(graph), create_GCN_model(graph), create_GAT_model(graph)]\n    for gnn_model in gnn_models:\n        keras_model = gnn_model[1]\n        generator = gnn_model[2]\n        ens = Ensemble(keras_model, n_estimators=2, n_predictions=1)\n        ens.compile(optimizer=Adam(), loss=categorical_crossentropy, weighted_metrics=['acc'])\n        with pytest.raises(ValueError):\n            ens.evaluate(generator=generator, test_data=test_data, test_targets=test_targets)\n        with pytest.raises(ValueError):\n            ens.evaluate(generator=generator, test_data=test_data, test_targets=None)\n        with pytest.raises(ValueError):\n            ens.evaluate(generator=generator.flow(test_data, test_targets), test_data=test_data, test_targets=test_targets)\n        (test_metrics_mean, test_metrics_std) = ens.evaluate(generator.flow(test_data, test_targets))\n        assert (len(test_metrics_mean) == '???')\n        assert (len(test_metrics_mean.shape) == 1)\n        assert (len(test_metrics_std.shape) == 1)\n        ens = BaggingEnsemble(keras_model, n_estimators=2, n_predictions=1)\n        ens.compile(optimizer=Adam(), loss=categorical_crossentropy, weighted_metrics=['acc'])\n        with pytest.raises(ValueError):\n            ens.evaluate(generator=generator, test_data=test_data, test_targets=test_targets)\n        with pytest.raises(ValueError):\n            ens.evaluate(generator=generator, test_data=test_data, test_targets=None)\n        with pytest.raises(ValueError):\n            ens.evaluate(generator=generator.flow(test_data, test_targets), test_data=test_data, test_targets=test_targets)\n        (test_metrics_mean, test_metrics_std) = ens.evaluate(generator.flow(test_data, test_targets))\n        assert (len(test_metrics_mean) == len(test_metrics_std))\n        assert (len(test_metrics_mean.shape) == 1)\n        assert (len(test_metrics_std.shape) == 1)", "ground_truth": "len(test_metrics_std)", "quality_analysis": {"complexity_score": 8, "left_complexity": 4, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_17", "reponame": "stellargraph", "testpath": "tests/test_ensemble.py", "testname": "test_ensemble.py", "classname": null, "funcname": "test_evaluate", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "import tensorflow as tf", "from stellargraph import StellarGraph", "from stellargraph.layer import GraphSAGE, GCN, GAT, HinSAGE, link_classification, link_regression", "from stellargraph.mapper import GraphSAGENodeGenerator, FullBatchNodeGenerator, HinSAGENodeGenerator, GraphSAGELinkGenerator, HinSAGELinkGenerator", "from stellargraph.ensemble import Ensemble, BaggingEnsemble", "from tensorflow.keras import layers, Model", "from tensorflow.keras.optimizers import Adam", "from tensorflow.keras.losses import categorical_crossentropy, binary_crossentropy"], "code": "def test_evaluate():\n    tf.keras.backend.clear_session()\n    test_data = np.array([3, 4, 5])\n    test_targets = np.array([[1, 0], [0, 1], [0, 1]])\n    graph = example_graph_1(feature_size=5)\n    gnn_models = [create_graphSAGE_model(graph), create_HinSAGE_model(graph), create_GCN_model(graph), create_GAT_model(graph)]\n    for gnn_model in gnn_models:\n        keras_model = gnn_model[1]\n        generator = gnn_model[2]\n        ens = Ensemble(keras_model, n_estimators=2, n_predictions=1)\n        ens.compile(optimizer=Adam(), loss=categorical_crossentropy, weighted_metrics=['acc'])\n        with pytest.raises(ValueError):\n            ens.evaluate(generator=generator, test_data=test_data, test_targets=test_targets)\n        with pytest.raises(ValueError):\n            ens.evaluate(generator=generator, test_data=test_data, test_targets=None)\n        with pytest.raises(ValueError):\n            ens.evaluate(generator=generator.flow(test_data, test_targets), test_data=test_data, test_targets=test_targets)\n        (test_metrics_mean, test_metrics_std) = ens.evaluate(generator.flow(test_data, test_targets))\n        assert (len(test_metrics_mean) == len(test_metrics_std))\n        assert (len(test_metrics_mean.shape) == 1)\n        assert (len(test_metrics_std.shape) == 1)\n        ens = BaggingEnsemble(keras_model, n_estimators=2, n_predictions=1)\n        ens.compile(optimizer=Adam(), loss=categorical_crossentropy, weighted_metrics=['acc'])\n        with pytest.raises(ValueError):\n            ens.evaluate(generator=generator, test_data=test_data, test_targets=test_targets)\n        with pytest.raises(ValueError):\n            ens.evaluate(generator=generator, test_data=test_data, test_targets=None)\n        with pytest.raises(ValueError):\n            ens.evaluate(generator=generator.flow(test_data, test_targets), test_data=test_data, test_targets=test_targets)\n        (test_metrics_mean, test_metrics_std) = ens.evaluate(generator.flow(test_data, test_targets))\n        assert (len(test_metrics_mean) == len(test_metrics_std))\n        assert (len(test_metrics_mean.shape) == 1)\n        assert (len(test_metrics_std.shape) == 1)", "masked_code": "def test_evaluate():\n    tf.keras.backend.clear_session()\n    test_data = np.array([3, 4, 5])\n    test_targets = np.array([[1, 0], [0, 1], [0, 1]])\n    graph = example_graph_1(feature_size=5)\n    gnn_models = [create_graphSAGE_model(graph), create_HinSAGE_model(graph), create_GCN_model(graph), create_GAT_model(graph)]\n    for gnn_model in gnn_models:\n        keras_model = gnn_model[1]\n        generator = gnn_model[2]\n        ens = Ensemble(keras_model, n_estimators=2, n_predictions=1)\n        ens.compile(optimizer=Adam(), loss=categorical_crossentropy, weighted_metrics=['acc'])\n        with pytest.raises(ValueError):\n            ens.evaluate(generator=generator, test_data=test_data, test_targets=test_targets)\n        with pytest.raises(ValueError):\n            ens.evaluate(generator=generator, test_data=test_data, test_targets=None)\n        with pytest.raises(ValueError):\n            ens.evaluate(generator=generator.flow(test_data, test_targets), test_data=test_data, test_targets=test_targets)\n        (test_metrics_mean, test_metrics_std) = ens.evaluate(generator.flow(test_data, test_targets))\n        assert (len(test_metrics_mean) == len(test_metrics_std))\n        assert (len(test_metrics_mean.shape) == 1)\n        assert (len(test_metrics_std.shape) == 1)\n        ens = BaggingEnsemble(keras_model, n_estimators=2, n_predictions=1)\n        ens.compile(optimizer=Adam(), loss=categorical_crossentropy, weighted_metrics=['acc'])\n        with pytest.raises(ValueError):\n            ens.evaluate(generator=generator, test_data=test_data, test_targets=test_targets)\n        with pytest.raises(ValueError):\n            ens.evaluate(generator=generator, test_data=test_data, test_targets=None)\n        with pytest.raises(ValueError):\n            ens.evaluate(generator=generator.flow(test_data, test_targets), test_data=test_data, test_targets=test_targets)\n        (test_metrics_mean, test_metrics_std) = ens.evaluate(generator.flow(test_data, test_targets))\n        assert (len(test_metrics_mean) == '???')\n        assert (len(test_metrics_mean.shape) == 1)\n        assert (len(test_metrics_std.shape) == 1)", "ground_truth": "len(test_metrics_std)", "quality_analysis": {"complexity_score": 8, "left_complexity": 4, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_18", "reponame": "stellargraph", "testpath": "tests/test_ensemble.py", "testname": "test_ensemble.py", "classname": null, "funcname": "test_predict", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "import tensorflow as tf", "from stellargraph import StellarGraph", "from stellargraph.layer import GraphSAGE, GCN, GAT, HinSAGE, link_classification, link_regression", "from stellargraph.mapper import GraphSAGENodeGenerator, FullBatchNodeGenerator, HinSAGENodeGenerator, GraphSAGELinkGenerator, HinSAGELinkGenerator", "from stellargraph.ensemble import Ensemble, BaggingEnsemble", "from tensorflow.keras import layers, Model", "from tensorflow.keras.optimizers import Adam", "from tensorflow.keras.losses import categorical_crossentropy, binary_crossentropy"], "code": "def test_predict():\n    tf.keras.backend.clear_session()\n    test_data = np.array([4, 5, 6])\n    test_targets = np.array([[1, 0], [0, 1], [0, 1]])\n    graph = example_graph_1(feature_size=2)\n    gnn_models = [create_graphSAGE_model(graph), create_HinSAGE_model(graph), create_GCN_model(graph), create_GAT_model(graph)]\n    for (i, gnn_model) in enumerate(gnn_models):\n        keras_model = gnn_model[1]\n        generator = gnn_model[2]\n        ens = Ensemble(keras_model, n_estimators=2, n_predictions=2)\n        ens.compile(optimizer=Adam(), loss=categorical_crossentropy, weighted_metrics=['acc'])\n        test_gen = generator.flow(test_data)\n        with pytest.raises(ValueError):\n            ens.predict(generator=test_gen, predict_data=test_data)\n        test_predictions = ens.predict(test_gen, summarise=True)\n        print('test_predictions shape {}'.format(test_predictions.shape))\n        if (i > 1):\n            assert (len(test_predictions) == 1)\n            assert (test_predictions.shape[1] == test_targets.shape[0])\n        else:\n            assert (len(test_predictions) == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])\n        test_predictions = ens.predict(test_gen, summarise=False)\n        assert (test_predictions.shape[0] == ens.n_estimators)\n        assert (test_predictions.shape[1] == ens.n_predictions)\n        if (i > 1):\n            assert (test_predictions.shape[2] == 1)\n        else:\n            assert (test_predictions.shape[2] == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])\n        ens = BaggingEnsemble(keras_model, n_estimators=2, n_predictions=2)\n        ens.compile(optimizer=Adam(), loss=categorical_crossentropy, weighted_metrics=['acc'])\n        test_gen = generator.flow(test_data)\n        with pytest.raises(ValueError):\n            ens.predict(generator=test_gen, predict_data=test_data)\n        test_predictions = ens.predict(test_gen, summarise=True)\n        print('test_predictions shape {}'.format(test_predictions.shape))\n        if (i > 1):\n            assert (len(test_predictions) == 1)\n            assert (test_predictions.shape[1] == test_targets.shape[0])\n        else:\n            assert (len(test_predictions) == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])\n        test_predictions = ens.predict(test_gen, summarise=False)\n        assert (test_predictions.shape[0] == ens.n_estimators)\n        assert (test_predictions.shape[1] == ens.n_predictions)\n        if (i > 1):\n            assert (test_predictions.shape[2] == 1)\n        else:\n            assert (test_predictions.shape[2] == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])", "masked_code": "def test_predict():\n    tf.keras.backend.clear_session()\n    test_data = np.array([4, 5, 6])\n    test_targets = np.array([[1, 0], [0, 1], [0, 1]])\n    graph = example_graph_1(feature_size=2)\n    gnn_models = [create_graphSAGE_model(graph), create_HinSAGE_model(graph), create_GCN_model(graph), create_GAT_model(graph)]\n    for (i, gnn_model) in enumerate(gnn_models):\n        keras_model = gnn_model[1]\n        generator = gnn_model[2]\n        ens = Ensemble(keras_model, n_estimators=2, n_predictions=2)\n        ens.compile(optimizer=Adam(), loss=categorical_crossentropy, weighted_metrics=['acc'])\n        test_gen = generator.flow(test_data)\n        with pytest.raises(ValueError):\n            ens.predict(generator=test_gen, predict_data=test_data)\n        test_predictions = ens.predict(test_gen, summarise=True)\n        print('test_predictions shape {}'.format(test_predictions.shape))\n        if (i > 1):\n            assert (len(test_predictions) == 1)\n            assert (test_predictions.shape[1] == test_targets.shape[0])\n        else:\n            assert (len(test_predictions) == len(test_data))\n        assert (test_predictions.shape[(- 1)] == '???')\n        test_predictions = ens.predict(test_gen, summarise=False)\n        assert (test_predictions.shape[0] == ens.n_estimators)\n        assert (test_predictions.shape[1] == ens.n_predictions)\n        if (i > 1):\n            assert (test_predictions.shape[2] == 1)\n        else:\n            assert (test_predictions.shape[2] == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])\n        ens = BaggingEnsemble(keras_model, n_estimators=2, n_predictions=2)\n        ens.compile(optimizer=Adam(), loss=categorical_crossentropy, weighted_metrics=['acc'])\n        test_gen = generator.flow(test_data)\n        with pytest.raises(ValueError):\n            ens.predict(generator=test_gen, predict_data=test_data)\n        test_predictions = ens.predict(test_gen, summarise=True)\n        print('test_predictions shape {}'.format(test_predictions.shape))\n        if (i > 1):\n            assert (len(test_predictions) == 1)\n            assert (test_predictions.shape[1] == test_targets.shape[0])\n        else:\n            assert (len(test_predictions) == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])\n        test_predictions = ens.predict(test_gen, summarise=False)\n        assert (test_predictions.shape[0] == ens.n_estimators)\n        assert (test_predictions.shape[1] == ens.n_predictions)\n        if (i > 1):\n            assert (test_predictions.shape[2] == 1)\n        else:\n            assert (test_predictions.shape[2] == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])", "ground_truth": "test_targets.shape[(- 1)]", "quality_analysis": {"complexity_score": 16, "left_complexity": 8, "right_complexity": 8, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_19", "reponame": "stellargraph", "testpath": "tests/test_ensemble.py", "testname": "test_ensemble.py", "classname": null, "funcname": "test_predict", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "import tensorflow as tf", "from stellargraph import StellarGraph", "from stellargraph.layer import GraphSAGE, GCN, GAT, HinSAGE, link_classification, link_regression", "from stellargraph.mapper import GraphSAGENodeGenerator, FullBatchNodeGenerator, HinSAGENodeGenerator, GraphSAGELinkGenerator, HinSAGELinkGenerator", "from stellargraph.ensemble import Ensemble, BaggingEnsemble", "from tensorflow.keras import layers, Model", "from tensorflow.keras.optimizers import Adam", "from tensorflow.keras.losses import categorical_crossentropy, binary_crossentropy"], "code": "def test_predict():\n    tf.keras.backend.clear_session()\n    test_data = np.array([4, 5, 6])\n    test_targets = np.array([[1, 0], [0, 1], [0, 1]])\n    graph = example_graph_1(feature_size=2)\n    gnn_models = [create_graphSAGE_model(graph), create_HinSAGE_model(graph), create_GCN_model(graph), create_GAT_model(graph)]\n    for (i, gnn_model) in enumerate(gnn_models):\n        keras_model = gnn_model[1]\n        generator = gnn_model[2]\n        ens = Ensemble(keras_model, n_estimators=2, n_predictions=2)\n        ens.compile(optimizer=Adam(), loss=categorical_crossentropy, weighted_metrics=['acc'])\n        test_gen = generator.flow(test_data)\n        with pytest.raises(ValueError):\n            ens.predict(generator=test_gen, predict_data=test_data)\n        test_predictions = ens.predict(test_gen, summarise=True)\n        print('test_predictions shape {}'.format(test_predictions.shape))\n        if (i > 1):\n            assert (len(test_predictions) == 1)\n            assert (test_predictions.shape[1] == test_targets.shape[0])\n        else:\n            assert (len(test_predictions) == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])\n        test_predictions = ens.predict(test_gen, summarise=False)\n        assert (test_predictions.shape[0] == ens.n_estimators)\n        assert (test_predictions.shape[1] == ens.n_predictions)\n        if (i > 1):\n            assert (test_predictions.shape[2] == 1)\n        else:\n            assert (test_predictions.shape[2] == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])\n        ens = BaggingEnsemble(keras_model, n_estimators=2, n_predictions=2)\n        ens.compile(optimizer=Adam(), loss=categorical_crossentropy, weighted_metrics=['acc'])\n        test_gen = generator.flow(test_data)\n        with pytest.raises(ValueError):\n            ens.predict(generator=test_gen, predict_data=test_data)\n        test_predictions = ens.predict(test_gen, summarise=True)\n        print('test_predictions shape {}'.format(test_predictions.shape))\n        if (i > 1):\n            assert (len(test_predictions) == 1)\n            assert (test_predictions.shape[1] == test_targets.shape[0])\n        else:\n            assert (len(test_predictions) == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])\n        test_predictions = ens.predict(test_gen, summarise=False)\n        assert (test_predictions.shape[0] == ens.n_estimators)\n        assert (test_predictions.shape[1] == ens.n_predictions)\n        if (i > 1):\n            assert (test_predictions.shape[2] == 1)\n        else:\n            assert (test_predictions.shape[2] == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])", "masked_code": "def test_predict():\n    tf.keras.backend.clear_session()\n    test_data = np.array([4, 5, 6])\n    test_targets = np.array([[1, 0], [0, 1], [0, 1]])\n    graph = example_graph_1(feature_size=2)\n    gnn_models = [create_graphSAGE_model(graph), create_HinSAGE_model(graph), create_GCN_model(graph), create_GAT_model(graph)]\n    for (i, gnn_model) in enumerate(gnn_models):\n        keras_model = gnn_model[1]\n        generator = gnn_model[2]\n        ens = Ensemble(keras_model, n_estimators=2, n_predictions=2)\n        ens.compile(optimizer=Adam(), loss=categorical_crossentropy, weighted_metrics=['acc'])\n        test_gen = generator.flow(test_data)\n        with pytest.raises(ValueError):\n            ens.predict(generator=test_gen, predict_data=test_data)\n        test_predictions = ens.predict(test_gen, summarise=True)\n        print('test_predictions shape {}'.format(test_predictions.shape))\n        if (i > 1):\n            assert (len(test_predictions) == 1)\n            assert (test_predictions.shape[1] == test_targets.shape[0])\n        else:\n            assert (len(test_predictions) == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])\n        test_predictions = ens.predict(test_gen, summarise=False)\n        assert (test_predictions.shape[0] == '???')\n        assert (test_predictions.shape[1] == ens.n_predictions)\n        if (i > 1):\n            assert (test_predictions.shape[2] == 1)\n        else:\n            assert (test_predictions.shape[2] == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])\n        ens = BaggingEnsemble(keras_model, n_estimators=2, n_predictions=2)\n        ens.compile(optimizer=Adam(), loss=categorical_crossentropy, weighted_metrics=['acc'])\n        test_gen = generator.flow(test_data)\n        with pytest.raises(ValueError):\n            ens.predict(generator=test_gen, predict_data=test_data)\n        test_predictions = ens.predict(test_gen, summarise=True)\n        print('test_predictions shape {}'.format(test_predictions.shape))\n        if (i > 1):\n            assert (len(test_predictions) == 1)\n            assert (test_predictions.shape[1] == test_targets.shape[0])\n        else:\n            assert (len(test_predictions) == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])\n        test_predictions = ens.predict(test_gen, summarise=False)\n        assert (test_predictions.shape[0] == ens.n_estimators)\n        assert (test_predictions.shape[1] == ens.n_predictions)\n        if (i > 1):\n            assert (test_predictions.shape[2] == 1)\n        else:\n            assert (test_predictions.shape[2] == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])", "ground_truth": "ens.n_estimators", "quality_analysis": {"complexity_score": 8, "left_complexity": 6, "right_complexity": 2, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_20", "reponame": "stellargraph", "testpath": "tests/test_ensemble.py", "testname": "test_ensemble.py", "classname": null, "funcname": "test_predict", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "import tensorflow as tf", "from stellargraph import StellarGraph", "from stellargraph.layer import GraphSAGE, GCN, GAT, HinSAGE, link_classification, link_regression", "from stellargraph.mapper import GraphSAGENodeGenerator, FullBatchNodeGenerator, HinSAGENodeGenerator, GraphSAGELinkGenerator, HinSAGELinkGenerator", "from stellargraph.ensemble import Ensemble, BaggingEnsemble", "from tensorflow.keras import layers, Model", "from tensorflow.keras.optimizers import Adam", "from tensorflow.keras.losses import categorical_crossentropy, binary_crossentropy"], "code": "def test_predict():\n    tf.keras.backend.clear_session()\n    test_data = np.array([4, 5, 6])\n    test_targets = np.array([[1, 0], [0, 1], [0, 1]])\n    graph = example_graph_1(feature_size=2)\n    gnn_models = [create_graphSAGE_model(graph), create_HinSAGE_model(graph), create_GCN_model(graph), create_GAT_model(graph)]\n    for (i, gnn_model) in enumerate(gnn_models):\n        keras_model = gnn_model[1]\n        generator = gnn_model[2]\n        ens = Ensemble(keras_model, n_estimators=2, n_predictions=2)\n        ens.compile(optimizer=Adam(), loss=categorical_crossentropy, weighted_metrics=['acc'])\n        test_gen = generator.flow(test_data)\n        with pytest.raises(ValueError):\n            ens.predict(generator=test_gen, predict_data=test_data)\n        test_predictions = ens.predict(test_gen, summarise=True)\n        print('test_predictions shape {}'.format(test_predictions.shape))\n        if (i > 1):\n            assert (len(test_predictions) == 1)\n            assert (test_predictions.shape[1] == test_targets.shape[0])\n        else:\n            assert (len(test_predictions) == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])\n        test_predictions = ens.predict(test_gen, summarise=False)\n        assert (test_predictions.shape[0] == ens.n_estimators)\n        assert (test_predictions.shape[1] == ens.n_predictions)\n        if (i > 1):\n            assert (test_predictions.shape[2] == 1)\n        else:\n            assert (test_predictions.shape[2] == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])\n        ens = BaggingEnsemble(keras_model, n_estimators=2, n_predictions=2)\n        ens.compile(optimizer=Adam(), loss=categorical_crossentropy, weighted_metrics=['acc'])\n        test_gen = generator.flow(test_data)\n        with pytest.raises(ValueError):\n            ens.predict(generator=test_gen, predict_data=test_data)\n        test_predictions = ens.predict(test_gen, summarise=True)\n        print('test_predictions shape {}'.format(test_predictions.shape))\n        if (i > 1):\n            assert (len(test_predictions) == 1)\n            assert (test_predictions.shape[1] == test_targets.shape[0])\n        else:\n            assert (len(test_predictions) == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])\n        test_predictions = ens.predict(test_gen, summarise=False)\n        assert (test_predictions.shape[0] == ens.n_estimators)\n        assert (test_predictions.shape[1] == ens.n_predictions)\n        if (i > 1):\n            assert (test_predictions.shape[2] == 1)\n        else:\n            assert (test_predictions.shape[2] == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])", "masked_code": "def test_predict():\n    tf.keras.backend.clear_session()\n    test_data = np.array([4, 5, 6])\n    test_targets = np.array([[1, 0], [0, 1], [0, 1]])\n    graph = example_graph_1(feature_size=2)\n    gnn_models = [create_graphSAGE_model(graph), create_HinSAGE_model(graph), create_GCN_model(graph), create_GAT_model(graph)]\n    for (i, gnn_model) in enumerate(gnn_models):\n        keras_model = gnn_model[1]\n        generator = gnn_model[2]\n        ens = Ensemble(keras_model, n_estimators=2, n_predictions=2)\n        ens.compile(optimizer=Adam(), loss=categorical_crossentropy, weighted_metrics=['acc'])\n        test_gen = generator.flow(test_data)\n        with pytest.raises(ValueError):\n            ens.predict(generator=test_gen, predict_data=test_data)\n        test_predictions = ens.predict(test_gen, summarise=True)\n        print('test_predictions shape {}'.format(test_predictions.shape))\n        if (i > 1):\n            assert (len(test_predictions) == 1)\n            assert (test_predictions.shape[1] == test_targets.shape[0])\n        else:\n            assert (len(test_predictions) == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])\n        test_predictions = ens.predict(test_gen, summarise=False)\n        assert (test_predictions.shape[0] == ens.n_estimators)\n        assert (test_predictions.shape[1] == '???')\n        if (i > 1):\n            assert (test_predictions.shape[2] == 1)\n        else:\n            assert (test_predictions.shape[2] == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])\n        ens = BaggingEnsemble(keras_model, n_estimators=2, n_predictions=2)\n        ens.compile(optimizer=Adam(), loss=categorical_crossentropy, weighted_metrics=['acc'])\n        test_gen = generator.flow(test_data)\n        with pytest.raises(ValueError):\n            ens.predict(generator=test_gen, predict_data=test_data)\n        test_predictions = ens.predict(test_gen, summarise=True)\n        print('test_predictions shape {}'.format(test_predictions.shape))\n        if (i > 1):\n            assert (len(test_predictions) == 1)\n            assert (test_predictions.shape[1] == test_targets.shape[0])\n        else:\n            assert (len(test_predictions) == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])\n        test_predictions = ens.predict(test_gen, summarise=False)\n        assert (test_predictions.shape[0] == ens.n_estimators)\n        assert (test_predictions.shape[1] == ens.n_predictions)\n        if (i > 1):\n            assert (test_predictions.shape[2] == 1)\n        else:\n            assert (test_predictions.shape[2] == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])", "ground_truth": "ens.n_predictions", "quality_analysis": {"complexity_score": 8, "left_complexity": 6, "right_complexity": 2, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_21", "reponame": "stellargraph", "testpath": "tests/test_ensemble.py", "testname": "test_ensemble.py", "classname": null, "funcname": "test_predict", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "import tensorflow as tf", "from stellargraph import StellarGraph", "from stellargraph.layer import GraphSAGE, GCN, GAT, HinSAGE, link_classification, link_regression", "from stellargraph.mapper import GraphSAGENodeGenerator, FullBatchNodeGenerator, HinSAGENodeGenerator, GraphSAGELinkGenerator, HinSAGELinkGenerator", "from stellargraph.ensemble import Ensemble, BaggingEnsemble", "from tensorflow.keras import layers, Model", "from tensorflow.keras.optimizers import Adam", "from tensorflow.keras.losses import categorical_crossentropy, binary_crossentropy"], "code": "def test_predict():\n    tf.keras.backend.clear_session()\n    test_data = np.array([4, 5, 6])\n    test_targets = np.array([[1, 0], [0, 1], [0, 1]])\n    graph = example_graph_1(feature_size=2)\n    gnn_models = [create_graphSAGE_model(graph), create_HinSAGE_model(graph), create_GCN_model(graph), create_GAT_model(graph)]\n    for (i, gnn_model) in enumerate(gnn_models):\n        keras_model = gnn_model[1]\n        generator = gnn_model[2]\n        ens = Ensemble(keras_model, n_estimators=2, n_predictions=2)\n        ens.compile(optimizer=Adam(), loss=categorical_crossentropy, weighted_metrics=['acc'])\n        test_gen = generator.flow(test_data)\n        with pytest.raises(ValueError):\n            ens.predict(generator=test_gen, predict_data=test_data)\n        test_predictions = ens.predict(test_gen, summarise=True)\n        print('test_predictions shape {}'.format(test_predictions.shape))\n        if (i > 1):\n            assert (len(test_predictions) == 1)\n            assert (test_predictions.shape[1] == test_targets.shape[0])\n        else:\n            assert (len(test_predictions) == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])\n        test_predictions = ens.predict(test_gen, summarise=False)\n        assert (test_predictions.shape[0] == ens.n_estimators)\n        assert (test_predictions.shape[1] == ens.n_predictions)\n        if (i > 1):\n            assert (test_predictions.shape[2] == 1)\n        else:\n            assert (test_predictions.shape[2] == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])\n        ens = BaggingEnsemble(keras_model, n_estimators=2, n_predictions=2)\n        ens.compile(optimizer=Adam(), loss=categorical_crossentropy, weighted_metrics=['acc'])\n        test_gen = generator.flow(test_data)\n        with pytest.raises(ValueError):\n            ens.predict(generator=test_gen, predict_data=test_data)\n        test_predictions = ens.predict(test_gen, summarise=True)\n        print('test_predictions shape {}'.format(test_predictions.shape))\n        if (i > 1):\n            assert (len(test_predictions) == 1)\n            assert (test_predictions.shape[1] == test_targets.shape[0])\n        else:\n            assert (len(test_predictions) == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])\n        test_predictions = ens.predict(test_gen, summarise=False)\n        assert (test_predictions.shape[0] == ens.n_estimators)\n        assert (test_predictions.shape[1] == ens.n_predictions)\n        if (i > 1):\n            assert (test_predictions.shape[2] == 1)\n        else:\n            assert (test_predictions.shape[2] == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])", "masked_code": "def test_predict():\n    tf.keras.backend.clear_session()\n    test_data = np.array([4, 5, 6])\n    test_targets = np.array([[1, 0], [0, 1], [0, 1]])\n    graph = example_graph_1(feature_size=2)\n    gnn_models = [create_graphSAGE_model(graph), create_HinSAGE_model(graph), create_GCN_model(graph), create_GAT_model(graph)]\n    for (i, gnn_model) in enumerate(gnn_models):\n        keras_model = gnn_model[1]\n        generator = gnn_model[2]\n        ens = Ensemble(keras_model, n_estimators=2, n_predictions=2)\n        ens.compile(optimizer=Adam(), loss=categorical_crossentropy, weighted_metrics=['acc'])\n        test_gen = generator.flow(test_data)\n        with pytest.raises(ValueError):\n            ens.predict(generator=test_gen, predict_data=test_data)\n        test_predictions = ens.predict(test_gen, summarise=True)\n        print('test_predictions shape {}'.format(test_predictions.shape))\n        if (i > 1):\n            assert (len(test_predictions) == 1)\n            assert (test_predictions.shape[1] == test_targets.shape[0])\n        else:\n            assert (len(test_predictions) == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])\n        test_predictions = ens.predict(test_gen, summarise=False)\n        assert (test_predictions.shape[0] == ens.n_estimators)\n        assert (test_predictions.shape[1] == ens.n_predictions)\n        if (i > 1):\n            assert (test_predictions.shape[2] == 1)\n        else:\n            assert (test_predictions.shape[2] == len(test_data))\n        assert (test_predictions.shape[(- 1)] == '???')\n        ens = BaggingEnsemble(keras_model, n_estimators=2, n_predictions=2)\n        ens.compile(optimizer=Adam(), loss=categorical_crossentropy, weighted_metrics=['acc'])\n        test_gen = generator.flow(test_data)\n        with pytest.raises(ValueError):\n            ens.predict(generator=test_gen, predict_data=test_data)\n        test_predictions = ens.predict(test_gen, summarise=True)\n        print('test_predictions shape {}'.format(test_predictions.shape))\n        if (i > 1):\n            assert (len(test_predictions) == 1)\n            assert (test_predictions.shape[1] == test_targets.shape[0])\n        else:\n            assert (len(test_predictions) == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])\n        test_predictions = ens.predict(test_gen, summarise=False)\n        assert (test_predictions.shape[0] == ens.n_estimators)\n        assert (test_predictions.shape[1] == ens.n_predictions)\n        if (i > 1):\n            assert (test_predictions.shape[2] == 1)\n        else:\n            assert (test_predictions.shape[2] == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])", "ground_truth": "test_targets.shape[(- 1)]", "quality_analysis": {"complexity_score": 16, "left_complexity": 8, "right_complexity": 8, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_22", "reponame": "stellargraph", "testpath": "tests/test_ensemble.py", "testname": "test_ensemble.py", "classname": null, "funcname": "test_predict", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "import tensorflow as tf", "from stellargraph import StellarGraph", "from stellargraph.layer import GraphSAGE, GCN, GAT, HinSAGE, link_classification, link_regression", "from stellargraph.mapper import GraphSAGENodeGenerator, FullBatchNodeGenerator, HinSAGENodeGenerator, GraphSAGELinkGenerator, HinSAGELinkGenerator", "from stellargraph.ensemble import Ensemble, BaggingEnsemble", "from tensorflow.keras import layers, Model", "from tensorflow.keras.optimizers import Adam", "from tensorflow.keras.losses import categorical_crossentropy, binary_crossentropy"], "code": "def test_predict():\n    tf.keras.backend.clear_session()\n    test_data = np.array([4, 5, 6])\n    test_targets = np.array([[1, 0], [0, 1], [0, 1]])\n    graph = example_graph_1(feature_size=2)\n    gnn_models = [create_graphSAGE_model(graph), create_HinSAGE_model(graph), create_GCN_model(graph), create_GAT_model(graph)]\n    for (i, gnn_model) in enumerate(gnn_models):\n        keras_model = gnn_model[1]\n        generator = gnn_model[2]\n        ens = Ensemble(keras_model, n_estimators=2, n_predictions=2)\n        ens.compile(optimizer=Adam(), loss=categorical_crossentropy, weighted_metrics=['acc'])\n        test_gen = generator.flow(test_data)\n        with pytest.raises(ValueError):\n            ens.predict(generator=test_gen, predict_data=test_data)\n        test_predictions = ens.predict(test_gen, summarise=True)\n        print('test_predictions shape {}'.format(test_predictions.shape))\n        if (i > 1):\n            assert (len(test_predictions) == 1)\n            assert (test_predictions.shape[1] == test_targets.shape[0])\n        else:\n            assert (len(test_predictions) == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])\n        test_predictions = ens.predict(test_gen, summarise=False)\n        assert (test_predictions.shape[0] == ens.n_estimators)\n        assert (test_predictions.shape[1] == ens.n_predictions)\n        if (i > 1):\n            assert (test_predictions.shape[2] == 1)\n        else:\n            assert (test_predictions.shape[2] == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])\n        ens = BaggingEnsemble(keras_model, n_estimators=2, n_predictions=2)\n        ens.compile(optimizer=Adam(), loss=categorical_crossentropy, weighted_metrics=['acc'])\n        test_gen = generator.flow(test_data)\n        with pytest.raises(ValueError):\n            ens.predict(generator=test_gen, predict_data=test_data)\n        test_predictions = ens.predict(test_gen, summarise=True)\n        print('test_predictions shape {}'.format(test_predictions.shape))\n        if (i > 1):\n            assert (len(test_predictions) == 1)\n            assert (test_predictions.shape[1] == test_targets.shape[0])\n        else:\n            assert (len(test_predictions) == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])\n        test_predictions = ens.predict(test_gen, summarise=False)\n        assert (test_predictions.shape[0] == ens.n_estimators)\n        assert (test_predictions.shape[1] == ens.n_predictions)\n        if (i > 1):\n            assert (test_predictions.shape[2] == 1)\n        else:\n            assert (test_predictions.shape[2] == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])", "masked_code": "def test_predict():\n    tf.keras.backend.clear_session()\n    test_data = np.array([4, 5, 6])\n    test_targets = np.array([[1, 0], [0, 1], [0, 1]])\n    graph = example_graph_1(feature_size=2)\n    gnn_models = [create_graphSAGE_model(graph), create_HinSAGE_model(graph), create_GCN_model(graph), create_GAT_model(graph)]\n    for (i, gnn_model) in enumerate(gnn_models):\n        keras_model = gnn_model[1]\n        generator = gnn_model[2]\n        ens = Ensemble(keras_model, n_estimators=2, n_predictions=2)\n        ens.compile(optimizer=Adam(), loss=categorical_crossentropy, weighted_metrics=['acc'])\n        test_gen = generator.flow(test_data)\n        with pytest.raises(ValueError):\n            ens.predict(generator=test_gen, predict_data=test_data)\n        test_predictions = ens.predict(test_gen, summarise=True)\n        print('test_predictions shape {}'.format(test_predictions.shape))\n        if (i > 1):\n            assert (len(test_predictions) == 1)\n            assert (test_predictions.shape[1] == test_targets.shape[0])\n        else:\n            assert (len(test_predictions) == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])\n        test_predictions = ens.predict(test_gen, summarise=False)\n        assert (test_predictions.shape[0] == ens.n_estimators)\n        assert (test_predictions.shape[1] == ens.n_predictions)\n        if (i > 1):\n            assert (test_predictions.shape[2] == 1)\n        else:\n            assert (test_predictions.shape[2] == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])\n        ens = BaggingEnsemble(keras_model, n_estimators=2, n_predictions=2)\n        ens.compile(optimizer=Adam(), loss=categorical_crossentropy, weighted_metrics=['acc'])\n        test_gen = generator.flow(test_data)\n        with pytest.raises(ValueError):\n            ens.predict(generator=test_gen, predict_data=test_data)\n        test_predictions = ens.predict(test_gen, summarise=True)\n        print('test_predictions shape {}'.format(test_predictions.shape))\n        if (i > 1):\n            assert (len(test_predictions) == 1)\n            assert (test_predictions.shape[1] == test_targets.shape[0])\n        else:\n            assert (len(test_predictions) == len(test_data))\n        assert (test_predictions.shape[(- 1)] == '???')\n        test_predictions = ens.predict(test_gen, summarise=False)\n        assert (test_predictions.shape[0] == ens.n_estimators)\n        assert (test_predictions.shape[1] == ens.n_predictions)\n        if (i > 1):\n            assert (test_predictions.shape[2] == 1)\n        else:\n            assert (test_predictions.shape[2] == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])", "ground_truth": "test_targets.shape[(- 1)]", "quality_analysis": {"complexity_score": 16, "left_complexity": 8, "right_complexity": 8, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_23", "reponame": "stellargraph", "testpath": "tests/test_ensemble.py", "testname": "test_ensemble.py", "classname": null, "funcname": "test_predict", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "import tensorflow as tf", "from stellargraph import StellarGraph", "from stellargraph.layer import GraphSAGE, GCN, GAT, HinSAGE, link_classification, link_regression", "from stellargraph.mapper import GraphSAGENodeGenerator, FullBatchNodeGenerator, HinSAGENodeGenerator, GraphSAGELinkGenerator, HinSAGELinkGenerator", "from stellargraph.ensemble import Ensemble, BaggingEnsemble", "from tensorflow.keras import layers, Model", "from tensorflow.keras.optimizers import Adam", "from tensorflow.keras.losses import categorical_crossentropy, binary_crossentropy"], "code": "def test_predict():\n    tf.keras.backend.clear_session()\n    test_data = np.array([4, 5, 6])\n    test_targets = np.array([[1, 0], [0, 1], [0, 1]])\n    graph = example_graph_1(feature_size=2)\n    gnn_models = [create_graphSAGE_model(graph), create_HinSAGE_model(graph), create_GCN_model(graph), create_GAT_model(graph)]\n    for (i, gnn_model) in enumerate(gnn_models):\n        keras_model = gnn_model[1]\n        generator = gnn_model[2]\n        ens = Ensemble(keras_model, n_estimators=2, n_predictions=2)\n        ens.compile(optimizer=Adam(), loss=categorical_crossentropy, weighted_metrics=['acc'])\n        test_gen = generator.flow(test_data)\n        with pytest.raises(ValueError):\n            ens.predict(generator=test_gen, predict_data=test_data)\n        test_predictions = ens.predict(test_gen, summarise=True)\n        print('test_predictions shape {}'.format(test_predictions.shape))\n        if (i > 1):\n            assert (len(test_predictions) == 1)\n            assert (test_predictions.shape[1] == test_targets.shape[0])\n        else:\n            assert (len(test_predictions) == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])\n        test_predictions = ens.predict(test_gen, summarise=False)\n        assert (test_predictions.shape[0] == ens.n_estimators)\n        assert (test_predictions.shape[1] == ens.n_predictions)\n        if (i > 1):\n            assert (test_predictions.shape[2] == 1)\n        else:\n            assert (test_predictions.shape[2] == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])\n        ens = BaggingEnsemble(keras_model, n_estimators=2, n_predictions=2)\n        ens.compile(optimizer=Adam(), loss=categorical_crossentropy, weighted_metrics=['acc'])\n        test_gen = generator.flow(test_data)\n        with pytest.raises(ValueError):\n            ens.predict(generator=test_gen, predict_data=test_data)\n        test_predictions = ens.predict(test_gen, summarise=True)\n        print('test_predictions shape {}'.format(test_predictions.shape))\n        if (i > 1):\n            assert (len(test_predictions) == 1)\n            assert (test_predictions.shape[1] == test_targets.shape[0])\n        else:\n            assert (len(test_predictions) == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])\n        test_predictions = ens.predict(test_gen, summarise=False)\n        assert (test_predictions.shape[0] == ens.n_estimators)\n        assert (test_predictions.shape[1] == ens.n_predictions)\n        if (i > 1):\n            assert (test_predictions.shape[2] == 1)\n        else:\n            assert (test_predictions.shape[2] == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])", "masked_code": "def test_predict():\n    tf.keras.backend.clear_session()\n    test_data = np.array([4, 5, 6])\n    test_targets = np.array([[1, 0], [0, 1], [0, 1]])\n    graph = example_graph_1(feature_size=2)\n    gnn_models = [create_graphSAGE_model(graph), create_HinSAGE_model(graph), create_GCN_model(graph), create_GAT_model(graph)]\n    for (i, gnn_model) in enumerate(gnn_models):\n        keras_model = gnn_model[1]\n        generator = gnn_model[2]\n        ens = Ensemble(keras_model, n_estimators=2, n_predictions=2)\n        ens.compile(optimizer=Adam(), loss=categorical_crossentropy, weighted_metrics=['acc'])\n        test_gen = generator.flow(test_data)\n        with pytest.raises(ValueError):\n            ens.predict(generator=test_gen, predict_data=test_data)\n        test_predictions = ens.predict(test_gen, summarise=True)\n        print('test_predictions shape {}'.format(test_predictions.shape))\n        if (i > 1):\n            assert (len(test_predictions) == 1)\n            assert (test_predictions.shape[1] == test_targets.shape[0])\n        else:\n            assert (len(test_predictions) == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])\n        test_predictions = ens.predict(test_gen, summarise=False)\n        assert (test_predictions.shape[0] == ens.n_estimators)\n        assert (test_predictions.shape[1] == ens.n_predictions)\n        if (i > 1):\n            assert (test_predictions.shape[2] == 1)\n        else:\n            assert (test_predictions.shape[2] == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])\n        ens = BaggingEnsemble(keras_model, n_estimators=2, n_predictions=2)\n        ens.compile(optimizer=Adam(), loss=categorical_crossentropy, weighted_metrics=['acc'])\n        test_gen = generator.flow(test_data)\n        with pytest.raises(ValueError):\n            ens.predict(generator=test_gen, predict_data=test_data)\n        test_predictions = ens.predict(test_gen, summarise=True)\n        print('test_predictions shape {}'.format(test_predictions.shape))\n        if (i > 1):\n            assert (len(test_predictions) == 1)\n            assert (test_predictions.shape[1] == test_targets.shape[0])\n        else:\n            assert (len(test_predictions) == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])\n        test_predictions = ens.predict(test_gen, summarise=False)\n        assert (test_predictions.shape[0] == '???')\n        assert (test_predictions.shape[1] == ens.n_predictions)\n        if (i > 1):\n            assert (test_predictions.shape[2] == 1)\n        else:\n            assert (test_predictions.shape[2] == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])", "ground_truth": "ens.n_estimators", "quality_analysis": {"complexity_score": 8, "left_complexity": 6, "right_complexity": 2, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_24", "reponame": "stellargraph", "testpath": "tests/test_ensemble.py", "testname": "test_ensemble.py", "classname": null, "funcname": "test_predict", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "import tensorflow as tf", "from stellargraph import StellarGraph", "from stellargraph.layer import GraphSAGE, GCN, GAT, HinSAGE, link_classification, link_regression", "from stellargraph.mapper import GraphSAGENodeGenerator, FullBatchNodeGenerator, HinSAGENodeGenerator, GraphSAGELinkGenerator, HinSAGELinkGenerator", "from stellargraph.ensemble import Ensemble, BaggingEnsemble", "from tensorflow.keras import layers, Model", "from tensorflow.keras.optimizers import Adam", "from tensorflow.keras.losses import categorical_crossentropy, binary_crossentropy"], "code": "def test_predict():\n    tf.keras.backend.clear_session()\n    test_data = np.array([4, 5, 6])\n    test_targets = np.array([[1, 0], [0, 1], [0, 1]])\n    graph = example_graph_1(feature_size=2)\n    gnn_models = [create_graphSAGE_model(graph), create_HinSAGE_model(graph), create_GCN_model(graph), create_GAT_model(graph)]\n    for (i, gnn_model) in enumerate(gnn_models):\n        keras_model = gnn_model[1]\n        generator = gnn_model[2]\n        ens = Ensemble(keras_model, n_estimators=2, n_predictions=2)\n        ens.compile(optimizer=Adam(), loss=categorical_crossentropy, weighted_metrics=['acc'])\n        test_gen = generator.flow(test_data)\n        with pytest.raises(ValueError):\n            ens.predict(generator=test_gen, predict_data=test_data)\n        test_predictions = ens.predict(test_gen, summarise=True)\n        print('test_predictions shape {}'.format(test_predictions.shape))\n        if (i > 1):\n            assert (len(test_predictions) == 1)\n            assert (test_predictions.shape[1] == test_targets.shape[0])\n        else:\n            assert (len(test_predictions) == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])\n        test_predictions = ens.predict(test_gen, summarise=False)\n        assert (test_predictions.shape[0] == ens.n_estimators)\n        assert (test_predictions.shape[1] == ens.n_predictions)\n        if (i > 1):\n            assert (test_predictions.shape[2] == 1)\n        else:\n            assert (test_predictions.shape[2] == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])\n        ens = BaggingEnsemble(keras_model, n_estimators=2, n_predictions=2)\n        ens.compile(optimizer=Adam(), loss=categorical_crossentropy, weighted_metrics=['acc'])\n        test_gen = generator.flow(test_data)\n        with pytest.raises(ValueError):\n            ens.predict(generator=test_gen, predict_data=test_data)\n        test_predictions = ens.predict(test_gen, summarise=True)\n        print('test_predictions shape {}'.format(test_predictions.shape))\n        if (i > 1):\n            assert (len(test_predictions) == 1)\n            assert (test_predictions.shape[1] == test_targets.shape[0])\n        else:\n            assert (len(test_predictions) == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])\n        test_predictions = ens.predict(test_gen, summarise=False)\n        assert (test_predictions.shape[0] == ens.n_estimators)\n        assert (test_predictions.shape[1] == ens.n_predictions)\n        if (i > 1):\n            assert (test_predictions.shape[2] == 1)\n        else:\n            assert (test_predictions.shape[2] == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])", "masked_code": "def test_predict():\n    tf.keras.backend.clear_session()\n    test_data = np.array([4, 5, 6])\n    test_targets = np.array([[1, 0], [0, 1], [0, 1]])\n    graph = example_graph_1(feature_size=2)\n    gnn_models = [create_graphSAGE_model(graph), create_HinSAGE_model(graph), create_GCN_model(graph), create_GAT_model(graph)]\n    for (i, gnn_model) in enumerate(gnn_models):\n        keras_model = gnn_model[1]\n        generator = gnn_model[2]\n        ens = Ensemble(keras_model, n_estimators=2, n_predictions=2)\n        ens.compile(optimizer=Adam(), loss=categorical_crossentropy, weighted_metrics=['acc'])\n        test_gen = generator.flow(test_data)\n        with pytest.raises(ValueError):\n            ens.predict(generator=test_gen, predict_data=test_data)\n        test_predictions = ens.predict(test_gen, summarise=True)\n        print('test_predictions shape {}'.format(test_predictions.shape))\n        if (i > 1):\n            assert (len(test_predictions) == 1)\n            assert (test_predictions.shape[1] == test_targets.shape[0])\n        else:\n            assert (len(test_predictions) == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])\n        test_predictions = ens.predict(test_gen, summarise=False)\n        assert (test_predictions.shape[0] == ens.n_estimators)\n        assert (test_predictions.shape[1] == ens.n_predictions)\n        if (i > 1):\n            assert (test_predictions.shape[2] == 1)\n        else:\n            assert (test_predictions.shape[2] == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])\n        ens = BaggingEnsemble(keras_model, n_estimators=2, n_predictions=2)\n        ens.compile(optimizer=Adam(), loss=categorical_crossentropy, weighted_metrics=['acc'])\n        test_gen = generator.flow(test_data)\n        with pytest.raises(ValueError):\n            ens.predict(generator=test_gen, predict_data=test_data)\n        test_predictions = ens.predict(test_gen, summarise=True)\n        print('test_predictions shape {}'.format(test_predictions.shape))\n        if (i > 1):\n            assert (len(test_predictions) == 1)\n            assert (test_predictions.shape[1] == test_targets.shape[0])\n        else:\n            assert (len(test_predictions) == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])\n        test_predictions = ens.predict(test_gen, summarise=False)\n        assert (test_predictions.shape[0] == ens.n_estimators)\n        assert (test_predictions.shape[1] == '???')\n        if (i > 1):\n            assert (test_predictions.shape[2] == 1)\n        else:\n            assert (test_predictions.shape[2] == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])", "ground_truth": "ens.n_predictions", "quality_analysis": {"complexity_score": 8, "left_complexity": 6, "right_complexity": 2, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_25", "reponame": "stellargraph", "testpath": "tests/test_ensemble.py", "testname": "test_ensemble.py", "classname": null, "funcname": "test_predict", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "import tensorflow as tf", "from stellargraph import StellarGraph", "from stellargraph.layer import GraphSAGE, GCN, GAT, HinSAGE, link_classification, link_regression", "from stellargraph.mapper import GraphSAGENodeGenerator, FullBatchNodeGenerator, HinSAGENodeGenerator, GraphSAGELinkGenerator, HinSAGELinkGenerator", "from stellargraph.ensemble import Ensemble, BaggingEnsemble", "from tensorflow.keras import layers, Model", "from tensorflow.keras.optimizers import Adam", "from tensorflow.keras.losses import categorical_crossentropy, binary_crossentropy"], "code": "def test_predict():\n    tf.keras.backend.clear_session()\n    test_data = np.array([4, 5, 6])\n    test_targets = np.array([[1, 0], [0, 1], [0, 1]])\n    graph = example_graph_1(feature_size=2)\n    gnn_models = [create_graphSAGE_model(graph), create_HinSAGE_model(graph), create_GCN_model(graph), create_GAT_model(graph)]\n    for (i, gnn_model) in enumerate(gnn_models):\n        keras_model = gnn_model[1]\n        generator = gnn_model[2]\n        ens = Ensemble(keras_model, n_estimators=2, n_predictions=2)\n        ens.compile(optimizer=Adam(), loss=categorical_crossentropy, weighted_metrics=['acc'])\n        test_gen = generator.flow(test_data)\n        with pytest.raises(ValueError):\n            ens.predict(generator=test_gen, predict_data=test_data)\n        test_predictions = ens.predict(test_gen, summarise=True)\n        print('test_predictions shape {}'.format(test_predictions.shape))\n        if (i > 1):\n            assert (len(test_predictions) == 1)\n            assert (test_predictions.shape[1] == test_targets.shape[0])\n        else:\n            assert (len(test_predictions) == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])\n        test_predictions = ens.predict(test_gen, summarise=False)\n        assert (test_predictions.shape[0] == ens.n_estimators)\n        assert (test_predictions.shape[1] == ens.n_predictions)\n        if (i > 1):\n            assert (test_predictions.shape[2] == 1)\n        else:\n            assert (test_predictions.shape[2] == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])\n        ens = BaggingEnsemble(keras_model, n_estimators=2, n_predictions=2)\n        ens.compile(optimizer=Adam(), loss=categorical_crossentropy, weighted_metrics=['acc'])\n        test_gen = generator.flow(test_data)\n        with pytest.raises(ValueError):\n            ens.predict(generator=test_gen, predict_data=test_data)\n        test_predictions = ens.predict(test_gen, summarise=True)\n        print('test_predictions shape {}'.format(test_predictions.shape))\n        if (i > 1):\n            assert (len(test_predictions) == 1)\n            assert (test_predictions.shape[1] == test_targets.shape[0])\n        else:\n            assert (len(test_predictions) == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])\n        test_predictions = ens.predict(test_gen, summarise=False)\n        assert (test_predictions.shape[0] == ens.n_estimators)\n        assert (test_predictions.shape[1] == ens.n_predictions)\n        if (i > 1):\n            assert (test_predictions.shape[2] == 1)\n        else:\n            assert (test_predictions.shape[2] == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])", "masked_code": "def test_predict():\n    tf.keras.backend.clear_session()\n    test_data = np.array([4, 5, 6])\n    test_targets = np.array([[1, 0], [0, 1], [0, 1]])\n    graph = example_graph_1(feature_size=2)\n    gnn_models = [create_graphSAGE_model(graph), create_HinSAGE_model(graph), create_GCN_model(graph), create_GAT_model(graph)]\n    for (i, gnn_model) in enumerate(gnn_models):\n        keras_model = gnn_model[1]\n        generator = gnn_model[2]\n        ens = Ensemble(keras_model, n_estimators=2, n_predictions=2)\n        ens.compile(optimizer=Adam(), loss=categorical_crossentropy, weighted_metrics=['acc'])\n        test_gen = generator.flow(test_data)\n        with pytest.raises(ValueError):\n            ens.predict(generator=test_gen, predict_data=test_data)\n        test_predictions = ens.predict(test_gen, summarise=True)\n        print('test_predictions shape {}'.format(test_predictions.shape))\n        if (i > 1):\n            assert (len(test_predictions) == 1)\n            assert (test_predictions.shape[1] == test_targets.shape[0])\n        else:\n            assert (len(test_predictions) == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])\n        test_predictions = ens.predict(test_gen, summarise=False)\n        assert (test_predictions.shape[0] == ens.n_estimators)\n        assert (test_predictions.shape[1] == ens.n_predictions)\n        if (i > 1):\n            assert (test_predictions.shape[2] == 1)\n        else:\n            assert (test_predictions.shape[2] == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])\n        ens = BaggingEnsemble(keras_model, n_estimators=2, n_predictions=2)\n        ens.compile(optimizer=Adam(), loss=categorical_crossentropy, weighted_metrics=['acc'])\n        test_gen = generator.flow(test_data)\n        with pytest.raises(ValueError):\n            ens.predict(generator=test_gen, predict_data=test_data)\n        test_predictions = ens.predict(test_gen, summarise=True)\n        print('test_predictions shape {}'.format(test_predictions.shape))\n        if (i > 1):\n            assert (len(test_predictions) == 1)\n            assert (test_predictions.shape[1] == test_targets.shape[0])\n        else:\n            assert (len(test_predictions) == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])\n        test_predictions = ens.predict(test_gen, summarise=False)\n        assert (test_predictions.shape[0] == ens.n_estimators)\n        assert (test_predictions.shape[1] == ens.n_predictions)\n        if (i > 1):\n            assert (test_predictions.shape[2] == 1)\n        else:\n            assert (test_predictions.shape[2] == len(test_data))\n        assert (test_predictions.shape[(- 1)] == '???')", "ground_truth": "test_targets.shape[(- 1)]", "quality_analysis": {"complexity_score": 16, "left_complexity": 8, "right_complexity": 8, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_26", "reponame": "stellargraph", "testpath": "tests/test_ensemble.py", "testname": "test_ensemble.py", "classname": null, "funcname": "test_predict", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "import tensorflow as tf", "from stellargraph import StellarGraph", "from stellargraph.layer import GraphSAGE, GCN, GAT, HinSAGE, link_classification, link_regression", "from stellargraph.mapper import GraphSAGENodeGenerator, FullBatchNodeGenerator, HinSAGENodeGenerator, GraphSAGELinkGenerator, HinSAGELinkGenerator", "from stellargraph.ensemble import Ensemble, BaggingEnsemble", "from tensorflow.keras import layers, Model", "from tensorflow.keras.optimizers import Adam", "from tensorflow.keras.losses import categorical_crossentropy, binary_crossentropy"], "code": "def test_predict():\n    tf.keras.backend.clear_session()\n    test_data = np.array([4, 5, 6])\n    test_targets = np.array([[1, 0], [0, 1], [0, 1]])\n    graph = example_graph_1(feature_size=2)\n    gnn_models = [create_graphSAGE_model(graph), create_HinSAGE_model(graph), create_GCN_model(graph), create_GAT_model(graph)]\n    for (i, gnn_model) in enumerate(gnn_models):\n        keras_model = gnn_model[1]\n        generator = gnn_model[2]\n        ens = Ensemble(keras_model, n_estimators=2, n_predictions=2)\n        ens.compile(optimizer=Adam(), loss=categorical_crossentropy, weighted_metrics=['acc'])\n        test_gen = generator.flow(test_data)\n        with pytest.raises(ValueError):\n            ens.predict(generator=test_gen, predict_data=test_data)\n        test_predictions = ens.predict(test_gen, summarise=True)\n        print('test_predictions shape {}'.format(test_predictions.shape))\n        if (i > 1):\n            assert (len(test_predictions) == 1)\n            assert (test_predictions.shape[1] == test_targets.shape[0])\n        else:\n            assert (len(test_predictions) == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])\n        test_predictions = ens.predict(test_gen, summarise=False)\n        assert (test_predictions.shape[0] == ens.n_estimators)\n        assert (test_predictions.shape[1] == ens.n_predictions)\n        if (i > 1):\n            assert (test_predictions.shape[2] == 1)\n        else:\n            assert (test_predictions.shape[2] == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])\n        ens = BaggingEnsemble(keras_model, n_estimators=2, n_predictions=2)\n        ens.compile(optimizer=Adam(), loss=categorical_crossentropy, weighted_metrics=['acc'])\n        test_gen = generator.flow(test_data)\n        with pytest.raises(ValueError):\n            ens.predict(generator=test_gen, predict_data=test_data)\n        test_predictions = ens.predict(test_gen, summarise=True)\n        print('test_predictions shape {}'.format(test_predictions.shape))\n        if (i > 1):\n            assert (len(test_predictions) == 1)\n            assert (test_predictions.shape[1] == test_targets.shape[0])\n        else:\n            assert (len(test_predictions) == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])\n        test_predictions = ens.predict(test_gen, summarise=False)\n        assert (test_predictions.shape[0] == ens.n_estimators)\n        assert (test_predictions.shape[1] == ens.n_predictions)\n        if (i > 1):\n            assert (test_predictions.shape[2] == 1)\n        else:\n            assert (test_predictions.shape[2] == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])", "masked_code": "def test_predict():\n    tf.keras.backend.clear_session()\n    test_data = np.array([4, 5, 6])\n    test_targets = np.array([[1, 0], [0, 1], [0, 1]])\n    graph = example_graph_1(feature_size=2)\n    gnn_models = [create_graphSAGE_model(graph), create_HinSAGE_model(graph), create_GCN_model(graph), create_GAT_model(graph)]\n    for (i, gnn_model) in enumerate(gnn_models):\n        keras_model = gnn_model[1]\n        generator = gnn_model[2]\n        ens = Ensemble(keras_model, n_estimators=2, n_predictions=2)\n        ens.compile(optimizer=Adam(), loss=categorical_crossentropy, weighted_metrics=['acc'])\n        test_gen = generator.flow(test_data)\n        with pytest.raises(ValueError):\n            ens.predict(generator=test_gen, predict_data=test_data)\n        test_predictions = ens.predict(test_gen, summarise=True)\n        print('test_predictions shape {}'.format(test_predictions.shape))\n        if (i > 1):\n            assert (len(test_predictions) == 1)\n            assert (test_predictions.shape[1] == '???')\n        else:\n            assert (len(test_predictions) == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])\n        test_predictions = ens.predict(test_gen, summarise=False)\n        assert (test_predictions.shape[0] == ens.n_estimators)\n        assert (test_predictions.shape[1] == ens.n_predictions)\n        if (i > 1):\n            assert (test_predictions.shape[2] == 1)\n        else:\n            assert (test_predictions.shape[2] == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])\n        ens = BaggingEnsemble(keras_model, n_estimators=2, n_predictions=2)\n        ens.compile(optimizer=Adam(), loss=categorical_crossentropy, weighted_metrics=['acc'])\n        test_gen = generator.flow(test_data)\n        with pytest.raises(ValueError):\n            ens.predict(generator=test_gen, predict_data=test_data)\n        test_predictions = ens.predict(test_gen, summarise=True)\n        print('test_predictions shape {}'.format(test_predictions.shape))\n        if (i > 1):\n            assert (len(test_predictions) == 1)\n            assert (test_predictions.shape[1] == test_targets.shape[0])\n        else:\n            assert (len(test_predictions) == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])\n        test_predictions = ens.predict(test_gen, summarise=False)\n        assert (test_predictions.shape[0] == ens.n_estimators)\n        assert (test_predictions.shape[1] == ens.n_predictions)\n        if (i > 1):\n            assert (test_predictions.shape[2] == 1)\n        else:\n            assert (test_predictions.shape[2] == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])", "ground_truth": "test_targets.shape[0]", "quality_analysis": {"complexity_score": 12, "left_complexity": 6, "right_complexity": 6, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_27", "reponame": "stellargraph", "testpath": "tests/test_ensemble.py", "testname": "test_ensemble.py", "classname": null, "funcname": "test_predict", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "import tensorflow as tf", "from stellargraph import StellarGraph", "from stellargraph.layer import GraphSAGE, GCN, GAT, HinSAGE, link_classification, link_regression", "from stellargraph.mapper import GraphSAGENodeGenerator, FullBatchNodeGenerator, HinSAGENodeGenerator, GraphSAGELinkGenerator, HinSAGELinkGenerator", "from stellargraph.ensemble import Ensemble, BaggingEnsemble", "from tensorflow.keras import layers, Model", "from tensorflow.keras.optimizers import Adam", "from tensorflow.keras.losses import categorical_crossentropy, binary_crossentropy"], "code": "def test_predict():\n    tf.keras.backend.clear_session()\n    test_data = np.array([4, 5, 6])\n    test_targets = np.array([[1, 0], [0, 1], [0, 1]])\n    graph = example_graph_1(feature_size=2)\n    gnn_models = [create_graphSAGE_model(graph), create_HinSAGE_model(graph), create_GCN_model(graph), create_GAT_model(graph)]\n    for (i, gnn_model) in enumerate(gnn_models):\n        keras_model = gnn_model[1]\n        generator = gnn_model[2]\n        ens = Ensemble(keras_model, n_estimators=2, n_predictions=2)\n        ens.compile(optimizer=Adam(), loss=categorical_crossentropy, weighted_metrics=['acc'])\n        test_gen = generator.flow(test_data)\n        with pytest.raises(ValueError):\n            ens.predict(generator=test_gen, predict_data=test_data)\n        test_predictions = ens.predict(test_gen, summarise=True)\n        print('test_predictions shape {}'.format(test_predictions.shape))\n        if (i > 1):\n            assert (len(test_predictions) == 1)\n            assert (test_predictions.shape[1] == test_targets.shape[0])\n        else:\n            assert (len(test_predictions) == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])\n        test_predictions = ens.predict(test_gen, summarise=False)\n        assert (test_predictions.shape[0] == ens.n_estimators)\n        assert (test_predictions.shape[1] == ens.n_predictions)\n        if (i > 1):\n            assert (test_predictions.shape[2] == 1)\n        else:\n            assert (test_predictions.shape[2] == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])\n        ens = BaggingEnsemble(keras_model, n_estimators=2, n_predictions=2)\n        ens.compile(optimizer=Adam(), loss=categorical_crossentropy, weighted_metrics=['acc'])\n        test_gen = generator.flow(test_data)\n        with pytest.raises(ValueError):\n            ens.predict(generator=test_gen, predict_data=test_data)\n        test_predictions = ens.predict(test_gen, summarise=True)\n        print('test_predictions shape {}'.format(test_predictions.shape))\n        if (i > 1):\n            assert (len(test_predictions) == 1)\n            assert (test_predictions.shape[1] == test_targets.shape[0])\n        else:\n            assert (len(test_predictions) == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])\n        test_predictions = ens.predict(test_gen, summarise=False)\n        assert (test_predictions.shape[0] == ens.n_estimators)\n        assert (test_predictions.shape[1] == ens.n_predictions)\n        if (i > 1):\n            assert (test_predictions.shape[2] == 1)\n        else:\n            assert (test_predictions.shape[2] == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])", "masked_code": "def test_predict():\n    tf.keras.backend.clear_session()\n    test_data = np.array([4, 5, 6])\n    test_targets = np.array([[1, 0], [0, 1], [0, 1]])\n    graph = example_graph_1(feature_size=2)\n    gnn_models = [create_graphSAGE_model(graph), create_HinSAGE_model(graph), create_GCN_model(graph), create_GAT_model(graph)]\n    for (i, gnn_model) in enumerate(gnn_models):\n        keras_model = gnn_model[1]\n        generator = gnn_model[2]\n        ens = Ensemble(keras_model, n_estimators=2, n_predictions=2)\n        ens.compile(optimizer=Adam(), loss=categorical_crossentropy, weighted_metrics=['acc'])\n        test_gen = generator.flow(test_data)\n        with pytest.raises(ValueError):\n            ens.predict(generator=test_gen, predict_data=test_data)\n        test_predictions = ens.predict(test_gen, summarise=True)\n        print('test_predictions shape {}'.format(test_predictions.shape))\n        if (i > 1):\n            assert (len(test_predictions) == 1)\n            assert (test_predictions.shape[1] == test_targets.shape[0])\n        else:\n            assert (len(test_predictions) == '???')\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])\n        test_predictions = ens.predict(test_gen, summarise=False)\n        assert (test_predictions.shape[0] == ens.n_estimators)\n        assert (test_predictions.shape[1] == ens.n_predictions)\n        if (i > 1):\n            assert (test_predictions.shape[2] == 1)\n        else:\n            assert (test_predictions.shape[2] == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])\n        ens = BaggingEnsemble(keras_model, n_estimators=2, n_predictions=2)\n        ens.compile(optimizer=Adam(), loss=categorical_crossentropy, weighted_metrics=['acc'])\n        test_gen = generator.flow(test_data)\n        with pytest.raises(ValueError):\n            ens.predict(generator=test_gen, predict_data=test_data)\n        test_predictions = ens.predict(test_gen, summarise=True)\n        print('test_predictions shape {}'.format(test_predictions.shape))\n        if (i > 1):\n            assert (len(test_predictions) == 1)\n            assert (test_predictions.shape[1] == test_targets.shape[0])\n        else:\n            assert (len(test_predictions) == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])\n        test_predictions = ens.predict(test_gen, summarise=False)\n        assert (test_predictions.shape[0] == ens.n_estimators)\n        assert (test_predictions.shape[1] == ens.n_predictions)\n        if (i > 1):\n            assert (test_predictions.shape[2] == 1)\n        else:\n            assert (test_predictions.shape[2] == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])", "ground_truth": "len(test_data)", "quality_analysis": {"complexity_score": 8, "left_complexity": 4, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_28", "reponame": "stellargraph", "testpath": "tests/test_ensemble.py", "testname": "test_ensemble.py", "classname": null, "funcname": "test_predict", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "import tensorflow as tf", "from stellargraph import StellarGraph", "from stellargraph.layer import GraphSAGE, GCN, GAT, HinSAGE, link_classification, link_regression", "from stellargraph.mapper import GraphSAGENodeGenerator, FullBatchNodeGenerator, HinSAGENodeGenerator, GraphSAGELinkGenerator, HinSAGELinkGenerator", "from stellargraph.ensemble import Ensemble, BaggingEnsemble", "from tensorflow.keras import layers, Model", "from tensorflow.keras.optimizers import Adam", "from tensorflow.keras.losses import categorical_crossentropy, binary_crossentropy"], "code": "def test_predict():\n    tf.keras.backend.clear_session()\n    test_data = np.array([4, 5, 6])\n    test_targets = np.array([[1, 0], [0, 1], [0, 1]])\n    graph = example_graph_1(feature_size=2)\n    gnn_models = [create_graphSAGE_model(graph), create_HinSAGE_model(graph), create_GCN_model(graph), create_GAT_model(graph)]\n    for (i, gnn_model) in enumerate(gnn_models):\n        keras_model = gnn_model[1]\n        generator = gnn_model[2]\n        ens = Ensemble(keras_model, n_estimators=2, n_predictions=2)\n        ens.compile(optimizer=Adam(), loss=categorical_crossentropy, weighted_metrics=['acc'])\n        test_gen = generator.flow(test_data)\n        with pytest.raises(ValueError):\n            ens.predict(generator=test_gen, predict_data=test_data)\n        test_predictions = ens.predict(test_gen, summarise=True)\n        print('test_predictions shape {}'.format(test_predictions.shape))\n        if (i > 1):\n            assert (len(test_predictions) == 1)\n            assert (test_predictions.shape[1] == test_targets.shape[0])\n        else:\n            assert (len(test_predictions) == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])\n        test_predictions = ens.predict(test_gen, summarise=False)\n        assert (test_predictions.shape[0] == ens.n_estimators)\n        assert (test_predictions.shape[1] == ens.n_predictions)\n        if (i > 1):\n            assert (test_predictions.shape[2] == 1)\n        else:\n            assert (test_predictions.shape[2] == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])\n        ens = BaggingEnsemble(keras_model, n_estimators=2, n_predictions=2)\n        ens.compile(optimizer=Adam(), loss=categorical_crossentropy, weighted_metrics=['acc'])\n        test_gen = generator.flow(test_data)\n        with pytest.raises(ValueError):\n            ens.predict(generator=test_gen, predict_data=test_data)\n        test_predictions = ens.predict(test_gen, summarise=True)\n        print('test_predictions shape {}'.format(test_predictions.shape))\n        if (i > 1):\n            assert (len(test_predictions) == 1)\n            assert (test_predictions.shape[1] == test_targets.shape[0])\n        else:\n            assert (len(test_predictions) == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])\n        test_predictions = ens.predict(test_gen, summarise=False)\n        assert (test_predictions.shape[0] == ens.n_estimators)\n        assert (test_predictions.shape[1] == ens.n_predictions)\n        if (i > 1):\n            assert (test_predictions.shape[2] == 1)\n        else:\n            assert (test_predictions.shape[2] == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])", "masked_code": "def test_predict():\n    tf.keras.backend.clear_session()\n    test_data = np.array([4, 5, 6])\n    test_targets = np.array([[1, 0], [0, 1], [0, 1]])\n    graph = example_graph_1(feature_size=2)\n    gnn_models = [create_graphSAGE_model(graph), create_HinSAGE_model(graph), create_GCN_model(graph), create_GAT_model(graph)]\n    for (i, gnn_model) in enumerate(gnn_models):\n        keras_model = gnn_model[1]\n        generator = gnn_model[2]\n        ens = Ensemble(keras_model, n_estimators=2, n_predictions=2)\n        ens.compile(optimizer=Adam(), loss=categorical_crossentropy, weighted_metrics=['acc'])\n        test_gen = generator.flow(test_data)\n        with pytest.raises(ValueError):\n            ens.predict(generator=test_gen, predict_data=test_data)\n        test_predictions = ens.predict(test_gen, summarise=True)\n        print('test_predictions shape {}'.format(test_predictions.shape))\n        if (i > 1):\n            assert (len(test_predictions) == 1)\n            assert (test_predictions.shape[1] == test_targets.shape[0])\n        else:\n            assert (len(test_predictions) == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])\n        test_predictions = ens.predict(test_gen, summarise=False)\n        assert (test_predictions.shape[0] == ens.n_estimators)\n        assert (test_predictions.shape[1] == ens.n_predictions)\n        if (i > 1):\n            assert (test_predictions.shape[2] == 1)\n        else:\n            assert (test_predictions.shape[2] == '???')\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])\n        ens = BaggingEnsemble(keras_model, n_estimators=2, n_predictions=2)\n        ens.compile(optimizer=Adam(), loss=categorical_crossentropy, weighted_metrics=['acc'])\n        test_gen = generator.flow(test_data)\n        with pytest.raises(ValueError):\n            ens.predict(generator=test_gen, predict_data=test_data)\n        test_predictions = ens.predict(test_gen, summarise=True)\n        print('test_predictions shape {}'.format(test_predictions.shape))\n        if (i > 1):\n            assert (len(test_predictions) == 1)\n            assert (test_predictions.shape[1] == test_targets.shape[0])\n        else:\n            assert (len(test_predictions) == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])\n        test_predictions = ens.predict(test_gen, summarise=False)\n        assert (test_predictions.shape[0] == ens.n_estimators)\n        assert (test_predictions.shape[1] == ens.n_predictions)\n        if (i > 1):\n            assert (test_predictions.shape[2] == 1)\n        else:\n            assert (test_predictions.shape[2] == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])", "ground_truth": "len(test_data)", "quality_analysis": {"complexity_score": 10, "left_complexity": 6, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_29", "reponame": "stellargraph", "testpath": "tests/test_ensemble.py", "testname": "test_ensemble.py", "classname": null, "funcname": "test_predict", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "import tensorflow as tf", "from stellargraph import StellarGraph", "from stellargraph.layer import GraphSAGE, GCN, GAT, HinSAGE, link_classification, link_regression", "from stellargraph.mapper import GraphSAGENodeGenerator, FullBatchNodeGenerator, HinSAGENodeGenerator, GraphSAGELinkGenerator, HinSAGELinkGenerator", "from stellargraph.ensemble import Ensemble, BaggingEnsemble", "from tensorflow.keras import layers, Model", "from tensorflow.keras.optimizers import Adam", "from tensorflow.keras.losses import categorical_crossentropy, binary_crossentropy"], "code": "def test_predict():\n    tf.keras.backend.clear_session()\n    test_data = np.array([4, 5, 6])\n    test_targets = np.array([[1, 0], [0, 1], [0, 1]])\n    graph = example_graph_1(feature_size=2)\n    gnn_models = [create_graphSAGE_model(graph), create_HinSAGE_model(graph), create_GCN_model(graph), create_GAT_model(graph)]\n    for (i, gnn_model) in enumerate(gnn_models):\n        keras_model = gnn_model[1]\n        generator = gnn_model[2]\n        ens = Ensemble(keras_model, n_estimators=2, n_predictions=2)\n        ens.compile(optimizer=Adam(), loss=categorical_crossentropy, weighted_metrics=['acc'])\n        test_gen = generator.flow(test_data)\n        with pytest.raises(ValueError):\n            ens.predict(generator=test_gen, predict_data=test_data)\n        test_predictions = ens.predict(test_gen, summarise=True)\n        print('test_predictions shape {}'.format(test_predictions.shape))\n        if (i > 1):\n            assert (len(test_predictions) == 1)\n            assert (test_predictions.shape[1] == test_targets.shape[0])\n        else:\n            assert (len(test_predictions) == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])\n        test_predictions = ens.predict(test_gen, summarise=False)\n        assert (test_predictions.shape[0] == ens.n_estimators)\n        assert (test_predictions.shape[1] == ens.n_predictions)\n        if (i > 1):\n            assert (test_predictions.shape[2] == 1)\n        else:\n            assert (test_predictions.shape[2] == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])\n        ens = BaggingEnsemble(keras_model, n_estimators=2, n_predictions=2)\n        ens.compile(optimizer=Adam(), loss=categorical_crossentropy, weighted_metrics=['acc'])\n        test_gen = generator.flow(test_data)\n        with pytest.raises(ValueError):\n            ens.predict(generator=test_gen, predict_data=test_data)\n        test_predictions = ens.predict(test_gen, summarise=True)\n        print('test_predictions shape {}'.format(test_predictions.shape))\n        if (i > 1):\n            assert (len(test_predictions) == 1)\n            assert (test_predictions.shape[1] == test_targets.shape[0])\n        else:\n            assert (len(test_predictions) == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])\n        test_predictions = ens.predict(test_gen, summarise=False)\n        assert (test_predictions.shape[0] == ens.n_estimators)\n        assert (test_predictions.shape[1] == ens.n_predictions)\n        if (i > 1):\n            assert (test_predictions.shape[2] == 1)\n        else:\n            assert (test_predictions.shape[2] == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])", "masked_code": "def test_predict():\n    tf.keras.backend.clear_session()\n    test_data = np.array([4, 5, 6])\n    test_targets = np.array([[1, 0], [0, 1], [0, 1]])\n    graph = example_graph_1(feature_size=2)\n    gnn_models = [create_graphSAGE_model(graph), create_HinSAGE_model(graph), create_GCN_model(graph), create_GAT_model(graph)]\n    for (i, gnn_model) in enumerate(gnn_models):\n        keras_model = gnn_model[1]\n        generator = gnn_model[2]\n        ens = Ensemble(keras_model, n_estimators=2, n_predictions=2)\n        ens.compile(optimizer=Adam(), loss=categorical_crossentropy, weighted_metrics=['acc'])\n        test_gen = generator.flow(test_data)\n        with pytest.raises(ValueError):\n            ens.predict(generator=test_gen, predict_data=test_data)\n        test_predictions = ens.predict(test_gen, summarise=True)\n        print('test_predictions shape {}'.format(test_predictions.shape))\n        if (i > 1):\n            assert (len(test_predictions) == 1)\n            assert (test_predictions.shape[1] == test_targets.shape[0])\n        else:\n            assert (len(test_predictions) == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])\n        test_predictions = ens.predict(test_gen, summarise=False)\n        assert (test_predictions.shape[0] == ens.n_estimators)\n        assert (test_predictions.shape[1] == ens.n_predictions)\n        if (i > 1):\n            assert (test_predictions.shape[2] == 1)\n        else:\n            assert (test_predictions.shape[2] == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])\n        ens = BaggingEnsemble(keras_model, n_estimators=2, n_predictions=2)\n        ens.compile(optimizer=Adam(), loss=categorical_crossentropy, weighted_metrics=['acc'])\n        test_gen = generator.flow(test_data)\n        with pytest.raises(ValueError):\n            ens.predict(generator=test_gen, predict_data=test_data)\n        test_predictions = ens.predict(test_gen, summarise=True)\n        print('test_predictions shape {}'.format(test_predictions.shape))\n        if (i > 1):\n            assert (len(test_predictions) == 1)\n            assert (test_predictions.shape[1] == '???')\n        else:\n            assert (len(test_predictions) == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])\n        test_predictions = ens.predict(test_gen, summarise=False)\n        assert (test_predictions.shape[0] == ens.n_estimators)\n        assert (test_predictions.shape[1] == ens.n_predictions)\n        if (i > 1):\n            assert (test_predictions.shape[2] == 1)\n        else:\n            assert (test_predictions.shape[2] == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])", "ground_truth": "test_targets.shape[0]", "quality_analysis": {"complexity_score": 12, "left_complexity": 6, "right_complexity": 6, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_30", "reponame": "stellargraph", "testpath": "tests/test_ensemble.py", "testname": "test_ensemble.py", "classname": null, "funcname": "test_predict", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "import tensorflow as tf", "from stellargraph import StellarGraph", "from stellargraph.layer import GraphSAGE, GCN, GAT, HinSAGE, link_classification, link_regression", "from stellargraph.mapper import GraphSAGENodeGenerator, FullBatchNodeGenerator, HinSAGENodeGenerator, GraphSAGELinkGenerator, HinSAGELinkGenerator", "from stellargraph.ensemble import Ensemble, BaggingEnsemble", "from tensorflow.keras import layers, Model", "from tensorflow.keras.optimizers import Adam", "from tensorflow.keras.losses import categorical_crossentropy, binary_crossentropy"], "code": "def test_predict():\n    tf.keras.backend.clear_session()\n    test_data = np.array([4, 5, 6])\n    test_targets = np.array([[1, 0], [0, 1], [0, 1]])\n    graph = example_graph_1(feature_size=2)\n    gnn_models = [create_graphSAGE_model(graph), create_HinSAGE_model(graph), create_GCN_model(graph), create_GAT_model(graph)]\n    for (i, gnn_model) in enumerate(gnn_models):\n        keras_model = gnn_model[1]\n        generator = gnn_model[2]\n        ens = Ensemble(keras_model, n_estimators=2, n_predictions=2)\n        ens.compile(optimizer=Adam(), loss=categorical_crossentropy, weighted_metrics=['acc'])\n        test_gen = generator.flow(test_data)\n        with pytest.raises(ValueError):\n            ens.predict(generator=test_gen, predict_data=test_data)\n        test_predictions = ens.predict(test_gen, summarise=True)\n        print('test_predictions shape {}'.format(test_predictions.shape))\n        if (i > 1):\n            assert (len(test_predictions) == 1)\n            assert (test_predictions.shape[1] == test_targets.shape[0])\n        else:\n            assert (len(test_predictions) == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])\n        test_predictions = ens.predict(test_gen, summarise=False)\n        assert (test_predictions.shape[0] == ens.n_estimators)\n        assert (test_predictions.shape[1] == ens.n_predictions)\n        if (i > 1):\n            assert (test_predictions.shape[2] == 1)\n        else:\n            assert (test_predictions.shape[2] == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])\n        ens = BaggingEnsemble(keras_model, n_estimators=2, n_predictions=2)\n        ens.compile(optimizer=Adam(), loss=categorical_crossentropy, weighted_metrics=['acc'])\n        test_gen = generator.flow(test_data)\n        with pytest.raises(ValueError):\n            ens.predict(generator=test_gen, predict_data=test_data)\n        test_predictions = ens.predict(test_gen, summarise=True)\n        print('test_predictions shape {}'.format(test_predictions.shape))\n        if (i > 1):\n            assert (len(test_predictions) == 1)\n            assert (test_predictions.shape[1] == test_targets.shape[0])\n        else:\n            assert (len(test_predictions) == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])\n        test_predictions = ens.predict(test_gen, summarise=False)\n        assert (test_predictions.shape[0] == ens.n_estimators)\n        assert (test_predictions.shape[1] == ens.n_predictions)\n        if (i > 1):\n            assert (test_predictions.shape[2] == 1)\n        else:\n            assert (test_predictions.shape[2] == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])", "masked_code": "def test_predict():\n    tf.keras.backend.clear_session()\n    test_data = np.array([4, 5, 6])\n    test_targets = np.array([[1, 0], [0, 1], [0, 1]])\n    graph = example_graph_1(feature_size=2)\n    gnn_models = [create_graphSAGE_model(graph), create_HinSAGE_model(graph), create_GCN_model(graph), create_GAT_model(graph)]\n    for (i, gnn_model) in enumerate(gnn_models):\n        keras_model = gnn_model[1]\n        generator = gnn_model[2]\n        ens = Ensemble(keras_model, n_estimators=2, n_predictions=2)\n        ens.compile(optimizer=Adam(), loss=categorical_crossentropy, weighted_metrics=['acc'])\n        test_gen = generator.flow(test_data)\n        with pytest.raises(ValueError):\n            ens.predict(generator=test_gen, predict_data=test_data)\n        test_predictions = ens.predict(test_gen, summarise=True)\n        print('test_predictions shape {}'.format(test_predictions.shape))\n        if (i > 1):\n            assert (len(test_predictions) == 1)\n            assert (test_predictions.shape[1] == test_targets.shape[0])\n        else:\n            assert (len(test_predictions) == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])\n        test_predictions = ens.predict(test_gen, summarise=False)\n        assert (test_predictions.shape[0] == ens.n_estimators)\n        assert (test_predictions.shape[1] == ens.n_predictions)\n        if (i > 1):\n            assert (test_predictions.shape[2] == 1)\n        else:\n            assert (test_predictions.shape[2] == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])\n        ens = BaggingEnsemble(keras_model, n_estimators=2, n_predictions=2)\n        ens.compile(optimizer=Adam(), loss=categorical_crossentropy, weighted_metrics=['acc'])\n        test_gen = generator.flow(test_data)\n        with pytest.raises(ValueError):\n            ens.predict(generator=test_gen, predict_data=test_data)\n        test_predictions = ens.predict(test_gen, summarise=True)\n        print('test_predictions shape {}'.format(test_predictions.shape))\n        if (i > 1):\n            assert (len(test_predictions) == 1)\n            assert (test_predictions.shape[1] == test_targets.shape[0])\n        else:\n            assert (len(test_predictions) == '???')\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])\n        test_predictions = ens.predict(test_gen, summarise=False)\n        assert (test_predictions.shape[0] == ens.n_estimators)\n        assert (test_predictions.shape[1] == ens.n_predictions)\n        if (i > 1):\n            assert (test_predictions.shape[2] == 1)\n        else:\n            assert (test_predictions.shape[2] == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])", "ground_truth": "len(test_data)", "quality_analysis": {"complexity_score": 8, "left_complexity": 4, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_31", "reponame": "stellargraph", "testpath": "tests/test_ensemble.py", "testname": "test_ensemble.py", "classname": null, "funcname": "test_predict", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "import tensorflow as tf", "from stellargraph import StellarGraph", "from stellargraph.layer import GraphSAGE, GCN, GAT, HinSAGE, link_classification, link_regression", "from stellargraph.mapper import GraphSAGENodeGenerator, FullBatchNodeGenerator, HinSAGENodeGenerator, GraphSAGELinkGenerator, HinSAGELinkGenerator", "from stellargraph.ensemble import Ensemble, BaggingEnsemble", "from tensorflow.keras import layers, Model", "from tensorflow.keras.optimizers import Adam", "from tensorflow.keras.losses import categorical_crossentropy, binary_crossentropy"], "code": "def test_predict():\n    tf.keras.backend.clear_session()\n    test_data = np.array([4, 5, 6])\n    test_targets = np.array([[1, 0], [0, 1], [0, 1]])\n    graph = example_graph_1(feature_size=2)\n    gnn_models = [create_graphSAGE_model(graph), create_HinSAGE_model(graph), create_GCN_model(graph), create_GAT_model(graph)]\n    for (i, gnn_model) in enumerate(gnn_models):\n        keras_model = gnn_model[1]\n        generator = gnn_model[2]\n        ens = Ensemble(keras_model, n_estimators=2, n_predictions=2)\n        ens.compile(optimizer=Adam(), loss=categorical_crossentropy, weighted_metrics=['acc'])\n        test_gen = generator.flow(test_data)\n        with pytest.raises(ValueError):\n            ens.predict(generator=test_gen, predict_data=test_data)\n        test_predictions = ens.predict(test_gen, summarise=True)\n        print('test_predictions shape {}'.format(test_predictions.shape))\n        if (i > 1):\n            assert (len(test_predictions) == 1)\n            assert (test_predictions.shape[1] == test_targets.shape[0])\n        else:\n            assert (len(test_predictions) == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])\n        test_predictions = ens.predict(test_gen, summarise=False)\n        assert (test_predictions.shape[0] == ens.n_estimators)\n        assert (test_predictions.shape[1] == ens.n_predictions)\n        if (i > 1):\n            assert (test_predictions.shape[2] == 1)\n        else:\n            assert (test_predictions.shape[2] == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])\n        ens = BaggingEnsemble(keras_model, n_estimators=2, n_predictions=2)\n        ens.compile(optimizer=Adam(), loss=categorical_crossentropy, weighted_metrics=['acc'])\n        test_gen = generator.flow(test_data)\n        with pytest.raises(ValueError):\n            ens.predict(generator=test_gen, predict_data=test_data)\n        test_predictions = ens.predict(test_gen, summarise=True)\n        print('test_predictions shape {}'.format(test_predictions.shape))\n        if (i > 1):\n            assert (len(test_predictions) == 1)\n            assert (test_predictions.shape[1] == test_targets.shape[0])\n        else:\n            assert (len(test_predictions) == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])\n        test_predictions = ens.predict(test_gen, summarise=False)\n        assert (test_predictions.shape[0] == ens.n_estimators)\n        assert (test_predictions.shape[1] == ens.n_predictions)\n        if (i > 1):\n            assert (test_predictions.shape[2] == 1)\n        else:\n            assert (test_predictions.shape[2] == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])", "masked_code": "def test_predict():\n    tf.keras.backend.clear_session()\n    test_data = np.array([4, 5, 6])\n    test_targets = np.array([[1, 0], [0, 1], [0, 1]])\n    graph = example_graph_1(feature_size=2)\n    gnn_models = [create_graphSAGE_model(graph), create_HinSAGE_model(graph), create_GCN_model(graph), create_GAT_model(graph)]\n    for (i, gnn_model) in enumerate(gnn_models):\n        keras_model = gnn_model[1]\n        generator = gnn_model[2]\n        ens = Ensemble(keras_model, n_estimators=2, n_predictions=2)\n        ens.compile(optimizer=Adam(), loss=categorical_crossentropy, weighted_metrics=['acc'])\n        test_gen = generator.flow(test_data)\n        with pytest.raises(ValueError):\n            ens.predict(generator=test_gen, predict_data=test_data)\n        test_predictions = ens.predict(test_gen, summarise=True)\n        print('test_predictions shape {}'.format(test_predictions.shape))\n        if (i > 1):\n            assert (len(test_predictions) == 1)\n            assert (test_predictions.shape[1] == test_targets.shape[0])\n        else:\n            assert (len(test_predictions) == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])\n        test_predictions = ens.predict(test_gen, summarise=False)\n        assert (test_predictions.shape[0] == ens.n_estimators)\n        assert (test_predictions.shape[1] == ens.n_predictions)\n        if (i > 1):\n            assert (test_predictions.shape[2] == 1)\n        else:\n            assert (test_predictions.shape[2] == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])\n        ens = BaggingEnsemble(keras_model, n_estimators=2, n_predictions=2)\n        ens.compile(optimizer=Adam(), loss=categorical_crossentropy, weighted_metrics=['acc'])\n        test_gen = generator.flow(test_data)\n        with pytest.raises(ValueError):\n            ens.predict(generator=test_gen, predict_data=test_data)\n        test_predictions = ens.predict(test_gen, summarise=True)\n        print('test_predictions shape {}'.format(test_predictions.shape))\n        if (i > 1):\n            assert (len(test_predictions) == 1)\n            assert (test_predictions.shape[1] == test_targets.shape[0])\n        else:\n            assert (len(test_predictions) == len(test_data))\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])\n        test_predictions = ens.predict(test_gen, summarise=False)\n        assert (test_predictions.shape[0] == ens.n_estimators)\n        assert (test_predictions.shape[1] == ens.n_predictions)\n        if (i > 1):\n            assert (test_predictions.shape[2] == 1)\n        else:\n            assert (test_predictions.shape[2] == '???')\n        assert (test_predictions.shape[(- 1)] == test_targets.shape[(- 1)])", "ground_truth": "len(test_data)", "quality_analysis": {"complexity_score": 10, "left_complexity": 6, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_32", "reponame": "stellargraph", "testpath": "tests/test_ensemble.py", "testname": "test_ensemble.py", "classname": null, "funcname": "test_evaluate_link_prediction", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "import tensorflow as tf", "from stellargraph import StellarGraph", "from stellargraph.layer import GraphSAGE, GCN, GAT, HinSAGE, link_classification, link_regression", "from stellargraph.mapper import GraphSAGENodeGenerator, FullBatchNodeGenerator, HinSAGENodeGenerator, GraphSAGELinkGenerator, HinSAGELinkGenerator", "from stellargraph.ensemble import Ensemble, BaggingEnsemble", "from tensorflow.keras import layers, Model", "from tensorflow.keras.optimizers import Adam", "from tensorflow.keras.losses import categorical_crossentropy, binary_crossentropy"], "code": "def test_evaluate_link_prediction():\n    tf.keras.backend.clear_session()\n    edge_ids_test = np.array([[1, 2], [2, 3], [1, 3]])\n    edge_labels_test = np.array([1, 1, 0])\n    graph = example_graph_1(feature_size=4)\n    gnn_models = [create_graphSAGE_model(graph, link_prediction=True), create_HinSAGE_model(graph, link_prediction=True)]\n    for gnn_model in gnn_models:\n        keras_model = gnn_model[1]\n        generator = gnn_model[2]\n        ens = Ensemble(keras_model, n_estimators=2, n_predictions=1)\n        ens.compile(optimizer=Adam(), loss=binary_crossentropy, weighted_metrics=['acc'])\n        with pytest.raises(ValueError):\n            ens.evaluate(generator=generator, test_data=edge_ids_test, test_targets=edge_labels_test)\n        with pytest.raises(ValueError):\n            ens.evaluate(generator=generator, test_data=edge_labels_test, test_targets=None)\n        with pytest.raises(ValueError):\n            ens.evaluate(generator=generator.flow(edge_ids_test, edge_labels_test), test_data=edge_ids_test, test_targets=edge_labels_test)\n        (test_metrics_mean, test_metrics_std) = ens.evaluate(generator.flow(edge_ids_test, edge_labels_test))\n        assert (len(test_metrics_mean) == len(test_metrics_std))\n        assert (len(test_metrics_mean.shape) == 1)\n        assert (len(test_metrics_std.shape) == 1)\n        ens = BaggingEnsemble(keras_model, n_estimators=2, n_predictions=1)\n        ens.compile(optimizer=Adam(), loss=binary_crossentropy, weighted_metrics=['acc'])\n        with pytest.raises(ValueError):\n            ens.evaluate(generator=generator, test_data=edge_ids_test, test_targets=edge_labels_test)\n        with pytest.raises(ValueError):\n            ens.evaluate(generator=generator, test_data=edge_labels_test, test_targets=None)\n        with pytest.raises(ValueError):\n            ens.evaluate(generator=generator.flow(edge_ids_test, edge_labels_test), test_data=edge_ids_test, test_targets=edge_labels_test)\n        (test_metrics_mean, test_metrics_std) = ens.evaluate(generator.flow(edge_ids_test, edge_labels_test))\n        assert (len(test_metrics_mean) == len(test_metrics_std))\n        assert (len(test_metrics_mean.shape) == 1)\n        assert (len(test_metrics_std.shape) == 1)", "masked_code": "def test_evaluate_link_prediction():\n    tf.keras.backend.clear_session()\n    edge_ids_test = np.array([[1, 2], [2, 3], [1, 3]])\n    edge_labels_test = np.array([1, 1, 0])\n    graph = example_graph_1(feature_size=4)\n    gnn_models = [create_graphSAGE_model(graph, link_prediction=True), create_HinSAGE_model(graph, link_prediction=True)]\n    for gnn_model in gnn_models:\n        keras_model = gnn_model[1]\n        generator = gnn_model[2]\n        ens = Ensemble(keras_model, n_estimators=2, n_predictions=1)\n        ens.compile(optimizer=Adam(), loss=binary_crossentropy, weighted_metrics=['acc'])\n        with pytest.raises(ValueError):\n            ens.evaluate(generator=generator, test_data=edge_ids_test, test_targets=edge_labels_test)\n        with pytest.raises(ValueError):\n            ens.evaluate(generator=generator, test_data=edge_labels_test, test_targets=None)\n        with pytest.raises(ValueError):\n            ens.evaluate(generator=generator.flow(edge_ids_test, edge_labels_test), test_data=edge_ids_test, test_targets=edge_labels_test)\n        (test_metrics_mean, test_metrics_std) = ens.evaluate(generator.flow(edge_ids_test, edge_labels_test))\n        assert (len(test_metrics_mean) == '???')\n        assert (len(test_metrics_mean.shape) == 1)\n        assert (len(test_metrics_std.shape) == 1)\n        ens = BaggingEnsemble(keras_model, n_estimators=2, n_predictions=1)\n        ens.compile(optimizer=Adam(), loss=binary_crossentropy, weighted_metrics=['acc'])\n        with pytest.raises(ValueError):\n            ens.evaluate(generator=generator, test_data=edge_ids_test, test_targets=edge_labels_test)\n        with pytest.raises(ValueError):\n            ens.evaluate(generator=generator, test_data=edge_labels_test, test_targets=None)\n        with pytest.raises(ValueError):\n            ens.evaluate(generator=generator.flow(edge_ids_test, edge_labels_test), test_data=edge_ids_test, test_targets=edge_labels_test)\n        (test_metrics_mean, test_metrics_std) = ens.evaluate(generator.flow(edge_ids_test, edge_labels_test))\n        assert (len(test_metrics_mean) == len(test_metrics_std))\n        assert (len(test_metrics_mean.shape) == 1)\n        assert (len(test_metrics_std.shape) == 1)", "ground_truth": "len(test_metrics_std)", "quality_analysis": {"complexity_score": 8, "left_complexity": 4, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_33", "reponame": "stellargraph", "testpath": "tests/test_ensemble.py", "testname": "test_ensemble.py", "classname": null, "funcname": "test_evaluate_link_prediction", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "import tensorflow as tf", "from stellargraph import StellarGraph", "from stellargraph.layer import GraphSAGE, GCN, GAT, HinSAGE, link_classification, link_regression", "from stellargraph.mapper import GraphSAGENodeGenerator, FullBatchNodeGenerator, HinSAGENodeGenerator, GraphSAGELinkGenerator, HinSAGELinkGenerator", "from stellargraph.ensemble import Ensemble, BaggingEnsemble", "from tensorflow.keras import layers, Model", "from tensorflow.keras.optimizers import Adam", "from tensorflow.keras.losses import categorical_crossentropy, binary_crossentropy"], "code": "def test_evaluate_link_prediction():\n    tf.keras.backend.clear_session()\n    edge_ids_test = np.array([[1, 2], [2, 3], [1, 3]])\n    edge_labels_test = np.array([1, 1, 0])\n    graph = example_graph_1(feature_size=4)\n    gnn_models = [create_graphSAGE_model(graph, link_prediction=True), create_HinSAGE_model(graph, link_prediction=True)]\n    for gnn_model in gnn_models:\n        keras_model = gnn_model[1]\n        generator = gnn_model[2]\n        ens = Ensemble(keras_model, n_estimators=2, n_predictions=1)\n        ens.compile(optimizer=Adam(), loss=binary_crossentropy, weighted_metrics=['acc'])\n        with pytest.raises(ValueError):\n            ens.evaluate(generator=generator, test_data=edge_ids_test, test_targets=edge_labels_test)\n        with pytest.raises(ValueError):\n            ens.evaluate(generator=generator, test_data=edge_labels_test, test_targets=None)\n        with pytest.raises(ValueError):\n            ens.evaluate(generator=generator.flow(edge_ids_test, edge_labels_test), test_data=edge_ids_test, test_targets=edge_labels_test)\n        (test_metrics_mean, test_metrics_std) = ens.evaluate(generator.flow(edge_ids_test, edge_labels_test))\n        assert (len(test_metrics_mean) == len(test_metrics_std))\n        assert (len(test_metrics_mean.shape) == 1)\n        assert (len(test_metrics_std.shape) == 1)\n        ens = BaggingEnsemble(keras_model, n_estimators=2, n_predictions=1)\n        ens.compile(optimizer=Adam(), loss=binary_crossentropy, weighted_metrics=['acc'])\n        with pytest.raises(ValueError):\n            ens.evaluate(generator=generator, test_data=edge_ids_test, test_targets=edge_labels_test)\n        with pytest.raises(ValueError):\n            ens.evaluate(generator=generator, test_data=edge_labels_test, test_targets=None)\n        with pytest.raises(ValueError):\n            ens.evaluate(generator=generator.flow(edge_ids_test, edge_labels_test), test_data=edge_ids_test, test_targets=edge_labels_test)\n        (test_metrics_mean, test_metrics_std) = ens.evaluate(generator.flow(edge_ids_test, edge_labels_test))\n        assert (len(test_metrics_mean) == len(test_metrics_std))\n        assert (len(test_metrics_mean.shape) == 1)\n        assert (len(test_metrics_std.shape) == 1)", "masked_code": "def test_evaluate_link_prediction():\n    tf.keras.backend.clear_session()\n    edge_ids_test = np.array([[1, 2], [2, 3], [1, 3]])\n    edge_labels_test = np.array([1, 1, 0])\n    graph = example_graph_1(feature_size=4)\n    gnn_models = [create_graphSAGE_model(graph, link_prediction=True), create_HinSAGE_model(graph, link_prediction=True)]\n    for gnn_model in gnn_models:\n        keras_model = gnn_model[1]\n        generator = gnn_model[2]\n        ens = Ensemble(keras_model, n_estimators=2, n_predictions=1)\n        ens.compile(optimizer=Adam(), loss=binary_crossentropy, weighted_metrics=['acc'])\n        with pytest.raises(ValueError):\n            ens.evaluate(generator=generator, test_data=edge_ids_test, test_targets=edge_labels_test)\n        with pytest.raises(ValueError):\n            ens.evaluate(generator=generator, test_data=edge_labels_test, test_targets=None)\n        with pytest.raises(ValueError):\n            ens.evaluate(generator=generator.flow(edge_ids_test, edge_labels_test), test_data=edge_ids_test, test_targets=edge_labels_test)\n        (test_metrics_mean, test_metrics_std) = ens.evaluate(generator.flow(edge_ids_test, edge_labels_test))\n        assert (len(test_metrics_mean) == len(test_metrics_std))\n        assert (len(test_metrics_mean.shape) == 1)\n        assert (len(test_metrics_std.shape) == 1)\n        ens = BaggingEnsemble(keras_model, n_estimators=2, n_predictions=1)\n        ens.compile(optimizer=Adam(), loss=binary_crossentropy, weighted_metrics=['acc'])\n        with pytest.raises(ValueError):\n            ens.evaluate(generator=generator, test_data=edge_ids_test, test_targets=edge_labels_test)\n        with pytest.raises(ValueError):\n            ens.evaluate(generator=generator, test_data=edge_labels_test, test_targets=None)\n        with pytest.raises(ValueError):\n            ens.evaluate(generator=generator.flow(edge_ids_test, edge_labels_test), test_data=edge_ids_test, test_targets=edge_labels_test)\n        (test_metrics_mean, test_metrics_std) = ens.evaluate(generator.flow(edge_ids_test, edge_labels_test))\n        assert (len(test_metrics_mean) == '???')\n        assert (len(test_metrics_mean.shape) == 1)\n        assert (len(test_metrics_std.shape) == 1)", "ground_truth": "len(test_metrics_std)", "quality_analysis": {"complexity_score": 8, "left_complexity": 4, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_34", "reponame": "stellargraph", "testpath": "tests/test_ensemble.py", "testname": "test_ensemble.py", "classname": null, "funcname": "test_predict_link_prediction", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "import tensorflow as tf", "from stellargraph import StellarGraph", "from stellargraph.layer import GraphSAGE, GCN, GAT, HinSAGE, link_classification, link_regression", "from stellargraph.mapper import GraphSAGENodeGenerator, FullBatchNodeGenerator, HinSAGENodeGenerator, GraphSAGELinkGenerator, HinSAGELinkGenerator", "from stellargraph.ensemble import Ensemble, BaggingEnsemble", "from tensorflow.keras import layers, Model", "from tensorflow.keras.optimizers import Adam", "from tensorflow.keras.losses import categorical_crossentropy, binary_crossentropy"], "code": "def test_predict_link_prediction():\n    tf.keras.backend.clear_session()\n    edge_ids_test = np.array([[1, 2], [2, 3], [1, 3]])\n    graph = example_graph_1(feature_size=2)\n    gnn_models = [create_graphSAGE_model(graph, link_prediction=True), create_HinSAGE_model(graph, link_prediction=True)]\n    for gnn_model in gnn_models:\n        keras_model = gnn_model[1]\n        generator = gnn_model[2]\n        ens = Ensemble(keras_model, n_estimators=2, n_predictions=1)\n        ens.compile(optimizer=Adam(), loss=binary_crossentropy, weighted_metrics=['acc'])\n        test_gen = generator.flow(edge_ids_test)\n        with pytest.raises(ValueError):\n            ens.predict(generator=test_gen, predict_data=edge_ids_test)\n        test_predictions = ens.predict(test_gen, summarise=True)\n        print('test_predictions shape {}'.format(test_predictions.shape))\n        assert (len(test_predictions) == len(edge_ids_test))\n        assert (test_predictions.shape[1] == 1)\n        test_predictions = ens.predict(test_gen, summarise=False)\n        assert (test_predictions.shape[0] == ens.n_estimators)\n        assert (test_predictions.shape[1] == ens.n_predictions)\n        assert (test_predictions.shape[2] == len(edge_ids_test))\n        assert (test_predictions.shape[3] == 1)\n        ens = BaggingEnsemble(keras_model, n_estimators=2, n_predictions=1)\n        ens.compile(optimizer=Adam(), loss=binary_crossentropy, weighted_metrics=['acc'])\n        test_gen = generator.flow(edge_ids_test)\n        with pytest.raises(ValueError):\n            ens.predict(generator=test_gen, predict_data=edge_ids_test)\n        test_predictions = ens.predict(test_gen, summarise=True)\n        print('test_predictions shape {}'.format(test_predictions.shape))\n        assert (len(test_predictions) == len(edge_ids_test))\n        assert (test_predictions.shape[1] == 1)\n        test_predictions = ens.predict(test_gen, summarise=False)\n        assert (test_predictions.shape[0] == ens.n_estimators)\n        assert (test_predictions.shape[1] == ens.n_predictions)\n        assert (test_predictions.shape[2] == len(edge_ids_test))\n        assert (test_predictions.shape[3] == 1)", "masked_code": "def test_predict_link_prediction():\n    tf.keras.backend.clear_session()\n    edge_ids_test = np.array([[1, 2], [2, 3], [1, 3]])\n    graph = example_graph_1(feature_size=2)\n    gnn_models = [create_graphSAGE_model(graph, link_prediction=True), create_HinSAGE_model(graph, link_prediction=True)]\n    for gnn_model in gnn_models:\n        keras_model = gnn_model[1]\n        generator = gnn_model[2]\n        ens = Ensemble(keras_model, n_estimators=2, n_predictions=1)\n        ens.compile(optimizer=Adam(), loss=binary_crossentropy, weighted_metrics=['acc'])\n        test_gen = generator.flow(edge_ids_test)\n        with pytest.raises(ValueError):\n            ens.predict(generator=test_gen, predict_data=edge_ids_test)\n        test_predictions = ens.predict(test_gen, summarise=True)\n        print('test_predictions shape {}'.format(test_predictions.shape))\n        assert (len(test_predictions) == '???')\n        assert (test_predictions.shape[1] == 1)\n        test_predictions = ens.predict(test_gen, summarise=False)\n        assert (test_predictions.shape[0] == ens.n_estimators)\n        assert (test_predictions.shape[1] == ens.n_predictions)\n        assert (test_predictions.shape[2] == len(edge_ids_test))\n        assert (test_predictions.shape[3] == 1)\n        ens = BaggingEnsemble(keras_model, n_estimators=2, n_predictions=1)\n        ens.compile(optimizer=Adam(), loss=binary_crossentropy, weighted_metrics=['acc'])\n        test_gen = generator.flow(edge_ids_test)\n        with pytest.raises(ValueError):\n            ens.predict(generator=test_gen, predict_data=edge_ids_test)\n        test_predictions = ens.predict(test_gen, summarise=True)\n        print('test_predictions shape {}'.format(test_predictions.shape))\n        assert (len(test_predictions) == len(edge_ids_test))\n        assert (test_predictions.shape[1] == 1)\n        test_predictions = ens.predict(test_gen, summarise=False)\n        assert (test_predictions.shape[0] == ens.n_estimators)\n        assert (test_predictions.shape[1] == ens.n_predictions)\n        assert (test_predictions.shape[2] == len(edge_ids_test))\n        assert (test_predictions.shape[3] == 1)", "ground_truth": "len(edge_ids_test)", "quality_analysis": {"complexity_score": 8, "left_complexity": 4, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_35", "reponame": "stellargraph", "testpath": "tests/test_ensemble.py", "testname": "test_ensemble.py", "classname": null, "funcname": "test_predict_link_prediction", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "import tensorflow as tf", "from stellargraph import StellarGraph", "from stellargraph.layer import GraphSAGE, GCN, GAT, HinSAGE, link_classification, link_regression", "from stellargraph.mapper import GraphSAGENodeGenerator, FullBatchNodeGenerator, HinSAGENodeGenerator, GraphSAGELinkGenerator, HinSAGELinkGenerator", "from stellargraph.ensemble import Ensemble, BaggingEnsemble", "from tensorflow.keras import layers, Model", "from tensorflow.keras.optimizers import Adam", "from tensorflow.keras.losses import categorical_crossentropy, binary_crossentropy"], "code": "def test_predict_link_prediction():\n    tf.keras.backend.clear_session()\n    edge_ids_test = np.array([[1, 2], [2, 3], [1, 3]])\n    graph = example_graph_1(feature_size=2)\n    gnn_models = [create_graphSAGE_model(graph, link_prediction=True), create_HinSAGE_model(graph, link_prediction=True)]\n    for gnn_model in gnn_models:\n        keras_model = gnn_model[1]\n        generator = gnn_model[2]\n        ens = Ensemble(keras_model, n_estimators=2, n_predictions=1)\n        ens.compile(optimizer=Adam(), loss=binary_crossentropy, weighted_metrics=['acc'])\n        test_gen = generator.flow(edge_ids_test)\n        with pytest.raises(ValueError):\n            ens.predict(generator=test_gen, predict_data=edge_ids_test)\n        test_predictions = ens.predict(test_gen, summarise=True)\n        print('test_predictions shape {}'.format(test_predictions.shape))\n        assert (len(test_predictions) == len(edge_ids_test))\n        assert (test_predictions.shape[1] == 1)\n        test_predictions = ens.predict(test_gen, summarise=False)\n        assert (test_predictions.shape[0] == ens.n_estimators)\n        assert (test_predictions.shape[1] == ens.n_predictions)\n        assert (test_predictions.shape[2] == len(edge_ids_test))\n        assert (test_predictions.shape[3] == 1)\n        ens = BaggingEnsemble(keras_model, n_estimators=2, n_predictions=1)\n        ens.compile(optimizer=Adam(), loss=binary_crossentropy, weighted_metrics=['acc'])\n        test_gen = generator.flow(edge_ids_test)\n        with pytest.raises(ValueError):\n            ens.predict(generator=test_gen, predict_data=edge_ids_test)\n        test_predictions = ens.predict(test_gen, summarise=True)\n        print('test_predictions shape {}'.format(test_predictions.shape))\n        assert (len(test_predictions) == len(edge_ids_test))\n        assert (test_predictions.shape[1] == 1)\n        test_predictions = ens.predict(test_gen, summarise=False)\n        assert (test_predictions.shape[0] == ens.n_estimators)\n        assert (test_predictions.shape[1] == ens.n_predictions)\n        assert (test_predictions.shape[2] == len(edge_ids_test))\n        assert (test_predictions.shape[3] == 1)", "masked_code": "def test_predict_link_prediction():\n    tf.keras.backend.clear_session()\n    edge_ids_test = np.array([[1, 2], [2, 3], [1, 3]])\n    graph = example_graph_1(feature_size=2)\n    gnn_models = [create_graphSAGE_model(graph, link_prediction=True), create_HinSAGE_model(graph, link_prediction=True)]\n    for gnn_model in gnn_models:\n        keras_model = gnn_model[1]\n        generator = gnn_model[2]\n        ens = Ensemble(keras_model, n_estimators=2, n_predictions=1)\n        ens.compile(optimizer=Adam(), loss=binary_crossentropy, weighted_metrics=['acc'])\n        test_gen = generator.flow(edge_ids_test)\n        with pytest.raises(ValueError):\n            ens.predict(generator=test_gen, predict_data=edge_ids_test)\n        test_predictions = ens.predict(test_gen, summarise=True)\n        print('test_predictions shape {}'.format(test_predictions.shape))\n        assert (len(test_predictions) == len(edge_ids_test))\n        assert (test_predictions.shape[1] == 1)\n        test_predictions = ens.predict(test_gen, summarise=False)\n        assert (test_predictions.shape[0] == '???')\n        assert (test_predictions.shape[1] == ens.n_predictions)\n        assert (test_predictions.shape[2] == len(edge_ids_test))\n        assert (test_predictions.shape[3] == 1)\n        ens = BaggingEnsemble(keras_model, n_estimators=2, n_predictions=1)\n        ens.compile(optimizer=Adam(), loss=binary_crossentropy, weighted_metrics=['acc'])\n        test_gen = generator.flow(edge_ids_test)\n        with pytest.raises(ValueError):\n            ens.predict(generator=test_gen, predict_data=edge_ids_test)\n        test_predictions = ens.predict(test_gen, summarise=True)\n        print('test_predictions shape {}'.format(test_predictions.shape))\n        assert (len(test_predictions) == len(edge_ids_test))\n        assert (test_predictions.shape[1] == 1)\n        test_predictions = ens.predict(test_gen, summarise=False)\n        assert (test_predictions.shape[0] == ens.n_estimators)\n        assert (test_predictions.shape[1] == ens.n_predictions)\n        assert (test_predictions.shape[2] == len(edge_ids_test))\n        assert (test_predictions.shape[3] == 1)", "ground_truth": "ens.n_estimators", "quality_analysis": {"complexity_score": 8, "left_complexity": 6, "right_complexity": 2, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_36", "reponame": "stellargraph", "testpath": "tests/test_ensemble.py", "testname": "test_ensemble.py", "classname": null, "funcname": "test_predict_link_prediction", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "import tensorflow as tf", "from stellargraph import StellarGraph", "from stellargraph.layer import GraphSAGE, GCN, GAT, HinSAGE, link_classification, link_regression", "from stellargraph.mapper import GraphSAGENodeGenerator, FullBatchNodeGenerator, HinSAGENodeGenerator, GraphSAGELinkGenerator, HinSAGELinkGenerator", "from stellargraph.ensemble import Ensemble, BaggingEnsemble", "from tensorflow.keras import layers, Model", "from tensorflow.keras.optimizers import Adam", "from tensorflow.keras.losses import categorical_crossentropy, binary_crossentropy"], "code": "def test_predict_link_prediction():\n    tf.keras.backend.clear_session()\n    edge_ids_test = np.array([[1, 2], [2, 3], [1, 3]])\n    graph = example_graph_1(feature_size=2)\n    gnn_models = [create_graphSAGE_model(graph, link_prediction=True), create_HinSAGE_model(graph, link_prediction=True)]\n    for gnn_model in gnn_models:\n        keras_model = gnn_model[1]\n        generator = gnn_model[2]\n        ens = Ensemble(keras_model, n_estimators=2, n_predictions=1)\n        ens.compile(optimizer=Adam(), loss=binary_crossentropy, weighted_metrics=['acc'])\n        test_gen = generator.flow(edge_ids_test)\n        with pytest.raises(ValueError):\n            ens.predict(generator=test_gen, predict_data=edge_ids_test)\n        test_predictions = ens.predict(test_gen, summarise=True)\n        print('test_predictions shape {}'.format(test_predictions.shape))\n        assert (len(test_predictions) == len(edge_ids_test))\n        assert (test_predictions.shape[1] == 1)\n        test_predictions = ens.predict(test_gen, summarise=False)\n        assert (test_predictions.shape[0] == ens.n_estimators)\n        assert (test_predictions.shape[1] == ens.n_predictions)\n        assert (test_predictions.shape[2] == len(edge_ids_test))\n        assert (test_predictions.shape[3] == 1)\n        ens = BaggingEnsemble(keras_model, n_estimators=2, n_predictions=1)\n        ens.compile(optimizer=Adam(), loss=binary_crossentropy, weighted_metrics=['acc'])\n        test_gen = generator.flow(edge_ids_test)\n        with pytest.raises(ValueError):\n            ens.predict(generator=test_gen, predict_data=edge_ids_test)\n        test_predictions = ens.predict(test_gen, summarise=True)\n        print('test_predictions shape {}'.format(test_predictions.shape))\n        assert (len(test_predictions) == len(edge_ids_test))\n        assert (test_predictions.shape[1] == 1)\n        test_predictions = ens.predict(test_gen, summarise=False)\n        assert (test_predictions.shape[0] == ens.n_estimators)\n        assert (test_predictions.shape[1] == ens.n_predictions)\n        assert (test_predictions.shape[2] == len(edge_ids_test))\n        assert (test_predictions.shape[3] == 1)", "masked_code": "def test_predict_link_prediction():\n    tf.keras.backend.clear_session()\n    edge_ids_test = np.array([[1, 2], [2, 3], [1, 3]])\n    graph = example_graph_1(feature_size=2)\n    gnn_models = [create_graphSAGE_model(graph, link_prediction=True), create_HinSAGE_model(graph, link_prediction=True)]\n    for gnn_model in gnn_models:\n        keras_model = gnn_model[1]\n        generator = gnn_model[2]\n        ens = Ensemble(keras_model, n_estimators=2, n_predictions=1)\n        ens.compile(optimizer=Adam(), loss=binary_crossentropy, weighted_metrics=['acc'])\n        test_gen = generator.flow(edge_ids_test)\n        with pytest.raises(ValueError):\n            ens.predict(generator=test_gen, predict_data=edge_ids_test)\n        test_predictions = ens.predict(test_gen, summarise=True)\n        print('test_predictions shape {}'.format(test_predictions.shape))\n        assert (len(test_predictions) == len(edge_ids_test))\n        assert (test_predictions.shape[1] == 1)\n        test_predictions = ens.predict(test_gen, summarise=False)\n        assert (test_predictions.shape[0] == ens.n_estimators)\n        assert (test_predictions.shape[1] == '???')\n        assert (test_predictions.shape[2] == len(edge_ids_test))\n        assert (test_predictions.shape[3] == 1)\n        ens = BaggingEnsemble(keras_model, n_estimators=2, n_predictions=1)\n        ens.compile(optimizer=Adam(), loss=binary_crossentropy, weighted_metrics=['acc'])\n        test_gen = generator.flow(edge_ids_test)\n        with pytest.raises(ValueError):\n            ens.predict(generator=test_gen, predict_data=edge_ids_test)\n        test_predictions = ens.predict(test_gen, summarise=True)\n        print('test_predictions shape {}'.format(test_predictions.shape))\n        assert (len(test_predictions) == len(edge_ids_test))\n        assert (test_predictions.shape[1] == 1)\n        test_predictions = ens.predict(test_gen, summarise=False)\n        assert (test_predictions.shape[0] == ens.n_estimators)\n        assert (test_predictions.shape[1] == ens.n_predictions)\n        assert (test_predictions.shape[2] == len(edge_ids_test))\n        assert (test_predictions.shape[3] == 1)", "ground_truth": "ens.n_predictions", "quality_analysis": {"complexity_score": 8, "left_complexity": 6, "right_complexity": 2, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_37", "reponame": "stellargraph", "testpath": "tests/test_ensemble.py", "testname": "test_ensemble.py", "classname": null, "funcname": "test_predict_link_prediction", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "import tensorflow as tf", "from stellargraph import StellarGraph", "from stellargraph.layer import GraphSAGE, GCN, GAT, HinSAGE, link_classification, link_regression", "from stellargraph.mapper import GraphSAGENodeGenerator, FullBatchNodeGenerator, HinSAGENodeGenerator, GraphSAGELinkGenerator, HinSAGELinkGenerator", "from stellargraph.ensemble import Ensemble, BaggingEnsemble", "from tensorflow.keras import layers, Model", "from tensorflow.keras.optimizers import Adam", "from tensorflow.keras.losses import categorical_crossentropy, binary_crossentropy"], "code": "def test_predict_link_prediction():\n    tf.keras.backend.clear_session()\n    edge_ids_test = np.array([[1, 2], [2, 3], [1, 3]])\n    graph = example_graph_1(feature_size=2)\n    gnn_models = [create_graphSAGE_model(graph, link_prediction=True), create_HinSAGE_model(graph, link_prediction=True)]\n    for gnn_model in gnn_models:\n        keras_model = gnn_model[1]\n        generator = gnn_model[2]\n        ens = Ensemble(keras_model, n_estimators=2, n_predictions=1)\n        ens.compile(optimizer=Adam(), loss=binary_crossentropy, weighted_metrics=['acc'])\n        test_gen = generator.flow(edge_ids_test)\n        with pytest.raises(ValueError):\n            ens.predict(generator=test_gen, predict_data=edge_ids_test)\n        test_predictions = ens.predict(test_gen, summarise=True)\n        print('test_predictions shape {}'.format(test_predictions.shape))\n        assert (len(test_predictions) == len(edge_ids_test))\n        assert (test_predictions.shape[1] == 1)\n        test_predictions = ens.predict(test_gen, summarise=False)\n        assert (test_predictions.shape[0] == ens.n_estimators)\n        assert (test_predictions.shape[1] == ens.n_predictions)\n        assert (test_predictions.shape[2] == len(edge_ids_test))\n        assert (test_predictions.shape[3] == 1)\n        ens = BaggingEnsemble(keras_model, n_estimators=2, n_predictions=1)\n        ens.compile(optimizer=Adam(), loss=binary_crossentropy, weighted_metrics=['acc'])\n        test_gen = generator.flow(edge_ids_test)\n        with pytest.raises(ValueError):\n            ens.predict(generator=test_gen, predict_data=edge_ids_test)\n        test_predictions = ens.predict(test_gen, summarise=True)\n        print('test_predictions shape {}'.format(test_predictions.shape))\n        assert (len(test_predictions) == len(edge_ids_test))\n        assert (test_predictions.shape[1] == 1)\n        test_predictions = ens.predict(test_gen, summarise=False)\n        assert (test_predictions.shape[0] == ens.n_estimators)\n        assert (test_predictions.shape[1] == ens.n_predictions)\n        assert (test_predictions.shape[2] == len(edge_ids_test))\n        assert (test_predictions.shape[3] == 1)", "masked_code": "def test_predict_link_prediction():\n    tf.keras.backend.clear_session()\n    edge_ids_test = np.array([[1, 2], [2, 3], [1, 3]])\n    graph = example_graph_1(feature_size=2)\n    gnn_models = [create_graphSAGE_model(graph, link_prediction=True), create_HinSAGE_model(graph, link_prediction=True)]\n    for gnn_model in gnn_models:\n        keras_model = gnn_model[1]\n        generator = gnn_model[2]\n        ens = Ensemble(keras_model, n_estimators=2, n_predictions=1)\n        ens.compile(optimizer=Adam(), loss=binary_crossentropy, weighted_metrics=['acc'])\n        test_gen = generator.flow(edge_ids_test)\n        with pytest.raises(ValueError):\n            ens.predict(generator=test_gen, predict_data=edge_ids_test)\n        test_predictions = ens.predict(test_gen, summarise=True)\n        print('test_predictions shape {}'.format(test_predictions.shape))\n        assert (len(test_predictions) == len(edge_ids_test))\n        assert (test_predictions.shape[1] == 1)\n        test_predictions = ens.predict(test_gen, summarise=False)\n        assert (test_predictions.shape[0] == ens.n_estimators)\n        assert (test_predictions.shape[1] == ens.n_predictions)\n        assert (test_predictions.shape[2] == '???')\n        assert (test_predictions.shape[3] == 1)\n        ens = BaggingEnsemble(keras_model, n_estimators=2, n_predictions=1)\n        ens.compile(optimizer=Adam(), loss=binary_crossentropy, weighted_metrics=['acc'])\n        test_gen = generator.flow(edge_ids_test)\n        with pytest.raises(ValueError):\n            ens.predict(generator=test_gen, predict_data=edge_ids_test)\n        test_predictions = ens.predict(test_gen, summarise=True)\n        print('test_predictions shape {}'.format(test_predictions.shape))\n        assert (len(test_predictions) == len(edge_ids_test))\n        assert (test_predictions.shape[1] == 1)\n        test_predictions = ens.predict(test_gen, summarise=False)\n        assert (test_predictions.shape[0] == ens.n_estimators)\n        assert (test_predictions.shape[1] == ens.n_predictions)\n        assert (test_predictions.shape[2] == len(edge_ids_test))\n        assert (test_predictions.shape[3] == 1)", "ground_truth": "len(edge_ids_test)", "quality_analysis": {"complexity_score": 10, "left_complexity": 6, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_38", "reponame": "stellargraph", "testpath": "tests/test_ensemble.py", "testname": "test_ensemble.py", "classname": null, "funcname": "test_predict_link_prediction", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "import tensorflow as tf", "from stellargraph import StellarGraph", "from stellargraph.layer import GraphSAGE, GCN, GAT, HinSAGE, link_classification, link_regression", "from stellargraph.mapper import GraphSAGENodeGenerator, FullBatchNodeGenerator, HinSAGENodeGenerator, GraphSAGELinkGenerator, HinSAGELinkGenerator", "from stellargraph.ensemble import Ensemble, BaggingEnsemble", "from tensorflow.keras import layers, Model", "from tensorflow.keras.optimizers import Adam", "from tensorflow.keras.losses import categorical_crossentropy, binary_crossentropy"], "code": "def test_predict_link_prediction():\n    tf.keras.backend.clear_session()\n    edge_ids_test = np.array([[1, 2], [2, 3], [1, 3]])\n    graph = example_graph_1(feature_size=2)\n    gnn_models = [create_graphSAGE_model(graph, link_prediction=True), create_HinSAGE_model(graph, link_prediction=True)]\n    for gnn_model in gnn_models:\n        keras_model = gnn_model[1]\n        generator = gnn_model[2]\n        ens = Ensemble(keras_model, n_estimators=2, n_predictions=1)\n        ens.compile(optimizer=Adam(), loss=binary_crossentropy, weighted_metrics=['acc'])\n        test_gen = generator.flow(edge_ids_test)\n        with pytest.raises(ValueError):\n            ens.predict(generator=test_gen, predict_data=edge_ids_test)\n        test_predictions = ens.predict(test_gen, summarise=True)\n        print('test_predictions shape {}'.format(test_predictions.shape))\n        assert (len(test_predictions) == len(edge_ids_test))\n        assert (test_predictions.shape[1] == 1)\n        test_predictions = ens.predict(test_gen, summarise=False)\n        assert (test_predictions.shape[0] == ens.n_estimators)\n        assert (test_predictions.shape[1] == ens.n_predictions)\n        assert (test_predictions.shape[2] == len(edge_ids_test))\n        assert (test_predictions.shape[3] == 1)\n        ens = BaggingEnsemble(keras_model, n_estimators=2, n_predictions=1)\n        ens.compile(optimizer=Adam(), loss=binary_crossentropy, weighted_metrics=['acc'])\n        test_gen = generator.flow(edge_ids_test)\n        with pytest.raises(ValueError):\n            ens.predict(generator=test_gen, predict_data=edge_ids_test)\n        test_predictions = ens.predict(test_gen, summarise=True)\n        print('test_predictions shape {}'.format(test_predictions.shape))\n        assert (len(test_predictions) == len(edge_ids_test))\n        assert (test_predictions.shape[1] == 1)\n        test_predictions = ens.predict(test_gen, summarise=False)\n        assert (test_predictions.shape[0] == ens.n_estimators)\n        assert (test_predictions.shape[1] == ens.n_predictions)\n        assert (test_predictions.shape[2] == len(edge_ids_test))\n        assert (test_predictions.shape[3] == 1)", "masked_code": "def test_predict_link_prediction():\n    tf.keras.backend.clear_session()\n    edge_ids_test = np.array([[1, 2], [2, 3], [1, 3]])\n    graph = example_graph_1(feature_size=2)\n    gnn_models = [create_graphSAGE_model(graph, link_prediction=True), create_HinSAGE_model(graph, link_prediction=True)]\n    for gnn_model in gnn_models:\n        keras_model = gnn_model[1]\n        generator = gnn_model[2]\n        ens = Ensemble(keras_model, n_estimators=2, n_predictions=1)\n        ens.compile(optimizer=Adam(), loss=binary_crossentropy, weighted_metrics=['acc'])\n        test_gen = generator.flow(edge_ids_test)\n        with pytest.raises(ValueError):\n            ens.predict(generator=test_gen, predict_data=edge_ids_test)\n        test_predictions = ens.predict(test_gen, summarise=True)\n        print('test_predictions shape {}'.format(test_predictions.shape))\n        assert (len(test_predictions) == len(edge_ids_test))\n        assert (test_predictions.shape[1] == 1)\n        test_predictions = ens.predict(test_gen, summarise=False)\n        assert (test_predictions.shape[0] == ens.n_estimators)\n        assert (test_predictions.shape[1] == ens.n_predictions)\n        assert (test_predictions.shape[2] == len(edge_ids_test))\n        assert (test_predictions.shape[3] == 1)\n        ens = BaggingEnsemble(keras_model, n_estimators=2, n_predictions=1)\n        ens.compile(optimizer=Adam(), loss=binary_crossentropy, weighted_metrics=['acc'])\n        test_gen = generator.flow(edge_ids_test)\n        with pytest.raises(ValueError):\n            ens.predict(generator=test_gen, predict_data=edge_ids_test)\n        test_predictions = ens.predict(test_gen, summarise=True)\n        print('test_predictions shape {}'.format(test_predictions.shape))\n        assert (len(test_predictions) == '???')\n        assert (test_predictions.shape[1] == 1)\n        test_predictions = ens.predict(test_gen, summarise=False)\n        assert (test_predictions.shape[0] == ens.n_estimators)\n        assert (test_predictions.shape[1] == ens.n_predictions)\n        assert (test_predictions.shape[2] == len(edge_ids_test))\n        assert (test_predictions.shape[3] == 1)", "ground_truth": "len(edge_ids_test)", "quality_analysis": {"complexity_score": 8, "left_complexity": 4, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_39", "reponame": "stellargraph", "testpath": "tests/test_ensemble.py", "testname": "test_ensemble.py", "classname": null, "funcname": "test_predict_link_prediction", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "import tensorflow as tf", "from stellargraph import StellarGraph", "from stellargraph.layer import GraphSAGE, GCN, GAT, HinSAGE, link_classification, link_regression", "from stellargraph.mapper import GraphSAGENodeGenerator, FullBatchNodeGenerator, HinSAGENodeGenerator, GraphSAGELinkGenerator, HinSAGELinkGenerator", "from stellargraph.ensemble import Ensemble, BaggingEnsemble", "from tensorflow.keras import layers, Model", "from tensorflow.keras.optimizers import Adam", "from tensorflow.keras.losses import categorical_crossentropy, binary_crossentropy"], "code": "def test_predict_link_prediction():\n    tf.keras.backend.clear_session()\n    edge_ids_test = np.array([[1, 2], [2, 3], [1, 3]])\n    graph = example_graph_1(feature_size=2)\n    gnn_models = [create_graphSAGE_model(graph, link_prediction=True), create_HinSAGE_model(graph, link_prediction=True)]\n    for gnn_model in gnn_models:\n        keras_model = gnn_model[1]\n        generator = gnn_model[2]\n        ens = Ensemble(keras_model, n_estimators=2, n_predictions=1)\n        ens.compile(optimizer=Adam(), loss=binary_crossentropy, weighted_metrics=['acc'])\n        test_gen = generator.flow(edge_ids_test)\n        with pytest.raises(ValueError):\n            ens.predict(generator=test_gen, predict_data=edge_ids_test)\n        test_predictions = ens.predict(test_gen, summarise=True)\n        print('test_predictions shape {}'.format(test_predictions.shape))\n        assert (len(test_predictions) == len(edge_ids_test))\n        assert (test_predictions.shape[1] == 1)\n        test_predictions = ens.predict(test_gen, summarise=False)\n        assert (test_predictions.shape[0] == ens.n_estimators)\n        assert (test_predictions.shape[1] == ens.n_predictions)\n        assert (test_predictions.shape[2] == len(edge_ids_test))\n        assert (test_predictions.shape[3] == 1)\n        ens = BaggingEnsemble(keras_model, n_estimators=2, n_predictions=1)\n        ens.compile(optimizer=Adam(), loss=binary_crossentropy, weighted_metrics=['acc'])\n        test_gen = generator.flow(edge_ids_test)\n        with pytest.raises(ValueError):\n            ens.predict(generator=test_gen, predict_data=edge_ids_test)\n        test_predictions = ens.predict(test_gen, summarise=True)\n        print('test_predictions shape {}'.format(test_predictions.shape))\n        assert (len(test_predictions) == len(edge_ids_test))\n        assert (test_predictions.shape[1] == 1)\n        test_predictions = ens.predict(test_gen, summarise=False)\n        assert (test_predictions.shape[0] == ens.n_estimators)\n        assert (test_predictions.shape[1] == ens.n_predictions)\n        assert (test_predictions.shape[2] == len(edge_ids_test))\n        assert (test_predictions.shape[3] == 1)", "masked_code": "def test_predict_link_prediction():\n    tf.keras.backend.clear_session()\n    edge_ids_test = np.array([[1, 2], [2, 3], [1, 3]])\n    graph = example_graph_1(feature_size=2)\n    gnn_models = [create_graphSAGE_model(graph, link_prediction=True), create_HinSAGE_model(graph, link_prediction=True)]\n    for gnn_model in gnn_models:\n        keras_model = gnn_model[1]\n        generator = gnn_model[2]\n        ens = Ensemble(keras_model, n_estimators=2, n_predictions=1)\n        ens.compile(optimizer=Adam(), loss=binary_crossentropy, weighted_metrics=['acc'])\n        test_gen = generator.flow(edge_ids_test)\n        with pytest.raises(ValueError):\n            ens.predict(generator=test_gen, predict_data=edge_ids_test)\n        test_predictions = ens.predict(test_gen, summarise=True)\n        print('test_predictions shape {}'.format(test_predictions.shape))\n        assert (len(test_predictions) == len(edge_ids_test))\n        assert (test_predictions.shape[1] == 1)\n        test_predictions = ens.predict(test_gen, summarise=False)\n        assert (test_predictions.shape[0] == ens.n_estimators)\n        assert (test_predictions.shape[1] == ens.n_predictions)\n        assert (test_predictions.shape[2] == len(edge_ids_test))\n        assert (test_predictions.shape[3] == 1)\n        ens = BaggingEnsemble(keras_model, n_estimators=2, n_predictions=1)\n        ens.compile(optimizer=Adam(), loss=binary_crossentropy, weighted_metrics=['acc'])\n        test_gen = generator.flow(edge_ids_test)\n        with pytest.raises(ValueError):\n            ens.predict(generator=test_gen, predict_data=edge_ids_test)\n        test_predictions = ens.predict(test_gen, summarise=True)\n        print('test_predictions shape {}'.format(test_predictions.shape))\n        assert (len(test_predictions) == len(edge_ids_test))\n        assert (test_predictions.shape[1] == 1)\n        test_predictions = ens.predict(test_gen, summarise=False)\n        assert (test_predictions.shape[0] == '???')\n        assert (test_predictions.shape[1] == ens.n_predictions)\n        assert (test_predictions.shape[2] == len(edge_ids_test))\n        assert (test_predictions.shape[3] == 1)", "ground_truth": "ens.n_estimators", "quality_analysis": {"complexity_score": 8, "left_complexity": 6, "right_complexity": 2, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_40", "reponame": "stellargraph", "testpath": "tests/test_ensemble.py", "testname": "test_ensemble.py", "classname": null, "funcname": "test_predict_link_prediction", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "import tensorflow as tf", "from stellargraph import StellarGraph", "from stellargraph.layer import GraphSAGE, GCN, GAT, HinSAGE, link_classification, link_regression", "from stellargraph.mapper import GraphSAGENodeGenerator, FullBatchNodeGenerator, HinSAGENodeGenerator, GraphSAGELinkGenerator, HinSAGELinkGenerator", "from stellargraph.ensemble import Ensemble, BaggingEnsemble", "from tensorflow.keras import layers, Model", "from tensorflow.keras.optimizers import Adam", "from tensorflow.keras.losses import categorical_crossentropy, binary_crossentropy"], "code": "def test_predict_link_prediction():\n    tf.keras.backend.clear_session()\n    edge_ids_test = np.array([[1, 2], [2, 3], [1, 3]])\n    graph = example_graph_1(feature_size=2)\n    gnn_models = [create_graphSAGE_model(graph, link_prediction=True), create_HinSAGE_model(graph, link_prediction=True)]\n    for gnn_model in gnn_models:\n        keras_model = gnn_model[1]\n        generator = gnn_model[2]\n        ens = Ensemble(keras_model, n_estimators=2, n_predictions=1)\n        ens.compile(optimizer=Adam(), loss=binary_crossentropy, weighted_metrics=['acc'])\n        test_gen = generator.flow(edge_ids_test)\n        with pytest.raises(ValueError):\n            ens.predict(generator=test_gen, predict_data=edge_ids_test)\n        test_predictions = ens.predict(test_gen, summarise=True)\n        print('test_predictions shape {}'.format(test_predictions.shape))\n        assert (len(test_predictions) == len(edge_ids_test))\n        assert (test_predictions.shape[1] == 1)\n        test_predictions = ens.predict(test_gen, summarise=False)\n        assert (test_predictions.shape[0] == ens.n_estimators)\n        assert (test_predictions.shape[1] == ens.n_predictions)\n        assert (test_predictions.shape[2] == len(edge_ids_test))\n        assert (test_predictions.shape[3] == 1)\n        ens = BaggingEnsemble(keras_model, n_estimators=2, n_predictions=1)\n        ens.compile(optimizer=Adam(), loss=binary_crossentropy, weighted_metrics=['acc'])\n        test_gen = generator.flow(edge_ids_test)\n        with pytest.raises(ValueError):\n            ens.predict(generator=test_gen, predict_data=edge_ids_test)\n        test_predictions = ens.predict(test_gen, summarise=True)\n        print('test_predictions shape {}'.format(test_predictions.shape))\n        assert (len(test_predictions) == len(edge_ids_test))\n        assert (test_predictions.shape[1] == 1)\n        test_predictions = ens.predict(test_gen, summarise=False)\n        assert (test_predictions.shape[0] == ens.n_estimators)\n        assert (test_predictions.shape[1] == ens.n_predictions)\n        assert (test_predictions.shape[2] == len(edge_ids_test))\n        assert (test_predictions.shape[3] == 1)", "masked_code": "def test_predict_link_prediction():\n    tf.keras.backend.clear_session()\n    edge_ids_test = np.array([[1, 2], [2, 3], [1, 3]])\n    graph = example_graph_1(feature_size=2)\n    gnn_models = [create_graphSAGE_model(graph, link_prediction=True), create_HinSAGE_model(graph, link_prediction=True)]\n    for gnn_model in gnn_models:\n        keras_model = gnn_model[1]\n        generator = gnn_model[2]\n        ens = Ensemble(keras_model, n_estimators=2, n_predictions=1)\n        ens.compile(optimizer=Adam(), loss=binary_crossentropy, weighted_metrics=['acc'])\n        test_gen = generator.flow(edge_ids_test)\n        with pytest.raises(ValueError):\n            ens.predict(generator=test_gen, predict_data=edge_ids_test)\n        test_predictions = ens.predict(test_gen, summarise=True)\n        print('test_predictions shape {}'.format(test_predictions.shape))\n        assert (len(test_predictions) == len(edge_ids_test))\n        assert (test_predictions.shape[1] == 1)\n        test_predictions = ens.predict(test_gen, summarise=False)\n        assert (test_predictions.shape[0] == ens.n_estimators)\n        assert (test_predictions.shape[1] == ens.n_predictions)\n        assert (test_predictions.shape[2] == len(edge_ids_test))\n        assert (test_predictions.shape[3] == 1)\n        ens = BaggingEnsemble(keras_model, n_estimators=2, n_predictions=1)\n        ens.compile(optimizer=Adam(), loss=binary_crossentropy, weighted_metrics=['acc'])\n        test_gen = generator.flow(edge_ids_test)\n        with pytest.raises(ValueError):\n            ens.predict(generator=test_gen, predict_data=edge_ids_test)\n        test_predictions = ens.predict(test_gen, summarise=True)\n        print('test_predictions shape {}'.format(test_predictions.shape))\n        assert (len(test_predictions) == len(edge_ids_test))\n        assert (test_predictions.shape[1] == 1)\n        test_predictions = ens.predict(test_gen, summarise=False)\n        assert (test_predictions.shape[0] == ens.n_estimators)\n        assert (test_predictions.shape[1] == '???')\n        assert (test_predictions.shape[2] == len(edge_ids_test))\n        assert (test_predictions.shape[3] == 1)", "ground_truth": "ens.n_predictions", "quality_analysis": {"complexity_score": 8, "left_complexity": 6, "right_complexity": 2, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_41", "reponame": "stellargraph", "testpath": "tests/test_ensemble.py", "testname": "test_ensemble.py", "classname": null, "funcname": "test_predict_link_prediction", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "import tensorflow as tf", "from stellargraph import StellarGraph", "from stellargraph.layer import GraphSAGE, GCN, GAT, HinSAGE, link_classification, link_regression", "from stellargraph.mapper import GraphSAGENodeGenerator, FullBatchNodeGenerator, HinSAGENodeGenerator, GraphSAGELinkGenerator, HinSAGELinkGenerator", "from stellargraph.ensemble import Ensemble, BaggingEnsemble", "from tensorflow.keras import layers, Model", "from tensorflow.keras.optimizers import Adam", "from tensorflow.keras.losses import categorical_crossentropy, binary_crossentropy"], "code": "def test_predict_link_prediction():\n    tf.keras.backend.clear_session()\n    edge_ids_test = np.array([[1, 2], [2, 3], [1, 3]])\n    graph = example_graph_1(feature_size=2)\n    gnn_models = [create_graphSAGE_model(graph, link_prediction=True), create_HinSAGE_model(graph, link_prediction=True)]\n    for gnn_model in gnn_models:\n        keras_model = gnn_model[1]\n        generator = gnn_model[2]\n        ens = Ensemble(keras_model, n_estimators=2, n_predictions=1)\n        ens.compile(optimizer=Adam(), loss=binary_crossentropy, weighted_metrics=['acc'])\n        test_gen = generator.flow(edge_ids_test)\n        with pytest.raises(ValueError):\n            ens.predict(generator=test_gen, predict_data=edge_ids_test)\n        test_predictions = ens.predict(test_gen, summarise=True)\n        print('test_predictions shape {}'.format(test_predictions.shape))\n        assert (len(test_predictions) == len(edge_ids_test))\n        assert (test_predictions.shape[1] == 1)\n        test_predictions = ens.predict(test_gen, summarise=False)\n        assert (test_predictions.shape[0] == ens.n_estimators)\n        assert (test_predictions.shape[1] == ens.n_predictions)\n        assert (test_predictions.shape[2] == len(edge_ids_test))\n        assert (test_predictions.shape[3] == 1)\n        ens = BaggingEnsemble(keras_model, n_estimators=2, n_predictions=1)\n        ens.compile(optimizer=Adam(), loss=binary_crossentropy, weighted_metrics=['acc'])\n        test_gen = generator.flow(edge_ids_test)\n        with pytest.raises(ValueError):\n            ens.predict(generator=test_gen, predict_data=edge_ids_test)\n        test_predictions = ens.predict(test_gen, summarise=True)\n        print('test_predictions shape {}'.format(test_predictions.shape))\n        assert (len(test_predictions) == len(edge_ids_test))\n        assert (test_predictions.shape[1] == 1)\n        test_predictions = ens.predict(test_gen, summarise=False)\n        assert (test_predictions.shape[0] == ens.n_estimators)\n        assert (test_predictions.shape[1] == ens.n_predictions)\n        assert (test_predictions.shape[2] == len(edge_ids_test))\n        assert (test_predictions.shape[3] == 1)", "masked_code": "def test_predict_link_prediction():\n    tf.keras.backend.clear_session()\n    edge_ids_test = np.array([[1, 2], [2, 3], [1, 3]])\n    graph = example_graph_1(feature_size=2)\n    gnn_models = [create_graphSAGE_model(graph, link_prediction=True), create_HinSAGE_model(graph, link_prediction=True)]\n    for gnn_model in gnn_models:\n        keras_model = gnn_model[1]\n        generator = gnn_model[2]\n        ens = Ensemble(keras_model, n_estimators=2, n_predictions=1)\n        ens.compile(optimizer=Adam(), loss=binary_crossentropy, weighted_metrics=['acc'])\n        test_gen = generator.flow(edge_ids_test)\n        with pytest.raises(ValueError):\n            ens.predict(generator=test_gen, predict_data=edge_ids_test)\n        test_predictions = ens.predict(test_gen, summarise=True)\n        print('test_predictions shape {}'.format(test_predictions.shape))\n        assert (len(test_predictions) == len(edge_ids_test))\n        assert (test_predictions.shape[1] == 1)\n        test_predictions = ens.predict(test_gen, summarise=False)\n        assert (test_predictions.shape[0] == ens.n_estimators)\n        assert (test_predictions.shape[1] == ens.n_predictions)\n        assert (test_predictions.shape[2] == len(edge_ids_test))\n        assert (test_predictions.shape[3] == 1)\n        ens = BaggingEnsemble(keras_model, n_estimators=2, n_predictions=1)\n        ens.compile(optimizer=Adam(), loss=binary_crossentropy, weighted_metrics=['acc'])\n        test_gen = generator.flow(edge_ids_test)\n        with pytest.raises(ValueError):\n            ens.predict(generator=test_gen, predict_data=edge_ids_test)\n        test_predictions = ens.predict(test_gen, summarise=True)\n        print('test_predictions shape {}'.format(test_predictions.shape))\n        assert (len(test_predictions) == len(edge_ids_test))\n        assert (test_predictions.shape[1] == 1)\n        test_predictions = ens.predict(test_gen, summarise=False)\n        assert (test_predictions.shape[0] == ens.n_estimators)\n        assert (test_predictions.shape[1] == ens.n_predictions)\n        assert (test_predictions.shape[2] == '???')\n        assert (test_predictions.shape[3] == 1)", "ground_truth": "len(edge_ids_test)", "quality_analysis": {"complexity_score": 10, "left_complexity": 6, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_42", "reponame": "stellargraph", "testpath": "tests/test_losses.py", "testname": "test_losses.py", "classname": null, "funcname": "test_self_adversarial_negative_sampling", "imports": ["from stellargraph.losses import *", "import numpy as np", "import pytest", "import tensorflow as tf", "from scipy.special import softmax, expit"], "code": "@pytest.mark.parametrize('temperature', [0.0, 0.5, 1.0, 2.0])\ndef test_self_adversarial_negative_sampling(temperature):\n    labels = np.array([1, 0, (- 2), 0, 1], dtype=np.int32)\n    logit_scores = np.array([1.2, (- 2.3), 0.0, 4.5, (- 0.67)], dtype=np.float32)\n    scores = expit(logit_scores)\n    loss_func = SelfAdversarialNegativeSampling(temperature)\n    actual_loss = loss_func(tf.constant(labels), tf.constant(logit_scores))\n\n    def loss_part(score, label):\n        if (label == 1):\n            return (- np.log(score))\n        relevant = scores[np.where((labels == label))]\n        numer = np.exp((temperature * score))\n        denom = np.sum(np.exp((temperature * relevant)))\n        return (((- np.log((1 - score))) * numer) / denom)\n    expected_loss = np.mean([loss_part(score, label) for (score, label) in zip(scores, labels)])\n    assert (actual_loss.numpy() == pytest.approx(expected_loss, rel=1e-06))", "masked_code": "@pytest.mark.parametrize('temperature', [0.0, 0.5, 1.0, 2.0])\ndef test_self_adversarial_negative_sampling(temperature):\n    labels = np.array([1, 0, (- 2), 0, 1], dtype=np.int32)\n    logit_scores = np.array([1.2, (- 2.3), 0.0, 4.5, (- 0.67)], dtype=np.float32)\n    scores = expit(logit_scores)\n    loss_func = SelfAdversarialNegativeSampling(temperature)\n    actual_loss = loss_func(tf.constant(labels), tf.constant(logit_scores))\n\n    def loss_part(score, label):\n        if (label == 1):\n            return (- np.log(score))\n        relevant = scores[np.where((labels == label))]\n        numer = np.exp((temperature * score))\n        denom = np.sum(np.exp((temperature * relevant)))\n        return (((- np.log((1 - score))) * numer) / denom)\n    expected_loss = np.mean([loss_part(score, label) for (score, label) in zip(scores, labels)])\n    assert (actual_loss.numpy() == '???')", "ground_truth": "pytest.approx(expected_loss, rel=1e-06)", "quality_analysis": {"complexity_score": 7, "left_complexity": 3, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_43", "reponame": "stellargraph", "testpath": "tests/core/test_convert.py", "testname": "test_convert.py", "classname": null, "funcname": "test_columnar_convert_type_column", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "from stellargraph.core.convert import ColumnarConverter, convert_nodes, convert_edges, from_networkx", "from stellargraph.core.indexed_array import IndexedArray"], "code": "def test_columnar_convert_type_column():\n    converter = ColumnarConverter(name='some_name', default_type='foo', type_column='type_column', column_defaults={}, selected_columns={'type_column': 'TC', 'data': 'D'}, transform_columns={})\n    df = pd.DataFrame({'type_column': ['c', 'a', 'a', 'c', 'b'], 'data': [1, 2, 3, 4, 5]}, index=[1, 10, 100, 1000, 10000])\n    (ids, columns, type_info) = converter.convert(df)\n    assert (columns.keys() == {'D'})\n    np.testing.assert_array_equal(ids, [10, 100, 10000, 1, 1000])\n    np.testing.assert_array_equal(columns['D'], [2, 3, 5, 1, 4])\n    _check_type_info(type_info, [('a', _empty_array(2)), ('b', _empty_array(1)), ('c', _empty_array(2))])\n    with pytest.raises(ValueError, match=\"selected_columns: expected type column \\\\('type_column'\\\\) .* found only 'TC', 'data'\"):\n        ColumnarConverter(name='some_name', default_type='foo', type_column='type_column', column_defaults={}, selected_columns={'TC': 'type_column', 'data': 'D'}, transform_columns={})", "masked_code": "def test_columnar_convert_type_column():\n    converter = ColumnarConverter(name='some_name', default_type='foo', type_column='type_column', column_defaults={}, selected_columns={'type_column': 'TC', 'data': 'D'}, transform_columns={})\n    df = pd.DataFrame({'type_column': ['c', 'a', 'a', 'c', 'b'], 'data': [1, 2, 3, 4, 5]}, index=[1, 10, 100, 1000, 10000])\n    (ids, columns, type_info) = converter.convert(df)\n    assert (columns.keys() == '???')\n    np.testing.assert_array_equal(ids, [10, 100, 10000, 1, 1000])\n    np.testing.assert_array_equal(columns['D'], [2, 3, 5, 1, 4])\n    _check_type_info(type_info, [('a', _empty_array(2)), ('b', _empty_array(1)), ('c', _empty_array(2))])\n    with pytest.raises(ValueError, match=\"selected_columns: expected type column \\\\('type_column'\\\\) .* found only 'TC', 'data'\"):\n        ColumnarConverter(name='some_name', default_type='foo', type_column='type_column', column_defaults={}, selected_columns={'TC': 'type_column', 'data': 'D'}, transform_columns={})", "ground_truth": "{'D'}", "quality_analysis": {"complexity_score": 3, "left_complexity": 3, "right_complexity": 0, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_44", "reponame": "stellargraph", "testpath": "tests/core/test_convert.py", "testname": "test_convert.py", "classname": null, "funcname": "test_columnar_convert_transform_columns", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "from stellargraph.core.convert import ColumnarConverter, convert_nodes, convert_edges, from_networkx", "from stellargraph.core.indexed_array import IndexedArray"], "code": "def test_columnar_convert_transform_columns():\n    columns = {'x': np.complex128(1), 'y': np.uint16(2), 'z': np.float32(3.0)}\n    dfs = {name: pd.DataFrame({'s': [0], 't': [1], 'w': [w]}, index=[i]) for (i, (name, w)) in enumerate(columns.items())}\n    converter = ColumnarConverter(name='some_name', default_type='foo', type_column=None, column_defaults={}, selected_columns={'s': 'ss', 't': 'tt', 'w': 'ww'}, transform_columns={'w': (lambda x: (x + 1))})\n    (ids, columns, type_info) = converter.convert(dfs)\n    assert (columns['ww'][0] == 2)\n    assert (columns['ww'][1] == 3)\n    assert (columns['ww'][2] == 4)\n    _check_type_info(type_info, [('x', _empty_array(1)), ('y', _empty_array(1)), ('z', _empty_array(1))])\n    np.testing.assert_array_equal(columns['ss'], 0)\n    np.testing.assert_array_equal(columns['tt'], 1)", "masked_code": "def test_columnar_convert_transform_columns():\n    columns = {'x': np.complex128(1), 'y': np.uint16(2), 'z': np.float32(3.0)}\n    dfs = {name: pd.DataFrame({'s': [0], 't': [1], 'w': [w]}, index=[i]) for (i, (name, w)) in enumerate(columns.items())}\n    converter = ColumnarConverter(name='some_name', default_type='foo', type_column=None, column_defaults={}, selected_columns={'s': 'ss', 't': 'tt', 'w': 'ww'}, transform_columns={'w': (lambda x: (x + 1))})\n    (ids, columns, type_info) = converter.convert(dfs)\n    assert (columns['ww'][0] == 2)\n    assert (columns['ww'][1] == '???')\n    assert (columns['ww'][2] == 4)\n    _check_type_info(type_info, [('x', _empty_array(1)), ('y', _empty_array(1)), ('z', _empty_array(1))])\n    np.testing.assert_array_equal(columns['ss'], 0)\n    np.testing.assert_array_equal(columns['tt'], 1)", "ground_truth": "3", "quality_analysis": {"complexity_score": 10, "left_complexity": 9, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_45", "reponame": "stellargraph", "testpath": "tests/core/test_convert.py", "testname": "test_convert.py", "classname": null, "funcname": "test_columnar_convert_transform_columns", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "from stellargraph.core.convert import ColumnarConverter, convert_nodes, convert_edges, from_networkx", "from stellargraph.core.indexed_array import IndexedArray"], "code": "def test_columnar_convert_transform_columns():\n    columns = {'x': np.complex128(1), 'y': np.uint16(2), 'z': np.float32(3.0)}\n    dfs = {name: pd.DataFrame({'s': [0], 't': [1], 'w': [w]}, index=[i]) for (i, (name, w)) in enumerate(columns.items())}\n    converter = ColumnarConverter(name='some_name', default_type='foo', type_column=None, column_defaults={}, selected_columns={'s': 'ss', 't': 'tt', 'w': 'ww'}, transform_columns={'w': (lambda x: (x + 1))})\n    (ids, columns, type_info) = converter.convert(dfs)\n    assert (columns['ww'][0] == 2)\n    assert (columns['ww'][1] == 3)\n    assert (columns['ww'][2] == 4)\n    _check_type_info(type_info, [('x', _empty_array(1)), ('y', _empty_array(1)), ('z', _empty_array(1))])\n    np.testing.assert_array_equal(columns['ss'], 0)\n    np.testing.assert_array_equal(columns['tt'], 1)", "masked_code": "def test_columnar_convert_transform_columns():\n    columns = {'x': np.complex128(1), 'y': np.uint16(2), 'z': np.float32(3.0)}\n    dfs = {name: pd.DataFrame({'s': [0], 't': [1], 'w': [w]}, index=[i]) for (i, (name, w)) in enumerate(columns.items())}\n    converter = ColumnarConverter(name='some_name', default_type='foo', type_column=None, column_defaults={}, selected_columns={'s': 'ss', 't': 'tt', 'w': 'ww'}, transform_columns={'w': (lambda x: (x + 1))})\n    (ids, columns, type_info) = converter.convert(dfs)\n    assert (columns['ww'][0] == 2)\n    assert (columns['ww'][1] == 3)\n    assert (columns['ww'][2] == '???')\n    _check_type_info(type_info, [('x', _empty_array(1)), ('y', _empty_array(1)), ('z', _empty_array(1))])\n    np.testing.assert_array_equal(columns['ss'], 0)\n    np.testing.assert_array_equal(columns['tt'], 1)", "ground_truth": "4", "quality_analysis": {"complexity_score": 10, "left_complexity": 9, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_46", "reponame": "stellargraph", "testpath": "tests/core/test_element_data.py", "testname": "test_element_data.py", "classname": null, "funcname": "test_external_id_index_to_iloc", "imports": ["import pytest", "import numpy as np", "from stellargraph.core.element_data import ExternalIdIndex"], "code": "@pytest.mark.parametrize('count,expected_missing', [(0, 255), (255, 255), (256, 65535), (65535, 65535), (65536, 4294967295)])\ndef test_external_id_index_to_iloc(count, expected_missing):\n    values = [f'id{x}' for x in range(count)]\n    idx = ExternalIdIndex(values)\n    all_ilocs = idx.to_iloc(values)\n    assert (all_ilocs == list(range(count))).all()\n    assert (all_ilocs < expected_missing).all()\n    if (count <= 256):\n        for (i, x) in enumerate(values):\n            np.testing.assert_array_equal(idx.to_iloc([x]), [i])\n    assert (idx.to_iloc(['A']) == expected_missing)", "masked_code": "@pytest.mark.parametrize('count,expected_missing', [(0, 255), (255, 255), (256, 65535), (65535, 65535), (65536, 4294967295)])\ndef test_external_id_index_to_iloc(count, expected_missing):\n    values = [f'id{x}' for x in range(count)]\n    idx = ExternalIdIndex(values)\n    all_ilocs = idx.to_iloc(values)\n    assert (all_ilocs == list(range(count))).all()\n    assert (all_ilocs < expected_missing).all()\n    if (count <= 256):\n        for (i, x) in enumerate(values):\n            np.testing.assert_array_equal(idx.to_iloc([x]), [i])\n    assert (idx.to_iloc(['A']) == '???')", "ground_truth": "expected_missing", "quality_analysis": {"complexity_score": 7, "left_complexity": 6, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_47", "reponame": "stellargraph", "testpath": "tests/core/test_experimental.py", "testname": "test_experimental.py", "classname": null, "funcname": "test_experimental_class", "imports": ["import pytest", "import random", "from stellargraph.core.experimental import experimental, ExperimentalWarning"], "code": "def test_experimental_class(args, kwargs):\n    with pytest.warns(ExperimentalWarning, match='^ClassNoInit is experimental: class is experimental\\\\.'):\n        ClassNoInit()\n    with pytest.warns(ExperimentalWarning, match='^ClassInit is experimental: class is experimental\\\\.'):\n        instance = ClassInit(*args, **kwargs)\n    assert (instance.args == args)\n    assert (instance.kwargs == kwargs)", "masked_code": "def test_experimental_class(args, kwargs):\n    with pytest.warns(ExperimentalWarning, match='^ClassNoInit is experimental: class is experimental\\\\.'):\n        ClassNoInit()\n    with pytest.warns(ExperimentalWarning, match='^ClassInit is experimental: class is experimental\\\\.'):\n        instance = ClassInit(*args, **kwargs)\n    assert (instance.args == '???')\n    assert (instance.kwargs == kwargs)", "ground_truth": "args", "quality_analysis": {"complexity_score": 3, "left_complexity": 2, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_48", "reponame": "stellargraph", "testpath": "tests/core/test_experimental.py", "testname": "test_experimental.py", "classname": null, "funcname": "test_experimental_class", "imports": ["import pytest", "import random", "from stellargraph.core.experimental import experimental, ExperimentalWarning"], "code": "def test_experimental_class(args, kwargs):\n    with pytest.warns(ExperimentalWarning, match='^ClassNoInit is experimental: class is experimental\\\\.'):\n        ClassNoInit()\n    with pytest.warns(ExperimentalWarning, match='^ClassInit is experimental: class is experimental\\\\.'):\n        instance = ClassInit(*args, **kwargs)\n    assert (instance.args == args)\n    assert (instance.kwargs == kwargs)", "masked_code": "def test_experimental_class(args, kwargs):\n    with pytest.warns(ExperimentalWarning, match='^ClassNoInit is experimental: class is experimental\\\\.'):\n        ClassNoInit()\n    with pytest.warns(ExperimentalWarning, match='^ClassInit is experimental: class is experimental\\\\.'):\n        instance = ClassInit(*args, **kwargs)\n    assert (instance.args == args)\n    assert (instance.kwargs == '???')", "ground_truth": "kwargs", "quality_analysis": {"complexity_score": 3, "left_complexity": 2, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_49", "reponame": "stellargraph", "testpath": "tests/core/test_experimental.py", "testname": "test_experimental.py", "classname": null, "funcname": "test_experimental_method", "imports": ["import pytest", "import random", "from stellargraph.core.experimental import experimental, ExperimentalWarning"], "code": "def test_experimental_method(args, kwargs):\n    instance = Class()\n    with pytest.warns(ExperimentalWarning, match='^Class\\\\.method is experimental: method is experimental\\\\.'):\n        ret = instance.method(*args, **kwargs)\n    assert (ret[0] is instance)\n    assert (ret[1:] == (args, kwargs))", "masked_code": "def test_experimental_method(args, kwargs):\n    instance = Class()\n    with pytest.warns(ExperimentalWarning, match='^Class\\\\.method is experimental: method is experimental\\\\.'):\n        ret = instance.method(*args, **kwargs)\n    assert (ret[0] is instance)\n    assert (ret[1:] == '???')", "ground_truth": "(args, kwargs)", "quality_analysis": {"complexity_score": 8, "left_complexity": 4, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_50", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_graph_constructor_nodes_from_edges", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "def test_graph_constructor_nodes_from_edges():\n    edges = {'a': pd.DataFrame({'source': [1], 'target': [0]}, index=[0]), 'b': pd.DataFrame({'source': [4, 5], 'target': [0, 2]}, index=[1, 2])}\n    g = StellarGraph(edges=edges, node_type_default='abc')\n    assert (g.node_types == {'abc'})\n    assert (sorted(g.nodes()) == [0, 1, 2, 4, 5])\n    with pytest.raises(TypeError, match='edges: expected dict, found int'):\n        StellarGraph(edges=1)\n    with pytest.raises(TypeError, match='edges.*: expected IndexedArray or pandas DataFrame, found int'):\n        StellarGraph(edges={'a': 1})\n    with pytest.raises(ValueError, match=\"edges.*: expected 'source', 'target', 'weight' columns, found: 'x'\"):\n        StellarGraph(edges=pd.DataFrame(columns=['x']))", "masked_code": "def test_graph_constructor_nodes_from_edges():\n    edges = {'a': pd.DataFrame({'source': [1], 'target': [0]}, index=[0]), 'b': pd.DataFrame({'source': [4, 5], 'target': [0, 2]}, index=[1, 2])}\n    g = StellarGraph(edges=edges, node_type_default='abc')\n    assert (g.node_types == '???')\n    assert (sorted(g.nodes()) == [0, 1, 2, 4, 5])\n    with pytest.raises(TypeError, match='edges: expected dict, found int'):\n        StellarGraph(edges=1)\n    with pytest.raises(TypeError, match='edges.*: expected IndexedArray or pandas DataFrame, found int'):\n        StellarGraph(edges={'a': 1})\n    with pytest.raises(ValueError, match=\"edges.*: expected 'source', 'target', 'weight' columns, found: 'x'\"):\n        StellarGraph(edges=pd.DataFrame(columns=['x']))", "ground_truth": "{'abc'}", "quality_analysis": {"complexity_score": 2, "left_complexity": 2, "right_complexity": 0, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_51", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_graph_constructor_nodes_from_edges", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "def test_graph_constructor_nodes_from_edges():\n    edges = {'a': pd.DataFrame({'source': [1], 'target': [0]}, index=[0]), 'b': pd.DataFrame({'source': [4, 5], 'target': [0, 2]}, index=[1, 2])}\n    g = StellarGraph(edges=edges, node_type_default='abc')\n    assert (g.node_types == {'abc'})\n    assert (sorted(g.nodes()) == [0, 1, 2, 4, 5])\n    with pytest.raises(TypeError, match='edges: expected dict, found int'):\n        StellarGraph(edges=1)\n    with pytest.raises(TypeError, match='edges.*: expected IndexedArray or pandas DataFrame, found int'):\n        StellarGraph(edges={'a': 1})\n    with pytest.raises(ValueError, match=\"edges.*: expected 'source', 'target', 'weight' columns, found: 'x'\"):\n        StellarGraph(edges=pd.DataFrame(columns=['x']))", "masked_code": "def test_graph_constructor_nodes_from_edges():\n    edges = {'a': pd.DataFrame({'source': [1], 'target': [0]}, index=[0]), 'b': pd.DataFrame({'source': [4, 5], 'target': [0, 2]}, index=[1, 2])}\n    g = StellarGraph(edges=edges, node_type_default='abc')\n    assert (g.node_types == {'abc'})\n    assert (sorted(g.nodes()) == '???')\n    with pytest.raises(TypeError, match='edges: expected dict, found int'):\n        StellarGraph(edges=1)\n    with pytest.raises(TypeError, match='edges.*: expected IndexedArray or pandas DataFrame, found int'):\n        StellarGraph(edges={'a': 1})\n    with pytest.raises(ValueError, match=\"edges.*: expected 'source', 'target', 'weight' columns, found: 'x'\"):\n        StellarGraph(edges=pd.DataFrame(columns=['x']))", "ground_truth": "[0, 1, 2, 4, 5]", "quality_analysis": {"complexity_score": 13, "left_complexity": 6, "right_complexity": 7, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_52", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_graph_constructor_edge_labels", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "def test_graph_constructor_edge_labels():\n    edges = pd.DataFrame({'source': [4, 1, 5], 'target': [0, 0, 2], 'ET': ['b', 'a', 'b']})\n    g = StellarGraph(edges=edges, edge_type_column='ET')\n    assert (sorted(g.edges(include_edge_type=True)) == [(1, 0, 'a'), (4, 0, 'b'), (5, 2, 'b')])", "masked_code": "def test_graph_constructor_edge_labels():\n    edges = pd.DataFrame({'source': [4, 1, 5], 'target': [0, 0, 2], 'ET': ['b', 'a', 'b']})\n    g = StellarGraph(edges=edges, edge_type_column='ET')\n    assert (sorted(g.edges(include_edge_type=True)) == '???')", "ground_truth": "[(1, 0, 'a'), (4, 0, 'b'), (5, 2, 'b')]", "quality_analysis": {"complexity_score": 23, "left_complexity": 6, "right_complexity": 17, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_53", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_graph_constructor_internal", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "def test_graph_constructor_internal():\n    orig = example_graph_random(node_types=3, edge_types=3, is_directed=True)\n    undir_g = StellarGraph(orig._nodes, orig._edges)\n    dir_g = StellarDiGraph(orig._nodes, orig._edges)\n    assert (not undir_g.is_directed())\n    assert dir_g.is_directed()\n    for g in [undir_g, dir_g]:\n        assert (g.node_types == orig.node_types)\n        for t in orig.node_types:\n            np.testing.assert_array_equal(g.node_features(node_type=t), orig.node_features(node_type=t))\n        assert (g.edges(include_edge_type=True) == orig.edges(include_edge_type=True))\n    with pytest.raises(TypeError, match=\"edges: expected type 'EdgeData' .* found dict\"):\n        StellarGraph(orig._nodes, {})\n    with pytest.raises(TypeError, match=\"nodes: expected type 'NodeData' .* found DataFrame\"):\n        StellarGraph(pd.DataFrame(index=[0]), orig._edges)\n    non_default = ['source_column', 'target_column', 'edge_weight_column', 'node_type_default', 'edge_type_default', 'edge_type_column', 'dtype']\n    unchecked = {'is_directed', 'graph', 'node_type_name', 'edge_type_name', 'node_features'}\n    assert (set(non_default) == (set(StellarGraph.__init__.__kwdefaults__) - unchecked))\n    for param in non_default:\n        with pytest.raises(ValueError, match=f'{param}: expected the default value .* found <object'):\n            StellarGraph(orig._nodes, orig._edges, **{param: object()})", "masked_code": "def test_graph_constructor_internal():\n    orig = example_graph_random(node_types=3, edge_types=3, is_directed=True)\n    undir_g = StellarGraph(orig._nodes, orig._edges)\n    dir_g = StellarDiGraph(orig._nodes, orig._edges)\n    assert (not undir_g.is_directed())\n    assert dir_g.is_directed()\n    for g in [undir_g, dir_g]:\n        assert (g.node_types == orig.node_types)\n        for t in orig.node_types:\n            np.testing.assert_array_equal(g.node_features(node_type=t), orig.node_features(node_type=t))\n        assert (g.edges(include_edge_type=True) == orig.edges(include_edge_type=True))\n    with pytest.raises(TypeError, match=\"edges: expected type 'EdgeData' .* found dict\"):\n        StellarGraph(orig._nodes, {})\n    with pytest.raises(TypeError, match=\"nodes: expected type 'NodeData' .* found DataFrame\"):\n        StellarGraph(pd.DataFrame(index=[0]), orig._edges)\n    non_default = ['source_column', 'target_column', 'edge_weight_column', 'node_type_default', 'edge_type_default', 'edge_type_column', 'dtype']\n    unchecked = {'is_directed', 'graph', 'node_type_name', 'edge_type_name', 'node_features'}\n    assert (set(non_default) == '???')\n    for param in non_default:\n        with pytest.raises(ValueError, match=f'{param}: expected the default value .* found <object'):\n            StellarGraph(orig._nodes, orig._edges, **{param: object()})", "ground_truth": "(set(StellarGraph.__init__.__kwdefaults__) - unchecked)", "quality_analysis": {"complexity_score": 12, "left_complexity": 4, "right_complexity": 8, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_54", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_graph_constructor_internal", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "def test_graph_constructor_internal():\n    orig = example_graph_random(node_types=3, edge_types=3, is_directed=True)\n    undir_g = StellarGraph(orig._nodes, orig._edges)\n    dir_g = StellarDiGraph(orig._nodes, orig._edges)\n    assert (not undir_g.is_directed())\n    assert dir_g.is_directed()\n    for g in [undir_g, dir_g]:\n        assert (g.node_types == orig.node_types)\n        for t in orig.node_types:\n            np.testing.assert_array_equal(g.node_features(node_type=t), orig.node_features(node_type=t))\n        assert (g.edges(include_edge_type=True) == orig.edges(include_edge_type=True))\n    with pytest.raises(TypeError, match=\"edges: expected type 'EdgeData' .* found dict\"):\n        StellarGraph(orig._nodes, {})\n    with pytest.raises(TypeError, match=\"nodes: expected type 'NodeData' .* found DataFrame\"):\n        StellarGraph(pd.DataFrame(index=[0]), orig._edges)\n    non_default = ['source_column', 'target_column', 'edge_weight_column', 'node_type_default', 'edge_type_default', 'edge_type_column', 'dtype']\n    unchecked = {'is_directed', 'graph', 'node_type_name', 'edge_type_name', 'node_features'}\n    assert (set(non_default) == (set(StellarGraph.__init__.__kwdefaults__) - unchecked))\n    for param in non_default:\n        with pytest.raises(ValueError, match=f'{param}: expected the default value .* found <object'):\n            StellarGraph(orig._nodes, orig._edges, **{param: object()})", "masked_code": "def test_graph_constructor_internal():\n    orig = example_graph_random(node_types=3, edge_types=3, is_directed=True)\n    undir_g = StellarGraph(orig._nodes, orig._edges)\n    dir_g = StellarDiGraph(orig._nodes, orig._edges)\n    assert (not undir_g.is_directed())\n    assert dir_g.is_directed()\n    for g in [undir_g, dir_g]:\n        assert (g.node_types == '???')\n        for t in orig.node_types:\n            np.testing.assert_array_equal(g.node_features(node_type=t), orig.node_features(node_type=t))\n        assert (g.edges(include_edge_type=True) == orig.edges(include_edge_type=True))\n    with pytest.raises(TypeError, match=\"edges: expected type 'EdgeData' .* found dict\"):\n        StellarGraph(orig._nodes, {})\n    with pytest.raises(TypeError, match=\"nodes: expected type 'NodeData' .* found DataFrame\"):\n        StellarGraph(pd.DataFrame(index=[0]), orig._edges)\n    non_default = ['source_column', 'target_column', 'edge_weight_column', 'node_type_default', 'edge_type_default', 'edge_type_column', 'dtype']\n    unchecked = {'is_directed', 'graph', 'node_type_name', 'edge_type_name', 'node_features'}\n    assert (set(non_default) == (set(StellarGraph.__init__.__kwdefaults__) - unchecked))\n    for param in non_default:\n        with pytest.raises(ValueError, match=f'{param}: expected the default value .* found <object'):\n            StellarGraph(orig._nodes, orig._edges, **{param: object()})", "ground_truth": "orig.node_types", "quality_analysis": {"complexity_score": 4, "left_complexity": 2, "right_complexity": 2, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_55", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_graph_constructor_internal", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "def test_graph_constructor_internal():\n    orig = example_graph_random(node_types=3, edge_types=3, is_directed=True)\n    undir_g = StellarGraph(orig._nodes, orig._edges)\n    dir_g = StellarDiGraph(orig._nodes, orig._edges)\n    assert (not undir_g.is_directed())\n    assert dir_g.is_directed()\n    for g in [undir_g, dir_g]:\n        assert (g.node_types == orig.node_types)\n        for t in orig.node_types:\n            np.testing.assert_array_equal(g.node_features(node_type=t), orig.node_features(node_type=t))\n        assert (g.edges(include_edge_type=True) == orig.edges(include_edge_type=True))\n    with pytest.raises(TypeError, match=\"edges: expected type 'EdgeData' .* found dict\"):\n        StellarGraph(orig._nodes, {})\n    with pytest.raises(TypeError, match=\"nodes: expected type 'NodeData' .* found DataFrame\"):\n        StellarGraph(pd.DataFrame(index=[0]), orig._edges)\n    non_default = ['source_column', 'target_column', 'edge_weight_column', 'node_type_default', 'edge_type_default', 'edge_type_column', 'dtype']\n    unchecked = {'is_directed', 'graph', 'node_type_name', 'edge_type_name', 'node_features'}\n    assert (set(non_default) == (set(StellarGraph.__init__.__kwdefaults__) - unchecked))\n    for param in non_default:\n        with pytest.raises(ValueError, match=f'{param}: expected the default value .* found <object'):\n            StellarGraph(orig._nodes, orig._edges, **{param: object()})", "masked_code": "def test_graph_constructor_internal():\n    orig = example_graph_random(node_types=3, edge_types=3, is_directed=True)\n    undir_g = StellarGraph(orig._nodes, orig._edges)\n    dir_g = StellarDiGraph(orig._nodes, orig._edges)\n    assert (not undir_g.is_directed())\n    assert dir_g.is_directed()\n    for g in [undir_g, dir_g]:\n        assert (g.node_types == orig.node_types)\n        for t in orig.node_types:\n            np.testing.assert_array_equal(g.node_features(node_type=t), orig.node_features(node_type=t))\n        assert (g.edges(include_edge_type=True) == '???')\n    with pytest.raises(TypeError, match=\"edges: expected type 'EdgeData' .* found dict\"):\n        StellarGraph(orig._nodes, {})\n    with pytest.raises(TypeError, match=\"nodes: expected type 'NodeData' .* found DataFrame\"):\n        StellarGraph(pd.DataFrame(index=[0]), orig._edges)\n    non_default = ['source_column', 'target_column', 'edge_weight_column', 'node_type_default', 'edge_type_default', 'edge_type_column', 'dtype']\n    unchecked = {'is_directed', 'graph', 'node_type_name', 'edge_type_name', 'node_features'}\n    assert (set(non_default) == (set(StellarGraph.__init__.__kwdefaults__) - unchecked))\n    for param in non_default:\n        with pytest.raises(ValueError, match=f'{param}: expected the default value .* found <object'):\n            StellarGraph(orig._nodes, orig._edges, **{param: object()})", "ground_truth": "orig.edges(include_edge_type=True)", "quality_analysis": {"complexity_score": 6, "left_complexity": 3, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_56", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_node_ids_to_ilocs", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "def test_node_ids_to_ilocs():\n    sg = example_graph(feature_size=8)\n    aa = sg.node_ids_to_ilocs([1, 2, 3, 4])\n    assert (list(aa) == [0, 1, 2, 3])\n    sg = example_hin_1(feature_sizes={}, reverse_order=True)\n    aa = sg.node_ids_to_ilocs([0, 1, 2, 3])\n    assert (list(aa) == [3, 2, 1, 0])\n    aa = sg.node_ids_to_ilocs([0, 1, 2, 3])\n    assert (list(aa) == [3, 2, 1, 0])\n    aa = sg.node_ids_to_ilocs([4, 5, 6])\n    assert (list(aa) == [6, 5, 4])\n    aa = sg.node_ids_to_ilocs([4, 5, 6])\n    assert (list(aa) == [6, 5, 4])\n    aa = sg.node_ids_to_ilocs([1, 2, 5])\n    assert (list(aa) == [2, 1, 5])", "masked_code": "def test_node_ids_to_ilocs():\n    sg = example_graph(feature_size=8)\n    aa = sg.node_ids_to_ilocs([1, 2, 3, 4])\n    assert (list(aa) == '???')\n    sg = example_hin_1(feature_sizes={}, reverse_order=True)\n    aa = sg.node_ids_to_ilocs([0, 1, 2, 3])\n    assert (list(aa) == [3, 2, 1, 0])\n    aa = sg.node_ids_to_ilocs([0, 1, 2, 3])\n    assert (list(aa) == [3, 2, 1, 0])\n    aa = sg.node_ids_to_ilocs([4, 5, 6])\n    assert (list(aa) == [6, 5, 4])\n    aa = sg.node_ids_to_ilocs([4, 5, 6])\n    assert (list(aa) == [6, 5, 4])\n    aa = sg.node_ids_to_ilocs([1, 2, 5])\n    assert (list(aa) == [2, 1, 5])", "ground_truth": "[0, 1, 2, 3]", "quality_analysis": {"complexity_score": 10, "left_complexity": 4, "right_complexity": 6, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_57", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_node_ids_to_ilocs", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "def test_node_ids_to_ilocs():\n    sg = example_graph(feature_size=8)\n    aa = sg.node_ids_to_ilocs([1, 2, 3, 4])\n    assert (list(aa) == [0, 1, 2, 3])\n    sg = example_hin_1(feature_sizes={}, reverse_order=True)\n    aa = sg.node_ids_to_ilocs([0, 1, 2, 3])\n    assert (list(aa) == [3, 2, 1, 0])\n    aa = sg.node_ids_to_ilocs([0, 1, 2, 3])\n    assert (list(aa) == [3, 2, 1, 0])\n    aa = sg.node_ids_to_ilocs([4, 5, 6])\n    assert (list(aa) == [6, 5, 4])\n    aa = sg.node_ids_to_ilocs([4, 5, 6])\n    assert (list(aa) == [6, 5, 4])\n    aa = sg.node_ids_to_ilocs([1, 2, 5])\n    assert (list(aa) == [2, 1, 5])", "masked_code": "def test_node_ids_to_ilocs():\n    sg = example_graph(feature_size=8)\n    aa = sg.node_ids_to_ilocs([1, 2, 3, 4])\n    assert (list(aa) == [0, 1, 2, 3])\n    sg = example_hin_1(feature_sizes={}, reverse_order=True)\n    aa = sg.node_ids_to_ilocs([0, 1, 2, 3])\n    assert (list(aa) == '???')\n    aa = sg.node_ids_to_ilocs([0, 1, 2, 3])\n    assert (list(aa) == [3, 2, 1, 0])\n    aa = sg.node_ids_to_ilocs([4, 5, 6])\n    assert (list(aa) == [6, 5, 4])\n    aa = sg.node_ids_to_ilocs([4, 5, 6])\n    assert (list(aa) == [6, 5, 4])\n    aa = sg.node_ids_to_ilocs([1, 2, 5])\n    assert (list(aa) == [2, 1, 5])", "ground_truth": "[3, 2, 1, 0]", "quality_analysis": {"complexity_score": 10, "left_complexity": 4, "right_complexity": 6, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_58", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_node_ids_to_ilocs", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "def test_node_ids_to_ilocs():\n    sg = example_graph(feature_size=8)\n    aa = sg.node_ids_to_ilocs([1, 2, 3, 4])\n    assert (list(aa) == [0, 1, 2, 3])\n    sg = example_hin_1(feature_sizes={}, reverse_order=True)\n    aa = sg.node_ids_to_ilocs([0, 1, 2, 3])\n    assert (list(aa) == [3, 2, 1, 0])\n    aa = sg.node_ids_to_ilocs([0, 1, 2, 3])\n    assert (list(aa) == [3, 2, 1, 0])\n    aa = sg.node_ids_to_ilocs([4, 5, 6])\n    assert (list(aa) == [6, 5, 4])\n    aa = sg.node_ids_to_ilocs([4, 5, 6])\n    assert (list(aa) == [6, 5, 4])\n    aa = sg.node_ids_to_ilocs([1, 2, 5])\n    assert (list(aa) == [2, 1, 5])", "masked_code": "def test_node_ids_to_ilocs():\n    sg = example_graph(feature_size=8)\n    aa = sg.node_ids_to_ilocs([1, 2, 3, 4])\n    assert (list(aa) == [0, 1, 2, 3])\n    sg = example_hin_1(feature_sizes={}, reverse_order=True)\n    aa = sg.node_ids_to_ilocs([0, 1, 2, 3])\n    assert (list(aa) == [3, 2, 1, 0])\n    aa = sg.node_ids_to_ilocs([0, 1, 2, 3])\n    assert (list(aa) == '???')\n    aa = sg.node_ids_to_ilocs([4, 5, 6])\n    assert (list(aa) == [6, 5, 4])\n    aa = sg.node_ids_to_ilocs([4, 5, 6])\n    assert (list(aa) == [6, 5, 4])\n    aa = sg.node_ids_to_ilocs([1, 2, 5])\n    assert (list(aa) == [2, 1, 5])", "ground_truth": "[3, 2, 1, 0]", "quality_analysis": {"complexity_score": 10, "left_complexity": 4, "right_complexity": 6, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_59", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_node_ids_to_ilocs", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "def test_node_ids_to_ilocs():\n    sg = example_graph(feature_size=8)\n    aa = sg.node_ids_to_ilocs([1, 2, 3, 4])\n    assert (list(aa) == [0, 1, 2, 3])\n    sg = example_hin_1(feature_sizes={}, reverse_order=True)\n    aa = sg.node_ids_to_ilocs([0, 1, 2, 3])\n    assert (list(aa) == [3, 2, 1, 0])\n    aa = sg.node_ids_to_ilocs([0, 1, 2, 3])\n    assert (list(aa) == [3, 2, 1, 0])\n    aa = sg.node_ids_to_ilocs([4, 5, 6])\n    assert (list(aa) == [6, 5, 4])\n    aa = sg.node_ids_to_ilocs([4, 5, 6])\n    assert (list(aa) == [6, 5, 4])\n    aa = sg.node_ids_to_ilocs([1, 2, 5])\n    assert (list(aa) == [2, 1, 5])", "masked_code": "def test_node_ids_to_ilocs():\n    sg = example_graph(feature_size=8)\n    aa = sg.node_ids_to_ilocs([1, 2, 3, 4])\n    assert (list(aa) == [0, 1, 2, 3])\n    sg = example_hin_1(feature_sizes={}, reverse_order=True)\n    aa = sg.node_ids_to_ilocs([0, 1, 2, 3])\n    assert (list(aa) == [3, 2, 1, 0])\n    aa = sg.node_ids_to_ilocs([0, 1, 2, 3])\n    assert (list(aa) == [3, 2, 1, 0])\n    aa = sg.node_ids_to_ilocs([4, 5, 6])\n    assert (list(aa) == '???')\n    aa = sg.node_ids_to_ilocs([4, 5, 6])\n    assert (list(aa) == [6, 5, 4])\n    aa = sg.node_ids_to_ilocs([1, 2, 5])\n    assert (list(aa) == [2, 1, 5])", "ground_truth": "[6, 5, 4]", "quality_analysis": {"complexity_score": 9, "left_complexity": 4, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_60", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_node_ids_to_ilocs", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "def test_node_ids_to_ilocs():\n    sg = example_graph(feature_size=8)\n    aa = sg.node_ids_to_ilocs([1, 2, 3, 4])\n    assert (list(aa) == [0, 1, 2, 3])\n    sg = example_hin_1(feature_sizes={}, reverse_order=True)\n    aa = sg.node_ids_to_ilocs([0, 1, 2, 3])\n    assert (list(aa) == [3, 2, 1, 0])\n    aa = sg.node_ids_to_ilocs([0, 1, 2, 3])\n    assert (list(aa) == [3, 2, 1, 0])\n    aa = sg.node_ids_to_ilocs([4, 5, 6])\n    assert (list(aa) == [6, 5, 4])\n    aa = sg.node_ids_to_ilocs([4, 5, 6])\n    assert (list(aa) == [6, 5, 4])\n    aa = sg.node_ids_to_ilocs([1, 2, 5])\n    assert (list(aa) == [2, 1, 5])", "masked_code": "def test_node_ids_to_ilocs():\n    sg = example_graph(feature_size=8)\n    aa = sg.node_ids_to_ilocs([1, 2, 3, 4])\n    assert (list(aa) == [0, 1, 2, 3])\n    sg = example_hin_1(feature_sizes={}, reverse_order=True)\n    aa = sg.node_ids_to_ilocs([0, 1, 2, 3])\n    assert (list(aa) == [3, 2, 1, 0])\n    aa = sg.node_ids_to_ilocs([0, 1, 2, 3])\n    assert (list(aa) == [3, 2, 1, 0])\n    aa = sg.node_ids_to_ilocs([4, 5, 6])\n    assert (list(aa) == [6, 5, 4])\n    aa = sg.node_ids_to_ilocs([4, 5, 6])\n    assert (list(aa) == '???')\n    aa = sg.node_ids_to_ilocs([1, 2, 5])\n    assert (list(aa) == [2, 1, 5])", "ground_truth": "[6, 5, 4]", "quality_analysis": {"complexity_score": 9, "left_complexity": 4, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_61", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_node_ids_to_ilocs", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "def test_node_ids_to_ilocs():\n    sg = example_graph(feature_size=8)\n    aa = sg.node_ids_to_ilocs([1, 2, 3, 4])\n    assert (list(aa) == [0, 1, 2, 3])\n    sg = example_hin_1(feature_sizes={}, reverse_order=True)\n    aa = sg.node_ids_to_ilocs([0, 1, 2, 3])\n    assert (list(aa) == [3, 2, 1, 0])\n    aa = sg.node_ids_to_ilocs([0, 1, 2, 3])\n    assert (list(aa) == [3, 2, 1, 0])\n    aa = sg.node_ids_to_ilocs([4, 5, 6])\n    assert (list(aa) == [6, 5, 4])\n    aa = sg.node_ids_to_ilocs([4, 5, 6])\n    assert (list(aa) == [6, 5, 4])\n    aa = sg.node_ids_to_ilocs([1, 2, 5])\n    assert (list(aa) == [2, 1, 5])", "masked_code": "def test_node_ids_to_ilocs():\n    sg = example_graph(feature_size=8)\n    aa = sg.node_ids_to_ilocs([1, 2, 3, 4])\n    assert (list(aa) == [0, 1, 2, 3])\n    sg = example_hin_1(feature_sizes={}, reverse_order=True)\n    aa = sg.node_ids_to_ilocs([0, 1, 2, 3])\n    assert (list(aa) == [3, 2, 1, 0])\n    aa = sg.node_ids_to_ilocs([0, 1, 2, 3])\n    assert (list(aa) == [3, 2, 1, 0])\n    aa = sg.node_ids_to_ilocs([4, 5, 6])\n    assert (list(aa) == [6, 5, 4])\n    aa = sg.node_ids_to_ilocs([4, 5, 6])\n    assert (list(aa) == [6, 5, 4])\n    aa = sg.node_ids_to_ilocs([1, 2, 5])\n    assert (list(aa) == '???')", "ground_truth": "[2, 1, 5]", "quality_analysis": {"complexity_score": 9, "left_complexity": 4, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_62", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_feature_conversion_from_nodes", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "def test_feature_conversion_from_nodes():\n    sg = example_graph(feature_size=8)\n    aa = sg.node_features([1, 2, 3, 4])\n    assert (aa[(:, 0)] == pytest.approx([1, 2, 3, 4]))\n    assert (aa.shape == (4, 8))\n    assert (sg.node_feature_sizes()['default'] == 8)", "masked_code": "def test_feature_conversion_from_nodes():\n    sg = example_graph(feature_size=8)\n    aa = sg.node_features([1, 2, 3, 4])\n    assert (aa[(:, 0)] == '???')\n    assert (aa.shape == (4, 8))\n    assert (sg.node_feature_sizes()['default'] == 8)", "ground_truth": "pytest.approx([1, 2, 3, 4])", "quality_analysis": {"complexity_score": 16, "left_complexity": 7, "right_complexity": 9, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_63", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_feature_conversion_from_nodes", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "def test_feature_conversion_from_nodes():\n    sg = example_graph(feature_size=8)\n    aa = sg.node_features([1, 2, 3, 4])\n    assert (aa[(:, 0)] == pytest.approx([1, 2, 3, 4]))\n    assert (aa.shape == (4, 8))\n    assert (sg.node_feature_sizes()['default'] == 8)", "masked_code": "def test_feature_conversion_from_nodes():\n    sg = example_graph(feature_size=8)\n    aa = sg.node_features([1, 2, 3, 4])\n    assert (aa[(:, 0)] == pytest.approx([1, 2, 3, 4]))\n    assert (aa.shape == '???')\n    assert (sg.node_feature_sizes()['default'] == 8)", "ground_truth": "(4, 8)", "quality_analysis": {"complexity_score": 6, "left_complexity": 2, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_64", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_feature_conversion_from_nodes", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "def test_feature_conversion_from_nodes():\n    sg = example_graph(feature_size=8)\n    aa = sg.node_features([1, 2, 3, 4])\n    assert (aa[(:, 0)] == pytest.approx([1, 2, 3, 4]))\n    assert (aa.shape == (4, 8))\n    assert (sg.node_feature_sizes()['default'] == 8)", "masked_code": "def test_feature_conversion_from_nodes():\n    sg = example_graph(feature_size=8)\n    aa = sg.node_features([1, 2, 3, 4])\n    assert (aa[(:, 0)] == pytest.approx([1, 2, 3, 4]))\n    assert (aa.shape == (4, 8))\n    assert (sg.node_feature_sizes()['default'] == '???')", "ground_truth": "8", "quality_analysis": {"complexity_score": 8, "left_complexity": 7, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_65", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_node_feature_sizes_shapes", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "def test_node_feature_sizes_shapes():\n    g = example_hin_1(feature_sizes={'A': 4, 'B': (6, 7)})\n    assert (g.node_feature_shapes() == {'A': (4,), 'B': (6, 7)})\n    with pytest.raises(ValueError, match=\"node_feature_sizes expects node types .* found type 'B' with feature shape \\\\(6, 7\\\\)\"):\n        g.node_feature_sizes()\n    assert (g.node_feature_shapes(node_types=['A']) == {'A': (4,)})\n    assert (g.node_feature_sizes(node_types=['A']) == {'A': 4})\n    assert (g.node_feature_shapes(node_types=['B']) == {'B': (6, 7)})\n    with pytest.raises(ValueError, match=\"node_feature_sizes expects node types .* found type 'B' with feature shape \\\\(6, 7\\\\)\"):\n        g.node_feature_sizes(node_types=['B'])", "masked_code": "def test_node_feature_sizes_shapes():\n    g = example_hin_1(feature_sizes={'A': 4, 'B': (6, 7)})\n    assert (g.node_feature_shapes() == '???')\n    with pytest.raises(ValueError, match=\"node_feature_sizes expects node types .* found type 'B' with feature shape \\\\(6, 7\\\\)\"):\n        g.node_feature_sizes()\n    assert (g.node_feature_shapes(node_types=['A']) == {'A': (4,)})\n    assert (g.node_feature_sizes(node_types=['A']) == {'A': 4})\n    assert (g.node_feature_shapes(node_types=['B']) == {'B': (6, 7)})\n    with pytest.raises(ValueError, match=\"node_feature_sizes expects node types .* found type 'B' with feature shape \\\\(6, 7\\\\)\"):\n        g.node_feature_sizes(node_types=['B'])", "ground_truth": "{'A': (4,), 'B': (6, 7)}", "quality_analysis": {"complexity_score": 15, "left_complexity": 3, "right_complexity": 12, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_66", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_node_feature_sizes_shapes", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "def test_node_feature_sizes_shapes():\n    g = example_hin_1(feature_sizes={'A': 4, 'B': (6, 7)})\n    assert (g.node_feature_shapes() == {'A': (4,), 'B': (6, 7)})\n    with pytest.raises(ValueError, match=\"node_feature_sizes expects node types .* found type 'B' with feature shape \\\\(6, 7\\\\)\"):\n        g.node_feature_sizes()\n    assert (g.node_feature_shapes(node_types=['A']) == {'A': (4,)})\n    assert (g.node_feature_sizes(node_types=['A']) == {'A': 4})\n    assert (g.node_feature_shapes(node_types=['B']) == {'B': (6, 7)})\n    with pytest.raises(ValueError, match=\"node_feature_sizes expects node types .* found type 'B' with feature shape \\\\(6, 7\\\\)\"):\n        g.node_feature_sizes(node_types=['B'])", "masked_code": "def test_node_feature_sizes_shapes():\n    g = example_hin_1(feature_sizes={'A': 4, 'B': (6, 7)})\n    assert (g.node_feature_shapes() == {'A': (4,), 'B': (6, 7)})\n    with pytest.raises(ValueError, match=\"node_feature_sizes expects node types .* found type 'B' with feature shape \\\\(6, 7\\\\)\"):\n        g.node_feature_sizes()\n    assert (g.node_feature_shapes(node_types=['A']) == '???')\n    assert (g.node_feature_sizes(node_types=['A']) == {'A': 4})\n    assert (g.node_feature_shapes(node_types=['B']) == {'B': (6, 7)})\n    with pytest.raises(ValueError, match=\"node_feature_sizes expects node types .* found type 'B' with feature shape \\\\(6, 7\\\\)\"):\n        g.node_feature_sizes(node_types=['B'])", "ground_truth": "{'A': (4,)}", "quality_analysis": {"complexity_score": 10, "left_complexity": 3, "right_complexity": 7, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_67", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_node_feature_sizes_shapes", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "def test_node_feature_sizes_shapes():\n    g = example_hin_1(feature_sizes={'A': 4, 'B': (6, 7)})\n    assert (g.node_feature_shapes() == {'A': (4,), 'B': (6, 7)})\n    with pytest.raises(ValueError, match=\"node_feature_sizes expects node types .* found type 'B' with feature shape \\\\(6, 7\\\\)\"):\n        g.node_feature_sizes()\n    assert (g.node_feature_shapes(node_types=['A']) == {'A': (4,)})\n    assert (g.node_feature_sizes(node_types=['A']) == {'A': 4})\n    assert (g.node_feature_shapes(node_types=['B']) == {'B': (6, 7)})\n    with pytest.raises(ValueError, match=\"node_feature_sizes expects node types .* found type 'B' with feature shape \\\\(6, 7\\\\)\"):\n        g.node_feature_sizes(node_types=['B'])", "masked_code": "def test_node_feature_sizes_shapes():\n    g = example_hin_1(feature_sizes={'A': 4, 'B': (6, 7)})\n    assert (g.node_feature_shapes() == {'A': (4,), 'B': (6, 7)})\n    with pytest.raises(ValueError, match=\"node_feature_sizes expects node types .* found type 'B' with feature shape \\\\(6, 7\\\\)\"):\n        g.node_feature_sizes()\n    assert (g.node_feature_shapes(node_types=['A']) == {'A': (4,)})\n    assert (g.node_feature_sizes(node_types=['A']) == '???')\n    assert (g.node_feature_shapes(node_types=['B']) == {'B': (6, 7)})\n    with pytest.raises(ValueError, match=\"node_feature_sizes expects node types .* found type 'B' with feature shape \\\\(6, 7\\\\)\"):\n        g.node_feature_sizes(node_types=['B'])", "ground_truth": "{'A': 4}", "quality_analysis": {"complexity_score": 8, "left_complexity": 3, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_68", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_node_feature_sizes_shapes", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "def test_node_feature_sizes_shapes():\n    g = example_hin_1(feature_sizes={'A': 4, 'B': (6, 7)})\n    assert (g.node_feature_shapes() == {'A': (4,), 'B': (6, 7)})\n    with pytest.raises(ValueError, match=\"node_feature_sizes expects node types .* found type 'B' with feature shape \\\\(6, 7\\\\)\"):\n        g.node_feature_sizes()\n    assert (g.node_feature_shapes(node_types=['A']) == {'A': (4,)})\n    assert (g.node_feature_sizes(node_types=['A']) == {'A': 4})\n    assert (g.node_feature_shapes(node_types=['B']) == {'B': (6, 7)})\n    with pytest.raises(ValueError, match=\"node_feature_sizes expects node types .* found type 'B' with feature shape \\\\(6, 7\\\\)\"):\n        g.node_feature_sizes(node_types=['B'])", "masked_code": "def test_node_feature_sizes_shapes():\n    g = example_hin_1(feature_sizes={'A': 4, 'B': (6, 7)})\n    assert (g.node_feature_shapes() == {'A': (4,), 'B': (6, 7)})\n    with pytest.raises(ValueError, match=\"node_feature_sizes expects node types .* found type 'B' with feature shape \\\\(6, 7\\\\)\"):\n        g.node_feature_sizes()\n    assert (g.node_feature_shapes(node_types=['A']) == {'A': (4,)})\n    assert (g.node_feature_sizes(node_types=['A']) == {'A': 4})\n    assert (g.node_feature_shapes(node_types=['B']) == '???')\n    with pytest.raises(ValueError, match=\"node_feature_sizes expects node types .* found type 'B' with feature shape \\\\(6, 7\\\\)\"):\n        g.node_feature_sizes(node_types=['B'])", "ground_truth": "{'B': (6, 7)}", "quality_analysis": {"complexity_score": 11, "left_complexity": 3, "right_complexity": 8, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_69", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_edge_feature_sizes_shapes", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "def test_edge_feature_sizes_shapes():\n    g = example_hin_1(feature_sizes={'F': 4, 'R': 6}, edge_features=True)\n    assert (g.edge_feature_shapes() == {'F': (4,), 'R': (6,)})\n    assert (g.edge_feature_shapes(edge_types=['F']) == {'F': (4,)})\n    assert (g.edge_feature_sizes(edge_types=['F']) == {'F': 4})\n    assert (g.edge_feature_shapes(edge_types=['R']) == {'R': (6,)})\n    assert (g.edge_feature_sizes(edge_types=['R']) == {'R': 6})", "masked_code": "def test_edge_feature_sizes_shapes():\n    g = example_hin_1(feature_sizes={'F': 4, 'R': 6}, edge_features=True)\n    assert (g.edge_feature_shapes() == '???')\n    assert (g.edge_feature_shapes(edge_types=['F']) == {'F': (4,)})\n    assert (g.edge_feature_sizes(edge_types=['F']) == {'F': 4})\n    assert (g.edge_feature_shapes(edge_types=['R']) == {'R': (6,)})\n    assert (g.edge_feature_sizes(edge_types=['R']) == {'R': 6})", "ground_truth": "{'F': (4,), 'R': (6,)}", "quality_analysis": {"complexity_score": 14, "left_complexity": 3, "right_complexity": 11, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_70", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_edge_feature_sizes_shapes", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "def test_edge_feature_sizes_shapes():\n    g = example_hin_1(feature_sizes={'F': 4, 'R': 6}, edge_features=True)\n    assert (g.edge_feature_shapes() == {'F': (4,), 'R': (6,)})\n    assert (g.edge_feature_shapes(edge_types=['F']) == {'F': (4,)})\n    assert (g.edge_feature_sizes(edge_types=['F']) == {'F': 4})\n    assert (g.edge_feature_shapes(edge_types=['R']) == {'R': (6,)})\n    assert (g.edge_feature_sizes(edge_types=['R']) == {'R': 6})", "masked_code": "def test_edge_feature_sizes_shapes():\n    g = example_hin_1(feature_sizes={'F': 4, 'R': 6}, edge_features=True)\n    assert (g.edge_feature_shapes() == {'F': (4,), 'R': (6,)})\n    assert (g.edge_feature_shapes(edge_types=['F']) == '???')\n    assert (g.edge_feature_sizes(edge_types=['F']) == {'F': 4})\n    assert (g.edge_feature_shapes(edge_types=['R']) == {'R': (6,)})\n    assert (g.edge_feature_sizes(edge_types=['R']) == {'R': 6})", "ground_truth": "{'F': (4,)}", "quality_analysis": {"complexity_score": 10, "left_complexity": 3, "right_complexity": 7, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_71", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_edge_feature_sizes_shapes", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "def test_edge_feature_sizes_shapes():\n    g = example_hin_1(feature_sizes={'F': 4, 'R': 6}, edge_features=True)\n    assert (g.edge_feature_shapes() == {'F': (4,), 'R': (6,)})\n    assert (g.edge_feature_shapes(edge_types=['F']) == {'F': (4,)})\n    assert (g.edge_feature_sizes(edge_types=['F']) == {'F': 4})\n    assert (g.edge_feature_shapes(edge_types=['R']) == {'R': (6,)})\n    assert (g.edge_feature_sizes(edge_types=['R']) == {'R': 6})", "masked_code": "def test_edge_feature_sizes_shapes():\n    g = example_hin_1(feature_sizes={'F': 4, 'R': 6}, edge_features=True)\n    assert (g.edge_feature_shapes() == {'F': (4,), 'R': (6,)})\n    assert (g.edge_feature_shapes(edge_types=['F']) == {'F': (4,)})\n    assert (g.edge_feature_sizes(edge_types=['F']) == '???')\n    assert (g.edge_feature_shapes(edge_types=['R']) == {'R': (6,)})\n    assert (g.edge_feature_sizes(edge_types=['R']) == {'R': 6})", "ground_truth": "{'F': 4}", "quality_analysis": {"complexity_score": 8, "left_complexity": 3, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_72", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_edge_feature_sizes_shapes", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "def test_edge_feature_sizes_shapes():\n    g = example_hin_1(feature_sizes={'F': 4, 'R': 6}, edge_features=True)\n    assert (g.edge_feature_shapes() == {'F': (4,), 'R': (6,)})\n    assert (g.edge_feature_shapes(edge_types=['F']) == {'F': (4,)})\n    assert (g.edge_feature_sizes(edge_types=['F']) == {'F': 4})\n    assert (g.edge_feature_shapes(edge_types=['R']) == {'R': (6,)})\n    assert (g.edge_feature_sizes(edge_types=['R']) == {'R': 6})", "masked_code": "def test_edge_feature_sizes_shapes():\n    g = example_hin_1(feature_sizes={'F': 4, 'R': 6}, edge_features=True)\n    assert (g.edge_feature_shapes() == {'F': (4,), 'R': (6,)})\n    assert (g.edge_feature_shapes(edge_types=['F']) == {'F': (4,)})\n    assert (g.edge_feature_sizes(edge_types=['F']) == {'F': 4})\n    assert (g.edge_feature_shapes(edge_types=['R']) == '???')\n    assert (g.edge_feature_sizes(edge_types=['R']) == {'R': 6})", "ground_truth": "{'R': (6,)}", "quality_analysis": {"complexity_score": 10, "left_complexity": 3, "right_complexity": 7, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_73", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_edge_feature_sizes_shapes", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "def test_edge_feature_sizes_shapes():\n    g = example_hin_1(feature_sizes={'F': 4, 'R': 6}, edge_features=True)\n    assert (g.edge_feature_shapes() == {'F': (4,), 'R': (6,)})\n    assert (g.edge_feature_shapes(edge_types=['F']) == {'F': (4,)})\n    assert (g.edge_feature_sizes(edge_types=['F']) == {'F': 4})\n    assert (g.edge_feature_shapes(edge_types=['R']) == {'R': (6,)})\n    assert (g.edge_feature_sizes(edge_types=['R']) == {'R': 6})", "masked_code": "def test_edge_feature_sizes_shapes():\n    g = example_hin_1(feature_sizes={'F': 4, 'R': 6}, edge_features=True)\n    assert (g.edge_feature_shapes() == {'F': (4,), 'R': (6,)})\n    assert (g.edge_feature_shapes(edge_types=['F']) == {'F': (4,)})\n    assert (g.edge_feature_sizes(edge_types=['F']) == {'F': 4})\n    assert (g.edge_feature_shapes(edge_types=['R']) == {'R': (6,)})\n    assert (g.edge_feature_sizes(edge_types=['R']) == '???')", "ground_truth": "{'R': 6}", "quality_analysis": {"complexity_score": 8, "left_complexity": 3, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_74", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_null_node_feature", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "def test_null_node_feature():\n    sg = example_graph(feature_size=6)\n    aa = sg.node_features([1, None, 2, None])\n    assert (aa.shape == (4, 6))\n    assert (aa[(:, 0)] == pytest.approx([1, 0, 2, 0]))\n    sg = example_hin_1(feature_sizes={'A': 4, 'B': 2}, reverse_order=True)\n    ab = sg.node_features([None, 5, None])\n    assert (ab.shape == (3, 2))\n    assert (ab[(:, 0)] == pytest.approx([0, 5, 0]))\n    ab = sg.node_features([None, 6, None], 'B')\n    assert (ab.shape == (3, 2))\n    assert (ab[(:, 0)] == pytest.approx([0, 6, 0]))\n    with pytest.raises(ValueError):\n        sg.node_features([None, 5, None], 'A')\n    with pytest.raises(ValueError):\n        sg.node_features([None, None])", "masked_code": "def test_null_node_feature():\n    sg = example_graph(feature_size=6)\n    aa = sg.node_features([1, None, 2, None])\n    assert (aa.shape == '???')\n    assert (aa[(:, 0)] == pytest.approx([1, 0, 2, 0]))\n    sg = example_hin_1(feature_sizes={'A': 4, 'B': 2}, reverse_order=True)\n    ab = sg.node_features([None, 5, None])\n    assert (ab.shape == (3, 2))\n    assert (ab[(:, 0)] == pytest.approx([0, 5, 0]))\n    ab = sg.node_features([None, 6, None], 'B')\n    assert (ab.shape == (3, 2))\n    assert (ab[(:, 0)] == pytest.approx([0, 6, 0]))\n    with pytest.raises(ValueError):\n        sg.node_features([None, 5, None], 'A')\n    with pytest.raises(ValueError):\n        sg.node_features([None, None])", "ground_truth": "(4, 6)", "quality_analysis": {"complexity_score": 6, "left_complexity": 2, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_75", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_null_node_feature", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "def test_null_node_feature():\n    sg = example_graph(feature_size=6)\n    aa = sg.node_features([1, None, 2, None])\n    assert (aa.shape == (4, 6))\n    assert (aa[(:, 0)] == pytest.approx([1, 0, 2, 0]))\n    sg = example_hin_1(feature_sizes={'A': 4, 'B': 2}, reverse_order=True)\n    ab = sg.node_features([None, 5, None])\n    assert (ab.shape == (3, 2))\n    assert (ab[(:, 0)] == pytest.approx([0, 5, 0]))\n    ab = sg.node_features([None, 6, None], 'B')\n    assert (ab.shape == (3, 2))\n    assert (ab[(:, 0)] == pytest.approx([0, 6, 0]))\n    with pytest.raises(ValueError):\n        sg.node_features([None, 5, None], 'A')\n    with pytest.raises(ValueError):\n        sg.node_features([None, None])", "masked_code": "def test_null_node_feature():\n    sg = example_graph(feature_size=6)\n    aa = sg.node_features([1, None, 2, None])\n    assert (aa.shape == (4, 6))\n    assert (aa[(:, 0)] == '???')\n    sg = example_hin_1(feature_sizes={'A': 4, 'B': 2}, reverse_order=True)\n    ab = sg.node_features([None, 5, None])\n    assert (ab.shape == (3, 2))\n    assert (ab[(:, 0)] == pytest.approx([0, 5, 0]))\n    ab = sg.node_features([None, 6, None], 'B')\n    assert (ab.shape == (3, 2))\n    assert (ab[(:, 0)] == pytest.approx([0, 6, 0]))\n    with pytest.raises(ValueError):\n        sg.node_features([None, 5, None], 'A')\n    with pytest.raises(ValueError):\n        sg.node_features([None, None])", "ground_truth": "pytest.approx([1, 0, 2, 0])", "quality_analysis": {"complexity_score": 16, "left_complexity": 7, "right_complexity": 9, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_76", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_null_node_feature", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "def test_null_node_feature():\n    sg = example_graph(feature_size=6)\n    aa = sg.node_features([1, None, 2, None])\n    assert (aa.shape == (4, 6))\n    assert (aa[(:, 0)] == pytest.approx([1, 0, 2, 0]))\n    sg = example_hin_1(feature_sizes={'A': 4, 'B': 2}, reverse_order=True)\n    ab = sg.node_features([None, 5, None])\n    assert (ab.shape == (3, 2))\n    assert (ab[(:, 0)] == pytest.approx([0, 5, 0]))\n    ab = sg.node_features([None, 6, None], 'B')\n    assert (ab.shape == (3, 2))\n    assert (ab[(:, 0)] == pytest.approx([0, 6, 0]))\n    with pytest.raises(ValueError):\n        sg.node_features([None, 5, None], 'A')\n    with pytest.raises(ValueError):\n        sg.node_features([None, None])", "masked_code": "def test_null_node_feature():\n    sg = example_graph(feature_size=6)\n    aa = sg.node_features([1, None, 2, None])\n    assert (aa.shape == (4, 6))\n    assert (aa[(:, 0)] == pytest.approx([1, 0, 2, 0]))\n    sg = example_hin_1(feature_sizes={'A': 4, 'B': 2}, reverse_order=True)\n    ab = sg.node_features([None, 5, None])\n    assert (ab.shape == '???')\n    assert (ab[(:, 0)] == pytest.approx([0, 5, 0]))\n    ab = sg.node_features([None, 6, None], 'B')\n    assert (ab.shape == (3, 2))\n    assert (ab[(:, 0)] == pytest.approx([0, 6, 0]))\n    with pytest.raises(ValueError):\n        sg.node_features([None, 5, None], 'A')\n    with pytest.raises(ValueError):\n        sg.node_features([None, None])", "ground_truth": "(3, 2)", "quality_analysis": {"complexity_score": 6, "left_complexity": 2, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_77", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_null_node_feature", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "def test_null_node_feature():\n    sg = example_graph(feature_size=6)\n    aa = sg.node_features([1, None, 2, None])\n    assert (aa.shape == (4, 6))\n    assert (aa[(:, 0)] == pytest.approx([1, 0, 2, 0]))\n    sg = example_hin_1(feature_sizes={'A': 4, 'B': 2}, reverse_order=True)\n    ab = sg.node_features([None, 5, None])\n    assert (ab.shape == (3, 2))\n    assert (ab[(:, 0)] == pytest.approx([0, 5, 0]))\n    ab = sg.node_features([None, 6, None], 'B')\n    assert (ab.shape == (3, 2))\n    assert (ab[(:, 0)] == pytest.approx([0, 6, 0]))\n    with pytest.raises(ValueError):\n        sg.node_features([None, 5, None], 'A')\n    with pytest.raises(ValueError):\n        sg.node_features([None, None])", "masked_code": "def test_null_node_feature():\n    sg = example_graph(feature_size=6)\n    aa = sg.node_features([1, None, 2, None])\n    assert (aa.shape == (4, 6))\n    assert (aa[(:, 0)] == pytest.approx([1, 0, 2, 0]))\n    sg = example_hin_1(feature_sizes={'A': 4, 'B': 2}, reverse_order=True)\n    ab = sg.node_features([None, 5, None])\n    assert (ab.shape == (3, 2))\n    assert (ab[(:, 0)] == '???')\n    ab = sg.node_features([None, 6, None], 'B')\n    assert (ab.shape == (3, 2))\n    assert (ab[(:, 0)] == pytest.approx([0, 6, 0]))\n    with pytest.raises(ValueError):\n        sg.node_features([None, 5, None], 'A')\n    with pytest.raises(ValueError):\n        sg.node_features([None, None])", "ground_truth": "pytest.approx([0, 5, 0])", "quality_analysis": {"complexity_score": 15, "left_complexity": 7, "right_complexity": 8, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_78", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_null_node_feature", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "def test_null_node_feature():\n    sg = example_graph(feature_size=6)\n    aa = sg.node_features([1, None, 2, None])\n    assert (aa.shape == (4, 6))\n    assert (aa[(:, 0)] == pytest.approx([1, 0, 2, 0]))\n    sg = example_hin_1(feature_sizes={'A': 4, 'B': 2}, reverse_order=True)\n    ab = sg.node_features([None, 5, None])\n    assert (ab.shape == (3, 2))\n    assert (ab[(:, 0)] == pytest.approx([0, 5, 0]))\n    ab = sg.node_features([None, 6, None], 'B')\n    assert (ab.shape == (3, 2))\n    assert (ab[(:, 0)] == pytest.approx([0, 6, 0]))\n    with pytest.raises(ValueError):\n        sg.node_features([None, 5, None], 'A')\n    with pytest.raises(ValueError):\n        sg.node_features([None, None])", "masked_code": "def test_null_node_feature():\n    sg = example_graph(feature_size=6)\n    aa = sg.node_features([1, None, 2, None])\n    assert (aa.shape == (4, 6))\n    assert (aa[(:, 0)] == pytest.approx([1, 0, 2, 0]))\n    sg = example_hin_1(feature_sizes={'A': 4, 'B': 2}, reverse_order=True)\n    ab = sg.node_features([None, 5, None])\n    assert (ab.shape == (3, 2))\n    assert (ab[(:, 0)] == pytest.approx([0, 5, 0]))\n    ab = sg.node_features([None, 6, None], 'B')\n    assert (ab.shape == '???')\n    assert (ab[(:, 0)] == pytest.approx([0, 6, 0]))\n    with pytest.raises(ValueError):\n        sg.node_features([None, 5, None], 'A')\n    with pytest.raises(ValueError):\n        sg.node_features([None, None])", "ground_truth": "(3, 2)", "quality_analysis": {"complexity_score": 6, "left_complexity": 2, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_79", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_null_node_feature", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "def test_null_node_feature():\n    sg = example_graph(feature_size=6)\n    aa = sg.node_features([1, None, 2, None])\n    assert (aa.shape == (4, 6))\n    assert (aa[(:, 0)] == pytest.approx([1, 0, 2, 0]))\n    sg = example_hin_1(feature_sizes={'A': 4, 'B': 2}, reverse_order=True)\n    ab = sg.node_features([None, 5, None])\n    assert (ab.shape == (3, 2))\n    assert (ab[(:, 0)] == pytest.approx([0, 5, 0]))\n    ab = sg.node_features([None, 6, None], 'B')\n    assert (ab.shape == (3, 2))\n    assert (ab[(:, 0)] == pytest.approx([0, 6, 0]))\n    with pytest.raises(ValueError):\n        sg.node_features([None, 5, None], 'A')\n    with pytest.raises(ValueError):\n        sg.node_features([None, None])", "masked_code": "def test_null_node_feature():\n    sg = example_graph(feature_size=6)\n    aa = sg.node_features([1, None, 2, None])\n    assert (aa.shape == (4, 6))\n    assert (aa[(:, 0)] == pytest.approx([1, 0, 2, 0]))\n    sg = example_hin_1(feature_sizes={'A': 4, 'B': 2}, reverse_order=True)\n    ab = sg.node_features([None, 5, None])\n    assert (ab.shape == (3, 2))\n    assert (ab[(:, 0)] == pytest.approx([0, 5, 0]))\n    ab = sg.node_features([None, 6, None], 'B')\n    assert (ab.shape == (3, 2))\n    assert (ab[(:, 0)] == '???')\n    with pytest.raises(ValueError):\n        sg.node_features([None, 5, None], 'A')\n    with pytest.raises(ValueError):\n        sg.node_features([None, None])", "ground_truth": "pytest.approx([0, 6, 0])", "quality_analysis": {"complexity_score": 15, "left_complexity": 7, "right_complexity": 8, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_80", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_null_edge_feature", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "def test_null_edge_feature():\n    sg = example_graph(edge_feature_size=6)\n    aa = sg.edge_features([1, None, 2, None])\n    assert (aa.shape == (4, 6))\n    assert (aa[(:, 0)] == pytest.approx([(- 1), 0, (- 2), 0]))\n    sg = example_hin_1(feature_sizes={'F': 4, 'R': 2}, reverse_order=True, edge_features=True)\n    ab = sg.edge_features([None, 4, None])\n    assert (ab.shape == (3, 2))\n    assert (ab[(:, 0)] == pytest.approx([0, (- 4), 0]))\n    ab = sg.edge_features([None, 4, None], 'R')\n    assert (ab.shape == (3, 2))\n    assert (ab[(:, 0)] == pytest.approx([0, (- 4), 0]))\n    with pytest.raises(ValueError):\n        sg.edge_features([None, 4, None], 'F')\n    with pytest.raises(ValueError):\n        sg.edge_features([None, None])", "masked_code": "def test_null_edge_feature():\n    sg = example_graph(edge_feature_size=6)\n    aa = sg.edge_features([1, None, 2, None])\n    assert (aa.shape == '???')\n    assert (aa[(:, 0)] == pytest.approx([(- 1), 0, (- 2), 0]))\n    sg = example_hin_1(feature_sizes={'F': 4, 'R': 2}, reverse_order=True, edge_features=True)\n    ab = sg.edge_features([None, 4, None])\n    assert (ab.shape == (3, 2))\n    assert (ab[(:, 0)] == pytest.approx([0, (- 4), 0]))\n    ab = sg.edge_features([None, 4, None], 'R')\n    assert (ab.shape == (3, 2))\n    assert (ab[(:, 0)] == pytest.approx([0, (- 4), 0]))\n    with pytest.raises(ValueError):\n        sg.edge_features([None, 4, None], 'F')\n    with pytest.raises(ValueError):\n        sg.edge_features([None, None])", "ground_truth": "(4, 6)", "quality_analysis": {"complexity_score": 6, "left_complexity": 2, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_81", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_null_edge_feature", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "def test_null_edge_feature():\n    sg = example_graph(edge_feature_size=6)\n    aa = sg.edge_features([1, None, 2, None])\n    assert (aa.shape == (4, 6))\n    assert (aa[(:, 0)] == pytest.approx([(- 1), 0, (- 2), 0]))\n    sg = example_hin_1(feature_sizes={'F': 4, 'R': 2}, reverse_order=True, edge_features=True)\n    ab = sg.edge_features([None, 4, None])\n    assert (ab.shape == (3, 2))\n    assert (ab[(:, 0)] == pytest.approx([0, (- 4), 0]))\n    ab = sg.edge_features([None, 4, None], 'R')\n    assert (ab.shape == (3, 2))\n    assert (ab[(:, 0)] == pytest.approx([0, (- 4), 0]))\n    with pytest.raises(ValueError):\n        sg.edge_features([None, 4, None], 'F')\n    with pytest.raises(ValueError):\n        sg.edge_features([None, None])", "masked_code": "def test_null_edge_feature():\n    sg = example_graph(edge_feature_size=6)\n    aa = sg.edge_features([1, None, 2, None])\n    assert (aa.shape == (4, 6))\n    assert (aa[(:, 0)] == '???')\n    sg = example_hin_1(feature_sizes={'F': 4, 'R': 2}, reverse_order=True, edge_features=True)\n    ab = sg.edge_features([None, 4, None])\n    assert (ab.shape == (3, 2))\n    assert (ab[(:, 0)] == pytest.approx([0, (- 4), 0]))\n    ab = sg.edge_features([None, 4, None], 'R')\n    assert (ab.shape == (3, 2))\n    assert (ab[(:, 0)] == pytest.approx([0, (- 4), 0]))\n    with pytest.raises(ValueError):\n        sg.edge_features([None, 4, None], 'F')\n    with pytest.raises(ValueError):\n        sg.edge_features([None, None])", "ground_truth": "pytest.approx([(- 1), 0, (- 2), 0])", "quality_analysis": {"complexity_score": 20, "left_complexity": 7, "right_complexity": 13, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_82", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_null_edge_feature", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "def test_null_edge_feature():\n    sg = example_graph(edge_feature_size=6)\n    aa = sg.edge_features([1, None, 2, None])\n    assert (aa.shape == (4, 6))\n    assert (aa[(:, 0)] == pytest.approx([(- 1), 0, (- 2), 0]))\n    sg = example_hin_1(feature_sizes={'F': 4, 'R': 2}, reverse_order=True, edge_features=True)\n    ab = sg.edge_features([None, 4, None])\n    assert (ab.shape == (3, 2))\n    assert (ab[(:, 0)] == pytest.approx([0, (- 4), 0]))\n    ab = sg.edge_features([None, 4, None], 'R')\n    assert (ab.shape == (3, 2))\n    assert (ab[(:, 0)] == pytest.approx([0, (- 4), 0]))\n    with pytest.raises(ValueError):\n        sg.edge_features([None, 4, None], 'F')\n    with pytest.raises(ValueError):\n        sg.edge_features([None, None])", "masked_code": "def test_null_edge_feature():\n    sg = example_graph(edge_feature_size=6)\n    aa = sg.edge_features([1, None, 2, None])\n    assert (aa.shape == (4, 6))\n    assert (aa[(:, 0)] == pytest.approx([(- 1), 0, (- 2), 0]))\n    sg = example_hin_1(feature_sizes={'F': 4, 'R': 2}, reverse_order=True, edge_features=True)\n    ab = sg.edge_features([None, 4, None])\n    assert (ab.shape == '???')\n    assert (ab[(:, 0)] == pytest.approx([0, (- 4), 0]))\n    ab = sg.edge_features([None, 4, None], 'R')\n    assert (ab.shape == (3, 2))\n    assert (ab[(:, 0)] == pytest.approx([0, (- 4), 0]))\n    with pytest.raises(ValueError):\n        sg.edge_features([None, 4, None], 'F')\n    with pytest.raises(ValueError):\n        sg.edge_features([None, None])", "ground_truth": "(3, 2)", "quality_analysis": {"complexity_score": 6, "left_complexity": 2, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_83", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_null_edge_feature", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "def test_null_edge_feature():\n    sg = example_graph(edge_feature_size=6)\n    aa = sg.edge_features([1, None, 2, None])\n    assert (aa.shape == (4, 6))\n    assert (aa[(:, 0)] == pytest.approx([(- 1), 0, (- 2), 0]))\n    sg = example_hin_1(feature_sizes={'F': 4, 'R': 2}, reverse_order=True, edge_features=True)\n    ab = sg.edge_features([None, 4, None])\n    assert (ab.shape == (3, 2))\n    assert (ab[(:, 0)] == pytest.approx([0, (- 4), 0]))\n    ab = sg.edge_features([None, 4, None], 'R')\n    assert (ab.shape == (3, 2))\n    assert (ab[(:, 0)] == pytest.approx([0, (- 4), 0]))\n    with pytest.raises(ValueError):\n        sg.edge_features([None, 4, None], 'F')\n    with pytest.raises(ValueError):\n        sg.edge_features([None, None])", "masked_code": "def test_null_edge_feature():\n    sg = example_graph(edge_feature_size=6)\n    aa = sg.edge_features([1, None, 2, None])\n    assert (aa.shape == (4, 6))\n    assert (aa[(:, 0)] == pytest.approx([(- 1), 0, (- 2), 0]))\n    sg = example_hin_1(feature_sizes={'F': 4, 'R': 2}, reverse_order=True, edge_features=True)\n    ab = sg.edge_features([None, 4, None])\n    assert (ab.shape == (3, 2))\n    assert (ab[(:, 0)] == '???')\n    ab = sg.edge_features([None, 4, None], 'R')\n    assert (ab.shape == (3, 2))\n    assert (ab[(:, 0)] == pytest.approx([0, (- 4), 0]))\n    with pytest.raises(ValueError):\n        sg.edge_features([None, 4, None], 'F')\n    with pytest.raises(ValueError):\n        sg.edge_features([None, None])", "ground_truth": "pytest.approx([0, (- 4), 0])", "quality_analysis": {"complexity_score": 17, "left_complexity": 7, "right_complexity": 10, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_84", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_null_edge_feature", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "def test_null_edge_feature():\n    sg = example_graph(edge_feature_size=6)\n    aa = sg.edge_features([1, None, 2, None])\n    assert (aa.shape == (4, 6))\n    assert (aa[(:, 0)] == pytest.approx([(- 1), 0, (- 2), 0]))\n    sg = example_hin_1(feature_sizes={'F': 4, 'R': 2}, reverse_order=True, edge_features=True)\n    ab = sg.edge_features([None, 4, None])\n    assert (ab.shape == (3, 2))\n    assert (ab[(:, 0)] == pytest.approx([0, (- 4), 0]))\n    ab = sg.edge_features([None, 4, None], 'R')\n    assert (ab.shape == (3, 2))\n    assert (ab[(:, 0)] == pytest.approx([0, (- 4), 0]))\n    with pytest.raises(ValueError):\n        sg.edge_features([None, 4, None], 'F')\n    with pytest.raises(ValueError):\n        sg.edge_features([None, None])", "masked_code": "def test_null_edge_feature():\n    sg = example_graph(edge_feature_size=6)\n    aa = sg.edge_features([1, None, 2, None])\n    assert (aa.shape == (4, 6))\n    assert (aa[(:, 0)] == pytest.approx([(- 1), 0, (- 2), 0]))\n    sg = example_hin_1(feature_sizes={'F': 4, 'R': 2}, reverse_order=True, edge_features=True)\n    ab = sg.edge_features([None, 4, None])\n    assert (ab.shape == (3, 2))\n    assert (ab[(:, 0)] == pytest.approx([0, (- 4), 0]))\n    ab = sg.edge_features([None, 4, None], 'R')\n    assert (ab.shape == '???')\n    assert (ab[(:, 0)] == pytest.approx([0, (- 4), 0]))\n    with pytest.raises(ValueError):\n        sg.edge_features([None, 4, None], 'F')\n    with pytest.raises(ValueError):\n        sg.edge_features([None, None])", "ground_truth": "(3, 2)", "quality_analysis": {"complexity_score": 6, "left_complexity": 2, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_85", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_null_edge_feature", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "def test_null_edge_feature():\n    sg = example_graph(edge_feature_size=6)\n    aa = sg.edge_features([1, None, 2, None])\n    assert (aa.shape == (4, 6))\n    assert (aa[(:, 0)] == pytest.approx([(- 1), 0, (- 2), 0]))\n    sg = example_hin_1(feature_sizes={'F': 4, 'R': 2}, reverse_order=True, edge_features=True)\n    ab = sg.edge_features([None, 4, None])\n    assert (ab.shape == (3, 2))\n    assert (ab[(:, 0)] == pytest.approx([0, (- 4), 0]))\n    ab = sg.edge_features([None, 4, None], 'R')\n    assert (ab.shape == (3, 2))\n    assert (ab[(:, 0)] == pytest.approx([0, (- 4), 0]))\n    with pytest.raises(ValueError):\n        sg.edge_features([None, 4, None], 'F')\n    with pytest.raises(ValueError):\n        sg.edge_features([None, None])", "masked_code": "def test_null_edge_feature():\n    sg = example_graph(edge_feature_size=6)\n    aa = sg.edge_features([1, None, 2, None])\n    assert (aa.shape == (4, 6))\n    assert (aa[(:, 0)] == pytest.approx([(- 1), 0, (- 2), 0]))\n    sg = example_hin_1(feature_sizes={'F': 4, 'R': 2}, reverse_order=True, edge_features=True)\n    ab = sg.edge_features([None, 4, None])\n    assert (ab.shape == (3, 2))\n    assert (ab[(:, 0)] == pytest.approx([0, (- 4), 0]))\n    ab = sg.edge_features([None, 4, None], 'R')\n    assert (ab.shape == (3, 2))\n    assert (ab[(:, 0)] == '???')\n    with pytest.raises(ValueError):\n        sg.edge_features([None, 4, None], 'F')\n    with pytest.raises(ValueError):\n        sg.edge_features([None, None])", "ground_truth": "pytest.approx([0, (- 4), 0])", "quality_analysis": {"complexity_score": 17, "left_complexity": 7, "right_complexity": 10, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_86", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_node_types", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "def test_node_types():\n    sg = example_graph(feature_size=6)\n    assert (sg.node_types == {'default'})\n    sg = example_hin_1(feature_sizes={'A': 4, 'B': 2}, reverse_order=True)\n    assert (sg.node_types == {'A', 'B'})\n    sg = example_hin_1(reverse_order=True)\n    assert (sg.node_types == {'A', 'B'})", "masked_code": "def test_node_types():\n    sg = example_graph(feature_size=6)\n    assert (sg.node_types == '???')\n    sg = example_hin_1(feature_sizes={'A': 4, 'B': 2}, reverse_order=True)\n    assert (sg.node_types == {'A', 'B'})\n    sg = example_hin_1(reverse_order=True)\n    assert (sg.node_types == {'A', 'B'})", "ground_truth": "{'default'}", "quality_analysis": {"complexity_score": 2, "left_complexity": 2, "right_complexity": 0, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_87", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_node_types", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "def test_node_types():\n    sg = example_graph(feature_size=6)\n    assert (sg.node_types == {'default'})\n    sg = example_hin_1(feature_sizes={'A': 4, 'B': 2}, reverse_order=True)\n    assert (sg.node_types == {'A', 'B'})\n    sg = example_hin_1(reverse_order=True)\n    assert (sg.node_types == {'A', 'B'})", "masked_code": "def test_node_types():\n    sg = example_graph(feature_size=6)\n    assert (sg.node_types == {'default'})\n    sg = example_hin_1(feature_sizes={'A': 4, 'B': 2}, reverse_order=True)\n    assert (sg.node_types == '???')\n    sg = example_hin_1(reverse_order=True)\n    assert (sg.node_types == {'A', 'B'})", "ground_truth": "{'A', 'B'}", "quality_analysis": {"complexity_score": 2, "left_complexity": 2, "right_complexity": 0, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_88", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_node_types", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "def test_node_types():\n    sg = example_graph(feature_size=6)\n    assert (sg.node_types == {'default'})\n    sg = example_hin_1(feature_sizes={'A': 4, 'B': 2}, reverse_order=True)\n    assert (sg.node_types == {'A', 'B'})\n    sg = example_hin_1(reverse_order=True)\n    assert (sg.node_types == {'A', 'B'})", "masked_code": "def test_node_types():\n    sg = example_graph(feature_size=6)\n    assert (sg.node_types == {'default'})\n    sg = example_hin_1(feature_sizes={'A': 4, 'B': 2}, reverse_order=True)\n    assert (sg.node_types == {'A', 'B'})\n    sg = example_hin_1(reverse_order=True)\n    assert (sg.node_types == '???')", "ground_truth": "{'A', 'B'}", "quality_analysis": {"complexity_score": 2, "left_complexity": 2, "right_complexity": 0, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_89", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_edge_types", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "def test_edge_types():\n    sg = example_graph(feature_size=6)\n    assert (set(sg.edge_types) == {'default'})\n    sg = example_hin_1()\n    assert (set(sg.edge_types) == {'F', 'R'})", "masked_code": "def test_edge_types():\n    sg = example_graph(feature_size=6)\n    assert (set(sg.edge_types) == '???')\n    sg = example_hin_1()\n    assert (set(sg.edge_types) == {'F', 'R'})", "ground_truth": "{'default'}", "quality_analysis": {"complexity_score": 5, "left_complexity": 5, "right_complexity": 0, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_90", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_edge_types", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "def test_edge_types():\n    sg = example_graph(feature_size=6)\n    assert (set(sg.edge_types) == {'default'})\n    sg = example_hin_1()\n    assert (set(sg.edge_types) == {'F', 'R'})", "masked_code": "def test_edge_types():\n    sg = example_graph(feature_size=6)\n    assert (set(sg.edge_types) == {'default'})\n    sg = example_hin_1()\n    assert (set(sg.edge_types) == '???')", "ground_truth": "{'F', 'R'}", "quality_analysis": {"complexity_score": 5, "left_complexity": 5, "right_complexity": 0, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_91", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_feature_conversion_from_dataframe", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "def test_feature_conversion_from_dataframe():\n    g = example_graph_nx()\n    df = pd.DataFrame({v: (np.ones(10) * float(v)) for v in list(g)}).T\n    gs = StellarGraph.from_networkx(g, node_features=df)\n    aa = gs.node_features([1, 2, 3, 4])\n    assert (aa[(:, 0)] == pytest.approx([1, 2, 3, 4]))\n    aa = gs.node_features([1, 2, None, None])\n    assert (aa[(:, 0)] == pytest.approx([1, 2, 0, 0]))\n    g = example_hin_1_nx()\n    df = {t: pd.DataFrame({v: (np.ones(10) * float(v)) for (v, vdata) in g.nodes(data=True) if (vdata['label'] == t)}).T for t in ['A', 'B']}\n    gs = StellarGraph.from_networkx(g, node_features=df)\n    aa = gs.node_features([0, 1, 2, 3], 'A')\n    assert (aa[(:, 0)] == pytest.approx([0, 1, 2, 3]))\n    assert (aa.shape == (4, 10))\n    ab = gs.node_features([4, 5], 'B')\n    assert (ab.shape == (2, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 5]))\n    with pytest.raises(ValueError):\n        ab = gs.node_features([1, 5])\n    with pytest.raises(ValueError):\n        ab = gs.node_features([4, 5], 'A')\n    ab = gs.node_features([4, None, None], 'B')\n    assert (ab.shape == (3, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 0, 0]))", "masked_code": "def test_feature_conversion_from_dataframe():\n    g = example_graph_nx()\n    df = pd.DataFrame({v: (np.ones(10) * float(v)) for v in list(g)}).T\n    gs = StellarGraph.from_networkx(g, node_features=df)\n    aa = gs.node_features([1, 2, 3, 4])\n    assert (aa[(:, 0)] == '???')\n    aa = gs.node_features([1, 2, None, None])\n    assert (aa[(:, 0)] == pytest.approx([1, 2, 0, 0]))\n    g = example_hin_1_nx()\n    df = {t: pd.DataFrame({v: (np.ones(10) * float(v)) for (v, vdata) in g.nodes(data=True) if (vdata['label'] == t)}).T for t in ['A', 'B']}\n    gs = StellarGraph.from_networkx(g, node_features=df)\n    aa = gs.node_features([0, 1, 2, 3], 'A')\n    assert (aa[(:, 0)] == pytest.approx([0, 1, 2, 3]))\n    assert (aa.shape == (4, 10))\n    ab = gs.node_features([4, 5], 'B')\n    assert (ab.shape == (2, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 5]))\n    with pytest.raises(ValueError):\n        ab = gs.node_features([1, 5])\n    with pytest.raises(ValueError):\n        ab = gs.node_features([4, 5], 'A')\n    ab = gs.node_features([4, None, None], 'B')\n    assert (ab.shape == (3, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 0, 0]))", "ground_truth": "pytest.approx([1, 2, 3, 4])", "quality_analysis": {"complexity_score": 16, "left_complexity": 7, "right_complexity": 9, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_92", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_feature_conversion_from_dataframe", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "def test_feature_conversion_from_dataframe():\n    g = example_graph_nx()\n    df = pd.DataFrame({v: (np.ones(10) * float(v)) for v in list(g)}).T\n    gs = StellarGraph.from_networkx(g, node_features=df)\n    aa = gs.node_features([1, 2, 3, 4])\n    assert (aa[(:, 0)] == pytest.approx([1, 2, 3, 4]))\n    aa = gs.node_features([1, 2, None, None])\n    assert (aa[(:, 0)] == pytest.approx([1, 2, 0, 0]))\n    g = example_hin_1_nx()\n    df = {t: pd.DataFrame({v: (np.ones(10) * float(v)) for (v, vdata) in g.nodes(data=True) if (vdata['label'] == t)}).T for t in ['A', 'B']}\n    gs = StellarGraph.from_networkx(g, node_features=df)\n    aa = gs.node_features([0, 1, 2, 3], 'A')\n    assert (aa[(:, 0)] == pytest.approx([0, 1, 2, 3]))\n    assert (aa.shape == (4, 10))\n    ab = gs.node_features([4, 5], 'B')\n    assert (ab.shape == (2, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 5]))\n    with pytest.raises(ValueError):\n        ab = gs.node_features([1, 5])\n    with pytest.raises(ValueError):\n        ab = gs.node_features([4, 5], 'A')\n    ab = gs.node_features([4, None, None], 'B')\n    assert (ab.shape == (3, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 0, 0]))", "masked_code": "def test_feature_conversion_from_dataframe():\n    g = example_graph_nx()\n    df = pd.DataFrame({v: (np.ones(10) * float(v)) for v in list(g)}).T\n    gs = StellarGraph.from_networkx(g, node_features=df)\n    aa = gs.node_features([1, 2, 3, 4])\n    assert (aa[(:, 0)] == pytest.approx([1, 2, 3, 4]))\n    aa = gs.node_features([1, 2, None, None])\n    assert (aa[(:, 0)] == '???')\n    g = example_hin_1_nx()\n    df = {t: pd.DataFrame({v: (np.ones(10) * float(v)) for (v, vdata) in g.nodes(data=True) if (vdata['label'] == t)}).T for t in ['A', 'B']}\n    gs = StellarGraph.from_networkx(g, node_features=df)\n    aa = gs.node_features([0, 1, 2, 3], 'A')\n    assert (aa[(:, 0)] == pytest.approx([0, 1, 2, 3]))\n    assert (aa.shape == (4, 10))\n    ab = gs.node_features([4, 5], 'B')\n    assert (ab.shape == (2, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 5]))\n    with pytest.raises(ValueError):\n        ab = gs.node_features([1, 5])\n    with pytest.raises(ValueError):\n        ab = gs.node_features([4, 5], 'A')\n    ab = gs.node_features([4, None, None], 'B')\n    assert (ab.shape == (3, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 0, 0]))", "ground_truth": "pytest.approx([1, 2, 0, 0])", "quality_analysis": {"complexity_score": 16, "left_complexity": 7, "right_complexity": 9, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_93", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_feature_conversion_from_dataframe", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "def test_feature_conversion_from_dataframe():\n    g = example_graph_nx()\n    df = pd.DataFrame({v: (np.ones(10) * float(v)) for v in list(g)}).T\n    gs = StellarGraph.from_networkx(g, node_features=df)\n    aa = gs.node_features([1, 2, 3, 4])\n    assert (aa[(:, 0)] == pytest.approx([1, 2, 3, 4]))\n    aa = gs.node_features([1, 2, None, None])\n    assert (aa[(:, 0)] == pytest.approx([1, 2, 0, 0]))\n    g = example_hin_1_nx()\n    df = {t: pd.DataFrame({v: (np.ones(10) * float(v)) for (v, vdata) in g.nodes(data=True) if (vdata['label'] == t)}).T for t in ['A', 'B']}\n    gs = StellarGraph.from_networkx(g, node_features=df)\n    aa = gs.node_features([0, 1, 2, 3], 'A')\n    assert (aa[(:, 0)] == pytest.approx([0, 1, 2, 3]))\n    assert (aa.shape == (4, 10))\n    ab = gs.node_features([4, 5], 'B')\n    assert (ab.shape == (2, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 5]))\n    with pytest.raises(ValueError):\n        ab = gs.node_features([1, 5])\n    with pytest.raises(ValueError):\n        ab = gs.node_features([4, 5], 'A')\n    ab = gs.node_features([4, None, None], 'B')\n    assert (ab.shape == (3, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 0, 0]))", "masked_code": "def test_feature_conversion_from_dataframe():\n    g = example_graph_nx()\n    df = pd.DataFrame({v: (np.ones(10) * float(v)) for v in list(g)}).T\n    gs = StellarGraph.from_networkx(g, node_features=df)\n    aa = gs.node_features([1, 2, 3, 4])\n    assert (aa[(:, 0)] == pytest.approx([1, 2, 3, 4]))\n    aa = gs.node_features([1, 2, None, None])\n    assert (aa[(:, 0)] == pytest.approx([1, 2, 0, 0]))\n    g = example_hin_1_nx()\n    df = {t: pd.DataFrame({v: (np.ones(10) * float(v)) for (v, vdata) in g.nodes(data=True) if (vdata['label'] == t)}).T for t in ['A', 'B']}\n    gs = StellarGraph.from_networkx(g, node_features=df)\n    aa = gs.node_features([0, 1, 2, 3], 'A')\n    assert (aa[(:, 0)] == '???')\n    assert (aa.shape == (4, 10))\n    ab = gs.node_features([4, 5], 'B')\n    assert (ab.shape == (2, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 5]))\n    with pytest.raises(ValueError):\n        ab = gs.node_features([1, 5])\n    with pytest.raises(ValueError):\n        ab = gs.node_features([4, 5], 'A')\n    ab = gs.node_features([4, None, None], 'B')\n    assert (ab.shape == (3, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 0, 0]))", "ground_truth": "pytest.approx([0, 1, 2, 3])", "quality_analysis": {"complexity_score": 16, "left_complexity": 7, "right_complexity": 9, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_94", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_feature_conversion_from_dataframe", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "def test_feature_conversion_from_dataframe():\n    g = example_graph_nx()\n    df = pd.DataFrame({v: (np.ones(10) * float(v)) for v in list(g)}).T\n    gs = StellarGraph.from_networkx(g, node_features=df)\n    aa = gs.node_features([1, 2, 3, 4])\n    assert (aa[(:, 0)] == pytest.approx([1, 2, 3, 4]))\n    aa = gs.node_features([1, 2, None, None])\n    assert (aa[(:, 0)] == pytest.approx([1, 2, 0, 0]))\n    g = example_hin_1_nx()\n    df = {t: pd.DataFrame({v: (np.ones(10) * float(v)) for (v, vdata) in g.nodes(data=True) if (vdata['label'] == t)}).T for t in ['A', 'B']}\n    gs = StellarGraph.from_networkx(g, node_features=df)\n    aa = gs.node_features([0, 1, 2, 3], 'A')\n    assert (aa[(:, 0)] == pytest.approx([0, 1, 2, 3]))\n    assert (aa.shape == (4, 10))\n    ab = gs.node_features([4, 5], 'B')\n    assert (ab.shape == (2, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 5]))\n    with pytest.raises(ValueError):\n        ab = gs.node_features([1, 5])\n    with pytest.raises(ValueError):\n        ab = gs.node_features([4, 5], 'A')\n    ab = gs.node_features([4, None, None], 'B')\n    assert (ab.shape == (3, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 0, 0]))", "masked_code": "def test_feature_conversion_from_dataframe():\n    g = example_graph_nx()\n    df = pd.DataFrame({v: (np.ones(10) * float(v)) for v in list(g)}).T\n    gs = StellarGraph.from_networkx(g, node_features=df)\n    aa = gs.node_features([1, 2, 3, 4])\n    assert (aa[(:, 0)] == pytest.approx([1, 2, 3, 4]))\n    aa = gs.node_features([1, 2, None, None])\n    assert (aa[(:, 0)] == pytest.approx([1, 2, 0, 0]))\n    g = example_hin_1_nx()\n    df = {t: pd.DataFrame({v: (np.ones(10) * float(v)) for (v, vdata) in g.nodes(data=True) if (vdata['label'] == t)}).T for t in ['A', 'B']}\n    gs = StellarGraph.from_networkx(g, node_features=df)\n    aa = gs.node_features([0, 1, 2, 3], 'A')\n    assert (aa[(:, 0)] == pytest.approx([0, 1, 2, 3]))\n    assert (aa.shape == '???')\n    ab = gs.node_features([4, 5], 'B')\n    assert (ab.shape == (2, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 5]))\n    with pytest.raises(ValueError):\n        ab = gs.node_features([1, 5])\n    with pytest.raises(ValueError):\n        ab = gs.node_features([4, 5], 'A')\n    ab = gs.node_features([4, None, None], 'B')\n    assert (ab.shape == (3, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 0, 0]))", "ground_truth": "(4, 10)", "quality_analysis": {"complexity_score": 6, "left_complexity": 2, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_95", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_feature_conversion_from_dataframe", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "def test_feature_conversion_from_dataframe():\n    g = example_graph_nx()\n    df = pd.DataFrame({v: (np.ones(10) * float(v)) for v in list(g)}).T\n    gs = StellarGraph.from_networkx(g, node_features=df)\n    aa = gs.node_features([1, 2, 3, 4])\n    assert (aa[(:, 0)] == pytest.approx([1, 2, 3, 4]))\n    aa = gs.node_features([1, 2, None, None])\n    assert (aa[(:, 0)] == pytest.approx([1, 2, 0, 0]))\n    g = example_hin_1_nx()\n    df = {t: pd.DataFrame({v: (np.ones(10) * float(v)) for (v, vdata) in g.nodes(data=True) if (vdata['label'] == t)}).T for t in ['A', 'B']}\n    gs = StellarGraph.from_networkx(g, node_features=df)\n    aa = gs.node_features([0, 1, 2, 3], 'A')\n    assert (aa[(:, 0)] == pytest.approx([0, 1, 2, 3]))\n    assert (aa.shape == (4, 10))\n    ab = gs.node_features([4, 5], 'B')\n    assert (ab.shape == (2, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 5]))\n    with pytest.raises(ValueError):\n        ab = gs.node_features([1, 5])\n    with pytest.raises(ValueError):\n        ab = gs.node_features([4, 5], 'A')\n    ab = gs.node_features([4, None, None], 'B')\n    assert (ab.shape == (3, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 0, 0]))", "masked_code": "def test_feature_conversion_from_dataframe():\n    g = example_graph_nx()\n    df = pd.DataFrame({v: (np.ones(10) * float(v)) for v in list(g)}).T\n    gs = StellarGraph.from_networkx(g, node_features=df)\n    aa = gs.node_features([1, 2, 3, 4])\n    assert (aa[(:, 0)] == pytest.approx([1, 2, 3, 4]))\n    aa = gs.node_features([1, 2, None, None])\n    assert (aa[(:, 0)] == pytest.approx([1, 2, 0, 0]))\n    g = example_hin_1_nx()\n    df = {t: pd.DataFrame({v: (np.ones(10) * float(v)) for (v, vdata) in g.nodes(data=True) if (vdata['label'] == t)}).T for t in ['A', 'B']}\n    gs = StellarGraph.from_networkx(g, node_features=df)\n    aa = gs.node_features([0, 1, 2, 3], 'A')\n    assert (aa[(:, 0)] == pytest.approx([0, 1, 2, 3]))\n    assert (aa.shape == (4, 10))\n    ab = gs.node_features([4, 5], 'B')\n    assert (ab.shape == '???')\n    assert (ab[(:, 0)] == pytest.approx([4, 5]))\n    with pytest.raises(ValueError):\n        ab = gs.node_features([1, 5])\n    with pytest.raises(ValueError):\n        ab = gs.node_features([4, 5], 'A')\n    ab = gs.node_features([4, None, None], 'B')\n    assert (ab.shape == (3, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 0, 0]))", "ground_truth": "(2, 10)", "quality_analysis": {"complexity_score": 6, "left_complexity": 2, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_96", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_feature_conversion_from_dataframe", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "def test_feature_conversion_from_dataframe():\n    g = example_graph_nx()\n    df = pd.DataFrame({v: (np.ones(10) * float(v)) for v in list(g)}).T\n    gs = StellarGraph.from_networkx(g, node_features=df)\n    aa = gs.node_features([1, 2, 3, 4])\n    assert (aa[(:, 0)] == pytest.approx([1, 2, 3, 4]))\n    aa = gs.node_features([1, 2, None, None])\n    assert (aa[(:, 0)] == pytest.approx([1, 2, 0, 0]))\n    g = example_hin_1_nx()\n    df = {t: pd.DataFrame({v: (np.ones(10) * float(v)) for (v, vdata) in g.nodes(data=True) if (vdata['label'] == t)}).T for t in ['A', 'B']}\n    gs = StellarGraph.from_networkx(g, node_features=df)\n    aa = gs.node_features([0, 1, 2, 3], 'A')\n    assert (aa[(:, 0)] == pytest.approx([0, 1, 2, 3]))\n    assert (aa.shape == (4, 10))\n    ab = gs.node_features([4, 5], 'B')\n    assert (ab.shape == (2, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 5]))\n    with pytest.raises(ValueError):\n        ab = gs.node_features([1, 5])\n    with pytest.raises(ValueError):\n        ab = gs.node_features([4, 5], 'A')\n    ab = gs.node_features([4, None, None], 'B')\n    assert (ab.shape == (3, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 0, 0]))", "masked_code": "def test_feature_conversion_from_dataframe():\n    g = example_graph_nx()\n    df = pd.DataFrame({v: (np.ones(10) * float(v)) for v in list(g)}).T\n    gs = StellarGraph.from_networkx(g, node_features=df)\n    aa = gs.node_features([1, 2, 3, 4])\n    assert (aa[(:, 0)] == pytest.approx([1, 2, 3, 4]))\n    aa = gs.node_features([1, 2, None, None])\n    assert (aa[(:, 0)] == pytest.approx([1, 2, 0, 0]))\n    g = example_hin_1_nx()\n    df = {t: pd.DataFrame({v: (np.ones(10) * float(v)) for (v, vdata) in g.nodes(data=True) if (vdata['label'] == t)}).T for t in ['A', 'B']}\n    gs = StellarGraph.from_networkx(g, node_features=df)\n    aa = gs.node_features([0, 1, 2, 3], 'A')\n    assert (aa[(:, 0)] == pytest.approx([0, 1, 2, 3]))\n    assert (aa.shape == (4, 10))\n    ab = gs.node_features([4, 5], 'B')\n    assert (ab.shape == (2, 10))\n    assert (ab[(:, 0)] == '???')\n    with pytest.raises(ValueError):\n        ab = gs.node_features([1, 5])\n    with pytest.raises(ValueError):\n        ab = gs.node_features([4, 5], 'A')\n    ab = gs.node_features([4, None, None], 'B')\n    assert (ab.shape == (3, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 0, 0]))", "ground_truth": "pytest.approx([4, 5])", "quality_analysis": {"complexity_score": 14, "left_complexity": 7, "right_complexity": 7, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_97", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_feature_conversion_from_dataframe", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "def test_feature_conversion_from_dataframe():\n    g = example_graph_nx()\n    df = pd.DataFrame({v: (np.ones(10) * float(v)) for v in list(g)}).T\n    gs = StellarGraph.from_networkx(g, node_features=df)\n    aa = gs.node_features([1, 2, 3, 4])\n    assert (aa[(:, 0)] == pytest.approx([1, 2, 3, 4]))\n    aa = gs.node_features([1, 2, None, None])\n    assert (aa[(:, 0)] == pytest.approx([1, 2, 0, 0]))\n    g = example_hin_1_nx()\n    df = {t: pd.DataFrame({v: (np.ones(10) * float(v)) for (v, vdata) in g.nodes(data=True) if (vdata['label'] == t)}).T for t in ['A', 'B']}\n    gs = StellarGraph.from_networkx(g, node_features=df)\n    aa = gs.node_features([0, 1, 2, 3], 'A')\n    assert (aa[(:, 0)] == pytest.approx([0, 1, 2, 3]))\n    assert (aa.shape == (4, 10))\n    ab = gs.node_features([4, 5], 'B')\n    assert (ab.shape == (2, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 5]))\n    with pytest.raises(ValueError):\n        ab = gs.node_features([1, 5])\n    with pytest.raises(ValueError):\n        ab = gs.node_features([4, 5], 'A')\n    ab = gs.node_features([4, None, None], 'B')\n    assert (ab.shape == (3, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 0, 0]))", "masked_code": "def test_feature_conversion_from_dataframe():\n    g = example_graph_nx()\n    df = pd.DataFrame({v: (np.ones(10) * float(v)) for v in list(g)}).T\n    gs = StellarGraph.from_networkx(g, node_features=df)\n    aa = gs.node_features([1, 2, 3, 4])\n    assert (aa[(:, 0)] == pytest.approx([1, 2, 3, 4]))\n    aa = gs.node_features([1, 2, None, None])\n    assert (aa[(:, 0)] == pytest.approx([1, 2, 0, 0]))\n    g = example_hin_1_nx()\n    df = {t: pd.DataFrame({v: (np.ones(10) * float(v)) for (v, vdata) in g.nodes(data=True) if (vdata['label'] == t)}).T for t in ['A', 'B']}\n    gs = StellarGraph.from_networkx(g, node_features=df)\n    aa = gs.node_features([0, 1, 2, 3], 'A')\n    assert (aa[(:, 0)] == pytest.approx([0, 1, 2, 3]))\n    assert (aa.shape == (4, 10))\n    ab = gs.node_features([4, 5], 'B')\n    assert (ab.shape == (2, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 5]))\n    with pytest.raises(ValueError):\n        ab = gs.node_features([1, 5])\n    with pytest.raises(ValueError):\n        ab = gs.node_features([4, 5], 'A')\n    ab = gs.node_features([4, None, None], 'B')\n    assert (ab.shape == '???')\n    assert (ab[(:, 0)] == pytest.approx([4, 0, 0]))", "ground_truth": "(3, 10)", "quality_analysis": {"complexity_score": 6, "left_complexity": 2, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_98", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_feature_conversion_from_dataframe", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "def test_feature_conversion_from_dataframe():\n    g = example_graph_nx()\n    df = pd.DataFrame({v: (np.ones(10) * float(v)) for v in list(g)}).T\n    gs = StellarGraph.from_networkx(g, node_features=df)\n    aa = gs.node_features([1, 2, 3, 4])\n    assert (aa[(:, 0)] == pytest.approx([1, 2, 3, 4]))\n    aa = gs.node_features([1, 2, None, None])\n    assert (aa[(:, 0)] == pytest.approx([1, 2, 0, 0]))\n    g = example_hin_1_nx()\n    df = {t: pd.DataFrame({v: (np.ones(10) * float(v)) for (v, vdata) in g.nodes(data=True) if (vdata['label'] == t)}).T for t in ['A', 'B']}\n    gs = StellarGraph.from_networkx(g, node_features=df)\n    aa = gs.node_features([0, 1, 2, 3], 'A')\n    assert (aa[(:, 0)] == pytest.approx([0, 1, 2, 3]))\n    assert (aa.shape == (4, 10))\n    ab = gs.node_features([4, 5], 'B')\n    assert (ab.shape == (2, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 5]))\n    with pytest.raises(ValueError):\n        ab = gs.node_features([1, 5])\n    with pytest.raises(ValueError):\n        ab = gs.node_features([4, 5], 'A')\n    ab = gs.node_features([4, None, None], 'B')\n    assert (ab.shape == (3, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 0, 0]))", "masked_code": "def test_feature_conversion_from_dataframe():\n    g = example_graph_nx()\n    df = pd.DataFrame({v: (np.ones(10) * float(v)) for v in list(g)}).T\n    gs = StellarGraph.from_networkx(g, node_features=df)\n    aa = gs.node_features([1, 2, 3, 4])\n    assert (aa[(:, 0)] == pytest.approx([1, 2, 3, 4]))\n    aa = gs.node_features([1, 2, None, None])\n    assert (aa[(:, 0)] == pytest.approx([1, 2, 0, 0]))\n    g = example_hin_1_nx()\n    df = {t: pd.DataFrame({v: (np.ones(10) * float(v)) for (v, vdata) in g.nodes(data=True) if (vdata['label'] == t)}).T for t in ['A', 'B']}\n    gs = StellarGraph.from_networkx(g, node_features=df)\n    aa = gs.node_features([0, 1, 2, 3], 'A')\n    assert (aa[(:, 0)] == pytest.approx([0, 1, 2, 3]))\n    assert (aa.shape == (4, 10))\n    ab = gs.node_features([4, 5], 'B')\n    assert (ab.shape == (2, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 5]))\n    with pytest.raises(ValueError):\n        ab = gs.node_features([1, 5])\n    with pytest.raises(ValueError):\n        ab = gs.node_features([4, 5], 'A')\n    ab = gs.node_features([4, None, None], 'B')\n    assert (ab.shape == (3, 10))\n    assert (ab[(:, 0)] == '???')", "ground_truth": "pytest.approx([4, 0, 0])", "quality_analysis": {"complexity_score": 15, "left_complexity": 7, "right_complexity": 8, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_99", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_feature_conversion_from_iterator", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "def test_feature_conversion_from_iterator():\n    g = example_graph_nx()\n    node_features = [(v, (np.ones(10) * float(v))) for v in list(g)]\n    gs = StellarGraph.from_networkx(g, node_features=node_features)\n    aa = gs.node_features([1, 2, 3, 4])\n    assert (aa[(:, 0)] == pytest.approx([1, 2, 3, 4]))\n    aa = gs.node_features([1, 2, None, None])\n    assert (aa[(:, 0)] == pytest.approx([1, 2, 0, 0]))\n    adj_expected = np.array([[0, 1, 0, 1], [1, 0, 1, 1], [0, 1, 0, 0], [1, 1, 0, 0]])\n    A = gs.to_adjacency_matrix()\n    assert (A.dtype == 'float32')\n    np.testing.assert_allclose(A.toarray(), adj_expected)\n    A = gs.to_adjacency_matrix(nodes=[3, 2])\n    assert (A.dtype == 'float32')\n    np.testing.assert_allclose(A.toarray(), adj_expected[[2, 1]][(:, [2, 1])])\n    g = example_hin_1_nx()\n    nf = {t: [(v, (np.ones(10) * float(v))) for (v, vdata) in g.nodes(data=True) if (vdata['label'] == t)] for t in ['A', 'B']}\n    gs = StellarGraph.from_networkx(g, node_features=nf)\n    aa = gs.node_features([0, 1, 2, 3], 'A')\n    assert (aa[(:, 0)] == pytest.approx([0, 1, 2, 3]))\n    assert (aa.shape == (4, 10))\n    ab = gs.node_features([4, 5], 'B')\n    assert (ab.shape == (2, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 5]))\n    with pytest.raises(ValueError):\n        ab = gs.node_features([1, 5])\n    with pytest.raises(ValueError):\n        ab = gs.node_features([4, 5], 'A')\n    ab = gs.node_features([4, None, None], 'B')\n    assert (ab.shape == (3, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 0, 0]))\n    g = example_hin_1_nx()\n    nf = [(v, (np.ones((5 if (vdata['label'] == 'A') else 10)) * float(v))) for (v, vdata) in g.nodes(data=True)]\n    gs = StellarGraph.from_networkx(g, node_features=nf)\n    aa = gs.node_features([0, 1, 2, 3], 'A')\n    assert (aa[(:, 0)] == pytest.approx([0, 1, 2, 3]))\n    assert (aa.shape == (4, 5))\n    ab = gs.node_features([4, 5], 'B')\n    assert (ab.shape == (2, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 5]))", "masked_code": "def test_feature_conversion_from_iterator():\n    g = example_graph_nx()\n    node_features = [(v, (np.ones(10) * float(v))) for v in list(g)]\n    gs = StellarGraph.from_networkx(g, node_features=node_features)\n    aa = gs.node_features([1, 2, 3, 4])\n    assert (aa[(:, 0)] == '???')\n    aa = gs.node_features([1, 2, None, None])\n    assert (aa[(:, 0)] == pytest.approx([1, 2, 0, 0]))\n    adj_expected = np.array([[0, 1, 0, 1], [1, 0, 1, 1], [0, 1, 0, 0], [1, 1, 0, 0]])\n    A = gs.to_adjacency_matrix()\n    assert (A.dtype == 'float32')\n    np.testing.assert_allclose(A.toarray(), adj_expected)\n    A = gs.to_adjacency_matrix(nodes=[3, 2])\n    assert (A.dtype == 'float32')\n    np.testing.assert_allclose(A.toarray(), adj_expected[[2, 1]][(:, [2, 1])])\n    g = example_hin_1_nx()\n    nf = {t: [(v, (np.ones(10) * float(v))) for (v, vdata) in g.nodes(data=True) if (vdata['label'] == t)] for t in ['A', 'B']}\n    gs = StellarGraph.from_networkx(g, node_features=nf)\n    aa = gs.node_features([0, 1, 2, 3], 'A')\n    assert (aa[(:, 0)] == pytest.approx([0, 1, 2, 3]))\n    assert (aa.shape == (4, 10))\n    ab = gs.node_features([4, 5], 'B')\n    assert (ab.shape == (2, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 5]))\n    with pytest.raises(ValueError):\n        ab = gs.node_features([1, 5])\n    with pytest.raises(ValueError):\n        ab = gs.node_features([4, 5], 'A')\n    ab = gs.node_features([4, None, None], 'B')\n    assert (ab.shape == (3, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 0, 0]))\n    g = example_hin_1_nx()\n    nf = [(v, (np.ones((5 if (vdata['label'] == 'A') else 10)) * float(v))) for (v, vdata) in g.nodes(data=True)]\n    gs = StellarGraph.from_networkx(g, node_features=nf)\n    aa = gs.node_features([0, 1, 2, 3], 'A')\n    assert (aa[(:, 0)] == pytest.approx([0, 1, 2, 3]))\n    assert (aa.shape == (4, 5))\n    ab = gs.node_features([4, 5], 'B')\n    assert (ab.shape == (2, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 5]))", "ground_truth": "pytest.approx([1, 2, 3, 4])", "quality_analysis": {"complexity_score": 16, "left_complexity": 7, "right_complexity": 9, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_100", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_feature_conversion_from_iterator", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "def test_feature_conversion_from_iterator():\n    g = example_graph_nx()\n    node_features = [(v, (np.ones(10) * float(v))) for v in list(g)]\n    gs = StellarGraph.from_networkx(g, node_features=node_features)\n    aa = gs.node_features([1, 2, 3, 4])\n    assert (aa[(:, 0)] == pytest.approx([1, 2, 3, 4]))\n    aa = gs.node_features([1, 2, None, None])\n    assert (aa[(:, 0)] == pytest.approx([1, 2, 0, 0]))\n    adj_expected = np.array([[0, 1, 0, 1], [1, 0, 1, 1], [0, 1, 0, 0], [1, 1, 0, 0]])\n    A = gs.to_adjacency_matrix()\n    assert (A.dtype == 'float32')\n    np.testing.assert_allclose(A.toarray(), adj_expected)\n    A = gs.to_adjacency_matrix(nodes=[3, 2])\n    assert (A.dtype == 'float32')\n    np.testing.assert_allclose(A.toarray(), adj_expected[[2, 1]][(:, [2, 1])])\n    g = example_hin_1_nx()\n    nf = {t: [(v, (np.ones(10) * float(v))) for (v, vdata) in g.nodes(data=True) if (vdata['label'] == t)] for t in ['A', 'B']}\n    gs = StellarGraph.from_networkx(g, node_features=nf)\n    aa = gs.node_features([0, 1, 2, 3], 'A')\n    assert (aa[(:, 0)] == pytest.approx([0, 1, 2, 3]))\n    assert (aa.shape == (4, 10))\n    ab = gs.node_features([4, 5], 'B')\n    assert (ab.shape == (2, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 5]))\n    with pytest.raises(ValueError):\n        ab = gs.node_features([1, 5])\n    with pytest.raises(ValueError):\n        ab = gs.node_features([4, 5], 'A')\n    ab = gs.node_features([4, None, None], 'B')\n    assert (ab.shape == (3, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 0, 0]))\n    g = example_hin_1_nx()\n    nf = [(v, (np.ones((5 if (vdata['label'] == 'A') else 10)) * float(v))) for (v, vdata) in g.nodes(data=True)]\n    gs = StellarGraph.from_networkx(g, node_features=nf)\n    aa = gs.node_features([0, 1, 2, 3], 'A')\n    assert (aa[(:, 0)] == pytest.approx([0, 1, 2, 3]))\n    assert (aa.shape == (4, 5))\n    ab = gs.node_features([4, 5], 'B')\n    assert (ab.shape == (2, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 5]))", "masked_code": "def test_feature_conversion_from_iterator():\n    g = example_graph_nx()\n    node_features = [(v, (np.ones(10) * float(v))) for v in list(g)]\n    gs = StellarGraph.from_networkx(g, node_features=node_features)\n    aa = gs.node_features([1, 2, 3, 4])\n    assert (aa[(:, 0)] == pytest.approx([1, 2, 3, 4]))\n    aa = gs.node_features([1, 2, None, None])\n    assert (aa[(:, 0)] == '???')\n    adj_expected = np.array([[0, 1, 0, 1], [1, 0, 1, 1], [0, 1, 0, 0], [1, 1, 0, 0]])\n    A = gs.to_adjacency_matrix()\n    assert (A.dtype == 'float32')\n    np.testing.assert_allclose(A.toarray(), adj_expected)\n    A = gs.to_adjacency_matrix(nodes=[3, 2])\n    assert (A.dtype == 'float32')\n    np.testing.assert_allclose(A.toarray(), adj_expected[[2, 1]][(:, [2, 1])])\n    g = example_hin_1_nx()\n    nf = {t: [(v, (np.ones(10) * float(v))) for (v, vdata) in g.nodes(data=True) if (vdata['label'] == t)] for t in ['A', 'B']}\n    gs = StellarGraph.from_networkx(g, node_features=nf)\n    aa = gs.node_features([0, 1, 2, 3], 'A')\n    assert (aa[(:, 0)] == pytest.approx([0, 1, 2, 3]))\n    assert (aa.shape == (4, 10))\n    ab = gs.node_features([4, 5], 'B')\n    assert (ab.shape == (2, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 5]))\n    with pytest.raises(ValueError):\n        ab = gs.node_features([1, 5])\n    with pytest.raises(ValueError):\n        ab = gs.node_features([4, 5], 'A')\n    ab = gs.node_features([4, None, None], 'B')\n    assert (ab.shape == (3, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 0, 0]))\n    g = example_hin_1_nx()\n    nf = [(v, (np.ones((5 if (vdata['label'] == 'A') else 10)) * float(v))) for (v, vdata) in g.nodes(data=True)]\n    gs = StellarGraph.from_networkx(g, node_features=nf)\n    aa = gs.node_features([0, 1, 2, 3], 'A')\n    assert (aa[(:, 0)] == pytest.approx([0, 1, 2, 3]))\n    assert (aa.shape == (4, 5))\n    ab = gs.node_features([4, 5], 'B')\n    assert (ab.shape == (2, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 5]))", "ground_truth": "pytest.approx([1, 2, 0, 0])", "quality_analysis": {"complexity_score": 16, "left_complexity": 7, "right_complexity": 9, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_101", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_feature_conversion_from_iterator", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "def test_feature_conversion_from_iterator():\n    g = example_graph_nx()\n    node_features = [(v, (np.ones(10) * float(v))) for v in list(g)]\n    gs = StellarGraph.from_networkx(g, node_features=node_features)\n    aa = gs.node_features([1, 2, 3, 4])\n    assert (aa[(:, 0)] == pytest.approx([1, 2, 3, 4]))\n    aa = gs.node_features([1, 2, None, None])\n    assert (aa[(:, 0)] == pytest.approx([1, 2, 0, 0]))\n    adj_expected = np.array([[0, 1, 0, 1], [1, 0, 1, 1], [0, 1, 0, 0], [1, 1, 0, 0]])\n    A = gs.to_adjacency_matrix()\n    assert (A.dtype == 'float32')\n    np.testing.assert_allclose(A.toarray(), adj_expected)\n    A = gs.to_adjacency_matrix(nodes=[3, 2])\n    assert (A.dtype == 'float32')\n    np.testing.assert_allclose(A.toarray(), adj_expected[[2, 1]][(:, [2, 1])])\n    g = example_hin_1_nx()\n    nf = {t: [(v, (np.ones(10) * float(v))) for (v, vdata) in g.nodes(data=True) if (vdata['label'] == t)] for t in ['A', 'B']}\n    gs = StellarGraph.from_networkx(g, node_features=nf)\n    aa = gs.node_features([0, 1, 2, 3], 'A')\n    assert (aa[(:, 0)] == pytest.approx([0, 1, 2, 3]))\n    assert (aa.shape == (4, 10))\n    ab = gs.node_features([4, 5], 'B')\n    assert (ab.shape == (2, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 5]))\n    with pytest.raises(ValueError):\n        ab = gs.node_features([1, 5])\n    with pytest.raises(ValueError):\n        ab = gs.node_features([4, 5], 'A')\n    ab = gs.node_features([4, None, None], 'B')\n    assert (ab.shape == (3, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 0, 0]))\n    g = example_hin_1_nx()\n    nf = [(v, (np.ones((5 if (vdata['label'] == 'A') else 10)) * float(v))) for (v, vdata) in g.nodes(data=True)]\n    gs = StellarGraph.from_networkx(g, node_features=nf)\n    aa = gs.node_features([0, 1, 2, 3], 'A')\n    assert (aa[(:, 0)] == pytest.approx([0, 1, 2, 3]))\n    assert (aa.shape == (4, 5))\n    ab = gs.node_features([4, 5], 'B')\n    assert (ab.shape == (2, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 5]))", "masked_code": "def test_feature_conversion_from_iterator():\n    g = example_graph_nx()\n    node_features = [(v, (np.ones(10) * float(v))) for v in list(g)]\n    gs = StellarGraph.from_networkx(g, node_features=node_features)\n    aa = gs.node_features([1, 2, 3, 4])\n    assert (aa[(:, 0)] == pytest.approx([1, 2, 3, 4]))\n    aa = gs.node_features([1, 2, None, None])\n    assert (aa[(:, 0)] == pytest.approx([1, 2, 0, 0]))\n    adj_expected = np.array([[0, 1, 0, 1], [1, 0, 1, 1], [0, 1, 0, 0], [1, 1, 0, 0]])\n    A = gs.to_adjacency_matrix()\n    assert (A.dtype == '???')\n    np.testing.assert_allclose(A.toarray(), adj_expected)\n    A = gs.to_adjacency_matrix(nodes=[3, 2])\n    assert (A.dtype == 'float32')\n    np.testing.assert_allclose(A.toarray(), adj_expected[[2, 1]][(:, [2, 1])])\n    g = example_hin_1_nx()\n    nf = {t: [(v, (np.ones(10) * float(v))) for (v, vdata) in g.nodes(data=True) if (vdata['label'] == t)] for t in ['A', 'B']}\n    gs = StellarGraph.from_networkx(g, node_features=nf)\n    aa = gs.node_features([0, 1, 2, 3], 'A')\n    assert (aa[(:, 0)] == pytest.approx([0, 1, 2, 3]))\n    assert (aa.shape == (4, 10))\n    ab = gs.node_features([4, 5], 'B')\n    assert (ab.shape == (2, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 5]))\n    with pytest.raises(ValueError):\n        ab = gs.node_features([1, 5])\n    with pytest.raises(ValueError):\n        ab = gs.node_features([4, 5], 'A')\n    ab = gs.node_features([4, None, None], 'B')\n    assert (ab.shape == (3, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 0, 0]))\n    g = example_hin_1_nx()\n    nf = [(v, (np.ones((5 if (vdata['label'] == 'A') else 10)) * float(v))) for (v, vdata) in g.nodes(data=True)]\n    gs = StellarGraph.from_networkx(g, node_features=nf)\n    aa = gs.node_features([0, 1, 2, 3], 'A')\n    assert (aa[(:, 0)] == pytest.approx([0, 1, 2, 3]))\n    assert (aa.shape == (4, 5))\n    ab = gs.node_features([4, 5], 'B')\n    assert (ab.shape == (2, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 5]))", "ground_truth": "'float32'", "quality_analysis": {"complexity_score": 3, "left_complexity": 2, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_102", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_feature_conversion_from_iterator", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "def test_feature_conversion_from_iterator():\n    g = example_graph_nx()\n    node_features = [(v, (np.ones(10) * float(v))) for v in list(g)]\n    gs = StellarGraph.from_networkx(g, node_features=node_features)\n    aa = gs.node_features([1, 2, 3, 4])\n    assert (aa[(:, 0)] == pytest.approx([1, 2, 3, 4]))\n    aa = gs.node_features([1, 2, None, None])\n    assert (aa[(:, 0)] == pytest.approx([1, 2, 0, 0]))\n    adj_expected = np.array([[0, 1, 0, 1], [1, 0, 1, 1], [0, 1, 0, 0], [1, 1, 0, 0]])\n    A = gs.to_adjacency_matrix()\n    assert (A.dtype == 'float32')\n    np.testing.assert_allclose(A.toarray(), adj_expected)\n    A = gs.to_adjacency_matrix(nodes=[3, 2])\n    assert (A.dtype == 'float32')\n    np.testing.assert_allclose(A.toarray(), adj_expected[[2, 1]][(:, [2, 1])])\n    g = example_hin_1_nx()\n    nf = {t: [(v, (np.ones(10) * float(v))) for (v, vdata) in g.nodes(data=True) if (vdata['label'] == t)] for t in ['A', 'B']}\n    gs = StellarGraph.from_networkx(g, node_features=nf)\n    aa = gs.node_features([0, 1, 2, 3], 'A')\n    assert (aa[(:, 0)] == pytest.approx([0, 1, 2, 3]))\n    assert (aa.shape == (4, 10))\n    ab = gs.node_features([4, 5], 'B')\n    assert (ab.shape == (2, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 5]))\n    with pytest.raises(ValueError):\n        ab = gs.node_features([1, 5])\n    with pytest.raises(ValueError):\n        ab = gs.node_features([4, 5], 'A')\n    ab = gs.node_features([4, None, None], 'B')\n    assert (ab.shape == (3, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 0, 0]))\n    g = example_hin_1_nx()\n    nf = [(v, (np.ones((5 if (vdata['label'] == 'A') else 10)) * float(v))) for (v, vdata) in g.nodes(data=True)]\n    gs = StellarGraph.from_networkx(g, node_features=nf)\n    aa = gs.node_features([0, 1, 2, 3], 'A')\n    assert (aa[(:, 0)] == pytest.approx([0, 1, 2, 3]))\n    assert (aa.shape == (4, 5))\n    ab = gs.node_features([4, 5], 'B')\n    assert (ab.shape == (2, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 5]))", "masked_code": "def test_feature_conversion_from_iterator():\n    g = example_graph_nx()\n    node_features = [(v, (np.ones(10) * float(v))) for v in list(g)]\n    gs = StellarGraph.from_networkx(g, node_features=node_features)\n    aa = gs.node_features([1, 2, 3, 4])\n    assert (aa[(:, 0)] == pytest.approx([1, 2, 3, 4]))\n    aa = gs.node_features([1, 2, None, None])\n    assert (aa[(:, 0)] == pytest.approx([1, 2, 0, 0]))\n    adj_expected = np.array([[0, 1, 0, 1], [1, 0, 1, 1], [0, 1, 0, 0], [1, 1, 0, 0]])\n    A = gs.to_adjacency_matrix()\n    assert (A.dtype == 'float32')\n    np.testing.assert_allclose(A.toarray(), adj_expected)\n    A = gs.to_adjacency_matrix(nodes=[3, 2])\n    assert (A.dtype == '???')\n    np.testing.assert_allclose(A.toarray(), adj_expected[[2, 1]][(:, [2, 1])])\n    g = example_hin_1_nx()\n    nf = {t: [(v, (np.ones(10) * float(v))) for (v, vdata) in g.nodes(data=True) if (vdata['label'] == t)] for t in ['A', 'B']}\n    gs = StellarGraph.from_networkx(g, node_features=nf)\n    aa = gs.node_features([0, 1, 2, 3], 'A')\n    assert (aa[(:, 0)] == pytest.approx([0, 1, 2, 3]))\n    assert (aa.shape == (4, 10))\n    ab = gs.node_features([4, 5], 'B')\n    assert (ab.shape == (2, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 5]))\n    with pytest.raises(ValueError):\n        ab = gs.node_features([1, 5])\n    with pytest.raises(ValueError):\n        ab = gs.node_features([4, 5], 'A')\n    ab = gs.node_features([4, None, None], 'B')\n    assert (ab.shape == (3, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 0, 0]))\n    g = example_hin_1_nx()\n    nf = [(v, (np.ones((5 if (vdata['label'] == 'A') else 10)) * float(v))) for (v, vdata) in g.nodes(data=True)]\n    gs = StellarGraph.from_networkx(g, node_features=nf)\n    aa = gs.node_features([0, 1, 2, 3], 'A')\n    assert (aa[(:, 0)] == pytest.approx([0, 1, 2, 3]))\n    assert (aa.shape == (4, 5))\n    ab = gs.node_features([4, 5], 'B')\n    assert (ab.shape == (2, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 5]))", "ground_truth": "'float32'", "quality_analysis": {"complexity_score": 3, "left_complexity": 2, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_103", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_feature_conversion_from_iterator", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "def test_feature_conversion_from_iterator():\n    g = example_graph_nx()\n    node_features = [(v, (np.ones(10) * float(v))) for v in list(g)]\n    gs = StellarGraph.from_networkx(g, node_features=node_features)\n    aa = gs.node_features([1, 2, 3, 4])\n    assert (aa[(:, 0)] == pytest.approx([1, 2, 3, 4]))\n    aa = gs.node_features([1, 2, None, None])\n    assert (aa[(:, 0)] == pytest.approx([1, 2, 0, 0]))\n    adj_expected = np.array([[0, 1, 0, 1], [1, 0, 1, 1], [0, 1, 0, 0], [1, 1, 0, 0]])\n    A = gs.to_adjacency_matrix()\n    assert (A.dtype == 'float32')\n    np.testing.assert_allclose(A.toarray(), adj_expected)\n    A = gs.to_adjacency_matrix(nodes=[3, 2])\n    assert (A.dtype == 'float32')\n    np.testing.assert_allclose(A.toarray(), adj_expected[[2, 1]][(:, [2, 1])])\n    g = example_hin_1_nx()\n    nf = {t: [(v, (np.ones(10) * float(v))) for (v, vdata) in g.nodes(data=True) if (vdata['label'] == t)] for t in ['A', 'B']}\n    gs = StellarGraph.from_networkx(g, node_features=nf)\n    aa = gs.node_features([0, 1, 2, 3], 'A')\n    assert (aa[(:, 0)] == pytest.approx([0, 1, 2, 3]))\n    assert (aa.shape == (4, 10))\n    ab = gs.node_features([4, 5], 'B')\n    assert (ab.shape == (2, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 5]))\n    with pytest.raises(ValueError):\n        ab = gs.node_features([1, 5])\n    with pytest.raises(ValueError):\n        ab = gs.node_features([4, 5], 'A')\n    ab = gs.node_features([4, None, None], 'B')\n    assert (ab.shape == (3, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 0, 0]))\n    g = example_hin_1_nx()\n    nf = [(v, (np.ones((5 if (vdata['label'] == 'A') else 10)) * float(v))) for (v, vdata) in g.nodes(data=True)]\n    gs = StellarGraph.from_networkx(g, node_features=nf)\n    aa = gs.node_features([0, 1, 2, 3], 'A')\n    assert (aa[(:, 0)] == pytest.approx([0, 1, 2, 3]))\n    assert (aa.shape == (4, 5))\n    ab = gs.node_features([4, 5], 'B')\n    assert (ab.shape == (2, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 5]))", "masked_code": "def test_feature_conversion_from_iterator():\n    g = example_graph_nx()\n    node_features = [(v, (np.ones(10) * float(v))) for v in list(g)]\n    gs = StellarGraph.from_networkx(g, node_features=node_features)\n    aa = gs.node_features([1, 2, 3, 4])\n    assert (aa[(:, 0)] == pytest.approx([1, 2, 3, 4]))\n    aa = gs.node_features([1, 2, None, None])\n    assert (aa[(:, 0)] == pytest.approx([1, 2, 0, 0]))\n    adj_expected = np.array([[0, 1, 0, 1], [1, 0, 1, 1], [0, 1, 0, 0], [1, 1, 0, 0]])\n    A = gs.to_adjacency_matrix()\n    assert (A.dtype == 'float32')\n    np.testing.assert_allclose(A.toarray(), adj_expected)\n    A = gs.to_adjacency_matrix(nodes=[3, 2])\n    assert (A.dtype == 'float32')\n    np.testing.assert_allclose(A.toarray(), adj_expected[[2, 1]][(:, [2, 1])])\n    g = example_hin_1_nx()\n    nf = {t: [(v, (np.ones(10) * float(v))) for (v, vdata) in g.nodes(data=True) if (vdata['label'] == t)] for t in ['A', 'B']}\n    gs = StellarGraph.from_networkx(g, node_features=nf)\n    aa = gs.node_features([0, 1, 2, 3], 'A')\n    assert (aa[(:, 0)] == '???')\n    assert (aa.shape == (4, 10))\n    ab = gs.node_features([4, 5], 'B')\n    assert (ab.shape == (2, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 5]))\n    with pytest.raises(ValueError):\n        ab = gs.node_features([1, 5])\n    with pytest.raises(ValueError):\n        ab = gs.node_features([4, 5], 'A')\n    ab = gs.node_features([4, None, None], 'B')\n    assert (ab.shape == (3, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 0, 0]))\n    g = example_hin_1_nx()\n    nf = [(v, (np.ones((5 if (vdata['label'] == 'A') else 10)) * float(v))) for (v, vdata) in g.nodes(data=True)]\n    gs = StellarGraph.from_networkx(g, node_features=nf)\n    aa = gs.node_features([0, 1, 2, 3], 'A')\n    assert (aa[(:, 0)] == pytest.approx([0, 1, 2, 3]))\n    assert (aa.shape == (4, 5))\n    ab = gs.node_features([4, 5], 'B')\n    assert (ab.shape == (2, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 5]))", "ground_truth": "pytest.approx([0, 1, 2, 3])", "quality_analysis": {"complexity_score": 16, "left_complexity": 7, "right_complexity": 9, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_104", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_feature_conversion_from_iterator", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "def test_feature_conversion_from_iterator():\n    g = example_graph_nx()\n    node_features = [(v, (np.ones(10) * float(v))) for v in list(g)]\n    gs = StellarGraph.from_networkx(g, node_features=node_features)\n    aa = gs.node_features([1, 2, 3, 4])\n    assert (aa[(:, 0)] == pytest.approx([1, 2, 3, 4]))\n    aa = gs.node_features([1, 2, None, None])\n    assert (aa[(:, 0)] == pytest.approx([1, 2, 0, 0]))\n    adj_expected = np.array([[0, 1, 0, 1], [1, 0, 1, 1], [0, 1, 0, 0], [1, 1, 0, 0]])\n    A = gs.to_adjacency_matrix()\n    assert (A.dtype == 'float32')\n    np.testing.assert_allclose(A.toarray(), adj_expected)\n    A = gs.to_adjacency_matrix(nodes=[3, 2])\n    assert (A.dtype == 'float32')\n    np.testing.assert_allclose(A.toarray(), adj_expected[[2, 1]][(:, [2, 1])])\n    g = example_hin_1_nx()\n    nf = {t: [(v, (np.ones(10) * float(v))) for (v, vdata) in g.nodes(data=True) if (vdata['label'] == t)] for t in ['A', 'B']}\n    gs = StellarGraph.from_networkx(g, node_features=nf)\n    aa = gs.node_features([0, 1, 2, 3], 'A')\n    assert (aa[(:, 0)] == pytest.approx([0, 1, 2, 3]))\n    assert (aa.shape == (4, 10))\n    ab = gs.node_features([4, 5], 'B')\n    assert (ab.shape == (2, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 5]))\n    with pytest.raises(ValueError):\n        ab = gs.node_features([1, 5])\n    with pytest.raises(ValueError):\n        ab = gs.node_features([4, 5], 'A')\n    ab = gs.node_features([4, None, None], 'B')\n    assert (ab.shape == (3, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 0, 0]))\n    g = example_hin_1_nx()\n    nf = [(v, (np.ones((5 if (vdata['label'] == 'A') else 10)) * float(v))) for (v, vdata) in g.nodes(data=True)]\n    gs = StellarGraph.from_networkx(g, node_features=nf)\n    aa = gs.node_features([0, 1, 2, 3], 'A')\n    assert (aa[(:, 0)] == pytest.approx([0, 1, 2, 3]))\n    assert (aa.shape == (4, 5))\n    ab = gs.node_features([4, 5], 'B')\n    assert (ab.shape == (2, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 5]))", "masked_code": "def test_feature_conversion_from_iterator():\n    g = example_graph_nx()\n    node_features = [(v, (np.ones(10) * float(v))) for v in list(g)]\n    gs = StellarGraph.from_networkx(g, node_features=node_features)\n    aa = gs.node_features([1, 2, 3, 4])\n    assert (aa[(:, 0)] == pytest.approx([1, 2, 3, 4]))\n    aa = gs.node_features([1, 2, None, None])\n    assert (aa[(:, 0)] == pytest.approx([1, 2, 0, 0]))\n    adj_expected = np.array([[0, 1, 0, 1], [1, 0, 1, 1], [0, 1, 0, 0], [1, 1, 0, 0]])\n    A = gs.to_adjacency_matrix()\n    assert (A.dtype == 'float32')\n    np.testing.assert_allclose(A.toarray(), adj_expected)\n    A = gs.to_adjacency_matrix(nodes=[3, 2])\n    assert (A.dtype == 'float32')\n    np.testing.assert_allclose(A.toarray(), adj_expected[[2, 1]][(:, [2, 1])])\n    g = example_hin_1_nx()\n    nf = {t: [(v, (np.ones(10) * float(v))) for (v, vdata) in g.nodes(data=True) if (vdata['label'] == t)] for t in ['A', 'B']}\n    gs = StellarGraph.from_networkx(g, node_features=nf)\n    aa = gs.node_features([0, 1, 2, 3], 'A')\n    assert (aa[(:, 0)] == pytest.approx([0, 1, 2, 3]))\n    assert (aa.shape == '???')\n    ab = gs.node_features([4, 5], 'B')\n    assert (ab.shape == (2, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 5]))\n    with pytest.raises(ValueError):\n        ab = gs.node_features([1, 5])\n    with pytest.raises(ValueError):\n        ab = gs.node_features([4, 5], 'A')\n    ab = gs.node_features([4, None, None], 'B')\n    assert (ab.shape == (3, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 0, 0]))\n    g = example_hin_1_nx()\n    nf = [(v, (np.ones((5 if (vdata['label'] == 'A') else 10)) * float(v))) for (v, vdata) in g.nodes(data=True)]\n    gs = StellarGraph.from_networkx(g, node_features=nf)\n    aa = gs.node_features([0, 1, 2, 3], 'A')\n    assert (aa[(:, 0)] == pytest.approx([0, 1, 2, 3]))\n    assert (aa.shape == (4, 5))\n    ab = gs.node_features([4, 5], 'B')\n    assert (ab.shape == (2, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 5]))", "ground_truth": "(4, 10)", "quality_analysis": {"complexity_score": 6, "left_complexity": 2, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_105", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_feature_conversion_from_iterator", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "def test_feature_conversion_from_iterator():\n    g = example_graph_nx()\n    node_features = [(v, (np.ones(10) * float(v))) for v in list(g)]\n    gs = StellarGraph.from_networkx(g, node_features=node_features)\n    aa = gs.node_features([1, 2, 3, 4])\n    assert (aa[(:, 0)] == pytest.approx([1, 2, 3, 4]))\n    aa = gs.node_features([1, 2, None, None])\n    assert (aa[(:, 0)] == pytest.approx([1, 2, 0, 0]))\n    adj_expected = np.array([[0, 1, 0, 1], [1, 0, 1, 1], [0, 1, 0, 0], [1, 1, 0, 0]])\n    A = gs.to_adjacency_matrix()\n    assert (A.dtype == 'float32')\n    np.testing.assert_allclose(A.toarray(), adj_expected)\n    A = gs.to_adjacency_matrix(nodes=[3, 2])\n    assert (A.dtype == 'float32')\n    np.testing.assert_allclose(A.toarray(), adj_expected[[2, 1]][(:, [2, 1])])\n    g = example_hin_1_nx()\n    nf = {t: [(v, (np.ones(10) * float(v))) for (v, vdata) in g.nodes(data=True) if (vdata['label'] == t)] for t in ['A', 'B']}\n    gs = StellarGraph.from_networkx(g, node_features=nf)\n    aa = gs.node_features([0, 1, 2, 3], 'A')\n    assert (aa[(:, 0)] == pytest.approx([0, 1, 2, 3]))\n    assert (aa.shape == (4, 10))\n    ab = gs.node_features([4, 5], 'B')\n    assert (ab.shape == (2, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 5]))\n    with pytest.raises(ValueError):\n        ab = gs.node_features([1, 5])\n    with pytest.raises(ValueError):\n        ab = gs.node_features([4, 5], 'A')\n    ab = gs.node_features([4, None, None], 'B')\n    assert (ab.shape == (3, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 0, 0]))\n    g = example_hin_1_nx()\n    nf = [(v, (np.ones((5 if (vdata['label'] == 'A') else 10)) * float(v))) for (v, vdata) in g.nodes(data=True)]\n    gs = StellarGraph.from_networkx(g, node_features=nf)\n    aa = gs.node_features([0, 1, 2, 3], 'A')\n    assert (aa[(:, 0)] == pytest.approx([0, 1, 2, 3]))\n    assert (aa.shape == (4, 5))\n    ab = gs.node_features([4, 5], 'B')\n    assert (ab.shape == (2, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 5]))", "masked_code": "def test_feature_conversion_from_iterator():\n    g = example_graph_nx()\n    node_features = [(v, (np.ones(10) * float(v))) for v in list(g)]\n    gs = StellarGraph.from_networkx(g, node_features=node_features)\n    aa = gs.node_features([1, 2, 3, 4])\n    assert (aa[(:, 0)] == pytest.approx([1, 2, 3, 4]))\n    aa = gs.node_features([1, 2, None, None])\n    assert (aa[(:, 0)] == pytest.approx([1, 2, 0, 0]))\n    adj_expected = np.array([[0, 1, 0, 1], [1, 0, 1, 1], [0, 1, 0, 0], [1, 1, 0, 0]])\n    A = gs.to_adjacency_matrix()\n    assert (A.dtype == 'float32')\n    np.testing.assert_allclose(A.toarray(), adj_expected)\n    A = gs.to_adjacency_matrix(nodes=[3, 2])\n    assert (A.dtype == 'float32')\n    np.testing.assert_allclose(A.toarray(), adj_expected[[2, 1]][(:, [2, 1])])\n    g = example_hin_1_nx()\n    nf = {t: [(v, (np.ones(10) * float(v))) for (v, vdata) in g.nodes(data=True) if (vdata['label'] == t)] for t in ['A', 'B']}\n    gs = StellarGraph.from_networkx(g, node_features=nf)\n    aa = gs.node_features([0, 1, 2, 3], 'A')\n    assert (aa[(:, 0)] == pytest.approx([0, 1, 2, 3]))\n    assert (aa.shape == (4, 10))\n    ab = gs.node_features([4, 5], 'B')\n    assert (ab.shape == '???')\n    assert (ab[(:, 0)] == pytest.approx([4, 5]))\n    with pytest.raises(ValueError):\n        ab = gs.node_features([1, 5])\n    with pytest.raises(ValueError):\n        ab = gs.node_features([4, 5], 'A')\n    ab = gs.node_features([4, None, None], 'B')\n    assert (ab.shape == (3, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 0, 0]))\n    g = example_hin_1_nx()\n    nf = [(v, (np.ones((5 if (vdata['label'] == 'A') else 10)) * float(v))) for (v, vdata) in g.nodes(data=True)]\n    gs = StellarGraph.from_networkx(g, node_features=nf)\n    aa = gs.node_features([0, 1, 2, 3], 'A')\n    assert (aa[(:, 0)] == pytest.approx([0, 1, 2, 3]))\n    assert (aa.shape == (4, 5))\n    ab = gs.node_features([4, 5], 'B')\n    assert (ab.shape == (2, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 5]))", "ground_truth": "(2, 10)", "quality_analysis": {"complexity_score": 6, "left_complexity": 2, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_106", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_feature_conversion_from_iterator", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "def test_feature_conversion_from_iterator():\n    g = example_graph_nx()\n    node_features = [(v, (np.ones(10) * float(v))) for v in list(g)]\n    gs = StellarGraph.from_networkx(g, node_features=node_features)\n    aa = gs.node_features([1, 2, 3, 4])\n    assert (aa[(:, 0)] == pytest.approx([1, 2, 3, 4]))\n    aa = gs.node_features([1, 2, None, None])\n    assert (aa[(:, 0)] == pytest.approx([1, 2, 0, 0]))\n    adj_expected = np.array([[0, 1, 0, 1], [1, 0, 1, 1], [0, 1, 0, 0], [1, 1, 0, 0]])\n    A = gs.to_adjacency_matrix()\n    assert (A.dtype == 'float32')\n    np.testing.assert_allclose(A.toarray(), adj_expected)\n    A = gs.to_adjacency_matrix(nodes=[3, 2])\n    assert (A.dtype == 'float32')\n    np.testing.assert_allclose(A.toarray(), adj_expected[[2, 1]][(:, [2, 1])])\n    g = example_hin_1_nx()\n    nf = {t: [(v, (np.ones(10) * float(v))) for (v, vdata) in g.nodes(data=True) if (vdata['label'] == t)] for t in ['A', 'B']}\n    gs = StellarGraph.from_networkx(g, node_features=nf)\n    aa = gs.node_features([0, 1, 2, 3], 'A')\n    assert (aa[(:, 0)] == pytest.approx([0, 1, 2, 3]))\n    assert (aa.shape == (4, 10))\n    ab = gs.node_features([4, 5], 'B')\n    assert (ab.shape == (2, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 5]))\n    with pytest.raises(ValueError):\n        ab = gs.node_features([1, 5])\n    with pytest.raises(ValueError):\n        ab = gs.node_features([4, 5], 'A')\n    ab = gs.node_features([4, None, None], 'B')\n    assert (ab.shape == (3, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 0, 0]))\n    g = example_hin_1_nx()\n    nf = [(v, (np.ones((5 if (vdata['label'] == 'A') else 10)) * float(v))) for (v, vdata) in g.nodes(data=True)]\n    gs = StellarGraph.from_networkx(g, node_features=nf)\n    aa = gs.node_features([0, 1, 2, 3], 'A')\n    assert (aa[(:, 0)] == pytest.approx([0, 1, 2, 3]))\n    assert (aa.shape == (4, 5))\n    ab = gs.node_features([4, 5], 'B')\n    assert (ab.shape == (2, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 5]))", "masked_code": "def test_feature_conversion_from_iterator():\n    g = example_graph_nx()\n    node_features = [(v, (np.ones(10) * float(v))) for v in list(g)]\n    gs = StellarGraph.from_networkx(g, node_features=node_features)\n    aa = gs.node_features([1, 2, 3, 4])\n    assert (aa[(:, 0)] == pytest.approx([1, 2, 3, 4]))\n    aa = gs.node_features([1, 2, None, None])\n    assert (aa[(:, 0)] == pytest.approx([1, 2, 0, 0]))\n    adj_expected = np.array([[0, 1, 0, 1], [1, 0, 1, 1], [0, 1, 0, 0], [1, 1, 0, 0]])\n    A = gs.to_adjacency_matrix()\n    assert (A.dtype == 'float32')\n    np.testing.assert_allclose(A.toarray(), adj_expected)\n    A = gs.to_adjacency_matrix(nodes=[3, 2])\n    assert (A.dtype == 'float32')\n    np.testing.assert_allclose(A.toarray(), adj_expected[[2, 1]][(:, [2, 1])])\n    g = example_hin_1_nx()\n    nf = {t: [(v, (np.ones(10) * float(v))) for (v, vdata) in g.nodes(data=True) if (vdata['label'] == t)] for t in ['A', 'B']}\n    gs = StellarGraph.from_networkx(g, node_features=nf)\n    aa = gs.node_features([0, 1, 2, 3], 'A')\n    assert (aa[(:, 0)] == pytest.approx([0, 1, 2, 3]))\n    assert (aa.shape == (4, 10))\n    ab = gs.node_features([4, 5], 'B')\n    assert (ab.shape == (2, 10))\n    assert (ab[(:, 0)] == '???')\n    with pytest.raises(ValueError):\n        ab = gs.node_features([1, 5])\n    with pytest.raises(ValueError):\n        ab = gs.node_features([4, 5], 'A')\n    ab = gs.node_features([4, None, None], 'B')\n    assert (ab.shape == (3, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 0, 0]))\n    g = example_hin_1_nx()\n    nf = [(v, (np.ones((5 if (vdata['label'] == 'A') else 10)) * float(v))) for (v, vdata) in g.nodes(data=True)]\n    gs = StellarGraph.from_networkx(g, node_features=nf)\n    aa = gs.node_features([0, 1, 2, 3], 'A')\n    assert (aa[(:, 0)] == pytest.approx([0, 1, 2, 3]))\n    assert (aa.shape == (4, 5))\n    ab = gs.node_features([4, 5], 'B')\n    assert (ab.shape == (2, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 5]))", "ground_truth": "pytest.approx([4, 5])", "quality_analysis": {"complexity_score": 14, "left_complexity": 7, "right_complexity": 7, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_107", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_feature_conversion_from_iterator", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "def test_feature_conversion_from_iterator():\n    g = example_graph_nx()\n    node_features = [(v, (np.ones(10) * float(v))) for v in list(g)]\n    gs = StellarGraph.from_networkx(g, node_features=node_features)\n    aa = gs.node_features([1, 2, 3, 4])\n    assert (aa[(:, 0)] == pytest.approx([1, 2, 3, 4]))\n    aa = gs.node_features([1, 2, None, None])\n    assert (aa[(:, 0)] == pytest.approx([1, 2, 0, 0]))\n    adj_expected = np.array([[0, 1, 0, 1], [1, 0, 1, 1], [0, 1, 0, 0], [1, 1, 0, 0]])\n    A = gs.to_adjacency_matrix()\n    assert (A.dtype == 'float32')\n    np.testing.assert_allclose(A.toarray(), adj_expected)\n    A = gs.to_adjacency_matrix(nodes=[3, 2])\n    assert (A.dtype == 'float32')\n    np.testing.assert_allclose(A.toarray(), adj_expected[[2, 1]][(:, [2, 1])])\n    g = example_hin_1_nx()\n    nf = {t: [(v, (np.ones(10) * float(v))) for (v, vdata) in g.nodes(data=True) if (vdata['label'] == t)] for t in ['A', 'B']}\n    gs = StellarGraph.from_networkx(g, node_features=nf)\n    aa = gs.node_features([0, 1, 2, 3], 'A')\n    assert (aa[(:, 0)] == pytest.approx([0, 1, 2, 3]))\n    assert (aa.shape == (4, 10))\n    ab = gs.node_features([4, 5], 'B')\n    assert (ab.shape == (2, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 5]))\n    with pytest.raises(ValueError):\n        ab = gs.node_features([1, 5])\n    with pytest.raises(ValueError):\n        ab = gs.node_features([4, 5], 'A')\n    ab = gs.node_features([4, None, None], 'B')\n    assert (ab.shape == (3, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 0, 0]))\n    g = example_hin_1_nx()\n    nf = [(v, (np.ones((5 if (vdata['label'] == 'A') else 10)) * float(v))) for (v, vdata) in g.nodes(data=True)]\n    gs = StellarGraph.from_networkx(g, node_features=nf)\n    aa = gs.node_features([0, 1, 2, 3], 'A')\n    assert (aa[(:, 0)] == pytest.approx([0, 1, 2, 3]))\n    assert (aa.shape == (4, 5))\n    ab = gs.node_features([4, 5], 'B')\n    assert (ab.shape == (2, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 5]))", "masked_code": "def test_feature_conversion_from_iterator():\n    g = example_graph_nx()\n    node_features = [(v, (np.ones(10) * float(v))) for v in list(g)]\n    gs = StellarGraph.from_networkx(g, node_features=node_features)\n    aa = gs.node_features([1, 2, 3, 4])\n    assert (aa[(:, 0)] == pytest.approx([1, 2, 3, 4]))\n    aa = gs.node_features([1, 2, None, None])\n    assert (aa[(:, 0)] == pytest.approx([1, 2, 0, 0]))\n    adj_expected = np.array([[0, 1, 0, 1], [1, 0, 1, 1], [0, 1, 0, 0], [1, 1, 0, 0]])\n    A = gs.to_adjacency_matrix()\n    assert (A.dtype == 'float32')\n    np.testing.assert_allclose(A.toarray(), adj_expected)\n    A = gs.to_adjacency_matrix(nodes=[3, 2])\n    assert (A.dtype == 'float32')\n    np.testing.assert_allclose(A.toarray(), adj_expected[[2, 1]][(:, [2, 1])])\n    g = example_hin_1_nx()\n    nf = {t: [(v, (np.ones(10) * float(v))) for (v, vdata) in g.nodes(data=True) if (vdata['label'] == t)] for t in ['A', 'B']}\n    gs = StellarGraph.from_networkx(g, node_features=nf)\n    aa = gs.node_features([0, 1, 2, 3], 'A')\n    assert (aa[(:, 0)] == pytest.approx([0, 1, 2, 3]))\n    assert (aa.shape == (4, 10))\n    ab = gs.node_features([4, 5], 'B')\n    assert (ab.shape == (2, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 5]))\n    with pytest.raises(ValueError):\n        ab = gs.node_features([1, 5])\n    with pytest.raises(ValueError):\n        ab = gs.node_features([4, 5], 'A')\n    ab = gs.node_features([4, None, None], 'B')\n    assert (ab.shape == '???')\n    assert (ab[(:, 0)] == pytest.approx([4, 0, 0]))\n    g = example_hin_1_nx()\n    nf = [(v, (np.ones((5 if (vdata['label'] == 'A') else 10)) * float(v))) for (v, vdata) in g.nodes(data=True)]\n    gs = StellarGraph.from_networkx(g, node_features=nf)\n    aa = gs.node_features([0, 1, 2, 3], 'A')\n    assert (aa[(:, 0)] == pytest.approx([0, 1, 2, 3]))\n    assert (aa.shape == (4, 5))\n    ab = gs.node_features([4, 5], 'B')\n    assert (ab.shape == (2, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 5]))", "ground_truth": "(3, 10)", "quality_analysis": {"complexity_score": 6, "left_complexity": 2, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_108", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_feature_conversion_from_iterator", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "def test_feature_conversion_from_iterator():\n    g = example_graph_nx()\n    node_features = [(v, (np.ones(10) * float(v))) for v in list(g)]\n    gs = StellarGraph.from_networkx(g, node_features=node_features)\n    aa = gs.node_features([1, 2, 3, 4])\n    assert (aa[(:, 0)] == pytest.approx([1, 2, 3, 4]))\n    aa = gs.node_features([1, 2, None, None])\n    assert (aa[(:, 0)] == pytest.approx([1, 2, 0, 0]))\n    adj_expected = np.array([[0, 1, 0, 1], [1, 0, 1, 1], [0, 1, 0, 0], [1, 1, 0, 0]])\n    A = gs.to_adjacency_matrix()\n    assert (A.dtype == 'float32')\n    np.testing.assert_allclose(A.toarray(), adj_expected)\n    A = gs.to_adjacency_matrix(nodes=[3, 2])\n    assert (A.dtype == 'float32')\n    np.testing.assert_allclose(A.toarray(), adj_expected[[2, 1]][(:, [2, 1])])\n    g = example_hin_1_nx()\n    nf = {t: [(v, (np.ones(10) * float(v))) for (v, vdata) in g.nodes(data=True) if (vdata['label'] == t)] for t in ['A', 'B']}\n    gs = StellarGraph.from_networkx(g, node_features=nf)\n    aa = gs.node_features([0, 1, 2, 3], 'A')\n    assert (aa[(:, 0)] == pytest.approx([0, 1, 2, 3]))\n    assert (aa.shape == (4, 10))\n    ab = gs.node_features([4, 5], 'B')\n    assert (ab.shape == (2, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 5]))\n    with pytest.raises(ValueError):\n        ab = gs.node_features([1, 5])\n    with pytest.raises(ValueError):\n        ab = gs.node_features([4, 5], 'A')\n    ab = gs.node_features([4, None, None], 'B')\n    assert (ab.shape == (3, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 0, 0]))\n    g = example_hin_1_nx()\n    nf = [(v, (np.ones((5 if (vdata['label'] == 'A') else 10)) * float(v))) for (v, vdata) in g.nodes(data=True)]\n    gs = StellarGraph.from_networkx(g, node_features=nf)\n    aa = gs.node_features([0, 1, 2, 3], 'A')\n    assert (aa[(:, 0)] == pytest.approx([0, 1, 2, 3]))\n    assert (aa.shape == (4, 5))\n    ab = gs.node_features([4, 5], 'B')\n    assert (ab.shape == (2, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 5]))", "masked_code": "def test_feature_conversion_from_iterator():\n    g = example_graph_nx()\n    node_features = [(v, (np.ones(10) * float(v))) for v in list(g)]\n    gs = StellarGraph.from_networkx(g, node_features=node_features)\n    aa = gs.node_features([1, 2, 3, 4])\n    assert (aa[(:, 0)] == pytest.approx([1, 2, 3, 4]))\n    aa = gs.node_features([1, 2, None, None])\n    assert (aa[(:, 0)] == pytest.approx([1, 2, 0, 0]))\n    adj_expected = np.array([[0, 1, 0, 1], [1, 0, 1, 1], [0, 1, 0, 0], [1, 1, 0, 0]])\n    A = gs.to_adjacency_matrix()\n    assert (A.dtype == 'float32')\n    np.testing.assert_allclose(A.toarray(), adj_expected)\n    A = gs.to_adjacency_matrix(nodes=[3, 2])\n    assert (A.dtype == 'float32')\n    np.testing.assert_allclose(A.toarray(), adj_expected[[2, 1]][(:, [2, 1])])\n    g = example_hin_1_nx()\n    nf = {t: [(v, (np.ones(10) * float(v))) for (v, vdata) in g.nodes(data=True) if (vdata['label'] == t)] for t in ['A', 'B']}\n    gs = StellarGraph.from_networkx(g, node_features=nf)\n    aa = gs.node_features([0, 1, 2, 3], 'A')\n    assert (aa[(:, 0)] == pytest.approx([0, 1, 2, 3]))\n    assert (aa.shape == (4, 10))\n    ab = gs.node_features([4, 5], 'B')\n    assert (ab.shape == (2, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 5]))\n    with pytest.raises(ValueError):\n        ab = gs.node_features([1, 5])\n    with pytest.raises(ValueError):\n        ab = gs.node_features([4, 5], 'A')\n    ab = gs.node_features([4, None, None], 'B')\n    assert (ab.shape == (3, 10))\n    assert (ab[(:, 0)] == '???')\n    g = example_hin_1_nx()\n    nf = [(v, (np.ones((5 if (vdata['label'] == 'A') else 10)) * float(v))) for (v, vdata) in g.nodes(data=True)]\n    gs = StellarGraph.from_networkx(g, node_features=nf)\n    aa = gs.node_features([0, 1, 2, 3], 'A')\n    assert (aa[(:, 0)] == pytest.approx([0, 1, 2, 3]))\n    assert (aa.shape == (4, 5))\n    ab = gs.node_features([4, 5], 'B')\n    assert (ab.shape == (2, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 5]))", "ground_truth": "pytest.approx([4, 0, 0])", "quality_analysis": {"complexity_score": 15, "left_complexity": 7, "right_complexity": 8, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_109", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_feature_conversion_from_iterator", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "def test_feature_conversion_from_iterator():\n    g = example_graph_nx()\n    node_features = [(v, (np.ones(10) * float(v))) for v in list(g)]\n    gs = StellarGraph.from_networkx(g, node_features=node_features)\n    aa = gs.node_features([1, 2, 3, 4])\n    assert (aa[(:, 0)] == pytest.approx([1, 2, 3, 4]))\n    aa = gs.node_features([1, 2, None, None])\n    assert (aa[(:, 0)] == pytest.approx([1, 2, 0, 0]))\n    adj_expected = np.array([[0, 1, 0, 1], [1, 0, 1, 1], [0, 1, 0, 0], [1, 1, 0, 0]])\n    A = gs.to_adjacency_matrix()\n    assert (A.dtype == 'float32')\n    np.testing.assert_allclose(A.toarray(), adj_expected)\n    A = gs.to_adjacency_matrix(nodes=[3, 2])\n    assert (A.dtype == 'float32')\n    np.testing.assert_allclose(A.toarray(), adj_expected[[2, 1]][(:, [2, 1])])\n    g = example_hin_1_nx()\n    nf = {t: [(v, (np.ones(10) * float(v))) for (v, vdata) in g.nodes(data=True) if (vdata['label'] == t)] for t in ['A', 'B']}\n    gs = StellarGraph.from_networkx(g, node_features=nf)\n    aa = gs.node_features([0, 1, 2, 3], 'A')\n    assert (aa[(:, 0)] == pytest.approx([0, 1, 2, 3]))\n    assert (aa.shape == (4, 10))\n    ab = gs.node_features([4, 5], 'B')\n    assert (ab.shape == (2, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 5]))\n    with pytest.raises(ValueError):\n        ab = gs.node_features([1, 5])\n    with pytest.raises(ValueError):\n        ab = gs.node_features([4, 5], 'A')\n    ab = gs.node_features([4, None, None], 'B')\n    assert (ab.shape == (3, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 0, 0]))\n    g = example_hin_1_nx()\n    nf = [(v, (np.ones((5 if (vdata['label'] == 'A') else 10)) * float(v))) for (v, vdata) in g.nodes(data=True)]\n    gs = StellarGraph.from_networkx(g, node_features=nf)\n    aa = gs.node_features([0, 1, 2, 3], 'A')\n    assert (aa[(:, 0)] == pytest.approx([0, 1, 2, 3]))\n    assert (aa.shape == (4, 5))\n    ab = gs.node_features([4, 5], 'B')\n    assert (ab.shape == (2, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 5]))", "masked_code": "def test_feature_conversion_from_iterator():\n    g = example_graph_nx()\n    node_features = [(v, (np.ones(10) * float(v))) for v in list(g)]\n    gs = StellarGraph.from_networkx(g, node_features=node_features)\n    aa = gs.node_features([1, 2, 3, 4])\n    assert (aa[(:, 0)] == pytest.approx([1, 2, 3, 4]))\n    aa = gs.node_features([1, 2, None, None])\n    assert (aa[(:, 0)] == pytest.approx([1, 2, 0, 0]))\n    adj_expected = np.array([[0, 1, 0, 1], [1, 0, 1, 1], [0, 1, 0, 0], [1, 1, 0, 0]])\n    A = gs.to_adjacency_matrix()\n    assert (A.dtype == 'float32')\n    np.testing.assert_allclose(A.toarray(), adj_expected)\n    A = gs.to_adjacency_matrix(nodes=[3, 2])\n    assert (A.dtype == 'float32')\n    np.testing.assert_allclose(A.toarray(), adj_expected[[2, 1]][(:, [2, 1])])\n    g = example_hin_1_nx()\n    nf = {t: [(v, (np.ones(10) * float(v))) for (v, vdata) in g.nodes(data=True) if (vdata['label'] == t)] for t in ['A', 'B']}\n    gs = StellarGraph.from_networkx(g, node_features=nf)\n    aa = gs.node_features([0, 1, 2, 3], 'A')\n    assert (aa[(:, 0)] == pytest.approx([0, 1, 2, 3]))\n    assert (aa.shape == (4, 10))\n    ab = gs.node_features([4, 5], 'B')\n    assert (ab.shape == (2, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 5]))\n    with pytest.raises(ValueError):\n        ab = gs.node_features([1, 5])\n    with pytest.raises(ValueError):\n        ab = gs.node_features([4, 5], 'A')\n    ab = gs.node_features([4, None, None], 'B')\n    assert (ab.shape == (3, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 0, 0]))\n    g = example_hin_1_nx()\n    nf = [(v, (np.ones((5 if (vdata['label'] == 'A') else 10)) * float(v))) for (v, vdata) in g.nodes(data=True)]\n    gs = StellarGraph.from_networkx(g, node_features=nf)\n    aa = gs.node_features([0, 1, 2, 3], 'A')\n    assert (aa[(:, 0)] == '???')\n    assert (aa.shape == (4, 5))\n    ab = gs.node_features([4, 5], 'B')\n    assert (ab.shape == (2, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 5]))", "ground_truth": "pytest.approx([0, 1, 2, 3])", "quality_analysis": {"complexity_score": 16, "left_complexity": 7, "right_complexity": 9, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_110", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_feature_conversion_from_iterator", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "def test_feature_conversion_from_iterator():\n    g = example_graph_nx()\n    node_features = [(v, (np.ones(10) * float(v))) for v in list(g)]\n    gs = StellarGraph.from_networkx(g, node_features=node_features)\n    aa = gs.node_features([1, 2, 3, 4])\n    assert (aa[(:, 0)] == pytest.approx([1, 2, 3, 4]))\n    aa = gs.node_features([1, 2, None, None])\n    assert (aa[(:, 0)] == pytest.approx([1, 2, 0, 0]))\n    adj_expected = np.array([[0, 1, 0, 1], [1, 0, 1, 1], [0, 1, 0, 0], [1, 1, 0, 0]])\n    A = gs.to_adjacency_matrix()\n    assert (A.dtype == 'float32')\n    np.testing.assert_allclose(A.toarray(), adj_expected)\n    A = gs.to_adjacency_matrix(nodes=[3, 2])\n    assert (A.dtype == 'float32')\n    np.testing.assert_allclose(A.toarray(), adj_expected[[2, 1]][(:, [2, 1])])\n    g = example_hin_1_nx()\n    nf = {t: [(v, (np.ones(10) * float(v))) for (v, vdata) in g.nodes(data=True) if (vdata['label'] == t)] for t in ['A', 'B']}\n    gs = StellarGraph.from_networkx(g, node_features=nf)\n    aa = gs.node_features([0, 1, 2, 3], 'A')\n    assert (aa[(:, 0)] == pytest.approx([0, 1, 2, 3]))\n    assert (aa.shape == (4, 10))\n    ab = gs.node_features([4, 5], 'B')\n    assert (ab.shape == (2, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 5]))\n    with pytest.raises(ValueError):\n        ab = gs.node_features([1, 5])\n    with pytest.raises(ValueError):\n        ab = gs.node_features([4, 5], 'A')\n    ab = gs.node_features([4, None, None], 'B')\n    assert (ab.shape == (3, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 0, 0]))\n    g = example_hin_1_nx()\n    nf = [(v, (np.ones((5 if (vdata['label'] == 'A') else 10)) * float(v))) for (v, vdata) in g.nodes(data=True)]\n    gs = StellarGraph.from_networkx(g, node_features=nf)\n    aa = gs.node_features([0, 1, 2, 3], 'A')\n    assert (aa[(:, 0)] == pytest.approx([0, 1, 2, 3]))\n    assert (aa.shape == (4, 5))\n    ab = gs.node_features([4, 5], 'B')\n    assert (ab.shape == (2, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 5]))", "masked_code": "def test_feature_conversion_from_iterator():\n    g = example_graph_nx()\n    node_features = [(v, (np.ones(10) * float(v))) for v in list(g)]\n    gs = StellarGraph.from_networkx(g, node_features=node_features)\n    aa = gs.node_features([1, 2, 3, 4])\n    assert (aa[(:, 0)] == pytest.approx([1, 2, 3, 4]))\n    aa = gs.node_features([1, 2, None, None])\n    assert (aa[(:, 0)] == pytest.approx([1, 2, 0, 0]))\n    adj_expected = np.array([[0, 1, 0, 1], [1, 0, 1, 1], [0, 1, 0, 0], [1, 1, 0, 0]])\n    A = gs.to_adjacency_matrix()\n    assert (A.dtype == 'float32')\n    np.testing.assert_allclose(A.toarray(), adj_expected)\n    A = gs.to_adjacency_matrix(nodes=[3, 2])\n    assert (A.dtype == 'float32')\n    np.testing.assert_allclose(A.toarray(), adj_expected[[2, 1]][(:, [2, 1])])\n    g = example_hin_1_nx()\n    nf = {t: [(v, (np.ones(10) * float(v))) for (v, vdata) in g.nodes(data=True) if (vdata['label'] == t)] for t in ['A', 'B']}\n    gs = StellarGraph.from_networkx(g, node_features=nf)\n    aa = gs.node_features([0, 1, 2, 3], 'A')\n    assert (aa[(:, 0)] == pytest.approx([0, 1, 2, 3]))\n    assert (aa.shape == (4, 10))\n    ab = gs.node_features([4, 5], 'B')\n    assert (ab.shape == (2, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 5]))\n    with pytest.raises(ValueError):\n        ab = gs.node_features([1, 5])\n    with pytest.raises(ValueError):\n        ab = gs.node_features([4, 5], 'A')\n    ab = gs.node_features([4, None, None], 'B')\n    assert (ab.shape == (3, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 0, 0]))\n    g = example_hin_1_nx()\n    nf = [(v, (np.ones((5 if (vdata['label'] == 'A') else 10)) * float(v))) for (v, vdata) in g.nodes(data=True)]\n    gs = StellarGraph.from_networkx(g, node_features=nf)\n    aa = gs.node_features([0, 1, 2, 3], 'A')\n    assert (aa[(:, 0)] == pytest.approx([0, 1, 2, 3]))\n    assert (aa.shape == '???')\n    ab = gs.node_features([4, 5], 'B')\n    assert (ab.shape == (2, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 5]))", "ground_truth": "(4, 5)", "quality_analysis": {"complexity_score": 6, "left_complexity": 2, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_111", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_feature_conversion_from_iterator", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "def test_feature_conversion_from_iterator():\n    g = example_graph_nx()\n    node_features = [(v, (np.ones(10) * float(v))) for v in list(g)]\n    gs = StellarGraph.from_networkx(g, node_features=node_features)\n    aa = gs.node_features([1, 2, 3, 4])\n    assert (aa[(:, 0)] == pytest.approx([1, 2, 3, 4]))\n    aa = gs.node_features([1, 2, None, None])\n    assert (aa[(:, 0)] == pytest.approx([1, 2, 0, 0]))\n    adj_expected = np.array([[0, 1, 0, 1], [1, 0, 1, 1], [0, 1, 0, 0], [1, 1, 0, 0]])\n    A = gs.to_adjacency_matrix()\n    assert (A.dtype == 'float32')\n    np.testing.assert_allclose(A.toarray(), adj_expected)\n    A = gs.to_adjacency_matrix(nodes=[3, 2])\n    assert (A.dtype == 'float32')\n    np.testing.assert_allclose(A.toarray(), adj_expected[[2, 1]][(:, [2, 1])])\n    g = example_hin_1_nx()\n    nf = {t: [(v, (np.ones(10) * float(v))) for (v, vdata) in g.nodes(data=True) if (vdata['label'] == t)] for t in ['A', 'B']}\n    gs = StellarGraph.from_networkx(g, node_features=nf)\n    aa = gs.node_features([0, 1, 2, 3], 'A')\n    assert (aa[(:, 0)] == pytest.approx([0, 1, 2, 3]))\n    assert (aa.shape == (4, 10))\n    ab = gs.node_features([4, 5], 'B')\n    assert (ab.shape == (2, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 5]))\n    with pytest.raises(ValueError):\n        ab = gs.node_features([1, 5])\n    with pytest.raises(ValueError):\n        ab = gs.node_features([4, 5], 'A')\n    ab = gs.node_features([4, None, None], 'B')\n    assert (ab.shape == (3, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 0, 0]))\n    g = example_hin_1_nx()\n    nf = [(v, (np.ones((5 if (vdata['label'] == 'A') else 10)) * float(v))) for (v, vdata) in g.nodes(data=True)]\n    gs = StellarGraph.from_networkx(g, node_features=nf)\n    aa = gs.node_features([0, 1, 2, 3], 'A')\n    assert (aa[(:, 0)] == pytest.approx([0, 1, 2, 3]))\n    assert (aa.shape == (4, 5))\n    ab = gs.node_features([4, 5], 'B')\n    assert (ab.shape == (2, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 5]))", "masked_code": "def test_feature_conversion_from_iterator():\n    g = example_graph_nx()\n    node_features = [(v, (np.ones(10) * float(v))) for v in list(g)]\n    gs = StellarGraph.from_networkx(g, node_features=node_features)\n    aa = gs.node_features([1, 2, 3, 4])\n    assert (aa[(:, 0)] == pytest.approx([1, 2, 3, 4]))\n    aa = gs.node_features([1, 2, None, None])\n    assert (aa[(:, 0)] == pytest.approx([1, 2, 0, 0]))\n    adj_expected = np.array([[0, 1, 0, 1], [1, 0, 1, 1], [0, 1, 0, 0], [1, 1, 0, 0]])\n    A = gs.to_adjacency_matrix()\n    assert (A.dtype == 'float32')\n    np.testing.assert_allclose(A.toarray(), adj_expected)\n    A = gs.to_adjacency_matrix(nodes=[3, 2])\n    assert (A.dtype == 'float32')\n    np.testing.assert_allclose(A.toarray(), adj_expected[[2, 1]][(:, [2, 1])])\n    g = example_hin_1_nx()\n    nf = {t: [(v, (np.ones(10) * float(v))) for (v, vdata) in g.nodes(data=True) if (vdata['label'] == t)] for t in ['A', 'B']}\n    gs = StellarGraph.from_networkx(g, node_features=nf)\n    aa = gs.node_features([0, 1, 2, 3], 'A')\n    assert (aa[(:, 0)] == pytest.approx([0, 1, 2, 3]))\n    assert (aa.shape == (4, 10))\n    ab = gs.node_features([4, 5], 'B')\n    assert (ab.shape == (2, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 5]))\n    with pytest.raises(ValueError):\n        ab = gs.node_features([1, 5])\n    with pytest.raises(ValueError):\n        ab = gs.node_features([4, 5], 'A')\n    ab = gs.node_features([4, None, None], 'B')\n    assert (ab.shape == (3, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 0, 0]))\n    g = example_hin_1_nx()\n    nf = [(v, (np.ones((5 if (vdata['label'] == 'A') else 10)) * float(v))) for (v, vdata) in g.nodes(data=True)]\n    gs = StellarGraph.from_networkx(g, node_features=nf)\n    aa = gs.node_features([0, 1, 2, 3], 'A')\n    assert (aa[(:, 0)] == pytest.approx([0, 1, 2, 3]))\n    assert (aa.shape == (4, 5))\n    ab = gs.node_features([4, 5], 'B')\n    assert (ab.shape == '???')\n    assert (ab[(:, 0)] == pytest.approx([4, 5]))", "ground_truth": "(2, 10)", "quality_analysis": {"complexity_score": 6, "left_complexity": 2, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_112", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_feature_conversion_from_iterator", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "def test_feature_conversion_from_iterator():\n    g = example_graph_nx()\n    node_features = [(v, (np.ones(10) * float(v))) for v in list(g)]\n    gs = StellarGraph.from_networkx(g, node_features=node_features)\n    aa = gs.node_features([1, 2, 3, 4])\n    assert (aa[(:, 0)] == pytest.approx([1, 2, 3, 4]))\n    aa = gs.node_features([1, 2, None, None])\n    assert (aa[(:, 0)] == pytest.approx([1, 2, 0, 0]))\n    adj_expected = np.array([[0, 1, 0, 1], [1, 0, 1, 1], [0, 1, 0, 0], [1, 1, 0, 0]])\n    A = gs.to_adjacency_matrix()\n    assert (A.dtype == 'float32')\n    np.testing.assert_allclose(A.toarray(), adj_expected)\n    A = gs.to_adjacency_matrix(nodes=[3, 2])\n    assert (A.dtype == 'float32')\n    np.testing.assert_allclose(A.toarray(), adj_expected[[2, 1]][(:, [2, 1])])\n    g = example_hin_1_nx()\n    nf = {t: [(v, (np.ones(10) * float(v))) for (v, vdata) in g.nodes(data=True) if (vdata['label'] == t)] for t in ['A', 'B']}\n    gs = StellarGraph.from_networkx(g, node_features=nf)\n    aa = gs.node_features([0, 1, 2, 3], 'A')\n    assert (aa[(:, 0)] == pytest.approx([0, 1, 2, 3]))\n    assert (aa.shape == (4, 10))\n    ab = gs.node_features([4, 5], 'B')\n    assert (ab.shape == (2, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 5]))\n    with pytest.raises(ValueError):\n        ab = gs.node_features([1, 5])\n    with pytest.raises(ValueError):\n        ab = gs.node_features([4, 5], 'A')\n    ab = gs.node_features([4, None, None], 'B')\n    assert (ab.shape == (3, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 0, 0]))\n    g = example_hin_1_nx()\n    nf = [(v, (np.ones((5 if (vdata['label'] == 'A') else 10)) * float(v))) for (v, vdata) in g.nodes(data=True)]\n    gs = StellarGraph.from_networkx(g, node_features=nf)\n    aa = gs.node_features([0, 1, 2, 3], 'A')\n    assert (aa[(:, 0)] == pytest.approx([0, 1, 2, 3]))\n    assert (aa.shape == (4, 5))\n    ab = gs.node_features([4, 5], 'B')\n    assert (ab.shape == (2, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 5]))", "masked_code": "def test_feature_conversion_from_iterator():\n    g = example_graph_nx()\n    node_features = [(v, (np.ones(10) * float(v))) for v in list(g)]\n    gs = StellarGraph.from_networkx(g, node_features=node_features)\n    aa = gs.node_features([1, 2, 3, 4])\n    assert (aa[(:, 0)] == pytest.approx([1, 2, 3, 4]))\n    aa = gs.node_features([1, 2, None, None])\n    assert (aa[(:, 0)] == pytest.approx([1, 2, 0, 0]))\n    adj_expected = np.array([[0, 1, 0, 1], [1, 0, 1, 1], [0, 1, 0, 0], [1, 1, 0, 0]])\n    A = gs.to_adjacency_matrix()\n    assert (A.dtype == 'float32')\n    np.testing.assert_allclose(A.toarray(), adj_expected)\n    A = gs.to_adjacency_matrix(nodes=[3, 2])\n    assert (A.dtype == 'float32')\n    np.testing.assert_allclose(A.toarray(), adj_expected[[2, 1]][(:, [2, 1])])\n    g = example_hin_1_nx()\n    nf = {t: [(v, (np.ones(10) * float(v))) for (v, vdata) in g.nodes(data=True) if (vdata['label'] == t)] for t in ['A', 'B']}\n    gs = StellarGraph.from_networkx(g, node_features=nf)\n    aa = gs.node_features([0, 1, 2, 3], 'A')\n    assert (aa[(:, 0)] == pytest.approx([0, 1, 2, 3]))\n    assert (aa.shape == (4, 10))\n    ab = gs.node_features([4, 5], 'B')\n    assert (ab.shape == (2, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 5]))\n    with pytest.raises(ValueError):\n        ab = gs.node_features([1, 5])\n    with pytest.raises(ValueError):\n        ab = gs.node_features([4, 5], 'A')\n    ab = gs.node_features([4, None, None], 'B')\n    assert (ab.shape == (3, 10))\n    assert (ab[(:, 0)] == pytest.approx([4, 0, 0]))\n    g = example_hin_1_nx()\n    nf = [(v, (np.ones((5 if (vdata['label'] == 'A') else 10)) * float(v))) for (v, vdata) in g.nodes(data=True)]\n    gs = StellarGraph.from_networkx(g, node_features=nf)\n    aa = gs.node_features([0, 1, 2, 3], 'A')\n    assert (aa[(:, 0)] == pytest.approx([0, 1, 2, 3]))\n    assert (aa.shape == (4, 5))\n    ab = gs.node_features([4, 5], 'B')\n    assert (ab.shape == (2, 10))\n    assert (ab[(:, 0)] == '???')", "ground_truth": "pytest.approx([4, 5])", "quality_analysis": {"complexity_score": 14, "left_complexity": 7, "right_complexity": 7, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_113", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_edges_include_edge_type", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "@pytest.mark.parametrize('use_ilocs', [True, False])\ndef test_edges_include_edge_type(use_ilocs):\n    g = example_hin_1(reverse_order=True)\n    r = {(src, dst, 'R') for (src, dst) in [(0, 4), (1, 4), (1, 5), (2, 4), (3, 5)]}\n    f = {(4, 5, 'F')}\n    expected = (r | f)\n    if use_ilocs:\n        expected = {(tuple(g.node_ids_to_ilocs(x[:2])) + tuple(g.edge_type_names_to_ilocs([x[2]]))) for x in expected}\n    expected = normalize_edges(expected, directed=False)\n    assert (normalize_edges(g.edges(include_edge_type=True, use_ilocs=use_ilocs), directed=False) == expected)", "masked_code": "@pytest.mark.parametrize('use_ilocs', [True, False])\ndef test_edges_include_edge_type(use_ilocs):\n    g = example_hin_1(reverse_order=True)\n    r = {(src, dst, 'R') for (src, dst) in [(0, 4), (1, 4), (1, 5), (2, 4), (3, 5)]}\n    f = {(4, 5, 'F')}\n    expected = (r | f)\n    if use_ilocs:\n        expected = {(tuple(g.node_ids_to_ilocs(x[:2])) + tuple(g.edge_type_names_to_ilocs([x[2]]))) for x in expected}\n    expected = normalize_edges(expected, directed=False)\n    assert (normalize_edges(g.edges(include_edge_type=True, use_ilocs=use_ilocs), directed=False) == '???')", "ground_truth": "expected", "quality_analysis": {"complexity_score": 7, "left_complexity": 6, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_114", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_to_networkx_deprecation", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "def test_to_networkx_deprecation(line_graph):\n    with pytest.warns(None) as record:\n        line_graph.to_networkx(node_type_name='n', edge_type_name='e', edge_weight_label='w', feature_name='f')\n    assert (len(record) == 4)\n    assert ('node_type_name' in str(record.pop(DeprecationWarning).message))\n    assert ('edge_type_name' in str(record.pop(DeprecationWarning).message))\n    assert ('edge_weight_label' in str(record.pop(DeprecationWarning).message))\n    assert ('feature_name' in str(record.pop(DeprecationWarning).message))", "masked_code": "def test_to_networkx_deprecation(line_graph):\n    with pytest.warns(None) as record:\n        line_graph.to_networkx(node_type_name='n', edge_type_name='e', edge_weight_label='w', feature_name='f')\n    assert (len(record) == '???')\n    assert ('node_type_name' in str(record.pop(DeprecationWarning).message))\n    assert ('edge_type_name' in str(record.pop(DeprecationWarning).message))\n    assert ('edge_weight_label' in str(record.pop(DeprecationWarning).message))\n    assert ('feature_name' in str(record.pop(DeprecationWarning).message))", "ground_truth": "4", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_115", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_isolated_node_neighbor_methods", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "@pytest.mark.parametrize('use_ilocs', [True, False])\n@pytest.mark.parametrize('is_directed', [False, True])\ndef test_isolated_node_neighbor_methods(is_directed, use_ilocs):\n    cls = (StellarDiGraph if is_directed else StellarGraph)\n    graph = cls(nodes=pd.DataFrame(index=[1]), edges=pd.DataFrame(columns=['source', 'target']))\n    node = (graph.node_ids_to_ilocs([1])[0] if use_ilocs else 1)\n    assert (graph.neighbors(node, use_ilocs=use_ilocs) == [])\n    assert (graph.in_nodes(node, use_ilocs=use_ilocs) == [])\n    assert (graph.out_nodes(node, use_ilocs=use_ilocs) == [])", "masked_code": "@pytest.mark.parametrize('use_ilocs', [True, False])\n@pytest.mark.parametrize('is_directed', [False, True])\ndef test_isolated_node_neighbor_methods(is_directed, use_ilocs):\n    cls = (StellarDiGraph if is_directed else StellarGraph)\n    graph = cls(nodes=pd.DataFrame(index=[1]), edges=pd.DataFrame(columns=['source', 'target']))\n    node = (graph.node_ids_to_ilocs([1])[0] if use_ilocs else 1)\n    assert (graph.neighbors(node, use_ilocs=use_ilocs) == '???')\n    assert (graph.in_nodes(node, use_ilocs=use_ilocs) == [])\n    assert (graph.out_nodes(node, use_ilocs=use_ilocs) == [])", "ground_truth": "[]", "quality_analysis": {"complexity_score": 6, "left_complexity": 4, "right_complexity": 2, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_116", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_isolated_node_neighbor_methods", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "@pytest.mark.parametrize('use_ilocs', [True, False])\n@pytest.mark.parametrize('is_directed', [False, True])\ndef test_isolated_node_neighbor_methods(is_directed, use_ilocs):\n    cls = (StellarDiGraph if is_directed else StellarGraph)\n    graph = cls(nodes=pd.DataFrame(index=[1]), edges=pd.DataFrame(columns=['source', 'target']))\n    node = (graph.node_ids_to_ilocs([1])[0] if use_ilocs else 1)\n    assert (graph.neighbors(node, use_ilocs=use_ilocs) == [])\n    assert (graph.in_nodes(node, use_ilocs=use_ilocs) == [])\n    assert (graph.out_nodes(node, use_ilocs=use_ilocs) == [])", "masked_code": "@pytest.mark.parametrize('use_ilocs', [True, False])\n@pytest.mark.parametrize('is_directed', [False, True])\ndef test_isolated_node_neighbor_methods(is_directed, use_ilocs):\n    cls = (StellarDiGraph if is_directed else StellarGraph)\n    graph = cls(nodes=pd.DataFrame(index=[1]), edges=pd.DataFrame(columns=['source', 'target']))\n    node = (graph.node_ids_to_ilocs([1])[0] if use_ilocs else 1)\n    assert (graph.neighbors(node, use_ilocs=use_ilocs) == [])\n    assert (graph.in_nodes(node, use_ilocs=use_ilocs) == '???')\n    assert (graph.out_nodes(node, use_ilocs=use_ilocs) == [])", "ground_truth": "[]", "quality_analysis": {"complexity_score": 6, "left_complexity": 4, "right_complexity": 2, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_117", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_isolated_node_neighbor_methods", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "@pytest.mark.parametrize('use_ilocs', [True, False])\n@pytest.mark.parametrize('is_directed', [False, True])\ndef test_isolated_node_neighbor_methods(is_directed, use_ilocs):\n    cls = (StellarDiGraph if is_directed else StellarGraph)\n    graph = cls(nodes=pd.DataFrame(index=[1]), edges=pd.DataFrame(columns=['source', 'target']))\n    node = (graph.node_ids_to_ilocs([1])[0] if use_ilocs else 1)\n    assert (graph.neighbors(node, use_ilocs=use_ilocs) == [])\n    assert (graph.in_nodes(node, use_ilocs=use_ilocs) == [])\n    assert (graph.out_nodes(node, use_ilocs=use_ilocs) == [])", "masked_code": "@pytest.mark.parametrize('use_ilocs', [True, False])\n@pytest.mark.parametrize('is_directed', [False, True])\ndef test_isolated_node_neighbor_methods(is_directed, use_ilocs):\n    cls = (StellarDiGraph if is_directed else StellarGraph)\n    graph = cls(nodes=pd.DataFrame(index=[1]), edges=pd.DataFrame(columns=['source', 'target']))\n    node = (graph.node_ids_to_ilocs([1])[0] if use_ilocs else 1)\n    assert (graph.neighbors(node, use_ilocs=use_ilocs) == [])\n    assert (graph.in_nodes(node, use_ilocs=use_ilocs) == [])\n    assert (graph.out_nodes(node, use_ilocs=use_ilocs) == '???')", "ground_truth": "[]", "quality_analysis": {"complexity_score": 6, "left_complexity": 4, "right_complexity": 2, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_118", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_info_homogeneous", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "@pytest.mark.parametrize('is_directed', [False, True])\ndef test_info_homogeneous(is_directed):\n    g = example_graph(feature_size=12, node_label='ABC', edge_label='xyz', is_directed=is_directed, edge_feature_size=34)\n    if is_directed:\n        title = 'StellarDiGraph: Directed multigraph'\n    else:\n        title = 'StellarGraph: Undirected multigraph'\n    assert (g.info() == f'''{title}\n Nodes: 4, Edges: 4\n\n Node types:\n  ABC: [4]\n    Features: float32 vector, length 12\n    Edge types: ABC-xyz->ABC\n\n Edge types:\n    ABC-xyz->ABC: [4]\n        Weights: all 1 (default)\n        Features: float32 vector, length 34''')", "masked_code": "@pytest.mark.parametrize('is_directed', [False, True])\ndef test_info_homogeneous(is_directed):\n    g = example_graph(feature_size=12, node_label='ABC', edge_label='xyz', is_directed=is_directed, edge_feature_size=34)\n    if is_directed:\n        title = 'StellarDiGraph: Directed multigraph'\n    else:\n        title = 'StellarGraph: Undirected multigraph'\n    assert (g.info() == '???')", "ground_truth": "f'''{title}\n Nodes: 4, Edges: 4\n\n Node types:\n  ABC: [4]\n    Features: float32 vector, length 12\n    Edge types: ABC-xyz->ABC\n\n Edge types:\n    ABC-xyz->ABC: [4]\n        Weights: all 1 (default)\n        Features: float32 vector, length 34'''", "quality_analysis": {"complexity_score": 3, "left_complexity": 3, "right_complexity": 0, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_119", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_info_heterogeneous", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "def test_info_heterogeneous():\n    g = example_hin_1({'A': 0, 'B': (34, 4), 'F': 0, 'R': 56}, reverse_order=True, edge_features=True)\n    assert (g.info() == 'StellarGraph: Undirected multigraph\\n Nodes: 7, Edges: 6\\n\\n Node types:\\n  A: [4]\\n    Features: none\\n    Edge types: A-R->B\\n  B: [3]\\n    Features: float32 tensor, shape (34, 4)\\n    Edge types: B-F->B, B-R->A\\n\\n Edge types:\\n    A-R->B: [5]\\n        Weights: all 1 (default)\\n        Features: float32 vector, length 56\\n    B-F->B: [1]\\n        Weights: all 10\\n        Features: none')", "masked_code": "def test_info_heterogeneous():\n    g = example_hin_1({'A': 0, 'B': (34, 4), 'F': 0, 'R': 56}, reverse_order=True, edge_features=True)\n    assert (g.info() == '???')", "ground_truth": "'StellarGraph: Undirected multigraph\\n Nodes: 7, Edges: 6\\n\\n Node types:\\n  A: [4]\\n    Features: none\\n    Edge types: A-R->B\\n  B: [3]\\n    Features: float32 tensor, shape (34, 4)\\n    Edge types: B-F->B, B-R->A\\n\\n Edge types:\\n    A-R->B: [5]\\n        Weights: all 1 (default)\\n        Features: float32 vector, length 56\\n    B-F->B: [1]\\n        Weights: all 10\\n        Features: none'", "quality_analysis": {"complexity_score": 4, "left_complexity": 3, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_120", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_info_weighted", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "def test_info_weighted(weighted_hin):\n    assert (weighted_hin.info() == 'StellarGraph: Undirected multigraph\\n Nodes: 7, Edges: 12\\n\\n Node types:\\n  A: [4]\\n    Features: none\\n    Edge types: A-R->A, A-S->A, A-T->B, A-U->A, A-U->B\\n  B: [3]\\n    Features: none\\n    Edge types: B-T->A, B-U->A\\n\\n Edge types:\\n    A-U->B: [3]\\n        Weights: range=[4, 5], mean=4.66667, std=0.57735\\n        Features: none\\n    A-T->B: [3]\\n        Weights: all 2\\n        Features: none\\n    A-U->A: [2]\\n        Weights: range=[2, 3], mean=2.5, std=0.707107\\n        Features: none\\n    A-S->A: [2]\\n        Weights: all 2\\n        Features: none\\n    A-R->A: [2]\\n        Weights: all 1 (default)\\n        Features: none')", "masked_code": "def test_info_weighted(weighted_hin):\n    assert (weighted_hin.info() == '???')", "ground_truth": "'StellarGraph: Undirected multigraph\\n Nodes: 7, Edges: 12\\n\\n Node types:\\n  A: [4]\\n    Features: none\\n    Edge types: A-R->A, A-S->A, A-T->B, A-U->A, A-U->B\\n  B: [3]\\n    Features: none\\n    Edge types: B-T->A, B-U->A\\n\\n Edge types:\\n    A-U->B: [3]\\n        Weights: range=[4, 5], mean=4.66667, std=0.57735\\n        Features: none\\n    A-T->B: [3]\\n        Weights: all 2\\n        Features: none\\n    A-U->A: [2]\\n        Weights: range=[2, 3], mean=2.5, std=0.707107\\n        Features: none\\n    A-S->A: [2]\\n        Weights: all 2\\n        Features: none\\n    A-R->A: [2]\\n        Weights: all 1 (default)\\n        Features: none'", "quality_analysis": {"complexity_score": 4, "left_complexity": 3, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_121", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_info_no_graph", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "def test_info_no_graph():\n    nodes = pd.DataFrame(np.ones((5, 1)), index=[0, 1, 2, 3, 4])\n    graph_nodes_only = StellarGraph(nodes=nodes)\n    assert (graph_nodes_only.info() == 'StellarGraph: Undirected multigraph\\n Nodes: 5, Edges: 0\\n\\n Node types:\\n  default: [5]\\n    Features: float32 vector, length 1\\n    Edge types: none\\n\\n Edge types:')\n    graph_nothing = StellarGraph(nodes={})\n    assert (graph_nothing.info() == 'StellarGraph: Undirected multigraph\\n Nodes: 0, Edges: 0\\n\\n Node types:\\n\\n Edge types:')", "masked_code": "def test_info_no_graph():\n    nodes = pd.DataFrame(np.ones((5, 1)), index=[0, 1, 2, 3, 4])\n    graph_nodes_only = StellarGraph(nodes=nodes)\n    assert (graph_nodes_only.info() == '???')\n    graph_nothing = StellarGraph(nodes={})\n    assert (graph_nothing.info() == 'StellarGraph: Undirected multigraph\\n Nodes: 0, Edges: 0\\n\\n Node types:\\n\\n Edge types:')", "ground_truth": "'StellarGraph: Undirected multigraph\\n Nodes: 5, Edges: 0\\n\\n Node types:\\n  default: [5]\\n    Features: float32 vector, length 1\\n    Edge types: none\\n\\n Edge types:'", "quality_analysis": {"complexity_score": 4, "left_complexity": 3, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_122", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_info_no_graph", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "def test_info_no_graph():\n    nodes = pd.DataFrame(np.ones((5, 1)), index=[0, 1, 2, 3, 4])\n    graph_nodes_only = StellarGraph(nodes=nodes)\n    assert (graph_nodes_only.info() == 'StellarGraph: Undirected multigraph\\n Nodes: 5, Edges: 0\\n\\n Node types:\\n  default: [5]\\n    Features: float32 vector, length 1\\n    Edge types: none\\n\\n Edge types:')\n    graph_nothing = StellarGraph(nodes={})\n    assert (graph_nothing.info() == 'StellarGraph: Undirected multigraph\\n Nodes: 0, Edges: 0\\n\\n Node types:\\n\\n Edge types:')", "masked_code": "def test_info_no_graph():\n    nodes = pd.DataFrame(np.ones((5, 1)), index=[0, 1, 2, 3, 4])\n    graph_nodes_only = StellarGraph(nodes=nodes)\n    assert (graph_nodes_only.info() == 'StellarGraph: Undirected multigraph\\n Nodes: 5, Edges: 0\\n\\n Node types:\\n  default: [5]\\n    Features: float32 vector, length 1\\n    Edge types: none\\n\\n Edge types:')\n    graph_nothing = StellarGraph(nodes={})\n    assert (graph_nothing.info() == '???')", "ground_truth": "'StellarGraph: Undirected multigraph\\n Nodes: 0, Edges: 0\\n\\n Node types:\\n\\n Edge types:'", "quality_analysis": {"complexity_score": 4, "left_complexity": 3, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_123", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_info_truncate", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "def test_info_truncate():\n    max_node_type = 21\n    max_node = (((max_node_type + 1) * (max_node_type + 1)) - 1)\n\n    def edges(i):\n        ids = range((i * i), ((i + 1) * (i + 1)))\n        return pd.DataFrame({'source': (max_node - i), 'target': ((max_node - i) - 1)}, index=ids)\n    graph = StellarGraph({f'n_{i}': pd.DataFrame(index=range((i * i), ((i + 1) * (i + 1)))) for i in range((max_node_type + 1))}, {f'e_{i}': edges(i) for i in range(23)})\n    assert (graph.info() == 'StellarGraph: Undirected multigraph\\n Nodes: 484, Edges: 529\\n\\n Node types:\\n  n_21: [43]\\n    Features: none\\n    Edge types: n_21-e_0->n_21, n_21-e_1->n_21, n_21-e_10->n_21, n_21-e_11->n_21, n_21-e_12->n_21, ... (18 more)\\n  n_20: [41]\\n    Features: none\\n    Edge types: none\\n  n_19: [39]\\n    Features: none\\n    Edge types: none\\n  n_18: [37]\\n    Features: none\\n    Edge types: none\\n  n_17: [35]\\n    Features: none\\n    Edge types: none\\n  n_16: [33]\\n    Features: none\\n    Edge types: none\\n  n_15: [31]\\n    Features: none\\n    Edge types: none\\n  n_14: [29]\\n    Features: none\\n    Edge types: none\\n  n_13: [27]\\n    Features: none\\n    Edge types: none\\n  n_12: [25]\\n    Features: none\\n    Edge types: none\\n  n_11: [23]\\n    Features: none\\n    Edge types: none\\n  n_10: [21]\\n    Features: none\\n    Edge types: none\\n  n_9: [19]\\n    Features: none\\n    Edge types: none\\n  n_8: [17]\\n    Features: none\\n    Edge types: none\\n  n_7: [15]\\n    Features: none\\n    Edge types: none\\n  n_6: [13]\\n    Features: none\\n    Edge types: none\\n  n_5: [11]\\n    Features: none\\n    Edge types: none\\n  n_4: [9]\\n    Features: none\\n    Edge types: none\\n  n_3: [7]\\n    Features: none\\n    Edge types: none\\n  n_2: [5]\\n    Features: none\\n    Edge types: none\\n  ... (2 more)\\n\\n Edge types:\\n    n_21-e_22->n_21: [45]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_21->n_21: [43]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_20->n_21: [41]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_19->n_21: [39]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_18->n_21: [37]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_17->n_21: [35]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_16->n_21: [33]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_15->n_21: [31]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_14->n_21: [29]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_13->n_21: [27]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_12->n_21: [25]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_11->n_21: [23]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_10->n_21: [21]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_9->n_21: [19]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_8->n_21: [17]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_7->n_21: [15]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_6->n_21: [13]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_5->n_21: [11]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_4->n_21: [9]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_3->n_21: [7]\\n        Weights: all 1 (default)\\n        Features: none\\n    ... (3 more)')\n    assert (graph.info(truncate=2) == 'StellarGraph: Undirected multigraph\\n Nodes: 484, Edges: 529\\n\\n Node types:\\n  n_21: [43]\\n    Features: none\\n    Edge types: n_21-e_0->n_21, n_21-e_1->n_21, ... (21 more)\\n  n_20: [41]\\n    Features: none\\n    Edge types: none\\n  ... (20 more)\\n\\n Edge types:\\n    n_21-e_22->n_21: [45]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_21->n_21: [43]\\n        Weights: all 1 (default)\\n        Features: none\\n    ... (21 more)')\n    assert (graph.info(truncate=None) == 'StellarGraph: Undirected multigraph\\n Nodes: 484, Edges: 529\\n\\n Node types:\\n  n_21: [43]\\n    Features: none\\n    Edge types: n_21-e_0->n_21, n_21-e_1->n_21, n_21-e_10->n_21, n_21-e_11->n_21, n_21-e_12->n_21, ... (18 more)\\n  n_20: [41]\\n    Features: none\\n    Edge types: none\\n  n_19: [39]\\n    Features: none\\n    Edge types: none\\n  n_18: [37]\\n    Features: none\\n    Edge types: none\\n  n_17: [35]\\n    Features: none\\n    Edge types: none\\n  n_16: [33]\\n    Features: none\\n    Edge types: none\\n  n_15: [31]\\n    Features: none\\n    Edge types: none\\n  n_14: [29]\\n    Features: none\\n    Edge types: none\\n  n_13: [27]\\n    Features: none\\n    Edge types: none\\n  n_12: [25]\\n    Features: none\\n    Edge types: none\\n  n_11: [23]\\n    Features: none\\n    Edge types: none\\n  n_10: [21]\\n    Features: none\\n    Edge types: none\\n  n_9: [19]\\n    Features: none\\n    Edge types: none\\n  n_8: [17]\\n    Features: none\\n    Edge types: none\\n  n_7: [15]\\n    Features: none\\n    Edge types: none\\n  n_6: [13]\\n    Features: none\\n    Edge types: none\\n  n_5: [11]\\n    Features: none\\n    Edge types: none\\n  n_4: [9]\\n    Features: none\\n    Edge types: none\\n  n_3: [7]\\n    Features: none\\n    Edge types: none\\n  n_2: [5]\\n    Features: none\\n    Edge types: none\\n  n_1: [3]\\n    Features: none\\n    Edge types: none\\n  n_0: [1]\\n    Features: none\\n    Edge types: none\\n\\n Edge types:\\n    n_21-e_22->n_21: [45]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_21->n_21: [43]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_20->n_21: [41]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_19->n_21: [39]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_18->n_21: [37]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_17->n_21: [35]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_16->n_21: [33]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_15->n_21: [31]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_14->n_21: [29]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_13->n_21: [27]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_12->n_21: [25]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_11->n_21: [23]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_10->n_21: [21]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_9->n_21: [19]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_8->n_21: [17]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_7->n_21: [15]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_6->n_21: [13]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_5->n_21: [11]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_4->n_21: [9]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_3->n_21: [7]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_2->n_21: [5]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_1->n_21: [3]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_0->n_21: [1]\\n        Weights: all 1 (default)\\n        Features: none')", "masked_code": "def test_info_truncate():\n    max_node_type = 21\n    max_node = (((max_node_type + 1) * (max_node_type + 1)) - 1)\n\n    def edges(i):\n        ids = range((i * i), ((i + 1) * (i + 1)))\n        return pd.DataFrame({'source': (max_node - i), 'target': ((max_node - i) - 1)}, index=ids)\n    graph = StellarGraph({f'n_{i}': pd.DataFrame(index=range((i * i), ((i + 1) * (i + 1)))) for i in range((max_node_type + 1))}, {f'e_{i}': edges(i) for i in range(23)})\n    assert (graph.info() == '???')\n    assert (graph.info(truncate=2) == 'StellarGraph: Undirected multigraph\\n Nodes: 484, Edges: 529\\n\\n Node types:\\n  n_21: [43]\\n    Features: none\\n    Edge types: n_21-e_0->n_21, n_21-e_1->n_21, ... (21 more)\\n  n_20: [41]\\n    Features: none\\n    Edge types: none\\n  ... (20 more)\\n\\n Edge types:\\n    n_21-e_22->n_21: [45]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_21->n_21: [43]\\n        Weights: all 1 (default)\\n        Features: none\\n    ... (21 more)')\n    assert (graph.info(truncate=None) == 'StellarGraph: Undirected multigraph\\n Nodes: 484, Edges: 529\\n\\n Node types:\\n  n_21: [43]\\n    Features: none\\n    Edge types: n_21-e_0->n_21, n_21-e_1->n_21, n_21-e_10->n_21, n_21-e_11->n_21, n_21-e_12->n_21, ... (18 more)\\n  n_20: [41]\\n    Features: none\\n    Edge types: none\\n  n_19: [39]\\n    Features: none\\n    Edge types: none\\n  n_18: [37]\\n    Features: none\\n    Edge types: none\\n  n_17: [35]\\n    Features: none\\n    Edge types: none\\n  n_16: [33]\\n    Features: none\\n    Edge types: none\\n  n_15: [31]\\n    Features: none\\n    Edge types: none\\n  n_14: [29]\\n    Features: none\\n    Edge types: none\\n  n_13: [27]\\n    Features: none\\n    Edge types: none\\n  n_12: [25]\\n    Features: none\\n    Edge types: none\\n  n_11: [23]\\n    Features: none\\n    Edge types: none\\n  n_10: [21]\\n    Features: none\\n    Edge types: none\\n  n_9: [19]\\n    Features: none\\n    Edge types: none\\n  n_8: [17]\\n    Features: none\\n    Edge types: none\\n  n_7: [15]\\n    Features: none\\n    Edge types: none\\n  n_6: [13]\\n    Features: none\\n    Edge types: none\\n  n_5: [11]\\n    Features: none\\n    Edge types: none\\n  n_4: [9]\\n    Features: none\\n    Edge types: none\\n  n_3: [7]\\n    Features: none\\n    Edge types: none\\n  n_2: [5]\\n    Features: none\\n    Edge types: none\\n  n_1: [3]\\n    Features: none\\n    Edge types: none\\n  n_0: [1]\\n    Features: none\\n    Edge types: none\\n\\n Edge types:\\n    n_21-e_22->n_21: [45]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_21->n_21: [43]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_20->n_21: [41]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_19->n_21: [39]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_18->n_21: [37]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_17->n_21: [35]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_16->n_21: [33]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_15->n_21: [31]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_14->n_21: [29]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_13->n_21: [27]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_12->n_21: [25]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_11->n_21: [23]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_10->n_21: [21]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_9->n_21: [19]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_8->n_21: [17]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_7->n_21: [15]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_6->n_21: [13]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_5->n_21: [11]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_4->n_21: [9]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_3->n_21: [7]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_2->n_21: [5]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_1->n_21: [3]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_0->n_21: [1]\\n        Weights: all 1 (default)\\n        Features: none')", "ground_truth": "'StellarGraph: Undirected multigraph\\n Nodes: 484, Edges: 529\\n\\n Node types:\\n  n_21: [43]\\n    Features: none\\n    Edge types: n_21-e_0->n_21, n_21-e_1->n_21, n_21-e_10->n_21, n_21-e_11->n_21, n_21-e_12->n_21, ... (18 more)\\n  n_20: [41]\\n    Features: none\\n    Edge types: none\\n  n_19: [39]\\n    Features: none\\n    Edge types: none\\n  n_18: [37]\\n    Features: none\\n    Edge types: none\\n  n_17: [35]\\n    Features: none\\n    Edge types: none\\n  n_16: [33]\\n    Features: none\\n    Edge types: none\\n  n_15: [31]\\n    Features: none\\n    Edge types: none\\n  n_14: [29]\\n    Features: none\\n    Edge types: none\\n  n_13: [27]\\n    Features: none\\n    Edge types: none\\n  n_12: [25]\\n    Features: none\\n    Edge types: none\\n  n_11: [23]\\n    Features: none\\n    Edge types: none\\n  n_10: [21]\\n    Features: none\\n    Edge types: none\\n  n_9: [19]\\n    Features: none\\n    Edge types: none\\n  n_8: [17]\\n    Features: none\\n    Edge types: none\\n  n_7: [15]\\n    Features: none\\n    Edge types: none\\n  n_6: [13]\\n    Features: none\\n    Edge types: none\\n  n_5: [11]\\n    Features: none\\n    Edge types: none\\n  n_4: [9]\\n    Features: none\\n    Edge types: none\\n  n_3: [7]\\n    Features: none\\n    Edge types: none\\n  n_2: [5]\\n    Features: none\\n    Edge types: none\\n  ... (2 more)\\n\\n Edge types:\\n    n_21-e_22->n_21: [45]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_21->n_21: [43]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_20->n_21: [41]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_19->n_21: [39]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_18->n_21: [37]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_17->n_21: [35]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_16->n_21: [33]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_15->n_21: [31]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_14->n_21: [29]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_13->n_21: [27]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_12->n_21: [25]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_11->n_21: [23]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_10->n_21: [21]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_9->n_21: [19]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_8->n_21: [17]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_7->n_21: [15]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_6->n_21: [13]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_5->n_21: [11]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_4->n_21: [9]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_3->n_21: [7]\\n        Weights: all 1 (default)\\n        Features: none\\n    ... (3 more)'", "quality_analysis": {"complexity_score": 4, "left_complexity": 3, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_124", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_info_truncate", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "def test_info_truncate():\n    max_node_type = 21\n    max_node = (((max_node_type + 1) * (max_node_type + 1)) - 1)\n\n    def edges(i):\n        ids = range((i * i), ((i + 1) * (i + 1)))\n        return pd.DataFrame({'source': (max_node - i), 'target': ((max_node - i) - 1)}, index=ids)\n    graph = StellarGraph({f'n_{i}': pd.DataFrame(index=range((i * i), ((i + 1) * (i + 1)))) for i in range((max_node_type + 1))}, {f'e_{i}': edges(i) for i in range(23)})\n    assert (graph.info() == 'StellarGraph: Undirected multigraph\\n Nodes: 484, Edges: 529\\n\\n Node types:\\n  n_21: [43]\\n    Features: none\\n    Edge types: n_21-e_0->n_21, n_21-e_1->n_21, n_21-e_10->n_21, n_21-e_11->n_21, n_21-e_12->n_21, ... (18 more)\\n  n_20: [41]\\n    Features: none\\n    Edge types: none\\n  n_19: [39]\\n    Features: none\\n    Edge types: none\\n  n_18: [37]\\n    Features: none\\n    Edge types: none\\n  n_17: [35]\\n    Features: none\\n    Edge types: none\\n  n_16: [33]\\n    Features: none\\n    Edge types: none\\n  n_15: [31]\\n    Features: none\\n    Edge types: none\\n  n_14: [29]\\n    Features: none\\n    Edge types: none\\n  n_13: [27]\\n    Features: none\\n    Edge types: none\\n  n_12: [25]\\n    Features: none\\n    Edge types: none\\n  n_11: [23]\\n    Features: none\\n    Edge types: none\\n  n_10: [21]\\n    Features: none\\n    Edge types: none\\n  n_9: [19]\\n    Features: none\\n    Edge types: none\\n  n_8: [17]\\n    Features: none\\n    Edge types: none\\n  n_7: [15]\\n    Features: none\\n    Edge types: none\\n  n_6: [13]\\n    Features: none\\n    Edge types: none\\n  n_5: [11]\\n    Features: none\\n    Edge types: none\\n  n_4: [9]\\n    Features: none\\n    Edge types: none\\n  n_3: [7]\\n    Features: none\\n    Edge types: none\\n  n_2: [5]\\n    Features: none\\n    Edge types: none\\n  ... (2 more)\\n\\n Edge types:\\n    n_21-e_22->n_21: [45]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_21->n_21: [43]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_20->n_21: [41]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_19->n_21: [39]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_18->n_21: [37]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_17->n_21: [35]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_16->n_21: [33]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_15->n_21: [31]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_14->n_21: [29]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_13->n_21: [27]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_12->n_21: [25]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_11->n_21: [23]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_10->n_21: [21]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_9->n_21: [19]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_8->n_21: [17]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_7->n_21: [15]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_6->n_21: [13]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_5->n_21: [11]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_4->n_21: [9]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_3->n_21: [7]\\n        Weights: all 1 (default)\\n        Features: none\\n    ... (3 more)')\n    assert (graph.info(truncate=2) == 'StellarGraph: Undirected multigraph\\n Nodes: 484, Edges: 529\\n\\n Node types:\\n  n_21: [43]\\n    Features: none\\n    Edge types: n_21-e_0->n_21, n_21-e_1->n_21, ... (21 more)\\n  n_20: [41]\\n    Features: none\\n    Edge types: none\\n  ... (20 more)\\n\\n Edge types:\\n    n_21-e_22->n_21: [45]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_21->n_21: [43]\\n        Weights: all 1 (default)\\n        Features: none\\n    ... (21 more)')\n    assert (graph.info(truncate=None) == 'StellarGraph: Undirected multigraph\\n Nodes: 484, Edges: 529\\n\\n Node types:\\n  n_21: [43]\\n    Features: none\\n    Edge types: n_21-e_0->n_21, n_21-e_1->n_21, n_21-e_10->n_21, n_21-e_11->n_21, n_21-e_12->n_21, ... (18 more)\\n  n_20: [41]\\n    Features: none\\n    Edge types: none\\n  n_19: [39]\\n    Features: none\\n    Edge types: none\\n  n_18: [37]\\n    Features: none\\n    Edge types: none\\n  n_17: [35]\\n    Features: none\\n    Edge types: none\\n  n_16: [33]\\n    Features: none\\n    Edge types: none\\n  n_15: [31]\\n    Features: none\\n    Edge types: none\\n  n_14: [29]\\n    Features: none\\n    Edge types: none\\n  n_13: [27]\\n    Features: none\\n    Edge types: none\\n  n_12: [25]\\n    Features: none\\n    Edge types: none\\n  n_11: [23]\\n    Features: none\\n    Edge types: none\\n  n_10: [21]\\n    Features: none\\n    Edge types: none\\n  n_9: [19]\\n    Features: none\\n    Edge types: none\\n  n_8: [17]\\n    Features: none\\n    Edge types: none\\n  n_7: [15]\\n    Features: none\\n    Edge types: none\\n  n_6: [13]\\n    Features: none\\n    Edge types: none\\n  n_5: [11]\\n    Features: none\\n    Edge types: none\\n  n_4: [9]\\n    Features: none\\n    Edge types: none\\n  n_3: [7]\\n    Features: none\\n    Edge types: none\\n  n_2: [5]\\n    Features: none\\n    Edge types: none\\n  n_1: [3]\\n    Features: none\\n    Edge types: none\\n  n_0: [1]\\n    Features: none\\n    Edge types: none\\n\\n Edge types:\\n    n_21-e_22->n_21: [45]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_21->n_21: [43]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_20->n_21: [41]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_19->n_21: [39]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_18->n_21: [37]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_17->n_21: [35]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_16->n_21: [33]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_15->n_21: [31]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_14->n_21: [29]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_13->n_21: [27]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_12->n_21: [25]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_11->n_21: [23]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_10->n_21: [21]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_9->n_21: [19]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_8->n_21: [17]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_7->n_21: [15]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_6->n_21: [13]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_5->n_21: [11]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_4->n_21: [9]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_3->n_21: [7]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_2->n_21: [5]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_1->n_21: [3]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_0->n_21: [1]\\n        Weights: all 1 (default)\\n        Features: none')", "masked_code": "def test_info_truncate():\n    max_node_type = 21\n    max_node = (((max_node_type + 1) * (max_node_type + 1)) - 1)\n\n    def edges(i):\n        ids = range((i * i), ((i + 1) * (i + 1)))\n        return pd.DataFrame({'source': (max_node - i), 'target': ((max_node - i) - 1)}, index=ids)\n    graph = StellarGraph({f'n_{i}': pd.DataFrame(index=range((i * i), ((i + 1) * (i + 1)))) for i in range((max_node_type + 1))}, {f'e_{i}': edges(i) for i in range(23)})\n    assert (graph.info() == 'StellarGraph: Undirected multigraph\\n Nodes: 484, Edges: 529\\n\\n Node types:\\n  n_21: [43]\\n    Features: none\\n    Edge types: n_21-e_0->n_21, n_21-e_1->n_21, n_21-e_10->n_21, n_21-e_11->n_21, n_21-e_12->n_21, ... (18 more)\\n  n_20: [41]\\n    Features: none\\n    Edge types: none\\n  n_19: [39]\\n    Features: none\\n    Edge types: none\\n  n_18: [37]\\n    Features: none\\n    Edge types: none\\n  n_17: [35]\\n    Features: none\\n    Edge types: none\\n  n_16: [33]\\n    Features: none\\n    Edge types: none\\n  n_15: [31]\\n    Features: none\\n    Edge types: none\\n  n_14: [29]\\n    Features: none\\n    Edge types: none\\n  n_13: [27]\\n    Features: none\\n    Edge types: none\\n  n_12: [25]\\n    Features: none\\n    Edge types: none\\n  n_11: [23]\\n    Features: none\\n    Edge types: none\\n  n_10: [21]\\n    Features: none\\n    Edge types: none\\n  n_9: [19]\\n    Features: none\\n    Edge types: none\\n  n_8: [17]\\n    Features: none\\n    Edge types: none\\n  n_7: [15]\\n    Features: none\\n    Edge types: none\\n  n_6: [13]\\n    Features: none\\n    Edge types: none\\n  n_5: [11]\\n    Features: none\\n    Edge types: none\\n  n_4: [9]\\n    Features: none\\n    Edge types: none\\n  n_3: [7]\\n    Features: none\\n    Edge types: none\\n  n_2: [5]\\n    Features: none\\n    Edge types: none\\n  ... (2 more)\\n\\n Edge types:\\n    n_21-e_22->n_21: [45]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_21->n_21: [43]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_20->n_21: [41]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_19->n_21: [39]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_18->n_21: [37]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_17->n_21: [35]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_16->n_21: [33]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_15->n_21: [31]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_14->n_21: [29]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_13->n_21: [27]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_12->n_21: [25]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_11->n_21: [23]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_10->n_21: [21]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_9->n_21: [19]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_8->n_21: [17]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_7->n_21: [15]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_6->n_21: [13]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_5->n_21: [11]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_4->n_21: [9]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_3->n_21: [7]\\n        Weights: all 1 (default)\\n        Features: none\\n    ... (3 more)')\n    assert (graph.info(truncate=2) == '???')\n    assert (graph.info(truncate=None) == 'StellarGraph: Undirected multigraph\\n Nodes: 484, Edges: 529\\n\\n Node types:\\n  n_21: [43]\\n    Features: none\\n    Edge types: n_21-e_0->n_21, n_21-e_1->n_21, n_21-e_10->n_21, n_21-e_11->n_21, n_21-e_12->n_21, ... (18 more)\\n  n_20: [41]\\n    Features: none\\n    Edge types: none\\n  n_19: [39]\\n    Features: none\\n    Edge types: none\\n  n_18: [37]\\n    Features: none\\n    Edge types: none\\n  n_17: [35]\\n    Features: none\\n    Edge types: none\\n  n_16: [33]\\n    Features: none\\n    Edge types: none\\n  n_15: [31]\\n    Features: none\\n    Edge types: none\\n  n_14: [29]\\n    Features: none\\n    Edge types: none\\n  n_13: [27]\\n    Features: none\\n    Edge types: none\\n  n_12: [25]\\n    Features: none\\n    Edge types: none\\n  n_11: [23]\\n    Features: none\\n    Edge types: none\\n  n_10: [21]\\n    Features: none\\n    Edge types: none\\n  n_9: [19]\\n    Features: none\\n    Edge types: none\\n  n_8: [17]\\n    Features: none\\n    Edge types: none\\n  n_7: [15]\\n    Features: none\\n    Edge types: none\\n  n_6: [13]\\n    Features: none\\n    Edge types: none\\n  n_5: [11]\\n    Features: none\\n    Edge types: none\\n  n_4: [9]\\n    Features: none\\n    Edge types: none\\n  n_3: [7]\\n    Features: none\\n    Edge types: none\\n  n_2: [5]\\n    Features: none\\n    Edge types: none\\n  n_1: [3]\\n    Features: none\\n    Edge types: none\\n  n_0: [1]\\n    Features: none\\n    Edge types: none\\n\\n Edge types:\\n    n_21-e_22->n_21: [45]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_21->n_21: [43]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_20->n_21: [41]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_19->n_21: [39]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_18->n_21: [37]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_17->n_21: [35]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_16->n_21: [33]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_15->n_21: [31]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_14->n_21: [29]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_13->n_21: [27]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_12->n_21: [25]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_11->n_21: [23]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_10->n_21: [21]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_9->n_21: [19]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_8->n_21: [17]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_7->n_21: [15]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_6->n_21: [13]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_5->n_21: [11]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_4->n_21: [9]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_3->n_21: [7]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_2->n_21: [5]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_1->n_21: [3]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_0->n_21: [1]\\n        Weights: all 1 (default)\\n        Features: none')", "ground_truth": "'StellarGraph: Undirected multigraph\\n Nodes: 484, Edges: 529\\n\\n Node types:\\n  n_21: [43]\\n    Features: none\\n    Edge types: n_21-e_0->n_21, n_21-e_1->n_21, ... (21 more)\\n  n_20: [41]\\n    Features: none\\n    Edge types: none\\n  ... (20 more)\\n\\n Edge types:\\n    n_21-e_22->n_21: [45]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_21->n_21: [43]\\n        Weights: all 1 (default)\\n        Features: none\\n    ... (21 more)'", "quality_analysis": {"complexity_score": 4, "left_complexity": 3, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_125", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_info_truncate", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "def test_info_truncate():\n    max_node_type = 21\n    max_node = (((max_node_type + 1) * (max_node_type + 1)) - 1)\n\n    def edges(i):\n        ids = range((i * i), ((i + 1) * (i + 1)))\n        return pd.DataFrame({'source': (max_node - i), 'target': ((max_node - i) - 1)}, index=ids)\n    graph = StellarGraph({f'n_{i}': pd.DataFrame(index=range((i * i), ((i + 1) * (i + 1)))) for i in range((max_node_type + 1))}, {f'e_{i}': edges(i) for i in range(23)})\n    assert (graph.info() == 'StellarGraph: Undirected multigraph\\n Nodes: 484, Edges: 529\\n\\n Node types:\\n  n_21: [43]\\n    Features: none\\n    Edge types: n_21-e_0->n_21, n_21-e_1->n_21, n_21-e_10->n_21, n_21-e_11->n_21, n_21-e_12->n_21, ... (18 more)\\n  n_20: [41]\\n    Features: none\\n    Edge types: none\\n  n_19: [39]\\n    Features: none\\n    Edge types: none\\n  n_18: [37]\\n    Features: none\\n    Edge types: none\\n  n_17: [35]\\n    Features: none\\n    Edge types: none\\n  n_16: [33]\\n    Features: none\\n    Edge types: none\\n  n_15: [31]\\n    Features: none\\n    Edge types: none\\n  n_14: [29]\\n    Features: none\\n    Edge types: none\\n  n_13: [27]\\n    Features: none\\n    Edge types: none\\n  n_12: [25]\\n    Features: none\\n    Edge types: none\\n  n_11: [23]\\n    Features: none\\n    Edge types: none\\n  n_10: [21]\\n    Features: none\\n    Edge types: none\\n  n_9: [19]\\n    Features: none\\n    Edge types: none\\n  n_8: [17]\\n    Features: none\\n    Edge types: none\\n  n_7: [15]\\n    Features: none\\n    Edge types: none\\n  n_6: [13]\\n    Features: none\\n    Edge types: none\\n  n_5: [11]\\n    Features: none\\n    Edge types: none\\n  n_4: [9]\\n    Features: none\\n    Edge types: none\\n  n_3: [7]\\n    Features: none\\n    Edge types: none\\n  n_2: [5]\\n    Features: none\\n    Edge types: none\\n  ... (2 more)\\n\\n Edge types:\\n    n_21-e_22->n_21: [45]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_21->n_21: [43]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_20->n_21: [41]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_19->n_21: [39]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_18->n_21: [37]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_17->n_21: [35]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_16->n_21: [33]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_15->n_21: [31]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_14->n_21: [29]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_13->n_21: [27]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_12->n_21: [25]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_11->n_21: [23]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_10->n_21: [21]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_9->n_21: [19]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_8->n_21: [17]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_7->n_21: [15]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_6->n_21: [13]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_5->n_21: [11]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_4->n_21: [9]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_3->n_21: [7]\\n        Weights: all 1 (default)\\n        Features: none\\n    ... (3 more)')\n    assert (graph.info(truncate=2) == 'StellarGraph: Undirected multigraph\\n Nodes: 484, Edges: 529\\n\\n Node types:\\n  n_21: [43]\\n    Features: none\\n    Edge types: n_21-e_0->n_21, n_21-e_1->n_21, ... (21 more)\\n  n_20: [41]\\n    Features: none\\n    Edge types: none\\n  ... (20 more)\\n\\n Edge types:\\n    n_21-e_22->n_21: [45]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_21->n_21: [43]\\n        Weights: all 1 (default)\\n        Features: none\\n    ... (21 more)')\n    assert (graph.info(truncate=None) == 'StellarGraph: Undirected multigraph\\n Nodes: 484, Edges: 529\\n\\n Node types:\\n  n_21: [43]\\n    Features: none\\n    Edge types: n_21-e_0->n_21, n_21-e_1->n_21, n_21-e_10->n_21, n_21-e_11->n_21, n_21-e_12->n_21, ... (18 more)\\n  n_20: [41]\\n    Features: none\\n    Edge types: none\\n  n_19: [39]\\n    Features: none\\n    Edge types: none\\n  n_18: [37]\\n    Features: none\\n    Edge types: none\\n  n_17: [35]\\n    Features: none\\n    Edge types: none\\n  n_16: [33]\\n    Features: none\\n    Edge types: none\\n  n_15: [31]\\n    Features: none\\n    Edge types: none\\n  n_14: [29]\\n    Features: none\\n    Edge types: none\\n  n_13: [27]\\n    Features: none\\n    Edge types: none\\n  n_12: [25]\\n    Features: none\\n    Edge types: none\\n  n_11: [23]\\n    Features: none\\n    Edge types: none\\n  n_10: [21]\\n    Features: none\\n    Edge types: none\\n  n_9: [19]\\n    Features: none\\n    Edge types: none\\n  n_8: [17]\\n    Features: none\\n    Edge types: none\\n  n_7: [15]\\n    Features: none\\n    Edge types: none\\n  n_6: [13]\\n    Features: none\\n    Edge types: none\\n  n_5: [11]\\n    Features: none\\n    Edge types: none\\n  n_4: [9]\\n    Features: none\\n    Edge types: none\\n  n_3: [7]\\n    Features: none\\n    Edge types: none\\n  n_2: [5]\\n    Features: none\\n    Edge types: none\\n  n_1: [3]\\n    Features: none\\n    Edge types: none\\n  n_0: [1]\\n    Features: none\\n    Edge types: none\\n\\n Edge types:\\n    n_21-e_22->n_21: [45]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_21->n_21: [43]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_20->n_21: [41]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_19->n_21: [39]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_18->n_21: [37]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_17->n_21: [35]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_16->n_21: [33]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_15->n_21: [31]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_14->n_21: [29]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_13->n_21: [27]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_12->n_21: [25]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_11->n_21: [23]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_10->n_21: [21]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_9->n_21: [19]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_8->n_21: [17]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_7->n_21: [15]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_6->n_21: [13]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_5->n_21: [11]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_4->n_21: [9]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_3->n_21: [7]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_2->n_21: [5]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_1->n_21: [3]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_0->n_21: [1]\\n        Weights: all 1 (default)\\n        Features: none')", "masked_code": "def test_info_truncate():\n    max_node_type = 21\n    max_node = (((max_node_type + 1) * (max_node_type + 1)) - 1)\n\n    def edges(i):\n        ids = range((i * i), ((i + 1) * (i + 1)))\n        return pd.DataFrame({'source': (max_node - i), 'target': ((max_node - i) - 1)}, index=ids)\n    graph = StellarGraph({f'n_{i}': pd.DataFrame(index=range((i * i), ((i + 1) * (i + 1)))) for i in range((max_node_type + 1))}, {f'e_{i}': edges(i) for i in range(23)})\n    assert (graph.info() == 'StellarGraph: Undirected multigraph\\n Nodes: 484, Edges: 529\\n\\n Node types:\\n  n_21: [43]\\n    Features: none\\n    Edge types: n_21-e_0->n_21, n_21-e_1->n_21, n_21-e_10->n_21, n_21-e_11->n_21, n_21-e_12->n_21, ... (18 more)\\n  n_20: [41]\\n    Features: none\\n    Edge types: none\\n  n_19: [39]\\n    Features: none\\n    Edge types: none\\n  n_18: [37]\\n    Features: none\\n    Edge types: none\\n  n_17: [35]\\n    Features: none\\n    Edge types: none\\n  n_16: [33]\\n    Features: none\\n    Edge types: none\\n  n_15: [31]\\n    Features: none\\n    Edge types: none\\n  n_14: [29]\\n    Features: none\\n    Edge types: none\\n  n_13: [27]\\n    Features: none\\n    Edge types: none\\n  n_12: [25]\\n    Features: none\\n    Edge types: none\\n  n_11: [23]\\n    Features: none\\n    Edge types: none\\n  n_10: [21]\\n    Features: none\\n    Edge types: none\\n  n_9: [19]\\n    Features: none\\n    Edge types: none\\n  n_8: [17]\\n    Features: none\\n    Edge types: none\\n  n_7: [15]\\n    Features: none\\n    Edge types: none\\n  n_6: [13]\\n    Features: none\\n    Edge types: none\\n  n_5: [11]\\n    Features: none\\n    Edge types: none\\n  n_4: [9]\\n    Features: none\\n    Edge types: none\\n  n_3: [7]\\n    Features: none\\n    Edge types: none\\n  n_2: [5]\\n    Features: none\\n    Edge types: none\\n  ... (2 more)\\n\\n Edge types:\\n    n_21-e_22->n_21: [45]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_21->n_21: [43]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_20->n_21: [41]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_19->n_21: [39]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_18->n_21: [37]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_17->n_21: [35]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_16->n_21: [33]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_15->n_21: [31]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_14->n_21: [29]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_13->n_21: [27]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_12->n_21: [25]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_11->n_21: [23]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_10->n_21: [21]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_9->n_21: [19]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_8->n_21: [17]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_7->n_21: [15]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_6->n_21: [13]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_5->n_21: [11]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_4->n_21: [9]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_3->n_21: [7]\\n        Weights: all 1 (default)\\n        Features: none\\n    ... (3 more)')\n    assert (graph.info(truncate=2) == 'StellarGraph: Undirected multigraph\\n Nodes: 484, Edges: 529\\n\\n Node types:\\n  n_21: [43]\\n    Features: none\\n    Edge types: n_21-e_0->n_21, n_21-e_1->n_21, ... (21 more)\\n  n_20: [41]\\n    Features: none\\n    Edge types: none\\n  ... (20 more)\\n\\n Edge types:\\n    n_21-e_22->n_21: [45]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_21->n_21: [43]\\n        Weights: all 1 (default)\\n        Features: none\\n    ... (21 more)')\n    assert (graph.info(truncate=None) == '???')", "ground_truth": "'StellarGraph: Undirected multigraph\\n Nodes: 484, Edges: 529\\n\\n Node types:\\n  n_21: [43]\\n    Features: none\\n    Edge types: n_21-e_0->n_21, n_21-e_1->n_21, n_21-e_10->n_21, n_21-e_11->n_21, n_21-e_12->n_21, ... (18 more)\\n  n_20: [41]\\n    Features: none\\n    Edge types: none\\n  n_19: [39]\\n    Features: none\\n    Edge types: none\\n  n_18: [37]\\n    Features: none\\n    Edge types: none\\n  n_17: [35]\\n    Features: none\\n    Edge types: none\\n  n_16: [33]\\n    Features: none\\n    Edge types: none\\n  n_15: [31]\\n    Features: none\\n    Edge types: none\\n  n_14: [29]\\n    Features: none\\n    Edge types: none\\n  n_13: [27]\\n    Features: none\\n    Edge types: none\\n  n_12: [25]\\n    Features: none\\n    Edge types: none\\n  n_11: [23]\\n    Features: none\\n    Edge types: none\\n  n_10: [21]\\n    Features: none\\n    Edge types: none\\n  n_9: [19]\\n    Features: none\\n    Edge types: none\\n  n_8: [17]\\n    Features: none\\n    Edge types: none\\n  n_7: [15]\\n    Features: none\\n    Edge types: none\\n  n_6: [13]\\n    Features: none\\n    Edge types: none\\n  n_5: [11]\\n    Features: none\\n    Edge types: none\\n  n_4: [9]\\n    Features: none\\n    Edge types: none\\n  n_3: [7]\\n    Features: none\\n    Edge types: none\\n  n_2: [5]\\n    Features: none\\n    Edge types: none\\n  n_1: [3]\\n    Features: none\\n    Edge types: none\\n  n_0: [1]\\n    Features: none\\n    Edge types: none\\n\\n Edge types:\\n    n_21-e_22->n_21: [45]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_21->n_21: [43]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_20->n_21: [41]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_19->n_21: [39]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_18->n_21: [37]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_17->n_21: [35]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_16->n_21: [33]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_15->n_21: [31]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_14->n_21: [29]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_13->n_21: [27]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_12->n_21: [25]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_11->n_21: [23]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_10->n_21: [21]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_9->n_21: [19]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_8->n_21: [17]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_7->n_21: [15]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_6->n_21: [13]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_5->n_21: [11]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_4->n_21: [9]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_3->n_21: [7]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_2->n_21: [5]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_1->n_21: [3]\\n        Weights: all 1 (default)\\n        Features: none\\n    n_21-e_0->n_21: [1]\\n        Weights: all 1 (default)\\n        Features: none'", "quality_analysis": {"complexity_score": 4, "left_complexity": 3, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_126", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_edges_include_weights", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "def test_edges_include_weights():\n    g = example_weighted_hin()\n    (edges, weights) = g.edges(include_edge_weight=True)\n    nxg = g.to_networkx()\n    assert (len(edges) == len(weights) == len(nxg.edges()))\n    grouped = pd.DataFrame(edges, columns=['source', 'target']).assign(weight=weights).groupby(['source', 'target']).agg(list)\n    for ((src, tgt), row) in grouped.iterrows():\n        assert (sorted(row['weight']) == sorted([data['weight'] for data in nxg.get_edge_data(src, tgt).values()]))", "masked_code": "def test_edges_include_weights():\n    g = example_weighted_hin()\n    (edges, weights) = g.edges(include_edge_weight=True)\n    nxg = g.to_networkx()\n    assert (len(edges) == '???' == len(nxg.edges()))\n    grouped = pd.DataFrame(edges, columns=['source', 'target']).assign(weight=weights).groupby(['source', 'target']).agg(list)\n    for ((src, tgt), row) in grouped.iterrows():\n        assert (sorted(row['weight']) == sorted([data['weight'] for data in nxg.get_edge_data(src, tgt).values()]))", "ground_truth": "len(weights)", "quality_analysis": {"complexity_score": 8, "left_complexity": 4, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_127", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_edges_include_weights", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "def test_edges_include_weights():\n    g = example_weighted_hin()\n    (edges, weights) = g.edges(include_edge_weight=True)\n    nxg = g.to_networkx()\n    assert (len(edges) == len(weights) == len(nxg.edges()))\n    grouped = pd.DataFrame(edges, columns=['source', 'target']).assign(weight=weights).groupby(['source', 'target']).agg(list)\n    for ((src, tgt), row) in grouped.iterrows():\n        assert (sorted(row['weight']) == sorted([data['weight'] for data in nxg.get_edge_data(src, tgt).values()]))", "masked_code": "def test_edges_include_weights():\n    g = example_weighted_hin()\n    (edges, weights) = g.edges(include_edge_weight=True)\n    nxg = g.to_networkx()\n    assert (len(edges) == len(weights) == len(nxg.edges()))\n    grouped = pd.DataFrame(edges, columns=['source', 'target']).assign(weight=weights).groupby(['source', 'target']).agg(list)\n    for ((src, tgt), row) in grouped.iterrows():\n        assert (sorted(row['weight']) == '???')", "ground_truth": "sorted([data['weight'] for data in nxg.get_edge_data(src, tgt).values()])", "quality_analysis": {"complexity_score": 11, "left_complexity": 8, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_128", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_to_adjacency_matrix_empty", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "@pytest.mark.parametrize('is_directed', [False, True])\ndef test_to_adjacency_matrix_empty(is_directed):\n    cls = (StellarDiGraph if is_directed else StellarGraph)\n    g = cls()\n    assert (g.to_adjacency_matrix().shape == (0, 0))\n    g = example_hin_1(is_directed=is_directed, self_loop=True)\n    assert (g.to_adjacency_matrix(nodes=[]).shape == (0, 0))", "masked_code": "@pytest.mark.parametrize('is_directed', [False, True])\ndef test_to_adjacency_matrix_empty(is_directed):\n    cls = (StellarDiGraph if is_directed else StellarGraph)\n    g = cls()\n    assert (g.to_adjacency_matrix().shape == '???')\n    g = example_hin_1(is_directed=is_directed, self_loop=True)\n    assert (g.to_adjacency_matrix(nodes=[]).shape == (0, 0))", "ground_truth": "(0, 0)", "quality_analysis": {"complexity_score": 6, "left_complexity": 2, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_129", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_to_adjacency_matrix_empty", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "@pytest.mark.parametrize('is_directed', [False, True])\ndef test_to_adjacency_matrix_empty(is_directed):\n    cls = (StellarDiGraph if is_directed else StellarGraph)\n    g = cls()\n    assert (g.to_adjacency_matrix().shape == (0, 0))\n    g = example_hin_1(is_directed=is_directed, self_loop=True)\n    assert (g.to_adjacency_matrix(nodes=[]).shape == (0, 0))", "masked_code": "@pytest.mark.parametrize('is_directed', [False, True])\ndef test_to_adjacency_matrix_empty(is_directed):\n    cls = (StellarDiGraph if is_directed else StellarGraph)\n    g = cls()\n    assert (g.to_adjacency_matrix().shape == (0, 0))\n    g = example_hin_1(is_directed=is_directed, self_loop=True)\n    assert (g.to_adjacency_matrix(nodes=[]).shape == '???')", "ground_truth": "(0, 0)", "quality_analysis": {"complexity_score": 6, "left_complexity": 2, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_130", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_edge_weights_undirected", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "@pytest.mark.parametrize('use_ilocs', [True, False])\ndef test_edge_weights_undirected(use_ilocs):\n    g = example_hin_1(is_directed=False, self_loop=True, reverse_order=True)\n    edges = [(5, 5), (4, 5), (5, 4), (0, 4), (4, 0)]\n    weights = [[11.0, 12.0, 1.0], [10.0], [10.0], [1], [1]]\n    if use_ilocs:\n        edges = [g.node_ids_to_ilocs(edge) for edge in edges]\n    for (edge, weight) in zip(edges, weights):\n        assert (g._edge_weights(*edge, use_ilocs=use_ilocs) == weight)", "masked_code": "@pytest.mark.parametrize('use_ilocs', [True, False])\ndef test_edge_weights_undirected(use_ilocs):\n    g = example_hin_1(is_directed=False, self_loop=True, reverse_order=True)\n    edges = [(5, 5), (4, 5), (5, 4), (0, 4), (4, 0)]\n    weights = [[11.0, 12.0, 1.0], [10.0], [10.0], [1], [1]]\n    if use_ilocs:\n        edges = [g.node_ids_to_ilocs(edge) for edge in edges]\n    for (edge, weight) in zip(edges, weights):\n        assert (g._edge_weights(*edge, use_ilocs=use_ilocs) == '???')", "ground_truth": "weight", "quality_analysis": {"complexity_score": 4, "left_complexity": 3, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_131", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_edge_weights_directed", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "@pytest.mark.parametrize('use_ilocs', [True, False])\ndef test_edge_weights_directed(use_ilocs):\n    g = example_hin_1(is_directed=True, self_loop=True, reverse_order=True)\n    edges = [(5, 5), (4, 5), (5, 4), (0, 4), (4, 0)]\n    weights = [[11.0, 12.0, 1.0], [10.0], [], [], [1]]\n    if use_ilocs:\n        edges = [g.node_ids_to_ilocs(edge) for edge in edges]\n    for (edge, weight) in zip(edges, weights):\n        assert (g._edge_weights(*edge, use_ilocs=use_ilocs) == weight)", "masked_code": "@pytest.mark.parametrize('use_ilocs', [True, False])\ndef test_edge_weights_directed(use_ilocs):\n    g = example_hin_1(is_directed=True, self_loop=True, reverse_order=True)\n    edges = [(5, 5), (4, 5), (5, 4), (0, 4), (4, 0)]\n    weights = [[11.0, 12.0, 1.0], [10.0], [], [], [1]]\n    if use_ilocs:\n        edges = [g.node_ids_to_ilocs(edge) for edge in edges]\n    for (edge, weight) in zip(edges, weights):\n        assert (g._edge_weights(*edge, use_ilocs=use_ilocs) == '???')", "ground_truth": "weight", "quality_analysis": {"complexity_score": 4, "left_complexity": 3, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_132", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_from_networkx_empty", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "def test_from_networkx_empty():\n    empty = StellarGraph.from_networkx(nx.Graph())\n    assert (not empty.is_directed())\n    assert (empty.node_types == set())\n    assert isinstance(empty, StellarGraph)\n    empty = StellarGraph.from_networkx(nx.DiGraph())\n    assert empty.is_directed()\n    assert (empty.node_types == set())\n    assert isinstance(empty, StellarDiGraph)\n    features = pd.DataFrame(columns=range(10))\n    empty_with_features = StellarGraph.from_networkx(nx.Graph(), node_features=features)\n    assert (empty_with_features.node_types == set())", "masked_code": "def test_from_networkx_empty():\n    empty = StellarGraph.from_networkx(nx.Graph())\n    assert (not empty.is_directed())\n    assert (empty.node_types == '???')\n    assert isinstance(empty, StellarGraph)\n    empty = StellarGraph.from_networkx(nx.DiGraph())\n    assert empty.is_directed()\n    assert (empty.node_types == set())\n    assert isinstance(empty, StellarDiGraph)\n    features = pd.DataFrame(columns=range(10))\n    empty_with_features = StellarGraph.from_networkx(nx.Graph(), node_features=features)\n    assert (empty_with_features.node_types == set())", "ground_truth": "set()", "quality_analysis": {"complexity_score": 5, "left_complexity": 2, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_133", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_from_networkx_empty", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "def test_from_networkx_empty():\n    empty = StellarGraph.from_networkx(nx.Graph())\n    assert (not empty.is_directed())\n    assert (empty.node_types == set())\n    assert isinstance(empty, StellarGraph)\n    empty = StellarGraph.from_networkx(nx.DiGraph())\n    assert empty.is_directed()\n    assert (empty.node_types == set())\n    assert isinstance(empty, StellarDiGraph)\n    features = pd.DataFrame(columns=range(10))\n    empty_with_features = StellarGraph.from_networkx(nx.Graph(), node_features=features)\n    assert (empty_with_features.node_types == set())", "masked_code": "def test_from_networkx_empty():\n    empty = StellarGraph.from_networkx(nx.Graph())\n    assert (not empty.is_directed())\n    assert (empty.node_types == set())\n    assert isinstance(empty, StellarGraph)\n    empty = StellarGraph.from_networkx(nx.DiGraph())\n    assert empty.is_directed()\n    assert (empty.node_types == '???')\n    assert isinstance(empty, StellarDiGraph)\n    features = pd.DataFrame(columns=range(10))\n    empty_with_features = StellarGraph.from_networkx(nx.Graph(), node_features=features)\n    assert (empty_with_features.node_types == set())", "ground_truth": "set()", "quality_analysis": {"complexity_score": 5, "left_complexity": 2, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_134", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_from_networkx_empty", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "def test_from_networkx_empty():\n    empty = StellarGraph.from_networkx(nx.Graph())\n    assert (not empty.is_directed())\n    assert (empty.node_types == set())\n    assert isinstance(empty, StellarGraph)\n    empty = StellarGraph.from_networkx(nx.DiGraph())\n    assert empty.is_directed()\n    assert (empty.node_types == set())\n    assert isinstance(empty, StellarDiGraph)\n    features = pd.DataFrame(columns=range(10))\n    empty_with_features = StellarGraph.from_networkx(nx.Graph(), node_features=features)\n    assert (empty_with_features.node_types == set())", "masked_code": "def test_from_networkx_empty():\n    empty = StellarGraph.from_networkx(nx.Graph())\n    assert (not empty.is_directed())\n    assert (empty.node_types == set())\n    assert isinstance(empty, StellarGraph)\n    empty = StellarGraph.from_networkx(nx.DiGraph())\n    assert empty.is_directed()\n    assert (empty.node_types == set())\n    assert isinstance(empty, StellarDiGraph)\n    features = pd.DataFrame(columns=range(10))\n    empty_with_features = StellarGraph.from_networkx(nx.Graph(), node_features=features)\n    assert (empty_with_features.node_types == '???')", "ground_truth": "set()", "quality_analysis": {"complexity_score": 5, "left_complexity": 2, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_135", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_from_networkx_smoke", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "def test_from_networkx_smoke():\n    g = nx.MultiGraph()\n    g.add_node(1, node_label='a', features=[1])\n    g.add_node(2)\n    g.add_node(3, features=[2, 3, 4, 5])\n    g.add_edge(1, 2, weight_attr=123)\n    g.add_edge(2, 2, edge_label='X', weight_attr=456)\n    g.add_edge(1, 2, edge_label='Y')\n    g.add_edge(1, 1)\n    with pytest.warns(UserWarning, match=\"found the following nodes \\\\(of type 'b'\\\\) without features, using 4-dimensional zero vector: 2\"):\n        from_nx = StellarGraph.from_networkx(g, edge_weight_attr='weight_attr', node_type_attr='node_label', edge_type_attr='edge_label', node_type_default='b', edge_type_default='X', node_features='features')\n    raw = StellarGraph(nodes={'a': pd.DataFrame([1], index=[1]), 'b': pd.DataFrame([(0, 0, 0, 0), (2, 3, 4, 5)], index=[2, 3])}, edges={'X': pd.DataFrame([(1, 2, 123.0), (2, 2, 456.0), (1, 1, 1.0)], columns=['source', 'target', 'weight']), 'Y': pd.DataFrame([(1, 2, 1.0)], columns=['source', 'target', 'weight'], index=[3])})\n\n    def both(f, numpy=False):\n        if numpy:\n            np.testing.assert_array_equal(f(from_nx), f(raw))\n        else:\n            assert (f(from_nx) == f(raw))\n    both((lambda g: sorted(g.nodes())))\n    nodes = raw.nodes()\n    for n in nodes:\n        both((lambda g: g.node_type(n)))\n        both((lambda g: g.node_features([n])), numpy=True)\n    both((lambda g: dict(zip(*g.edges(include_edge_type=True, include_edge_weight=True)))))", "masked_code": "def test_from_networkx_smoke():\n    g = nx.MultiGraph()\n    g.add_node(1, node_label='a', features=[1])\n    g.add_node(2)\n    g.add_node(3, features=[2, 3, 4, 5])\n    g.add_edge(1, 2, weight_attr=123)\n    g.add_edge(2, 2, edge_label='X', weight_attr=456)\n    g.add_edge(1, 2, edge_label='Y')\n    g.add_edge(1, 1)\n    with pytest.warns(UserWarning, match=\"found the following nodes \\\\(of type 'b'\\\\) without features, using 4-dimensional zero vector: 2\"):\n        from_nx = StellarGraph.from_networkx(g, edge_weight_attr='weight_attr', node_type_attr='node_label', edge_type_attr='edge_label', node_type_default='b', edge_type_default='X', node_features='features')\n    raw = StellarGraph(nodes={'a': pd.DataFrame([1], index=[1]), 'b': pd.DataFrame([(0, 0, 0, 0), (2, 3, 4, 5)], index=[2, 3])}, edges={'X': pd.DataFrame([(1, 2, 123.0), (2, 2, 456.0), (1, 1, 1.0)], columns=['source', 'target', 'weight']), 'Y': pd.DataFrame([(1, 2, 1.0)], columns=['source', 'target', 'weight'], index=[3])})\n\n    def both(f, numpy=False):\n        if numpy:\n            np.testing.assert_array_equal(f(from_nx), f(raw))\n        else:\n            assert (f(from_nx) == '???')\n    both((lambda g: sorted(g.nodes())))\n    nodes = raw.nodes()\n    for n in nodes:\n        both((lambda g: g.node_type(n)))\n        both((lambda g: g.node_features([n])), numpy=True)\n    both((lambda g: dict(zip(*g.edges(include_edge_type=True, include_edge_weight=True)))))", "ground_truth": "f(raw)", "quality_analysis": {"complexity_score": 8, "left_complexity": 4, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_136", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_subgraph", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "@pytest.mark.parametrize('is_directed', [False, True])\n@pytest.mark.parametrize('nodes', [[], [0], [5], [0, 1, 4, 5], np.array([0, 1, 4, 5]), pd.Index([0, 1, 4, 5])])\ndef test_subgraph(is_directed, nodes):\n    g = example_hin_1(feature_sizes={}, is_directed=is_directed, self_loop=True)\n    sub = g.subgraph(nodes)\n    expected = StellarGraph.from_networkx(g.to_networkx().subgraph(nodes))\n    assert (sub.is_directed() == is_directed)\n    assert (set(sub.nodes()) == set(expected.nodes()))\n    (sub_edges, sub_weights) = sub.edges(include_edge_type=True, include_edge_weight=True)\n    (exp_edges, exp_weights) = expected.edges(include_edge_type=True, include_edge_weight=True)\n    assert (normalize_edges(sub_edges, is_directed) == normalize_edges(exp_edges, is_directed))\n    np.testing.assert_array_equal(sub_weights, exp_weights)\n    for node in nodes:\n        assert (sub.node_type(node) == g.node_type(node))\n        np.testing.assert_array_equal(sub.node_features([node]), g.node_features([node]))", "masked_code": "@pytest.mark.parametrize('is_directed', [False, True])\n@pytest.mark.parametrize('nodes', [[], [0], [5], [0, 1, 4, 5], np.array([0, 1, 4, 5]), pd.Index([0, 1, 4, 5])])\ndef test_subgraph(is_directed, nodes):\n    g = example_hin_1(feature_sizes={}, is_directed=is_directed, self_loop=True)\n    sub = g.subgraph(nodes)\n    expected = StellarGraph.from_networkx(g.to_networkx().subgraph(nodes))\n    assert (sub.is_directed() == '???')\n    assert (set(sub.nodes()) == set(expected.nodes()))\n    (sub_edges, sub_weights) = sub.edges(include_edge_type=True, include_edge_weight=True)\n    (exp_edges, exp_weights) = expected.edges(include_edge_type=True, include_edge_weight=True)\n    assert (normalize_edges(sub_edges, is_directed) == normalize_edges(exp_edges, is_directed))\n    np.testing.assert_array_equal(sub_weights, exp_weights)\n    for node in nodes:\n        assert (sub.node_type(node) == g.node_type(node))\n        np.testing.assert_array_equal(sub.node_features([node]), g.node_features([node]))", "ground_truth": "is_directed", "quality_analysis": {"complexity_score": 4, "left_complexity": 3, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_137", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_subgraph", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "@pytest.mark.parametrize('is_directed', [False, True])\n@pytest.mark.parametrize('nodes', [[], [0], [5], [0, 1, 4, 5], np.array([0, 1, 4, 5]), pd.Index([0, 1, 4, 5])])\ndef test_subgraph(is_directed, nodes):\n    g = example_hin_1(feature_sizes={}, is_directed=is_directed, self_loop=True)\n    sub = g.subgraph(nodes)\n    expected = StellarGraph.from_networkx(g.to_networkx().subgraph(nodes))\n    assert (sub.is_directed() == is_directed)\n    assert (set(sub.nodes()) == set(expected.nodes()))\n    (sub_edges, sub_weights) = sub.edges(include_edge_type=True, include_edge_weight=True)\n    (exp_edges, exp_weights) = expected.edges(include_edge_type=True, include_edge_weight=True)\n    assert (normalize_edges(sub_edges, is_directed) == normalize_edges(exp_edges, is_directed))\n    np.testing.assert_array_equal(sub_weights, exp_weights)\n    for node in nodes:\n        assert (sub.node_type(node) == g.node_type(node))\n        np.testing.assert_array_equal(sub.node_features([node]), g.node_features([node]))", "masked_code": "@pytest.mark.parametrize('is_directed', [False, True])\n@pytest.mark.parametrize('nodes', [[], [0], [5], [0, 1, 4, 5], np.array([0, 1, 4, 5]), pd.Index([0, 1, 4, 5])])\ndef test_subgraph(is_directed, nodes):\n    g = example_hin_1(feature_sizes={}, is_directed=is_directed, self_loop=True)\n    sub = g.subgraph(nodes)\n    expected = StellarGraph.from_networkx(g.to_networkx().subgraph(nodes))\n    assert (sub.is_directed() == is_directed)\n    assert (set(sub.nodes()) == '???')\n    (sub_edges, sub_weights) = sub.edges(include_edge_type=True, include_edge_weight=True)\n    (exp_edges, exp_weights) = expected.edges(include_edge_type=True, include_edge_weight=True)\n    assert (normalize_edges(sub_edges, is_directed) == normalize_edges(exp_edges, is_directed))\n    np.testing.assert_array_equal(sub_weights, exp_weights)\n    for node in nodes:\n        assert (sub.node_type(node) == g.node_type(node))\n        np.testing.assert_array_equal(sub.node_features([node]), g.node_features([node]))", "ground_truth": "set(expected.nodes())", "quality_analysis": {"complexity_score": 12, "left_complexity": 6, "right_complexity": 6, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_138", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_subgraph", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "@pytest.mark.parametrize('is_directed', [False, True])\n@pytest.mark.parametrize('nodes', [[], [0], [5], [0, 1, 4, 5], np.array([0, 1, 4, 5]), pd.Index([0, 1, 4, 5])])\ndef test_subgraph(is_directed, nodes):\n    g = example_hin_1(feature_sizes={}, is_directed=is_directed, self_loop=True)\n    sub = g.subgraph(nodes)\n    expected = StellarGraph.from_networkx(g.to_networkx().subgraph(nodes))\n    assert (sub.is_directed() == is_directed)\n    assert (set(sub.nodes()) == set(expected.nodes()))\n    (sub_edges, sub_weights) = sub.edges(include_edge_type=True, include_edge_weight=True)\n    (exp_edges, exp_weights) = expected.edges(include_edge_type=True, include_edge_weight=True)\n    assert (normalize_edges(sub_edges, is_directed) == normalize_edges(exp_edges, is_directed))\n    np.testing.assert_array_equal(sub_weights, exp_weights)\n    for node in nodes:\n        assert (sub.node_type(node) == g.node_type(node))\n        np.testing.assert_array_equal(sub.node_features([node]), g.node_features([node]))", "masked_code": "@pytest.mark.parametrize('is_directed', [False, True])\n@pytest.mark.parametrize('nodes', [[], [0], [5], [0, 1, 4, 5], np.array([0, 1, 4, 5]), pd.Index([0, 1, 4, 5])])\ndef test_subgraph(is_directed, nodes):\n    g = example_hin_1(feature_sizes={}, is_directed=is_directed, self_loop=True)\n    sub = g.subgraph(nodes)\n    expected = StellarGraph.from_networkx(g.to_networkx().subgraph(nodes))\n    assert (sub.is_directed() == is_directed)\n    assert (set(sub.nodes()) == set(expected.nodes()))\n    (sub_edges, sub_weights) = sub.edges(include_edge_type=True, include_edge_weight=True)\n    (exp_edges, exp_weights) = expected.edges(include_edge_type=True, include_edge_weight=True)\n    assert (normalize_edges(sub_edges, is_directed) == '???')\n    np.testing.assert_array_equal(sub_weights, exp_weights)\n    for node in nodes:\n        assert (sub.node_type(node) == g.node_type(node))\n        np.testing.assert_array_equal(sub.node_features([node]), g.node_features([node]))", "ground_truth": "normalize_edges(exp_edges, is_directed)", "quality_analysis": {"complexity_score": 10, "left_complexity": 5, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_139", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_subgraph", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "@pytest.mark.parametrize('is_directed', [False, True])\n@pytest.mark.parametrize('nodes', [[], [0], [5], [0, 1, 4, 5], np.array([0, 1, 4, 5]), pd.Index([0, 1, 4, 5])])\ndef test_subgraph(is_directed, nodes):\n    g = example_hin_1(feature_sizes={}, is_directed=is_directed, self_loop=True)\n    sub = g.subgraph(nodes)\n    expected = StellarGraph.from_networkx(g.to_networkx().subgraph(nodes))\n    assert (sub.is_directed() == is_directed)\n    assert (set(sub.nodes()) == set(expected.nodes()))\n    (sub_edges, sub_weights) = sub.edges(include_edge_type=True, include_edge_weight=True)\n    (exp_edges, exp_weights) = expected.edges(include_edge_type=True, include_edge_weight=True)\n    assert (normalize_edges(sub_edges, is_directed) == normalize_edges(exp_edges, is_directed))\n    np.testing.assert_array_equal(sub_weights, exp_weights)\n    for node in nodes:\n        assert (sub.node_type(node) == g.node_type(node))\n        np.testing.assert_array_equal(sub.node_features([node]), g.node_features([node]))", "masked_code": "@pytest.mark.parametrize('is_directed', [False, True])\n@pytest.mark.parametrize('nodes', [[], [0], [5], [0, 1, 4, 5], np.array([0, 1, 4, 5]), pd.Index([0, 1, 4, 5])])\ndef test_subgraph(is_directed, nodes):\n    g = example_hin_1(feature_sizes={}, is_directed=is_directed, self_loop=True)\n    sub = g.subgraph(nodes)\n    expected = StellarGraph.from_networkx(g.to_networkx().subgraph(nodes))\n    assert (sub.is_directed() == is_directed)\n    assert (set(sub.nodes()) == set(expected.nodes()))\n    (sub_edges, sub_weights) = sub.edges(include_edge_type=True, include_edge_weight=True)\n    (exp_edges, exp_weights) = expected.edges(include_edge_type=True, include_edge_weight=True)\n    assert (normalize_edges(sub_edges, is_directed) == normalize_edges(exp_edges, is_directed))\n    np.testing.assert_array_equal(sub_weights, exp_weights)\n    for node in nodes:\n        assert (sub.node_type(node) == '???')\n        np.testing.assert_array_equal(sub.node_features([node]), g.node_features([node]))", "ground_truth": "g.node_type(node)", "quality_analysis": {"complexity_score": 8, "left_complexity": 4, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_140", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_connected_components", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "@pytest.mark.parametrize('is_directed', [False, True])\ndef test_connected_components(is_directed):\n    nodes = pd.DataFrame(index=range(6))\n    edges = pd.DataFrame([(0, 2), (2, 5), (1, 4)], columns=['source', 'target'])\n    if is_directed:\n        g = StellarDiGraph(nodes, edges)\n    else:\n        g = StellarGraph(nodes, edges)\n    (a, b, c) = g.connected_components()\n    assert (set(a) == {0, 2, 5})\n    assert (set(b) == {1, 4})\n    assert (set(c) == {3})\n    assert (set(g.subgraph(a).edges()) == {(0, 2), (2, 5)})", "masked_code": "@pytest.mark.parametrize('is_directed', [False, True])\ndef test_connected_components(is_directed):\n    nodes = pd.DataFrame(index=range(6))\n    edges = pd.DataFrame([(0, 2), (2, 5), (1, 4)], columns=['source', 'target'])\n    if is_directed:\n        g = StellarDiGraph(nodes, edges)\n    else:\n        g = StellarGraph(nodes, edges)\n    (a, b, c) = g.connected_components()\n    assert (set(a) == '???')\n    assert (set(b) == {1, 4})\n    assert (set(c) == {3})\n    assert (set(g.subgraph(a).edges()) == {(0, 2), (2, 5)})", "ground_truth": "{0, 2, 5}", "quality_analysis": {"complexity_score": 4, "left_complexity": 4, "right_complexity": 0, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_141", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_connected_components", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "@pytest.mark.parametrize('is_directed', [False, True])\ndef test_connected_components(is_directed):\n    nodes = pd.DataFrame(index=range(6))\n    edges = pd.DataFrame([(0, 2), (2, 5), (1, 4)], columns=['source', 'target'])\n    if is_directed:\n        g = StellarDiGraph(nodes, edges)\n    else:\n        g = StellarGraph(nodes, edges)\n    (a, b, c) = g.connected_components()\n    assert (set(a) == {0, 2, 5})\n    assert (set(b) == {1, 4})\n    assert (set(c) == {3})\n    assert (set(g.subgraph(a).edges()) == {(0, 2), (2, 5)})", "masked_code": "@pytest.mark.parametrize('is_directed', [False, True])\ndef test_connected_components(is_directed):\n    nodes = pd.DataFrame(index=range(6))\n    edges = pd.DataFrame([(0, 2), (2, 5), (1, 4)], columns=['source', 'target'])\n    if is_directed:\n        g = StellarDiGraph(nodes, edges)\n    else:\n        g = StellarGraph(nodes, edges)\n    (a, b, c) = g.connected_components()\n    assert (set(a) == {0, 2, 5})\n    assert (set(b) == '???')\n    assert (set(c) == {3})\n    assert (set(g.subgraph(a).edges()) == {(0, 2), (2, 5)})", "ground_truth": "{1, 4}", "quality_analysis": {"complexity_score": 4, "left_complexity": 4, "right_complexity": 0, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_142", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_connected_components", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "@pytest.mark.parametrize('is_directed', [False, True])\ndef test_connected_components(is_directed):\n    nodes = pd.DataFrame(index=range(6))\n    edges = pd.DataFrame([(0, 2), (2, 5), (1, 4)], columns=['source', 'target'])\n    if is_directed:\n        g = StellarDiGraph(nodes, edges)\n    else:\n        g = StellarGraph(nodes, edges)\n    (a, b, c) = g.connected_components()\n    assert (set(a) == {0, 2, 5})\n    assert (set(b) == {1, 4})\n    assert (set(c) == {3})\n    assert (set(g.subgraph(a).edges()) == {(0, 2), (2, 5)})", "masked_code": "@pytest.mark.parametrize('is_directed', [False, True])\ndef test_connected_components(is_directed):\n    nodes = pd.DataFrame(index=range(6))\n    edges = pd.DataFrame([(0, 2), (2, 5), (1, 4)], columns=['source', 'target'])\n    if is_directed:\n        g = StellarDiGraph(nodes, edges)\n    else:\n        g = StellarGraph(nodes, edges)\n    (a, b, c) = g.connected_components()\n    assert (set(a) == {0, 2, 5})\n    assert (set(b) == {1, 4})\n    assert (set(c) == '???')\n    assert (set(g.subgraph(a).edges()) == {(0, 2), (2, 5)})", "ground_truth": "{3}", "quality_analysis": {"complexity_score": 4, "left_complexity": 4, "right_complexity": 0, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_143", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_connected_components", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "@pytest.mark.parametrize('is_directed', [False, True])\ndef test_connected_components(is_directed):\n    nodes = pd.DataFrame(index=range(6))\n    edges = pd.DataFrame([(0, 2), (2, 5), (1, 4)], columns=['source', 'target'])\n    if is_directed:\n        g = StellarDiGraph(nodes, edges)\n    else:\n        g = StellarGraph(nodes, edges)\n    (a, b, c) = g.connected_components()\n    assert (set(a) == {0, 2, 5})\n    assert (set(b) == {1, 4})\n    assert (set(c) == {3})\n    assert (set(g.subgraph(a).edges()) == {(0, 2), (2, 5)})", "masked_code": "@pytest.mark.parametrize('is_directed', [False, True])\ndef test_connected_components(is_directed):\n    nodes = pd.DataFrame(index=range(6))\n    edges = pd.DataFrame([(0, 2), (2, 5), (1, 4)], columns=['source', 'target'])\n    if is_directed:\n        g = StellarDiGraph(nodes, edges)\n    else:\n        g = StellarGraph(nodes, edges)\n    (a, b, c) = g.connected_components()\n    assert (set(a) == {0, 2, 5})\n    assert (set(b) == {1, 4})\n    assert (set(c) == {3})\n    assert (set(g.subgraph(a).edges()) == '???')", "ground_truth": "{(0, 2), (2, 5)}", "quality_analysis": {"complexity_score": 6, "left_complexity": 6, "right_complexity": 0, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_144", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_nodes_node_type_filter", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "@pytest.mark.parametrize('use_ilocs', [True, False])\ndef test_nodes_node_type_filter(use_ilocs):\n    g = example_hin_1(reverse_order=True)\n    if use_ilocs:\n        assert (sorted(g.nodes(node_type='A', use_ilocs=use_ilocs)) == sorted(g.node_ids_to_ilocs([0, 1, 2, 3])))\n        assert (sorted(g.nodes(node_type='B', use_ilocs=use_ilocs)) == sorted(g.node_ids_to_ilocs([4, 5, 6])))\n    else:\n        assert (sorted(g.nodes(node_type='A', use_ilocs=use_ilocs)) == [0, 1, 2, 3])\n        assert (sorted(g.nodes(node_type='B', use_ilocs=use_ilocs)) == [4, 5, 6])\n    assert (sorted(g.nodes(node_type=None, use_ilocs=use_ilocs)) == list(range(7)))\n    with pytest.raises(KeyError, match=\"'C'\"):\n        g.nodes(node_type='C')", "masked_code": "@pytest.mark.parametrize('use_ilocs', [True, False])\ndef test_nodes_node_type_filter(use_ilocs):\n    g = example_hin_1(reverse_order=True)\n    if use_ilocs:\n        assert (sorted(g.nodes(node_type='A', use_ilocs=use_ilocs)) == sorted(g.node_ids_to_ilocs([0, 1, 2, 3])))\n        assert (sorted(g.nodes(node_type='B', use_ilocs=use_ilocs)) == sorted(g.node_ids_to_ilocs([4, 5, 6])))\n    else:\n        assert (sorted(g.nodes(node_type='A', use_ilocs=use_ilocs)) == [0, 1, 2, 3])\n        assert (sorted(g.nodes(node_type='B', use_ilocs=use_ilocs)) == [4, 5, 6])\n    assert (sorted(g.nodes(node_type=None, use_ilocs=use_ilocs)) == '???')\n    with pytest.raises(KeyError, match=\"'C'\"):\n        g.nodes(node_type='C')", "ground_truth": "list(range(7))", "quality_analysis": {"complexity_score": 13, "left_complexity": 6, "right_complexity": 7, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_145", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_nodes_node_type_filter", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "@pytest.mark.parametrize('use_ilocs', [True, False])\ndef test_nodes_node_type_filter(use_ilocs):\n    g = example_hin_1(reverse_order=True)\n    if use_ilocs:\n        assert (sorted(g.nodes(node_type='A', use_ilocs=use_ilocs)) == sorted(g.node_ids_to_ilocs([0, 1, 2, 3])))\n        assert (sorted(g.nodes(node_type='B', use_ilocs=use_ilocs)) == sorted(g.node_ids_to_ilocs([4, 5, 6])))\n    else:\n        assert (sorted(g.nodes(node_type='A', use_ilocs=use_ilocs)) == [0, 1, 2, 3])\n        assert (sorted(g.nodes(node_type='B', use_ilocs=use_ilocs)) == [4, 5, 6])\n    assert (sorted(g.nodes(node_type=None, use_ilocs=use_ilocs)) == list(range(7)))\n    with pytest.raises(KeyError, match=\"'C'\"):\n        g.nodes(node_type='C')", "masked_code": "@pytest.mark.parametrize('use_ilocs', [True, False])\ndef test_nodes_node_type_filter(use_ilocs):\n    g = example_hin_1(reverse_order=True)\n    if use_ilocs:\n        assert (sorted(g.nodes(node_type='A', use_ilocs=use_ilocs)) == '???')\n        assert (sorted(g.nodes(node_type='B', use_ilocs=use_ilocs)) == sorted(g.node_ids_to_ilocs([4, 5, 6])))\n    else:\n        assert (sorted(g.nodes(node_type='A', use_ilocs=use_ilocs)) == [0, 1, 2, 3])\n        assert (sorted(g.nodes(node_type='B', use_ilocs=use_ilocs)) == [4, 5, 6])\n    assert (sorted(g.nodes(node_type=None, use_ilocs=use_ilocs)) == list(range(7)))\n    with pytest.raises(KeyError, match=\"'C'\"):\n        g.nodes(node_type='C')", "ground_truth": "sorted(g.node_ids_to_ilocs([0, 1, 2, 3]))", "quality_analysis": {"complexity_score": 18, "left_complexity": 6, "right_complexity": 12, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_146", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_nodes_node_type_filter", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "@pytest.mark.parametrize('use_ilocs', [True, False])\ndef test_nodes_node_type_filter(use_ilocs):\n    g = example_hin_1(reverse_order=True)\n    if use_ilocs:\n        assert (sorted(g.nodes(node_type='A', use_ilocs=use_ilocs)) == sorted(g.node_ids_to_ilocs([0, 1, 2, 3])))\n        assert (sorted(g.nodes(node_type='B', use_ilocs=use_ilocs)) == sorted(g.node_ids_to_ilocs([4, 5, 6])))\n    else:\n        assert (sorted(g.nodes(node_type='A', use_ilocs=use_ilocs)) == [0, 1, 2, 3])\n        assert (sorted(g.nodes(node_type='B', use_ilocs=use_ilocs)) == [4, 5, 6])\n    assert (sorted(g.nodes(node_type=None, use_ilocs=use_ilocs)) == list(range(7)))\n    with pytest.raises(KeyError, match=\"'C'\"):\n        g.nodes(node_type='C')", "masked_code": "@pytest.mark.parametrize('use_ilocs', [True, False])\ndef test_nodes_node_type_filter(use_ilocs):\n    g = example_hin_1(reverse_order=True)\n    if use_ilocs:\n        assert (sorted(g.nodes(node_type='A', use_ilocs=use_ilocs)) == sorted(g.node_ids_to_ilocs([0, 1, 2, 3])))\n        assert (sorted(g.nodes(node_type='B', use_ilocs=use_ilocs)) == '???')\n    else:\n        assert (sorted(g.nodes(node_type='A', use_ilocs=use_ilocs)) == [0, 1, 2, 3])\n        assert (sorted(g.nodes(node_type='B', use_ilocs=use_ilocs)) == [4, 5, 6])\n    assert (sorted(g.nodes(node_type=None, use_ilocs=use_ilocs)) == list(range(7)))\n    with pytest.raises(KeyError, match=\"'C'\"):\n        g.nodes(node_type='C')", "ground_truth": "sorted(g.node_ids_to_ilocs([4, 5, 6]))", "quality_analysis": {"complexity_score": 17, "left_complexity": 6, "right_complexity": 11, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_147", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_nodes_node_type_filter", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "@pytest.mark.parametrize('use_ilocs', [True, False])\ndef test_nodes_node_type_filter(use_ilocs):\n    g = example_hin_1(reverse_order=True)\n    if use_ilocs:\n        assert (sorted(g.nodes(node_type='A', use_ilocs=use_ilocs)) == sorted(g.node_ids_to_ilocs([0, 1, 2, 3])))\n        assert (sorted(g.nodes(node_type='B', use_ilocs=use_ilocs)) == sorted(g.node_ids_to_ilocs([4, 5, 6])))\n    else:\n        assert (sorted(g.nodes(node_type='A', use_ilocs=use_ilocs)) == [0, 1, 2, 3])\n        assert (sorted(g.nodes(node_type='B', use_ilocs=use_ilocs)) == [4, 5, 6])\n    assert (sorted(g.nodes(node_type=None, use_ilocs=use_ilocs)) == list(range(7)))\n    with pytest.raises(KeyError, match=\"'C'\"):\n        g.nodes(node_type='C')", "masked_code": "@pytest.mark.parametrize('use_ilocs', [True, False])\ndef test_nodes_node_type_filter(use_ilocs):\n    g = example_hin_1(reverse_order=True)\n    if use_ilocs:\n        assert (sorted(g.nodes(node_type='A', use_ilocs=use_ilocs)) == sorted(g.node_ids_to_ilocs([0, 1, 2, 3])))\n        assert (sorted(g.nodes(node_type='B', use_ilocs=use_ilocs)) == sorted(g.node_ids_to_ilocs([4, 5, 6])))\n    else:\n        assert (sorted(g.nodes(node_type='A', use_ilocs=use_ilocs)) == '???')\n        assert (sorted(g.nodes(node_type='B', use_ilocs=use_ilocs)) == [4, 5, 6])\n    assert (sorted(g.nodes(node_type=None, use_ilocs=use_ilocs)) == list(range(7)))\n    with pytest.raises(KeyError, match=\"'C'\"):\n        g.nodes(node_type='C')", "ground_truth": "[0, 1, 2, 3]", "quality_analysis": {"complexity_score": 12, "left_complexity": 6, "right_complexity": 6, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_148", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_nodes_node_type_filter", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "@pytest.mark.parametrize('use_ilocs', [True, False])\ndef test_nodes_node_type_filter(use_ilocs):\n    g = example_hin_1(reverse_order=True)\n    if use_ilocs:\n        assert (sorted(g.nodes(node_type='A', use_ilocs=use_ilocs)) == sorted(g.node_ids_to_ilocs([0, 1, 2, 3])))\n        assert (sorted(g.nodes(node_type='B', use_ilocs=use_ilocs)) == sorted(g.node_ids_to_ilocs([4, 5, 6])))\n    else:\n        assert (sorted(g.nodes(node_type='A', use_ilocs=use_ilocs)) == [0, 1, 2, 3])\n        assert (sorted(g.nodes(node_type='B', use_ilocs=use_ilocs)) == [4, 5, 6])\n    assert (sorted(g.nodes(node_type=None, use_ilocs=use_ilocs)) == list(range(7)))\n    with pytest.raises(KeyError, match=\"'C'\"):\n        g.nodes(node_type='C')", "masked_code": "@pytest.mark.parametrize('use_ilocs', [True, False])\ndef test_nodes_node_type_filter(use_ilocs):\n    g = example_hin_1(reverse_order=True)\n    if use_ilocs:\n        assert (sorted(g.nodes(node_type='A', use_ilocs=use_ilocs)) == sorted(g.node_ids_to_ilocs([0, 1, 2, 3])))\n        assert (sorted(g.nodes(node_type='B', use_ilocs=use_ilocs)) == sorted(g.node_ids_to_ilocs([4, 5, 6])))\n    else:\n        assert (sorted(g.nodes(node_type='A', use_ilocs=use_ilocs)) == [0, 1, 2, 3])\n        assert (sorted(g.nodes(node_type='B', use_ilocs=use_ilocs)) == '???')\n    assert (sorted(g.nodes(node_type=None, use_ilocs=use_ilocs)) == list(range(7)))\n    with pytest.raises(KeyError, match=\"'C'\"):\n        g.nodes(node_type='C')", "ground_truth": "[4, 5, 6]", "quality_analysis": {"complexity_score": 11, "left_complexity": 6, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_149", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_node_degrees", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "@pytest.mark.parametrize('use_ilocs', [True, False])\ndef test_node_degrees(use_ilocs):\n    g = example_hin_1(reverse_order=True)\n    degrees = g.node_degrees(use_ilocs=use_ilocs)\n    expected = {0: 1, 1: 2, 2: 1, 3: 1, 4: 4, 5: 3, 6: 0}\n    if use_ilocs:\n        for node_id in expected.keys():\n            node_iloc = g.node_ids_to_ilocs([node_id])[0]\n            assert (expected[node_id] == degrees[node_iloc])\n    else:\n        assert (expected == degrees)", "masked_code": "@pytest.mark.parametrize('use_ilocs', [True, False])\ndef test_node_degrees(use_ilocs):\n    g = example_hin_1(reverse_order=True)\n    degrees = g.node_degrees(use_ilocs=use_ilocs)\n    expected = {0: 1, 1: 2, 2: 1, 3: 1, 4: 4, 5: 3, 6: 0}\n    if use_ilocs:\n        for node_id in expected.keys():\n            node_iloc = g.node_ids_to_ilocs([node_id])[0]\n            assert (expected[node_id] == '???')\n    else:\n        assert (expected == degrees)", "ground_truth": "degrees[node_iloc]", "quality_analysis": {"complexity_score": 10, "left_complexity": 5, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_150", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_unique_node_type", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "def test_unique_node_type():\n    one_type = example_graph_random(node_types=1, edge_types=10)\n    assert (one_type.unique_node_type() == 'n-0')\n    many_types = example_graph_random(node_types=4, edge_types=1)\n    with pytest.raises(ValueError, match=\"Expected only one node type for 'unique_node_type', found: 'n-0', 'n-1', 'n-2', 'n-3'\"):\n        many_types.unique_node_type()\n    with pytest.raises(ValueError, match='^ABC custom message 123$'):\n        many_types.unique_node_type('ABC custom message 123')\n    with pytest.raises(ValueError, match=\"^ABC custom message 'n-0', 'n-1', 'n-2', 'n-3' 123$\"):\n        many_types.unique_node_type('ABC custom message %(found)s 123')", "masked_code": "def test_unique_node_type():\n    one_type = example_graph_random(node_types=1, edge_types=10)\n    assert (one_type.unique_node_type() == '???')\n    many_types = example_graph_random(node_types=4, edge_types=1)\n    with pytest.raises(ValueError, match=\"Expected only one node type for 'unique_node_type', found: 'n-0', 'n-1', 'n-2', 'n-3'\"):\n        many_types.unique_node_type()\n    with pytest.raises(ValueError, match='^ABC custom message 123$'):\n        many_types.unique_node_type('ABC custom message 123')\n    with pytest.raises(ValueError, match=\"^ABC custom message 'n-0', 'n-1', 'n-2', 'n-3' 123$\"):\n        many_types.unique_node_type('ABC custom message %(found)s 123')", "ground_truth": "'n-0'", "quality_analysis": {"complexity_score": 4, "left_complexity": 3, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_151", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_unique_edge_type", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "def test_unique_edge_type():\n    one_type = example_graph_random(node_types=10, edge_types=1)\n    assert (one_type.unique_edge_type() == 'e-0')\n    many_types = example_graph_random(node_types=1, edge_types=4)\n    with pytest.raises(ValueError, match=\"Expected only one edge type for 'unique_edge_type', found: 'e-0', 'e-1', 'e-2', 'e-3'\"):\n        many_types.unique_edge_type()\n    with pytest.raises(ValueError, match='^ABC custom message 123$'):\n        many_types.unique_edge_type('ABC custom message 123')\n    with pytest.raises(ValueError, match=\"^ABC custom message 'e-0', 'e-1', 'e-2', 'e-3' 123$\"):\n        many_types.unique_edge_type('ABC custom message %(found)s 123')", "masked_code": "def test_unique_edge_type():\n    one_type = example_graph_random(node_types=10, edge_types=1)\n    assert (one_type.unique_edge_type() == '???')\n    many_types = example_graph_random(node_types=1, edge_types=4)\n    with pytest.raises(ValueError, match=\"Expected only one edge type for 'unique_edge_type', found: 'e-0', 'e-1', 'e-2', 'e-3'\"):\n        many_types.unique_edge_type()\n    with pytest.raises(ValueError, match='^ABC custom message 123$'):\n        many_types.unique_edge_type('ABC custom message 123')\n    with pytest.raises(ValueError, match=\"^ABC custom message 'e-0', 'e-1', 'e-2', 'e-3' 123$\"):\n        many_types.unique_edge_type('ABC custom message %(found)s 123')", "ground_truth": "'e-0'", "quality_analysis": {"complexity_score": 4, "left_complexity": 3, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_152", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_correct_adjacency_list_type", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "def test_correct_adjacency_list_type():\n    cycle_graph = nx.cycle_graph(200)\n    sg = StellarGraph.from_networkx(cycle_graph)\n    sg._edges._init_undirected_adj_lists()\n    assert (sg.number_of_edges() == 200)\n    assert (sg._edges.ids.dtype == np.uint8)\n    assert all(((deg == 2) for deg in sg.node_degrees().values()))\n    assert (sg._edges._edges_dict.flat.dtype == np.uint16)", "masked_code": "def test_correct_adjacency_list_type():\n    cycle_graph = nx.cycle_graph(200)\n    sg = StellarGraph.from_networkx(cycle_graph)\n    sg._edges._init_undirected_adj_lists()\n    assert (sg.number_of_edges() == '???')\n    assert (sg._edges.ids.dtype == np.uint8)\n    assert all(((deg == 2) for deg in sg.node_degrees().values()))\n    assert (sg._edges._edges_dict.flat.dtype == np.uint16)", "ground_truth": "200", "quality_analysis": {"complexity_score": 4, "left_complexity": 3, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_153", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_correct_adjacency_list_type", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "def test_correct_adjacency_list_type():\n    cycle_graph = nx.cycle_graph(200)\n    sg = StellarGraph.from_networkx(cycle_graph)\n    sg._edges._init_undirected_adj_lists()\n    assert (sg.number_of_edges() == 200)\n    assert (sg._edges.ids.dtype == np.uint8)\n    assert all(((deg == 2) for deg in sg.node_degrees().values()))\n    assert (sg._edges._edges_dict.flat.dtype == np.uint16)", "masked_code": "def test_correct_adjacency_list_type():\n    cycle_graph = nx.cycle_graph(200)\n    sg = StellarGraph.from_networkx(cycle_graph)\n    sg._edges._init_undirected_adj_lists()\n    assert (sg.number_of_edges() == 200)\n    assert (sg._edges.ids.dtype == '???')\n    assert all(((deg == 2) for deg in sg.node_degrees().values()))\n    assert (sg._edges._edges_dict.flat.dtype == np.uint16)", "ground_truth": "np.uint8", "quality_analysis": {"complexity_score": 4, "left_complexity": 2, "right_complexity": 2, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_154", "reponame": "stellargraph", "testpath": "tests/core/test_graph.py", "testname": "test_graph.py", "classname": null, "funcname": "test_correct_adjacency_list_type", "imports": ["import networkx as nx", "import numpy as np", "import pandas as pd", "import pytest", "import random", "from stellargraph.core.graph import *", "from stellargraph.core.indexed_array import IndexedArray", "from stellargraph.core.experimental import ExperimentalWarning", "from ..test_utils.alloc import snapshot, peak, allocation_benchmark", "from ..test_utils.graphs import example_graph_nx, example_graph, example_hin_1_nx, example_hin_1, line_graph, weighted_hin, example_graph_random, knowledge_graph", "from .. import test_utils"], "code": "def test_correct_adjacency_list_type():\n    cycle_graph = nx.cycle_graph(200)\n    sg = StellarGraph.from_networkx(cycle_graph)\n    sg._edges._init_undirected_adj_lists()\n    assert (sg.number_of_edges() == 200)\n    assert (sg._edges.ids.dtype == np.uint8)\n    assert all(((deg == 2) for deg in sg.node_degrees().values()))\n    assert (sg._edges._edges_dict.flat.dtype == np.uint16)", "masked_code": "def test_correct_adjacency_list_type():\n    cycle_graph = nx.cycle_graph(200)\n    sg = StellarGraph.from_networkx(cycle_graph)\n    sg._edges._init_undirected_adj_lists()\n    assert (sg.number_of_edges() == 200)\n    assert (sg._edges.ids.dtype == np.uint8)\n    assert all(((deg == 2) for deg in sg.node_degrees().values()))\n    assert (sg._edges._edges_dict.flat.dtype == '???')", "ground_truth": "np.uint16", "quality_analysis": {"complexity_score": 4, "left_complexity": 2, "right_complexity": 2, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_155", "reponame": "stellargraph", "testpath": "tests/core/test_indexed_array.py", "testname": "test_indexed_array.py", "classname": null, "funcname": "test_indexed_array_empty", "imports": ["import numpy as np", "import pytest", "from stellargraph import IndexedArray"], "code": "def test_indexed_array_empty():\n    frame = IndexedArray()\n    assert (frame.index == range(0))\n    np.testing.assert_array_equal(frame.values, np.empty((0, 0)))", "masked_code": "def test_indexed_array_empty():\n    frame = IndexedArray()\n    assert (frame.index == '???')\n    np.testing.assert_array_equal(frame.values, np.empty((0, 0)))", "ground_truth": "range(0)", "quality_analysis": {"complexity_score": 6, "left_complexity": 2, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_156", "reponame": "stellargraph", "testpath": "tests/core/test_indexed_array.py", "testname": "test_indexed_array.py", "classname": null, "funcname": "test_indexed_array_non_empty", "imports": ["import numpy as np", "import pytest", "from stellargraph import IndexedArray"], "code": "def test_indexed_array_non_empty():\n    list_ids = ['a', 'b', 'c']\n    array_ids = np.array([10, (- 1), 2])\n    range_ids = range(106, 100, (- 2))\n    values = np.random.rand(3, 4, 5)\n    frame = IndexedArray(values)\n    assert (frame.index == range(3))\n    assert (frame.values is values)\n    frame = IndexedArray(values, index=list_ids)\n    assert (frame.index is list_ids)\n    assert (frame.values is values)\n    frame = IndexedArray(values, index=array_ids)\n    assert (frame.index is array_ids)\n    assert (frame.values is values)\n    frame = IndexedArray(values, index=range_ids)\n    assert (frame.index is range_ids)\n    assert (frame.values is values)", "masked_code": "def test_indexed_array_non_empty():\n    list_ids = ['a', 'b', 'c']\n    array_ids = np.array([10, (- 1), 2])\n    range_ids = range(106, 100, (- 2))\n    values = np.random.rand(3, 4, 5)\n    frame = IndexedArray(values)\n    assert (frame.index == '???')\n    assert (frame.values is values)\n    frame = IndexedArray(values, index=list_ids)\n    assert (frame.index is list_ids)\n    assert (frame.values is values)\n    frame = IndexedArray(values, index=array_ids)\n    assert (frame.index is array_ids)\n    assert (frame.values is values)\n    frame = IndexedArray(values, index=range_ids)\n    assert (frame.index is range_ids)\n    assert (frame.values is values)", "ground_truth": "range(3)", "quality_analysis": {"complexity_score": 6, "left_complexity": 2, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_157", "reponame": "stellargraph", "testpath": "tests/core/test_schema.py", "testname": "test_schema.py", "classname": null, "funcname": "test_graph_schema_sampling", "imports": ["import pytest", "from stellargraph.core.schema import *", "import itertools as it"], "code": "def test_graph_schema_sampling(example_graph_schema):\n    schema = example_graph_schema(bb=0)\n    with pytest.raises(TypeError):\n        schema.type_adjacency_list('A', 2)\n    with pytest.raises(TypeError):\n        schema.type_adjacency_list('A', None)\n    type_list = schema.type_adjacency_list(['A', 'B'], n_hops=2)\n    assert (type_list[0][0] == 'A')\n    assert (type_list[1][0] == 'B')\n    for lt in type_list:\n        adj_types = [t.n2 for t in schema.schema[lt[0]]]\n        list_types = [type_list[adj_n][0] for adj_n in lt[1]]\n        if (len(list_types) > 0):\n            assert (set(adj_types) == set(list_types))", "masked_code": "def test_graph_schema_sampling(example_graph_schema):\n    schema = example_graph_schema(bb=0)\n    with pytest.raises(TypeError):\n        schema.type_adjacency_list('A', 2)\n    with pytest.raises(TypeError):\n        schema.type_adjacency_list('A', None)\n    type_list = schema.type_adjacency_list(['A', 'B'], n_hops=2)\n    assert (type_list[0][0] == 'A')\n    assert (type_list[1][0] == 'B')\n    for lt in type_list:\n        adj_types = [t.n2 for t in schema.schema[lt[0]]]\n        list_types = [type_list[adj_n][0] for adj_n in lt[1]]\n        if (len(list_types) > 0):\n            assert (set(adj_types) == '???')", "ground_truth": "set(list_types)", "quality_analysis": {"complexity_score": 8, "left_complexity": 4, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_158", "reponame": "stellargraph", "testpath": "tests/core/test_schema.py", "testname": "test_schema.py", "classname": null, "funcname": "test_graph_schema_sampling_layout_1", "imports": ["import pytest", "from stellargraph.core.schema import *", "import itertools as it"], "code": "def test_graph_schema_sampling_layout_1(example_graph_schema):\n    schema = example_graph_schema(aa=0, bb=0)\n    sampling_layout = schema.sampling_layout(['A'], [2, 2])\n    assert (len(sampling_layout) == 1)\n    assert (sampling_layout[0][2] == ('A', [2, 3]))\n    assert (sampling_layout[0][1] == ('B', [1]))\n    assert (sampling_layout[0][0] == ('A', [0]))\n    schema = example_graph_schema(ab=2, ba=2, bb=0)\n    with pytest.raises(TypeError):\n        schema.sampling_layout('A', [1, 2])\n    schema = example_graph_schema(ab=2, ba=2, bb=0)\n    sampling_layout = schema.sampling_layout(('A',), [1, 2])\n    assert (len(sampling_layout) == 1)\n    assert (sampling_layout[0] == [('A', [0]), ('A', [1]), ('B', [2]), ('B', [3]), ('A', [4]), ('B', [5]), ('B', [6]), ('A', [7]), ('A', [8]), ('A', [9]), ('A', [10])])", "masked_code": "def test_graph_schema_sampling_layout_1(example_graph_schema):\n    schema = example_graph_schema(aa=0, bb=0)\n    sampling_layout = schema.sampling_layout(['A'], [2, 2])\n    assert (len(sampling_layout) == 1)\n    assert (sampling_layout[0][2] == '???')\n    assert (sampling_layout[0][1] == ('B', [1]))\n    assert (sampling_layout[0][0] == ('A', [0]))\n    schema = example_graph_schema(ab=2, ba=2, bb=0)\n    with pytest.raises(TypeError):\n        schema.sampling_layout('A', [1, 2])\n    schema = example_graph_schema(ab=2, ba=2, bb=0)\n    sampling_layout = schema.sampling_layout(('A',), [1, 2])\n    assert (len(sampling_layout) == 1)\n    assert (sampling_layout[0] == [('A', [0]), ('A', [1]), ('B', [2]), ('B', [3]), ('A', [4]), ('B', [5]), ('B', [6]), ('A', [7]), ('A', [8]), ('A', [9]), ('A', [10])])", "ground_truth": "('A', [2, 3])", "quality_analysis": {"complexity_score": 16, "left_complexity": 9, "right_complexity": 7, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_159", "reponame": "stellargraph", "testpath": "tests/core/test_schema.py", "testname": "test_schema.py", "classname": null, "funcname": "test_graph_schema_sampling_layout_1", "imports": ["import pytest", "from stellargraph.core.schema import *", "import itertools as it"], "code": "def test_graph_schema_sampling_layout_1(example_graph_schema):\n    schema = example_graph_schema(aa=0, bb=0)\n    sampling_layout = schema.sampling_layout(['A'], [2, 2])\n    assert (len(sampling_layout) == 1)\n    assert (sampling_layout[0][2] == ('A', [2, 3]))\n    assert (sampling_layout[0][1] == ('B', [1]))\n    assert (sampling_layout[0][0] == ('A', [0]))\n    schema = example_graph_schema(ab=2, ba=2, bb=0)\n    with pytest.raises(TypeError):\n        schema.sampling_layout('A', [1, 2])\n    schema = example_graph_schema(ab=2, ba=2, bb=0)\n    sampling_layout = schema.sampling_layout(('A',), [1, 2])\n    assert (len(sampling_layout) == 1)\n    assert (sampling_layout[0] == [('A', [0]), ('A', [1]), ('B', [2]), ('B', [3]), ('A', [4]), ('B', [5]), ('B', [6]), ('A', [7]), ('A', [8]), ('A', [9]), ('A', [10])])", "masked_code": "def test_graph_schema_sampling_layout_1(example_graph_schema):\n    schema = example_graph_schema(aa=0, bb=0)\n    sampling_layout = schema.sampling_layout(['A'], [2, 2])\n    assert (len(sampling_layout) == 1)\n    assert (sampling_layout[0][2] == ('A', [2, 3]))\n    assert (sampling_layout[0][1] == '???')\n    assert (sampling_layout[0][0] == ('A', [0]))\n    schema = example_graph_schema(ab=2, ba=2, bb=0)\n    with pytest.raises(TypeError):\n        schema.sampling_layout('A', [1, 2])\n    schema = example_graph_schema(ab=2, ba=2, bb=0)\n    sampling_layout = schema.sampling_layout(('A',), [1, 2])\n    assert (len(sampling_layout) == 1)\n    assert (sampling_layout[0] == [('A', [0]), ('A', [1]), ('B', [2]), ('B', [3]), ('A', [4]), ('B', [5]), ('B', [6]), ('A', [7]), ('A', [8]), ('A', [9]), ('A', [10])])", "ground_truth": "('B', [1])", "quality_analysis": {"complexity_score": 15, "left_complexity": 9, "right_complexity": 6, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_160", "reponame": "stellargraph", "testpath": "tests/core/test_schema.py", "testname": "test_schema.py", "classname": null, "funcname": "test_graph_schema_sampling_layout_1", "imports": ["import pytest", "from stellargraph.core.schema import *", "import itertools as it"], "code": "def test_graph_schema_sampling_layout_1(example_graph_schema):\n    schema = example_graph_schema(aa=0, bb=0)\n    sampling_layout = schema.sampling_layout(['A'], [2, 2])\n    assert (len(sampling_layout) == 1)\n    assert (sampling_layout[0][2] == ('A', [2, 3]))\n    assert (sampling_layout[0][1] == ('B', [1]))\n    assert (sampling_layout[0][0] == ('A', [0]))\n    schema = example_graph_schema(ab=2, ba=2, bb=0)\n    with pytest.raises(TypeError):\n        schema.sampling_layout('A', [1, 2])\n    schema = example_graph_schema(ab=2, ba=2, bb=0)\n    sampling_layout = schema.sampling_layout(('A',), [1, 2])\n    assert (len(sampling_layout) == 1)\n    assert (sampling_layout[0] == [('A', [0]), ('A', [1]), ('B', [2]), ('B', [3]), ('A', [4]), ('B', [5]), ('B', [6]), ('A', [7]), ('A', [8]), ('A', [9]), ('A', [10])])", "masked_code": "def test_graph_schema_sampling_layout_1(example_graph_schema):\n    schema = example_graph_schema(aa=0, bb=0)\n    sampling_layout = schema.sampling_layout(['A'], [2, 2])\n    assert (len(sampling_layout) == 1)\n    assert (sampling_layout[0][2] == ('A', [2, 3]))\n    assert (sampling_layout[0][1] == ('B', [1]))\n    assert (sampling_layout[0][0] == '???')\n    schema = example_graph_schema(ab=2, ba=2, bb=0)\n    with pytest.raises(TypeError):\n        schema.sampling_layout('A', [1, 2])\n    schema = example_graph_schema(ab=2, ba=2, bb=0)\n    sampling_layout = schema.sampling_layout(('A',), [1, 2])\n    assert (len(sampling_layout) == 1)\n    assert (sampling_layout[0] == [('A', [0]), ('A', [1]), ('B', [2]), ('B', [3]), ('A', [4]), ('B', [5]), ('B', [6]), ('A', [7]), ('A', [8]), ('A', [9]), ('A', [10])])", "ground_truth": "('A', [0])", "quality_analysis": {"complexity_score": 15, "left_complexity": 9, "right_complexity": 6, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_161", "reponame": "stellargraph", "testpath": "tests/core/test_schema.py", "testname": "test_schema.py", "classname": null, "funcname": "test_graph_schema_sampling_layout_1", "imports": ["import pytest", "from stellargraph.core.schema import *", "import itertools as it"], "code": "def test_graph_schema_sampling_layout_1(example_graph_schema):\n    schema = example_graph_schema(aa=0, bb=0)\n    sampling_layout = schema.sampling_layout(['A'], [2, 2])\n    assert (len(sampling_layout) == 1)\n    assert (sampling_layout[0][2] == ('A', [2, 3]))\n    assert (sampling_layout[0][1] == ('B', [1]))\n    assert (sampling_layout[0][0] == ('A', [0]))\n    schema = example_graph_schema(ab=2, ba=2, bb=0)\n    with pytest.raises(TypeError):\n        schema.sampling_layout('A', [1, 2])\n    schema = example_graph_schema(ab=2, ba=2, bb=0)\n    sampling_layout = schema.sampling_layout(('A',), [1, 2])\n    assert (len(sampling_layout) == 1)\n    assert (sampling_layout[0] == [('A', [0]), ('A', [1]), ('B', [2]), ('B', [3]), ('A', [4]), ('B', [5]), ('B', [6]), ('A', [7]), ('A', [8]), ('A', [9]), ('A', [10])])", "masked_code": "def test_graph_schema_sampling_layout_1(example_graph_schema):\n    schema = example_graph_schema(aa=0, bb=0)\n    sampling_layout = schema.sampling_layout(['A'], [2, 2])\n    assert (len(sampling_layout) == 1)\n    assert (sampling_layout[0][2] == ('A', [2, 3]))\n    assert (sampling_layout[0][1] == ('B', [1]))\n    assert (sampling_layout[0][0] == ('A', [0]))\n    schema = example_graph_schema(ab=2, ba=2, bb=0)\n    with pytest.raises(TypeError):\n        schema.sampling_layout('A', [1, 2])\n    schema = example_graph_schema(ab=2, ba=2, bb=0)\n    sampling_layout = schema.sampling_layout(('A',), [1, 2])\n    assert (len(sampling_layout) == 1)\n    assert (sampling_layout[0] == '???')", "ground_truth": "[('A', [0]), ('A', [1]), ('B', [2]), ('B', [3]), ('A', [4]), ('B', [5]), ('B', [6]), ('A', [7]), ('A', [8]), ('A', [9]), ('A', [10])]", "quality_analysis": {"complexity_score": 73, "left_complexity": 5, "right_complexity": 68, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_162", "reponame": "stellargraph", "testpath": "tests/core/test_schema.py", "testname": "test_schema.py", "classname": null, "funcname": "test_graph_schema_sampling_tree", "imports": ["import pytest", "from stellargraph.core.schema import *", "import itertools as it"], "code": "def test_graph_schema_sampling_tree(example_graph_schema):\n    schema = example_graph_schema(bb=0)\n    type_list = schema.type_adjacency_list(['A', 'B'], 3)\n    (_, type_tree) = schema.sampling_tree(['A', 'B'], 3)\n\n    def check_tree(tree):\n        items = []\n        for x in tree:\n            chd = check_tree(x[2])\n            assert (x[1] == type_list[x[0]][0])\n            assert (chd == type_list[x[0]][1])\n            items.append(x[0])\n        return items\n    check_tree(type_tree)", "masked_code": "def test_graph_schema_sampling_tree(example_graph_schema):\n    schema = example_graph_schema(bb=0)\n    type_list = schema.type_adjacency_list(['A', 'B'], 3)\n    (_, type_tree) = schema.sampling_tree(['A', 'B'], 3)\n\n    def check_tree(tree):\n        items = []\n        for x in tree:\n            chd = check_tree(x[2])\n            assert (x[1] == '???')\n            assert (chd == type_list[x[0]][1])\n            items.append(x[0])\n        return items\n    check_tree(type_tree)", "ground_truth": "type_list[x[0]][0]", "quality_analysis": {"complexity_score": 18, "left_complexity": 5, "right_complexity": 13, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_163", "reponame": "stellargraph", "testpath": "tests/core/test_schema.py", "testname": "test_schema.py", "classname": null, "funcname": "test_graph_schema_sampling_layout_multiple", "imports": ["import pytest", "from stellargraph.core.schema import *", "import itertools as it"], "code": "def test_graph_schema_sampling_layout_multiple(example_graph_schema):\n    schema = example_graph_schema(bb=0)\n    sampling_layout = schema.sampling_layout(['A', 'B'], [2, 2])\n    assert (len(sampling_layout) == 2)\n    assert all(((x1[0] == x2[0]) for (x1, x2) in zip(*sampling_layout)))\n    print(sampling_layout[0])\n    assert (sampling_layout[0] == [('A', [0]), ('B', []), ('A', [1]), ('B', [2]), ('A', []), ('A', [3, 5]), ('B', [4, 6]), ('A', [7, 8]), ('A', []), ('B', [])])\n    assert (sampling_layout[1] == [('A', []), ('B', [0]), ('A', []), ('B', []), ('A', [1]), ('A', []), ('B', []), ('A', []), ('A', [2, 4]), ('B', [3, 5])])", "masked_code": "def test_graph_schema_sampling_layout_multiple(example_graph_schema):\n    schema = example_graph_schema(bb=0)\n    sampling_layout = schema.sampling_layout(['A', 'B'], [2, 2])\n    assert (len(sampling_layout) == 2)\n    assert all(((x1[0] == x2[0]) for (x1, x2) in zip(*sampling_layout)))\n    print(sampling_layout[0])\n    assert (sampling_layout[0] == '???')\n    assert (sampling_layout[1] == [('A', []), ('B', [0]), ('A', []), ('B', []), ('A', [1]), ('A', []), ('B', []), ('A', []), ('A', [2, 4]), ('B', [3, 5])])", "ground_truth": "[('A', [0]), ('B', []), ('A', [1]), ('B', [2]), ('A', []), ('A', [3, 5]), ('B', [4, 6]), ('A', [7, 8]), ('A', []), ('B', [])]", "quality_analysis": {"complexity_score": 66, "left_complexity": 5, "right_complexity": 61, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_164", "reponame": "stellargraph", "testpath": "tests/core/test_schema.py", "testname": "test_schema.py", "classname": null, "funcname": "test_graph_schema_sampling_layout_multiple", "imports": ["import pytest", "from stellargraph.core.schema import *", "import itertools as it"], "code": "def test_graph_schema_sampling_layout_multiple(example_graph_schema):\n    schema = example_graph_schema(bb=0)\n    sampling_layout = schema.sampling_layout(['A', 'B'], [2, 2])\n    assert (len(sampling_layout) == 2)\n    assert all(((x1[0] == x2[0]) for (x1, x2) in zip(*sampling_layout)))\n    print(sampling_layout[0])\n    assert (sampling_layout[0] == [('A', [0]), ('B', []), ('A', [1]), ('B', [2]), ('A', []), ('A', [3, 5]), ('B', [4, 6]), ('A', [7, 8]), ('A', []), ('B', [])])\n    assert (sampling_layout[1] == [('A', []), ('B', [0]), ('A', []), ('B', []), ('A', [1]), ('A', []), ('B', []), ('A', []), ('A', [2, 4]), ('B', [3, 5])])", "masked_code": "def test_graph_schema_sampling_layout_multiple(example_graph_schema):\n    schema = example_graph_schema(bb=0)\n    sampling_layout = schema.sampling_layout(['A', 'B'], [2, 2])\n    assert (len(sampling_layout) == 2)\n    assert all(((x1[0] == x2[0]) for (x1, x2) in zip(*sampling_layout)))\n    print(sampling_layout[0])\n    assert (sampling_layout[0] == [('A', [0]), ('B', []), ('A', [1]), ('B', [2]), ('A', []), ('A', [3, 5]), ('B', [4, 6]), ('A', [7, 8]), ('A', []), ('B', [])])\n    assert (sampling_layout[1] == '???')", "ground_truth": "[('A', []), ('B', [0]), ('A', []), ('B', []), ('A', [1]), ('A', []), ('B', []), ('A', []), ('A', [2, 4]), ('B', [3, 5])]", "quality_analysis": {"complexity_score": 63, "left_complexity": 5, "right_complexity": 58, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_165", "reponame": "stellargraph", "testpath": "tests/core/test_utils.py", "testname": "test_utils.py", "classname": null, "funcname": "test_normalize_adj", "imports": ["import pytest", "import numpy as np", "from stellargraph.core.utils import *", "from ..test_utils import flaky_xfail_mark", "from ..test_utils.graphs import example_graph_random"], "code": "def test_normalize_adj(example_graph):\n    node_list = list(example_graph.nodes())\n    Aadj = example_graph.to_adjacency_matrix()\n    csr = normalize_adj(Aadj, symmetric=True)\n    dense = csr.todense()\n    (eigen_vals, _) = np.linalg.eig(dense)\n    assert (eigen_vals.max() == pytest.approx(1, abs=1e-05))\n    assert (csr.get_shape() == Aadj.get_shape())\n    csr = normalize_adj(Aadj, symmetric=False)\n    dense = csr.todense()\n    num_pos_degree_nodes = (Aadj.sum(axis=1) > 0).sum()\n    assert (num_pos_degree_nodes == pytest.approx(dense.sum(), 0.1))\n    assert (csr.get_shape() == Aadj.get_shape())", "masked_code": "def test_normalize_adj(example_graph):\n    node_list = list(example_graph.nodes())\n    Aadj = example_graph.to_adjacency_matrix()\n    csr = normalize_adj(Aadj, symmetric=True)\n    dense = csr.todense()\n    (eigen_vals, _) = np.linalg.eig(dense)\n    assert (eigen_vals.max() == '???')\n    assert (csr.get_shape() == Aadj.get_shape())\n    csr = normalize_adj(Aadj, symmetric=False)\n    dense = csr.todense()\n    num_pos_degree_nodes = (Aadj.sum(axis=1) > 0).sum()\n    assert (num_pos_degree_nodes == pytest.approx(dense.sum(), 0.1))\n    assert (csr.get_shape() == Aadj.get_shape())", "ground_truth": "pytest.approx(1, abs=1e-05)", "quality_analysis": {"complexity_score": 7, "left_complexity": 3, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_166", "reponame": "stellargraph", "testpath": "tests/core/test_utils.py", "testname": "test_utils.py", "classname": null, "funcname": "test_normalize_adj", "imports": ["import pytest", "import numpy as np", "from stellargraph.core.utils import *", "from ..test_utils import flaky_xfail_mark", "from ..test_utils.graphs import example_graph_random"], "code": "def test_normalize_adj(example_graph):\n    node_list = list(example_graph.nodes())\n    Aadj = example_graph.to_adjacency_matrix()\n    csr = normalize_adj(Aadj, symmetric=True)\n    dense = csr.todense()\n    (eigen_vals, _) = np.linalg.eig(dense)\n    assert (eigen_vals.max() == pytest.approx(1, abs=1e-05))\n    assert (csr.get_shape() == Aadj.get_shape())\n    csr = normalize_adj(Aadj, symmetric=False)\n    dense = csr.todense()\n    num_pos_degree_nodes = (Aadj.sum(axis=1) > 0).sum()\n    assert (num_pos_degree_nodes == pytest.approx(dense.sum(), 0.1))\n    assert (csr.get_shape() == Aadj.get_shape())", "masked_code": "def test_normalize_adj(example_graph):\n    node_list = list(example_graph.nodes())\n    Aadj = example_graph.to_adjacency_matrix()\n    csr = normalize_adj(Aadj, symmetric=True)\n    dense = csr.todense()\n    (eigen_vals, _) = np.linalg.eig(dense)\n    assert (eigen_vals.max() == pytest.approx(1, abs=1e-05))\n    assert (csr.get_shape() == '???')\n    csr = normalize_adj(Aadj, symmetric=False)\n    dense = csr.todense()\n    num_pos_degree_nodes = (Aadj.sum(axis=1) > 0).sum()\n    assert (num_pos_degree_nodes == pytest.approx(dense.sum(), 0.1))\n    assert (csr.get_shape() == Aadj.get_shape())", "ground_truth": "Aadj.get_shape()", "quality_analysis": {"complexity_score": 6, "left_complexity": 3, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_167", "reponame": "stellargraph", "testpath": "tests/core/test_utils.py", "testname": "test_utils.py", "classname": null, "funcname": "test_normalize_adj", "imports": ["import pytest", "import numpy as np", "from stellargraph.core.utils import *", "from ..test_utils import flaky_xfail_mark", "from ..test_utils.graphs import example_graph_random"], "code": "def test_normalize_adj(example_graph):\n    node_list = list(example_graph.nodes())\n    Aadj = example_graph.to_adjacency_matrix()\n    csr = normalize_adj(Aadj, symmetric=True)\n    dense = csr.todense()\n    (eigen_vals, _) = np.linalg.eig(dense)\n    assert (eigen_vals.max() == pytest.approx(1, abs=1e-05))\n    assert (csr.get_shape() == Aadj.get_shape())\n    csr = normalize_adj(Aadj, symmetric=False)\n    dense = csr.todense()\n    num_pos_degree_nodes = (Aadj.sum(axis=1) > 0).sum()\n    assert (num_pos_degree_nodes == pytest.approx(dense.sum(), 0.1))\n    assert (csr.get_shape() == Aadj.get_shape())", "masked_code": "def test_normalize_adj(example_graph):\n    node_list = list(example_graph.nodes())\n    Aadj = example_graph.to_adjacency_matrix()\n    csr = normalize_adj(Aadj, symmetric=True)\n    dense = csr.todense()\n    (eigen_vals, _) = np.linalg.eig(dense)\n    assert (eigen_vals.max() == pytest.approx(1, abs=1e-05))\n    assert (csr.get_shape() == Aadj.get_shape())\n    csr = normalize_adj(Aadj, symmetric=False)\n    dense = csr.todense()\n    num_pos_degree_nodes = (Aadj.sum(axis=1) > 0).sum()\n    assert (num_pos_degree_nodes == pytest.approx(dense.sum(), 0.1))\n    assert (csr.get_shape() == '???')", "ground_truth": "Aadj.get_shape()", "quality_analysis": {"complexity_score": 6, "left_complexity": 3, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_168", "reponame": "stellargraph", "testpath": "tests/core/test_utils.py", "testname": "test_utils.py", "classname": null, "funcname": "test_normalized_laplacian", "imports": ["import pytest", "import numpy as np", "from stellargraph.core.utils import *", "from ..test_utils import flaky_xfail_mark", "from ..test_utils.graphs import example_graph_random"], "code": "def test_normalized_laplacian(example_graph):\n    Aadj = example_graph.to_adjacency_matrix()\n    laplacian = normalized_laplacian(Aadj).todense()\n    (eigenvalues, _) = np.linalg.eig(laplacian)\n    assert (eigenvalues.min() == pytest.approx(0, abs=1e-07))\n    assert (eigenvalues.max() <= (2 + 1e-07))\n    assert (laplacian.shape == Aadj.get_shape())\n    laplacian = normalized_laplacian(Aadj, symmetric=False)\n    num_degree_zero_nodes = (Aadj.sum(axis=1) == 0).sum()\n    assert (num_degree_zero_nodes == pytest.approx(laplacian.sum(), abs=1e-07))\n    assert (laplacian.get_shape() == Aadj.get_shape())", "masked_code": "def test_normalized_laplacian(example_graph):\n    Aadj = example_graph.to_adjacency_matrix()\n    laplacian = normalized_laplacian(Aadj).todense()\n    (eigenvalues, _) = np.linalg.eig(laplacian)\n    assert (eigenvalues.min() == '???')\n    assert (eigenvalues.max() <= (2 + 1e-07))\n    assert (laplacian.shape == Aadj.get_shape())\n    laplacian = normalized_laplacian(Aadj, symmetric=False)\n    num_degree_zero_nodes = (Aadj.sum(axis=1) == 0).sum()\n    assert (num_degree_zero_nodes == pytest.approx(laplacian.sum(), abs=1e-07))\n    assert (laplacian.get_shape() == Aadj.get_shape())", "ground_truth": "pytest.approx(0, abs=1e-07)", "quality_analysis": {"complexity_score": 7, "left_complexity": 3, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_169", "reponame": "stellargraph", "testpath": "tests/core/test_utils.py", "testname": "test_utils.py", "classname": null, "funcname": "test_normalized_laplacian", "imports": ["import pytest", "import numpy as np", "from stellargraph.core.utils import *", "from ..test_utils import flaky_xfail_mark", "from ..test_utils.graphs import example_graph_random"], "code": "def test_normalized_laplacian(example_graph):\n    Aadj = example_graph.to_adjacency_matrix()\n    laplacian = normalized_laplacian(Aadj).todense()\n    (eigenvalues, _) = np.linalg.eig(laplacian)\n    assert (eigenvalues.min() == pytest.approx(0, abs=1e-07))\n    assert (eigenvalues.max() <= (2 + 1e-07))\n    assert (laplacian.shape == Aadj.get_shape())\n    laplacian = normalized_laplacian(Aadj, symmetric=False)\n    num_degree_zero_nodes = (Aadj.sum(axis=1) == 0).sum()\n    assert (num_degree_zero_nodes == pytest.approx(laplacian.sum(), abs=1e-07))\n    assert (laplacian.get_shape() == Aadj.get_shape())", "masked_code": "def test_normalized_laplacian(example_graph):\n    Aadj = example_graph.to_adjacency_matrix()\n    laplacian = normalized_laplacian(Aadj).todense()\n    (eigenvalues, _) = np.linalg.eig(laplacian)\n    assert (eigenvalues.min() == pytest.approx(0, abs=1e-07))\n    assert (eigenvalues.max() <= (2 + 1e-07))\n    assert (laplacian.shape == '???')\n    laplacian = normalized_laplacian(Aadj, symmetric=False)\n    num_degree_zero_nodes = (Aadj.sum(axis=1) == 0).sum()\n    assert (num_degree_zero_nodes == pytest.approx(laplacian.sum(), abs=1e-07))\n    assert (laplacian.get_shape() == Aadj.get_shape())", "ground_truth": "Aadj.get_shape()", "quality_analysis": {"complexity_score": 5, "left_complexity": 2, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_170", "reponame": "stellargraph", "testpath": "tests/core/test_utils.py", "testname": "test_utils.py", "classname": null, "funcname": "test_normalized_laplacian", "imports": ["import pytest", "import numpy as np", "from stellargraph.core.utils import *", "from ..test_utils import flaky_xfail_mark", "from ..test_utils.graphs import example_graph_random"], "code": "def test_normalized_laplacian(example_graph):\n    Aadj = example_graph.to_adjacency_matrix()\n    laplacian = normalized_laplacian(Aadj).todense()\n    (eigenvalues, _) = np.linalg.eig(laplacian)\n    assert (eigenvalues.min() == pytest.approx(0, abs=1e-07))\n    assert (eigenvalues.max() <= (2 + 1e-07))\n    assert (laplacian.shape == Aadj.get_shape())\n    laplacian = normalized_laplacian(Aadj, symmetric=False)\n    num_degree_zero_nodes = (Aadj.sum(axis=1) == 0).sum()\n    assert (num_degree_zero_nodes == pytest.approx(laplacian.sum(), abs=1e-07))\n    assert (laplacian.get_shape() == Aadj.get_shape())", "masked_code": "def test_normalized_laplacian(example_graph):\n    Aadj = example_graph.to_adjacency_matrix()\n    laplacian = normalized_laplacian(Aadj).todense()\n    (eigenvalues, _) = np.linalg.eig(laplacian)\n    assert (eigenvalues.min() == pytest.approx(0, abs=1e-07))\n    assert (eigenvalues.max() <= (2 + 1e-07))\n    assert (laplacian.shape == Aadj.get_shape())\n    laplacian = normalized_laplacian(Aadj, symmetric=False)\n    num_degree_zero_nodes = (Aadj.sum(axis=1) == 0).sum()\n    assert (num_degree_zero_nodes == pytest.approx(laplacian.sum(), abs=1e-07))\n    assert (laplacian.get_shape() == '???')", "ground_truth": "Aadj.get_shape()", "quality_analysis": {"complexity_score": 6, "left_complexity": 3, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_171", "reponame": "stellargraph", "testpath": "tests/core/test_utils.py", "testname": "test_utils.py", "classname": null, "funcname": "test_rescale_laplacian", "imports": ["import pytest", "import numpy as np", "from stellargraph.core.utils import *", "from ..test_utils import flaky_xfail_mark", "from ..test_utils.graphs import example_graph_random"], "code": "def test_rescale_laplacian(example_graph):\n    node_list = list(example_graph.nodes())\n    Aadj = example_graph.to_adjacency_matrix()\n    rl = rescale_laplacian(normalized_laplacian(Aadj))\n    assert (rl.max() < 1)\n    assert (rl.get_shape() == Aadj.get_shape())", "masked_code": "def test_rescale_laplacian(example_graph):\n    node_list = list(example_graph.nodes())\n    Aadj = example_graph.to_adjacency_matrix()\n    rl = rescale_laplacian(normalized_laplacian(Aadj))\n    assert (rl.max() < 1)\n    assert (rl.get_shape() == '???')", "ground_truth": "Aadj.get_shape()", "quality_analysis": {"complexity_score": 6, "left_complexity": 3, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_172", "reponame": "stellargraph", "testpath": "tests/core/test_utils.py", "testname": "test_utils.py", "classname": null, "funcname": "test_GCN_Aadj_feats_op", "imports": ["import pytest", "import numpy as np", "from stellargraph.core.utils import *", "from ..test_utils import flaky_xfail_mark", "from ..test_utils.graphs import example_graph_random"], "code": "def test_GCN_Aadj_feats_op(example_graph):\n    node_list = list(example_graph.nodes())\n    Aadj = example_graph.to_adjacency_matrix()\n    features = example_graph.node_features(node_list)\n    (features_, Aadj_) = GCN_Aadj_feats_op(features=features, A=Aadj, method='gcn')\n    np.testing.assert_array_equal(features, features_)\n    assert (6 == pytest.approx(Aadj_.todense().sum(), 0.1))\n    with pytest.raises(ValueError):\n        GCN_Aadj_feats_op(features=features, A=Aadj, method='sgc', k=None)\n    with pytest.raises(ValueError):\n        GCN_Aadj_feats_op(features=features, A=Aadj, method='sgc', k=0)\n    with pytest.raises(ValueError):\n        GCN_Aadj_feats_op(features=features, A=Aadj, method='sgc', k=(- 191))\n    with pytest.raises(ValueError):\n        GCN_Aadj_feats_op(features=features, A=Aadj, method='sgc', k=2.0)\n    (features_, Aadj_) = GCN_Aadj_feats_op(features=features, A=Aadj, method='sgc', k=2)\n    assert (len(features_) == 6)\n    np.testing.assert_array_equal(features, features_)\n    assert (Aadj.get_shape() == Aadj_.get_shape())\n    (features_, Aadj_norm) = GCN_Aadj_feats_op(features=features, A=Aadj, method='gcn')\n    Aadj_norm = Aadj_norm.todense()\n    Aadj_power_2 = np.linalg.matrix_power(Aadj_norm, 2)\n    assert (Aadj_power_2.shape == Aadj_.get_shape())\n    assert (pytest.approx(Aadj_power_2) == Aadj_.todense())", "masked_code": "def test_GCN_Aadj_feats_op(example_graph):\n    node_list = list(example_graph.nodes())\n    Aadj = example_graph.to_adjacency_matrix()\n    features = example_graph.node_features(node_list)\n    (features_, Aadj_) = GCN_Aadj_feats_op(features=features, A=Aadj, method='gcn')\n    np.testing.assert_array_equal(features, features_)\n    assert (6 == pytest.approx(Aadj_.todense().sum(), 0.1))\n    with pytest.raises(ValueError):\n        GCN_Aadj_feats_op(features=features, A=Aadj, method='sgc', k=None)\n    with pytest.raises(ValueError):\n        GCN_Aadj_feats_op(features=features, A=Aadj, method='sgc', k=0)\n    with pytest.raises(ValueError):\n        GCN_Aadj_feats_op(features=features, A=Aadj, method='sgc', k=(- 191))\n    with pytest.raises(ValueError):\n        GCN_Aadj_feats_op(features=features, A=Aadj, method='sgc', k=2.0)\n    (features_, Aadj_) = GCN_Aadj_feats_op(features=features, A=Aadj, method='sgc', k=2)\n    assert (len(features_) == '???')\n    np.testing.assert_array_equal(features, features_)\n    assert (Aadj.get_shape() == Aadj_.get_shape())\n    (features_, Aadj_norm) = GCN_Aadj_feats_op(features=features, A=Aadj, method='gcn')\n    Aadj_norm = Aadj_norm.todense()\n    Aadj_power_2 = np.linalg.matrix_power(Aadj_norm, 2)\n    assert (Aadj_power_2.shape == Aadj_.get_shape())\n    assert (pytest.approx(Aadj_power_2) == Aadj_.todense())", "ground_truth": "6", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_173", "reponame": "stellargraph", "testpath": "tests/core/test_utils.py", "testname": "test_utils.py", "classname": null, "funcname": "test_GCN_Aadj_feats_op", "imports": ["import pytest", "import numpy as np", "from stellargraph.core.utils import *", "from ..test_utils import flaky_xfail_mark", "from ..test_utils.graphs import example_graph_random"], "code": "def test_GCN_Aadj_feats_op(example_graph):\n    node_list = list(example_graph.nodes())\n    Aadj = example_graph.to_adjacency_matrix()\n    features = example_graph.node_features(node_list)\n    (features_, Aadj_) = GCN_Aadj_feats_op(features=features, A=Aadj, method='gcn')\n    np.testing.assert_array_equal(features, features_)\n    assert (6 == pytest.approx(Aadj_.todense().sum(), 0.1))\n    with pytest.raises(ValueError):\n        GCN_Aadj_feats_op(features=features, A=Aadj, method='sgc', k=None)\n    with pytest.raises(ValueError):\n        GCN_Aadj_feats_op(features=features, A=Aadj, method='sgc', k=0)\n    with pytest.raises(ValueError):\n        GCN_Aadj_feats_op(features=features, A=Aadj, method='sgc', k=(- 191))\n    with pytest.raises(ValueError):\n        GCN_Aadj_feats_op(features=features, A=Aadj, method='sgc', k=2.0)\n    (features_, Aadj_) = GCN_Aadj_feats_op(features=features, A=Aadj, method='sgc', k=2)\n    assert (len(features_) == 6)\n    np.testing.assert_array_equal(features, features_)\n    assert (Aadj.get_shape() == Aadj_.get_shape())\n    (features_, Aadj_norm) = GCN_Aadj_feats_op(features=features, A=Aadj, method='gcn')\n    Aadj_norm = Aadj_norm.todense()\n    Aadj_power_2 = np.linalg.matrix_power(Aadj_norm, 2)\n    assert (Aadj_power_2.shape == Aadj_.get_shape())\n    assert (pytest.approx(Aadj_power_2) == Aadj_.todense())", "masked_code": "def test_GCN_Aadj_feats_op(example_graph):\n    node_list = list(example_graph.nodes())\n    Aadj = example_graph.to_adjacency_matrix()\n    features = example_graph.node_features(node_list)\n    (features_, Aadj_) = GCN_Aadj_feats_op(features=features, A=Aadj, method='gcn')\n    np.testing.assert_array_equal(features, features_)\n    assert (6 == pytest.approx(Aadj_.todense().sum(), 0.1))\n    with pytest.raises(ValueError):\n        GCN_Aadj_feats_op(features=features, A=Aadj, method='sgc', k=None)\n    with pytest.raises(ValueError):\n        GCN_Aadj_feats_op(features=features, A=Aadj, method='sgc', k=0)\n    with pytest.raises(ValueError):\n        GCN_Aadj_feats_op(features=features, A=Aadj, method='sgc', k=(- 191))\n    with pytest.raises(ValueError):\n        GCN_Aadj_feats_op(features=features, A=Aadj, method='sgc', k=2.0)\n    (features_, Aadj_) = GCN_Aadj_feats_op(features=features, A=Aadj, method='sgc', k=2)\n    assert (len(features_) == 6)\n    np.testing.assert_array_equal(features, features_)\n    assert (Aadj.get_shape() == '???')\n    (features_, Aadj_norm) = GCN_Aadj_feats_op(features=features, A=Aadj, method='gcn')\n    Aadj_norm = Aadj_norm.todense()\n    Aadj_power_2 = np.linalg.matrix_power(Aadj_norm, 2)\n    assert (Aadj_power_2.shape == Aadj_.get_shape())\n    assert (pytest.approx(Aadj_power_2) == Aadj_.todense())", "ground_truth": "Aadj_.get_shape()", "quality_analysis": {"complexity_score": 6, "left_complexity": 3, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_174", "reponame": "stellargraph", "testpath": "tests/core/test_utils.py", "testname": "test_utils.py", "classname": null, "funcname": "test_GCN_Aadj_feats_op", "imports": ["import pytest", "import numpy as np", "from stellargraph.core.utils import *", "from ..test_utils import flaky_xfail_mark", "from ..test_utils.graphs import example_graph_random"], "code": "def test_GCN_Aadj_feats_op(example_graph):\n    node_list = list(example_graph.nodes())\n    Aadj = example_graph.to_adjacency_matrix()\n    features = example_graph.node_features(node_list)\n    (features_, Aadj_) = GCN_Aadj_feats_op(features=features, A=Aadj, method='gcn')\n    np.testing.assert_array_equal(features, features_)\n    assert (6 == pytest.approx(Aadj_.todense().sum(), 0.1))\n    with pytest.raises(ValueError):\n        GCN_Aadj_feats_op(features=features, A=Aadj, method='sgc', k=None)\n    with pytest.raises(ValueError):\n        GCN_Aadj_feats_op(features=features, A=Aadj, method='sgc', k=0)\n    with pytest.raises(ValueError):\n        GCN_Aadj_feats_op(features=features, A=Aadj, method='sgc', k=(- 191))\n    with pytest.raises(ValueError):\n        GCN_Aadj_feats_op(features=features, A=Aadj, method='sgc', k=2.0)\n    (features_, Aadj_) = GCN_Aadj_feats_op(features=features, A=Aadj, method='sgc', k=2)\n    assert (len(features_) == 6)\n    np.testing.assert_array_equal(features, features_)\n    assert (Aadj.get_shape() == Aadj_.get_shape())\n    (features_, Aadj_norm) = GCN_Aadj_feats_op(features=features, A=Aadj, method='gcn')\n    Aadj_norm = Aadj_norm.todense()\n    Aadj_power_2 = np.linalg.matrix_power(Aadj_norm, 2)\n    assert (Aadj_power_2.shape == Aadj_.get_shape())\n    assert (pytest.approx(Aadj_power_2) == Aadj_.todense())", "masked_code": "def test_GCN_Aadj_feats_op(example_graph):\n    node_list = list(example_graph.nodes())\n    Aadj = example_graph.to_adjacency_matrix()\n    features = example_graph.node_features(node_list)\n    (features_, Aadj_) = GCN_Aadj_feats_op(features=features, A=Aadj, method='gcn')\n    np.testing.assert_array_equal(features, features_)\n    assert (6 == pytest.approx(Aadj_.todense().sum(), 0.1))\n    with pytest.raises(ValueError):\n        GCN_Aadj_feats_op(features=features, A=Aadj, method='sgc', k=None)\n    with pytest.raises(ValueError):\n        GCN_Aadj_feats_op(features=features, A=Aadj, method='sgc', k=0)\n    with pytest.raises(ValueError):\n        GCN_Aadj_feats_op(features=features, A=Aadj, method='sgc', k=(- 191))\n    with pytest.raises(ValueError):\n        GCN_Aadj_feats_op(features=features, A=Aadj, method='sgc', k=2.0)\n    (features_, Aadj_) = GCN_Aadj_feats_op(features=features, A=Aadj, method='sgc', k=2)\n    assert (len(features_) == 6)\n    np.testing.assert_array_equal(features, features_)\n    assert (Aadj.get_shape() == Aadj_.get_shape())\n    (features_, Aadj_norm) = GCN_Aadj_feats_op(features=features, A=Aadj, method='gcn')\n    Aadj_norm = Aadj_norm.todense()\n    Aadj_power_2 = np.linalg.matrix_power(Aadj_norm, 2)\n    assert (Aadj_power_2.shape == '???')\n    assert (pytest.approx(Aadj_power_2) == Aadj_.todense())", "ground_truth": "Aadj_.get_shape()", "quality_analysis": {"complexity_score": 5, "left_complexity": 2, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_175", "reponame": "stellargraph", "testpath": "tests/core/test_utils.py", "testname": "test_utils.py", "classname": null, "funcname": "test_GCN_Aadj_feats_op", "imports": ["import pytest", "import numpy as np", "from stellargraph.core.utils import *", "from ..test_utils import flaky_xfail_mark", "from ..test_utils.graphs import example_graph_random"], "code": "def test_GCN_Aadj_feats_op(example_graph):\n    node_list = list(example_graph.nodes())\n    Aadj = example_graph.to_adjacency_matrix()\n    features = example_graph.node_features(node_list)\n    (features_, Aadj_) = GCN_Aadj_feats_op(features=features, A=Aadj, method='gcn')\n    np.testing.assert_array_equal(features, features_)\n    assert (6 == pytest.approx(Aadj_.todense().sum(), 0.1))\n    with pytest.raises(ValueError):\n        GCN_Aadj_feats_op(features=features, A=Aadj, method='sgc', k=None)\n    with pytest.raises(ValueError):\n        GCN_Aadj_feats_op(features=features, A=Aadj, method='sgc', k=0)\n    with pytest.raises(ValueError):\n        GCN_Aadj_feats_op(features=features, A=Aadj, method='sgc', k=(- 191))\n    with pytest.raises(ValueError):\n        GCN_Aadj_feats_op(features=features, A=Aadj, method='sgc', k=2.0)\n    (features_, Aadj_) = GCN_Aadj_feats_op(features=features, A=Aadj, method='sgc', k=2)\n    assert (len(features_) == 6)\n    np.testing.assert_array_equal(features, features_)\n    assert (Aadj.get_shape() == Aadj_.get_shape())\n    (features_, Aadj_norm) = GCN_Aadj_feats_op(features=features, A=Aadj, method='gcn')\n    Aadj_norm = Aadj_norm.todense()\n    Aadj_power_2 = np.linalg.matrix_power(Aadj_norm, 2)\n    assert (Aadj_power_2.shape == Aadj_.get_shape())\n    assert (pytest.approx(Aadj_power_2) == Aadj_.todense())", "masked_code": "def test_GCN_Aadj_feats_op(example_graph):\n    node_list = list(example_graph.nodes())\n    Aadj = example_graph.to_adjacency_matrix()\n    features = example_graph.node_features(node_list)\n    (features_, Aadj_) = GCN_Aadj_feats_op(features=features, A=Aadj, method='gcn')\n    np.testing.assert_array_equal(features, features_)\n    assert (6 == pytest.approx(Aadj_.todense().sum(), 0.1))\n    with pytest.raises(ValueError):\n        GCN_Aadj_feats_op(features=features, A=Aadj, method='sgc', k=None)\n    with pytest.raises(ValueError):\n        GCN_Aadj_feats_op(features=features, A=Aadj, method='sgc', k=0)\n    with pytest.raises(ValueError):\n        GCN_Aadj_feats_op(features=features, A=Aadj, method='sgc', k=(- 191))\n    with pytest.raises(ValueError):\n        GCN_Aadj_feats_op(features=features, A=Aadj, method='sgc', k=2.0)\n    (features_, Aadj_) = GCN_Aadj_feats_op(features=features, A=Aadj, method='sgc', k=2)\n    assert (len(features_) == 6)\n    np.testing.assert_array_equal(features, features_)\n    assert (Aadj.get_shape() == Aadj_.get_shape())\n    (features_, Aadj_norm) = GCN_Aadj_feats_op(features=features, A=Aadj, method='gcn')\n    Aadj_norm = Aadj_norm.todense()\n    Aadj_power_2 = np.linalg.matrix_power(Aadj_norm, 2)\n    assert (Aadj_power_2.shape == Aadj_.get_shape())\n    assert (pytest.approx(Aadj_power_2) == '???')", "ground_truth": "Aadj_.todense()", "quality_analysis": {"complexity_score": 7, "left_complexity": 4, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_176", "reponame": "stellargraph", "testpath": "tests/data/test_biased_random_walker.py", "testname": "test_biased_random_walker.py", "classname": "TestBiasedWeightedRandomWalk", "funcname": "test_weighted_walks", "imports": ["import numpy as np", "import pandas as pd", "import pytest", "import networkx as nx", "from stellargraph.data.explorer import BiasedRandomWalk", "from stellargraph.core.graph import StellarGraph", "from ..test_utils.graphs import create_test_graph, example_graph_random"], "code": "def test_weighted_walks(self):\n    g = weighted(1, 2, 3, 4)\n    nodes = list(g.nodes())\n    n = 1\n    length = 1\n    seed = None\n    p = 1.0\n    q = 1.0\n    biasedrw = BiasedRandomWalk(g)\n    assert (len(biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed, weighted=True)) == 4)\n    g = weighted(0, 0, 0, 0)\n    biasedrw = BiasedRandomWalk(g)\n    walks = biasedrw.run(nodes=nodes, n=2, p=p, q=q, length=3, weighted=True)\n    assert (len(walks) == 8)\n    for walk in walks:\n        assert (len(walk) == 1)\n    g = weighted(1, (- 2), 3, 4)\n    biasedrw = BiasedRandomWalk(g)\n    neg_message = 'graph: expected all edge weights to be non-negative and finite, found some negative or infinite: 1 to 2 \\\\(weight = -2\\\\)'\n    with pytest.raises(ValueError, match=neg_message):\n        BiasedRandomWalk(g, weighted=True)\n    with pytest.raises(ValueError, match=neg_message):\n        biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed, weighted=True)\n    g = weighted(1, np.inf, 3, 4)\n    biasedrw = BiasedRandomWalk(g)\n    inf_message = 'graph: expected all edge weights to be non-negative and finite, found some negative or infinite: 1 to 2 \\\\(weight = inf\\\\)'\n    with pytest.raises(ValueError, match=inf_message):\n        BiasedRandomWalk(g, weighted=True)\n    with pytest.raises(ValueError, match=inf_message):\n        biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed, weighted=True)", "masked_code": "def test_weighted_walks(self):\n    g = weighted(1, 2, 3, 4)\n    nodes = list(g.nodes())\n    n = 1\n    length = 1\n    seed = None\n    p = 1.0\n    q = 1.0\n    biasedrw = BiasedRandomWalk(g)\n    assert (len(biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed, weighted=True)) == '???')\n    g = weighted(0, 0, 0, 0)\n    biasedrw = BiasedRandomWalk(g)\n    walks = biasedrw.run(nodes=nodes, n=2, p=p, q=q, length=3, weighted=True)\n    assert (len(walks) == 8)\n    for walk in walks:\n        assert (len(walk) == 1)\n    g = weighted(1, (- 2), 3, 4)\n    biasedrw = BiasedRandomWalk(g)\n    neg_message = 'graph: expected all edge weights to be non-negative and finite, found some negative or infinite: 1 to 2 \\\\(weight = -2\\\\)'\n    with pytest.raises(ValueError, match=neg_message):\n        BiasedRandomWalk(g, weighted=True)\n    with pytest.raises(ValueError, match=neg_message):\n        biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed, weighted=True)\n    g = weighted(1, np.inf, 3, 4)\n    biasedrw = BiasedRandomWalk(g)\n    inf_message = 'graph: expected all edge weights to be non-negative and finite, found some negative or infinite: 1 to 2 \\\\(weight = inf\\\\)'\n    with pytest.raises(ValueError, match=inf_message):\n        BiasedRandomWalk(g, weighted=True)\n    with pytest.raises(ValueError, match=inf_message):\n        biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed, weighted=True)", "ground_truth": "4", "quality_analysis": {"complexity_score": 7, "left_complexity": 6, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_177", "reponame": "stellargraph", "testpath": "tests/data/test_biased_random_walker.py", "testname": "test_biased_random_walker.py", "classname": "TestBiasedWeightedRandomWalk", "funcname": "test_weighted_walks", "imports": ["import numpy as np", "import pandas as pd", "import pytest", "import networkx as nx", "from stellargraph.data.explorer import BiasedRandomWalk", "from stellargraph.core.graph import StellarGraph", "from ..test_utils.graphs import create_test_graph, example_graph_random"], "code": "def test_weighted_walks(self):\n    g = weighted(1, 2, 3, 4)\n    nodes = list(g.nodes())\n    n = 1\n    length = 1\n    seed = None\n    p = 1.0\n    q = 1.0\n    biasedrw = BiasedRandomWalk(g)\n    assert (len(biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed, weighted=True)) == 4)\n    g = weighted(0, 0, 0, 0)\n    biasedrw = BiasedRandomWalk(g)\n    walks = biasedrw.run(nodes=nodes, n=2, p=p, q=q, length=3, weighted=True)\n    assert (len(walks) == 8)\n    for walk in walks:\n        assert (len(walk) == 1)\n    g = weighted(1, (- 2), 3, 4)\n    biasedrw = BiasedRandomWalk(g)\n    neg_message = 'graph: expected all edge weights to be non-negative and finite, found some negative or infinite: 1 to 2 \\\\(weight = -2\\\\)'\n    with pytest.raises(ValueError, match=neg_message):\n        BiasedRandomWalk(g, weighted=True)\n    with pytest.raises(ValueError, match=neg_message):\n        biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed, weighted=True)\n    g = weighted(1, np.inf, 3, 4)\n    biasedrw = BiasedRandomWalk(g)\n    inf_message = 'graph: expected all edge weights to be non-negative and finite, found some negative or infinite: 1 to 2 \\\\(weight = inf\\\\)'\n    with pytest.raises(ValueError, match=inf_message):\n        BiasedRandomWalk(g, weighted=True)\n    with pytest.raises(ValueError, match=inf_message):\n        biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed, weighted=True)", "masked_code": "def test_weighted_walks(self):\n    g = weighted(1, 2, 3, 4)\n    nodes = list(g.nodes())\n    n = 1\n    length = 1\n    seed = None\n    p = 1.0\n    q = 1.0\n    biasedrw = BiasedRandomWalk(g)\n    assert (len(biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed, weighted=True)) == 4)\n    g = weighted(0, 0, 0, 0)\n    biasedrw = BiasedRandomWalk(g)\n    walks = biasedrw.run(nodes=nodes, n=2, p=p, q=q, length=3, weighted=True)\n    assert (len(walks) == '???')\n    for walk in walks:\n        assert (len(walk) == 1)\n    g = weighted(1, (- 2), 3, 4)\n    biasedrw = BiasedRandomWalk(g)\n    neg_message = 'graph: expected all edge weights to be non-negative and finite, found some negative or infinite: 1 to 2 \\\\(weight = -2\\\\)'\n    with pytest.raises(ValueError, match=neg_message):\n        BiasedRandomWalk(g, weighted=True)\n    with pytest.raises(ValueError, match=neg_message):\n        biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed, weighted=True)\n    g = weighted(1, np.inf, 3, 4)\n    biasedrw = BiasedRandomWalk(g)\n    inf_message = 'graph: expected all edge weights to be non-negative and finite, found some negative or infinite: 1 to 2 \\\\(weight = inf\\\\)'\n    with pytest.raises(ValueError, match=inf_message):\n        BiasedRandomWalk(g, weighted=True)\n    with pytest.raises(ValueError, match=inf_message):\n        biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed, weighted=True)", "ground_truth": "8", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_178", "reponame": "stellargraph", "testpath": "tests/data/test_biased_random_walker.py", "testname": "test_biased_random_walker.py", "classname": "TestBiasedWeightedRandomWalk", "funcname": "test_weighted_graph_label", "imports": ["import numpy as np", "import pandas as pd", "import pytest", "import networkx as nx", "from stellargraph.data.explorer import BiasedRandomWalk", "from stellargraph.core.graph import StellarGraph", "from ..test_utils.graphs import create_test_graph, example_graph_random"], "code": "def test_weighted_graph_label(self):\n    g = nx.Graph()\n    edges = [(1, 2), (2, 3), (3, 4), (4, 1)]\n    g.add_edges_from(edges)\n    g[1][2]['w'] = 1\n    g[2][3]['w'] = 2\n    g[3][4]['w'] = 3\n    g[4][1]['w'] = 4\n    g = StellarGraph.from_networkx(g, edge_weight_attr='w')\n    nodes = list(g.nodes())\n    n = 1\n    length = 1\n    seed = None\n    p = 1.0\n    q = 1.0\n    biasedrw = BiasedRandomWalk(g)\n    assert (len(biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed, weighted=True)) == 4)\n    g = nx.Graph()\n    edges = [(1, 2), (2, 3), (3, 4), (4, 1)]\n    g.add_edges_from(edges)\n    g[1][2]['wt'] = 1\n    g[2][3]['wt'] = 2\n    g[3][4]['wt'] = 3\n    g[4][1]['wt'] = 4", "masked_code": "def test_weighted_graph_label(self):\n    g = nx.Graph()\n    edges = [(1, 2), (2, 3), (3, 4), (4, 1)]\n    g.add_edges_from(edges)\n    g[1][2]['w'] = 1\n    g[2][3]['w'] = 2\n    g[3][4]['w'] = 3\n    g[4][1]['w'] = 4\n    g = StellarGraph.from_networkx(g, edge_weight_attr='w')\n    nodes = list(g.nodes())\n    n = 1\n    length = 1\n    seed = None\n    p = 1.0\n    q = 1.0\n    biasedrw = BiasedRandomWalk(g)\n    assert (len(biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed, weighted=True)) == '???')\n    g = nx.Graph()\n    edges = [(1, 2), (2, 3), (3, 4), (4, 1)]\n    g.add_edges_from(edges)\n    g[1][2]['wt'] = 1\n    g[2][3]['wt'] = 2\n    g[3][4]['wt'] = 3\n    g[4][1]['wt'] = 4", "ground_truth": "4", "quality_analysis": {"complexity_score": 7, "left_complexity": 6, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_179", "reponame": "stellargraph", "testpath": "tests/data/test_biased_random_walker.py", "testname": "test_biased_random_walker.py", "classname": "TestBiasedRandomWalk", "funcname": "test_walk_generation_single_root_node", "imports": ["import numpy as np", "import pandas as pd", "import pytest", "import networkx as nx", "from stellargraph.data.explorer import BiasedRandomWalk", "from stellargraph.core.graph import StellarGraph", "from ..test_utils.graphs import create_test_graph, example_graph_random"], "code": "def test_walk_generation_single_root_node(self):\n    g = create_test_graph()\n    biasedrw = BiasedRandomWalk(g)\n    nodes = ['0']\n    n = 1\n    length = 1\n    seed = 42\n    p = 0.25\n    q = 0.5\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs[0]) == length)\n    length = 2\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n    length = 2\n    n = 2\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n    n = 3\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)", "masked_code": "def test_walk_generation_single_root_node(self):\n    g = create_test_graph()\n    biasedrw = BiasedRandomWalk(g)\n    nodes = ['0']\n    n = 1\n    length = 1\n    seed = 42\n    p = 0.25\n    q = 0.5\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs[0]) == '???')\n    length = 2\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n    length = 2\n    n = 2\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n    n = 3\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)", "ground_truth": "length", "quality_analysis": {"complexity_score": 9, "left_complexity": 8, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_180", "reponame": "stellargraph", "testpath": "tests/data/test_biased_random_walker.py", "testname": "test_biased_random_walker.py", "classname": "TestBiasedRandomWalk", "funcname": "test_walk_generation_single_root_node", "imports": ["import numpy as np", "import pandas as pd", "import pytest", "import networkx as nx", "from stellargraph.data.explorer import BiasedRandomWalk", "from stellargraph.core.graph import StellarGraph", "from ..test_utils.graphs import create_test_graph, example_graph_random"], "code": "def test_walk_generation_single_root_node(self):\n    g = create_test_graph()\n    biasedrw = BiasedRandomWalk(g)\n    nodes = ['0']\n    n = 1\n    length = 1\n    seed = 42\n    p = 0.25\n    q = 0.5\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs[0]) == length)\n    length = 2\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n    length = 2\n    n = 2\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n    n = 3\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)", "masked_code": "def test_walk_generation_single_root_node(self):\n    g = create_test_graph()\n    biasedrw = BiasedRandomWalk(g)\n    nodes = ['0']\n    n = 1\n    length = 1\n    seed = 42\n    p = 0.25\n    q = 0.5\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs[0]) == length)\n    length = 2\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n    length = 2\n    n = 2\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == '???')\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n    n = 3\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)", "ground_truth": "n", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_181", "reponame": "stellargraph", "testpath": "tests/data/test_biased_random_walker.py", "testname": "test_biased_random_walker.py", "classname": "TestBiasedRandomWalk", "funcname": "test_walk_generation_single_root_node", "imports": ["import numpy as np", "import pandas as pd", "import pytest", "import networkx as nx", "from stellargraph.data.explorer import BiasedRandomWalk", "from stellargraph.core.graph import StellarGraph", "from ..test_utils.graphs import create_test_graph, example_graph_random"], "code": "def test_walk_generation_single_root_node(self):\n    g = create_test_graph()\n    biasedrw = BiasedRandomWalk(g)\n    nodes = ['0']\n    n = 1\n    length = 1\n    seed = 42\n    p = 0.25\n    q = 0.5\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs[0]) == length)\n    length = 2\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n    length = 2\n    n = 2\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n    n = 3\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)", "masked_code": "def test_walk_generation_single_root_node(self):\n    g = create_test_graph()\n    biasedrw = BiasedRandomWalk(g)\n    nodes = ['0']\n    n = 1\n    length = 1\n    seed = 42\n    p = 0.25\n    q = 0.5\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs[0]) == length)\n    length = 2\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n    length = 2\n    n = 2\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n    n = 3\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == '???')\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)", "ground_truth": "n", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_182", "reponame": "stellargraph", "testpath": "tests/data/test_biased_random_walker.py", "testname": "test_biased_random_walker.py", "classname": "TestBiasedRandomWalk", "funcname": "test_walk_generation_single_root_node", "imports": ["import numpy as np", "import pandas as pd", "import pytest", "import networkx as nx", "from stellargraph.data.explorer import BiasedRandomWalk", "from stellargraph.core.graph import StellarGraph", "from ..test_utils.graphs import create_test_graph, example_graph_random"], "code": "def test_walk_generation_single_root_node(self):\n    g = create_test_graph()\n    biasedrw = BiasedRandomWalk(g)\n    nodes = ['0']\n    n = 1\n    length = 1\n    seed = 42\n    p = 0.25\n    q = 0.5\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs[0]) == length)\n    length = 2\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n    length = 2\n    n = 2\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n    n = 3\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)", "masked_code": "def test_walk_generation_single_root_node(self):\n    g = create_test_graph()\n    biasedrw = BiasedRandomWalk(g)\n    nodes = ['0']\n    n = 1\n    length = 1\n    seed = 42\n    p = 0.25\n    q = 0.5\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs[0]) == length)\n    length = 2\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == '???')\n    length = 2\n    n = 2\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n    n = 3\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)", "ground_truth": "length", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_183", "reponame": "stellargraph", "testpath": "tests/data/test_biased_random_walker.py", "testname": "test_biased_random_walker.py", "classname": "TestBiasedRandomWalk", "funcname": "test_walk_generation_single_root_node", "imports": ["import numpy as np", "import pandas as pd", "import pytest", "import networkx as nx", "from stellargraph.data.explorer import BiasedRandomWalk", "from stellargraph.core.graph import StellarGraph", "from ..test_utils.graphs import create_test_graph, example_graph_random"], "code": "def test_walk_generation_single_root_node(self):\n    g = create_test_graph()\n    biasedrw = BiasedRandomWalk(g)\n    nodes = ['0']\n    n = 1\n    length = 1\n    seed = 42\n    p = 0.25\n    q = 0.5\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs[0]) == length)\n    length = 2\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n    length = 2\n    n = 2\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n    n = 3\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)", "masked_code": "def test_walk_generation_single_root_node(self):\n    g = create_test_graph()\n    biasedrw = BiasedRandomWalk(g)\n    nodes = ['0']\n    n = 1\n    length = 1\n    seed = 42\n    p = 0.25\n    q = 0.5\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs[0]) == length)\n    length = 2\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n    length = 2\n    n = 2\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == '???')\n    n = 3\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)", "ground_truth": "length", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_184", "reponame": "stellargraph", "testpath": "tests/data/test_biased_random_walker.py", "testname": "test_biased_random_walker.py", "classname": "TestBiasedRandomWalk", "funcname": "test_walk_generation_single_root_node", "imports": ["import numpy as np", "import pandas as pd", "import pytest", "import networkx as nx", "from stellargraph.data.explorer import BiasedRandomWalk", "from stellargraph.core.graph import StellarGraph", "from ..test_utils.graphs import create_test_graph, example_graph_random"], "code": "def test_walk_generation_single_root_node(self):\n    g = create_test_graph()\n    biasedrw = BiasedRandomWalk(g)\n    nodes = ['0']\n    n = 1\n    length = 1\n    seed = 42\n    p = 0.25\n    q = 0.5\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs[0]) == length)\n    length = 2\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n    length = 2\n    n = 2\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n    n = 3\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)", "masked_code": "def test_walk_generation_single_root_node(self):\n    g = create_test_graph()\n    biasedrw = BiasedRandomWalk(g)\n    nodes = ['0']\n    n = 1\n    length = 1\n    seed = 42\n    p = 0.25\n    q = 0.5\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs[0]) == length)\n    length = 2\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n    length = 2\n    n = 2\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n    n = 3\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == '???')", "ground_truth": "length", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_185", "reponame": "stellargraph", "testpath": "tests/data/test_biased_random_walker.py", "testname": "test_biased_random_walker.py", "classname": "TestBiasedRandomWalk", "funcname": "test_walk_generation_many_root_nodes", "imports": ["import numpy as np", "import pandas as pd", "import pytest", "import networkx as nx", "from stellargraph.data.explorer import BiasedRandomWalk", "from stellargraph.core.graph import StellarGraph", "from ..test_utils.graphs import create_test_graph, example_graph_random"], "code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph()\n    biasedrw = BiasedRandomWalk(g)\n    nodes = ['0', 2]\n    n = 1\n    length = 1\n    seed = None\n    p = 1.0\n    q = 0.3\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == length)\n        assert (subgraph[0] == nodes[i])\n    length = 2\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)\n    n = 2\n    length = 2\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)\n    length = 3\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)\n    n = 5\n    length = 10\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)", "masked_code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph()\n    biasedrw = BiasedRandomWalk(g)\n    nodes = ['0', 2]\n    n = 1\n    length = 1\n    seed = None\n    p = 1.0\n    q = 0.3\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == '???')\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == length)\n        assert (subgraph[0] == nodes[i])\n    length = 2\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)\n    n = 2\n    length = 2\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)\n    length = 3\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)\n    n = 5\n    length = 10\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)", "ground_truth": "(n * len(nodes))", "quality_analysis": {"complexity_score": 11, "left_complexity": 4, "right_complexity": 7, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_186", "reponame": "stellargraph", "testpath": "tests/data/test_biased_random_walker.py", "testname": "test_biased_random_walker.py", "classname": "TestBiasedRandomWalk", "funcname": "test_walk_generation_many_root_nodes", "imports": ["import numpy as np", "import pandas as pd", "import pytest", "import networkx as nx", "from stellargraph.data.explorer import BiasedRandomWalk", "from stellargraph.core.graph import StellarGraph", "from ..test_utils.graphs import create_test_graph, example_graph_random"], "code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph()\n    biasedrw = BiasedRandomWalk(g)\n    nodes = ['0', 2]\n    n = 1\n    length = 1\n    seed = None\n    p = 1.0\n    q = 0.3\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == length)\n        assert (subgraph[0] == nodes[i])\n    length = 2\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)\n    n = 2\n    length = 2\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)\n    length = 3\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)\n    n = 5\n    length = 10\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)", "masked_code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph()\n    biasedrw = BiasedRandomWalk(g)\n    nodes = ['0', 2]\n    n = 1\n    length = 1\n    seed = None\n    p = 1.0\n    q = 0.3\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == length)\n        assert (subgraph[0] == nodes[i])\n    length = 2\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == '???')\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)\n    n = 2\n    length = 2\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)\n    length = 3\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)\n    n = 5\n    length = 10\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)", "ground_truth": "(n * len(nodes))", "quality_analysis": {"complexity_score": 11, "left_complexity": 4, "right_complexity": 7, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_187", "reponame": "stellargraph", "testpath": "tests/data/test_biased_random_walker.py", "testname": "test_biased_random_walker.py", "classname": "TestBiasedRandomWalk", "funcname": "test_walk_generation_many_root_nodes", "imports": ["import numpy as np", "import pandas as pd", "import pytest", "import networkx as nx", "from stellargraph.data.explorer import BiasedRandomWalk", "from stellargraph.core.graph import StellarGraph", "from ..test_utils.graphs import create_test_graph, example_graph_random"], "code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph()\n    biasedrw = BiasedRandomWalk(g)\n    nodes = ['0', 2]\n    n = 1\n    length = 1\n    seed = None\n    p = 1.0\n    q = 0.3\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == length)\n        assert (subgraph[0] == nodes[i])\n    length = 2\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)\n    n = 2\n    length = 2\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)\n    length = 3\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)\n    n = 5\n    length = 10\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)", "masked_code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph()\n    biasedrw = BiasedRandomWalk(g)\n    nodes = ['0', 2]\n    n = 1\n    length = 1\n    seed = None\n    p = 1.0\n    q = 0.3\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == length)\n        assert (subgraph[0] == nodes[i])\n    length = 2\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)\n    n = 2\n    length = 2\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == '???')\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)\n    length = 3\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)\n    n = 5\n    length = 10\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)", "ground_truth": "(n * len(nodes))", "quality_analysis": {"complexity_score": 11, "left_complexity": 4, "right_complexity": 7, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_188", "reponame": "stellargraph", "testpath": "tests/data/test_biased_random_walker.py", "testname": "test_biased_random_walker.py", "classname": "TestBiasedRandomWalk", "funcname": "test_walk_generation_many_root_nodes", "imports": ["import numpy as np", "import pandas as pd", "import pytest", "import networkx as nx", "from stellargraph.data.explorer import BiasedRandomWalk", "from stellargraph.core.graph import StellarGraph", "from ..test_utils.graphs import create_test_graph, example_graph_random"], "code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph()\n    biasedrw = BiasedRandomWalk(g)\n    nodes = ['0', 2]\n    n = 1\n    length = 1\n    seed = None\n    p = 1.0\n    q = 0.3\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == length)\n        assert (subgraph[0] == nodes[i])\n    length = 2\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)\n    n = 2\n    length = 2\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)\n    length = 3\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)\n    n = 5\n    length = 10\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)", "masked_code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph()\n    biasedrw = BiasedRandomWalk(g)\n    nodes = ['0', 2]\n    n = 1\n    length = 1\n    seed = None\n    p = 1.0\n    q = 0.3\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == length)\n        assert (subgraph[0] == nodes[i])\n    length = 2\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)\n    n = 2\n    length = 2\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)\n    length = 3\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == '???')\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)\n    n = 5\n    length = 10\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)", "ground_truth": "(n * len(nodes))", "quality_analysis": {"complexity_score": 11, "left_complexity": 4, "right_complexity": 7, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_189", "reponame": "stellargraph", "testpath": "tests/data/test_biased_random_walker.py", "testname": "test_biased_random_walker.py", "classname": "TestBiasedRandomWalk", "funcname": "test_walk_generation_many_root_nodes", "imports": ["import numpy as np", "import pandas as pd", "import pytest", "import networkx as nx", "from stellargraph.data.explorer import BiasedRandomWalk", "from stellargraph.core.graph import StellarGraph", "from ..test_utils.graphs import create_test_graph, example_graph_random"], "code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph()\n    biasedrw = BiasedRandomWalk(g)\n    nodes = ['0', 2]\n    n = 1\n    length = 1\n    seed = None\n    p = 1.0\n    q = 0.3\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == length)\n        assert (subgraph[0] == nodes[i])\n    length = 2\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)\n    n = 2\n    length = 2\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)\n    length = 3\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)\n    n = 5\n    length = 10\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)", "masked_code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph()\n    biasedrw = BiasedRandomWalk(g)\n    nodes = ['0', 2]\n    n = 1\n    length = 1\n    seed = None\n    p = 1.0\n    q = 0.3\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == length)\n        assert (subgraph[0] == nodes[i])\n    length = 2\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)\n    n = 2\n    length = 2\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)\n    length = 3\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)\n    n = 5\n    length = 10\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == '???')\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)", "ground_truth": "(n * len(nodes))", "quality_analysis": {"complexity_score": 11, "left_complexity": 4, "right_complexity": 7, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_190", "reponame": "stellargraph", "testpath": "tests/data/test_biased_random_walker.py", "testname": "test_biased_random_walker.py", "classname": "TestBiasedRandomWalk", "funcname": "test_walk_generation_many_root_nodes", "imports": ["import numpy as np", "import pandas as pd", "import pytest", "import networkx as nx", "from stellargraph.data.explorer import BiasedRandomWalk", "from stellargraph.core.graph import StellarGraph", "from ..test_utils.graphs import create_test_graph, example_graph_random"], "code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph()\n    biasedrw = BiasedRandomWalk(g)\n    nodes = ['0', 2]\n    n = 1\n    length = 1\n    seed = None\n    p = 1.0\n    q = 0.3\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == length)\n        assert (subgraph[0] == nodes[i])\n    length = 2\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)\n    n = 2\n    length = 2\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)\n    length = 3\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)\n    n = 5\n    length = 10\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)", "masked_code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph()\n    biasedrw = BiasedRandomWalk(g)\n    nodes = ['0', 2]\n    n = 1\n    length = 1\n    seed = None\n    p = 1.0\n    q = 0.3\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == '???')\n        assert (subgraph[0] == nodes[i])\n    length = 2\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)\n    n = 2\n    length = 2\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)\n    length = 3\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)\n    n = 5\n    length = 10\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)", "ground_truth": "length", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_191", "reponame": "stellargraph", "testpath": "tests/data/test_biased_random_walker.py", "testname": "test_biased_random_walker.py", "classname": "TestBiasedRandomWalk", "funcname": "test_walk_generation_many_root_nodes", "imports": ["import numpy as np", "import pandas as pd", "import pytest", "import networkx as nx", "from stellargraph.data.explorer import BiasedRandomWalk", "from stellargraph.core.graph import StellarGraph", "from ..test_utils.graphs import create_test_graph, example_graph_random"], "code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph()\n    biasedrw = BiasedRandomWalk(g)\n    nodes = ['0', 2]\n    n = 1\n    length = 1\n    seed = None\n    p = 1.0\n    q = 0.3\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == length)\n        assert (subgraph[0] == nodes[i])\n    length = 2\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)\n    n = 2\n    length = 2\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)\n    length = 3\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)\n    n = 5\n    length = 10\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)", "masked_code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph()\n    biasedrw = BiasedRandomWalk(g)\n    nodes = ['0', 2]\n    n = 1\n    length = 1\n    seed = None\n    p = 1.0\n    q = 0.3\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == length)\n        assert (subgraph[0] == '???')\n    length = 2\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)\n    n = 2\n    length = 2\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)\n    length = 3\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)\n    n = 5\n    length = 10\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)", "ground_truth": "nodes[i]", "quality_analysis": {"complexity_score": 10, "left_complexity": 5, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_192", "reponame": "stellargraph", "testpath": "tests/data/test_biased_random_walker.py", "testname": "test_biased_random_walker.py", "classname": "TestBiasedRandomWalk", "funcname": "test_walk_generation_loner_root_node", "imports": ["import numpy as np", "import pandas as pd", "import pytest", "import networkx as nx", "from stellargraph.data.explorer import BiasedRandomWalk", "from stellargraph.core.graph import StellarGraph", "from ..test_utils.graphs import create_test_graph, example_graph_random"], "code": "def test_walk_generation_loner_root_node(self):\n    g = create_test_graph()\n    biasedrw = BiasedRandomWalk(g)\n    nodes = ['loner']\n    n = 1\n    length = 1\n    seed = None\n    p = 0.5\n    q = 1.0\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 1)\n    n = 10\n    length = 1\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n    n = 10\n    length = 10\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)", "masked_code": "def test_walk_generation_loner_root_node(self):\n    g = create_test_graph()\n    biasedrw = BiasedRandomWalk(g)\n    nodes = ['loner']\n    n = 1\n    length = 1\n    seed = None\n    p = 0.5\n    q = 1.0\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 1)\n    n = 10\n    length = 1\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == '???')\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n    n = 10\n    length = 10\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)", "ground_truth": "n", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_193", "reponame": "stellargraph", "testpath": "tests/data/test_biased_random_walker.py", "testname": "test_biased_random_walker.py", "classname": "TestBiasedRandomWalk", "funcname": "test_walk_generation_loner_root_node", "imports": ["import numpy as np", "import pandas as pd", "import pytest", "import networkx as nx", "from stellargraph.data.explorer import BiasedRandomWalk", "from stellargraph.core.graph import StellarGraph", "from ..test_utils.graphs import create_test_graph, example_graph_random"], "code": "def test_walk_generation_loner_root_node(self):\n    g = create_test_graph()\n    biasedrw = BiasedRandomWalk(g)\n    nodes = ['loner']\n    n = 1\n    length = 1\n    seed = None\n    p = 0.5\n    q = 1.0\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 1)\n    n = 10\n    length = 1\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n    n = 10\n    length = 10\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)", "masked_code": "def test_walk_generation_loner_root_node(self):\n    g = create_test_graph()\n    biasedrw = BiasedRandomWalk(g)\n    nodes = ['loner']\n    n = 1\n    length = 1\n    seed = None\n    p = 0.5\n    q = 1.0\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 1)\n    n = 10\n    length = 1\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n    n = 10\n    length = 10\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == '???')\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)", "ground_truth": "n", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_194", "reponame": "stellargraph", "testpath": "tests/data/test_biased_random_walker.py", "testname": "test_biased_random_walker.py", "classname": "TestBiasedRandomWalk", "funcname": "test_walk_generation_self_loner_root_node", "imports": ["import numpy as np", "import pandas as pd", "import pytest", "import networkx as nx", "from stellargraph.data.explorer import BiasedRandomWalk", "from stellargraph.core.graph import StellarGraph", "from ..test_utils.graphs import create_test_graph, example_graph_random"], "code": "def test_walk_generation_self_loner_root_node(self):\n    g = create_test_graph()\n    biasedrw = BiasedRandomWalk(g)\n    nodes = ['self loner']\n    n = 1\n    length = 1\n    seed = None\n    p = 1.0\n    q = 1.0\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 1)\n    n = 10\n    length = 1\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n        for node in subgraph:\n            assert (node == 'self loner')\n    n = 1\n    length = 99\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n        for node in subgraph:\n            assert (node == 'self loner')\n    n = 10\n    length = 10\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n        for node in subgraph:\n            assert (node == 'self loner')", "masked_code": "def test_walk_generation_self_loner_root_node(self):\n    g = create_test_graph()\n    biasedrw = BiasedRandomWalk(g)\n    nodes = ['self loner']\n    n = 1\n    length = 1\n    seed = None\n    p = 1.0\n    q = 1.0\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 1)\n    n = 10\n    length = 1\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == '???')\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n        for node in subgraph:\n            assert (node == 'self loner')\n    n = 1\n    length = 99\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n        for node in subgraph:\n            assert (node == 'self loner')\n    n = 10\n    length = 10\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n        for node in subgraph:\n            assert (node == 'self loner')", "ground_truth": "n", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_195", "reponame": "stellargraph", "testpath": "tests/data/test_biased_random_walker.py", "testname": "test_biased_random_walker.py", "classname": "TestBiasedRandomWalk", "funcname": "test_walk_generation_self_loner_root_node", "imports": ["import numpy as np", "import pandas as pd", "import pytest", "import networkx as nx", "from stellargraph.data.explorer import BiasedRandomWalk", "from stellargraph.core.graph import StellarGraph", "from ..test_utils.graphs import create_test_graph, example_graph_random"], "code": "def test_walk_generation_self_loner_root_node(self):\n    g = create_test_graph()\n    biasedrw = BiasedRandomWalk(g)\n    nodes = ['self loner']\n    n = 1\n    length = 1\n    seed = None\n    p = 1.0\n    q = 1.0\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 1)\n    n = 10\n    length = 1\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n        for node in subgraph:\n            assert (node == 'self loner')\n    n = 1\n    length = 99\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n        for node in subgraph:\n            assert (node == 'self loner')\n    n = 10\n    length = 10\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n        for node in subgraph:\n            assert (node == 'self loner')", "masked_code": "def test_walk_generation_self_loner_root_node(self):\n    g = create_test_graph()\n    biasedrw = BiasedRandomWalk(g)\n    nodes = ['self loner']\n    n = 1\n    length = 1\n    seed = None\n    p = 1.0\n    q = 1.0\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 1)\n    n = 10\n    length = 1\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n        for node in subgraph:\n            assert (node == 'self loner')\n    n = 1\n    length = 99\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == '???')\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n        for node in subgraph:\n            assert (node == 'self loner')\n    n = 10\n    length = 10\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n        for node in subgraph:\n            assert (node == 'self loner')", "ground_truth": "n", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_196", "reponame": "stellargraph", "testpath": "tests/data/test_biased_random_walker.py", "testname": "test_biased_random_walker.py", "classname": "TestBiasedRandomWalk", "funcname": "test_walk_generation_self_loner_root_node", "imports": ["import numpy as np", "import pandas as pd", "import pytest", "import networkx as nx", "from stellargraph.data.explorer import BiasedRandomWalk", "from stellargraph.core.graph import StellarGraph", "from ..test_utils.graphs import create_test_graph, example_graph_random"], "code": "def test_walk_generation_self_loner_root_node(self):\n    g = create_test_graph()\n    biasedrw = BiasedRandomWalk(g)\n    nodes = ['self loner']\n    n = 1\n    length = 1\n    seed = None\n    p = 1.0\n    q = 1.0\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 1)\n    n = 10\n    length = 1\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n        for node in subgraph:\n            assert (node == 'self loner')\n    n = 1\n    length = 99\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n        for node in subgraph:\n            assert (node == 'self loner')\n    n = 10\n    length = 10\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n        for node in subgraph:\n            assert (node == 'self loner')", "masked_code": "def test_walk_generation_self_loner_root_node(self):\n    g = create_test_graph()\n    biasedrw = BiasedRandomWalk(g)\n    nodes = ['self loner']\n    n = 1\n    length = 1\n    seed = None\n    p = 1.0\n    q = 1.0\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 1)\n    n = 10\n    length = 1\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n        for node in subgraph:\n            assert (node == 'self loner')\n    n = 1\n    length = 99\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n        for node in subgraph:\n            assert (node == 'self loner')\n    n = 10\n    length = 10\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == '???')\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n        for node in subgraph:\n            assert (node == 'self loner')", "ground_truth": "n", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_197", "reponame": "stellargraph", "testpath": "tests/data/test_biased_random_walker.py", "testname": "test_biased_random_walker.py", "classname": "TestBiasedRandomWalk", "funcname": "test_walk_generation_self_loner_root_node", "imports": ["import numpy as np", "import pandas as pd", "import pytest", "import networkx as nx", "from stellargraph.data.explorer import BiasedRandomWalk", "from stellargraph.core.graph import StellarGraph", "from ..test_utils.graphs import create_test_graph, example_graph_random"], "code": "def test_walk_generation_self_loner_root_node(self):\n    g = create_test_graph()\n    biasedrw = BiasedRandomWalk(g)\n    nodes = ['self loner']\n    n = 1\n    length = 1\n    seed = None\n    p = 1.0\n    q = 1.0\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 1)\n    n = 10\n    length = 1\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n        for node in subgraph:\n            assert (node == 'self loner')\n    n = 1\n    length = 99\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n        for node in subgraph:\n            assert (node == 'self loner')\n    n = 10\n    length = 10\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n        for node in subgraph:\n            assert (node == 'self loner')", "masked_code": "def test_walk_generation_self_loner_root_node(self):\n    g = create_test_graph()\n    biasedrw = BiasedRandomWalk(g)\n    nodes = ['self loner']\n    n = 1\n    length = 1\n    seed = None\n    p = 1.0\n    q = 1.0\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 1)\n    n = 10\n    length = 1\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == '???')\n        for node in subgraph:\n            assert (node == 'self loner')\n    n = 1\n    length = 99\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n        for node in subgraph:\n            assert (node == 'self loner')\n    n = 10\n    length = 10\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n        for node in subgraph:\n            assert (node == 'self loner')", "ground_truth": "length", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_198", "reponame": "stellargraph", "testpath": "tests/data/test_biased_random_walker.py", "testname": "test_biased_random_walker.py", "classname": "TestBiasedRandomWalk", "funcname": "test_walk_generation_self_loner_root_node", "imports": ["import numpy as np", "import pandas as pd", "import pytest", "import networkx as nx", "from stellargraph.data.explorer import BiasedRandomWalk", "from stellargraph.core.graph import StellarGraph", "from ..test_utils.graphs import create_test_graph, example_graph_random"], "code": "def test_walk_generation_self_loner_root_node(self):\n    g = create_test_graph()\n    biasedrw = BiasedRandomWalk(g)\n    nodes = ['self loner']\n    n = 1\n    length = 1\n    seed = None\n    p = 1.0\n    q = 1.0\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 1)\n    n = 10\n    length = 1\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n        for node in subgraph:\n            assert (node == 'self loner')\n    n = 1\n    length = 99\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n        for node in subgraph:\n            assert (node == 'self loner')\n    n = 10\n    length = 10\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n        for node in subgraph:\n            assert (node == 'self loner')", "masked_code": "def test_walk_generation_self_loner_root_node(self):\n    g = create_test_graph()\n    biasedrw = BiasedRandomWalk(g)\n    nodes = ['self loner']\n    n = 1\n    length = 1\n    seed = None\n    p = 1.0\n    q = 1.0\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 1)\n    n = 10\n    length = 1\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n        for node in subgraph:\n            assert (node == 'self loner')\n    n = 1\n    length = 99\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == '???')\n        for node in subgraph:\n            assert (node == 'self loner')\n    n = 10\n    length = 10\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n        for node in subgraph:\n            assert (node == 'self loner')", "ground_truth": "length", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_199", "reponame": "stellargraph", "testpath": "tests/data/test_biased_random_walker.py", "testname": "test_biased_random_walker.py", "classname": "TestBiasedRandomWalk", "funcname": "test_walk_generation_self_loner_root_node", "imports": ["import numpy as np", "import pandas as pd", "import pytest", "import networkx as nx", "from stellargraph.data.explorer import BiasedRandomWalk", "from stellargraph.core.graph import StellarGraph", "from ..test_utils.graphs import create_test_graph, example_graph_random"], "code": "def test_walk_generation_self_loner_root_node(self):\n    g = create_test_graph()\n    biasedrw = BiasedRandomWalk(g)\n    nodes = ['self loner']\n    n = 1\n    length = 1\n    seed = None\n    p = 1.0\n    q = 1.0\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 1)\n    n = 10\n    length = 1\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n        for node in subgraph:\n            assert (node == 'self loner')\n    n = 1\n    length = 99\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n        for node in subgraph:\n            assert (node == 'self loner')\n    n = 10\n    length = 10\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n        for node in subgraph:\n            assert (node == 'self loner')", "masked_code": "def test_walk_generation_self_loner_root_node(self):\n    g = create_test_graph()\n    biasedrw = BiasedRandomWalk(g)\n    nodes = ['self loner']\n    n = 1\n    length = 1\n    seed = None\n    p = 1.0\n    q = 1.0\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 1)\n    n = 10\n    length = 1\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n        for node in subgraph:\n            assert (node == 'self loner')\n    n = 1\n    length = 99\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n        for node in subgraph:\n            assert (node == 'self loner')\n    n = 10\n    length = 10\n    subgraphs = biasedrw.run(nodes=nodes, n=n, p=p, q=q, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == '???')\n        for node in subgraph:\n            assert (node == 'self loner')", "ground_truth": "length", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_200", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_walk_generation_single_root_node_loner", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_walk_generation_single_root_node_loner(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['loner'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == 1)\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == (- 1))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == (- 1))\n    assert (subgraphs[0][2] == (- 1))\n    assert (subgraphs[0][6] == (- 1))\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 99\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 17\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])", "masked_code": "def test_walk_generation_single_root_node_loner(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['loner'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == '???')\n    assert (len(subgraphs[0]) == 1)\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == (- 1))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == (- 1))\n    assert (subgraphs[0][2] == (- 1))\n    assert (subgraphs[0][6] == (- 1))\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 99\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 17\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])", "ground_truth": "n", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_201", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_walk_generation_single_root_node_loner", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_walk_generation_single_root_node_loner(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['loner'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == 1)\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == (- 1))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == (- 1))\n    assert (subgraphs[0][2] == (- 1))\n    assert (subgraphs[0][6] == (- 1))\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 99\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 17\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])", "masked_code": "def test_walk_generation_single_root_node_loner(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['loner'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == 1)\n    assert (subgraphs[0][0] == '???')\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == (- 1))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == (- 1))\n    assert (subgraphs[0][2] == (- 1))\n    assert (subgraphs[0][6] == (- 1))\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 99\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 17\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])", "ground_truth": "g.node_ids_to_ilocs(['loner'])[0]", "quality_analysis": {"complexity_score": 19, "left_complexity": 9, "right_complexity": 10, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_202", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_walk_generation_single_root_node_loner", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_walk_generation_single_root_node_loner(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['loner'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == 1)\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == (- 1))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == (- 1))\n    assert (subgraphs[0][2] == (- 1))\n    assert (subgraphs[0][6] == (- 1))\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 99\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 17\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])", "masked_code": "def test_walk_generation_single_root_node_loner(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['loner'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == 1)\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == '???')\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == (- 1))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == (- 1))\n    assert (subgraphs[0][2] == (- 1))\n    assert (subgraphs[0][6] == (- 1))\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 99\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 17\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])", "ground_truth": "n", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_203", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_walk_generation_single_root_node_loner", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_walk_generation_single_root_node_loner(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['loner'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == 1)\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == (- 1))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == (- 1))\n    assert (subgraphs[0][2] == (- 1))\n    assert (subgraphs[0][6] == (- 1))\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 99\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 17\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])", "masked_code": "def test_walk_generation_single_root_node_loner(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['loner'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == 1)\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == '???')\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == (- 1))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == (- 1))\n    assert (subgraphs[0][2] == (- 1))\n    assert (subgraphs[0][6] == (- 1))\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 99\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 17\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])", "ground_truth": "expected_bfw_size(n_size)", "quality_analysis": {"complexity_score": 12, "left_complexity": 8, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_204", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_walk_generation_single_root_node_loner", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_walk_generation_single_root_node_loner(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['loner'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == 1)\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == (- 1))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == (- 1))\n    assert (subgraphs[0][2] == (- 1))\n    assert (subgraphs[0][6] == (- 1))\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 99\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 17\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])", "masked_code": "def test_walk_generation_single_root_node_loner(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['loner'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == 1)\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == '???')\n    assert (subgraphs[0][1] == (- 1))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == (- 1))\n    assert (subgraphs[0][2] == (- 1))\n    assert (subgraphs[0][6] == (- 1))\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 99\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 17\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])", "ground_truth": "g.node_ids_to_ilocs(['loner'])[0]", "quality_analysis": {"complexity_score": 19, "left_complexity": 9, "right_complexity": 10, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_205", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_walk_generation_single_root_node_loner", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_walk_generation_single_root_node_loner(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['loner'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == 1)\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == (- 1))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == (- 1))\n    assert (subgraphs[0][2] == (- 1))\n    assert (subgraphs[0][6] == (- 1))\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 99\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 17\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])", "masked_code": "def test_walk_generation_single_root_node_loner(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['loner'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == 1)\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == '???')\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == (- 1))\n    assert (subgraphs[0][2] == (- 1))\n    assert (subgraphs[0][6] == (- 1))\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 99\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 17\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])", "ground_truth": "(- 1)", "quality_analysis": {"complexity_score": 12, "left_complexity": 9, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_206", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_walk_generation_single_root_node_loner", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_walk_generation_single_root_node_loner(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['loner'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == 1)\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == (- 1))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == (- 1))\n    assert (subgraphs[0][2] == (- 1))\n    assert (subgraphs[0][6] == (- 1))\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 99\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 17\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])", "masked_code": "def test_walk_generation_single_root_node_loner(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['loner'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == 1)\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == (- 1))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == '???')\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == (- 1))\n    assert (subgraphs[0][2] == (- 1))\n    assert (subgraphs[0][6] == (- 1))\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 99\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 17\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])", "ground_truth": "n", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_207", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_walk_generation_single_root_node_loner", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_walk_generation_single_root_node_loner(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['loner'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == 1)\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == (- 1))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == (- 1))\n    assert (subgraphs[0][2] == (- 1))\n    assert (subgraphs[0][6] == (- 1))\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 99\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 17\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])", "masked_code": "def test_walk_generation_single_root_node_loner(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['loner'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == 1)\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == (- 1))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == '???')\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == (- 1))\n    assert (subgraphs[0][2] == (- 1))\n    assert (subgraphs[0][6] == (- 1))\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 99\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 17\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])", "ground_truth": "expected_bfw_size(n_size)", "quality_analysis": {"complexity_score": 12, "left_complexity": 8, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_208", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_walk_generation_single_root_node_loner", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_walk_generation_single_root_node_loner(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['loner'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == 1)\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == (- 1))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == (- 1))\n    assert (subgraphs[0][2] == (- 1))\n    assert (subgraphs[0][6] == (- 1))\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 99\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 17\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])", "masked_code": "def test_walk_generation_single_root_node_loner(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['loner'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == 1)\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == (- 1))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == '???')\n    assert (subgraphs[0][1] == (- 1))\n    assert (subgraphs[0][2] == (- 1))\n    assert (subgraphs[0][6] == (- 1))\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 99\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 17\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])", "ground_truth": "g.node_ids_to_ilocs(['loner'])[0]", "quality_analysis": {"complexity_score": 19, "left_complexity": 9, "right_complexity": 10, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_209", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_walk_generation_single_root_node_loner", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_walk_generation_single_root_node_loner(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['loner'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == 1)\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == (- 1))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == (- 1))\n    assert (subgraphs[0][2] == (- 1))\n    assert (subgraphs[0][6] == (- 1))\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 99\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 17\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])", "masked_code": "def test_walk_generation_single_root_node_loner(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['loner'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == 1)\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == (- 1))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == '???')\n    assert (subgraphs[0][2] == (- 1))\n    assert (subgraphs[0][6] == (- 1))\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 99\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 17\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])", "ground_truth": "(- 1)", "quality_analysis": {"complexity_score": 12, "left_complexity": 9, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_210", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_walk_generation_single_root_node_loner", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_walk_generation_single_root_node_loner(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['loner'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == 1)\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == (- 1))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == (- 1))\n    assert (subgraphs[0][2] == (- 1))\n    assert (subgraphs[0][6] == (- 1))\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 99\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 17\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])", "masked_code": "def test_walk_generation_single_root_node_loner(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['loner'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == 1)\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == (- 1))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == (- 1))\n    assert (subgraphs[0][2] == '???')\n    assert (subgraphs[0][6] == (- 1))\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 99\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 17\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])", "ground_truth": "(- 1)", "quality_analysis": {"complexity_score": 12, "left_complexity": 9, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_211", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_walk_generation_single_root_node_loner", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_walk_generation_single_root_node_loner(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['loner'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == 1)\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == (- 1))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == (- 1))\n    assert (subgraphs[0][2] == (- 1))\n    assert (subgraphs[0][6] == (- 1))\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 99\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 17\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])", "masked_code": "def test_walk_generation_single_root_node_loner(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['loner'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == 1)\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == (- 1))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == (- 1))\n    assert (subgraphs[0][2] == (- 1))\n    assert (subgraphs[0][6] == '???')\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 99\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 17\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])", "ground_truth": "(- 1)", "quality_analysis": {"complexity_score": 12, "left_complexity": 9, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_212", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_walk_generation_single_root_node_loner", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_walk_generation_single_root_node_loner(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['loner'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == 1)\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == (- 1))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == (- 1))\n    assert (subgraphs[0][2] == (- 1))\n    assert (subgraphs[0][6] == (- 1))\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 99\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 17\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])", "masked_code": "def test_walk_generation_single_root_node_loner(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['loner'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == 1)\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == (- 1))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == (- 1))\n    assert (subgraphs[0][2] == (- 1))\n    assert (subgraphs[0][6] == (- 1))\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == '???')\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 99\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 17\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])", "ground_truth": "n", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_213", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_walk_generation_single_root_node_loner", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_walk_generation_single_root_node_loner(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['loner'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == 1)\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == (- 1))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == (- 1))\n    assert (subgraphs[0][2] == (- 1))\n    assert (subgraphs[0][6] == (- 1))\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 99\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 17\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])", "masked_code": "def test_walk_generation_single_root_node_loner(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['loner'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == 1)\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == (- 1))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == (- 1))\n    assert (subgraphs[0][2] == (- 1))\n    assert (subgraphs[0][6] == (- 1))\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == '???')\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 99\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 17\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])", "ground_truth": "expected_bfw_size(n_size)", "quality_analysis": {"complexity_score": 12, "left_complexity": 8, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_214", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_walk_generation_single_root_node_loner", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_walk_generation_single_root_node_loner(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['loner'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == 1)\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == (- 1))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == (- 1))\n    assert (subgraphs[0][2] == (- 1))\n    assert (subgraphs[0][6] == (- 1))\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 99\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 17\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])", "masked_code": "def test_walk_generation_single_root_node_loner(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['loner'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == 1)\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == (- 1))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == (- 1))\n    assert (subgraphs[0][2] == (- 1))\n    assert (subgraphs[0][6] == (- 1))\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == '???')\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 99\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 17\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])", "ground_truth": "g.node_ids_to_ilocs(['loner'])[0]", "quality_analysis": {"complexity_score": 19, "left_complexity": 9, "right_complexity": 10, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_215", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_walk_generation_single_root_node_loner", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_walk_generation_single_root_node_loner(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['loner'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == 1)\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == (- 1))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == (- 1))\n    assert (subgraphs[0][2] == (- 1))\n    assert (subgraphs[0][6] == (- 1))\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 99\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 17\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])", "masked_code": "def test_walk_generation_single_root_node_loner(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['loner'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == 1)\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == (- 1))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == (- 1))\n    assert (subgraphs[0][2] == (- 1))\n    assert (subgraphs[0][6] == (- 1))\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == '???')\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 99\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 17\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])", "ground_truth": "n", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_216", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_walk_generation_single_root_node_loner", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_walk_generation_single_root_node_loner(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['loner'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == 1)\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == (- 1))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == (- 1))\n    assert (subgraphs[0][2] == (- 1))\n    assert (subgraphs[0][6] == (- 1))\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 99\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 17\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])", "masked_code": "def test_walk_generation_single_root_node_loner(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['loner'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == 1)\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == (- 1))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == (- 1))\n    assert (subgraphs[0][2] == (- 1))\n    assert (subgraphs[0][6] == (- 1))\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == '???')\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 99\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 17\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])", "ground_truth": "n", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_217", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_walk_generation_single_root_node_loner", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_walk_generation_single_root_node_loner(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['loner'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == 1)\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == (- 1))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == (- 1))\n    assert (subgraphs[0][2] == (- 1))\n    assert (subgraphs[0][6] == (- 1))\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 99\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 17\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])", "masked_code": "def test_walk_generation_single_root_node_loner(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['loner'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == 1)\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == (- 1))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == (- 1))\n    assert (subgraphs[0][2] == (- 1))\n    assert (subgraphs[0][6] == (- 1))\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 99\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == '???')\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 17\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])", "ground_truth": "n", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_218", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_walk_generation_single_root_node_loner", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_walk_generation_single_root_node_loner(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['loner'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == 1)\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == (- 1))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == (- 1))\n    assert (subgraphs[0][2] == (- 1))\n    assert (subgraphs[0][6] == (- 1))\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 99\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 17\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])", "masked_code": "def test_walk_generation_single_root_node_loner(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['loner'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == 1)\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == (- 1))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == (- 1))\n    assert (subgraphs[0][2] == (- 1))\n    assert (subgraphs[0][6] == (- 1))\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 99\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 17\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == '???')\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])", "ground_truth": "n", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_219", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_walk_generation_single_root_node_loner", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_walk_generation_single_root_node_loner(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['loner'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == 1)\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == (- 1))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == (- 1))\n    assert (subgraphs[0][2] == (- 1))\n    assert (subgraphs[0][6] == (- 1))\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 99\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 17\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])", "masked_code": "def test_walk_generation_single_root_node_loner(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['loner'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == 1)\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == (- 1))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == (- 1))\n    assert (subgraphs[0][2] == (- 1))\n    assert (subgraphs[0][6] == (- 1))\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == '???')\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 99\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 17\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])", "ground_truth": "g.node_ids_to_ilocs(['loner'])[0]", "quality_analysis": {"complexity_score": 15, "left_complexity": 5, "right_complexity": 10, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_220", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_walk_generation_single_root_node_loner", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_walk_generation_single_root_node_loner(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['loner'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == 1)\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == (- 1))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == (- 1))\n    assert (subgraphs[0][2] == (- 1))\n    assert (subgraphs[0][6] == (- 1))\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 99\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 17\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])", "masked_code": "def test_walk_generation_single_root_node_loner(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['loner'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == 1)\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == (- 1))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == (- 1))\n    assert (subgraphs[0][2] == (- 1))\n    assert (subgraphs[0][6] == (- 1))\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == '???')\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 99\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 17\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])", "ground_truth": "expected_bfw_size(n_size)", "quality_analysis": {"complexity_score": 8, "left_complexity": 4, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_221", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_walk_generation_single_root_node_loner", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_walk_generation_single_root_node_loner(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['loner'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == 1)\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == (- 1))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == (- 1))\n    assert (subgraphs[0][2] == (- 1))\n    assert (subgraphs[0][6] == (- 1))\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 99\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 17\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])", "masked_code": "def test_walk_generation_single_root_node_loner(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['loner'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == 1)\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == (- 1))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == (- 1))\n    assert (subgraphs[0][2] == (- 1))\n    assert (subgraphs[0][6] == (- 1))\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == '???')\n    n = 99\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 17\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])", "ground_truth": "g.node_ids_to_ilocs(['loner'])[0]", "quality_analysis": {"complexity_score": 15, "left_complexity": 5, "right_complexity": 10, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_222", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_walk_generation_single_root_node_loner", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_walk_generation_single_root_node_loner(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['loner'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == 1)\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == (- 1))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == (- 1))\n    assert (subgraphs[0][2] == (- 1))\n    assert (subgraphs[0][6] == (- 1))\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 99\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 17\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])", "masked_code": "def test_walk_generation_single_root_node_loner(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['loner'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == 1)\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == (- 1))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == (- 1))\n    assert (subgraphs[0][2] == (- 1))\n    assert (subgraphs[0][6] == (- 1))\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 99\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == '???')\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 17\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])", "ground_truth": "expected_bfw_size(n_size)", "quality_analysis": {"complexity_score": 8, "left_complexity": 4, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_223", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_walk_generation_single_root_node_loner", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_walk_generation_single_root_node_loner(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['loner'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == 1)\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == (- 1))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == (- 1))\n    assert (subgraphs[0][2] == (- 1))\n    assert (subgraphs[0][6] == (- 1))\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 99\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 17\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])", "masked_code": "def test_walk_generation_single_root_node_loner(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['loner'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == 1)\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == (- 1))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == (- 1))\n    assert (subgraphs[0][2] == (- 1))\n    assert (subgraphs[0][6] == (- 1))\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 99\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == '???')\n    n = 17\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])", "ground_truth": "g.node_ids_to_ilocs(['loner'])[0]", "quality_analysis": {"complexity_score": 15, "left_complexity": 5, "right_complexity": 10, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_224", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_walk_generation_single_root_node_loner", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_walk_generation_single_root_node_loner(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['loner'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == 1)\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == (- 1))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == (- 1))\n    assert (subgraphs[0][2] == (- 1))\n    assert (subgraphs[0][6] == (- 1))\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 99\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 17\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])", "masked_code": "def test_walk_generation_single_root_node_loner(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['loner'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == 1)\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == (- 1))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == (- 1))\n    assert (subgraphs[0][2] == (- 1))\n    assert (subgraphs[0][6] == (- 1))\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 99\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 17\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == '???')\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])", "ground_truth": "expected_bfw_size(n_size)", "quality_analysis": {"complexity_score": 8, "left_complexity": 4, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_225", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_walk_generation_single_root_node_loner", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_walk_generation_single_root_node_loner(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['loner'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == 1)\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == (- 1))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == (- 1))\n    assert (subgraphs[0][2] == (- 1))\n    assert (subgraphs[0][6] == (- 1))\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 99\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 17\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])", "masked_code": "def test_walk_generation_single_root_node_loner(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['loner'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == 1)\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == (- 1))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    assert (subgraphs[0][1] == (- 1))\n    assert (subgraphs[0][2] == (- 1))\n    assert (subgraphs[0][6] == (- 1))\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 99\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == g.node_ids_to_ilocs(['loner'])[0])\n    n = 17\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == '???')", "ground_truth": "g.node_ids_to_ilocs(['loner'])[0]", "quality_analysis": {"complexity_score": 15, "left_complexity": 5, "right_complexity": 10, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_226", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_directed_walk_generation_single_root_node", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_directed_walk_generation_single_root_node(self, tree_graph):\n\n    def _check_directed_walk(walk, n_size):\n        if ((len(n_size) > 1) and (n_size[0] > 0) and (n_size[1] > 0)):\n            for child_pos in range(n_size[0]):\n                child = walk[(child_pos + 1)]\n                grandchildren_start = ((1 + n_size[0]) + (child_pos * n_size[1]))\n                grandchildren_end = (grandchildren_start + n_size[1])\n                grandchildren = walk[grandchildren_start:grandchildren_end]\n                if (child == 'root'):\n                    for grandchild in grandchildren:\n                        assert (grandchild in [0, 1, 2])\n                elif (child == '0'):\n                    for grandchild in grandchildren:\n                        assert (grandchild == 'root')\n                elif (child == 1):\n                    for grandchild in grandchildren:\n                        assert (grandchild in ['c1.1', 'root'])\n                elif (child == 2):\n                    for grandchild in grandchildren:\n                        assert (grandchild in ['c2.1', 'c2.2', 'root'])\n                else:\n                    assert (1 == 0)\n    bfw = SampledBreadthFirstWalk(tree_graph)\n    nodes = tree_graph.node_ids_to_ilocs(['root'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == 1)\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    assert (subgraphs[0][1] != (- 1))\n    assert (subgraphs[0][2] != (- 1))\n    _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraphs[0]), n_size)\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraphs[0]), n_size)\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n = 99\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n        _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraph), n_size)\n    n = 17\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])", "masked_code": "def test_directed_walk_generation_single_root_node(self, tree_graph):\n\n    def _check_directed_walk(walk, n_size):\n        if ((len(n_size) > 1) and (n_size[0] > 0) and (n_size[1] > 0)):\n            for child_pos in range(n_size[0]):\n                child = walk[(child_pos + 1)]\n                grandchildren_start = ((1 + n_size[0]) + (child_pos * n_size[1]))\n                grandchildren_end = (grandchildren_start + n_size[1])\n                grandchildren = walk[grandchildren_start:grandchildren_end]\n                if (child == 'root'):\n                    for grandchild in grandchildren:\n                        assert (grandchild in [0, 1, 2])\n                elif (child == '0'):\n                    for grandchild in grandchildren:\n                        assert (grandchild == 'root')\n                elif (child == 1):\n                    for grandchild in grandchildren:\n                        assert (grandchild in ['c1.1', 'root'])\n                elif (child == 2):\n                    for grandchild in grandchildren:\n                        assert (grandchild in ['c2.1', 'c2.2', 'root'])\n                else:\n                    assert (1 == 0)\n    bfw = SampledBreadthFirstWalk(tree_graph)\n    nodes = tree_graph.node_ids_to_ilocs(['root'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == '???')\n    assert (len(subgraphs[0]) == 1)\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    assert (subgraphs[0][1] != (- 1))\n    assert (subgraphs[0][2] != (- 1))\n    _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraphs[0]), n_size)\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraphs[0]), n_size)\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n = 99\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n        _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraph), n_size)\n    n = 17\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])", "ground_truth": "n", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_227", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_directed_walk_generation_single_root_node", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_directed_walk_generation_single_root_node(self, tree_graph):\n\n    def _check_directed_walk(walk, n_size):\n        if ((len(n_size) > 1) and (n_size[0] > 0) and (n_size[1] > 0)):\n            for child_pos in range(n_size[0]):\n                child = walk[(child_pos + 1)]\n                grandchildren_start = ((1 + n_size[0]) + (child_pos * n_size[1]))\n                grandchildren_end = (grandchildren_start + n_size[1])\n                grandchildren = walk[grandchildren_start:grandchildren_end]\n                if (child == 'root'):\n                    for grandchild in grandchildren:\n                        assert (grandchild in [0, 1, 2])\n                elif (child == '0'):\n                    for grandchild in grandchildren:\n                        assert (grandchild == 'root')\n                elif (child == 1):\n                    for grandchild in grandchildren:\n                        assert (grandchild in ['c1.1', 'root'])\n                elif (child == 2):\n                    for grandchild in grandchildren:\n                        assert (grandchild in ['c2.1', 'c2.2', 'root'])\n                else:\n                    assert (1 == 0)\n    bfw = SampledBreadthFirstWalk(tree_graph)\n    nodes = tree_graph.node_ids_to_ilocs(['root'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == 1)\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    assert (subgraphs[0][1] != (- 1))\n    assert (subgraphs[0][2] != (- 1))\n    _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraphs[0]), n_size)\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraphs[0]), n_size)\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n = 99\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n        _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraph), n_size)\n    n = 17\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])", "masked_code": "def test_directed_walk_generation_single_root_node(self, tree_graph):\n\n    def _check_directed_walk(walk, n_size):\n        if ((len(n_size) > 1) and (n_size[0] > 0) and (n_size[1] > 0)):\n            for child_pos in range(n_size[0]):\n                child = walk[(child_pos + 1)]\n                grandchildren_start = ((1 + n_size[0]) + (child_pos * n_size[1]))\n                grandchildren_end = (grandchildren_start + n_size[1])\n                grandchildren = walk[grandchildren_start:grandchildren_end]\n                if (child == 'root'):\n                    for grandchild in grandchildren:\n                        assert (grandchild in [0, 1, 2])\n                elif (child == '0'):\n                    for grandchild in grandchildren:\n                        assert (grandchild == 'root')\n                elif (child == 1):\n                    for grandchild in grandchildren:\n                        assert (grandchild in ['c1.1', 'root'])\n                elif (child == 2):\n                    for grandchild in grandchildren:\n                        assert (grandchild in ['c2.1', 'c2.2', 'root'])\n                else:\n                    assert (1 == 0)\n    bfw = SampledBreadthFirstWalk(tree_graph)\n    nodes = tree_graph.node_ids_to_ilocs(['root'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == 1)\n    assert (subgraphs[0][0] == '???')\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    assert (subgraphs[0][1] != (- 1))\n    assert (subgraphs[0][2] != (- 1))\n    _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraphs[0]), n_size)\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraphs[0]), n_size)\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n = 99\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n        _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraph), n_size)\n    n = 17\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])", "ground_truth": "tree_graph.node_ids_to_ilocs(['root'])[0]", "quality_analysis": {"complexity_score": 19, "left_complexity": 9, "right_complexity": 10, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_228", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_directed_walk_generation_single_root_node", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_directed_walk_generation_single_root_node(self, tree_graph):\n\n    def _check_directed_walk(walk, n_size):\n        if ((len(n_size) > 1) and (n_size[0] > 0) and (n_size[1] > 0)):\n            for child_pos in range(n_size[0]):\n                child = walk[(child_pos + 1)]\n                grandchildren_start = ((1 + n_size[0]) + (child_pos * n_size[1]))\n                grandchildren_end = (grandchildren_start + n_size[1])\n                grandchildren = walk[grandchildren_start:grandchildren_end]\n                if (child == 'root'):\n                    for grandchild in grandchildren:\n                        assert (grandchild in [0, 1, 2])\n                elif (child == '0'):\n                    for grandchild in grandchildren:\n                        assert (grandchild == 'root')\n                elif (child == 1):\n                    for grandchild in grandchildren:\n                        assert (grandchild in ['c1.1', 'root'])\n                elif (child == 2):\n                    for grandchild in grandchildren:\n                        assert (grandchild in ['c2.1', 'c2.2', 'root'])\n                else:\n                    assert (1 == 0)\n    bfw = SampledBreadthFirstWalk(tree_graph)\n    nodes = tree_graph.node_ids_to_ilocs(['root'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == 1)\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    assert (subgraphs[0][1] != (- 1))\n    assert (subgraphs[0][2] != (- 1))\n    _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraphs[0]), n_size)\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraphs[0]), n_size)\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n = 99\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n        _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraph), n_size)\n    n = 17\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])", "masked_code": "def test_directed_walk_generation_single_root_node(self, tree_graph):\n\n    def _check_directed_walk(walk, n_size):\n        if ((len(n_size) > 1) and (n_size[0] > 0) and (n_size[1] > 0)):\n            for child_pos in range(n_size[0]):\n                child = walk[(child_pos + 1)]\n                grandchildren_start = ((1 + n_size[0]) + (child_pos * n_size[1]))\n                grandchildren_end = (grandchildren_start + n_size[1])\n                grandchildren = walk[grandchildren_start:grandchildren_end]\n                if (child == 'root'):\n                    for grandchild in grandchildren:\n                        assert (grandchild in [0, 1, 2])\n                elif (child == '0'):\n                    for grandchild in grandchildren:\n                        assert (grandchild == 'root')\n                elif (child == 1):\n                    for grandchild in grandchildren:\n                        assert (grandchild in ['c1.1', 'root'])\n                elif (child == 2):\n                    for grandchild in grandchildren:\n                        assert (grandchild in ['c2.1', 'c2.2', 'root'])\n                else:\n                    assert (1 == 0)\n    bfw = SampledBreadthFirstWalk(tree_graph)\n    nodes = tree_graph.node_ids_to_ilocs(['root'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == 1)\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == '???')\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    assert (subgraphs[0][1] != (- 1))\n    assert (subgraphs[0][2] != (- 1))\n    _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraphs[0]), n_size)\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraphs[0]), n_size)\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n = 99\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n        _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraph), n_size)\n    n = 17\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])", "ground_truth": "n", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_229", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_directed_walk_generation_single_root_node", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_directed_walk_generation_single_root_node(self, tree_graph):\n\n    def _check_directed_walk(walk, n_size):\n        if ((len(n_size) > 1) and (n_size[0] > 0) and (n_size[1] > 0)):\n            for child_pos in range(n_size[0]):\n                child = walk[(child_pos + 1)]\n                grandchildren_start = ((1 + n_size[0]) + (child_pos * n_size[1]))\n                grandchildren_end = (grandchildren_start + n_size[1])\n                grandchildren = walk[grandchildren_start:grandchildren_end]\n                if (child == 'root'):\n                    for grandchild in grandchildren:\n                        assert (grandchild in [0, 1, 2])\n                elif (child == '0'):\n                    for grandchild in grandchildren:\n                        assert (grandchild == 'root')\n                elif (child == 1):\n                    for grandchild in grandchildren:\n                        assert (grandchild in ['c1.1', 'root'])\n                elif (child == 2):\n                    for grandchild in grandchildren:\n                        assert (grandchild in ['c2.1', 'c2.2', 'root'])\n                else:\n                    assert (1 == 0)\n    bfw = SampledBreadthFirstWalk(tree_graph)\n    nodes = tree_graph.node_ids_to_ilocs(['root'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == 1)\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    assert (subgraphs[0][1] != (- 1))\n    assert (subgraphs[0][2] != (- 1))\n    _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraphs[0]), n_size)\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraphs[0]), n_size)\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n = 99\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n        _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraph), n_size)\n    n = 17\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])", "masked_code": "def test_directed_walk_generation_single_root_node(self, tree_graph):\n\n    def _check_directed_walk(walk, n_size):\n        if ((len(n_size) > 1) and (n_size[0] > 0) and (n_size[1] > 0)):\n            for child_pos in range(n_size[0]):\n                child = walk[(child_pos + 1)]\n                grandchildren_start = ((1 + n_size[0]) + (child_pos * n_size[1]))\n                grandchildren_end = (grandchildren_start + n_size[1])\n                grandchildren = walk[grandchildren_start:grandchildren_end]\n                if (child == 'root'):\n                    for grandchild in grandchildren:\n                        assert (grandchild in [0, 1, 2])\n                elif (child == '0'):\n                    for grandchild in grandchildren:\n                        assert (grandchild == 'root')\n                elif (child == 1):\n                    for grandchild in grandchildren:\n                        assert (grandchild in ['c1.1', 'root'])\n                elif (child == 2):\n                    for grandchild in grandchildren:\n                        assert (grandchild in ['c2.1', 'c2.2', 'root'])\n                else:\n                    assert (1 == 0)\n    bfw = SampledBreadthFirstWalk(tree_graph)\n    nodes = tree_graph.node_ids_to_ilocs(['root'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == 1)\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == '???')\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    assert (subgraphs[0][1] != (- 1))\n    assert (subgraphs[0][2] != (- 1))\n    _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraphs[0]), n_size)\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraphs[0]), n_size)\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n = 99\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n        _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraph), n_size)\n    n = 17\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])", "ground_truth": "expected_bfw_size(n_size)", "quality_analysis": {"complexity_score": 12, "left_complexity": 8, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_230", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_directed_walk_generation_single_root_node", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_directed_walk_generation_single_root_node(self, tree_graph):\n\n    def _check_directed_walk(walk, n_size):\n        if ((len(n_size) > 1) and (n_size[0] > 0) and (n_size[1] > 0)):\n            for child_pos in range(n_size[0]):\n                child = walk[(child_pos + 1)]\n                grandchildren_start = ((1 + n_size[0]) + (child_pos * n_size[1]))\n                grandchildren_end = (grandchildren_start + n_size[1])\n                grandchildren = walk[grandchildren_start:grandchildren_end]\n                if (child == 'root'):\n                    for grandchild in grandchildren:\n                        assert (grandchild in [0, 1, 2])\n                elif (child == '0'):\n                    for grandchild in grandchildren:\n                        assert (grandchild == 'root')\n                elif (child == 1):\n                    for grandchild in grandchildren:\n                        assert (grandchild in ['c1.1', 'root'])\n                elif (child == 2):\n                    for grandchild in grandchildren:\n                        assert (grandchild in ['c2.1', 'c2.2', 'root'])\n                else:\n                    assert (1 == 0)\n    bfw = SampledBreadthFirstWalk(tree_graph)\n    nodes = tree_graph.node_ids_to_ilocs(['root'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == 1)\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    assert (subgraphs[0][1] != (- 1))\n    assert (subgraphs[0][2] != (- 1))\n    _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraphs[0]), n_size)\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraphs[0]), n_size)\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n = 99\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n        _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraph), n_size)\n    n = 17\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])", "masked_code": "def test_directed_walk_generation_single_root_node(self, tree_graph):\n\n    def _check_directed_walk(walk, n_size):\n        if ((len(n_size) > 1) and (n_size[0] > 0) and (n_size[1] > 0)):\n            for child_pos in range(n_size[0]):\n                child = walk[(child_pos + 1)]\n                grandchildren_start = ((1 + n_size[0]) + (child_pos * n_size[1]))\n                grandchildren_end = (grandchildren_start + n_size[1])\n                grandchildren = walk[grandchildren_start:grandchildren_end]\n                if (child == 'root'):\n                    for grandchild in grandchildren:\n                        assert (grandchild in [0, 1, 2])\n                elif (child == '0'):\n                    for grandchild in grandchildren:\n                        assert (grandchild == 'root')\n                elif (child == 1):\n                    for grandchild in grandchildren:\n                        assert (grandchild in ['c1.1', 'root'])\n                elif (child == 2):\n                    for grandchild in grandchildren:\n                        assert (grandchild in ['c2.1', 'c2.2', 'root'])\n                else:\n                    assert (1 == 0)\n    bfw = SampledBreadthFirstWalk(tree_graph)\n    nodes = tree_graph.node_ids_to_ilocs(['root'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == 1)\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == '???')\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    assert (subgraphs[0][1] != (- 1))\n    assert (subgraphs[0][2] != (- 1))\n    _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraphs[0]), n_size)\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraphs[0]), n_size)\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n = 99\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n        _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraph), n_size)\n    n = 17\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])", "ground_truth": "tree_graph.node_ids_to_ilocs(['root'])[0]", "quality_analysis": {"complexity_score": 19, "left_complexity": 9, "right_complexity": 10, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_231", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_directed_walk_generation_single_root_node", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_directed_walk_generation_single_root_node(self, tree_graph):\n\n    def _check_directed_walk(walk, n_size):\n        if ((len(n_size) > 1) and (n_size[0] > 0) and (n_size[1] > 0)):\n            for child_pos in range(n_size[0]):\n                child = walk[(child_pos + 1)]\n                grandchildren_start = ((1 + n_size[0]) + (child_pos * n_size[1]))\n                grandchildren_end = (grandchildren_start + n_size[1])\n                grandchildren = walk[grandchildren_start:grandchildren_end]\n                if (child == 'root'):\n                    for grandchild in grandchildren:\n                        assert (grandchild in [0, 1, 2])\n                elif (child == '0'):\n                    for grandchild in grandchildren:\n                        assert (grandchild == 'root')\n                elif (child == 1):\n                    for grandchild in grandchildren:\n                        assert (grandchild in ['c1.1', 'root'])\n                elif (child == 2):\n                    for grandchild in grandchildren:\n                        assert (grandchild in ['c2.1', 'c2.2', 'root'])\n                else:\n                    assert (1 == 0)\n    bfw = SampledBreadthFirstWalk(tree_graph)\n    nodes = tree_graph.node_ids_to_ilocs(['root'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == 1)\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    assert (subgraphs[0][1] != (- 1))\n    assert (subgraphs[0][2] != (- 1))\n    _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraphs[0]), n_size)\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraphs[0]), n_size)\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n = 99\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n        _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraph), n_size)\n    n = 17\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])", "masked_code": "def test_directed_walk_generation_single_root_node(self, tree_graph):\n\n    def _check_directed_walk(walk, n_size):\n        if ((len(n_size) > 1) and (n_size[0] > 0) and (n_size[1] > 0)):\n            for child_pos in range(n_size[0]):\n                child = walk[(child_pos + 1)]\n                grandchildren_start = ((1 + n_size[0]) + (child_pos * n_size[1]))\n                grandchildren_end = (grandchildren_start + n_size[1])\n                grandchildren = walk[grandchildren_start:grandchildren_end]\n                if (child == 'root'):\n                    for grandchild in grandchildren:\n                        assert (grandchild in [0, 1, 2])\n                elif (child == '0'):\n                    for grandchild in grandchildren:\n                        assert (grandchild == 'root')\n                elif (child == 1):\n                    for grandchild in grandchildren:\n                        assert (grandchild in ['c1.1', 'root'])\n                elif (child == 2):\n                    for grandchild in grandchildren:\n                        assert (grandchild in ['c2.1', 'c2.2', 'root'])\n                else:\n                    assert (1 == 0)\n    bfw = SampledBreadthFirstWalk(tree_graph)\n    nodes = tree_graph.node_ids_to_ilocs(['root'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == 1)\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == '???')\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    assert (subgraphs[0][1] != (- 1))\n    assert (subgraphs[0][2] != (- 1))\n    _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraphs[0]), n_size)\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraphs[0]), n_size)\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n = 99\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n        _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraph), n_size)\n    n = 17\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])", "ground_truth": "n", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_232", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_directed_walk_generation_single_root_node", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_directed_walk_generation_single_root_node(self, tree_graph):\n\n    def _check_directed_walk(walk, n_size):\n        if ((len(n_size) > 1) and (n_size[0] > 0) and (n_size[1] > 0)):\n            for child_pos in range(n_size[0]):\n                child = walk[(child_pos + 1)]\n                grandchildren_start = ((1 + n_size[0]) + (child_pos * n_size[1]))\n                grandchildren_end = (grandchildren_start + n_size[1])\n                grandchildren = walk[grandchildren_start:grandchildren_end]\n                if (child == 'root'):\n                    for grandchild in grandchildren:\n                        assert (grandchild in [0, 1, 2])\n                elif (child == '0'):\n                    for grandchild in grandchildren:\n                        assert (grandchild == 'root')\n                elif (child == 1):\n                    for grandchild in grandchildren:\n                        assert (grandchild in ['c1.1', 'root'])\n                elif (child == 2):\n                    for grandchild in grandchildren:\n                        assert (grandchild in ['c2.1', 'c2.2', 'root'])\n                else:\n                    assert (1 == 0)\n    bfw = SampledBreadthFirstWalk(tree_graph)\n    nodes = tree_graph.node_ids_to_ilocs(['root'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == 1)\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    assert (subgraphs[0][1] != (- 1))\n    assert (subgraphs[0][2] != (- 1))\n    _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraphs[0]), n_size)\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraphs[0]), n_size)\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n = 99\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n        _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraph), n_size)\n    n = 17\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])", "masked_code": "def test_directed_walk_generation_single_root_node(self, tree_graph):\n\n    def _check_directed_walk(walk, n_size):\n        if ((len(n_size) > 1) and (n_size[0] > 0) and (n_size[1] > 0)):\n            for child_pos in range(n_size[0]):\n                child = walk[(child_pos + 1)]\n                grandchildren_start = ((1 + n_size[0]) + (child_pos * n_size[1]))\n                grandchildren_end = (grandchildren_start + n_size[1])\n                grandchildren = walk[grandchildren_start:grandchildren_end]\n                if (child == 'root'):\n                    for grandchild in grandchildren:\n                        assert (grandchild in [0, 1, 2])\n                elif (child == '0'):\n                    for grandchild in grandchildren:\n                        assert (grandchild == 'root')\n                elif (child == 1):\n                    for grandchild in grandchildren:\n                        assert (grandchild in ['c1.1', 'root'])\n                elif (child == 2):\n                    for grandchild in grandchildren:\n                        assert (grandchild in ['c2.1', 'c2.2', 'root'])\n                else:\n                    assert (1 == 0)\n    bfw = SampledBreadthFirstWalk(tree_graph)\n    nodes = tree_graph.node_ids_to_ilocs(['root'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == 1)\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == '???')\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    assert (subgraphs[0][1] != (- 1))\n    assert (subgraphs[0][2] != (- 1))\n    _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraphs[0]), n_size)\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraphs[0]), n_size)\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n = 99\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n        _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraph), n_size)\n    n = 17\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])", "ground_truth": "expected_bfw_size(n_size)", "quality_analysis": {"complexity_score": 12, "left_complexity": 8, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_233", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_directed_walk_generation_single_root_node", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_directed_walk_generation_single_root_node(self, tree_graph):\n\n    def _check_directed_walk(walk, n_size):\n        if ((len(n_size) > 1) and (n_size[0] > 0) and (n_size[1] > 0)):\n            for child_pos in range(n_size[0]):\n                child = walk[(child_pos + 1)]\n                grandchildren_start = ((1 + n_size[0]) + (child_pos * n_size[1]))\n                grandchildren_end = (grandchildren_start + n_size[1])\n                grandchildren = walk[grandchildren_start:grandchildren_end]\n                if (child == 'root'):\n                    for grandchild in grandchildren:\n                        assert (grandchild in [0, 1, 2])\n                elif (child == '0'):\n                    for grandchild in grandchildren:\n                        assert (grandchild == 'root')\n                elif (child == 1):\n                    for grandchild in grandchildren:\n                        assert (grandchild in ['c1.1', 'root'])\n                elif (child == 2):\n                    for grandchild in grandchildren:\n                        assert (grandchild in ['c2.1', 'c2.2', 'root'])\n                else:\n                    assert (1 == 0)\n    bfw = SampledBreadthFirstWalk(tree_graph)\n    nodes = tree_graph.node_ids_to_ilocs(['root'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == 1)\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    assert (subgraphs[0][1] != (- 1))\n    assert (subgraphs[0][2] != (- 1))\n    _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraphs[0]), n_size)\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraphs[0]), n_size)\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n = 99\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n        _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraph), n_size)\n    n = 17\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])", "masked_code": "def test_directed_walk_generation_single_root_node(self, tree_graph):\n\n    def _check_directed_walk(walk, n_size):\n        if ((len(n_size) > 1) and (n_size[0] > 0) and (n_size[1] > 0)):\n            for child_pos in range(n_size[0]):\n                child = walk[(child_pos + 1)]\n                grandchildren_start = ((1 + n_size[0]) + (child_pos * n_size[1]))\n                grandchildren_end = (grandchildren_start + n_size[1])\n                grandchildren = walk[grandchildren_start:grandchildren_end]\n                if (child == 'root'):\n                    for grandchild in grandchildren:\n                        assert (grandchild in [0, 1, 2])\n                elif (child == '0'):\n                    for grandchild in grandchildren:\n                        assert (grandchild == 'root')\n                elif (child == 1):\n                    for grandchild in grandchildren:\n                        assert (grandchild in ['c1.1', 'root'])\n                elif (child == 2):\n                    for grandchild in grandchildren:\n                        assert (grandchild in ['c2.1', 'c2.2', 'root'])\n                else:\n                    assert (1 == 0)\n    bfw = SampledBreadthFirstWalk(tree_graph)\n    nodes = tree_graph.node_ids_to_ilocs(['root'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == 1)\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == '???')\n    assert (subgraphs[0][1] != (- 1))\n    assert (subgraphs[0][2] != (- 1))\n    _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraphs[0]), n_size)\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraphs[0]), n_size)\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n = 99\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n        _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraph), n_size)\n    n = 17\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])", "ground_truth": "tree_graph.node_ids_to_ilocs(['root'])[0]", "quality_analysis": {"complexity_score": 19, "left_complexity": 9, "right_complexity": 10, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_234", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_directed_walk_generation_single_root_node", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_directed_walk_generation_single_root_node(self, tree_graph):\n\n    def _check_directed_walk(walk, n_size):\n        if ((len(n_size) > 1) and (n_size[0] > 0) and (n_size[1] > 0)):\n            for child_pos in range(n_size[0]):\n                child = walk[(child_pos + 1)]\n                grandchildren_start = ((1 + n_size[0]) + (child_pos * n_size[1]))\n                grandchildren_end = (grandchildren_start + n_size[1])\n                grandchildren = walk[grandchildren_start:grandchildren_end]\n                if (child == 'root'):\n                    for grandchild in grandchildren:\n                        assert (grandchild in [0, 1, 2])\n                elif (child == '0'):\n                    for grandchild in grandchildren:\n                        assert (grandchild == 'root')\n                elif (child == 1):\n                    for grandchild in grandchildren:\n                        assert (grandchild in ['c1.1', 'root'])\n                elif (child == 2):\n                    for grandchild in grandchildren:\n                        assert (grandchild in ['c2.1', 'c2.2', 'root'])\n                else:\n                    assert (1 == 0)\n    bfw = SampledBreadthFirstWalk(tree_graph)\n    nodes = tree_graph.node_ids_to_ilocs(['root'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == 1)\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    assert (subgraphs[0][1] != (- 1))\n    assert (subgraphs[0][2] != (- 1))\n    _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraphs[0]), n_size)\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraphs[0]), n_size)\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n = 99\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n        _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraph), n_size)\n    n = 17\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])", "masked_code": "def test_directed_walk_generation_single_root_node(self, tree_graph):\n\n    def _check_directed_walk(walk, n_size):\n        if ((len(n_size) > 1) and (n_size[0] > 0) and (n_size[1] > 0)):\n            for child_pos in range(n_size[0]):\n                child = walk[(child_pos + 1)]\n                grandchildren_start = ((1 + n_size[0]) + (child_pos * n_size[1]))\n                grandchildren_end = (grandchildren_start + n_size[1])\n                grandchildren = walk[grandchildren_start:grandchildren_end]\n                if (child == 'root'):\n                    for grandchild in grandchildren:\n                        assert (grandchild in [0, 1, 2])\n                elif (child == '0'):\n                    for grandchild in grandchildren:\n                        assert (grandchild == 'root')\n                elif (child == 1):\n                    for grandchild in grandchildren:\n                        assert (grandchild in ['c1.1', 'root'])\n                elif (child == 2):\n                    for grandchild in grandchildren:\n                        assert (grandchild in ['c2.1', 'c2.2', 'root'])\n                else:\n                    assert (1 == 0)\n    bfw = SampledBreadthFirstWalk(tree_graph)\n    nodes = tree_graph.node_ids_to_ilocs(['root'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == 1)\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    assert (subgraphs[0][1] != (- 1))\n    assert (subgraphs[0][2] != (- 1))\n    _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraphs[0]), n_size)\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == '???')\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraphs[0]), n_size)\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n = 99\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n        _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraph), n_size)\n    n = 17\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])", "ground_truth": "n", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_235", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_directed_walk_generation_single_root_node", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_directed_walk_generation_single_root_node(self, tree_graph):\n\n    def _check_directed_walk(walk, n_size):\n        if ((len(n_size) > 1) and (n_size[0] > 0) and (n_size[1] > 0)):\n            for child_pos in range(n_size[0]):\n                child = walk[(child_pos + 1)]\n                grandchildren_start = ((1 + n_size[0]) + (child_pos * n_size[1]))\n                grandchildren_end = (grandchildren_start + n_size[1])\n                grandchildren = walk[grandchildren_start:grandchildren_end]\n                if (child == 'root'):\n                    for grandchild in grandchildren:\n                        assert (grandchild in [0, 1, 2])\n                elif (child == '0'):\n                    for grandchild in grandchildren:\n                        assert (grandchild == 'root')\n                elif (child == 1):\n                    for grandchild in grandchildren:\n                        assert (grandchild in ['c1.1', 'root'])\n                elif (child == 2):\n                    for grandchild in grandchildren:\n                        assert (grandchild in ['c2.1', 'c2.2', 'root'])\n                else:\n                    assert (1 == 0)\n    bfw = SampledBreadthFirstWalk(tree_graph)\n    nodes = tree_graph.node_ids_to_ilocs(['root'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == 1)\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    assert (subgraphs[0][1] != (- 1))\n    assert (subgraphs[0][2] != (- 1))\n    _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraphs[0]), n_size)\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraphs[0]), n_size)\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n = 99\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n        _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraph), n_size)\n    n = 17\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])", "masked_code": "def test_directed_walk_generation_single_root_node(self, tree_graph):\n\n    def _check_directed_walk(walk, n_size):\n        if ((len(n_size) > 1) and (n_size[0] > 0) and (n_size[1] > 0)):\n            for child_pos in range(n_size[0]):\n                child = walk[(child_pos + 1)]\n                grandchildren_start = ((1 + n_size[0]) + (child_pos * n_size[1]))\n                grandchildren_end = (grandchildren_start + n_size[1])\n                grandchildren = walk[grandchildren_start:grandchildren_end]\n                if (child == 'root'):\n                    for grandchild in grandchildren:\n                        assert (grandchild in [0, 1, 2])\n                elif (child == '0'):\n                    for grandchild in grandchildren:\n                        assert (grandchild == 'root')\n                elif (child == 1):\n                    for grandchild in grandchildren:\n                        assert (grandchild in ['c1.1', 'root'])\n                elif (child == 2):\n                    for grandchild in grandchildren:\n                        assert (grandchild in ['c2.1', 'c2.2', 'root'])\n                else:\n                    assert (1 == 0)\n    bfw = SampledBreadthFirstWalk(tree_graph)\n    nodes = tree_graph.node_ids_to_ilocs(['root'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == 1)\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    assert (subgraphs[0][1] != (- 1))\n    assert (subgraphs[0][2] != (- 1))\n    _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraphs[0]), n_size)\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == '???')\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraphs[0]), n_size)\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n = 99\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n        _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraph), n_size)\n    n = 17\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])", "ground_truth": "expected_bfw_size(n_size)", "quality_analysis": {"complexity_score": 12, "left_complexity": 8, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_236", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_directed_walk_generation_single_root_node", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_directed_walk_generation_single_root_node(self, tree_graph):\n\n    def _check_directed_walk(walk, n_size):\n        if ((len(n_size) > 1) and (n_size[0] > 0) and (n_size[1] > 0)):\n            for child_pos in range(n_size[0]):\n                child = walk[(child_pos + 1)]\n                grandchildren_start = ((1 + n_size[0]) + (child_pos * n_size[1]))\n                grandchildren_end = (grandchildren_start + n_size[1])\n                grandchildren = walk[grandchildren_start:grandchildren_end]\n                if (child == 'root'):\n                    for grandchild in grandchildren:\n                        assert (grandchild in [0, 1, 2])\n                elif (child == '0'):\n                    for grandchild in grandchildren:\n                        assert (grandchild == 'root')\n                elif (child == 1):\n                    for grandchild in grandchildren:\n                        assert (grandchild in ['c1.1', 'root'])\n                elif (child == 2):\n                    for grandchild in grandchildren:\n                        assert (grandchild in ['c2.1', 'c2.2', 'root'])\n                else:\n                    assert (1 == 0)\n    bfw = SampledBreadthFirstWalk(tree_graph)\n    nodes = tree_graph.node_ids_to_ilocs(['root'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == 1)\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    assert (subgraphs[0][1] != (- 1))\n    assert (subgraphs[0][2] != (- 1))\n    _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraphs[0]), n_size)\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraphs[0]), n_size)\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n = 99\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n        _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraph), n_size)\n    n = 17\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])", "masked_code": "def test_directed_walk_generation_single_root_node(self, tree_graph):\n\n    def _check_directed_walk(walk, n_size):\n        if ((len(n_size) > 1) and (n_size[0] > 0) and (n_size[1] > 0)):\n            for child_pos in range(n_size[0]):\n                child = walk[(child_pos + 1)]\n                grandchildren_start = ((1 + n_size[0]) + (child_pos * n_size[1]))\n                grandchildren_end = (grandchildren_start + n_size[1])\n                grandchildren = walk[grandchildren_start:grandchildren_end]\n                if (child == 'root'):\n                    for grandchild in grandchildren:\n                        assert (grandchild in [0, 1, 2])\n                elif (child == '0'):\n                    for grandchild in grandchildren:\n                        assert (grandchild == 'root')\n                elif (child == 1):\n                    for grandchild in grandchildren:\n                        assert (grandchild in ['c1.1', 'root'])\n                elif (child == 2):\n                    for grandchild in grandchildren:\n                        assert (grandchild in ['c2.1', 'c2.2', 'root'])\n                else:\n                    assert (1 == 0)\n    bfw = SampledBreadthFirstWalk(tree_graph)\n    nodes = tree_graph.node_ids_to_ilocs(['root'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == 1)\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    assert (subgraphs[0][1] != (- 1))\n    assert (subgraphs[0][2] != (- 1))\n    _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraphs[0]), n_size)\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == '???')\n    _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraphs[0]), n_size)\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n = 99\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n        _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraph), n_size)\n    n = 17\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])", "ground_truth": "tree_graph.node_ids_to_ilocs(['root'])[0]", "quality_analysis": {"complexity_score": 19, "left_complexity": 9, "right_complexity": 10, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_237", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_directed_walk_generation_single_root_node", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_directed_walk_generation_single_root_node(self, tree_graph):\n\n    def _check_directed_walk(walk, n_size):\n        if ((len(n_size) > 1) and (n_size[0] > 0) and (n_size[1] > 0)):\n            for child_pos in range(n_size[0]):\n                child = walk[(child_pos + 1)]\n                grandchildren_start = ((1 + n_size[0]) + (child_pos * n_size[1]))\n                grandchildren_end = (grandchildren_start + n_size[1])\n                grandchildren = walk[grandchildren_start:grandchildren_end]\n                if (child == 'root'):\n                    for grandchild in grandchildren:\n                        assert (grandchild in [0, 1, 2])\n                elif (child == '0'):\n                    for grandchild in grandchildren:\n                        assert (grandchild == 'root')\n                elif (child == 1):\n                    for grandchild in grandchildren:\n                        assert (grandchild in ['c1.1', 'root'])\n                elif (child == 2):\n                    for grandchild in grandchildren:\n                        assert (grandchild in ['c2.1', 'c2.2', 'root'])\n                else:\n                    assert (1 == 0)\n    bfw = SampledBreadthFirstWalk(tree_graph)\n    nodes = tree_graph.node_ids_to_ilocs(['root'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == 1)\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    assert (subgraphs[0][1] != (- 1))\n    assert (subgraphs[0][2] != (- 1))\n    _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraphs[0]), n_size)\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraphs[0]), n_size)\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n = 99\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n        _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraph), n_size)\n    n = 17\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])", "masked_code": "def test_directed_walk_generation_single_root_node(self, tree_graph):\n\n    def _check_directed_walk(walk, n_size):\n        if ((len(n_size) > 1) and (n_size[0] > 0) and (n_size[1] > 0)):\n            for child_pos in range(n_size[0]):\n                child = walk[(child_pos + 1)]\n                grandchildren_start = ((1 + n_size[0]) + (child_pos * n_size[1]))\n                grandchildren_end = (grandchildren_start + n_size[1])\n                grandchildren = walk[grandchildren_start:grandchildren_end]\n                if (child == 'root'):\n                    for grandchild in grandchildren:\n                        assert (grandchild in [0, 1, 2])\n                elif (child == '0'):\n                    for grandchild in grandchildren:\n                        assert (grandchild == 'root')\n                elif (child == 1):\n                    for grandchild in grandchildren:\n                        assert (grandchild in ['c1.1', 'root'])\n                elif (child == 2):\n                    for grandchild in grandchildren:\n                        assert (grandchild in ['c2.1', 'c2.2', 'root'])\n                else:\n                    assert (1 == 0)\n    bfw = SampledBreadthFirstWalk(tree_graph)\n    nodes = tree_graph.node_ids_to_ilocs(['root'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == 1)\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    assert (subgraphs[0][1] != (- 1))\n    assert (subgraphs[0][2] != (- 1))\n    _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraphs[0]), n_size)\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraphs[0]), n_size)\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == '???')\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n = 99\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n        _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraph), n_size)\n    n = 17\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])", "ground_truth": "n", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_238", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_directed_walk_generation_single_root_node", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_directed_walk_generation_single_root_node(self, tree_graph):\n\n    def _check_directed_walk(walk, n_size):\n        if ((len(n_size) > 1) and (n_size[0] > 0) and (n_size[1] > 0)):\n            for child_pos in range(n_size[0]):\n                child = walk[(child_pos + 1)]\n                grandchildren_start = ((1 + n_size[0]) + (child_pos * n_size[1]))\n                grandchildren_end = (grandchildren_start + n_size[1])\n                grandchildren = walk[grandchildren_start:grandchildren_end]\n                if (child == 'root'):\n                    for grandchild in grandchildren:\n                        assert (grandchild in [0, 1, 2])\n                elif (child == '0'):\n                    for grandchild in grandchildren:\n                        assert (grandchild == 'root')\n                elif (child == 1):\n                    for grandchild in grandchildren:\n                        assert (grandchild in ['c1.1', 'root'])\n                elif (child == 2):\n                    for grandchild in grandchildren:\n                        assert (grandchild in ['c2.1', 'c2.2', 'root'])\n                else:\n                    assert (1 == 0)\n    bfw = SampledBreadthFirstWalk(tree_graph)\n    nodes = tree_graph.node_ids_to_ilocs(['root'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == 1)\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    assert (subgraphs[0][1] != (- 1))\n    assert (subgraphs[0][2] != (- 1))\n    _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraphs[0]), n_size)\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraphs[0]), n_size)\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n = 99\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n        _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraph), n_size)\n    n = 17\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])", "masked_code": "def test_directed_walk_generation_single_root_node(self, tree_graph):\n\n    def _check_directed_walk(walk, n_size):\n        if ((len(n_size) > 1) and (n_size[0] > 0) and (n_size[1] > 0)):\n            for child_pos in range(n_size[0]):\n                child = walk[(child_pos + 1)]\n                grandchildren_start = ((1 + n_size[0]) + (child_pos * n_size[1]))\n                grandchildren_end = (grandchildren_start + n_size[1])\n                grandchildren = walk[grandchildren_start:grandchildren_end]\n                if (child == 'root'):\n                    for grandchild in grandchildren:\n                        assert (grandchild in [0, 1, 2])\n                elif (child == '0'):\n                    for grandchild in grandchildren:\n                        assert (grandchild == 'root')\n                elif (child == 1):\n                    for grandchild in grandchildren:\n                        assert (grandchild in ['c1.1', 'root'])\n                elif (child == 2):\n                    for grandchild in grandchildren:\n                        assert (grandchild in ['c2.1', 'c2.2', 'root'])\n                else:\n                    assert (1 == 0)\n    bfw = SampledBreadthFirstWalk(tree_graph)\n    nodes = tree_graph.node_ids_to_ilocs(['root'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == 1)\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    assert (subgraphs[0][1] != (- 1))\n    assert (subgraphs[0][2] != (- 1))\n    _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraphs[0]), n_size)\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraphs[0]), n_size)\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == '???')\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n = 99\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n        _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraph), n_size)\n    n = 17\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])", "ground_truth": "n", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_239", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_directed_walk_generation_single_root_node", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_directed_walk_generation_single_root_node(self, tree_graph):\n\n    def _check_directed_walk(walk, n_size):\n        if ((len(n_size) > 1) and (n_size[0] > 0) and (n_size[1] > 0)):\n            for child_pos in range(n_size[0]):\n                child = walk[(child_pos + 1)]\n                grandchildren_start = ((1 + n_size[0]) + (child_pos * n_size[1]))\n                grandchildren_end = (grandchildren_start + n_size[1])\n                grandchildren = walk[grandchildren_start:grandchildren_end]\n                if (child == 'root'):\n                    for grandchild in grandchildren:\n                        assert (grandchild in [0, 1, 2])\n                elif (child == '0'):\n                    for grandchild in grandchildren:\n                        assert (grandchild == 'root')\n                elif (child == 1):\n                    for grandchild in grandchildren:\n                        assert (grandchild in ['c1.1', 'root'])\n                elif (child == 2):\n                    for grandchild in grandchildren:\n                        assert (grandchild in ['c2.1', 'c2.2', 'root'])\n                else:\n                    assert (1 == 0)\n    bfw = SampledBreadthFirstWalk(tree_graph)\n    nodes = tree_graph.node_ids_to_ilocs(['root'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == 1)\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    assert (subgraphs[0][1] != (- 1))\n    assert (subgraphs[0][2] != (- 1))\n    _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraphs[0]), n_size)\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraphs[0]), n_size)\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n = 99\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n        _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraph), n_size)\n    n = 17\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])", "masked_code": "def test_directed_walk_generation_single_root_node(self, tree_graph):\n\n    def _check_directed_walk(walk, n_size):\n        if ((len(n_size) > 1) and (n_size[0] > 0) and (n_size[1] > 0)):\n            for child_pos in range(n_size[0]):\n                child = walk[(child_pos + 1)]\n                grandchildren_start = ((1 + n_size[0]) + (child_pos * n_size[1]))\n                grandchildren_end = (grandchildren_start + n_size[1])\n                grandchildren = walk[grandchildren_start:grandchildren_end]\n                if (child == 'root'):\n                    for grandchild in grandchildren:\n                        assert (grandchild in [0, 1, 2])\n                elif (child == '0'):\n                    for grandchild in grandchildren:\n                        assert (grandchild == 'root')\n                elif (child == 1):\n                    for grandchild in grandchildren:\n                        assert (grandchild in ['c1.1', 'root'])\n                elif (child == 2):\n                    for grandchild in grandchildren:\n                        assert (grandchild in ['c2.1', 'c2.2', 'root'])\n                else:\n                    assert (1 == 0)\n    bfw = SampledBreadthFirstWalk(tree_graph)\n    nodes = tree_graph.node_ids_to_ilocs(['root'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == 1)\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    assert (subgraphs[0][1] != (- 1))\n    assert (subgraphs[0][2] != (- 1))\n    _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraphs[0]), n_size)\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraphs[0]), n_size)\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n = 99\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == '???')\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n        _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraph), n_size)\n    n = 17\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])", "ground_truth": "n", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_240", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_directed_walk_generation_single_root_node", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_directed_walk_generation_single_root_node(self, tree_graph):\n\n    def _check_directed_walk(walk, n_size):\n        if ((len(n_size) > 1) and (n_size[0] > 0) and (n_size[1] > 0)):\n            for child_pos in range(n_size[0]):\n                child = walk[(child_pos + 1)]\n                grandchildren_start = ((1 + n_size[0]) + (child_pos * n_size[1]))\n                grandchildren_end = (grandchildren_start + n_size[1])\n                grandchildren = walk[grandchildren_start:grandchildren_end]\n                if (child == 'root'):\n                    for grandchild in grandchildren:\n                        assert (grandchild in [0, 1, 2])\n                elif (child == '0'):\n                    for grandchild in grandchildren:\n                        assert (grandchild == 'root')\n                elif (child == 1):\n                    for grandchild in grandchildren:\n                        assert (grandchild in ['c1.1', 'root'])\n                elif (child == 2):\n                    for grandchild in grandchildren:\n                        assert (grandchild in ['c2.1', 'c2.2', 'root'])\n                else:\n                    assert (1 == 0)\n    bfw = SampledBreadthFirstWalk(tree_graph)\n    nodes = tree_graph.node_ids_to_ilocs(['root'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == 1)\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    assert (subgraphs[0][1] != (- 1))\n    assert (subgraphs[0][2] != (- 1))\n    _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraphs[0]), n_size)\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraphs[0]), n_size)\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n = 99\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n        _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraph), n_size)\n    n = 17\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])", "masked_code": "def test_directed_walk_generation_single_root_node(self, tree_graph):\n\n    def _check_directed_walk(walk, n_size):\n        if ((len(n_size) > 1) and (n_size[0] > 0) and (n_size[1] > 0)):\n            for child_pos in range(n_size[0]):\n                child = walk[(child_pos + 1)]\n                grandchildren_start = ((1 + n_size[0]) + (child_pos * n_size[1]))\n                grandchildren_end = (grandchildren_start + n_size[1])\n                grandchildren = walk[grandchildren_start:grandchildren_end]\n                if (child == 'root'):\n                    for grandchild in grandchildren:\n                        assert (grandchild in [0, 1, 2])\n                elif (child == '0'):\n                    for grandchild in grandchildren:\n                        assert (grandchild == 'root')\n                elif (child == 1):\n                    for grandchild in grandchildren:\n                        assert (grandchild in ['c1.1', 'root'])\n                elif (child == 2):\n                    for grandchild in grandchildren:\n                        assert (grandchild in ['c2.1', 'c2.2', 'root'])\n                else:\n                    assert (1 == 0)\n    bfw = SampledBreadthFirstWalk(tree_graph)\n    nodes = tree_graph.node_ids_to_ilocs(['root'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == 1)\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    assert (subgraphs[0][1] != (- 1))\n    assert (subgraphs[0][2] != (- 1))\n    _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraphs[0]), n_size)\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraphs[0]), n_size)\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n = 99\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n        _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraph), n_size)\n    n = 17\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == '???')\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])", "ground_truth": "n", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_241", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_directed_walk_generation_single_root_node", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_directed_walk_generation_single_root_node(self, tree_graph):\n\n    def _check_directed_walk(walk, n_size):\n        if ((len(n_size) > 1) and (n_size[0] > 0) and (n_size[1] > 0)):\n            for child_pos in range(n_size[0]):\n                child = walk[(child_pos + 1)]\n                grandchildren_start = ((1 + n_size[0]) + (child_pos * n_size[1]))\n                grandchildren_end = (grandchildren_start + n_size[1])\n                grandchildren = walk[grandchildren_start:grandchildren_end]\n                if (child == 'root'):\n                    for grandchild in grandchildren:\n                        assert (grandchild in [0, 1, 2])\n                elif (child == '0'):\n                    for grandchild in grandchildren:\n                        assert (grandchild == 'root')\n                elif (child == 1):\n                    for grandchild in grandchildren:\n                        assert (grandchild in ['c1.1', 'root'])\n                elif (child == 2):\n                    for grandchild in grandchildren:\n                        assert (grandchild in ['c2.1', 'c2.2', 'root'])\n                else:\n                    assert (1 == 0)\n    bfw = SampledBreadthFirstWalk(tree_graph)\n    nodes = tree_graph.node_ids_to_ilocs(['root'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == 1)\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    assert (subgraphs[0][1] != (- 1))\n    assert (subgraphs[0][2] != (- 1))\n    _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraphs[0]), n_size)\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraphs[0]), n_size)\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n = 99\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n        _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraph), n_size)\n    n = 17\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])", "masked_code": "def test_directed_walk_generation_single_root_node(self, tree_graph):\n\n    def _check_directed_walk(walk, n_size):\n        if ((len(n_size) > 1) and (n_size[0] > 0) and (n_size[1] > 0)):\n            for child_pos in range(n_size[0]):\n                child = walk[(child_pos + 1)]\n                grandchildren_start = ((1 + n_size[0]) + (child_pos * n_size[1]))\n                grandchildren_end = (grandchildren_start + n_size[1])\n                grandchildren = walk[grandchildren_start:grandchildren_end]\n                if (child == 'root'):\n                    for grandchild in grandchildren:\n                        assert (grandchild in [0, 1, 2])\n                elif (child == '0'):\n                    for grandchild in grandchildren:\n                        assert (grandchild == 'root')\n                elif (child == 1):\n                    for grandchild in grandchildren:\n                        assert (grandchild in ['c1.1', 'root'])\n                elif (child == 2):\n                    for grandchild in grandchildren:\n                        assert (grandchild in ['c2.1', 'c2.2', 'root'])\n                else:\n                    assert (1 == 0)\n    bfw = SampledBreadthFirstWalk(tree_graph)\n    nodes = tree_graph.node_ids_to_ilocs(['root'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == 1)\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    assert (subgraphs[0][1] != (- 1))\n    assert (subgraphs[0][2] != (- 1))\n    _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraphs[0]), n_size)\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraphs[0]), n_size)\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == '???')\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n = 99\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n        _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraph), n_size)\n    n = 17\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])", "ground_truth": "tree_graph.node_ids_to_ilocs(['root'])[0]", "quality_analysis": {"complexity_score": 15, "left_complexity": 5, "right_complexity": 10, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_242", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_directed_walk_generation_single_root_node", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_directed_walk_generation_single_root_node(self, tree_graph):\n\n    def _check_directed_walk(walk, n_size):\n        if ((len(n_size) > 1) and (n_size[0] > 0) and (n_size[1] > 0)):\n            for child_pos in range(n_size[0]):\n                child = walk[(child_pos + 1)]\n                grandchildren_start = ((1 + n_size[0]) + (child_pos * n_size[1]))\n                grandchildren_end = (grandchildren_start + n_size[1])\n                grandchildren = walk[grandchildren_start:grandchildren_end]\n                if (child == 'root'):\n                    for grandchild in grandchildren:\n                        assert (grandchild in [0, 1, 2])\n                elif (child == '0'):\n                    for grandchild in grandchildren:\n                        assert (grandchild == 'root')\n                elif (child == 1):\n                    for grandchild in grandchildren:\n                        assert (grandchild in ['c1.1', 'root'])\n                elif (child == 2):\n                    for grandchild in grandchildren:\n                        assert (grandchild in ['c2.1', 'c2.2', 'root'])\n                else:\n                    assert (1 == 0)\n    bfw = SampledBreadthFirstWalk(tree_graph)\n    nodes = tree_graph.node_ids_to_ilocs(['root'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == 1)\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    assert (subgraphs[0][1] != (- 1))\n    assert (subgraphs[0][2] != (- 1))\n    _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraphs[0]), n_size)\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraphs[0]), n_size)\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n = 99\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n        _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraph), n_size)\n    n = 17\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])", "masked_code": "def test_directed_walk_generation_single_root_node(self, tree_graph):\n\n    def _check_directed_walk(walk, n_size):\n        if ((len(n_size) > 1) and (n_size[0] > 0) and (n_size[1] > 0)):\n            for child_pos in range(n_size[0]):\n                child = walk[(child_pos + 1)]\n                grandchildren_start = ((1 + n_size[0]) + (child_pos * n_size[1]))\n                grandchildren_end = (grandchildren_start + n_size[1])\n                grandchildren = walk[grandchildren_start:grandchildren_end]\n                if (child == 'root'):\n                    for grandchild in grandchildren:\n                        assert (grandchild in [0, 1, 2])\n                elif (child == '0'):\n                    for grandchild in grandchildren:\n                        assert (grandchild == 'root')\n                elif (child == 1):\n                    for grandchild in grandchildren:\n                        assert (grandchild in ['c1.1', 'root'])\n                elif (child == 2):\n                    for grandchild in grandchildren:\n                        assert (grandchild in ['c2.1', 'c2.2', 'root'])\n                else:\n                    assert (1 == 0)\n    bfw = SampledBreadthFirstWalk(tree_graph)\n    nodes = tree_graph.node_ids_to_ilocs(['root'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == 1)\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    assert (subgraphs[0][1] != (- 1))\n    assert (subgraphs[0][2] != (- 1))\n    _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraphs[0]), n_size)\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraphs[0]), n_size)\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == '???')\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n = 99\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n        _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraph), n_size)\n    n = 17\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])", "ground_truth": "expected_bfw_size(n_size)", "quality_analysis": {"complexity_score": 8, "left_complexity": 4, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_243", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_directed_walk_generation_single_root_node", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_directed_walk_generation_single_root_node(self, tree_graph):\n\n    def _check_directed_walk(walk, n_size):\n        if ((len(n_size) > 1) and (n_size[0] > 0) and (n_size[1] > 0)):\n            for child_pos in range(n_size[0]):\n                child = walk[(child_pos + 1)]\n                grandchildren_start = ((1 + n_size[0]) + (child_pos * n_size[1]))\n                grandchildren_end = (grandchildren_start + n_size[1])\n                grandchildren = walk[grandchildren_start:grandchildren_end]\n                if (child == 'root'):\n                    for grandchild in grandchildren:\n                        assert (grandchild in [0, 1, 2])\n                elif (child == '0'):\n                    for grandchild in grandchildren:\n                        assert (grandchild == 'root')\n                elif (child == 1):\n                    for grandchild in grandchildren:\n                        assert (grandchild in ['c1.1', 'root'])\n                elif (child == 2):\n                    for grandchild in grandchildren:\n                        assert (grandchild in ['c2.1', 'c2.2', 'root'])\n                else:\n                    assert (1 == 0)\n    bfw = SampledBreadthFirstWalk(tree_graph)\n    nodes = tree_graph.node_ids_to_ilocs(['root'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == 1)\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    assert (subgraphs[0][1] != (- 1))\n    assert (subgraphs[0][2] != (- 1))\n    _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraphs[0]), n_size)\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraphs[0]), n_size)\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n = 99\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n        _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraph), n_size)\n    n = 17\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])", "masked_code": "def test_directed_walk_generation_single_root_node(self, tree_graph):\n\n    def _check_directed_walk(walk, n_size):\n        if ((len(n_size) > 1) and (n_size[0] > 0) and (n_size[1] > 0)):\n            for child_pos in range(n_size[0]):\n                child = walk[(child_pos + 1)]\n                grandchildren_start = ((1 + n_size[0]) + (child_pos * n_size[1]))\n                grandchildren_end = (grandchildren_start + n_size[1])\n                grandchildren = walk[grandchildren_start:grandchildren_end]\n                if (child == 'root'):\n                    for grandchild in grandchildren:\n                        assert (grandchild in [0, 1, 2])\n                elif (child == '0'):\n                    for grandchild in grandchildren:\n                        assert (grandchild == 'root')\n                elif (child == 1):\n                    for grandchild in grandchildren:\n                        assert (grandchild in ['c1.1', 'root'])\n                elif (child == 2):\n                    for grandchild in grandchildren:\n                        assert (grandchild in ['c2.1', 'c2.2', 'root'])\n                else:\n                    assert (1 == 0)\n    bfw = SampledBreadthFirstWalk(tree_graph)\n    nodes = tree_graph.node_ids_to_ilocs(['root'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == 1)\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    assert (subgraphs[0][1] != (- 1))\n    assert (subgraphs[0][2] != (- 1))\n    _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraphs[0]), n_size)\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraphs[0]), n_size)\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == '???')\n    n = 99\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n        _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraph), n_size)\n    n = 17\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])", "ground_truth": "tree_graph.node_ids_to_ilocs(['root'])[0]", "quality_analysis": {"complexity_score": 15, "left_complexity": 5, "right_complexity": 10, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_244", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_directed_walk_generation_single_root_node", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_directed_walk_generation_single_root_node(self, tree_graph):\n\n    def _check_directed_walk(walk, n_size):\n        if ((len(n_size) > 1) and (n_size[0] > 0) and (n_size[1] > 0)):\n            for child_pos in range(n_size[0]):\n                child = walk[(child_pos + 1)]\n                grandchildren_start = ((1 + n_size[0]) + (child_pos * n_size[1]))\n                grandchildren_end = (grandchildren_start + n_size[1])\n                grandchildren = walk[grandchildren_start:grandchildren_end]\n                if (child == 'root'):\n                    for grandchild in grandchildren:\n                        assert (grandchild in [0, 1, 2])\n                elif (child == '0'):\n                    for grandchild in grandchildren:\n                        assert (grandchild == 'root')\n                elif (child == 1):\n                    for grandchild in grandchildren:\n                        assert (grandchild in ['c1.1', 'root'])\n                elif (child == 2):\n                    for grandchild in grandchildren:\n                        assert (grandchild in ['c2.1', 'c2.2', 'root'])\n                else:\n                    assert (1 == 0)\n    bfw = SampledBreadthFirstWalk(tree_graph)\n    nodes = tree_graph.node_ids_to_ilocs(['root'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == 1)\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    assert (subgraphs[0][1] != (- 1))\n    assert (subgraphs[0][2] != (- 1))\n    _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraphs[0]), n_size)\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraphs[0]), n_size)\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n = 99\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n        _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraph), n_size)\n    n = 17\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])", "masked_code": "def test_directed_walk_generation_single_root_node(self, tree_graph):\n\n    def _check_directed_walk(walk, n_size):\n        if ((len(n_size) > 1) and (n_size[0] > 0) and (n_size[1] > 0)):\n            for child_pos in range(n_size[0]):\n                child = walk[(child_pos + 1)]\n                grandchildren_start = ((1 + n_size[0]) + (child_pos * n_size[1]))\n                grandchildren_end = (grandchildren_start + n_size[1])\n                grandchildren = walk[grandchildren_start:grandchildren_end]\n                if (child == 'root'):\n                    for grandchild in grandchildren:\n                        assert (grandchild in [0, 1, 2])\n                elif (child == '0'):\n                    for grandchild in grandchildren:\n                        assert (grandchild == 'root')\n                elif (child == 1):\n                    for grandchild in grandchildren:\n                        assert (grandchild in ['c1.1', 'root'])\n                elif (child == 2):\n                    for grandchild in grandchildren:\n                        assert (grandchild in ['c2.1', 'c2.2', 'root'])\n                else:\n                    assert (1 == 0)\n    bfw = SampledBreadthFirstWalk(tree_graph)\n    nodes = tree_graph.node_ids_to_ilocs(['root'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == 1)\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    assert (subgraphs[0][1] != (- 1))\n    assert (subgraphs[0][2] != (- 1))\n    _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraphs[0]), n_size)\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraphs[0]), n_size)\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n = 99\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == '???')\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n        _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraph), n_size)\n    n = 17\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])", "ground_truth": "expected_bfw_size(n_size)", "quality_analysis": {"complexity_score": 8, "left_complexity": 4, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_245", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_directed_walk_generation_single_root_node", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_directed_walk_generation_single_root_node(self, tree_graph):\n\n    def _check_directed_walk(walk, n_size):\n        if ((len(n_size) > 1) and (n_size[0] > 0) and (n_size[1] > 0)):\n            for child_pos in range(n_size[0]):\n                child = walk[(child_pos + 1)]\n                grandchildren_start = ((1 + n_size[0]) + (child_pos * n_size[1]))\n                grandchildren_end = (grandchildren_start + n_size[1])\n                grandchildren = walk[grandchildren_start:grandchildren_end]\n                if (child == 'root'):\n                    for grandchild in grandchildren:\n                        assert (grandchild in [0, 1, 2])\n                elif (child == '0'):\n                    for grandchild in grandchildren:\n                        assert (grandchild == 'root')\n                elif (child == 1):\n                    for grandchild in grandchildren:\n                        assert (grandchild in ['c1.1', 'root'])\n                elif (child == 2):\n                    for grandchild in grandchildren:\n                        assert (grandchild in ['c2.1', 'c2.2', 'root'])\n                else:\n                    assert (1 == 0)\n    bfw = SampledBreadthFirstWalk(tree_graph)\n    nodes = tree_graph.node_ids_to_ilocs(['root'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == 1)\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    assert (subgraphs[0][1] != (- 1))\n    assert (subgraphs[0][2] != (- 1))\n    _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraphs[0]), n_size)\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraphs[0]), n_size)\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n = 99\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n        _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraph), n_size)\n    n = 17\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])", "masked_code": "def test_directed_walk_generation_single_root_node(self, tree_graph):\n\n    def _check_directed_walk(walk, n_size):\n        if ((len(n_size) > 1) and (n_size[0] > 0) and (n_size[1] > 0)):\n            for child_pos in range(n_size[0]):\n                child = walk[(child_pos + 1)]\n                grandchildren_start = ((1 + n_size[0]) + (child_pos * n_size[1]))\n                grandchildren_end = (grandchildren_start + n_size[1])\n                grandchildren = walk[grandchildren_start:grandchildren_end]\n                if (child == 'root'):\n                    for grandchild in grandchildren:\n                        assert (grandchild in [0, 1, 2])\n                elif (child == '0'):\n                    for grandchild in grandchildren:\n                        assert (grandchild == 'root')\n                elif (child == 1):\n                    for grandchild in grandchildren:\n                        assert (grandchild in ['c1.1', 'root'])\n                elif (child == 2):\n                    for grandchild in grandchildren:\n                        assert (grandchild in ['c2.1', 'c2.2', 'root'])\n                else:\n                    assert (1 == 0)\n    bfw = SampledBreadthFirstWalk(tree_graph)\n    nodes = tree_graph.node_ids_to_ilocs(['root'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == 1)\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    assert (subgraphs[0][1] != (- 1))\n    assert (subgraphs[0][2] != (- 1))\n    _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraphs[0]), n_size)\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraphs[0]), n_size)\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n = 99\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == '???')\n        _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraph), n_size)\n    n = 17\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])", "ground_truth": "tree_graph.node_ids_to_ilocs(['root'])[0]", "quality_analysis": {"complexity_score": 15, "left_complexity": 5, "right_complexity": 10, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_246", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_directed_walk_generation_single_root_node", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_directed_walk_generation_single_root_node(self, tree_graph):\n\n    def _check_directed_walk(walk, n_size):\n        if ((len(n_size) > 1) and (n_size[0] > 0) and (n_size[1] > 0)):\n            for child_pos in range(n_size[0]):\n                child = walk[(child_pos + 1)]\n                grandchildren_start = ((1 + n_size[0]) + (child_pos * n_size[1]))\n                grandchildren_end = (grandchildren_start + n_size[1])\n                grandchildren = walk[grandchildren_start:grandchildren_end]\n                if (child == 'root'):\n                    for grandchild in grandchildren:\n                        assert (grandchild in [0, 1, 2])\n                elif (child == '0'):\n                    for grandchild in grandchildren:\n                        assert (grandchild == 'root')\n                elif (child == 1):\n                    for grandchild in grandchildren:\n                        assert (grandchild in ['c1.1', 'root'])\n                elif (child == 2):\n                    for grandchild in grandchildren:\n                        assert (grandchild in ['c2.1', 'c2.2', 'root'])\n                else:\n                    assert (1 == 0)\n    bfw = SampledBreadthFirstWalk(tree_graph)\n    nodes = tree_graph.node_ids_to_ilocs(['root'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == 1)\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    assert (subgraphs[0][1] != (- 1))\n    assert (subgraphs[0][2] != (- 1))\n    _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraphs[0]), n_size)\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraphs[0]), n_size)\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n = 99\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n        _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraph), n_size)\n    n = 17\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])", "masked_code": "def test_directed_walk_generation_single_root_node(self, tree_graph):\n\n    def _check_directed_walk(walk, n_size):\n        if ((len(n_size) > 1) and (n_size[0] > 0) and (n_size[1] > 0)):\n            for child_pos in range(n_size[0]):\n                child = walk[(child_pos + 1)]\n                grandchildren_start = ((1 + n_size[0]) + (child_pos * n_size[1]))\n                grandchildren_end = (grandchildren_start + n_size[1])\n                grandchildren = walk[grandchildren_start:grandchildren_end]\n                if (child == 'root'):\n                    for grandchild in grandchildren:\n                        assert (grandchild in [0, 1, 2])\n                elif (child == '0'):\n                    for grandchild in grandchildren:\n                        assert (grandchild == 'root')\n                elif (child == 1):\n                    for grandchild in grandchildren:\n                        assert (grandchild in ['c1.1', 'root'])\n                elif (child == 2):\n                    for grandchild in grandchildren:\n                        assert (grandchild in ['c2.1', 'c2.2', 'root'])\n                else:\n                    assert (1 == 0)\n    bfw = SampledBreadthFirstWalk(tree_graph)\n    nodes = tree_graph.node_ids_to_ilocs(['root'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == 1)\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    assert (subgraphs[0][1] != (- 1))\n    assert (subgraphs[0][2] != (- 1))\n    _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraphs[0]), n_size)\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraphs[0]), n_size)\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n = 99\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n        _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraph), n_size)\n    n = 17\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == '???')\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])", "ground_truth": "expected_bfw_size(n_size)", "quality_analysis": {"complexity_score": 8, "left_complexity": 4, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_247", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_directed_walk_generation_single_root_node", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_directed_walk_generation_single_root_node(self, tree_graph):\n\n    def _check_directed_walk(walk, n_size):\n        if ((len(n_size) > 1) and (n_size[0] > 0) and (n_size[1] > 0)):\n            for child_pos in range(n_size[0]):\n                child = walk[(child_pos + 1)]\n                grandchildren_start = ((1 + n_size[0]) + (child_pos * n_size[1]))\n                grandchildren_end = (grandchildren_start + n_size[1])\n                grandchildren = walk[grandchildren_start:grandchildren_end]\n                if (child == 'root'):\n                    for grandchild in grandchildren:\n                        assert (grandchild in [0, 1, 2])\n                elif (child == '0'):\n                    for grandchild in grandchildren:\n                        assert (grandchild == 'root')\n                elif (child == 1):\n                    for grandchild in grandchildren:\n                        assert (grandchild in ['c1.1', 'root'])\n                elif (child == 2):\n                    for grandchild in grandchildren:\n                        assert (grandchild in ['c2.1', 'c2.2', 'root'])\n                else:\n                    assert (1 == 0)\n    bfw = SampledBreadthFirstWalk(tree_graph)\n    nodes = tree_graph.node_ids_to_ilocs(['root'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == 1)\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    assert (subgraphs[0][1] != (- 1))\n    assert (subgraphs[0][2] != (- 1))\n    _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraphs[0]), n_size)\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraphs[0]), n_size)\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n = 99\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n        _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraph), n_size)\n    n = 17\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])", "masked_code": "def test_directed_walk_generation_single_root_node(self, tree_graph):\n\n    def _check_directed_walk(walk, n_size):\n        if ((len(n_size) > 1) and (n_size[0] > 0) and (n_size[1] > 0)):\n            for child_pos in range(n_size[0]):\n                child = walk[(child_pos + 1)]\n                grandchildren_start = ((1 + n_size[0]) + (child_pos * n_size[1]))\n                grandchildren_end = (grandchildren_start + n_size[1])\n                grandchildren = walk[grandchildren_start:grandchildren_end]\n                if (child == 'root'):\n                    for grandchild in grandchildren:\n                        assert (grandchild in [0, 1, 2])\n                elif (child == '0'):\n                    for grandchild in grandchildren:\n                        assert (grandchild == 'root')\n                elif (child == 1):\n                    for grandchild in grandchildren:\n                        assert (grandchild in ['c1.1', 'root'])\n                elif (child == 2):\n                    for grandchild in grandchildren:\n                        assert (grandchild in ['c2.1', 'c2.2', 'root'])\n                else:\n                    assert (1 == 0)\n    bfw = SampledBreadthFirstWalk(tree_graph)\n    nodes = tree_graph.node_ids_to_ilocs(['root'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == 1)\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    assert (subgraphs[0][1] != (- 1))\n    assert (subgraphs[0][2] != (- 1))\n    _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraphs[0]), n_size)\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size))\n    assert (subgraphs[0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraphs[0]), n_size)\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    n = 99\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n        _check_directed_walk(tree_graph.node_ilocs_to_ids(subgraph), n_size)\n    n = 17\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size))\n        assert (subgraph[0] == '???')", "ground_truth": "tree_graph.node_ids_to_ilocs(['root'])[0]", "quality_analysis": {"complexity_score": 15, "left_complexity": 5, "right_complexity": 10, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_248", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_walk_generation_single_root_node_self_loner", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_walk_generation_single_root_node_self_loner(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['self loner'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))", "masked_code": "def test_walk_generation_single_root_node_self_loner(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['self loner'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == '???')\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))", "ground_truth": "expected_bfw_size(n_size=n_size)", "quality_analysis": {"complexity_score": 11, "left_complexity": 8, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_249", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_walk_generation_single_root_node_self_loner", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_walk_generation_single_root_node_self_loner(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['self loner'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))", "masked_code": "def test_walk_generation_single_root_node_self_loner(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['self loner'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == '???')\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))", "ground_truth": "expected_bfw_size(n_size=n_size)", "quality_analysis": {"complexity_score": 11, "left_complexity": 8, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_250", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_walk_generation_single_root_node_self_loner", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_walk_generation_single_root_node_self_loner(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['self loner'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))", "masked_code": "def test_walk_generation_single_root_node_self_loner(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['self loner'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == '???')\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))", "ground_truth": "expected_bfw_size(n_size=n_size)", "quality_analysis": {"complexity_score": 11, "left_complexity": 8, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_251", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_walk_generation_single_root_node_self_loner", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_walk_generation_single_root_node_self_loner(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['self loner'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))", "masked_code": "def test_walk_generation_single_root_node_self_loner(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['self loner'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == '???')\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))", "ground_truth": "expected_bfw_size(n_size=n_size)", "quality_analysis": {"complexity_score": 11, "left_complexity": 8, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_252", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_walk_generation_single_root_node_self_loner", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_walk_generation_single_root_node_self_loner(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['self loner'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))", "masked_code": "def test_walk_generation_single_root_node_self_loner(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['self loner'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == '???')\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))", "ground_truth": "(n * len(nodes))", "quality_analysis": {"complexity_score": 11, "left_complexity": 4, "right_complexity": 7, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_253", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_walk_generation_single_root_node_self_loner", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_walk_generation_single_root_node_self_loner(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['self loner'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))", "masked_code": "def test_walk_generation_single_root_node_self_loner(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['self loner'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    assert (len(subgraphs[0]) == '???')\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))", "ground_truth": "expected_bfw_size(n_size=n_size)", "quality_analysis": {"complexity_score": 11, "left_complexity": 8, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_254", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_walk_generation_single_root_node_self_loner", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_walk_generation_single_root_node_self_loner(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['self loner'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))", "masked_code": "def test_walk_generation_single_root_node_self_loner(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['self loner'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == '???')\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))", "ground_truth": "(n * len(nodes))", "quality_analysis": {"complexity_score": 11, "left_complexity": 4, "right_complexity": 7, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_255", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_walk_generation_single_root_node_self_loner", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_walk_generation_single_root_node_self_loner(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['self loner'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))", "masked_code": "def test_walk_generation_single_root_node_self_loner(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['self loner'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    assert (len(subgraphs[0]) == '???')\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))", "ground_truth": "expected_bfw_size(n_size=n_size)", "quality_analysis": {"complexity_score": 11, "left_complexity": 8, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_256", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_walk_generation_single_root_node_self_loner", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_walk_generation_single_root_node_self_loner(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['self loner'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))", "masked_code": "def test_walk_generation_single_root_node_self_loner(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['self loner'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == '???')\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))", "ground_truth": "(n * len(nodes))", "quality_analysis": {"complexity_score": 11, "left_complexity": 4, "right_complexity": 7, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_257", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_walk_generation_single_root_node_self_loner", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_walk_generation_single_root_node_self_loner(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['self loner'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))", "masked_code": "def test_walk_generation_single_root_node_self_loner(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['self loner'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    assert (len(subgraphs[0]) == '???')\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))", "ground_truth": "expected_bfw_size(n_size=n_size)", "quality_analysis": {"complexity_score": 11, "left_complexity": 8, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_258", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_walk_generation_single_root_node_self_loner", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_walk_generation_single_root_node_self_loner(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['self loner'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))", "masked_code": "def test_walk_generation_single_root_node_self_loner(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['self loner'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == '???')\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))", "ground_truth": "(n * len(nodes))", "quality_analysis": {"complexity_score": 11, "left_complexity": 4, "right_complexity": 7, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_259", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_walk_generation_single_root_node_self_loner", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_walk_generation_single_root_node_self_loner(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['self loner'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))", "masked_code": "def test_walk_generation_single_root_node_self_loner(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['self loner'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n = 3\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))\n    n_size = [3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    assert (len(subgraphs[0]) == '???')\n    assert (len(set(subgraphs[0])) == 1)\n    assert (nodes[0] in set(subgraphs[0]))", "ground_truth": "expected_bfw_size(n_size=n_size)", "quality_analysis": {"complexity_score": 11, "left_complexity": 8, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_260", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_walk_generation_single_root_node", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_walk_generation_single_root_node(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['0'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))\n    n_size = [1, 1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))\n    n_size = [2, 2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))\n    n_size = [2, 3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))", "masked_code": "def test_walk_generation_single_root_node(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['0'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == '???')\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))\n    n_size = [1, 1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))\n    n_size = [2, 2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))\n    n_size = [2, 3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))", "ground_truth": "expected_bfw_size(n_size=n_size)", "quality_analysis": {"complexity_score": 11, "left_complexity": 8, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_261", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_walk_generation_single_root_node", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_walk_generation_single_root_node(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['0'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))\n    n_size = [1, 1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))\n    n_size = [2, 2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))\n    n_size = [2, 3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))", "masked_code": "def test_walk_generation_single_root_node(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['0'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == '???')\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))\n    n_size = [1, 1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))\n    n_size = [2, 2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))\n    n_size = [2, 3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))", "ground_truth": "((len(nodes) * n) * expected_bfw_size(n_size=n_size))", "quality_analysis": {"complexity_score": 20, "left_complexity": 8, "right_complexity": 12, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_262", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_walk_generation_single_root_node", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_walk_generation_single_root_node(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['0'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))\n    n_size = [1, 1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))\n    n_size = [2, 2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))\n    n_size = [2, 3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))", "masked_code": "def test_walk_generation_single_root_node(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['0'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == '???')\n    n_size = [1, 1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))\n    n_size = [2, 2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))\n    n_size = [2, 3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))", "ground_truth": "((len(nodes) * n) * expected_bfw_size(n_size=n_size))", "quality_analysis": {"complexity_score": 20, "left_complexity": 8, "right_complexity": 12, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_263", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_walk_generation_single_root_node", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_walk_generation_single_root_node(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['0'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))\n    n_size = [1, 1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))\n    n_size = [2, 2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))\n    n_size = [2, 3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))", "masked_code": "def test_walk_generation_single_root_node(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['0'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))\n    n_size = [1, 1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == '???')\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))\n    n_size = [2, 2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))\n    n_size = [2, 3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))", "ground_truth": "((len(nodes) * n) * expected_bfw_size(n_size=n_size))", "quality_analysis": {"complexity_score": 20, "left_complexity": 8, "right_complexity": 12, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_264", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_walk_generation_single_root_node", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_walk_generation_single_root_node(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['0'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))\n    n_size = [1, 1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))\n    n_size = [2, 2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))\n    n_size = [2, 3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))", "masked_code": "def test_walk_generation_single_root_node(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['0'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))\n    n_size = [1, 1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == '???')\n    n_size = [2, 2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))\n    n_size = [2, 3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))", "ground_truth": "((len(nodes) * n) * expected_bfw_size(n_size=n_size))", "quality_analysis": {"complexity_score": 20, "left_complexity": 8, "right_complexity": 12, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_265", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_walk_generation_single_root_node", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_walk_generation_single_root_node(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['0'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))\n    n_size = [1, 1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))\n    n_size = [2, 2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))\n    n_size = [2, 3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))", "masked_code": "def test_walk_generation_single_root_node(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['0'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))\n    n_size = [1, 1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))\n    n_size = [2, 2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == '???')\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))\n    n_size = [2, 3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))", "ground_truth": "((len(nodes) * n) * expected_bfw_size(n_size=n_size))", "quality_analysis": {"complexity_score": 20, "left_complexity": 8, "right_complexity": 12, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_266", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_walk_generation_single_root_node", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_walk_generation_single_root_node(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['0'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))\n    n_size = [1, 1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))\n    n_size = [2, 2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))\n    n_size = [2, 3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))", "masked_code": "def test_walk_generation_single_root_node(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['0'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))\n    n_size = [1, 1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))\n    n_size = [2, 2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == '???')\n    n_size = [2, 3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))", "ground_truth": "((len(nodes) * n) * expected_bfw_size(n_size=n_size))", "quality_analysis": {"complexity_score": 20, "left_complexity": 8, "right_complexity": 12, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_267", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_walk_generation_single_root_node", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_walk_generation_single_root_node(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['0'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))\n    n_size = [1, 1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))\n    n_size = [2, 2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))\n    n_size = [2, 3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))", "masked_code": "def test_walk_generation_single_root_node(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['0'])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))\n    n_size = [1, 1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))\n    n_size = [2, 2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == ((len(nodes) * n) * expected_bfw_size(n_size=n_size)))\n    n_size = [2, 3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs[0]) == '???')", "ground_truth": "((len(nodes) * n) * expected_bfw_size(n_size=n_size))", "quality_analysis": {"complexity_score": 20, "left_complexity": 8, "right_complexity": 12, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_268", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_walk_generation_many_root_nodes", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['0', 2])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == nodes[i])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [1, 1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))", "masked_code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['0', 2])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == '???')\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == nodes[i])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [1, 1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))", "ground_truth": "(len(nodes) * n)", "quality_analysis": {"complexity_score": 11, "left_complexity": 4, "right_complexity": 7, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_269", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_walk_generation_many_root_nodes", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['0', 2])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == nodes[i])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [1, 1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))", "masked_code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['0', 2])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == nodes[i])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == '???')\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [1, 1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))", "ground_truth": "(len(nodes) * n)", "quality_analysis": {"complexity_score": 11, "left_complexity": 4, "right_complexity": 7, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_270", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_walk_generation_many_root_nodes", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['0', 2])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == nodes[i])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [1, 1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))", "masked_code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['0', 2])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == nodes[i])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == '???')\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [1, 1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))", "ground_truth": "(len(nodes) * n)", "quality_analysis": {"complexity_score": 11, "left_complexity": 4, "right_complexity": 7, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_271", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_walk_generation_many_root_nodes", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['0', 2])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == nodes[i])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [1, 1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))", "masked_code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['0', 2])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == nodes[i])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == '???')\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [1, 1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))", "ground_truth": "(len(nodes) * n)", "quality_analysis": {"complexity_score": 11, "left_complexity": 4, "right_complexity": 7, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_272", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_walk_generation_many_root_nodes", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['0', 2])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == nodes[i])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [1, 1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))", "masked_code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['0', 2])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == nodes[i])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [1, 1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == '???')\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))", "ground_truth": "(len(nodes) * n)", "quality_analysis": {"complexity_score": 11, "left_complexity": 4, "right_complexity": 7, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_273", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_walk_generation_many_root_nodes", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['0', 2])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == nodes[i])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [1, 1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))", "masked_code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['0', 2])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == nodes[i])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [1, 1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == '???')\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))", "ground_truth": "(len(nodes) * n)", "quality_analysis": {"complexity_score": 11, "left_complexity": 4, "right_complexity": 7, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_274", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_walk_generation_many_root_nodes", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['0', 2])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == nodes[i])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [1, 1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))", "masked_code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['0', 2])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == nodes[i])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [1, 1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == '???')\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))", "ground_truth": "(len(nodes) * n)", "quality_analysis": {"complexity_score": 11, "left_complexity": 4, "right_complexity": 7, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_275", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_walk_generation_many_root_nodes", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['0', 2])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == nodes[i])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [1, 1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))", "masked_code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['0', 2])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == nodes[i])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [1, 1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == '???')\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))", "ground_truth": "(len(nodes) * n)", "quality_analysis": {"complexity_score": 11, "left_complexity": 4, "right_complexity": 7, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_276", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_walk_generation_many_root_nodes", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['0', 2])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == nodes[i])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [1, 1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))", "masked_code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['0', 2])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == nodes[i])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [1, 1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == '???')\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))", "ground_truth": "(len(nodes) * n)", "quality_analysis": {"complexity_score": 11, "left_complexity": 4, "right_complexity": 7, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_277", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_walk_generation_many_root_nodes", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['0', 2])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == nodes[i])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [1, 1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))", "masked_code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['0', 2])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == '???')\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [1, 1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))", "ground_truth": "nodes[i]", "quality_analysis": {"complexity_score": 10, "left_complexity": 5, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_278", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_walk_generation_many_root_nodes", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['0', 2])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == nodes[i])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [1, 1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))", "masked_code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['0', 2])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == nodes[i])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == '???')\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [1, 1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))", "ground_truth": "expected_bfw_size(n_size=n_size)", "quality_analysis": {"complexity_score": 7, "left_complexity": 4, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_279", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_walk_generation_many_root_nodes", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['0', 2])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == nodes[i])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [1, 1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))", "masked_code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['0', 2])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == nodes[i])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == '???')\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [1, 1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))", "ground_truth": "expected_bfw_size(n_size=n_size)", "quality_analysis": {"complexity_score": 7, "left_complexity": 4, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_280", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_walk_generation_many_root_nodes", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['0', 2])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == nodes[i])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [1, 1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))", "masked_code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['0', 2])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == nodes[i])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == '???')\n    n_size = [1, 1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))", "ground_truth": "expected_bfw_size(n_size=n_size)", "quality_analysis": {"complexity_score": 7, "left_complexity": 4, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_281", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_walk_generation_many_root_nodes", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['0', 2])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == nodes[i])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [1, 1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))", "masked_code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['0', 2])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == nodes[i])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [1, 1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == '???')\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))", "ground_truth": "expected_bfw_size(n_size=n_size)", "quality_analysis": {"complexity_score": 7, "left_complexity": 4, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_282", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_walk_generation_many_root_nodes", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['0', 2])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == nodes[i])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [1, 1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))", "masked_code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['0', 2])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == nodes[i])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [1, 1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == '???')\n    n_size = [3, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))", "ground_truth": "expected_bfw_size(n_size=n_size)", "quality_analysis": {"complexity_score": 7, "left_complexity": 4, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_283", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_walk_generation_many_root_nodes", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['0', 2])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == nodes[i])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [1, 1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))", "masked_code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['0', 2])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == nodes[i])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [1, 1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == '???')\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))", "ground_truth": "expected_bfw_size(n_size=n_size)", "quality_analysis": {"complexity_score": 7, "left_complexity": 4, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_284", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_walk_generation_many_root_nodes", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['0', 2])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == nodes[i])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [1, 1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))", "masked_code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['0', 2])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == nodes[i])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [1, 1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == '???')\n    n_size = [2, 3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))", "ground_truth": "expected_bfw_size(n_size=n_size)", "quality_analysis": {"complexity_score": 7, "left_complexity": 4, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_285", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_walk_generation_many_root_nodes", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['0', 2])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == nodes[i])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [1, 1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))", "masked_code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs(['0', 2])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 1)\n        assert (subgraph[0] == nodes[i])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [1, 1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2, 3, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == '???')", "ground_truth": "expected_bfw_size(n_size=n_size)", "quality_analysis": {"complexity_score": 7, "left_complexity": 4, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_286", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_walk_generation_number_of_walks_per_root_nodes", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_walk_generation_number_of_walks_per_root_nodes(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = [1]\n    n = 2\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n        assert (subgraph[0] == nodes[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    nodes = [1, 5]\n    n_size = [1]\n    n = 2\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    nodes = [1, 5]\n    n_size = [2, 2]\n    n = 3\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [4, 4]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))", "masked_code": "def test_walk_generation_number_of_walks_per_root_nodes(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = [1]\n    n = 2\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == '???')\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n        assert (subgraph[0] == nodes[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    nodes = [1, 5]\n    n_size = [1]\n    n = 2\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    nodes = [1, 5]\n    n_size = [2, 2]\n    n = 3\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [4, 4]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))", "ground_truth": "(len(nodes) * n)", "quality_analysis": {"complexity_score": 11, "left_complexity": 4, "right_complexity": 7, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_287", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_walk_generation_number_of_walks_per_root_nodes", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_walk_generation_number_of_walks_per_root_nodes(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = [1]\n    n = 2\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n        assert (subgraph[0] == nodes[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    nodes = [1, 5]\n    n_size = [1]\n    n = 2\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    nodes = [1, 5]\n    n_size = [2, 2]\n    n = 3\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [4, 4]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))", "masked_code": "def test_walk_generation_number_of_walks_per_root_nodes(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = [1]\n    n = 2\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n        assert (subgraph[0] == nodes[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == '???')\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    nodes = [1, 5]\n    n_size = [1]\n    n = 2\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    nodes = [1, 5]\n    n_size = [2, 2]\n    n = 3\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [4, 4]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))", "ground_truth": "(len(nodes) * n)", "quality_analysis": {"complexity_score": 11, "left_complexity": 4, "right_complexity": 7, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_288", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_walk_generation_number_of_walks_per_root_nodes", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_walk_generation_number_of_walks_per_root_nodes(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = [1]\n    n = 2\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n        assert (subgraph[0] == nodes[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    nodes = [1, 5]\n    n_size = [1]\n    n = 2\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    nodes = [1, 5]\n    n_size = [2, 2]\n    n = 3\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [4, 4]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))", "masked_code": "def test_walk_generation_number_of_walks_per_root_nodes(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = [1]\n    n = 2\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n        assert (subgraph[0] == nodes[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == '???')\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    nodes = [1, 5]\n    n_size = [1]\n    n = 2\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    nodes = [1, 5]\n    n_size = [2, 2]\n    n = 3\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [4, 4]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))", "ground_truth": "(len(nodes) * n)", "quality_analysis": {"complexity_score": 11, "left_complexity": 4, "right_complexity": 7, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_289", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_walk_generation_number_of_walks_per_root_nodes", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_walk_generation_number_of_walks_per_root_nodes(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = [1]\n    n = 2\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n        assert (subgraph[0] == nodes[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    nodes = [1, 5]\n    n_size = [1]\n    n = 2\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    nodes = [1, 5]\n    n_size = [2, 2]\n    n = 3\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [4, 4]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))", "masked_code": "def test_walk_generation_number_of_walks_per_root_nodes(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = [1]\n    n = 2\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n        assert (subgraph[0] == nodes[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == '???')\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    nodes = [1, 5]\n    n_size = [1]\n    n = 2\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    nodes = [1, 5]\n    n_size = [2, 2]\n    n = 3\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [4, 4]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))", "ground_truth": "(len(nodes) * n)", "quality_analysis": {"complexity_score": 11, "left_complexity": 4, "right_complexity": 7, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_290", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_walk_generation_number_of_walks_per_root_nodes", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_walk_generation_number_of_walks_per_root_nodes(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = [1]\n    n = 2\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n        assert (subgraph[0] == nodes[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    nodes = [1, 5]\n    n_size = [1]\n    n = 2\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    nodes = [1, 5]\n    n_size = [2, 2]\n    n = 3\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [4, 4]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))", "masked_code": "def test_walk_generation_number_of_walks_per_root_nodes(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = [1]\n    n = 2\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n        assert (subgraph[0] == nodes[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    nodes = [1, 5]\n    n_size = [1]\n    n = 2\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == '???')\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    nodes = [1, 5]\n    n_size = [2, 2]\n    n = 3\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [4, 4]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))", "ground_truth": "(n * len(nodes))", "quality_analysis": {"complexity_score": 11, "left_complexity": 4, "right_complexity": 7, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_291", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_walk_generation_number_of_walks_per_root_nodes", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_walk_generation_number_of_walks_per_root_nodes(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = [1]\n    n = 2\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n        assert (subgraph[0] == nodes[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    nodes = [1, 5]\n    n_size = [1]\n    n = 2\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    nodes = [1, 5]\n    n_size = [2, 2]\n    n = 3\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [4, 4]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))", "masked_code": "def test_walk_generation_number_of_walks_per_root_nodes(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = [1]\n    n = 2\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n        assert (subgraph[0] == nodes[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    nodes = [1, 5]\n    n_size = [1]\n    n = 2\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == '???')\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    nodes = [1, 5]\n    n_size = [2, 2]\n    n = 3\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [4, 4]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))", "ground_truth": "(n * len(nodes))", "quality_analysis": {"complexity_score": 11, "left_complexity": 4, "right_complexity": 7, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_292", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_walk_generation_number_of_walks_per_root_nodes", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_walk_generation_number_of_walks_per_root_nodes(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = [1]\n    n = 2\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n        assert (subgraph[0] == nodes[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    nodes = [1, 5]\n    n_size = [1]\n    n = 2\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    nodes = [1, 5]\n    n_size = [2, 2]\n    n = 3\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [4, 4]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))", "masked_code": "def test_walk_generation_number_of_walks_per_root_nodes(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = [1]\n    n = 2\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n        assert (subgraph[0] == nodes[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    nodes = [1, 5]\n    n_size = [1]\n    n = 2\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == '???')\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    nodes = [1, 5]\n    n_size = [2, 2]\n    n = 3\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [4, 4]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))", "ground_truth": "(n * len(nodes))", "quality_analysis": {"complexity_score": 11, "left_complexity": 4, "right_complexity": 7, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_293", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_walk_generation_number_of_walks_per_root_nodes", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_walk_generation_number_of_walks_per_root_nodes(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = [1]\n    n = 2\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n        assert (subgraph[0] == nodes[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    nodes = [1, 5]\n    n_size = [1]\n    n = 2\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    nodes = [1, 5]\n    n_size = [2, 2]\n    n = 3\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [4, 4]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))", "masked_code": "def test_walk_generation_number_of_walks_per_root_nodes(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = [1]\n    n = 2\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n        assert (subgraph[0] == nodes[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    nodes = [1, 5]\n    n_size = [1]\n    n = 2\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    nodes = [1, 5]\n    n_size = [2, 2]\n    n = 3\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == '???')\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [4, 4]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))", "ground_truth": "(n * len(nodes))", "quality_analysis": {"complexity_score": 11, "left_complexity": 4, "right_complexity": 7, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_294", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_walk_generation_number_of_walks_per_root_nodes", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_walk_generation_number_of_walks_per_root_nodes(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = [1]\n    n = 2\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n        assert (subgraph[0] == nodes[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    nodes = [1, 5]\n    n_size = [1]\n    n = 2\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    nodes = [1, 5]\n    n_size = [2, 2]\n    n = 3\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [4, 4]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))", "masked_code": "def test_walk_generation_number_of_walks_per_root_nodes(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = [1]\n    n = 2\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n        assert (subgraph[0] == nodes[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    nodes = [1, 5]\n    n_size = [1]\n    n = 2\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    nodes = [1, 5]\n    n_size = [2, 2]\n    n = 3\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == '???')\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [4, 4]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))", "ground_truth": "(n * len(nodes))", "quality_analysis": {"complexity_score": 11, "left_complexity": 4, "right_complexity": 7, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_295", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_walk_generation_number_of_walks_per_root_nodes", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_walk_generation_number_of_walks_per_root_nodes(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = [1]\n    n = 2\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n        assert (subgraph[0] == nodes[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    nodes = [1, 5]\n    n_size = [1]\n    n = 2\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    nodes = [1, 5]\n    n_size = [2, 2]\n    n = 3\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [4, 4]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))", "masked_code": "def test_walk_generation_number_of_walks_per_root_nodes(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = [1]\n    n = 2\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n        assert (subgraph[0] == nodes[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    nodes = [1, 5]\n    n_size = [1]\n    n = 2\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    nodes = [1, 5]\n    n_size = [2, 2]\n    n = 3\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [4, 4]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == '???')\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))", "ground_truth": "(n * len(nodes))", "quality_analysis": {"complexity_score": 11, "left_complexity": 4, "right_complexity": 7, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_296", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_walk_generation_number_of_walks_per_root_nodes", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_walk_generation_number_of_walks_per_root_nodes(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = [1]\n    n = 2\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n        assert (subgraph[0] == nodes[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    nodes = [1, 5]\n    n_size = [1]\n    n = 2\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    nodes = [1, 5]\n    n_size = [2, 2]\n    n = 3\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [4, 4]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))", "masked_code": "def test_walk_generation_number_of_walks_per_root_nodes(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = [1]\n    n = 2\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == '???')\n        assert (subgraph[0] == nodes[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    nodes = [1, 5]\n    n_size = [1]\n    n = 2\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    nodes = [1, 5]\n    n_size = [2, 2]\n    n = 3\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [4, 4]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))", "ground_truth": "expected_bfw_size(n_size=n_size)", "quality_analysis": {"complexity_score": 7, "left_complexity": 4, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_297", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_walk_generation_number_of_walks_per_root_nodes", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_walk_generation_number_of_walks_per_root_nodes(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = [1]\n    n = 2\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n        assert (subgraph[0] == nodes[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    nodes = [1, 5]\n    n_size = [1]\n    n = 2\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    nodes = [1, 5]\n    n_size = [2, 2]\n    n = 3\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [4, 4]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))", "masked_code": "def test_walk_generation_number_of_walks_per_root_nodes(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = [1]\n    n = 2\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n        assert (subgraph[0] == '???')\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    nodes = [1, 5]\n    n_size = [1]\n    n = 2\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    nodes = [1, 5]\n    n_size = [2, 2]\n    n = 3\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [4, 4]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))", "ground_truth": "nodes[0]", "quality_analysis": {"complexity_score": 10, "left_complexity": 5, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_298", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_walk_generation_number_of_walks_per_root_nodes", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_walk_generation_number_of_walks_per_root_nodes(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = [1]\n    n = 2\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n        assert (subgraph[0] == nodes[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    nodes = [1, 5]\n    n_size = [1]\n    n = 2\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    nodes = [1, 5]\n    n_size = [2, 2]\n    n = 3\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [4, 4]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))", "masked_code": "def test_walk_generation_number_of_walks_per_root_nodes(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = [1]\n    n = 2\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n        assert (subgraph[0] == nodes[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == '???')\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    nodes = [1, 5]\n    n_size = [1]\n    n = 2\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    nodes = [1, 5]\n    n_size = [2, 2]\n    n = 3\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [4, 4]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))", "ground_truth": "expected_bfw_size(n_size=n_size)", "quality_analysis": {"complexity_score": 7, "left_complexity": 4, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_299", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_walk_generation_number_of_walks_per_root_nodes", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_walk_generation_number_of_walks_per_root_nodes(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = [1]\n    n = 2\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n        assert (subgraph[0] == nodes[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    nodes = [1, 5]\n    n_size = [1]\n    n = 2\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    nodes = [1, 5]\n    n_size = [2, 2]\n    n = 3\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [4, 4]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))", "masked_code": "def test_walk_generation_number_of_walks_per_root_nodes(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = [1]\n    n = 2\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n        assert (subgraph[0] == nodes[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == '???')\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    nodes = [1, 5]\n    n_size = [1]\n    n = 2\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    nodes = [1, 5]\n    n_size = [2, 2]\n    n = 3\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [4, 4]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))", "ground_truth": "expected_bfw_size(n_size=n_size)", "quality_analysis": {"complexity_score": 7, "left_complexity": 4, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_300", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_walk_generation_number_of_walks_per_root_nodes", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_walk_generation_number_of_walks_per_root_nodes(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = [1]\n    n = 2\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n        assert (subgraph[0] == nodes[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    nodes = [1, 5]\n    n_size = [1]\n    n = 2\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    nodes = [1, 5]\n    n_size = [2, 2]\n    n = 3\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [4, 4]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))", "masked_code": "def test_walk_generation_number_of_walks_per_root_nodes(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = [1]\n    n = 2\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n        assert (subgraph[0] == nodes[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == '???')\n    nodes = [1, 5]\n    n_size = [1]\n    n = 2\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    nodes = [1, 5]\n    n_size = [2, 2]\n    n = 3\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [4, 4]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))", "ground_truth": "expected_bfw_size(n_size=n_size)", "quality_analysis": {"complexity_score": 7, "left_complexity": 4, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_301", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_walk_generation_number_of_walks_per_root_nodes", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_walk_generation_number_of_walks_per_root_nodes(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = [1]\n    n = 2\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n        assert (subgraph[0] == nodes[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    nodes = [1, 5]\n    n_size = [1]\n    n = 2\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    nodes = [1, 5]\n    n_size = [2, 2]\n    n = 3\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [4, 4]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))", "masked_code": "def test_walk_generation_number_of_walks_per_root_nodes(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = [1]\n    n = 2\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n        assert (subgraph[0] == nodes[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    nodes = [1, 5]\n    n_size = [1]\n    n = 2\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == '???')\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    nodes = [1, 5]\n    n_size = [2, 2]\n    n = 3\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [4, 4]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))", "ground_truth": "expected_bfw_size(n_size=n_size)", "quality_analysis": {"complexity_score": 7, "left_complexity": 4, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_302", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_walk_generation_number_of_walks_per_root_nodes", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_walk_generation_number_of_walks_per_root_nodes(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = [1]\n    n = 2\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n        assert (subgraph[0] == nodes[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    nodes = [1, 5]\n    n_size = [1]\n    n = 2\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    nodes = [1, 5]\n    n_size = [2, 2]\n    n = 3\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [4, 4]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))", "masked_code": "def test_walk_generation_number_of_walks_per_root_nodes(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = [1]\n    n = 2\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n        assert (subgraph[0] == nodes[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    nodes = [1, 5]\n    n_size = [1]\n    n = 2\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == '???')\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    nodes = [1, 5]\n    n_size = [2, 2]\n    n = 3\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [4, 4]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))", "ground_truth": "expected_bfw_size(n_size=n_size)", "quality_analysis": {"complexity_score": 7, "left_complexity": 4, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_303", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_walk_generation_number_of_walks_per_root_nodes", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_walk_generation_number_of_walks_per_root_nodes(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = [1]\n    n = 2\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n        assert (subgraph[0] == nodes[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    nodes = [1, 5]\n    n_size = [1]\n    n = 2\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    nodes = [1, 5]\n    n_size = [2, 2]\n    n = 3\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [4, 4]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))", "masked_code": "def test_walk_generation_number_of_walks_per_root_nodes(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = [1]\n    n = 2\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n        assert (subgraph[0] == nodes[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    nodes = [1, 5]\n    n_size = [1]\n    n = 2\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == '???')\n    nodes = [1, 5]\n    n_size = [2, 2]\n    n = 3\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [4, 4]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))", "ground_truth": "expected_bfw_size(n_size=n_size)", "quality_analysis": {"complexity_score": 7, "left_complexity": 4, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_304", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_walk_generation_number_of_walks_per_root_nodes", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_walk_generation_number_of_walks_per_root_nodes(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = [1]\n    n = 2\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n        assert (subgraph[0] == nodes[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    nodes = [1, 5]\n    n_size = [1]\n    n = 2\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    nodes = [1, 5]\n    n_size = [2, 2]\n    n = 3\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [4, 4]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))", "masked_code": "def test_walk_generation_number_of_walks_per_root_nodes(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = [1]\n    n = 2\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n        assert (subgraph[0] == nodes[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    nodes = [1, 5]\n    n_size = [1]\n    n = 2\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    nodes = [1, 5]\n    n_size = [2, 2]\n    n = 3\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == '???')\n    n_size = [3, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [4, 4]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))", "ground_truth": "expected_bfw_size(n_size=n_size)", "quality_analysis": {"complexity_score": 7, "left_complexity": 4, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_305", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_walk_generation_number_of_walks_per_root_nodes", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_walk_generation_number_of_walks_per_root_nodes(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = [1]\n    n = 2\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n        assert (subgraph[0] == nodes[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    nodes = [1, 5]\n    n_size = [1]\n    n = 2\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    nodes = [1, 5]\n    n_size = [2, 2]\n    n = 3\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [4, 4]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))", "masked_code": "def test_walk_generation_number_of_walks_per_root_nodes(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = [1]\n    n = 2\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n        assert (subgraph[0] == nodes[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    nodes = [1, 5]\n    n_size = [1]\n    n = 2\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    nodes = [1, 5]\n    n_size = [2, 2]\n    n = 3\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == '???')\n    n_size = [4, 4]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))", "ground_truth": "expected_bfw_size(n_size=n_size)", "quality_analysis": {"complexity_score": 7, "left_complexity": 4, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_306", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_walk_generation_number_of_walks_per_root_nodes", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_walk_generation_number_of_walks_per_root_nodes(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = [1]\n    n = 2\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n        assert (subgraph[0] == nodes[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    nodes = [1, 5]\n    n_size = [1]\n    n = 2\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    nodes = [1, 5]\n    n_size = [2, 2]\n    n = 3\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [4, 4]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))", "masked_code": "def test_walk_generation_number_of_walks_per_root_nodes(self):\n    g = create_test_graph()\n    bfw = SampledBreadthFirstWalk(g)\n    nodes = [1]\n    n = 2\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n        assert (subgraph[0] == nodes[0])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    nodes = [1, 5]\n    n_size = [1]\n    n = 2\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    nodes = [1, 5]\n    n_size = [2, 2]\n    n = 3\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [3, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == expected_bfw_size(n_size=n_size))\n    n_size = [4, 4]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) == '???')", "ground_truth": "expected_bfw_size(n_size=n_size)", "quality_analysis": {"complexity_score": 7, "left_complexity": 4, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_307", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_fixed_random_seed", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_fixed_random_seed(self):\n    g = create_test_graph()\n    _conv = g.node_ids_to_ilocs\n    bfw = SampledBreadthFirstWalk(g)\n    w0 = bfw.run(nodes=_conv([1]), n=1, n_size=[7], seed=42)\n    w1 = bfw.run(nodes=_conv([1]), n=1, n_size=[7], seed=1010)\n    assert (len(w0) == len(w1))\n    assert (w0 != w1)\n    w0 = bfw.run(nodes=_conv([1]), n=1, n_size=[7], seed=42)\n    w1 = bfw.run(nodes=_conv([1]), n=1, n_size=[7], seed=42)\n    assert (len(w0) == len(w1))\n    assert (w0 == w1)\n    w0 = bfw.run(nodes=_conv([1]), n=5, n_size=[12], seed=101)\n    w1 = bfw.run(nodes=_conv([1]), n=5, n_size=[12], seed=101)\n    assert (len(w0) == len(w1))\n    assert (w0 == w1)\n    w0 = bfw.run(nodes=_conv([9, 'self loner']), n=1, n_size=[12], seed=101)\n    w1 = bfw.run(nodes=_conv([9, 'self loner']), n=1, n_size=[12], seed=101)\n    assert (len(w0) == len(w1))\n    assert (w0 == w1)\n    w0 = bfw.run(nodes=_conv([1, 'self loner', 4]), n=5, n_size=[12], seed=101)\n    w1 = bfw.run(nodes=_conv([1, 'self loner', 4]), n=5, n_size=[12], seed=101)\n    assert (len(w0) == len(w1))\n    assert (w0 == w1)", "masked_code": "def test_fixed_random_seed(self):\n    g = create_test_graph()\n    _conv = g.node_ids_to_ilocs\n    bfw = SampledBreadthFirstWalk(g)\n    w0 = bfw.run(nodes=_conv([1]), n=1, n_size=[7], seed=42)\n    w1 = bfw.run(nodes=_conv([1]), n=1, n_size=[7], seed=1010)\n    assert (len(w0) == '???')\n    assert (w0 != w1)\n    w0 = bfw.run(nodes=_conv([1]), n=1, n_size=[7], seed=42)\n    w1 = bfw.run(nodes=_conv([1]), n=1, n_size=[7], seed=42)\n    assert (len(w0) == len(w1))\n    assert (w0 == w1)\n    w0 = bfw.run(nodes=_conv([1]), n=5, n_size=[12], seed=101)\n    w1 = bfw.run(nodes=_conv([1]), n=5, n_size=[12], seed=101)\n    assert (len(w0) == len(w1))\n    assert (w0 == w1)\n    w0 = bfw.run(nodes=_conv([9, 'self loner']), n=1, n_size=[12], seed=101)\n    w1 = bfw.run(nodes=_conv([9, 'self loner']), n=1, n_size=[12], seed=101)\n    assert (len(w0) == len(w1))\n    assert (w0 == w1)\n    w0 = bfw.run(nodes=_conv([1, 'self loner', 4]), n=5, n_size=[12], seed=101)\n    w1 = bfw.run(nodes=_conv([1, 'self loner', 4]), n=5, n_size=[12], seed=101)\n    assert (len(w0) == len(w1))\n    assert (w0 == w1)", "ground_truth": "len(w1)", "quality_analysis": {"complexity_score": 8, "left_complexity": 4, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_308", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_fixed_random_seed", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_fixed_random_seed(self):\n    g = create_test_graph()\n    _conv = g.node_ids_to_ilocs\n    bfw = SampledBreadthFirstWalk(g)\n    w0 = bfw.run(nodes=_conv([1]), n=1, n_size=[7], seed=42)\n    w1 = bfw.run(nodes=_conv([1]), n=1, n_size=[7], seed=1010)\n    assert (len(w0) == len(w1))\n    assert (w0 != w1)\n    w0 = bfw.run(nodes=_conv([1]), n=1, n_size=[7], seed=42)\n    w1 = bfw.run(nodes=_conv([1]), n=1, n_size=[7], seed=42)\n    assert (len(w0) == len(w1))\n    assert (w0 == w1)\n    w0 = bfw.run(nodes=_conv([1]), n=5, n_size=[12], seed=101)\n    w1 = bfw.run(nodes=_conv([1]), n=5, n_size=[12], seed=101)\n    assert (len(w0) == len(w1))\n    assert (w0 == w1)\n    w0 = bfw.run(nodes=_conv([9, 'self loner']), n=1, n_size=[12], seed=101)\n    w1 = bfw.run(nodes=_conv([9, 'self loner']), n=1, n_size=[12], seed=101)\n    assert (len(w0) == len(w1))\n    assert (w0 == w1)\n    w0 = bfw.run(nodes=_conv([1, 'self loner', 4]), n=5, n_size=[12], seed=101)\n    w1 = bfw.run(nodes=_conv([1, 'self loner', 4]), n=5, n_size=[12], seed=101)\n    assert (len(w0) == len(w1))\n    assert (w0 == w1)", "masked_code": "def test_fixed_random_seed(self):\n    g = create_test_graph()\n    _conv = g.node_ids_to_ilocs\n    bfw = SampledBreadthFirstWalk(g)\n    w0 = bfw.run(nodes=_conv([1]), n=1, n_size=[7], seed=42)\n    w1 = bfw.run(nodes=_conv([1]), n=1, n_size=[7], seed=1010)\n    assert (len(w0) == len(w1))\n    assert (w0 != w1)\n    w0 = bfw.run(nodes=_conv([1]), n=1, n_size=[7], seed=42)\n    w1 = bfw.run(nodes=_conv([1]), n=1, n_size=[7], seed=42)\n    assert (len(w0) == '???')\n    assert (w0 == w1)\n    w0 = bfw.run(nodes=_conv([1]), n=5, n_size=[12], seed=101)\n    w1 = bfw.run(nodes=_conv([1]), n=5, n_size=[12], seed=101)\n    assert (len(w0) == len(w1))\n    assert (w0 == w1)\n    w0 = bfw.run(nodes=_conv([9, 'self loner']), n=1, n_size=[12], seed=101)\n    w1 = bfw.run(nodes=_conv([9, 'self loner']), n=1, n_size=[12], seed=101)\n    assert (len(w0) == len(w1))\n    assert (w0 == w1)\n    w0 = bfw.run(nodes=_conv([1, 'self loner', 4]), n=5, n_size=[12], seed=101)\n    w1 = bfw.run(nodes=_conv([1, 'self loner', 4]), n=5, n_size=[12], seed=101)\n    assert (len(w0) == len(w1))\n    assert (w0 == w1)", "ground_truth": "len(w1)", "quality_analysis": {"complexity_score": 8, "left_complexity": 4, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_309", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_fixed_random_seed", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_fixed_random_seed(self):\n    g = create_test_graph()\n    _conv = g.node_ids_to_ilocs\n    bfw = SampledBreadthFirstWalk(g)\n    w0 = bfw.run(nodes=_conv([1]), n=1, n_size=[7], seed=42)\n    w1 = bfw.run(nodes=_conv([1]), n=1, n_size=[7], seed=1010)\n    assert (len(w0) == len(w1))\n    assert (w0 != w1)\n    w0 = bfw.run(nodes=_conv([1]), n=1, n_size=[7], seed=42)\n    w1 = bfw.run(nodes=_conv([1]), n=1, n_size=[7], seed=42)\n    assert (len(w0) == len(w1))\n    assert (w0 == w1)\n    w0 = bfw.run(nodes=_conv([1]), n=5, n_size=[12], seed=101)\n    w1 = bfw.run(nodes=_conv([1]), n=5, n_size=[12], seed=101)\n    assert (len(w0) == len(w1))\n    assert (w0 == w1)\n    w0 = bfw.run(nodes=_conv([9, 'self loner']), n=1, n_size=[12], seed=101)\n    w1 = bfw.run(nodes=_conv([9, 'self loner']), n=1, n_size=[12], seed=101)\n    assert (len(w0) == len(w1))\n    assert (w0 == w1)\n    w0 = bfw.run(nodes=_conv([1, 'self loner', 4]), n=5, n_size=[12], seed=101)\n    w1 = bfw.run(nodes=_conv([1, 'self loner', 4]), n=5, n_size=[12], seed=101)\n    assert (len(w0) == len(w1))\n    assert (w0 == w1)", "masked_code": "def test_fixed_random_seed(self):\n    g = create_test_graph()\n    _conv = g.node_ids_to_ilocs\n    bfw = SampledBreadthFirstWalk(g)\n    w0 = bfw.run(nodes=_conv([1]), n=1, n_size=[7], seed=42)\n    w1 = bfw.run(nodes=_conv([1]), n=1, n_size=[7], seed=1010)\n    assert (len(w0) == len(w1))\n    assert (w0 != w1)\n    w0 = bfw.run(nodes=_conv([1]), n=1, n_size=[7], seed=42)\n    w1 = bfw.run(nodes=_conv([1]), n=1, n_size=[7], seed=42)\n    assert (len(w0) == len(w1))\n    assert (w0 == w1)\n    w0 = bfw.run(nodes=_conv([1]), n=5, n_size=[12], seed=101)\n    w1 = bfw.run(nodes=_conv([1]), n=5, n_size=[12], seed=101)\n    assert (len(w0) == '???')\n    assert (w0 == w1)\n    w0 = bfw.run(nodes=_conv([9, 'self loner']), n=1, n_size=[12], seed=101)\n    w1 = bfw.run(nodes=_conv([9, 'self loner']), n=1, n_size=[12], seed=101)\n    assert (len(w0) == len(w1))\n    assert (w0 == w1)\n    w0 = bfw.run(nodes=_conv([1, 'self loner', 4]), n=5, n_size=[12], seed=101)\n    w1 = bfw.run(nodes=_conv([1, 'self loner', 4]), n=5, n_size=[12], seed=101)\n    assert (len(w0) == len(w1))\n    assert (w0 == w1)", "ground_truth": "len(w1)", "quality_analysis": {"complexity_score": 8, "left_complexity": 4, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_310", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_fixed_random_seed", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_fixed_random_seed(self):\n    g = create_test_graph()\n    _conv = g.node_ids_to_ilocs\n    bfw = SampledBreadthFirstWalk(g)\n    w0 = bfw.run(nodes=_conv([1]), n=1, n_size=[7], seed=42)\n    w1 = bfw.run(nodes=_conv([1]), n=1, n_size=[7], seed=1010)\n    assert (len(w0) == len(w1))\n    assert (w0 != w1)\n    w0 = bfw.run(nodes=_conv([1]), n=1, n_size=[7], seed=42)\n    w1 = bfw.run(nodes=_conv([1]), n=1, n_size=[7], seed=42)\n    assert (len(w0) == len(w1))\n    assert (w0 == w1)\n    w0 = bfw.run(nodes=_conv([1]), n=5, n_size=[12], seed=101)\n    w1 = bfw.run(nodes=_conv([1]), n=5, n_size=[12], seed=101)\n    assert (len(w0) == len(w1))\n    assert (w0 == w1)\n    w0 = bfw.run(nodes=_conv([9, 'self loner']), n=1, n_size=[12], seed=101)\n    w1 = bfw.run(nodes=_conv([9, 'self loner']), n=1, n_size=[12], seed=101)\n    assert (len(w0) == len(w1))\n    assert (w0 == w1)\n    w0 = bfw.run(nodes=_conv([1, 'self loner', 4]), n=5, n_size=[12], seed=101)\n    w1 = bfw.run(nodes=_conv([1, 'self loner', 4]), n=5, n_size=[12], seed=101)\n    assert (len(w0) == len(w1))\n    assert (w0 == w1)", "masked_code": "def test_fixed_random_seed(self):\n    g = create_test_graph()\n    _conv = g.node_ids_to_ilocs\n    bfw = SampledBreadthFirstWalk(g)\n    w0 = bfw.run(nodes=_conv([1]), n=1, n_size=[7], seed=42)\n    w1 = bfw.run(nodes=_conv([1]), n=1, n_size=[7], seed=1010)\n    assert (len(w0) == len(w1))\n    assert (w0 != w1)\n    w0 = bfw.run(nodes=_conv([1]), n=1, n_size=[7], seed=42)\n    w1 = bfw.run(nodes=_conv([1]), n=1, n_size=[7], seed=42)\n    assert (len(w0) == len(w1))\n    assert (w0 == w1)\n    w0 = bfw.run(nodes=_conv([1]), n=5, n_size=[12], seed=101)\n    w1 = bfw.run(nodes=_conv([1]), n=5, n_size=[12], seed=101)\n    assert (len(w0) == len(w1))\n    assert (w0 == w1)\n    w0 = bfw.run(nodes=_conv([9, 'self loner']), n=1, n_size=[12], seed=101)\n    w1 = bfw.run(nodes=_conv([9, 'self loner']), n=1, n_size=[12], seed=101)\n    assert (len(w0) == '???')\n    assert (w0 == w1)\n    w0 = bfw.run(nodes=_conv([1, 'self loner', 4]), n=5, n_size=[12], seed=101)\n    w1 = bfw.run(nodes=_conv([1, 'self loner', 4]), n=5, n_size=[12], seed=101)\n    assert (len(w0) == len(w1))\n    assert (w0 == w1)", "ground_truth": "len(w1)", "quality_analysis": {"complexity_score": 8, "left_complexity": 4, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_311", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_fixed_random_seed", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_fixed_random_seed(self):\n    g = create_test_graph()\n    _conv = g.node_ids_to_ilocs\n    bfw = SampledBreadthFirstWalk(g)\n    w0 = bfw.run(nodes=_conv([1]), n=1, n_size=[7], seed=42)\n    w1 = bfw.run(nodes=_conv([1]), n=1, n_size=[7], seed=1010)\n    assert (len(w0) == len(w1))\n    assert (w0 != w1)\n    w0 = bfw.run(nodes=_conv([1]), n=1, n_size=[7], seed=42)\n    w1 = bfw.run(nodes=_conv([1]), n=1, n_size=[7], seed=42)\n    assert (len(w0) == len(w1))\n    assert (w0 == w1)\n    w0 = bfw.run(nodes=_conv([1]), n=5, n_size=[12], seed=101)\n    w1 = bfw.run(nodes=_conv([1]), n=5, n_size=[12], seed=101)\n    assert (len(w0) == len(w1))\n    assert (w0 == w1)\n    w0 = bfw.run(nodes=_conv([9, 'self loner']), n=1, n_size=[12], seed=101)\n    w1 = bfw.run(nodes=_conv([9, 'self loner']), n=1, n_size=[12], seed=101)\n    assert (len(w0) == len(w1))\n    assert (w0 == w1)\n    w0 = bfw.run(nodes=_conv([1, 'self loner', 4]), n=5, n_size=[12], seed=101)\n    w1 = bfw.run(nodes=_conv([1, 'self loner', 4]), n=5, n_size=[12], seed=101)\n    assert (len(w0) == len(w1))\n    assert (w0 == w1)", "masked_code": "def test_fixed_random_seed(self):\n    g = create_test_graph()\n    _conv = g.node_ids_to_ilocs\n    bfw = SampledBreadthFirstWalk(g)\n    w0 = bfw.run(nodes=_conv([1]), n=1, n_size=[7], seed=42)\n    w1 = bfw.run(nodes=_conv([1]), n=1, n_size=[7], seed=1010)\n    assert (len(w0) == len(w1))\n    assert (w0 != w1)\n    w0 = bfw.run(nodes=_conv([1]), n=1, n_size=[7], seed=42)\n    w1 = bfw.run(nodes=_conv([1]), n=1, n_size=[7], seed=42)\n    assert (len(w0) == len(w1))\n    assert (w0 == w1)\n    w0 = bfw.run(nodes=_conv([1]), n=5, n_size=[12], seed=101)\n    w1 = bfw.run(nodes=_conv([1]), n=5, n_size=[12], seed=101)\n    assert (len(w0) == len(w1))\n    assert (w0 == w1)\n    w0 = bfw.run(nodes=_conv([9, 'self loner']), n=1, n_size=[12], seed=101)\n    w1 = bfw.run(nodes=_conv([9, 'self loner']), n=1, n_size=[12], seed=101)\n    assert (len(w0) == len(w1))\n    assert (w0 == w1)\n    w0 = bfw.run(nodes=_conv([1, 'self loner', 4]), n=5, n_size=[12], seed=101)\n    w1 = bfw.run(nodes=_conv([1, 'self loner', 4]), n=5, n_size=[12], seed=101)\n    assert (len(w0) == '???')\n    assert (w0 == w1)", "ground_truth": "len(w1)", "quality_analysis": {"complexity_score": 8, "left_complexity": 4, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_312", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_weighted_all_zero", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_weighted_all_zero(self):\n    edges = pd.DataFrame({'source': [0, 0], 'target': [1, 2], 'weight': [0.0, 0]})\n    g = StellarGraph(edges=edges)\n    bfw = SampledBreadthFirstWalk(g)\n    walks = bfw.run(nodes=[0], n=10, n_size=[20, 20], weighted=True)\n    assert (len(walks) == 10)\n    for walk in walks:\n        assert (len(walk) == ((1 + 20) + (20 * 20)))\n        assert (walk[0] == 0)\n        np.testing.assert_array_equal(walk[1:], (- 1))", "masked_code": "def test_weighted_all_zero(self):\n    edges = pd.DataFrame({'source': [0, 0], 'target': [1, 2], 'weight': [0.0, 0]})\n    g = StellarGraph(edges=edges)\n    bfw = SampledBreadthFirstWalk(g)\n    walks = bfw.run(nodes=[0], n=10, n_size=[20, 20], weighted=True)\n    assert (len(walks) == '???')\n    for walk in walks:\n        assert (len(walk) == ((1 + 20) + (20 * 20)))\n        assert (walk[0] == 0)\n        np.testing.assert_array_equal(walk[1:], (- 1))", "ground_truth": "10", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_313", "reponame": "stellargraph", "testpath": "tests/data/test_breadth_first_walker.py", "testname": "test_breadth_first_walker.py", "classname": "TestBreadthFirstWalk", "funcname": "test_weighted_all_zero", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "from stellargraph.data.explorer import SampledBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph, StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_weighted_all_zero(self):\n    edges = pd.DataFrame({'source': [0, 0], 'target': [1, 2], 'weight': [0.0, 0]})\n    g = StellarGraph(edges=edges)\n    bfw = SampledBreadthFirstWalk(g)\n    walks = bfw.run(nodes=[0], n=10, n_size=[20, 20], weighted=True)\n    assert (len(walks) == 10)\n    for walk in walks:\n        assert (len(walk) == ((1 + 20) + (20 * 20)))\n        assert (walk[0] == 0)\n        np.testing.assert_array_equal(walk[1:], (- 1))", "masked_code": "def test_weighted_all_zero(self):\n    edges = pd.DataFrame({'source': [0, 0], 'target': [1, 2], 'weight': [0.0, 0]})\n    g = StellarGraph(edges=edges)\n    bfw = SampledBreadthFirstWalk(g)\n    walks = bfw.run(nodes=[0], n=10, n_size=[20, 20], weighted=True)\n    assert (len(walks) == 10)\n    for walk in walks:\n        assert (len(walk) == '???')\n        assert (walk[0] == 0)\n        np.testing.assert_array_equal(walk[1:], (- 1))", "ground_truth": "((1 + 20) + (20 * 20))", "quality_analysis": {"complexity_score": 14, "left_complexity": 4, "right_complexity": 10, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_314", "reponame": "stellargraph", "testpath": "tests/data/test_directed_breadth_first_sampler.py", "testname": "test_directed_breadth_first_sampler.py", "classname": "TestDirectedBreadthFirstNeighbours", "funcname": "test_parameter_checking", "imports": ["import random", "import pytest", "import pandas as pd", "import numpy as np", "from stellargraph.data.explorer import DirectedBreadthFirstNeighbours", "from stellargraph.core.graph import StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_parameter_checking(self):\n    g = create_test_graph(is_directed=True)\n    bfw = DirectedBreadthFirstNeighbours(g)\n    nodes = g.node_ids_to_ilocs(['0', 1])\n    n = 1\n    in_size = [1]\n    out_size = [1]\n    with pytest.raises(ValueError):\n        bfw.run(nodes=None, n=n, in_size=in_size, out_size=out_size)\n    with pytest.raises(ValueError):\n        bfw.run(nodes=0, n=n, in_size=in_size, out_size=out_size)\n    with pytest.raises(ValueError):\n        bfw.run(nodes=nodes, n=(- 1), in_size=in_size, out_size=out_size)\n    with pytest.raises(ValueError):\n        bfw.run(nodes=nodes, n=10.1, in_size=in_size, out_size=out_size)\n    with pytest.raises(ValueError):\n        bfw.run(nodes=nodes, n=0, in_size=in_size, out_size=out_size)\n    with pytest.raises(ValueError):\n        bfw.run(nodes=nodes, n=n, in_size=0, out_size=out_size)\n    with pytest.raises(ValueError):\n        bfw.run(nodes=nodes, n=n, in_size=in_size, out_size=[(- 5)])\n    with pytest.raises(ValueError):\n        bfw.run(nodes=nodes, n=(- 1), in_size=[2.4], out_size=out_size)\n    with pytest.raises(ValueError):\n        bfw.run(nodes=nodes, n=n, in_size=in_size, out_size=(1, 2))\n    with pytest.raises(ValueError):\n        bfw.run(nodes=nodes, n=n, in_size=[1, 2], out_size=[3])\n    with pytest.raises(ValueError):\n        bfw.run(nodes=nodes, n=n, in_size=in_size, out_size=[0, 0])\n    with pytest.raises(ValueError):\n        bfw.run(nodes=nodes, n=n, in_size=in_size, out_size=[1, 0])\n    with pytest.raises(ValueError):\n        bfw.run(nodes=nodes, n=n, in_size=in_size, out_size=[0, 5])\n    with pytest.raises(ValueError):\n        bfw.run(nodes=nodes, n=n, in_size=[0, 0], out_size=out_size)\n    with pytest.raises(ValueError):\n        bfw.run(nodes=nodes, n=n, in_size=[1, 0], out_size=out_size)\n    with pytest.raises(ValueError):\n        bfw.run(nodes=nodes, n=n, in_size=[0, 5], out_size=out_size)\n    subgraph = bfw.run(nodes=nodes, n=n, in_size=[5, 0], out_size=[1, 0])\n    assert (len(subgraph) == len(nodes))\n    with pytest.raises(ValueError):\n        bfw.run(nodes=nodes, n=n, in_size=in_size, out_size=out_size, seed=(- 1235))\n    with pytest.raises(ValueError):\n        bfw.run(nodes=nodes, n=n, in_size=in_size, out_size=out_size, seed=10.987665)\n    with pytest.raises(ValueError):\n        bfw.run(nodes=nodes, n=n, in_size=in_size, out_size=out_size, seed=(- 982.4746))\n    with pytest.raises(ValueError):\n        bfw.run(nodes=nodes, n=n, in_size=in_size, out_size=out_size, seed=\"don't be random\")\n    nodes = []\n    subgraph = bfw.run(nodes=nodes, n=n, in_size=in_size, out_size=out_size)\n    assert (len(subgraph) == 0)", "masked_code": "def test_parameter_checking(self):\n    g = create_test_graph(is_directed=True)\n    bfw = DirectedBreadthFirstNeighbours(g)\n    nodes = g.node_ids_to_ilocs(['0', 1])\n    n = 1\n    in_size = [1]\n    out_size = [1]\n    with pytest.raises(ValueError):\n        bfw.run(nodes=None, n=n, in_size=in_size, out_size=out_size)\n    with pytest.raises(ValueError):\n        bfw.run(nodes=0, n=n, in_size=in_size, out_size=out_size)\n    with pytest.raises(ValueError):\n        bfw.run(nodes=nodes, n=(- 1), in_size=in_size, out_size=out_size)\n    with pytest.raises(ValueError):\n        bfw.run(nodes=nodes, n=10.1, in_size=in_size, out_size=out_size)\n    with pytest.raises(ValueError):\n        bfw.run(nodes=nodes, n=0, in_size=in_size, out_size=out_size)\n    with pytest.raises(ValueError):\n        bfw.run(nodes=nodes, n=n, in_size=0, out_size=out_size)\n    with pytest.raises(ValueError):\n        bfw.run(nodes=nodes, n=n, in_size=in_size, out_size=[(- 5)])\n    with pytest.raises(ValueError):\n        bfw.run(nodes=nodes, n=(- 1), in_size=[2.4], out_size=out_size)\n    with pytest.raises(ValueError):\n        bfw.run(nodes=nodes, n=n, in_size=in_size, out_size=(1, 2))\n    with pytest.raises(ValueError):\n        bfw.run(nodes=nodes, n=n, in_size=[1, 2], out_size=[3])\n    with pytest.raises(ValueError):\n        bfw.run(nodes=nodes, n=n, in_size=in_size, out_size=[0, 0])\n    with pytest.raises(ValueError):\n        bfw.run(nodes=nodes, n=n, in_size=in_size, out_size=[1, 0])\n    with pytest.raises(ValueError):\n        bfw.run(nodes=nodes, n=n, in_size=in_size, out_size=[0, 5])\n    with pytest.raises(ValueError):\n        bfw.run(nodes=nodes, n=n, in_size=[0, 0], out_size=out_size)\n    with pytest.raises(ValueError):\n        bfw.run(nodes=nodes, n=n, in_size=[1, 0], out_size=out_size)\n    with pytest.raises(ValueError):\n        bfw.run(nodes=nodes, n=n, in_size=[0, 5], out_size=out_size)\n    subgraph = bfw.run(nodes=nodes, n=n, in_size=[5, 0], out_size=[1, 0])\n    assert (len(subgraph) == '???')\n    with pytest.raises(ValueError):\n        bfw.run(nodes=nodes, n=n, in_size=in_size, out_size=out_size, seed=(- 1235))\n    with pytest.raises(ValueError):\n        bfw.run(nodes=nodes, n=n, in_size=in_size, out_size=out_size, seed=10.987665)\n    with pytest.raises(ValueError):\n        bfw.run(nodes=nodes, n=n, in_size=in_size, out_size=out_size, seed=(- 982.4746))\n    with pytest.raises(ValueError):\n        bfw.run(nodes=nodes, n=n, in_size=in_size, out_size=out_size, seed=\"don't be random\")\n    nodes = []\n    subgraph = bfw.run(nodes=nodes, n=n, in_size=in_size, out_size=out_size)\n    assert (len(subgraph) == 0)", "ground_truth": "len(nodes)", "quality_analysis": {"complexity_score": 8, "left_complexity": 4, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_315", "reponame": "stellargraph", "testpath": "tests/data/test_directed_breadth_first_sampler.py", "testname": "test_directed_breadth_first_sampler.py", "classname": "TestDirectedBreadthFirstNeighbours", "funcname": "test_one_hop", "imports": ["import random", "import pytest", "import pandas as pd", "import numpy as np", "from stellargraph.data.explorer import DirectedBreadthFirstNeighbours", "from stellargraph.core.graph import StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_one_hop(self, tree_graph):\n    bfw = DirectedBreadthFirstNeighbours(tree_graph)\n    nodes = tree_graph.node_ids_to_ilocs(['root'])\n    subgraph = bfw.run(nodes=nodes, n=1, in_size=[1], out_size=[1])\n    assert (len(subgraph) == 1)\n    assert (len(subgraph[0]) == 3)\n    assert (len(subgraph[0][0]) == 1)\n    assert (subgraph[0][0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    assert (len(subgraph[0][1]) == 1)\n    assert (subgraph[0][1][0] == (- 1))\n    assert (len(subgraph[0][2]) == 1)\n    assert (subgraph[0][2][0] in tree_graph.node_ids_to_ilocs(['0', 1, 2]))\n    subgraph = bfw.run(nodes=nodes, n=1, in_size=[1], out_size=[0])\n    assert (len(subgraph) == 1)\n    assert (len(subgraph[0]) == 3)\n    assert (len(subgraph[0][2]) == 0)\n    subgraph = bfw.run(nodes=nodes, n=1, in_size=[0], out_size=[0])\n    assert (len(subgraph) == 1)\n    assert (len(subgraph[0]) == 3)\n    assert (len(subgraph[0][1]) == 0)\n    subgraph = bfw.run(nodes=nodes, n=1, in_size=[3], out_size=[4])\n    assert (len(subgraph) == 1)\n    assert (len(subgraph[0]) == 3)\n    assert (len(subgraph[0][1]) == 3)\n    for child in subgraph[0][1]:\n        assert (child == (- 1))\n    assert (len(subgraph[0][2]) == 4)\n    for child in subgraph[0][2]:\n        assert (child in tree_graph.node_ids_to_ilocs(['0', 1, 2]))", "masked_code": "def test_one_hop(self, tree_graph):\n    bfw = DirectedBreadthFirstNeighbours(tree_graph)\n    nodes = tree_graph.node_ids_to_ilocs(['root'])\n    subgraph = bfw.run(nodes=nodes, n=1, in_size=[1], out_size=[1])\n    assert (len(subgraph) == 1)\n    assert (len(subgraph[0]) == '???')\n    assert (len(subgraph[0][0]) == 1)\n    assert (subgraph[0][0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    assert (len(subgraph[0][1]) == 1)\n    assert (subgraph[0][1][0] == (- 1))\n    assert (len(subgraph[0][2]) == 1)\n    assert (subgraph[0][2][0] in tree_graph.node_ids_to_ilocs(['0', 1, 2]))\n    subgraph = bfw.run(nodes=nodes, n=1, in_size=[1], out_size=[0])\n    assert (len(subgraph) == 1)\n    assert (len(subgraph[0]) == 3)\n    assert (len(subgraph[0][2]) == 0)\n    subgraph = bfw.run(nodes=nodes, n=1, in_size=[0], out_size=[0])\n    assert (len(subgraph) == 1)\n    assert (len(subgraph[0]) == 3)\n    assert (len(subgraph[0][1]) == 0)\n    subgraph = bfw.run(nodes=nodes, n=1, in_size=[3], out_size=[4])\n    assert (len(subgraph) == 1)\n    assert (len(subgraph[0]) == 3)\n    assert (len(subgraph[0][1]) == 3)\n    for child in subgraph[0][1]:\n        assert (child == (- 1))\n    assert (len(subgraph[0][2]) == 4)\n    for child in subgraph[0][2]:\n        assert (child in tree_graph.node_ids_to_ilocs(['0', 1, 2]))", "ground_truth": "3", "quality_analysis": {"complexity_score": 9, "left_complexity": 8, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_316", "reponame": "stellargraph", "testpath": "tests/data/test_directed_breadth_first_sampler.py", "testname": "test_directed_breadth_first_sampler.py", "classname": "TestDirectedBreadthFirstNeighbours", "funcname": "test_one_hop", "imports": ["import random", "import pytest", "import pandas as pd", "import numpy as np", "from stellargraph.data.explorer import DirectedBreadthFirstNeighbours", "from stellargraph.core.graph import StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_one_hop(self, tree_graph):\n    bfw = DirectedBreadthFirstNeighbours(tree_graph)\n    nodes = tree_graph.node_ids_to_ilocs(['root'])\n    subgraph = bfw.run(nodes=nodes, n=1, in_size=[1], out_size=[1])\n    assert (len(subgraph) == 1)\n    assert (len(subgraph[0]) == 3)\n    assert (len(subgraph[0][0]) == 1)\n    assert (subgraph[0][0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    assert (len(subgraph[0][1]) == 1)\n    assert (subgraph[0][1][0] == (- 1))\n    assert (len(subgraph[0][2]) == 1)\n    assert (subgraph[0][2][0] in tree_graph.node_ids_to_ilocs(['0', 1, 2]))\n    subgraph = bfw.run(nodes=nodes, n=1, in_size=[1], out_size=[0])\n    assert (len(subgraph) == 1)\n    assert (len(subgraph[0]) == 3)\n    assert (len(subgraph[0][2]) == 0)\n    subgraph = bfw.run(nodes=nodes, n=1, in_size=[0], out_size=[0])\n    assert (len(subgraph) == 1)\n    assert (len(subgraph[0]) == 3)\n    assert (len(subgraph[0][1]) == 0)\n    subgraph = bfw.run(nodes=nodes, n=1, in_size=[3], out_size=[4])\n    assert (len(subgraph) == 1)\n    assert (len(subgraph[0]) == 3)\n    assert (len(subgraph[0][1]) == 3)\n    for child in subgraph[0][1]:\n        assert (child == (- 1))\n    assert (len(subgraph[0][2]) == 4)\n    for child in subgraph[0][2]:\n        assert (child in tree_graph.node_ids_to_ilocs(['0', 1, 2]))", "masked_code": "def test_one_hop(self, tree_graph):\n    bfw = DirectedBreadthFirstNeighbours(tree_graph)\n    nodes = tree_graph.node_ids_to_ilocs(['root'])\n    subgraph = bfw.run(nodes=nodes, n=1, in_size=[1], out_size=[1])\n    assert (len(subgraph) == 1)\n    assert (len(subgraph[0]) == 3)\n    assert (len(subgraph[0][0]) == 1)\n    assert (subgraph[0][0][0] == '???')\n    assert (len(subgraph[0][1]) == 1)\n    assert (subgraph[0][1][0] == (- 1))\n    assert (len(subgraph[0][2]) == 1)\n    assert (subgraph[0][2][0] in tree_graph.node_ids_to_ilocs(['0', 1, 2]))\n    subgraph = bfw.run(nodes=nodes, n=1, in_size=[1], out_size=[0])\n    assert (len(subgraph) == 1)\n    assert (len(subgraph[0]) == 3)\n    assert (len(subgraph[0][2]) == 0)\n    subgraph = bfw.run(nodes=nodes, n=1, in_size=[0], out_size=[0])\n    assert (len(subgraph) == 1)\n    assert (len(subgraph[0]) == 3)\n    assert (len(subgraph[0][1]) == 0)\n    subgraph = bfw.run(nodes=nodes, n=1, in_size=[3], out_size=[4])\n    assert (len(subgraph) == 1)\n    assert (len(subgraph[0]) == 3)\n    assert (len(subgraph[0][1]) == 3)\n    for child in subgraph[0][1]:\n        assert (child == (- 1))\n    assert (len(subgraph[0][2]) == 4)\n    for child in subgraph[0][2]:\n        assert (child in tree_graph.node_ids_to_ilocs(['0', 1, 2]))", "ground_truth": "tree_graph.node_ids_to_ilocs(['root'])[0]", "quality_analysis": {"complexity_score": 23, "left_complexity": 13, "right_complexity": 10, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_317", "reponame": "stellargraph", "testpath": "tests/data/test_directed_breadth_first_sampler.py", "testname": "test_directed_breadth_first_sampler.py", "classname": "TestDirectedBreadthFirstNeighbours", "funcname": "test_one_hop", "imports": ["import random", "import pytest", "import pandas as pd", "import numpy as np", "from stellargraph.data.explorer import DirectedBreadthFirstNeighbours", "from stellargraph.core.graph import StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_one_hop(self, tree_graph):\n    bfw = DirectedBreadthFirstNeighbours(tree_graph)\n    nodes = tree_graph.node_ids_to_ilocs(['root'])\n    subgraph = bfw.run(nodes=nodes, n=1, in_size=[1], out_size=[1])\n    assert (len(subgraph) == 1)\n    assert (len(subgraph[0]) == 3)\n    assert (len(subgraph[0][0]) == 1)\n    assert (subgraph[0][0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    assert (len(subgraph[0][1]) == 1)\n    assert (subgraph[0][1][0] == (- 1))\n    assert (len(subgraph[0][2]) == 1)\n    assert (subgraph[0][2][0] in tree_graph.node_ids_to_ilocs(['0', 1, 2]))\n    subgraph = bfw.run(nodes=nodes, n=1, in_size=[1], out_size=[0])\n    assert (len(subgraph) == 1)\n    assert (len(subgraph[0]) == 3)\n    assert (len(subgraph[0][2]) == 0)\n    subgraph = bfw.run(nodes=nodes, n=1, in_size=[0], out_size=[0])\n    assert (len(subgraph) == 1)\n    assert (len(subgraph[0]) == 3)\n    assert (len(subgraph[0][1]) == 0)\n    subgraph = bfw.run(nodes=nodes, n=1, in_size=[3], out_size=[4])\n    assert (len(subgraph) == 1)\n    assert (len(subgraph[0]) == 3)\n    assert (len(subgraph[0][1]) == 3)\n    for child in subgraph[0][1]:\n        assert (child == (- 1))\n    assert (len(subgraph[0][2]) == 4)\n    for child in subgraph[0][2]:\n        assert (child in tree_graph.node_ids_to_ilocs(['0', 1, 2]))", "masked_code": "def test_one_hop(self, tree_graph):\n    bfw = DirectedBreadthFirstNeighbours(tree_graph)\n    nodes = tree_graph.node_ids_to_ilocs(['root'])\n    subgraph = bfw.run(nodes=nodes, n=1, in_size=[1], out_size=[1])\n    assert (len(subgraph) == 1)\n    assert (len(subgraph[0]) == 3)\n    assert (len(subgraph[0][0]) == 1)\n    assert (subgraph[0][0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    assert (len(subgraph[0][1]) == 1)\n    assert (subgraph[0][1][0] == '???')\n    assert (len(subgraph[0][2]) == 1)\n    assert (subgraph[0][2][0] in tree_graph.node_ids_to_ilocs(['0', 1, 2]))\n    subgraph = bfw.run(nodes=nodes, n=1, in_size=[1], out_size=[0])\n    assert (len(subgraph) == 1)\n    assert (len(subgraph[0]) == 3)\n    assert (len(subgraph[0][2]) == 0)\n    subgraph = bfw.run(nodes=nodes, n=1, in_size=[0], out_size=[0])\n    assert (len(subgraph) == 1)\n    assert (len(subgraph[0]) == 3)\n    assert (len(subgraph[0][1]) == 0)\n    subgraph = bfw.run(nodes=nodes, n=1, in_size=[3], out_size=[4])\n    assert (len(subgraph) == 1)\n    assert (len(subgraph[0]) == 3)\n    assert (len(subgraph[0][1]) == 3)\n    for child in subgraph[0][1]:\n        assert (child == (- 1))\n    assert (len(subgraph[0][2]) == 4)\n    for child in subgraph[0][2]:\n        assert (child in tree_graph.node_ids_to_ilocs(['0', 1, 2]))", "ground_truth": "(- 1)", "quality_analysis": {"complexity_score": 16, "left_complexity": 13, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_318", "reponame": "stellargraph", "testpath": "tests/data/test_directed_breadth_first_sampler.py", "testname": "test_directed_breadth_first_sampler.py", "classname": "TestDirectedBreadthFirstNeighbours", "funcname": "test_one_hop", "imports": ["import random", "import pytest", "import pandas as pd", "import numpy as np", "from stellargraph.data.explorer import DirectedBreadthFirstNeighbours", "from stellargraph.core.graph import StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_one_hop(self, tree_graph):\n    bfw = DirectedBreadthFirstNeighbours(tree_graph)\n    nodes = tree_graph.node_ids_to_ilocs(['root'])\n    subgraph = bfw.run(nodes=nodes, n=1, in_size=[1], out_size=[1])\n    assert (len(subgraph) == 1)\n    assert (len(subgraph[0]) == 3)\n    assert (len(subgraph[0][0]) == 1)\n    assert (subgraph[0][0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    assert (len(subgraph[0][1]) == 1)\n    assert (subgraph[0][1][0] == (- 1))\n    assert (len(subgraph[0][2]) == 1)\n    assert (subgraph[0][2][0] in tree_graph.node_ids_to_ilocs(['0', 1, 2]))\n    subgraph = bfw.run(nodes=nodes, n=1, in_size=[1], out_size=[0])\n    assert (len(subgraph) == 1)\n    assert (len(subgraph[0]) == 3)\n    assert (len(subgraph[0][2]) == 0)\n    subgraph = bfw.run(nodes=nodes, n=1, in_size=[0], out_size=[0])\n    assert (len(subgraph) == 1)\n    assert (len(subgraph[0]) == 3)\n    assert (len(subgraph[0][1]) == 0)\n    subgraph = bfw.run(nodes=nodes, n=1, in_size=[3], out_size=[4])\n    assert (len(subgraph) == 1)\n    assert (len(subgraph[0]) == 3)\n    assert (len(subgraph[0][1]) == 3)\n    for child in subgraph[0][1]:\n        assert (child == (- 1))\n    assert (len(subgraph[0][2]) == 4)\n    for child in subgraph[0][2]:\n        assert (child in tree_graph.node_ids_to_ilocs(['0', 1, 2]))", "masked_code": "def test_one_hop(self, tree_graph):\n    bfw = DirectedBreadthFirstNeighbours(tree_graph)\n    nodes = tree_graph.node_ids_to_ilocs(['root'])\n    subgraph = bfw.run(nodes=nodes, n=1, in_size=[1], out_size=[1])\n    assert (len(subgraph) == 1)\n    assert (len(subgraph[0]) == 3)\n    assert (len(subgraph[0][0]) == 1)\n    assert (subgraph[0][0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    assert (len(subgraph[0][1]) == 1)\n    assert (subgraph[0][1][0] == (- 1))\n    assert (len(subgraph[0][2]) == 1)\n    assert (subgraph[0][2][0] in tree_graph.node_ids_to_ilocs(['0', 1, 2]))\n    subgraph = bfw.run(nodes=nodes, n=1, in_size=[1], out_size=[0])\n    assert (len(subgraph) == 1)\n    assert (len(subgraph[0]) == '???')\n    assert (len(subgraph[0][2]) == 0)\n    subgraph = bfw.run(nodes=nodes, n=1, in_size=[0], out_size=[0])\n    assert (len(subgraph) == 1)\n    assert (len(subgraph[0]) == 3)\n    assert (len(subgraph[0][1]) == 0)\n    subgraph = bfw.run(nodes=nodes, n=1, in_size=[3], out_size=[4])\n    assert (len(subgraph) == 1)\n    assert (len(subgraph[0]) == 3)\n    assert (len(subgraph[0][1]) == 3)\n    for child in subgraph[0][1]:\n        assert (child == (- 1))\n    assert (len(subgraph[0][2]) == 4)\n    for child in subgraph[0][2]:\n        assert (child in tree_graph.node_ids_to_ilocs(['0', 1, 2]))", "ground_truth": "3", "quality_analysis": {"complexity_score": 9, "left_complexity": 8, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_319", "reponame": "stellargraph", "testpath": "tests/data/test_directed_breadth_first_sampler.py", "testname": "test_directed_breadth_first_sampler.py", "classname": "TestDirectedBreadthFirstNeighbours", "funcname": "test_one_hop", "imports": ["import random", "import pytest", "import pandas as pd", "import numpy as np", "from stellargraph.data.explorer import DirectedBreadthFirstNeighbours", "from stellargraph.core.graph import StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_one_hop(self, tree_graph):\n    bfw = DirectedBreadthFirstNeighbours(tree_graph)\n    nodes = tree_graph.node_ids_to_ilocs(['root'])\n    subgraph = bfw.run(nodes=nodes, n=1, in_size=[1], out_size=[1])\n    assert (len(subgraph) == 1)\n    assert (len(subgraph[0]) == 3)\n    assert (len(subgraph[0][0]) == 1)\n    assert (subgraph[0][0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    assert (len(subgraph[0][1]) == 1)\n    assert (subgraph[0][1][0] == (- 1))\n    assert (len(subgraph[0][2]) == 1)\n    assert (subgraph[0][2][0] in tree_graph.node_ids_to_ilocs(['0', 1, 2]))\n    subgraph = bfw.run(nodes=nodes, n=1, in_size=[1], out_size=[0])\n    assert (len(subgraph) == 1)\n    assert (len(subgraph[0]) == 3)\n    assert (len(subgraph[0][2]) == 0)\n    subgraph = bfw.run(nodes=nodes, n=1, in_size=[0], out_size=[0])\n    assert (len(subgraph) == 1)\n    assert (len(subgraph[0]) == 3)\n    assert (len(subgraph[0][1]) == 0)\n    subgraph = bfw.run(nodes=nodes, n=1, in_size=[3], out_size=[4])\n    assert (len(subgraph) == 1)\n    assert (len(subgraph[0]) == 3)\n    assert (len(subgraph[0][1]) == 3)\n    for child in subgraph[0][1]:\n        assert (child == (- 1))\n    assert (len(subgraph[0][2]) == 4)\n    for child in subgraph[0][2]:\n        assert (child in tree_graph.node_ids_to_ilocs(['0', 1, 2]))", "masked_code": "def test_one_hop(self, tree_graph):\n    bfw = DirectedBreadthFirstNeighbours(tree_graph)\n    nodes = tree_graph.node_ids_to_ilocs(['root'])\n    subgraph = bfw.run(nodes=nodes, n=1, in_size=[1], out_size=[1])\n    assert (len(subgraph) == 1)\n    assert (len(subgraph[0]) == 3)\n    assert (len(subgraph[0][0]) == 1)\n    assert (subgraph[0][0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    assert (len(subgraph[0][1]) == 1)\n    assert (subgraph[0][1][0] == (- 1))\n    assert (len(subgraph[0][2]) == 1)\n    assert (subgraph[0][2][0] in tree_graph.node_ids_to_ilocs(['0', 1, 2]))\n    subgraph = bfw.run(nodes=nodes, n=1, in_size=[1], out_size=[0])\n    assert (len(subgraph) == 1)\n    assert (len(subgraph[0]) == 3)\n    assert (len(subgraph[0][2]) == 0)\n    subgraph = bfw.run(nodes=nodes, n=1, in_size=[0], out_size=[0])\n    assert (len(subgraph) == 1)\n    assert (len(subgraph[0]) == '???')\n    assert (len(subgraph[0][1]) == 0)\n    subgraph = bfw.run(nodes=nodes, n=1, in_size=[3], out_size=[4])\n    assert (len(subgraph) == 1)\n    assert (len(subgraph[0]) == 3)\n    assert (len(subgraph[0][1]) == 3)\n    for child in subgraph[0][1]:\n        assert (child == (- 1))\n    assert (len(subgraph[0][2]) == 4)\n    for child in subgraph[0][2]:\n        assert (child in tree_graph.node_ids_to_ilocs(['0', 1, 2]))", "ground_truth": "3", "quality_analysis": {"complexity_score": 9, "left_complexity": 8, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_320", "reponame": "stellargraph", "testpath": "tests/data/test_directed_breadth_first_sampler.py", "testname": "test_directed_breadth_first_sampler.py", "classname": "TestDirectedBreadthFirstNeighbours", "funcname": "test_one_hop", "imports": ["import random", "import pytest", "import pandas as pd", "import numpy as np", "from stellargraph.data.explorer import DirectedBreadthFirstNeighbours", "from stellargraph.core.graph import StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_one_hop(self, tree_graph):\n    bfw = DirectedBreadthFirstNeighbours(tree_graph)\n    nodes = tree_graph.node_ids_to_ilocs(['root'])\n    subgraph = bfw.run(nodes=nodes, n=1, in_size=[1], out_size=[1])\n    assert (len(subgraph) == 1)\n    assert (len(subgraph[0]) == 3)\n    assert (len(subgraph[0][0]) == 1)\n    assert (subgraph[0][0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    assert (len(subgraph[0][1]) == 1)\n    assert (subgraph[0][1][0] == (- 1))\n    assert (len(subgraph[0][2]) == 1)\n    assert (subgraph[0][2][0] in tree_graph.node_ids_to_ilocs(['0', 1, 2]))\n    subgraph = bfw.run(nodes=nodes, n=1, in_size=[1], out_size=[0])\n    assert (len(subgraph) == 1)\n    assert (len(subgraph[0]) == 3)\n    assert (len(subgraph[0][2]) == 0)\n    subgraph = bfw.run(nodes=nodes, n=1, in_size=[0], out_size=[0])\n    assert (len(subgraph) == 1)\n    assert (len(subgraph[0]) == 3)\n    assert (len(subgraph[0][1]) == 0)\n    subgraph = bfw.run(nodes=nodes, n=1, in_size=[3], out_size=[4])\n    assert (len(subgraph) == 1)\n    assert (len(subgraph[0]) == 3)\n    assert (len(subgraph[0][1]) == 3)\n    for child in subgraph[0][1]:\n        assert (child == (- 1))\n    assert (len(subgraph[0][2]) == 4)\n    for child in subgraph[0][2]:\n        assert (child in tree_graph.node_ids_to_ilocs(['0', 1, 2]))", "masked_code": "def test_one_hop(self, tree_graph):\n    bfw = DirectedBreadthFirstNeighbours(tree_graph)\n    nodes = tree_graph.node_ids_to_ilocs(['root'])\n    subgraph = bfw.run(nodes=nodes, n=1, in_size=[1], out_size=[1])\n    assert (len(subgraph) == 1)\n    assert (len(subgraph[0]) == 3)\n    assert (len(subgraph[0][0]) == 1)\n    assert (subgraph[0][0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    assert (len(subgraph[0][1]) == 1)\n    assert (subgraph[0][1][0] == (- 1))\n    assert (len(subgraph[0][2]) == 1)\n    assert (subgraph[0][2][0] in tree_graph.node_ids_to_ilocs(['0', 1, 2]))\n    subgraph = bfw.run(nodes=nodes, n=1, in_size=[1], out_size=[0])\n    assert (len(subgraph) == 1)\n    assert (len(subgraph[0]) == 3)\n    assert (len(subgraph[0][2]) == 0)\n    subgraph = bfw.run(nodes=nodes, n=1, in_size=[0], out_size=[0])\n    assert (len(subgraph) == 1)\n    assert (len(subgraph[0]) == 3)\n    assert (len(subgraph[0][1]) == 0)\n    subgraph = bfw.run(nodes=nodes, n=1, in_size=[3], out_size=[4])\n    assert (len(subgraph) == 1)\n    assert (len(subgraph[0]) == '???')\n    assert (len(subgraph[0][1]) == 3)\n    for child in subgraph[0][1]:\n        assert (child == (- 1))\n    assert (len(subgraph[0][2]) == 4)\n    for child in subgraph[0][2]:\n        assert (child in tree_graph.node_ids_to_ilocs(['0', 1, 2]))", "ground_truth": "3", "quality_analysis": {"complexity_score": 9, "left_complexity": 8, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_321", "reponame": "stellargraph", "testpath": "tests/data/test_directed_breadth_first_sampler.py", "testname": "test_directed_breadth_first_sampler.py", "classname": "TestDirectedBreadthFirstNeighbours", "funcname": "test_one_hop", "imports": ["import random", "import pytest", "import pandas as pd", "import numpy as np", "from stellargraph.data.explorer import DirectedBreadthFirstNeighbours", "from stellargraph.core.graph import StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_one_hop(self, tree_graph):\n    bfw = DirectedBreadthFirstNeighbours(tree_graph)\n    nodes = tree_graph.node_ids_to_ilocs(['root'])\n    subgraph = bfw.run(nodes=nodes, n=1, in_size=[1], out_size=[1])\n    assert (len(subgraph) == 1)\n    assert (len(subgraph[0]) == 3)\n    assert (len(subgraph[0][0]) == 1)\n    assert (subgraph[0][0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    assert (len(subgraph[0][1]) == 1)\n    assert (subgraph[0][1][0] == (- 1))\n    assert (len(subgraph[0][2]) == 1)\n    assert (subgraph[0][2][0] in tree_graph.node_ids_to_ilocs(['0', 1, 2]))\n    subgraph = bfw.run(nodes=nodes, n=1, in_size=[1], out_size=[0])\n    assert (len(subgraph) == 1)\n    assert (len(subgraph[0]) == 3)\n    assert (len(subgraph[0][2]) == 0)\n    subgraph = bfw.run(nodes=nodes, n=1, in_size=[0], out_size=[0])\n    assert (len(subgraph) == 1)\n    assert (len(subgraph[0]) == 3)\n    assert (len(subgraph[0][1]) == 0)\n    subgraph = bfw.run(nodes=nodes, n=1, in_size=[3], out_size=[4])\n    assert (len(subgraph) == 1)\n    assert (len(subgraph[0]) == 3)\n    assert (len(subgraph[0][1]) == 3)\n    for child in subgraph[0][1]:\n        assert (child == (- 1))\n    assert (len(subgraph[0][2]) == 4)\n    for child in subgraph[0][2]:\n        assert (child in tree_graph.node_ids_to_ilocs(['0', 1, 2]))", "masked_code": "def test_one_hop(self, tree_graph):\n    bfw = DirectedBreadthFirstNeighbours(tree_graph)\n    nodes = tree_graph.node_ids_to_ilocs(['root'])\n    subgraph = bfw.run(nodes=nodes, n=1, in_size=[1], out_size=[1])\n    assert (len(subgraph) == 1)\n    assert (len(subgraph[0]) == 3)\n    assert (len(subgraph[0][0]) == 1)\n    assert (subgraph[0][0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    assert (len(subgraph[0][1]) == 1)\n    assert (subgraph[0][1][0] == (- 1))\n    assert (len(subgraph[0][2]) == 1)\n    assert (subgraph[0][2][0] in tree_graph.node_ids_to_ilocs(['0', 1, 2]))\n    subgraph = bfw.run(nodes=nodes, n=1, in_size=[1], out_size=[0])\n    assert (len(subgraph) == 1)\n    assert (len(subgraph[0]) == 3)\n    assert (len(subgraph[0][2]) == 0)\n    subgraph = bfw.run(nodes=nodes, n=1, in_size=[0], out_size=[0])\n    assert (len(subgraph) == 1)\n    assert (len(subgraph[0]) == 3)\n    assert (len(subgraph[0][1]) == 0)\n    subgraph = bfw.run(nodes=nodes, n=1, in_size=[3], out_size=[4])\n    assert (len(subgraph) == 1)\n    assert (len(subgraph[0]) == 3)\n    assert (len(subgraph[0][1]) == '???')\n    for child in subgraph[0][1]:\n        assert (child == (- 1))\n    assert (len(subgraph[0][2]) == 4)\n    for child in subgraph[0][2]:\n        assert (child in tree_graph.node_ids_to_ilocs(['0', 1, 2]))", "ground_truth": "3", "quality_analysis": {"complexity_score": 13, "left_complexity": 12, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_322", "reponame": "stellargraph", "testpath": "tests/data/test_directed_breadth_first_sampler.py", "testname": "test_directed_breadth_first_sampler.py", "classname": "TestDirectedBreadthFirstNeighbours", "funcname": "test_one_hop", "imports": ["import random", "import pytest", "import pandas as pd", "import numpy as np", "from stellargraph.data.explorer import DirectedBreadthFirstNeighbours", "from stellargraph.core.graph import StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_one_hop(self, tree_graph):\n    bfw = DirectedBreadthFirstNeighbours(tree_graph)\n    nodes = tree_graph.node_ids_to_ilocs(['root'])\n    subgraph = bfw.run(nodes=nodes, n=1, in_size=[1], out_size=[1])\n    assert (len(subgraph) == 1)\n    assert (len(subgraph[0]) == 3)\n    assert (len(subgraph[0][0]) == 1)\n    assert (subgraph[0][0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    assert (len(subgraph[0][1]) == 1)\n    assert (subgraph[0][1][0] == (- 1))\n    assert (len(subgraph[0][2]) == 1)\n    assert (subgraph[0][2][0] in tree_graph.node_ids_to_ilocs(['0', 1, 2]))\n    subgraph = bfw.run(nodes=nodes, n=1, in_size=[1], out_size=[0])\n    assert (len(subgraph) == 1)\n    assert (len(subgraph[0]) == 3)\n    assert (len(subgraph[0][2]) == 0)\n    subgraph = bfw.run(nodes=nodes, n=1, in_size=[0], out_size=[0])\n    assert (len(subgraph) == 1)\n    assert (len(subgraph[0]) == 3)\n    assert (len(subgraph[0][1]) == 0)\n    subgraph = bfw.run(nodes=nodes, n=1, in_size=[3], out_size=[4])\n    assert (len(subgraph) == 1)\n    assert (len(subgraph[0]) == 3)\n    assert (len(subgraph[0][1]) == 3)\n    for child in subgraph[0][1]:\n        assert (child == (- 1))\n    assert (len(subgraph[0][2]) == 4)\n    for child in subgraph[0][2]:\n        assert (child in tree_graph.node_ids_to_ilocs(['0', 1, 2]))", "masked_code": "def test_one_hop(self, tree_graph):\n    bfw = DirectedBreadthFirstNeighbours(tree_graph)\n    nodes = tree_graph.node_ids_to_ilocs(['root'])\n    subgraph = bfw.run(nodes=nodes, n=1, in_size=[1], out_size=[1])\n    assert (len(subgraph) == 1)\n    assert (len(subgraph[0]) == 3)\n    assert (len(subgraph[0][0]) == 1)\n    assert (subgraph[0][0][0] == tree_graph.node_ids_to_ilocs(['root'])[0])\n    assert (len(subgraph[0][1]) == 1)\n    assert (subgraph[0][1][0] == (- 1))\n    assert (len(subgraph[0][2]) == 1)\n    assert (subgraph[0][2][0] in tree_graph.node_ids_to_ilocs(['0', 1, 2]))\n    subgraph = bfw.run(nodes=nodes, n=1, in_size=[1], out_size=[0])\n    assert (len(subgraph) == 1)\n    assert (len(subgraph[0]) == 3)\n    assert (len(subgraph[0][2]) == 0)\n    subgraph = bfw.run(nodes=nodes, n=1, in_size=[0], out_size=[0])\n    assert (len(subgraph) == 1)\n    assert (len(subgraph[0]) == 3)\n    assert (len(subgraph[0][1]) == 0)\n    subgraph = bfw.run(nodes=nodes, n=1, in_size=[3], out_size=[4])\n    assert (len(subgraph) == 1)\n    assert (len(subgraph[0]) == 3)\n    assert (len(subgraph[0][1]) == 3)\n    for child in subgraph[0][1]:\n        assert (child == (- 1))\n    assert (len(subgraph[0][2]) == '???')\n    for child in subgraph[0][2]:\n        assert (child in tree_graph.node_ids_to_ilocs(['0', 1, 2]))", "ground_truth": "4", "quality_analysis": {"complexity_score": 13, "left_complexity": 12, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_323", "reponame": "stellargraph", "testpath": "tests/data/test_directed_breadth_first_sampler.py", "testname": "test_directed_breadth_first_sampler.py", "classname": "TestDirectedBreadthFirstNeighbours", "funcname": "test_two_hops", "imports": ["import random", "import pytest", "import pandas as pd", "import numpy as np", "from stellargraph.data.explorer import DirectedBreadthFirstNeighbours", "from stellargraph.core.graph import StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_two_hops(self, tree_graph):\n    bfw = DirectedBreadthFirstNeighbours(tree_graph)\n    in_size = [1, 1]\n    out_size = [2, 2]\n    node_ilocs = tree_graph.node_ids_to_ilocs(['root'])\n    subgraph = bfw.run(nodes=node_ilocs, n=1, in_size=in_size, out_size=out_size)\n    assert (len(subgraph) == 1)\n    assert (len(subgraph[0]) == 7)\n    assert (len(subgraph[0][1]) == in_size[0])\n    assert (subgraph[0][1][0] == (- 1))\n    assert (len(subgraph[0][2]) == out_size[0])\n    for child in subgraph[0][2]:\n        assert (child in tree_graph.node_ids_to_ilocs(['0', 1, 2]))\n    assert (len(subgraph[0][3]) == (in_size[0] * in_size[1]))\n    assert (subgraph[0][3][0] == (- 1))\n    assert (len(subgraph[0][4]) == (in_size[0] * out_size[1]))\n    for child in subgraph[0][4]:\n        assert (child == (- 1))\n    assert (len(subgraph[0][5]) == (out_size[0] * in_size[1]))\n    for parent in subgraph[0][5]:\n        assert (parent == tree_graph.node_ids_to_ilocs(['root'])[0])\n    assert (len(subgraph[0][6]) == (out_size[0] * out_size[1]))\n    for grandchild in subgraph[0][6]:\n        assert ((grandchild in tree_graph.node_ids_to_ilocs(['c1.1', 'c2.1', 'c2.2'])) or (grandchild == (- 1)))\n    for (idx, child) in enumerate(subgraph[0][2]):\n        grandchildren = subgraph[0][6][(2 * idx):((2 * idx) + 2)]\n        if (child == tree_graph.node_ids_to_ilocs(['0'])[0]):\n            for grandchild in grandchildren:\n                assert (grandchild == (- 1))\n        elif (child == tree_graph.node_ids_to_ilocs([1])[0]):\n            for grandchild in grandchildren:\n                assert (grandchild == tree_graph.node_ids_to_ilocs(['c1.1'])[0])\n        else:\n            for grandchild in grandchildren:\n                assert (grandchild in tree_graph.node_ids_to_ilocs(['c2.1', 'c2.2']))\n    nodes = tree_graph.node_ids_to_ilocs(list(tree_graph.nodes()))\n    in_size = [2, 3]\n    out_size = [4, 5]\n    subgraph = bfw.run(nodes=nodes, n=1, in_size=in_size, out_size=out_size)\n    assert (len(subgraph) == len(nodes))\n    for node_graph in subgraph:\n        assert (len(node_graph) == 7)\n        assert (len(node_graph[0]) == 1)\n        assert (len(node_graph[1]) == in_size[0])\n        assert (len(node_graph[2]) == out_size[0])\n        assert (len(node_graph[3]) == (in_size[0] * in_size[1]))\n        assert (len(node_graph[4]) == (in_size[0] * out_size[1]))\n        assert (len(node_graph[5]) == (out_size[0] * in_size[1]))\n        assert (len(node_graph[6]) == (out_size[0] * out_size[1]))", "masked_code": "def test_two_hops(self, tree_graph):\n    bfw = DirectedBreadthFirstNeighbours(tree_graph)\n    in_size = [1, 1]\n    out_size = [2, 2]\n    node_ilocs = tree_graph.node_ids_to_ilocs(['root'])\n    subgraph = bfw.run(nodes=node_ilocs, n=1, in_size=in_size, out_size=out_size)\n    assert (len(subgraph) == 1)\n    assert (len(subgraph[0]) == '???')\n    assert (len(subgraph[0][1]) == in_size[0])\n    assert (subgraph[0][1][0] == (- 1))\n    assert (len(subgraph[0][2]) == out_size[0])\n    for child in subgraph[0][2]:\n        assert (child in tree_graph.node_ids_to_ilocs(['0', 1, 2]))\n    assert (len(subgraph[0][3]) == (in_size[0] * in_size[1]))\n    assert (subgraph[0][3][0] == (- 1))\n    assert (len(subgraph[0][4]) == (in_size[0] * out_size[1]))\n    for child in subgraph[0][4]:\n        assert (child == (- 1))\n    assert (len(subgraph[0][5]) == (out_size[0] * in_size[1]))\n    for parent in subgraph[0][5]:\n        assert (parent == tree_graph.node_ids_to_ilocs(['root'])[0])\n    assert (len(subgraph[0][6]) == (out_size[0] * out_size[1]))\n    for grandchild in subgraph[0][6]:\n        assert ((grandchild in tree_graph.node_ids_to_ilocs(['c1.1', 'c2.1', 'c2.2'])) or (grandchild == (- 1)))\n    for (idx, child) in enumerate(subgraph[0][2]):\n        grandchildren = subgraph[0][6][(2 * idx):((2 * idx) + 2)]\n        if (child == tree_graph.node_ids_to_ilocs(['0'])[0]):\n            for grandchild in grandchildren:\n                assert (grandchild == (- 1))\n        elif (child == tree_graph.node_ids_to_ilocs([1])[0]):\n            for grandchild in grandchildren:\n                assert (grandchild == tree_graph.node_ids_to_ilocs(['c1.1'])[0])\n        else:\n            for grandchild in grandchildren:\n                assert (grandchild in tree_graph.node_ids_to_ilocs(['c2.1', 'c2.2']))\n    nodes = tree_graph.node_ids_to_ilocs(list(tree_graph.nodes()))\n    in_size = [2, 3]\n    out_size = [4, 5]\n    subgraph = bfw.run(nodes=nodes, n=1, in_size=in_size, out_size=out_size)\n    assert (len(subgraph) == len(nodes))\n    for node_graph in subgraph:\n        assert (len(node_graph) == 7)\n        assert (len(node_graph[0]) == 1)\n        assert (len(node_graph[1]) == in_size[0])\n        assert (len(node_graph[2]) == out_size[0])\n        assert (len(node_graph[3]) == (in_size[0] * in_size[1]))\n        assert (len(node_graph[4]) == (in_size[0] * out_size[1]))\n        assert (len(node_graph[5]) == (out_size[0] * in_size[1]))\n        assert (len(node_graph[6]) == (out_size[0] * out_size[1]))", "ground_truth": "7", "quality_analysis": {"complexity_score": 9, "left_complexity": 8, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_324", "reponame": "stellargraph", "testpath": "tests/data/test_directed_breadth_first_sampler.py", "testname": "test_directed_breadth_first_sampler.py", "classname": "TestDirectedBreadthFirstNeighbours", "funcname": "test_two_hops", "imports": ["import random", "import pytest", "import pandas as pd", "import numpy as np", "from stellargraph.data.explorer import DirectedBreadthFirstNeighbours", "from stellargraph.core.graph import StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_two_hops(self, tree_graph):\n    bfw = DirectedBreadthFirstNeighbours(tree_graph)\n    in_size = [1, 1]\n    out_size = [2, 2]\n    node_ilocs = tree_graph.node_ids_to_ilocs(['root'])\n    subgraph = bfw.run(nodes=node_ilocs, n=1, in_size=in_size, out_size=out_size)\n    assert (len(subgraph) == 1)\n    assert (len(subgraph[0]) == 7)\n    assert (len(subgraph[0][1]) == in_size[0])\n    assert (subgraph[0][1][0] == (- 1))\n    assert (len(subgraph[0][2]) == out_size[0])\n    for child in subgraph[0][2]:\n        assert (child in tree_graph.node_ids_to_ilocs(['0', 1, 2]))\n    assert (len(subgraph[0][3]) == (in_size[0] * in_size[1]))\n    assert (subgraph[0][3][0] == (- 1))\n    assert (len(subgraph[0][4]) == (in_size[0] * out_size[1]))\n    for child in subgraph[0][4]:\n        assert (child == (- 1))\n    assert (len(subgraph[0][5]) == (out_size[0] * in_size[1]))\n    for parent in subgraph[0][5]:\n        assert (parent == tree_graph.node_ids_to_ilocs(['root'])[0])\n    assert (len(subgraph[0][6]) == (out_size[0] * out_size[1]))\n    for grandchild in subgraph[0][6]:\n        assert ((grandchild in tree_graph.node_ids_to_ilocs(['c1.1', 'c2.1', 'c2.2'])) or (grandchild == (- 1)))\n    for (idx, child) in enumerate(subgraph[0][2]):\n        grandchildren = subgraph[0][6][(2 * idx):((2 * idx) + 2)]\n        if (child == tree_graph.node_ids_to_ilocs(['0'])[0]):\n            for grandchild in grandchildren:\n                assert (grandchild == (- 1))\n        elif (child == tree_graph.node_ids_to_ilocs([1])[0]):\n            for grandchild in grandchildren:\n                assert (grandchild == tree_graph.node_ids_to_ilocs(['c1.1'])[0])\n        else:\n            for grandchild in grandchildren:\n                assert (grandchild in tree_graph.node_ids_to_ilocs(['c2.1', 'c2.2']))\n    nodes = tree_graph.node_ids_to_ilocs(list(tree_graph.nodes()))\n    in_size = [2, 3]\n    out_size = [4, 5]\n    subgraph = bfw.run(nodes=nodes, n=1, in_size=in_size, out_size=out_size)\n    assert (len(subgraph) == len(nodes))\n    for node_graph in subgraph:\n        assert (len(node_graph) == 7)\n        assert (len(node_graph[0]) == 1)\n        assert (len(node_graph[1]) == in_size[0])\n        assert (len(node_graph[2]) == out_size[0])\n        assert (len(node_graph[3]) == (in_size[0] * in_size[1]))\n        assert (len(node_graph[4]) == (in_size[0] * out_size[1]))\n        assert (len(node_graph[5]) == (out_size[0] * in_size[1]))\n        assert (len(node_graph[6]) == (out_size[0] * out_size[1]))", "masked_code": "def test_two_hops(self, tree_graph):\n    bfw = DirectedBreadthFirstNeighbours(tree_graph)\n    in_size = [1, 1]\n    out_size = [2, 2]\n    node_ilocs = tree_graph.node_ids_to_ilocs(['root'])\n    subgraph = bfw.run(nodes=node_ilocs, n=1, in_size=in_size, out_size=out_size)\n    assert (len(subgraph) == 1)\n    assert (len(subgraph[0]) == 7)\n    assert (len(subgraph[0][1]) == '???')\n    assert (subgraph[0][1][0] == (- 1))\n    assert (len(subgraph[0][2]) == out_size[0])\n    for child in subgraph[0][2]:\n        assert (child in tree_graph.node_ids_to_ilocs(['0', 1, 2]))\n    assert (len(subgraph[0][3]) == (in_size[0] * in_size[1]))\n    assert (subgraph[0][3][0] == (- 1))\n    assert (len(subgraph[0][4]) == (in_size[0] * out_size[1]))\n    for child in subgraph[0][4]:\n        assert (child == (- 1))\n    assert (len(subgraph[0][5]) == (out_size[0] * in_size[1]))\n    for parent in subgraph[0][5]:\n        assert (parent == tree_graph.node_ids_to_ilocs(['root'])[0])\n    assert (len(subgraph[0][6]) == (out_size[0] * out_size[1]))\n    for grandchild in subgraph[0][6]:\n        assert ((grandchild in tree_graph.node_ids_to_ilocs(['c1.1', 'c2.1', 'c2.2'])) or (grandchild == (- 1)))\n    for (idx, child) in enumerate(subgraph[0][2]):\n        grandchildren = subgraph[0][6][(2 * idx):((2 * idx) + 2)]\n        if (child == tree_graph.node_ids_to_ilocs(['0'])[0]):\n            for grandchild in grandchildren:\n                assert (grandchild == (- 1))\n        elif (child == tree_graph.node_ids_to_ilocs([1])[0]):\n            for grandchild in grandchildren:\n                assert (grandchild == tree_graph.node_ids_to_ilocs(['c1.1'])[0])\n        else:\n            for grandchild in grandchildren:\n                assert (grandchild in tree_graph.node_ids_to_ilocs(['c2.1', 'c2.2']))\n    nodes = tree_graph.node_ids_to_ilocs(list(tree_graph.nodes()))\n    in_size = [2, 3]\n    out_size = [4, 5]\n    subgraph = bfw.run(nodes=nodes, n=1, in_size=in_size, out_size=out_size)\n    assert (len(subgraph) == len(nodes))\n    for node_graph in subgraph:\n        assert (len(node_graph) == 7)\n        assert (len(node_graph[0]) == 1)\n        assert (len(node_graph[1]) == in_size[0])\n        assert (len(node_graph[2]) == out_size[0])\n        assert (len(node_graph[3]) == (in_size[0] * in_size[1]))\n        assert (len(node_graph[4]) == (in_size[0] * out_size[1]))\n        assert (len(node_graph[5]) == (out_size[0] * in_size[1]))\n        assert (len(node_graph[6]) == (out_size[0] * out_size[1]))", "ground_truth": "in_size[0]", "quality_analysis": {"complexity_score": 17, "left_complexity": 12, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_325", "reponame": "stellargraph", "testpath": "tests/data/test_directed_breadth_first_sampler.py", "testname": "test_directed_breadth_first_sampler.py", "classname": "TestDirectedBreadthFirstNeighbours", "funcname": "test_two_hops", "imports": ["import random", "import pytest", "import pandas as pd", "import numpy as np", "from stellargraph.data.explorer import DirectedBreadthFirstNeighbours", "from stellargraph.core.graph import StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_two_hops(self, tree_graph):\n    bfw = DirectedBreadthFirstNeighbours(tree_graph)\n    in_size = [1, 1]\n    out_size = [2, 2]\n    node_ilocs = tree_graph.node_ids_to_ilocs(['root'])\n    subgraph = bfw.run(nodes=node_ilocs, n=1, in_size=in_size, out_size=out_size)\n    assert (len(subgraph) == 1)\n    assert (len(subgraph[0]) == 7)\n    assert (len(subgraph[0][1]) == in_size[0])\n    assert (subgraph[0][1][0] == (- 1))\n    assert (len(subgraph[0][2]) == out_size[0])\n    for child in subgraph[0][2]:\n        assert (child in tree_graph.node_ids_to_ilocs(['0', 1, 2]))\n    assert (len(subgraph[0][3]) == (in_size[0] * in_size[1]))\n    assert (subgraph[0][3][0] == (- 1))\n    assert (len(subgraph[0][4]) == (in_size[0] * out_size[1]))\n    for child in subgraph[0][4]:\n        assert (child == (- 1))\n    assert (len(subgraph[0][5]) == (out_size[0] * in_size[1]))\n    for parent in subgraph[0][5]:\n        assert (parent == tree_graph.node_ids_to_ilocs(['root'])[0])\n    assert (len(subgraph[0][6]) == (out_size[0] * out_size[1]))\n    for grandchild in subgraph[0][6]:\n        assert ((grandchild in tree_graph.node_ids_to_ilocs(['c1.1', 'c2.1', 'c2.2'])) or (grandchild == (- 1)))\n    for (idx, child) in enumerate(subgraph[0][2]):\n        grandchildren = subgraph[0][6][(2 * idx):((2 * idx) + 2)]\n        if (child == tree_graph.node_ids_to_ilocs(['0'])[0]):\n            for grandchild in grandchildren:\n                assert (grandchild == (- 1))\n        elif (child == tree_graph.node_ids_to_ilocs([1])[0]):\n            for grandchild in grandchildren:\n                assert (grandchild == tree_graph.node_ids_to_ilocs(['c1.1'])[0])\n        else:\n            for grandchild in grandchildren:\n                assert (grandchild in tree_graph.node_ids_to_ilocs(['c2.1', 'c2.2']))\n    nodes = tree_graph.node_ids_to_ilocs(list(tree_graph.nodes()))\n    in_size = [2, 3]\n    out_size = [4, 5]\n    subgraph = bfw.run(nodes=nodes, n=1, in_size=in_size, out_size=out_size)\n    assert (len(subgraph) == len(nodes))\n    for node_graph in subgraph:\n        assert (len(node_graph) == 7)\n        assert (len(node_graph[0]) == 1)\n        assert (len(node_graph[1]) == in_size[0])\n        assert (len(node_graph[2]) == out_size[0])\n        assert (len(node_graph[3]) == (in_size[0] * in_size[1]))\n        assert (len(node_graph[4]) == (in_size[0] * out_size[1]))\n        assert (len(node_graph[5]) == (out_size[0] * in_size[1]))\n        assert (len(node_graph[6]) == (out_size[0] * out_size[1]))", "masked_code": "def test_two_hops(self, tree_graph):\n    bfw = DirectedBreadthFirstNeighbours(tree_graph)\n    in_size = [1, 1]\n    out_size = [2, 2]\n    node_ilocs = tree_graph.node_ids_to_ilocs(['root'])\n    subgraph = bfw.run(nodes=node_ilocs, n=1, in_size=in_size, out_size=out_size)\n    assert (len(subgraph) == 1)\n    assert (len(subgraph[0]) == 7)\n    assert (len(subgraph[0][1]) == in_size[0])\n    assert (subgraph[0][1][0] == '???')\n    assert (len(subgraph[0][2]) == out_size[0])\n    for child in subgraph[0][2]:\n        assert (child in tree_graph.node_ids_to_ilocs(['0', 1, 2]))\n    assert (len(subgraph[0][3]) == (in_size[0] * in_size[1]))\n    assert (subgraph[0][3][0] == (- 1))\n    assert (len(subgraph[0][4]) == (in_size[0] * out_size[1]))\n    for child in subgraph[0][4]:\n        assert (child == (- 1))\n    assert (len(subgraph[0][5]) == (out_size[0] * in_size[1]))\n    for parent in subgraph[0][5]:\n        assert (parent == tree_graph.node_ids_to_ilocs(['root'])[0])\n    assert (len(subgraph[0][6]) == (out_size[0] * out_size[1]))\n    for grandchild in subgraph[0][6]:\n        assert ((grandchild in tree_graph.node_ids_to_ilocs(['c1.1', 'c2.1', 'c2.2'])) or (grandchild == (- 1)))\n    for (idx, child) in enumerate(subgraph[0][2]):\n        grandchildren = subgraph[0][6][(2 * idx):((2 * idx) + 2)]\n        if (child == tree_graph.node_ids_to_ilocs(['0'])[0]):\n            for grandchild in grandchildren:\n                assert (grandchild == (- 1))\n        elif (child == tree_graph.node_ids_to_ilocs([1])[0]):\n            for grandchild in grandchildren:\n                assert (grandchild == tree_graph.node_ids_to_ilocs(['c1.1'])[0])\n        else:\n            for grandchild in grandchildren:\n                assert (grandchild in tree_graph.node_ids_to_ilocs(['c2.1', 'c2.2']))\n    nodes = tree_graph.node_ids_to_ilocs(list(tree_graph.nodes()))\n    in_size = [2, 3]\n    out_size = [4, 5]\n    subgraph = bfw.run(nodes=nodes, n=1, in_size=in_size, out_size=out_size)\n    assert (len(subgraph) == len(nodes))\n    for node_graph in subgraph:\n        assert (len(node_graph) == 7)\n        assert (len(node_graph[0]) == 1)\n        assert (len(node_graph[1]) == in_size[0])\n        assert (len(node_graph[2]) == out_size[0])\n        assert (len(node_graph[3]) == (in_size[0] * in_size[1]))\n        assert (len(node_graph[4]) == (in_size[0] * out_size[1]))\n        assert (len(node_graph[5]) == (out_size[0] * in_size[1]))\n        assert (len(node_graph[6]) == (out_size[0] * out_size[1]))", "ground_truth": "(- 1)", "quality_analysis": {"complexity_score": 16, "left_complexity": 13, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_326", "reponame": "stellargraph", "testpath": "tests/data/test_directed_breadth_first_sampler.py", "testname": "test_directed_breadth_first_sampler.py", "classname": "TestDirectedBreadthFirstNeighbours", "funcname": "test_two_hops", "imports": ["import random", "import pytest", "import pandas as pd", "import numpy as np", "from stellargraph.data.explorer import DirectedBreadthFirstNeighbours", "from stellargraph.core.graph import StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_two_hops(self, tree_graph):\n    bfw = DirectedBreadthFirstNeighbours(tree_graph)\n    in_size = [1, 1]\n    out_size = [2, 2]\n    node_ilocs = tree_graph.node_ids_to_ilocs(['root'])\n    subgraph = bfw.run(nodes=node_ilocs, n=1, in_size=in_size, out_size=out_size)\n    assert (len(subgraph) == 1)\n    assert (len(subgraph[0]) == 7)\n    assert (len(subgraph[0][1]) == in_size[0])\n    assert (subgraph[0][1][0] == (- 1))\n    assert (len(subgraph[0][2]) == out_size[0])\n    for child in subgraph[0][2]:\n        assert (child in tree_graph.node_ids_to_ilocs(['0', 1, 2]))\n    assert (len(subgraph[0][3]) == (in_size[0] * in_size[1]))\n    assert (subgraph[0][3][0] == (- 1))\n    assert (len(subgraph[0][4]) == (in_size[0] * out_size[1]))\n    for child in subgraph[0][4]:\n        assert (child == (- 1))\n    assert (len(subgraph[0][5]) == (out_size[0] * in_size[1]))\n    for parent in subgraph[0][5]:\n        assert (parent == tree_graph.node_ids_to_ilocs(['root'])[0])\n    assert (len(subgraph[0][6]) == (out_size[0] * out_size[1]))\n    for grandchild in subgraph[0][6]:\n        assert ((grandchild in tree_graph.node_ids_to_ilocs(['c1.1', 'c2.1', 'c2.2'])) or (grandchild == (- 1)))\n    for (idx, child) in enumerate(subgraph[0][2]):\n        grandchildren = subgraph[0][6][(2 * idx):((2 * idx) + 2)]\n        if (child == tree_graph.node_ids_to_ilocs(['0'])[0]):\n            for grandchild in grandchildren:\n                assert (grandchild == (- 1))\n        elif (child == tree_graph.node_ids_to_ilocs([1])[0]):\n            for grandchild in grandchildren:\n                assert (grandchild == tree_graph.node_ids_to_ilocs(['c1.1'])[0])\n        else:\n            for grandchild in grandchildren:\n                assert (grandchild in tree_graph.node_ids_to_ilocs(['c2.1', 'c2.2']))\n    nodes = tree_graph.node_ids_to_ilocs(list(tree_graph.nodes()))\n    in_size = [2, 3]\n    out_size = [4, 5]\n    subgraph = bfw.run(nodes=nodes, n=1, in_size=in_size, out_size=out_size)\n    assert (len(subgraph) == len(nodes))\n    for node_graph in subgraph:\n        assert (len(node_graph) == 7)\n        assert (len(node_graph[0]) == 1)\n        assert (len(node_graph[1]) == in_size[0])\n        assert (len(node_graph[2]) == out_size[0])\n        assert (len(node_graph[3]) == (in_size[0] * in_size[1]))\n        assert (len(node_graph[4]) == (in_size[0] * out_size[1]))\n        assert (len(node_graph[5]) == (out_size[0] * in_size[1]))\n        assert (len(node_graph[6]) == (out_size[0] * out_size[1]))", "masked_code": "def test_two_hops(self, tree_graph):\n    bfw = DirectedBreadthFirstNeighbours(tree_graph)\n    in_size = [1, 1]\n    out_size = [2, 2]\n    node_ilocs = tree_graph.node_ids_to_ilocs(['root'])\n    subgraph = bfw.run(nodes=node_ilocs, n=1, in_size=in_size, out_size=out_size)\n    assert (len(subgraph) == 1)\n    assert (len(subgraph[0]) == 7)\n    assert (len(subgraph[0][1]) == in_size[0])\n    assert (subgraph[0][1][0] == (- 1))\n    assert (len(subgraph[0][2]) == '???')\n    for child in subgraph[0][2]:\n        assert (child in tree_graph.node_ids_to_ilocs(['0', 1, 2]))\n    assert (len(subgraph[0][3]) == (in_size[0] * in_size[1]))\n    assert (subgraph[0][3][0] == (- 1))\n    assert (len(subgraph[0][4]) == (in_size[0] * out_size[1]))\n    for child in subgraph[0][4]:\n        assert (child == (- 1))\n    assert (len(subgraph[0][5]) == (out_size[0] * in_size[1]))\n    for parent in subgraph[0][5]:\n        assert (parent == tree_graph.node_ids_to_ilocs(['root'])[0])\n    assert (len(subgraph[0][6]) == (out_size[0] * out_size[1]))\n    for grandchild in subgraph[0][6]:\n        assert ((grandchild in tree_graph.node_ids_to_ilocs(['c1.1', 'c2.1', 'c2.2'])) or (grandchild == (- 1)))\n    for (idx, child) in enumerate(subgraph[0][2]):\n        grandchildren = subgraph[0][6][(2 * idx):((2 * idx) + 2)]\n        if (child == tree_graph.node_ids_to_ilocs(['0'])[0]):\n            for grandchild in grandchildren:\n                assert (grandchild == (- 1))\n        elif (child == tree_graph.node_ids_to_ilocs([1])[0]):\n            for grandchild in grandchildren:\n                assert (grandchild == tree_graph.node_ids_to_ilocs(['c1.1'])[0])\n        else:\n            for grandchild in grandchildren:\n                assert (grandchild in tree_graph.node_ids_to_ilocs(['c2.1', 'c2.2']))\n    nodes = tree_graph.node_ids_to_ilocs(list(tree_graph.nodes()))\n    in_size = [2, 3]\n    out_size = [4, 5]\n    subgraph = bfw.run(nodes=nodes, n=1, in_size=in_size, out_size=out_size)\n    assert (len(subgraph) == len(nodes))\n    for node_graph in subgraph:\n        assert (len(node_graph) == 7)\n        assert (len(node_graph[0]) == 1)\n        assert (len(node_graph[1]) == in_size[0])\n        assert (len(node_graph[2]) == out_size[0])\n        assert (len(node_graph[3]) == (in_size[0] * in_size[1]))\n        assert (len(node_graph[4]) == (in_size[0] * out_size[1]))\n        assert (len(node_graph[5]) == (out_size[0] * in_size[1]))\n        assert (len(node_graph[6]) == (out_size[0] * out_size[1]))", "ground_truth": "out_size[0]", "quality_analysis": {"complexity_score": 17, "left_complexity": 12, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_327", "reponame": "stellargraph", "testpath": "tests/data/test_directed_breadth_first_sampler.py", "testname": "test_directed_breadth_first_sampler.py", "classname": "TestDirectedBreadthFirstNeighbours", "funcname": "test_two_hops", "imports": ["import random", "import pytest", "import pandas as pd", "import numpy as np", "from stellargraph.data.explorer import DirectedBreadthFirstNeighbours", "from stellargraph.core.graph import StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_two_hops(self, tree_graph):\n    bfw = DirectedBreadthFirstNeighbours(tree_graph)\n    in_size = [1, 1]\n    out_size = [2, 2]\n    node_ilocs = tree_graph.node_ids_to_ilocs(['root'])\n    subgraph = bfw.run(nodes=node_ilocs, n=1, in_size=in_size, out_size=out_size)\n    assert (len(subgraph) == 1)\n    assert (len(subgraph[0]) == 7)\n    assert (len(subgraph[0][1]) == in_size[0])\n    assert (subgraph[0][1][0] == (- 1))\n    assert (len(subgraph[0][2]) == out_size[0])\n    for child in subgraph[0][2]:\n        assert (child in tree_graph.node_ids_to_ilocs(['0', 1, 2]))\n    assert (len(subgraph[0][3]) == (in_size[0] * in_size[1]))\n    assert (subgraph[0][3][0] == (- 1))\n    assert (len(subgraph[0][4]) == (in_size[0] * out_size[1]))\n    for child in subgraph[0][4]:\n        assert (child == (- 1))\n    assert (len(subgraph[0][5]) == (out_size[0] * in_size[1]))\n    for parent in subgraph[0][5]:\n        assert (parent == tree_graph.node_ids_to_ilocs(['root'])[0])\n    assert (len(subgraph[0][6]) == (out_size[0] * out_size[1]))\n    for grandchild in subgraph[0][6]:\n        assert ((grandchild in tree_graph.node_ids_to_ilocs(['c1.1', 'c2.1', 'c2.2'])) or (grandchild == (- 1)))\n    for (idx, child) in enumerate(subgraph[0][2]):\n        grandchildren = subgraph[0][6][(2 * idx):((2 * idx) + 2)]\n        if (child == tree_graph.node_ids_to_ilocs(['0'])[0]):\n            for grandchild in grandchildren:\n                assert (grandchild == (- 1))\n        elif (child == tree_graph.node_ids_to_ilocs([1])[0]):\n            for grandchild in grandchildren:\n                assert (grandchild == tree_graph.node_ids_to_ilocs(['c1.1'])[0])\n        else:\n            for grandchild in grandchildren:\n                assert (grandchild in tree_graph.node_ids_to_ilocs(['c2.1', 'c2.2']))\n    nodes = tree_graph.node_ids_to_ilocs(list(tree_graph.nodes()))\n    in_size = [2, 3]\n    out_size = [4, 5]\n    subgraph = bfw.run(nodes=nodes, n=1, in_size=in_size, out_size=out_size)\n    assert (len(subgraph) == len(nodes))\n    for node_graph in subgraph:\n        assert (len(node_graph) == 7)\n        assert (len(node_graph[0]) == 1)\n        assert (len(node_graph[1]) == in_size[0])\n        assert (len(node_graph[2]) == out_size[0])\n        assert (len(node_graph[3]) == (in_size[0] * in_size[1]))\n        assert (len(node_graph[4]) == (in_size[0] * out_size[1]))\n        assert (len(node_graph[5]) == (out_size[0] * in_size[1]))\n        assert (len(node_graph[6]) == (out_size[0] * out_size[1]))", "masked_code": "def test_two_hops(self, tree_graph):\n    bfw = DirectedBreadthFirstNeighbours(tree_graph)\n    in_size = [1, 1]\n    out_size = [2, 2]\n    node_ilocs = tree_graph.node_ids_to_ilocs(['root'])\n    subgraph = bfw.run(nodes=node_ilocs, n=1, in_size=in_size, out_size=out_size)\n    assert (len(subgraph) == 1)\n    assert (len(subgraph[0]) == 7)\n    assert (len(subgraph[0][1]) == in_size[0])\n    assert (subgraph[0][1][0] == (- 1))\n    assert (len(subgraph[0][2]) == out_size[0])\n    for child in subgraph[0][2]:\n        assert (child in tree_graph.node_ids_to_ilocs(['0', 1, 2]))\n    assert (len(subgraph[0][3]) == '???')\n    assert (subgraph[0][3][0] == (- 1))\n    assert (len(subgraph[0][4]) == (in_size[0] * out_size[1]))\n    for child in subgraph[0][4]:\n        assert (child == (- 1))\n    assert (len(subgraph[0][5]) == (out_size[0] * in_size[1]))\n    for parent in subgraph[0][5]:\n        assert (parent == tree_graph.node_ids_to_ilocs(['root'])[0])\n    assert (len(subgraph[0][6]) == (out_size[0] * out_size[1]))\n    for grandchild in subgraph[0][6]:\n        assert ((grandchild in tree_graph.node_ids_to_ilocs(['c1.1', 'c2.1', 'c2.2'])) or (grandchild == (- 1)))\n    for (idx, child) in enumerate(subgraph[0][2]):\n        grandchildren = subgraph[0][6][(2 * idx):((2 * idx) + 2)]\n        if (child == tree_graph.node_ids_to_ilocs(['0'])[0]):\n            for grandchild in grandchildren:\n                assert (grandchild == (- 1))\n        elif (child == tree_graph.node_ids_to_ilocs([1])[0]):\n            for grandchild in grandchildren:\n                assert (grandchild == tree_graph.node_ids_to_ilocs(['c1.1'])[0])\n        else:\n            for grandchild in grandchildren:\n                assert (grandchild in tree_graph.node_ids_to_ilocs(['c2.1', 'c2.2']))\n    nodes = tree_graph.node_ids_to_ilocs(list(tree_graph.nodes()))\n    in_size = [2, 3]\n    out_size = [4, 5]\n    subgraph = bfw.run(nodes=nodes, n=1, in_size=in_size, out_size=out_size)\n    assert (len(subgraph) == len(nodes))\n    for node_graph in subgraph:\n        assert (len(node_graph) == 7)\n        assert (len(node_graph[0]) == 1)\n        assert (len(node_graph[1]) == in_size[0])\n        assert (len(node_graph[2]) == out_size[0])\n        assert (len(node_graph[3]) == (in_size[0] * in_size[1]))\n        assert (len(node_graph[4]) == (in_size[0] * out_size[1]))\n        assert (len(node_graph[5]) == (out_size[0] * in_size[1]))\n        assert (len(node_graph[6]) == (out_size[0] * out_size[1]))", "ground_truth": "(in_size[0] * in_size[1])", "quality_analysis": {"complexity_score": 24, "left_complexity": 12, "right_complexity": 12, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_328", "reponame": "stellargraph", "testpath": "tests/data/test_directed_breadth_first_sampler.py", "testname": "test_directed_breadth_first_sampler.py", "classname": "TestDirectedBreadthFirstNeighbours", "funcname": "test_two_hops", "imports": ["import random", "import pytest", "import pandas as pd", "import numpy as np", "from stellargraph.data.explorer import DirectedBreadthFirstNeighbours", "from stellargraph.core.graph import StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_two_hops(self, tree_graph):\n    bfw = DirectedBreadthFirstNeighbours(tree_graph)\n    in_size = [1, 1]\n    out_size = [2, 2]\n    node_ilocs = tree_graph.node_ids_to_ilocs(['root'])\n    subgraph = bfw.run(nodes=node_ilocs, n=1, in_size=in_size, out_size=out_size)\n    assert (len(subgraph) == 1)\n    assert (len(subgraph[0]) == 7)\n    assert (len(subgraph[0][1]) == in_size[0])\n    assert (subgraph[0][1][0] == (- 1))\n    assert (len(subgraph[0][2]) == out_size[0])\n    for child in subgraph[0][2]:\n        assert (child in tree_graph.node_ids_to_ilocs(['0', 1, 2]))\n    assert (len(subgraph[0][3]) == (in_size[0] * in_size[1]))\n    assert (subgraph[0][3][0] == (- 1))\n    assert (len(subgraph[0][4]) == (in_size[0] * out_size[1]))\n    for child in subgraph[0][4]:\n        assert (child == (- 1))\n    assert (len(subgraph[0][5]) == (out_size[0] * in_size[1]))\n    for parent in subgraph[0][5]:\n        assert (parent == tree_graph.node_ids_to_ilocs(['root'])[0])\n    assert (len(subgraph[0][6]) == (out_size[0] * out_size[1]))\n    for grandchild in subgraph[0][6]:\n        assert ((grandchild in tree_graph.node_ids_to_ilocs(['c1.1', 'c2.1', 'c2.2'])) or (grandchild == (- 1)))\n    for (idx, child) in enumerate(subgraph[0][2]):\n        grandchildren = subgraph[0][6][(2 * idx):((2 * idx) + 2)]\n        if (child == tree_graph.node_ids_to_ilocs(['0'])[0]):\n            for grandchild in grandchildren:\n                assert (grandchild == (- 1))\n        elif (child == tree_graph.node_ids_to_ilocs([1])[0]):\n            for grandchild in grandchildren:\n                assert (grandchild == tree_graph.node_ids_to_ilocs(['c1.1'])[0])\n        else:\n            for grandchild in grandchildren:\n                assert (grandchild in tree_graph.node_ids_to_ilocs(['c2.1', 'c2.2']))\n    nodes = tree_graph.node_ids_to_ilocs(list(tree_graph.nodes()))\n    in_size = [2, 3]\n    out_size = [4, 5]\n    subgraph = bfw.run(nodes=nodes, n=1, in_size=in_size, out_size=out_size)\n    assert (len(subgraph) == len(nodes))\n    for node_graph in subgraph:\n        assert (len(node_graph) == 7)\n        assert (len(node_graph[0]) == 1)\n        assert (len(node_graph[1]) == in_size[0])\n        assert (len(node_graph[2]) == out_size[0])\n        assert (len(node_graph[3]) == (in_size[0] * in_size[1]))\n        assert (len(node_graph[4]) == (in_size[0] * out_size[1]))\n        assert (len(node_graph[5]) == (out_size[0] * in_size[1]))\n        assert (len(node_graph[6]) == (out_size[0] * out_size[1]))", "masked_code": "def test_two_hops(self, tree_graph):\n    bfw = DirectedBreadthFirstNeighbours(tree_graph)\n    in_size = [1, 1]\n    out_size = [2, 2]\n    node_ilocs = tree_graph.node_ids_to_ilocs(['root'])\n    subgraph = bfw.run(nodes=node_ilocs, n=1, in_size=in_size, out_size=out_size)\n    assert (len(subgraph) == 1)\n    assert (len(subgraph[0]) == 7)\n    assert (len(subgraph[0][1]) == in_size[0])\n    assert (subgraph[0][1][0] == (- 1))\n    assert (len(subgraph[0][2]) == out_size[0])\n    for child in subgraph[0][2]:\n        assert (child in tree_graph.node_ids_to_ilocs(['0', 1, 2]))\n    assert (len(subgraph[0][3]) == (in_size[0] * in_size[1]))\n    assert (subgraph[0][3][0] == '???')\n    assert (len(subgraph[0][4]) == (in_size[0] * out_size[1]))\n    for child in subgraph[0][4]:\n        assert (child == (- 1))\n    assert (len(subgraph[0][5]) == (out_size[0] * in_size[1]))\n    for parent in subgraph[0][5]:\n        assert (parent == tree_graph.node_ids_to_ilocs(['root'])[0])\n    assert (len(subgraph[0][6]) == (out_size[0] * out_size[1]))\n    for grandchild in subgraph[0][6]:\n        assert ((grandchild in tree_graph.node_ids_to_ilocs(['c1.1', 'c2.1', 'c2.2'])) or (grandchild == (- 1)))\n    for (idx, child) in enumerate(subgraph[0][2]):\n        grandchildren = subgraph[0][6][(2 * idx):((2 * idx) + 2)]\n        if (child == tree_graph.node_ids_to_ilocs(['0'])[0]):\n            for grandchild in grandchildren:\n                assert (grandchild == (- 1))\n        elif (child == tree_graph.node_ids_to_ilocs([1])[0]):\n            for grandchild in grandchildren:\n                assert (grandchild == tree_graph.node_ids_to_ilocs(['c1.1'])[0])\n        else:\n            for grandchild in grandchildren:\n                assert (grandchild in tree_graph.node_ids_to_ilocs(['c2.1', 'c2.2']))\n    nodes = tree_graph.node_ids_to_ilocs(list(tree_graph.nodes()))\n    in_size = [2, 3]\n    out_size = [4, 5]\n    subgraph = bfw.run(nodes=nodes, n=1, in_size=in_size, out_size=out_size)\n    assert (len(subgraph) == len(nodes))\n    for node_graph in subgraph:\n        assert (len(node_graph) == 7)\n        assert (len(node_graph[0]) == 1)\n        assert (len(node_graph[1]) == in_size[0])\n        assert (len(node_graph[2]) == out_size[0])\n        assert (len(node_graph[3]) == (in_size[0] * in_size[1]))\n        assert (len(node_graph[4]) == (in_size[0] * out_size[1]))\n        assert (len(node_graph[5]) == (out_size[0] * in_size[1]))\n        assert (len(node_graph[6]) == (out_size[0] * out_size[1]))", "ground_truth": "(- 1)", "quality_analysis": {"complexity_score": 16, "left_complexity": 13, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_329", "reponame": "stellargraph", "testpath": "tests/data/test_directed_breadth_first_sampler.py", "testname": "test_directed_breadth_first_sampler.py", "classname": "TestDirectedBreadthFirstNeighbours", "funcname": "test_two_hops", "imports": ["import random", "import pytest", "import pandas as pd", "import numpy as np", "from stellargraph.data.explorer import DirectedBreadthFirstNeighbours", "from stellargraph.core.graph import StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_two_hops(self, tree_graph):\n    bfw = DirectedBreadthFirstNeighbours(tree_graph)\n    in_size = [1, 1]\n    out_size = [2, 2]\n    node_ilocs = tree_graph.node_ids_to_ilocs(['root'])\n    subgraph = bfw.run(nodes=node_ilocs, n=1, in_size=in_size, out_size=out_size)\n    assert (len(subgraph) == 1)\n    assert (len(subgraph[0]) == 7)\n    assert (len(subgraph[0][1]) == in_size[0])\n    assert (subgraph[0][1][0] == (- 1))\n    assert (len(subgraph[0][2]) == out_size[0])\n    for child in subgraph[0][2]:\n        assert (child in tree_graph.node_ids_to_ilocs(['0', 1, 2]))\n    assert (len(subgraph[0][3]) == (in_size[0] * in_size[1]))\n    assert (subgraph[0][3][0] == (- 1))\n    assert (len(subgraph[0][4]) == (in_size[0] * out_size[1]))\n    for child in subgraph[0][4]:\n        assert (child == (- 1))\n    assert (len(subgraph[0][5]) == (out_size[0] * in_size[1]))\n    for parent in subgraph[0][5]:\n        assert (parent == tree_graph.node_ids_to_ilocs(['root'])[0])\n    assert (len(subgraph[0][6]) == (out_size[0] * out_size[1]))\n    for grandchild in subgraph[0][6]:\n        assert ((grandchild in tree_graph.node_ids_to_ilocs(['c1.1', 'c2.1', 'c2.2'])) or (grandchild == (- 1)))\n    for (idx, child) in enumerate(subgraph[0][2]):\n        grandchildren = subgraph[0][6][(2 * idx):((2 * idx) + 2)]\n        if (child == tree_graph.node_ids_to_ilocs(['0'])[0]):\n            for grandchild in grandchildren:\n                assert (grandchild == (- 1))\n        elif (child == tree_graph.node_ids_to_ilocs([1])[0]):\n            for grandchild in grandchildren:\n                assert (grandchild == tree_graph.node_ids_to_ilocs(['c1.1'])[0])\n        else:\n            for grandchild in grandchildren:\n                assert (grandchild in tree_graph.node_ids_to_ilocs(['c2.1', 'c2.2']))\n    nodes = tree_graph.node_ids_to_ilocs(list(tree_graph.nodes()))\n    in_size = [2, 3]\n    out_size = [4, 5]\n    subgraph = bfw.run(nodes=nodes, n=1, in_size=in_size, out_size=out_size)\n    assert (len(subgraph) == len(nodes))\n    for node_graph in subgraph:\n        assert (len(node_graph) == 7)\n        assert (len(node_graph[0]) == 1)\n        assert (len(node_graph[1]) == in_size[0])\n        assert (len(node_graph[2]) == out_size[0])\n        assert (len(node_graph[3]) == (in_size[0] * in_size[1]))\n        assert (len(node_graph[4]) == (in_size[0] * out_size[1]))\n        assert (len(node_graph[5]) == (out_size[0] * in_size[1]))\n        assert (len(node_graph[6]) == (out_size[0] * out_size[1]))", "masked_code": "def test_two_hops(self, tree_graph):\n    bfw = DirectedBreadthFirstNeighbours(tree_graph)\n    in_size = [1, 1]\n    out_size = [2, 2]\n    node_ilocs = tree_graph.node_ids_to_ilocs(['root'])\n    subgraph = bfw.run(nodes=node_ilocs, n=1, in_size=in_size, out_size=out_size)\n    assert (len(subgraph) == 1)\n    assert (len(subgraph[0]) == 7)\n    assert (len(subgraph[0][1]) == in_size[0])\n    assert (subgraph[0][1][0] == (- 1))\n    assert (len(subgraph[0][2]) == out_size[0])\n    for child in subgraph[0][2]:\n        assert (child in tree_graph.node_ids_to_ilocs(['0', 1, 2]))\n    assert (len(subgraph[0][3]) == (in_size[0] * in_size[1]))\n    assert (subgraph[0][3][0] == (- 1))\n    assert (len(subgraph[0][4]) == '???')\n    for child in subgraph[0][4]:\n        assert (child == (- 1))\n    assert (len(subgraph[0][5]) == (out_size[0] * in_size[1]))\n    for parent in subgraph[0][5]:\n        assert (parent == tree_graph.node_ids_to_ilocs(['root'])[0])\n    assert (len(subgraph[0][6]) == (out_size[0] * out_size[1]))\n    for grandchild in subgraph[0][6]:\n        assert ((grandchild in tree_graph.node_ids_to_ilocs(['c1.1', 'c2.1', 'c2.2'])) or (grandchild == (- 1)))\n    for (idx, child) in enumerate(subgraph[0][2]):\n        grandchildren = subgraph[0][6][(2 * idx):((2 * idx) + 2)]\n        if (child == tree_graph.node_ids_to_ilocs(['0'])[0]):\n            for grandchild in grandchildren:\n                assert (grandchild == (- 1))\n        elif (child == tree_graph.node_ids_to_ilocs([1])[0]):\n            for grandchild in grandchildren:\n                assert (grandchild == tree_graph.node_ids_to_ilocs(['c1.1'])[0])\n        else:\n            for grandchild in grandchildren:\n                assert (grandchild in tree_graph.node_ids_to_ilocs(['c2.1', 'c2.2']))\n    nodes = tree_graph.node_ids_to_ilocs(list(tree_graph.nodes()))\n    in_size = [2, 3]\n    out_size = [4, 5]\n    subgraph = bfw.run(nodes=nodes, n=1, in_size=in_size, out_size=out_size)\n    assert (len(subgraph) == len(nodes))\n    for node_graph in subgraph:\n        assert (len(node_graph) == 7)\n        assert (len(node_graph[0]) == 1)\n        assert (len(node_graph[1]) == in_size[0])\n        assert (len(node_graph[2]) == out_size[0])\n        assert (len(node_graph[3]) == (in_size[0] * in_size[1]))\n        assert (len(node_graph[4]) == (in_size[0] * out_size[1]))\n        assert (len(node_graph[5]) == (out_size[0] * in_size[1]))\n        assert (len(node_graph[6]) == (out_size[0] * out_size[1]))", "ground_truth": "(in_size[0] * out_size[1])", "quality_analysis": {"complexity_score": 24, "left_complexity": 12, "right_complexity": 12, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_330", "reponame": "stellargraph", "testpath": "tests/data/test_directed_breadth_first_sampler.py", "testname": "test_directed_breadth_first_sampler.py", "classname": "TestDirectedBreadthFirstNeighbours", "funcname": "test_two_hops", "imports": ["import random", "import pytest", "import pandas as pd", "import numpy as np", "from stellargraph.data.explorer import DirectedBreadthFirstNeighbours", "from stellargraph.core.graph import StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_two_hops(self, tree_graph):\n    bfw = DirectedBreadthFirstNeighbours(tree_graph)\n    in_size = [1, 1]\n    out_size = [2, 2]\n    node_ilocs = tree_graph.node_ids_to_ilocs(['root'])\n    subgraph = bfw.run(nodes=node_ilocs, n=1, in_size=in_size, out_size=out_size)\n    assert (len(subgraph) == 1)\n    assert (len(subgraph[0]) == 7)\n    assert (len(subgraph[0][1]) == in_size[0])\n    assert (subgraph[0][1][0] == (- 1))\n    assert (len(subgraph[0][2]) == out_size[0])\n    for child in subgraph[0][2]:\n        assert (child in tree_graph.node_ids_to_ilocs(['0', 1, 2]))\n    assert (len(subgraph[0][3]) == (in_size[0] * in_size[1]))\n    assert (subgraph[0][3][0] == (- 1))\n    assert (len(subgraph[0][4]) == (in_size[0] * out_size[1]))\n    for child in subgraph[0][4]:\n        assert (child == (- 1))\n    assert (len(subgraph[0][5]) == (out_size[0] * in_size[1]))\n    for parent in subgraph[0][5]:\n        assert (parent == tree_graph.node_ids_to_ilocs(['root'])[0])\n    assert (len(subgraph[0][6]) == (out_size[0] * out_size[1]))\n    for grandchild in subgraph[0][6]:\n        assert ((grandchild in tree_graph.node_ids_to_ilocs(['c1.1', 'c2.1', 'c2.2'])) or (grandchild == (- 1)))\n    for (idx, child) in enumerate(subgraph[0][2]):\n        grandchildren = subgraph[0][6][(2 * idx):((2 * idx) + 2)]\n        if (child == tree_graph.node_ids_to_ilocs(['0'])[0]):\n            for grandchild in grandchildren:\n                assert (grandchild == (- 1))\n        elif (child == tree_graph.node_ids_to_ilocs([1])[0]):\n            for grandchild in grandchildren:\n                assert (grandchild == tree_graph.node_ids_to_ilocs(['c1.1'])[0])\n        else:\n            for grandchild in grandchildren:\n                assert (grandchild in tree_graph.node_ids_to_ilocs(['c2.1', 'c2.2']))\n    nodes = tree_graph.node_ids_to_ilocs(list(tree_graph.nodes()))\n    in_size = [2, 3]\n    out_size = [4, 5]\n    subgraph = bfw.run(nodes=nodes, n=1, in_size=in_size, out_size=out_size)\n    assert (len(subgraph) == len(nodes))\n    for node_graph in subgraph:\n        assert (len(node_graph) == 7)\n        assert (len(node_graph[0]) == 1)\n        assert (len(node_graph[1]) == in_size[0])\n        assert (len(node_graph[2]) == out_size[0])\n        assert (len(node_graph[3]) == (in_size[0] * in_size[1]))\n        assert (len(node_graph[4]) == (in_size[0] * out_size[1]))\n        assert (len(node_graph[5]) == (out_size[0] * in_size[1]))\n        assert (len(node_graph[6]) == (out_size[0] * out_size[1]))", "masked_code": "def test_two_hops(self, tree_graph):\n    bfw = DirectedBreadthFirstNeighbours(tree_graph)\n    in_size = [1, 1]\n    out_size = [2, 2]\n    node_ilocs = tree_graph.node_ids_to_ilocs(['root'])\n    subgraph = bfw.run(nodes=node_ilocs, n=1, in_size=in_size, out_size=out_size)\n    assert (len(subgraph) == 1)\n    assert (len(subgraph[0]) == 7)\n    assert (len(subgraph[0][1]) == in_size[0])\n    assert (subgraph[0][1][0] == (- 1))\n    assert (len(subgraph[0][2]) == out_size[0])\n    for child in subgraph[0][2]:\n        assert (child in tree_graph.node_ids_to_ilocs(['0', 1, 2]))\n    assert (len(subgraph[0][3]) == (in_size[0] * in_size[1]))\n    assert (subgraph[0][3][0] == (- 1))\n    assert (len(subgraph[0][4]) == (in_size[0] * out_size[1]))\n    for child in subgraph[0][4]:\n        assert (child == (- 1))\n    assert (len(subgraph[0][5]) == '???')\n    for parent in subgraph[0][5]:\n        assert (parent == tree_graph.node_ids_to_ilocs(['root'])[0])\n    assert (len(subgraph[0][6]) == (out_size[0] * out_size[1]))\n    for grandchild in subgraph[0][6]:\n        assert ((grandchild in tree_graph.node_ids_to_ilocs(['c1.1', 'c2.1', 'c2.2'])) or (grandchild == (- 1)))\n    for (idx, child) in enumerate(subgraph[0][2]):\n        grandchildren = subgraph[0][6][(2 * idx):((2 * idx) + 2)]\n        if (child == tree_graph.node_ids_to_ilocs(['0'])[0]):\n            for grandchild in grandchildren:\n                assert (grandchild == (- 1))\n        elif (child == tree_graph.node_ids_to_ilocs([1])[0]):\n            for grandchild in grandchildren:\n                assert (grandchild == tree_graph.node_ids_to_ilocs(['c1.1'])[0])\n        else:\n            for grandchild in grandchildren:\n                assert (grandchild in tree_graph.node_ids_to_ilocs(['c2.1', 'c2.2']))\n    nodes = tree_graph.node_ids_to_ilocs(list(tree_graph.nodes()))\n    in_size = [2, 3]\n    out_size = [4, 5]\n    subgraph = bfw.run(nodes=nodes, n=1, in_size=in_size, out_size=out_size)\n    assert (len(subgraph) == len(nodes))\n    for node_graph in subgraph:\n        assert (len(node_graph) == 7)\n        assert (len(node_graph[0]) == 1)\n        assert (len(node_graph[1]) == in_size[0])\n        assert (len(node_graph[2]) == out_size[0])\n        assert (len(node_graph[3]) == (in_size[0] * in_size[1]))\n        assert (len(node_graph[4]) == (in_size[0] * out_size[1]))\n        assert (len(node_graph[5]) == (out_size[0] * in_size[1]))\n        assert (len(node_graph[6]) == (out_size[0] * out_size[1]))", "ground_truth": "(out_size[0] * in_size[1])", "quality_analysis": {"complexity_score": 24, "left_complexity": 12, "right_complexity": 12, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_331", "reponame": "stellargraph", "testpath": "tests/data/test_directed_breadth_first_sampler.py", "testname": "test_directed_breadth_first_sampler.py", "classname": "TestDirectedBreadthFirstNeighbours", "funcname": "test_two_hops", "imports": ["import random", "import pytest", "import pandas as pd", "import numpy as np", "from stellargraph.data.explorer import DirectedBreadthFirstNeighbours", "from stellargraph.core.graph import StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_two_hops(self, tree_graph):\n    bfw = DirectedBreadthFirstNeighbours(tree_graph)\n    in_size = [1, 1]\n    out_size = [2, 2]\n    node_ilocs = tree_graph.node_ids_to_ilocs(['root'])\n    subgraph = bfw.run(nodes=node_ilocs, n=1, in_size=in_size, out_size=out_size)\n    assert (len(subgraph) == 1)\n    assert (len(subgraph[0]) == 7)\n    assert (len(subgraph[0][1]) == in_size[0])\n    assert (subgraph[0][1][0] == (- 1))\n    assert (len(subgraph[0][2]) == out_size[0])\n    for child in subgraph[0][2]:\n        assert (child in tree_graph.node_ids_to_ilocs(['0', 1, 2]))\n    assert (len(subgraph[0][3]) == (in_size[0] * in_size[1]))\n    assert (subgraph[0][3][0] == (- 1))\n    assert (len(subgraph[0][4]) == (in_size[0] * out_size[1]))\n    for child in subgraph[0][4]:\n        assert (child == (- 1))\n    assert (len(subgraph[0][5]) == (out_size[0] * in_size[1]))\n    for parent in subgraph[0][5]:\n        assert (parent == tree_graph.node_ids_to_ilocs(['root'])[0])\n    assert (len(subgraph[0][6]) == (out_size[0] * out_size[1]))\n    for grandchild in subgraph[0][6]:\n        assert ((grandchild in tree_graph.node_ids_to_ilocs(['c1.1', 'c2.1', 'c2.2'])) or (grandchild == (- 1)))\n    for (idx, child) in enumerate(subgraph[0][2]):\n        grandchildren = subgraph[0][6][(2 * idx):((2 * idx) + 2)]\n        if (child == tree_graph.node_ids_to_ilocs(['0'])[0]):\n            for grandchild in grandchildren:\n                assert (grandchild == (- 1))\n        elif (child == tree_graph.node_ids_to_ilocs([1])[0]):\n            for grandchild in grandchildren:\n                assert (grandchild == tree_graph.node_ids_to_ilocs(['c1.1'])[0])\n        else:\n            for grandchild in grandchildren:\n                assert (grandchild in tree_graph.node_ids_to_ilocs(['c2.1', 'c2.2']))\n    nodes = tree_graph.node_ids_to_ilocs(list(tree_graph.nodes()))\n    in_size = [2, 3]\n    out_size = [4, 5]\n    subgraph = bfw.run(nodes=nodes, n=1, in_size=in_size, out_size=out_size)\n    assert (len(subgraph) == len(nodes))\n    for node_graph in subgraph:\n        assert (len(node_graph) == 7)\n        assert (len(node_graph[0]) == 1)\n        assert (len(node_graph[1]) == in_size[0])\n        assert (len(node_graph[2]) == out_size[0])\n        assert (len(node_graph[3]) == (in_size[0] * in_size[1]))\n        assert (len(node_graph[4]) == (in_size[0] * out_size[1]))\n        assert (len(node_graph[5]) == (out_size[0] * in_size[1]))\n        assert (len(node_graph[6]) == (out_size[0] * out_size[1]))", "masked_code": "def test_two_hops(self, tree_graph):\n    bfw = DirectedBreadthFirstNeighbours(tree_graph)\n    in_size = [1, 1]\n    out_size = [2, 2]\n    node_ilocs = tree_graph.node_ids_to_ilocs(['root'])\n    subgraph = bfw.run(nodes=node_ilocs, n=1, in_size=in_size, out_size=out_size)\n    assert (len(subgraph) == 1)\n    assert (len(subgraph[0]) == 7)\n    assert (len(subgraph[0][1]) == in_size[0])\n    assert (subgraph[0][1][0] == (- 1))\n    assert (len(subgraph[0][2]) == out_size[0])\n    for child in subgraph[0][2]:\n        assert (child in tree_graph.node_ids_to_ilocs(['0', 1, 2]))\n    assert (len(subgraph[0][3]) == (in_size[0] * in_size[1]))\n    assert (subgraph[0][3][0] == (- 1))\n    assert (len(subgraph[0][4]) == (in_size[0] * out_size[1]))\n    for child in subgraph[0][4]:\n        assert (child == (- 1))\n    assert (len(subgraph[0][5]) == (out_size[0] * in_size[1]))\n    for parent in subgraph[0][5]:\n        assert (parent == tree_graph.node_ids_to_ilocs(['root'])[0])\n    assert (len(subgraph[0][6]) == '???')\n    for grandchild in subgraph[0][6]:\n        assert ((grandchild in tree_graph.node_ids_to_ilocs(['c1.1', 'c2.1', 'c2.2'])) or (grandchild == (- 1)))\n    for (idx, child) in enumerate(subgraph[0][2]):\n        grandchildren = subgraph[0][6][(2 * idx):((2 * idx) + 2)]\n        if (child == tree_graph.node_ids_to_ilocs(['0'])[0]):\n            for grandchild in grandchildren:\n                assert (grandchild == (- 1))\n        elif (child == tree_graph.node_ids_to_ilocs([1])[0]):\n            for grandchild in grandchildren:\n                assert (grandchild == tree_graph.node_ids_to_ilocs(['c1.1'])[0])\n        else:\n            for grandchild in grandchildren:\n                assert (grandchild in tree_graph.node_ids_to_ilocs(['c2.1', 'c2.2']))\n    nodes = tree_graph.node_ids_to_ilocs(list(tree_graph.nodes()))\n    in_size = [2, 3]\n    out_size = [4, 5]\n    subgraph = bfw.run(nodes=nodes, n=1, in_size=in_size, out_size=out_size)\n    assert (len(subgraph) == len(nodes))\n    for node_graph in subgraph:\n        assert (len(node_graph) == 7)\n        assert (len(node_graph[0]) == 1)\n        assert (len(node_graph[1]) == in_size[0])\n        assert (len(node_graph[2]) == out_size[0])\n        assert (len(node_graph[3]) == (in_size[0] * in_size[1]))\n        assert (len(node_graph[4]) == (in_size[0] * out_size[1]))\n        assert (len(node_graph[5]) == (out_size[0] * in_size[1]))\n        assert (len(node_graph[6]) == (out_size[0] * out_size[1]))", "ground_truth": "(out_size[0] * out_size[1])", "quality_analysis": {"complexity_score": 24, "left_complexity": 12, "right_complexity": 12, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_332", "reponame": "stellargraph", "testpath": "tests/data/test_directed_breadth_first_sampler.py", "testname": "test_directed_breadth_first_sampler.py", "classname": "TestDirectedBreadthFirstNeighbours", "funcname": "test_two_hops", "imports": ["import random", "import pytest", "import pandas as pd", "import numpy as np", "from stellargraph.data.explorer import DirectedBreadthFirstNeighbours", "from stellargraph.core.graph import StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_two_hops(self, tree_graph):\n    bfw = DirectedBreadthFirstNeighbours(tree_graph)\n    in_size = [1, 1]\n    out_size = [2, 2]\n    node_ilocs = tree_graph.node_ids_to_ilocs(['root'])\n    subgraph = bfw.run(nodes=node_ilocs, n=1, in_size=in_size, out_size=out_size)\n    assert (len(subgraph) == 1)\n    assert (len(subgraph[0]) == 7)\n    assert (len(subgraph[0][1]) == in_size[0])\n    assert (subgraph[0][1][0] == (- 1))\n    assert (len(subgraph[0][2]) == out_size[0])\n    for child in subgraph[0][2]:\n        assert (child in tree_graph.node_ids_to_ilocs(['0', 1, 2]))\n    assert (len(subgraph[0][3]) == (in_size[0] * in_size[1]))\n    assert (subgraph[0][3][0] == (- 1))\n    assert (len(subgraph[0][4]) == (in_size[0] * out_size[1]))\n    for child in subgraph[0][4]:\n        assert (child == (- 1))\n    assert (len(subgraph[0][5]) == (out_size[0] * in_size[1]))\n    for parent in subgraph[0][5]:\n        assert (parent == tree_graph.node_ids_to_ilocs(['root'])[0])\n    assert (len(subgraph[0][6]) == (out_size[0] * out_size[1]))\n    for grandchild in subgraph[0][6]:\n        assert ((grandchild in tree_graph.node_ids_to_ilocs(['c1.1', 'c2.1', 'c2.2'])) or (grandchild == (- 1)))\n    for (idx, child) in enumerate(subgraph[0][2]):\n        grandchildren = subgraph[0][6][(2 * idx):((2 * idx) + 2)]\n        if (child == tree_graph.node_ids_to_ilocs(['0'])[0]):\n            for grandchild in grandchildren:\n                assert (grandchild == (- 1))\n        elif (child == tree_graph.node_ids_to_ilocs([1])[0]):\n            for grandchild in grandchildren:\n                assert (grandchild == tree_graph.node_ids_to_ilocs(['c1.1'])[0])\n        else:\n            for grandchild in grandchildren:\n                assert (grandchild in tree_graph.node_ids_to_ilocs(['c2.1', 'c2.2']))\n    nodes = tree_graph.node_ids_to_ilocs(list(tree_graph.nodes()))\n    in_size = [2, 3]\n    out_size = [4, 5]\n    subgraph = bfw.run(nodes=nodes, n=1, in_size=in_size, out_size=out_size)\n    assert (len(subgraph) == len(nodes))\n    for node_graph in subgraph:\n        assert (len(node_graph) == 7)\n        assert (len(node_graph[0]) == 1)\n        assert (len(node_graph[1]) == in_size[0])\n        assert (len(node_graph[2]) == out_size[0])\n        assert (len(node_graph[3]) == (in_size[0] * in_size[1]))\n        assert (len(node_graph[4]) == (in_size[0] * out_size[1]))\n        assert (len(node_graph[5]) == (out_size[0] * in_size[1]))\n        assert (len(node_graph[6]) == (out_size[0] * out_size[1]))", "masked_code": "def test_two_hops(self, tree_graph):\n    bfw = DirectedBreadthFirstNeighbours(tree_graph)\n    in_size = [1, 1]\n    out_size = [2, 2]\n    node_ilocs = tree_graph.node_ids_to_ilocs(['root'])\n    subgraph = bfw.run(nodes=node_ilocs, n=1, in_size=in_size, out_size=out_size)\n    assert (len(subgraph) == 1)\n    assert (len(subgraph[0]) == 7)\n    assert (len(subgraph[0][1]) == in_size[0])\n    assert (subgraph[0][1][0] == (- 1))\n    assert (len(subgraph[0][2]) == out_size[0])\n    for child in subgraph[0][2]:\n        assert (child in tree_graph.node_ids_to_ilocs(['0', 1, 2]))\n    assert (len(subgraph[0][3]) == (in_size[0] * in_size[1]))\n    assert (subgraph[0][3][0] == (- 1))\n    assert (len(subgraph[0][4]) == (in_size[0] * out_size[1]))\n    for child in subgraph[0][4]:\n        assert (child == (- 1))\n    assert (len(subgraph[0][5]) == (out_size[0] * in_size[1]))\n    for parent in subgraph[0][5]:\n        assert (parent == tree_graph.node_ids_to_ilocs(['root'])[0])\n    assert (len(subgraph[0][6]) == (out_size[0] * out_size[1]))\n    for grandchild in subgraph[0][6]:\n        assert ((grandchild in tree_graph.node_ids_to_ilocs(['c1.1', 'c2.1', 'c2.2'])) or (grandchild == (- 1)))\n    for (idx, child) in enumerate(subgraph[0][2]):\n        grandchildren = subgraph[0][6][(2 * idx):((2 * idx) + 2)]\n        if (child == tree_graph.node_ids_to_ilocs(['0'])[0]):\n            for grandchild in grandchildren:\n                assert (grandchild == (- 1))\n        elif (child == tree_graph.node_ids_to_ilocs([1])[0]):\n            for grandchild in grandchildren:\n                assert (grandchild == tree_graph.node_ids_to_ilocs(['c1.1'])[0])\n        else:\n            for grandchild in grandchildren:\n                assert (grandchild in tree_graph.node_ids_to_ilocs(['c2.1', 'c2.2']))\n    nodes = tree_graph.node_ids_to_ilocs(list(tree_graph.nodes()))\n    in_size = [2, 3]\n    out_size = [4, 5]\n    subgraph = bfw.run(nodes=nodes, n=1, in_size=in_size, out_size=out_size)\n    assert (len(subgraph) == '???')\n    for node_graph in subgraph:\n        assert (len(node_graph) == 7)\n        assert (len(node_graph[0]) == 1)\n        assert (len(node_graph[1]) == in_size[0])\n        assert (len(node_graph[2]) == out_size[0])\n        assert (len(node_graph[3]) == (in_size[0] * in_size[1]))\n        assert (len(node_graph[4]) == (in_size[0] * out_size[1]))\n        assert (len(node_graph[5]) == (out_size[0] * in_size[1]))\n        assert (len(node_graph[6]) == (out_size[0] * out_size[1]))", "ground_truth": "len(nodes)", "quality_analysis": {"complexity_score": 8, "left_complexity": 4, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_333", "reponame": "stellargraph", "testpath": "tests/data/test_directed_breadth_first_sampler.py", "testname": "test_directed_breadth_first_sampler.py", "classname": "TestDirectedBreadthFirstNeighbours", "funcname": "test_two_hops", "imports": ["import random", "import pytest", "import pandas as pd", "import numpy as np", "from stellargraph.data.explorer import DirectedBreadthFirstNeighbours", "from stellargraph.core.graph import StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_two_hops(self, tree_graph):\n    bfw = DirectedBreadthFirstNeighbours(tree_graph)\n    in_size = [1, 1]\n    out_size = [2, 2]\n    node_ilocs = tree_graph.node_ids_to_ilocs(['root'])\n    subgraph = bfw.run(nodes=node_ilocs, n=1, in_size=in_size, out_size=out_size)\n    assert (len(subgraph) == 1)\n    assert (len(subgraph[0]) == 7)\n    assert (len(subgraph[0][1]) == in_size[0])\n    assert (subgraph[0][1][0] == (- 1))\n    assert (len(subgraph[0][2]) == out_size[0])\n    for child in subgraph[0][2]:\n        assert (child in tree_graph.node_ids_to_ilocs(['0', 1, 2]))\n    assert (len(subgraph[0][3]) == (in_size[0] * in_size[1]))\n    assert (subgraph[0][3][0] == (- 1))\n    assert (len(subgraph[0][4]) == (in_size[0] * out_size[1]))\n    for child in subgraph[0][4]:\n        assert (child == (- 1))\n    assert (len(subgraph[0][5]) == (out_size[0] * in_size[1]))\n    for parent in subgraph[0][5]:\n        assert (parent == tree_graph.node_ids_to_ilocs(['root'])[0])\n    assert (len(subgraph[0][6]) == (out_size[0] * out_size[1]))\n    for grandchild in subgraph[0][6]:\n        assert ((grandchild in tree_graph.node_ids_to_ilocs(['c1.1', 'c2.1', 'c2.2'])) or (grandchild == (- 1)))\n    for (idx, child) in enumerate(subgraph[0][2]):\n        grandchildren = subgraph[0][6][(2 * idx):((2 * idx) + 2)]\n        if (child == tree_graph.node_ids_to_ilocs(['0'])[0]):\n            for grandchild in grandchildren:\n                assert (grandchild == (- 1))\n        elif (child == tree_graph.node_ids_to_ilocs([1])[0]):\n            for grandchild in grandchildren:\n                assert (grandchild == tree_graph.node_ids_to_ilocs(['c1.1'])[0])\n        else:\n            for grandchild in grandchildren:\n                assert (grandchild in tree_graph.node_ids_to_ilocs(['c2.1', 'c2.2']))\n    nodes = tree_graph.node_ids_to_ilocs(list(tree_graph.nodes()))\n    in_size = [2, 3]\n    out_size = [4, 5]\n    subgraph = bfw.run(nodes=nodes, n=1, in_size=in_size, out_size=out_size)\n    assert (len(subgraph) == len(nodes))\n    for node_graph in subgraph:\n        assert (len(node_graph) == 7)\n        assert (len(node_graph[0]) == 1)\n        assert (len(node_graph[1]) == in_size[0])\n        assert (len(node_graph[2]) == out_size[0])\n        assert (len(node_graph[3]) == (in_size[0] * in_size[1]))\n        assert (len(node_graph[4]) == (in_size[0] * out_size[1]))\n        assert (len(node_graph[5]) == (out_size[0] * in_size[1]))\n        assert (len(node_graph[6]) == (out_size[0] * out_size[1]))", "masked_code": "def test_two_hops(self, tree_graph):\n    bfw = DirectedBreadthFirstNeighbours(tree_graph)\n    in_size = [1, 1]\n    out_size = [2, 2]\n    node_ilocs = tree_graph.node_ids_to_ilocs(['root'])\n    subgraph = bfw.run(nodes=node_ilocs, n=1, in_size=in_size, out_size=out_size)\n    assert (len(subgraph) == 1)\n    assert (len(subgraph[0]) == 7)\n    assert (len(subgraph[0][1]) == in_size[0])\n    assert (subgraph[0][1][0] == (- 1))\n    assert (len(subgraph[0][2]) == out_size[0])\n    for child in subgraph[0][2]:\n        assert (child in tree_graph.node_ids_to_ilocs(['0', 1, 2]))\n    assert (len(subgraph[0][3]) == (in_size[0] * in_size[1]))\n    assert (subgraph[0][3][0] == (- 1))\n    assert (len(subgraph[0][4]) == (in_size[0] * out_size[1]))\n    for child in subgraph[0][4]:\n        assert (child == (- 1))\n    assert (len(subgraph[0][5]) == (out_size[0] * in_size[1]))\n    for parent in subgraph[0][5]:\n        assert (parent == tree_graph.node_ids_to_ilocs(['root'])[0])\n    assert (len(subgraph[0][6]) == (out_size[0] * out_size[1]))\n    for grandchild in subgraph[0][6]:\n        assert ((grandchild in tree_graph.node_ids_to_ilocs(['c1.1', 'c2.1', 'c2.2'])) or (grandchild == (- 1)))\n    for (idx, child) in enumerate(subgraph[0][2]):\n        grandchildren = subgraph[0][6][(2 * idx):((2 * idx) + 2)]\n        if (child == tree_graph.node_ids_to_ilocs(['0'])[0]):\n            for grandchild in grandchildren:\n                assert (grandchild == (- 1))\n        elif (child == tree_graph.node_ids_to_ilocs([1])[0]):\n            for grandchild in grandchildren:\n                assert (grandchild == tree_graph.node_ids_to_ilocs(['c1.1'])[0])\n        else:\n            for grandchild in grandchildren:\n                assert (grandchild in tree_graph.node_ids_to_ilocs(['c2.1', 'c2.2']))\n    nodes = tree_graph.node_ids_to_ilocs(list(tree_graph.nodes()))\n    in_size = [2, 3]\n    out_size = [4, 5]\n    subgraph = bfw.run(nodes=nodes, n=1, in_size=in_size, out_size=out_size)\n    assert (len(subgraph) == len(nodes))\n    for node_graph in subgraph:\n        assert (len(node_graph) == '???')\n        assert (len(node_graph[0]) == 1)\n        assert (len(node_graph[1]) == in_size[0])\n        assert (len(node_graph[2]) == out_size[0])\n        assert (len(node_graph[3]) == (in_size[0] * in_size[1]))\n        assert (len(node_graph[4]) == (in_size[0] * out_size[1]))\n        assert (len(node_graph[5]) == (out_size[0] * in_size[1]))\n        assert (len(node_graph[6]) == (out_size[0] * out_size[1]))", "ground_truth": "7", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_334", "reponame": "stellargraph", "testpath": "tests/data/test_directed_breadth_first_sampler.py", "testname": "test_directed_breadth_first_sampler.py", "classname": "TestDirectedBreadthFirstNeighbours", "funcname": "test_two_hops", "imports": ["import random", "import pytest", "import pandas as pd", "import numpy as np", "from stellargraph.data.explorer import DirectedBreadthFirstNeighbours", "from stellargraph.core.graph import StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_two_hops(self, tree_graph):\n    bfw = DirectedBreadthFirstNeighbours(tree_graph)\n    in_size = [1, 1]\n    out_size = [2, 2]\n    node_ilocs = tree_graph.node_ids_to_ilocs(['root'])\n    subgraph = bfw.run(nodes=node_ilocs, n=1, in_size=in_size, out_size=out_size)\n    assert (len(subgraph) == 1)\n    assert (len(subgraph[0]) == 7)\n    assert (len(subgraph[0][1]) == in_size[0])\n    assert (subgraph[0][1][0] == (- 1))\n    assert (len(subgraph[0][2]) == out_size[0])\n    for child in subgraph[0][2]:\n        assert (child in tree_graph.node_ids_to_ilocs(['0', 1, 2]))\n    assert (len(subgraph[0][3]) == (in_size[0] * in_size[1]))\n    assert (subgraph[0][3][0] == (- 1))\n    assert (len(subgraph[0][4]) == (in_size[0] * out_size[1]))\n    for child in subgraph[0][4]:\n        assert (child == (- 1))\n    assert (len(subgraph[0][5]) == (out_size[0] * in_size[1]))\n    for parent in subgraph[0][5]:\n        assert (parent == tree_graph.node_ids_to_ilocs(['root'])[0])\n    assert (len(subgraph[0][6]) == (out_size[0] * out_size[1]))\n    for grandchild in subgraph[0][6]:\n        assert ((grandchild in tree_graph.node_ids_to_ilocs(['c1.1', 'c2.1', 'c2.2'])) or (grandchild == (- 1)))\n    for (idx, child) in enumerate(subgraph[0][2]):\n        grandchildren = subgraph[0][6][(2 * idx):((2 * idx) + 2)]\n        if (child == tree_graph.node_ids_to_ilocs(['0'])[0]):\n            for grandchild in grandchildren:\n                assert (grandchild == (- 1))\n        elif (child == tree_graph.node_ids_to_ilocs([1])[0]):\n            for grandchild in grandchildren:\n                assert (grandchild == tree_graph.node_ids_to_ilocs(['c1.1'])[0])\n        else:\n            for grandchild in grandchildren:\n                assert (grandchild in tree_graph.node_ids_to_ilocs(['c2.1', 'c2.2']))\n    nodes = tree_graph.node_ids_to_ilocs(list(tree_graph.nodes()))\n    in_size = [2, 3]\n    out_size = [4, 5]\n    subgraph = bfw.run(nodes=nodes, n=1, in_size=in_size, out_size=out_size)\n    assert (len(subgraph) == len(nodes))\n    for node_graph in subgraph:\n        assert (len(node_graph) == 7)\n        assert (len(node_graph[0]) == 1)\n        assert (len(node_graph[1]) == in_size[0])\n        assert (len(node_graph[2]) == out_size[0])\n        assert (len(node_graph[3]) == (in_size[0] * in_size[1]))\n        assert (len(node_graph[4]) == (in_size[0] * out_size[1]))\n        assert (len(node_graph[5]) == (out_size[0] * in_size[1]))\n        assert (len(node_graph[6]) == (out_size[0] * out_size[1]))", "masked_code": "def test_two_hops(self, tree_graph):\n    bfw = DirectedBreadthFirstNeighbours(tree_graph)\n    in_size = [1, 1]\n    out_size = [2, 2]\n    node_ilocs = tree_graph.node_ids_to_ilocs(['root'])\n    subgraph = bfw.run(nodes=node_ilocs, n=1, in_size=in_size, out_size=out_size)\n    assert (len(subgraph) == 1)\n    assert (len(subgraph[0]) == 7)\n    assert (len(subgraph[0][1]) == in_size[0])\n    assert (subgraph[0][1][0] == (- 1))\n    assert (len(subgraph[0][2]) == out_size[0])\n    for child in subgraph[0][2]:\n        assert (child in tree_graph.node_ids_to_ilocs(['0', 1, 2]))\n    assert (len(subgraph[0][3]) == (in_size[0] * in_size[1]))\n    assert (subgraph[0][3][0] == (- 1))\n    assert (len(subgraph[0][4]) == (in_size[0] * out_size[1]))\n    for child in subgraph[0][4]:\n        assert (child == (- 1))\n    assert (len(subgraph[0][5]) == (out_size[0] * in_size[1]))\n    for parent in subgraph[0][5]:\n        assert (parent == tree_graph.node_ids_to_ilocs(['root'])[0])\n    assert (len(subgraph[0][6]) == (out_size[0] * out_size[1]))\n    for grandchild in subgraph[0][6]:\n        assert ((grandchild in tree_graph.node_ids_to_ilocs(['c1.1', 'c2.1', 'c2.2'])) or (grandchild == (- 1)))\n    for (idx, child) in enumerate(subgraph[0][2]):\n        grandchildren = subgraph[0][6][(2 * idx):((2 * idx) + 2)]\n        if (child == tree_graph.node_ids_to_ilocs(['0'])[0]):\n            for grandchild in grandchildren:\n                assert (grandchild == (- 1))\n        elif (child == tree_graph.node_ids_to_ilocs([1])[0]):\n            for grandchild in grandchildren:\n                assert (grandchild == tree_graph.node_ids_to_ilocs(['c1.1'])[0])\n        else:\n            for grandchild in grandchildren:\n                assert (grandchild in tree_graph.node_ids_to_ilocs(['c2.1', 'c2.2']))\n    nodes = tree_graph.node_ids_to_ilocs(list(tree_graph.nodes()))\n    in_size = [2, 3]\n    out_size = [4, 5]\n    subgraph = bfw.run(nodes=nodes, n=1, in_size=in_size, out_size=out_size)\n    assert (len(subgraph) == len(nodes))\n    for node_graph in subgraph:\n        assert (len(node_graph) == 7)\n        assert (len(node_graph[0]) == 1)\n        assert (len(node_graph[1]) == '???')\n        assert (len(node_graph[2]) == out_size[0])\n        assert (len(node_graph[3]) == (in_size[0] * in_size[1]))\n        assert (len(node_graph[4]) == (in_size[0] * out_size[1]))\n        assert (len(node_graph[5]) == (out_size[0] * in_size[1]))\n        assert (len(node_graph[6]) == (out_size[0] * out_size[1]))", "ground_truth": "in_size[0]", "quality_analysis": {"complexity_score": 13, "left_complexity": 8, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_335", "reponame": "stellargraph", "testpath": "tests/data/test_directed_breadth_first_sampler.py", "testname": "test_directed_breadth_first_sampler.py", "classname": "TestDirectedBreadthFirstNeighbours", "funcname": "test_two_hops", "imports": ["import random", "import pytest", "import pandas as pd", "import numpy as np", "from stellargraph.data.explorer import DirectedBreadthFirstNeighbours", "from stellargraph.core.graph import StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_two_hops(self, tree_graph):\n    bfw = DirectedBreadthFirstNeighbours(tree_graph)\n    in_size = [1, 1]\n    out_size = [2, 2]\n    node_ilocs = tree_graph.node_ids_to_ilocs(['root'])\n    subgraph = bfw.run(nodes=node_ilocs, n=1, in_size=in_size, out_size=out_size)\n    assert (len(subgraph) == 1)\n    assert (len(subgraph[0]) == 7)\n    assert (len(subgraph[0][1]) == in_size[0])\n    assert (subgraph[0][1][0] == (- 1))\n    assert (len(subgraph[0][2]) == out_size[0])\n    for child in subgraph[0][2]:\n        assert (child in tree_graph.node_ids_to_ilocs(['0', 1, 2]))\n    assert (len(subgraph[0][3]) == (in_size[0] * in_size[1]))\n    assert (subgraph[0][3][0] == (- 1))\n    assert (len(subgraph[0][4]) == (in_size[0] * out_size[1]))\n    for child in subgraph[0][4]:\n        assert (child == (- 1))\n    assert (len(subgraph[0][5]) == (out_size[0] * in_size[1]))\n    for parent in subgraph[0][5]:\n        assert (parent == tree_graph.node_ids_to_ilocs(['root'])[0])\n    assert (len(subgraph[0][6]) == (out_size[0] * out_size[1]))\n    for grandchild in subgraph[0][6]:\n        assert ((grandchild in tree_graph.node_ids_to_ilocs(['c1.1', 'c2.1', 'c2.2'])) or (grandchild == (- 1)))\n    for (idx, child) in enumerate(subgraph[0][2]):\n        grandchildren = subgraph[0][6][(2 * idx):((2 * idx) + 2)]\n        if (child == tree_graph.node_ids_to_ilocs(['0'])[0]):\n            for grandchild in grandchildren:\n                assert (grandchild == (- 1))\n        elif (child == tree_graph.node_ids_to_ilocs([1])[0]):\n            for grandchild in grandchildren:\n                assert (grandchild == tree_graph.node_ids_to_ilocs(['c1.1'])[0])\n        else:\n            for grandchild in grandchildren:\n                assert (grandchild in tree_graph.node_ids_to_ilocs(['c2.1', 'c2.2']))\n    nodes = tree_graph.node_ids_to_ilocs(list(tree_graph.nodes()))\n    in_size = [2, 3]\n    out_size = [4, 5]\n    subgraph = bfw.run(nodes=nodes, n=1, in_size=in_size, out_size=out_size)\n    assert (len(subgraph) == len(nodes))\n    for node_graph in subgraph:\n        assert (len(node_graph) == 7)\n        assert (len(node_graph[0]) == 1)\n        assert (len(node_graph[1]) == in_size[0])\n        assert (len(node_graph[2]) == out_size[0])\n        assert (len(node_graph[3]) == (in_size[0] * in_size[1]))\n        assert (len(node_graph[4]) == (in_size[0] * out_size[1]))\n        assert (len(node_graph[5]) == (out_size[0] * in_size[1]))\n        assert (len(node_graph[6]) == (out_size[0] * out_size[1]))", "masked_code": "def test_two_hops(self, tree_graph):\n    bfw = DirectedBreadthFirstNeighbours(tree_graph)\n    in_size = [1, 1]\n    out_size = [2, 2]\n    node_ilocs = tree_graph.node_ids_to_ilocs(['root'])\n    subgraph = bfw.run(nodes=node_ilocs, n=1, in_size=in_size, out_size=out_size)\n    assert (len(subgraph) == 1)\n    assert (len(subgraph[0]) == 7)\n    assert (len(subgraph[0][1]) == in_size[0])\n    assert (subgraph[0][1][0] == (- 1))\n    assert (len(subgraph[0][2]) == out_size[0])\n    for child in subgraph[0][2]:\n        assert (child in tree_graph.node_ids_to_ilocs(['0', 1, 2]))\n    assert (len(subgraph[0][3]) == (in_size[0] * in_size[1]))\n    assert (subgraph[0][3][0] == (- 1))\n    assert (len(subgraph[0][4]) == (in_size[0] * out_size[1]))\n    for child in subgraph[0][4]:\n        assert (child == (- 1))\n    assert (len(subgraph[0][5]) == (out_size[0] * in_size[1]))\n    for parent in subgraph[0][5]:\n        assert (parent == tree_graph.node_ids_to_ilocs(['root'])[0])\n    assert (len(subgraph[0][6]) == (out_size[0] * out_size[1]))\n    for grandchild in subgraph[0][6]:\n        assert ((grandchild in tree_graph.node_ids_to_ilocs(['c1.1', 'c2.1', 'c2.2'])) or (grandchild == (- 1)))\n    for (idx, child) in enumerate(subgraph[0][2]):\n        grandchildren = subgraph[0][6][(2 * idx):((2 * idx) + 2)]\n        if (child == tree_graph.node_ids_to_ilocs(['0'])[0]):\n            for grandchild in grandchildren:\n                assert (grandchild == (- 1))\n        elif (child == tree_graph.node_ids_to_ilocs([1])[0]):\n            for grandchild in grandchildren:\n                assert (grandchild == tree_graph.node_ids_to_ilocs(['c1.1'])[0])\n        else:\n            for grandchild in grandchildren:\n                assert (grandchild in tree_graph.node_ids_to_ilocs(['c2.1', 'c2.2']))\n    nodes = tree_graph.node_ids_to_ilocs(list(tree_graph.nodes()))\n    in_size = [2, 3]\n    out_size = [4, 5]\n    subgraph = bfw.run(nodes=nodes, n=1, in_size=in_size, out_size=out_size)\n    assert (len(subgraph) == len(nodes))\n    for node_graph in subgraph:\n        assert (len(node_graph) == 7)\n        assert (len(node_graph[0]) == 1)\n        assert (len(node_graph[1]) == in_size[0])\n        assert (len(node_graph[2]) == '???')\n        assert (len(node_graph[3]) == (in_size[0] * in_size[1]))\n        assert (len(node_graph[4]) == (in_size[0] * out_size[1]))\n        assert (len(node_graph[5]) == (out_size[0] * in_size[1]))\n        assert (len(node_graph[6]) == (out_size[0] * out_size[1]))", "ground_truth": "out_size[0]", "quality_analysis": {"complexity_score": 13, "left_complexity": 8, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_336", "reponame": "stellargraph", "testpath": "tests/data/test_directed_breadth_first_sampler.py", "testname": "test_directed_breadth_first_sampler.py", "classname": "TestDirectedBreadthFirstNeighbours", "funcname": "test_two_hops", "imports": ["import random", "import pytest", "import pandas as pd", "import numpy as np", "from stellargraph.data.explorer import DirectedBreadthFirstNeighbours", "from stellargraph.core.graph import StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_two_hops(self, tree_graph):\n    bfw = DirectedBreadthFirstNeighbours(tree_graph)\n    in_size = [1, 1]\n    out_size = [2, 2]\n    node_ilocs = tree_graph.node_ids_to_ilocs(['root'])\n    subgraph = bfw.run(nodes=node_ilocs, n=1, in_size=in_size, out_size=out_size)\n    assert (len(subgraph) == 1)\n    assert (len(subgraph[0]) == 7)\n    assert (len(subgraph[0][1]) == in_size[0])\n    assert (subgraph[0][1][0] == (- 1))\n    assert (len(subgraph[0][2]) == out_size[0])\n    for child in subgraph[0][2]:\n        assert (child in tree_graph.node_ids_to_ilocs(['0', 1, 2]))\n    assert (len(subgraph[0][3]) == (in_size[0] * in_size[1]))\n    assert (subgraph[0][3][0] == (- 1))\n    assert (len(subgraph[0][4]) == (in_size[0] * out_size[1]))\n    for child in subgraph[0][4]:\n        assert (child == (- 1))\n    assert (len(subgraph[0][5]) == (out_size[0] * in_size[1]))\n    for parent in subgraph[0][5]:\n        assert (parent == tree_graph.node_ids_to_ilocs(['root'])[0])\n    assert (len(subgraph[0][6]) == (out_size[0] * out_size[1]))\n    for grandchild in subgraph[0][6]:\n        assert ((grandchild in tree_graph.node_ids_to_ilocs(['c1.1', 'c2.1', 'c2.2'])) or (grandchild == (- 1)))\n    for (idx, child) in enumerate(subgraph[0][2]):\n        grandchildren = subgraph[0][6][(2 * idx):((2 * idx) + 2)]\n        if (child == tree_graph.node_ids_to_ilocs(['0'])[0]):\n            for grandchild in grandchildren:\n                assert (grandchild == (- 1))\n        elif (child == tree_graph.node_ids_to_ilocs([1])[0]):\n            for grandchild in grandchildren:\n                assert (grandchild == tree_graph.node_ids_to_ilocs(['c1.1'])[0])\n        else:\n            for grandchild in grandchildren:\n                assert (grandchild in tree_graph.node_ids_to_ilocs(['c2.1', 'c2.2']))\n    nodes = tree_graph.node_ids_to_ilocs(list(tree_graph.nodes()))\n    in_size = [2, 3]\n    out_size = [4, 5]\n    subgraph = bfw.run(nodes=nodes, n=1, in_size=in_size, out_size=out_size)\n    assert (len(subgraph) == len(nodes))\n    for node_graph in subgraph:\n        assert (len(node_graph) == 7)\n        assert (len(node_graph[0]) == 1)\n        assert (len(node_graph[1]) == in_size[0])\n        assert (len(node_graph[2]) == out_size[0])\n        assert (len(node_graph[3]) == (in_size[0] * in_size[1]))\n        assert (len(node_graph[4]) == (in_size[0] * out_size[1]))\n        assert (len(node_graph[5]) == (out_size[0] * in_size[1]))\n        assert (len(node_graph[6]) == (out_size[0] * out_size[1]))", "masked_code": "def test_two_hops(self, tree_graph):\n    bfw = DirectedBreadthFirstNeighbours(tree_graph)\n    in_size = [1, 1]\n    out_size = [2, 2]\n    node_ilocs = tree_graph.node_ids_to_ilocs(['root'])\n    subgraph = bfw.run(nodes=node_ilocs, n=1, in_size=in_size, out_size=out_size)\n    assert (len(subgraph) == 1)\n    assert (len(subgraph[0]) == 7)\n    assert (len(subgraph[0][1]) == in_size[0])\n    assert (subgraph[0][1][0] == (- 1))\n    assert (len(subgraph[0][2]) == out_size[0])\n    for child in subgraph[0][2]:\n        assert (child in tree_graph.node_ids_to_ilocs(['0', 1, 2]))\n    assert (len(subgraph[0][3]) == (in_size[0] * in_size[1]))\n    assert (subgraph[0][3][0] == (- 1))\n    assert (len(subgraph[0][4]) == (in_size[0] * out_size[1]))\n    for child in subgraph[0][4]:\n        assert (child == (- 1))\n    assert (len(subgraph[0][5]) == (out_size[0] * in_size[1]))\n    for parent in subgraph[0][5]:\n        assert (parent == tree_graph.node_ids_to_ilocs(['root'])[0])\n    assert (len(subgraph[0][6]) == (out_size[0] * out_size[1]))\n    for grandchild in subgraph[0][6]:\n        assert ((grandchild in tree_graph.node_ids_to_ilocs(['c1.1', 'c2.1', 'c2.2'])) or (grandchild == (- 1)))\n    for (idx, child) in enumerate(subgraph[0][2]):\n        grandchildren = subgraph[0][6][(2 * idx):((2 * idx) + 2)]\n        if (child == tree_graph.node_ids_to_ilocs(['0'])[0]):\n            for grandchild in grandchildren:\n                assert (grandchild == (- 1))\n        elif (child == tree_graph.node_ids_to_ilocs([1])[0]):\n            for grandchild in grandchildren:\n                assert (grandchild == tree_graph.node_ids_to_ilocs(['c1.1'])[0])\n        else:\n            for grandchild in grandchildren:\n                assert (grandchild in tree_graph.node_ids_to_ilocs(['c2.1', 'c2.2']))\n    nodes = tree_graph.node_ids_to_ilocs(list(tree_graph.nodes()))\n    in_size = [2, 3]\n    out_size = [4, 5]\n    subgraph = bfw.run(nodes=nodes, n=1, in_size=in_size, out_size=out_size)\n    assert (len(subgraph) == len(nodes))\n    for node_graph in subgraph:\n        assert (len(node_graph) == 7)\n        assert (len(node_graph[0]) == 1)\n        assert (len(node_graph[1]) == in_size[0])\n        assert (len(node_graph[2]) == out_size[0])\n        assert (len(node_graph[3]) == '???')\n        assert (len(node_graph[4]) == (in_size[0] * out_size[1]))\n        assert (len(node_graph[5]) == (out_size[0] * in_size[1]))\n        assert (len(node_graph[6]) == (out_size[0] * out_size[1]))", "ground_truth": "(in_size[0] * in_size[1])", "quality_analysis": {"complexity_score": 20, "left_complexity": 8, "right_complexity": 12, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_337", "reponame": "stellargraph", "testpath": "tests/data/test_directed_breadth_first_sampler.py", "testname": "test_directed_breadth_first_sampler.py", "classname": "TestDirectedBreadthFirstNeighbours", "funcname": "test_two_hops", "imports": ["import random", "import pytest", "import pandas as pd", "import numpy as np", "from stellargraph.data.explorer import DirectedBreadthFirstNeighbours", "from stellargraph.core.graph import StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_two_hops(self, tree_graph):\n    bfw = DirectedBreadthFirstNeighbours(tree_graph)\n    in_size = [1, 1]\n    out_size = [2, 2]\n    node_ilocs = tree_graph.node_ids_to_ilocs(['root'])\n    subgraph = bfw.run(nodes=node_ilocs, n=1, in_size=in_size, out_size=out_size)\n    assert (len(subgraph) == 1)\n    assert (len(subgraph[0]) == 7)\n    assert (len(subgraph[0][1]) == in_size[0])\n    assert (subgraph[0][1][0] == (- 1))\n    assert (len(subgraph[0][2]) == out_size[0])\n    for child in subgraph[0][2]:\n        assert (child in tree_graph.node_ids_to_ilocs(['0', 1, 2]))\n    assert (len(subgraph[0][3]) == (in_size[0] * in_size[1]))\n    assert (subgraph[0][3][0] == (- 1))\n    assert (len(subgraph[0][4]) == (in_size[0] * out_size[1]))\n    for child in subgraph[0][4]:\n        assert (child == (- 1))\n    assert (len(subgraph[0][5]) == (out_size[0] * in_size[1]))\n    for parent in subgraph[0][5]:\n        assert (parent == tree_graph.node_ids_to_ilocs(['root'])[0])\n    assert (len(subgraph[0][6]) == (out_size[0] * out_size[1]))\n    for grandchild in subgraph[0][6]:\n        assert ((grandchild in tree_graph.node_ids_to_ilocs(['c1.1', 'c2.1', 'c2.2'])) or (grandchild == (- 1)))\n    for (idx, child) in enumerate(subgraph[0][2]):\n        grandchildren = subgraph[0][6][(2 * idx):((2 * idx) + 2)]\n        if (child == tree_graph.node_ids_to_ilocs(['0'])[0]):\n            for grandchild in grandchildren:\n                assert (grandchild == (- 1))\n        elif (child == tree_graph.node_ids_to_ilocs([1])[0]):\n            for grandchild in grandchildren:\n                assert (grandchild == tree_graph.node_ids_to_ilocs(['c1.1'])[0])\n        else:\n            for grandchild in grandchildren:\n                assert (grandchild in tree_graph.node_ids_to_ilocs(['c2.1', 'c2.2']))\n    nodes = tree_graph.node_ids_to_ilocs(list(tree_graph.nodes()))\n    in_size = [2, 3]\n    out_size = [4, 5]\n    subgraph = bfw.run(nodes=nodes, n=1, in_size=in_size, out_size=out_size)\n    assert (len(subgraph) == len(nodes))\n    for node_graph in subgraph:\n        assert (len(node_graph) == 7)\n        assert (len(node_graph[0]) == 1)\n        assert (len(node_graph[1]) == in_size[0])\n        assert (len(node_graph[2]) == out_size[0])\n        assert (len(node_graph[3]) == (in_size[0] * in_size[1]))\n        assert (len(node_graph[4]) == (in_size[0] * out_size[1]))\n        assert (len(node_graph[5]) == (out_size[0] * in_size[1]))\n        assert (len(node_graph[6]) == (out_size[0] * out_size[1]))", "masked_code": "def test_two_hops(self, tree_graph):\n    bfw = DirectedBreadthFirstNeighbours(tree_graph)\n    in_size = [1, 1]\n    out_size = [2, 2]\n    node_ilocs = tree_graph.node_ids_to_ilocs(['root'])\n    subgraph = bfw.run(nodes=node_ilocs, n=1, in_size=in_size, out_size=out_size)\n    assert (len(subgraph) == 1)\n    assert (len(subgraph[0]) == 7)\n    assert (len(subgraph[0][1]) == in_size[0])\n    assert (subgraph[0][1][0] == (- 1))\n    assert (len(subgraph[0][2]) == out_size[0])\n    for child in subgraph[0][2]:\n        assert (child in tree_graph.node_ids_to_ilocs(['0', 1, 2]))\n    assert (len(subgraph[0][3]) == (in_size[0] * in_size[1]))\n    assert (subgraph[0][3][0] == (- 1))\n    assert (len(subgraph[0][4]) == (in_size[0] * out_size[1]))\n    for child in subgraph[0][4]:\n        assert (child == (- 1))\n    assert (len(subgraph[0][5]) == (out_size[0] * in_size[1]))\n    for parent in subgraph[0][5]:\n        assert (parent == tree_graph.node_ids_to_ilocs(['root'])[0])\n    assert (len(subgraph[0][6]) == (out_size[0] * out_size[1]))\n    for grandchild in subgraph[0][6]:\n        assert ((grandchild in tree_graph.node_ids_to_ilocs(['c1.1', 'c2.1', 'c2.2'])) or (grandchild == (- 1)))\n    for (idx, child) in enumerate(subgraph[0][2]):\n        grandchildren = subgraph[0][6][(2 * idx):((2 * idx) + 2)]\n        if (child == tree_graph.node_ids_to_ilocs(['0'])[0]):\n            for grandchild in grandchildren:\n                assert (grandchild == (- 1))\n        elif (child == tree_graph.node_ids_to_ilocs([1])[0]):\n            for grandchild in grandchildren:\n                assert (grandchild == tree_graph.node_ids_to_ilocs(['c1.1'])[0])\n        else:\n            for grandchild in grandchildren:\n                assert (grandchild in tree_graph.node_ids_to_ilocs(['c2.1', 'c2.2']))\n    nodes = tree_graph.node_ids_to_ilocs(list(tree_graph.nodes()))\n    in_size = [2, 3]\n    out_size = [4, 5]\n    subgraph = bfw.run(nodes=nodes, n=1, in_size=in_size, out_size=out_size)\n    assert (len(subgraph) == len(nodes))\n    for node_graph in subgraph:\n        assert (len(node_graph) == 7)\n        assert (len(node_graph[0]) == 1)\n        assert (len(node_graph[1]) == in_size[0])\n        assert (len(node_graph[2]) == out_size[0])\n        assert (len(node_graph[3]) == (in_size[0] * in_size[1]))\n        assert (len(node_graph[4]) == '???')\n        assert (len(node_graph[5]) == (out_size[0] * in_size[1]))\n        assert (len(node_graph[6]) == (out_size[0] * out_size[1]))", "ground_truth": "(in_size[0] * out_size[1])", "quality_analysis": {"complexity_score": 20, "left_complexity": 8, "right_complexity": 12, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_338", "reponame": "stellargraph", "testpath": "tests/data/test_directed_breadth_first_sampler.py", "testname": "test_directed_breadth_first_sampler.py", "classname": "TestDirectedBreadthFirstNeighbours", "funcname": "test_two_hops", "imports": ["import random", "import pytest", "import pandas as pd", "import numpy as np", "from stellargraph.data.explorer import DirectedBreadthFirstNeighbours", "from stellargraph.core.graph import StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_two_hops(self, tree_graph):\n    bfw = DirectedBreadthFirstNeighbours(tree_graph)\n    in_size = [1, 1]\n    out_size = [2, 2]\n    node_ilocs = tree_graph.node_ids_to_ilocs(['root'])\n    subgraph = bfw.run(nodes=node_ilocs, n=1, in_size=in_size, out_size=out_size)\n    assert (len(subgraph) == 1)\n    assert (len(subgraph[0]) == 7)\n    assert (len(subgraph[0][1]) == in_size[0])\n    assert (subgraph[0][1][0] == (- 1))\n    assert (len(subgraph[0][2]) == out_size[0])\n    for child in subgraph[0][2]:\n        assert (child in tree_graph.node_ids_to_ilocs(['0', 1, 2]))\n    assert (len(subgraph[0][3]) == (in_size[0] * in_size[1]))\n    assert (subgraph[0][3][0] == (- 1))\n    assert (len(subgraph[0][4]) == (in_size[0] * out_size[1]))\n    for child in subgraph[0][4]:\n        assert (child == (- 1))\n    assert (len(subgraph[0][5]) == (out_size[0] * in_size[1]))\n    for parent in subgraph[0][5]:\n        assert (parent == tree_graph.node_ids_to_ilocs(['root'])[0])\n    assert (len(subgraph[0][6]) == (out_size[0] * out_size[1]))\n    for grandchild in subgraph[0][6]:\n        assert ((grandchild in tree_graph.node_ids_to_ilocs(['c1.1', 'c2.1', 'c2.2'])) or (grandchild == (- 1)))\n    for (idx, child) in enumerate(subgraph[0][2]):\n        grandchildren = subgraph[0][6][(2 * idx):((2 * idx) + 2)]\n        if (child == tree_graph.node_ids_to_ilocs(['0'])[0]):\n            for grandchild in grandchildren:\n                assert (grandchild == (- 1))\n        elif (child == tree_graph.node_ids_to_ilocs([1])[0]):\n            for grandchild in grandchildren:\n                assert (grandchild == tree_graph.node_ids_to_ilocs(['c1.1'])[0])\n        else:\n            for grandchild in grandchildren:\n                assert (grandchild in tree_graph.node_ids_to_ilocs(['c2.1', 'c2.2']))\n    nodes = tree_graph.node_ids_to_ilocs(list(tree_graph.nodes()))\n    in_size = [2, 3]\n    out_size = [4, 5]\n    subgraph = bfw.run(nodes=nodes, n=1, in_size=in_size, out_size=out_size)\n    assert (len(subgraph) == len(nodes))\n    for node_graph in subgraph:\n        assert (len(node_graph) == 7)\n        assert (len(node_graph[0]) == 1)\n        assert (len(node_graph[1]) == in_size[0])\n        assert (len(node_graph[2]) == out_size[0])\n        assert (len(node_graph[3]) == (in_size[0] * in_size[1]))\n        assert (len(node_graph[4]) == (in_size[0] * out_size[1]))\n        assert (len(node_graph[5]) == (out_size[0] * in_size[1]))\n        assert (len(node_graph[6]) == (out_size[0] * out_size[1]))", "masked_code": "def test_two_hops(self, tree_graph):\n    bfw = DirectedBreadthFirstNeighbours(tree_graph)\n    in_size = [1, 1]\n    out_size = [2, 2]\n    node_ilocs = tree_graph.node_ids_to_ilocs(['root'])\n    subgraph = bfw.run(nodes=node_ilocs, n=1, in_size=in_size, out_size=out_size)\n    assert (len(subgraph) == 1)\n    assert (len(subgraph[0]) == 7)\n    assert (len(subgraph[0][1]) == in_size[0])\n    assert (subgraph[0][1][0] == (- 1))\n    assert (len(subgraph[0][2]) == out_size[0])\n    for child in subgraph[0][2]:\n        assert (child in tree_graph.node_ids_to_ilocs(['0', 1, 2]))\n    assert (len(subgraph[0][3]) == (in_size[0] * in_size[1]))\n    assert (subgraph[0][3][0] == (- 1))\n    assert (len(subgraph[0][4]) == (in_size[0] * out_size[1]))\n    for child in subgraph[0][4]:\n        assert (child == (- 1))\n    assert (len(subgraph[0][5]) == (out_size[0] * in_size[1]))\n    for parent in subgraph[0][5]:\n        assert (parent == tree_graph.node_ids_to_ilocs(['root'])[0])\n    assert (len(subgraph[0][6]) == (out_size[0] * out_size[1]))\n    for grandchild in subgraph[0][6]:\n        assert ((grandchild in tree_graph.node_ids_to_ilocs(['c1.1', 'c2.1', 'c2.2'])) or (grandchild == (- 1)))\n    for (idx, child) in enumerate(subgraph[0][2]):\n        grandchildren = subgraph[0][6][(2 * idx):((2 * idx) + 2)]\n        if (child == tree_graph.node_ids_to_ilocs(['0'])[0]):\n            for grandchild in grandchildren:\n                assert (grandchild == (- 1))\n        elif (child == tree_graph.node_ids_to_ilocs([1])[0]):\n            for grandchild in grandchildren:\n                assert (grandchild == tree_graph.node_ids_to_ilocs(['c1.1'])[0])\n        else:\n            for grandchild in grandchildren:\n                assert (grandchild in tree_graph.node_ids_to_ilocs(['c2.1', 'c2.2']))\n    nodes = tree_graph.node_ids_to_ilocs(list(tree_graph.nodes()))\n    in_size = [2, 3]\n    out_size = [4, 5]\n    subgraph = bfw.run(nodes=nodes, n=1, in_size=in_size, out_size=out_size)\n    assert (len(subgraph) == len(nodes))\n    for node_graph in subgraph:\n        assert (len(node_graph) == 7)\n        assert (len(node_graph[0]) == 1)\n        assert (len(node_graph[1]) == in_size[0])\n        assert (len(node_graph[2]) == out_size[0])\n        assert (len(node_graph[3]) == (in_size[0] * in_size[1]))\n        assert (len(node_graph[4]) == (in_size[0] * out_size[1]))\n        assert (len(node_graph[5]) == '???')\n        assert (len(node_graph[6]) == (out_size[0] * out_size[1]))", "ground_truth": "(out_size[0] * in_size[1])", "quality_analysis": {"complexity_score": 20, "left_complexity": 8, "right_complexity": 12, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_339", "reponame": "stellargraph", "testpath": "tests/data/test_directed_breadth_first_sampler.py", "testname": "test_directed_breadth_first_sampler.py", "classname": "TestDirectedBreadthFirstNeighbours", "funcname": "test_two_hops", "imports": ["import random", "import pytest", "import pandas as pd", "import numpy as np", "from stellargraph.data.explorer import DirectedBreadthFirstNeighbours", "from stellargraph.core.graph import StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_two_hops(self, tree_graph):\n    bfw = DirectedBreadthFirstNeighbours(tree_graph)\n    in_size = [1, 1]\n    out_size = [2, 2]\n    node_ilocs = tree_graph.node_ids_to_ilocs(['root'])\n    subgraph = bfw.run(nodes=node_ilocs, n=1, in_size=in_size, out_size=out_size)\n    assert (len(subgraph) == 1)\n    assert (len(subgraph[0]) == 7)\n    assert (len(subgraph[0][1]) == in_size[0])\n    assert (subgraph[0][1][0] == (- 1))\n    assert (len(subgraph[0][2]) == out_size[0])\n    for child in subgraph[0][2]:\n        assert (child in tree_graph.node_ids_to_ilocs(['0', 1, 2]))\n    assert (len(subgraph[0][3]) == (in_size[0] * in_size[1]))\n    assert (subgraph[0][3][0] == (- 1))\n    assert (len(subgraph[0][4]) == (in_size[0] * out_size[1]))\n    for child in subgraph[0][4]:\n        assert (child == (- 1))\n    assert (len(subgraph[0][5]) == (out_size[0] * in_size[1]))\n    for parent in subgraph[0][5]:\n        assert (parent == tree_graph.node_ids_to_ilocs(['root'])[0])\n    assert (len(subgraph[0][6]) == (out_size[0] * out_size[1]))\n    for grandchild in subgraph[0][6]:\n        assert ((grandchild in tree_graph.node_ids_to_ilocs(['c1.1', 'c2.1', 'c2.2'])) or (grandchild == (- 1)))\n    for (idx, child) in enumerate(subgraph[0][2]):\n        grandchildren = subgraph[0][6][(2 * idx):((2 * idx) + 2)]\n        if (child == tree_graph.node_ids_to_ilocs(['0'])[0]):\n            for grandchild in grandchildren:\n                assert (grandchild == (- 1))\n        elif (child == tree_graph.node_ids_to_ilocs([1])[0]):\n            for grandchild in grandchildren:\n                assert (grandchild == tree_graph.node_ids_to_ilocs(['c1.1'])[0])\n        else:\n            for grandchild in grandchildren:\n                assert (grandchild in tree_graph.node_ids_to_ilocs(['c2.1', 'c2.2']))\n    nodes = tree_graph.node_ids_to_ilocs(list(tree_graph.nodes()))\n    in_size = [2, 3]\n    out_size = [4, 5]\n    subgraph = bfw.run(nodes=nodes, n=1, in_size=in_size, out_size=out_size)\n    assert (len(subgraph) == len(nodes))\n    for node_graph in subgraph:\n        assert (len(node_graph) == 7)\n        assert (len(node_graph[0]) == 1)\n        assert (len(node_graph[1]) == in_size[0])\n        assert (len(node_graph[2]) == out_size[0])\n        assert (len(node_graph[3]) == (in_size[0] * in_size[1]))\n        assert (len(node_graph[4]) == (in_size[0] * out_size[1]))\n        assert (len(node_graph[5]) == (out_size[0] * in_size[1]))\n        assert (len(node_graph[6]) == (out_size[0] * out_size[1]))", "masked_code": "def test_two_hops(self, tree_graph):\n    bfw = DirectedBreadthFirstNeighbours(tree_graph)\n    in_size = [1, 1]\n    out_size = [2, 2]\n    node_ilocs = tree_graph.node_ids_to_ilocs(['root'])\n    subgraph = bfw.run(nodes=node_ilocs, n=1, in_size=in_size, out_size=out_size)\n    assert (len(subgraph) == 1)\n    assert (len(subgraph[0]) == 7)\n    assert (len(subgraph[0][1]) == in_size[0])\n    assert (subgraph[0][1][0] == (- 1))\n    assert (len(subgraph[0][2]) == out_size[0])\n    for child in subgraph[0][2]:\n        assert (child in tree_graph.node_ids_to_ilocs(['0', 1, 2]))\n    assert (len(subgraph[0][3]) == (in_size[0] * in_size[1]))\n    assert (subgraph[0][3][0] == (- 1))\n    assert (len(subgraph[0][4]) == (in_size[0] * out_size[1]))\n    for child in subgraph[0][4]:\n        assert (child == (- 1))\n    assert (len(subgraph[0][5]) == (out_size[0] * in_size[1]))\n    for parent in subgraph[0][5]:\n        assert (parent == tree_graph.node_ids_to_ilocs(['root'])[0])\n    assert (len(subgraph[0][6]) == (out_size[0] * out_size[1]))\n    for grandchild in subgraph[0][6]:\n        assert ((grandchild in tree_graph.node_ids_to_ilocs(['c1.1', 'c2.1', 'c2.2'])) or (grandchild == (- 1)))\n    for (idx, child) in enumerate(subgraph[0][2]):\n        grandchildren = subgraph[0][6][(2 * idx):((2 * idx) + 2)]\n        if (child == tree_graph.node_ids_to_ilocs(['0'])[0]):\n            for grandchild in grandchildren:\n                assert (grandchild == (- 1))\n        elif (child == tree_graph.node_ids_to_ilocs([1])[0]):\n            for grandchild in grandchildren:\n                assert (grandchild == tree_graph.node_ids_to_ilocs(['c1.1'])[0])\n        else:\n            for grandchild in grandchildren:\n                assert (grandchild in tree_graph.node_ids_to_ilocs(['c2.1', 'c2.2']))\n    nodes = tree_graph.node_ids_to_ilocs(list(tree_graph.nodes()))\n    in_size = [2, 3]\n    out_size = [4, 5]\n    subgraph = bfw.run(nodes=nodes, n=1, in_size=in_size, out_size=out_size)\n    assert (len(subgraph) == len(nodes))\n    for node_graph in subgraph:\n        assert (len(node_graph) == 7)\n        assert (len(node_graph[0]) == 1)\n        assert (len(node_graph[1]) == in_size[0])\n        assert (len(node_graph[2]) == out_size[0])\n        assert (len(node_graph[3]) == (in_size[0] * in_size[1]))\n        assert (len(node_graph[4]) == (in_size[0] * out_size[1]))\n        assert (len(node_graph[5]) == (out_size[0] * in_size[1]))\n        assert (len(node_graph[6]) == '???')", "ground_truth": "(out_size[0] * out_size[1])", "quality_analysis": {"complexity_score": 20, "left_complexity": 8, "right_complexity": 12, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_340", "reponame": "stellargraph", "testpath": "tests/data/test_directed_breadth_first_sampler.py", "testname": "test_directed_breadth_first_sampler.py", "classname": "TestDirectedBreadthFirstNeighbours", "funcname": "test_three_hops", "imports": ["import random", "import pytest", "import pandas as pd", "import numpy as np", "from stellargraph.data.explorer import DirectedBreadthFirstNeighbours", "from stellargraph.core.graph import StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_three_hops(self):\n    g = create_test_graph(is_directed=True)\n    bfw = DirectedBreadthFirstNeighbours(g)\n    graph_nodes = g.node_ids_to_ilocs(list(g.nodes()))\n    for _ in range(50):\n        node = random.choice(graph_nodes)\n        in_size = [random.randint(0, 2) for _ in range(3)]\n        out_size = [random.randint(0, 2) for _ in range(3)]\n        subgraph = bfw.run(nodes=[node], n=1, in_size=in_size, out_size=out_size)\n        assert (len(subgraph) == 1)\n        assert (len(subgraph[0]) == 15)\n        assert (len(subgraph[0][0]) == 1)\n        assert (len(subgraph[0][1]) == in_size[0])\n        assert (len(subgraph[0][2]) == out_size[0])\n        assert (len(subgraph[0][3]) == (in_size[0] * in_size[1]))\n        assert (len(subgraph[0][4]) == (in_size[0] * out_size[1]))\n        assert (len(subgraph[0][5]) == (out_size[0] * in_size[1]))\n        assert (len(subgraph[0][6]) == (out_size[0] * out_size[1]))\n        assert (len(subgraph[0][7]) == ((in_size[0] * in_size[1]) * in_size[2]))\n        assert (len(subgraph[0][8]) == ((in_size[0] * in_size[1]) * out_size[2]))\n        assert (len(subgraph[0][9]) == ((in_size[0] * out_size[1]) * in_size[2]))\n        assert (len(subgraph[0][10]) == ((in_size[0] * out_size[1]) * out_size[2]))\n        assert (len(subgraph[0][11]) == ((out_size[0] * in_size[1]) * in_size[2]))\n        assert (len(subgraph[0][12]) == ((out_size[0] * in_size[1]) * out_size[2]))\n        assert (len(subgraph[0][13]) == ((out_size[0] * out_size[1]) * in_size[2]))\n        assert (len(subgraph[0][14]) == ((out_size[0] * out_size[1]) * out_size[2]))", "masked_code": "def test_three_hops(self):\n    g = create_test_graph(is_directed=True)\n    bfw = DirectedBreadthFirstNeighbours(g)\n    graph_nodes = g.node_ids_to_ilocs(list(g.nodes()))\n    for _ in range(50):\n        node = random.choice(graph_nodes)\n        in_size = [random.randint(0, 2) for _ in range(3)]\n        out_size = [random.randint(0, 2) for _ in range(3)]\n        subgraph = bfw.run(nodes=[node], n=1, in_size=in_size, out_size=out_size)\n        assert (len(subgraph) == 1)\n        assert (len(subgraph[0]) == '???')\n        assert (len(subgraph[0][0]) == 1)\n        assert (len(subgraph[0][1]) == in_size[0])\n        assert (len(subgraph[0][2]) == out_size[0])\n        assert (len(subgraph[0][3]) == (in_size[0] * in_size[1]))\n        assert (len(subgraph[0][4]) == (in_size[0] * out_size[1]))\n        assert (len(subgraph[0][5]) == (out_size[0] * in_size[1]))\n        assert (len(subgraph[0][6]) == (out_size[0] * out_size[1]))\n        assert (len(subgraph[0][7]) == ((in_size[0] * in_size[1]) * in_size[2]))\n        assert (len(subgraph[0][8]) == ((in_size[0] * in_size[1]) * out_size[2]))\n        assert (len(subgraph[0][9]) == ((in_size[0] * out_size[1]) * in_size[2]))\n        assert (len(subgraph[0][10]) == ((in_size[0] * out_size[1]) * out_size[2]))\n        assert (len(subgraph[0][11]) == ((out_size[0] * in_size[1]) * in_size[2]))\n        assert (len(subgraph[0][12]) == ((out_size[0] * in_size[1]) * out_size[2]))\n        assert (len(subgraph[0][13]) == ((out_size[0] * out_size[1]) * in_size[2]))\n        assert (len(subgraph[0][14]) == ((out_size[0] * out_size[1]) * out_size[2]))", "ground_truth": "15", "quality_analysis": {"complexity_score": 9, "left_complexity": 8, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_341", "reponame": "stellargraph", "testpath": "tests/data/test_directed_breadth_first_sampler.py", "testname": "test_directed_breadth_first_sampler.py", "classname": "TestDirectedBreadthFirstNeighbours", "funcname": "test_three_hops", "imports": ["import random", "import pytest", "import pandas as pd", "import numpy as np", "from stellargraph.data.explorer import DirectedBreadthFirstNeighbours", "from stellargraph.core.graph import StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_three_hops(self):\n    g = create_test_graph(is_directed=True)\n    bfw = DirectedBreadthFirstNeighbours(g)\n    graph_nodes = g.node_ids_to_ilocs(list(g.nodes()))\n    for _ in range(50):\n        node = random.choice(graph_nodes)\n        in_size = [random.randint(0, 2) for _ in range(3)]\n        out_size = [random.randint(0, 2) for _ in range(3)]\n        subgraph = bfw.run(nodes=[node], n=1, in_size=in_size, out_size=out_size)\n        assert (len(subgraph) == 1)\n        assert (len(subgraph[0]) == 15)\n        assert (len(subgraph[0][0]) == 1)\n        assert (len(subgraph[0][1]) == in_size[0])\n        assert (len(subgraph[0][2]) == out_size[0])\n        assert (len(subgraph[0][3]) == (in_size[0] * in_size[1]))\n        assert (len(subgraph[0][4]) == (in_size[0] * out_size[1]))\n        assert (len(subgraph[0][5]) == (out_size[0] * in_size[1]))\n        assert (len(subgraph[0][6]) == (out_size[0] * out_size[1]))\n        assert (len(subgraph[0][7]) == ((in_size[0] * in_size[1]) * in_size[2]))\n        assert (len(subgraph[0][8]) == ((in_size[0] * in_size[1]) * out_size[2]))\n        assert (len(subgraph[0][9]) == ((in_size[0] * out_size[1]) * in_size[2]))\n        assert (len(subgraph[0][10]) == ((in_size[0] * out_size[1]) * out_size[2]))\n        assert (len(subgraph[0][11]) == ((out_size[0] * in_size[1]) * in_size[2]))\n        assert (len(subgraph[0][12]) == ((out_size[0] * in_size[1]) * out_size[2]))\n        assert (len(subgraph[0][13]) == ((out_size[0] * out_size[1]) * in_size[2]))\n        assert (len(subgraph[0][14]) == ((out_size[0] * out_size[1]) * out_size[2]))", "masked_code": "def test_three_hops(self):\n    g = create_test_graph(is_directed=True)\n    bfw = DirectedBreadthFirstNeighbours(g)\n    graph_nodes = g.node_ids_to_ilocs(list(g.nodes()))\n    for _ in range(50):\n        node = random.choice(graph_nodes)\n        in_size = [random.randint(0, 2) for _ in range(3)]\n        out_size = [random.randint(0, 2) for _ in range(3)]\n        subgraph = bfw.run(nodes=[node], n=1, in_size=in_size, out_size=out_size)\n        assert (len(subgraph) == 1)\n        assert (len(subgraph[0]) == 15)\n        assert (len(subgraph[0][0]) == 1)\n        assert (len(subgraph[0][1]) == '???')\n        assert (len(subgraph[0][2]) == out_size[0])\n        assert (len(subgraph[0][3]) == (in_size[0] * in_size[1]))\n        assert (len(subgraph[0][4]) == (in_size[0] * out_size[1]))\n        assert (len(subgraph[0][5]) == (out_size[0] * in_size[1]))\n        assert (len(subgraph[0][6]) == (out_size[0] * out_size[1]))\n        assert (len(subgraph[0][7]) == ((in_size[0] * in_size[1]) * in_size[2]))\n        assert (len(subgraph[0][8]) == ((in_size[0] * in_size[1]) * out_size[2]))\n        assert (len(subgraph[0][9]) == ((in_size[0] * out_size[1]) * in_size[2]))\n        assert (len(subgraph[0][10]) == ((in_size[0] * out_size[1]) * out_size[2]))\n        assert (len(subgraph[0][11]) == ((out_size[0] * in_size[1]) * in_size[2]))\n        assert (len(subgraph[0][12]) == ((out_size[0] * in_size[1]) * out_size[2]))\n        assert (len(subgraph[0][13]) == ((out_size[0] * out_size[1]) * in_size[2]))\n        assert (len(subgraph[0][14]) == ((out_size[0] * out_size[1]) * out_size[2]))", "ground_truth": "in_size[0]", "quality_analysis": {"complexity_score": 17, "left_complexity": 12, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_342", "reponame": "stellargraph", "testpath": "tests/data/test_directed_breadth_first_sampler.py", "testname": "test_directed_breadth_first_sampler.py", "classname": "TestDirectedBreadthFirstNeighbours", "funcname": "test_three_hops", "imports": ["import random", "import pytest", "import pandas as pd", "import numpy as np", "from stellargraph.data.explorer import DirectedBreadthFirstNeighbours", "from stellargraph.core.graph import StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_three_hops(self):\n    g = create_test_graph(is_directed=True)\n    bfw = DirectedBreadthFirstNeighbours(g)\n    graph_nodes = g.node_ids_to_ilocs(list(g.nodes()))\n    for _ in range(50):\n        node = random.choice(graph_nodes)\n        in_size = [random.randint(0, 2) for _ in range(3)]\n        out_size = [random.randint(0, 2) for _ in range(3)]\n        subgraph = bfw.run(nodes=[node], n=1, in_size=in_size, out_size=out_size)\n        assert (len(subgraph) == 1)\n        assert (len(subgraph[0]) == 15)\n        assert (len(subgraph[0][0]) == 1)\n        assert (len(subgraph[0][1]) == in_size[0])\n        assert (len(subgraph[0][2]) == out_size[0])\n        assert (len(subgraph[0][3]) == (in_size[0] * in_size[1]))\n        assert (len(subgraph[0][4]) == (in_size[0] * out_size[1]))\n        assert (len(subgraph[0][5]) == (out_size[0] * in_size[1]))\n        assert (len(subgraph[0][6]) == (out_size[0] * out_size[1]))\n        assert (len(subgraph[0][7]) == ((in_size[0] * in_size[1]) * in_size[2]))\n        assert (len(subgraph[0][8]) == ((in_size[0] * in_size[1]) * out_size[2]))\n        assert (len(subgraph[0][9]) == ((in_size[0] * out_size[1]) * in_size[2]))\n        assert (len(subgraph[0][10]) == ((in_size[0] * out_size[1]) * out_size[2]))\n        assert (len(subgraph[0][11]) == ((out_size[0] * in_size[1]) * in_size[2]))\n        assert (len(subgraph[0][12]) == ((out_size[0] * in_size[1]) * out_size[2]))\n        assert (len(subgraph[0][13]) == ((out_size[0] * out_size[1]) * in_size[2]))\n        assert (len(subgraph[0][14]) == ((out_size[0] * out_size[1]) * out_size[2]))", "masked_code": "def test_three_hops(self):\n    g = create_test_graph(is_directed=True)\n    bfw = DirectedBreadthFirstNeighbours(g)\n    graph_nodes = g.node_ids_to_ilocs(list(g.nodes()))\n    for _ in range(50):\n        node = random.choice(graph_nodes)\n        in_size = [random.randint(0, 2) for _ in range(3)]\n        out_size = [random.randint(0, 2) for _ in range(3)]\n        subgraph = bfw.run(nodes=[node], n=1, in_size=in_size, out_size=out_size)\n        assert (len(subgraph) == 1)\n        assert (len(subgraph[0]) == 15)\n        assert (len(subgraph[0][0]) == 1)\n        assert (len(subgraph[0][1]) == in_size[0])\n        assert (len(subgraph[0][2]) == '???')\n        assert (len(subgraph[0][3]) == (in_size[0] * in_size[1]))\n        assert (len(subgraph[0][4]) == (in_size[0] * out_size[1]))\n        assert (len(subgraph[0][5]) == (out_size[0] * in_size[1]))\n        assert (len(subgraph[0][6]) == (out_size[0] * out_size[1]))\n        assert (len(subgraph[0][7]) == ((in_size[0] * in_size[1]) * in_size[2]))\n        assert (len(subgraph[0][8]) == ((in_size[0] * in_size[1]) * out_size[2]))\n        assert (len(subgraph[0][9]) == ((in_size[0] * out_size[1]) * in_size[2]))\n        assert (len(subgraph[0][10]) == ((in_size[0] * out_size[1]) * out_size[2]))\n        assert (len(subgraph[0][11]) == ((out_size[0] * in_size[1]) * in_size[2]))\n        assert (len(subgraph[0][12]) == ((out_size[0] * in_size[1]) * out_size[2]))\n        assert (len(subgraph[0][13]) == ((out_size[0] * out_size[1]) * in_size[2]))\n        assert (len(subgraph[0][14]) == ((out_size[0] * out_size[1]) * out_size[2]))", "ground_truth": "out_size[0]", "quality_analysis": {"complexity_score": 17, "left_complexity": 12, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_343", "reponame": "stellargraph", "testpath": "tests/data/test_directed_breadth_first_sampler.py", "testname": "test_directed_breadth_first_sampler.py", "classname": "TestDirectedBreadthFirstNeighbours", "funcname": "test_three_hops", "imports": ["import random", "import pytest", "import pandas as pd", "import numpy as np", "from stellargraph.data.explorer import DirectedBreadthFirstNeighbours", "from stellargraph.core.graph import StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_three_hops(self):\n    g = create_test_graph(is_directed=True)\n    bfw = DirectedBreadthFirstNeighbours(g)\n    graph_nodes = g.node_ids_to_ilocs(list(g.nodes()))\n    for _ in range(50):\n        node = random.choice(graph_nodes)\n        in_size = [random.randint(0, 2) for _ in range(3)]\n        out_size = [random.randint(0, 2) for _ in range(3)]\n        subgraph = bfw.run(nodes=[node], n=1, in_size=in_size, out_size=out_size)\n        assert (len(subgraph) == 1)\n        assert (len(subgraph[0]) == 15)\n        assert (len(subgraph[0][0]) == 1)\n        assert (len(subgraph[0][1]) == in_size[0])\n        assert (len(subgraph[0][2]) == out_size[0])\n        assert (len(subgraph[0][3]) == (in_size[0] * in_size[1]))\n        assert (len(subgraph[0][4]) == (in_size[0] * out_size[1]))\n        assert (len(subgraph[0][5]) == (out_size[0] * in_size[1]))\n        assert (len(subgraph[0][6]) == (out_size[0] * out_size[1]))\n        assert (len(subgraph[0][7]) == ((in_size[0] * in_size[1]) * in_size[2]))\n        assert (len(subgraph[0][8]) == ((in_size[0] * in_size[1]) * out_size[2]))\n        assert (len(subgraph[0][9]) == ((in_size[0] * out_size[1]) * in_size[2]))\n        assert (len(subgraph[0][10]) == ((in_size[0] * out_size[1]) * out_size[2]))\n        assert (len(subgraph[0][11]) == ((out_size[0] * in_size[1]) * in_size[2]))\n        assert (len(subgraph[0][12]) == ((out_size[0] * in_size[1]) * out_size[2]))\n        assert (len(subgraph[0][13]) == ((out_size[0] * out_size[1]) * in_size[2]))\n        assert (len(subgraph[0][14]) == ((out_size[0] * out_size[1]) * out_size[2]))", "masked_code": "def test_three_hops(self):\n    g = create_test_graph(is_directed=True)\n    bfw = DirectedBreadthFirstNeighbours(g)\n    graph_nodes = g.node_ids_to_ilocs(list(g.nodes()))\n    for _ in range(50):\n        node = random.choice(graph_nodes)\n        in_size = [random.randint(0, 2) for _ in range(3)]\n        out_size = [random.randint(0, 2) for _ in range(3)]\n        subgraph = bfw.run(nodes=[node], n=1, in_size=in_size, out_size=out_size)\n        assert (len(subgraph) == 1)\n        assert (len(subgraph[0]) == 15)\n        assert (len(subgraph[0][0]) == 1)\n        assert (len(subgraph[0][1]) == in_size[0])\n        assert (len(subgraph[0][2]) == out_size[0])\n        assert (len(subgraph[0][3]) == '???')\n        assert (len(subgraph[0][4]) == (in_size[0] * out_size[1]))\n        assert (len(subgraph[0][5]) == (out_size[0] * in_size[1]))\n        assert (len(subgraph[0][6]) == (out_size[0] * out_size[1]))\n        assert (len(subgraph[0][7]) == ((in_size[0] * in_size[1]) * in_size[2]))\n        assert (len(subgraph[0][8]) == ((in_size[0] * in_size[1]) * out_size[2]))\n        assert (len(subgraph[0][9]) == ((in_size[0] * out_size[1]) * in_size[2]))\n        assert (len(subgraph[0][10]) == ((in_size[0] * out_size[1]) * out_size[2]))\n        assert (len(subgraph[0][11]) == ((out_size[0] * in_size[1]) * in_size[2]))\n        assert (len(subgraph[0][12]) == ((out_size[0] * in_size[1]) * out_size[2]))\n        assert (len(subgraph[0][13]) == ((out_size[0] * out_size[1]) * in_size[2]))\n        assert (len(subgraph[0][14]) == ((out_size[0] * out_size[1]) * out_size[2]))", "ground_truth": "(in_size[0] * in_size[1])", "quality_analysis": {"complexity_score": 24, "left_complexity": 12, "right_complexity": 12, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_344", "reponame": "stellargraph", "testpath": "tests/data/test_directed_breadth_first_sampler.py", "testname": "test_directed_breadth_first_sampler.py", "classname": "TestDirectedBreadthFirstNeighbours", "funcname": "test_three_hops", "imports": ["import random", "import pytest", "import pandas as pd", "import numpy as np", "from stellargraph.data.explorer import DirectedBreadthFirstNeighbours", "from stellargraph.core.graph import StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_three_hops(self):\n    g = create_test_graph(is_directed=True)\n    bfw = DirectedBreadthFirstNeighbours(g)\n    graph_nodes = g.node_ids_to_ilocs(list(g.nodes()))\n    for _ in range(50):\n        node = random.choice(graph_nodes)\n        in_size = [random.randint(0, 2) for _ in range(3)]\n        out_size = [random.randint(0, 2) for _ in range(3)]\n        subgraph = bfw.run(nodes=[node], n=1, in_size=in_size, out_size=out_size)\n        assert (len(subgraph) == 1)\n        assert (len(subgraph[0]) == 15)\n        assert (len(subgraph[0][0]) == 1)\n        assert (len(subgraph[0][1]) == in_size[0])\n        assert (len(subgraph[0][2]) == out_size[0])\n        assert (len(subgraph[0][3]) == (in_size[0] * in_size[1]))\n        assert (len(subgraph[0][4]) == (in_size[0] * out_size[1]))\n        assert (len(subgraph[0][5]) == (out_size[0] * in_size[1]))\n        assert (len(subgraph[0][6]) == (out_size[0] * out_size[1]))\n        assert (len(subgraph[0][7]) == ((in_size[0] * in_size[1]) * in_size[2]))\n        assert (len(subgraph[0][8]) == ((in_size[0] * in_size[1]) * out_size[2]))\n        assert (len(subgraph[0][9]) == ((in_size[0] * out_size[1]) * in_size[2]))\n        assert (len(subgraph[0][10]) == ((in_size[0] * out_size[1]) * out_size[2]))\n        assert (len(subgraph[0][11]) == ((out_size[0] * in_size[1]) * in_size[2]))\n        assert (len(subgraph[0][12]) == ((out_size[0] * in_size[1]) * out_size[2]))\n        assert (len(subgraph[0][13]) == ((out_size[0] * out_size[1]) * in_size[2]))\n        assert (len(subgraph[0][14]) == ((out_size[0] * out_size[1]) * out_size[2]))", "masked_code": "def test_three_hops(self):\n    g = create_test_graph(is_directed=True)\n    bfw = DirectedBreadthFirstNeighbours(g)\n    graph_nodes = g.node_ids_to_ilocs(list(g.nodes()))\n    for _ in range(50):\n        node = random.choice(graph_nodes)\n        in_size = [random.randint(0, 2) for _ in range(3)]\n        out_size = [random.randint(0, 2) for _ in range(3)]\n        subgraph = bfw.run(nodes=[node], n=1, in_size=in_size, out_size=out_size)\n        assert (len(subgraph) == 1)\n        assert (len(subgraph[0]) == 15)\n        assert (len(subgraph[0][0]) == 1)\n        assert (len(subgraph[0][1]) == in_size[0])\n        assert (len(subgraph[0][2]) == out_size[0])\n        assert (len(subgraph[0][3]) == (in_size[0] * in_size[1]))\n        assert (len(subgraph[0][4]) == '???')\n        assert (len(subgraph[0][5]) == (out_size[0] * in_size[1]))\n        assert (len(subgraph[0][6]) == (out_size[0] * out_size[1]))\n        assert (len(subgraph[0][7]) == ((in_size[0] * in_size[1]) * in_size[2]))\n        assert (len(subgraph[0][8]) == ((in_size[0] * in_size[1]) * out_size[2]))\n        assert (len(subgraph[0][9]) == ((in_size[0] * out_size[1]) * in_size[2]))\n        assert (len(subgraph[0][10]) == ((in_size[0] * out_size[1]) * out_size[2]))\n        assert (len(subgraph[0][11]) == ((out_size[0] * in_size[1]) * in_size[2]))\n        assert (len(subgraph[0][12]) == ((out_size[0] * in_size[1]) * out_size[2]))\n        assert (len(subgraph[0][13]) == ((out_size[0] * out_size[1]) * in_size[2]))\n        assert (len(subgraph[0][14]) == ((out_size[0] * out_size[1]) * out_size[2]))", "ground_truth": "(in_size[0] * out_size[1])", "quality_analysis": {"complexity_score": 24, "left_complexity": 12, "right_complexity": 12, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_345", "reponame": "stellargraph", "testpath": "tests/data/test_directed_breadth_first_sampler.py", "testname": "test_directed_breadth_first_sampler.py", "classname": "TestDirectedBreadthFirstNeighbours", "funcname": "test_three_hops", "imports": ["import random", "import pytest", "import pandas as pd", "import numpy as np", "from stellargraph.data.explorer import DirectedBreadthFirstNeighbours", "from stellargraph.core.graph import StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_three_hops(self):\n    g = create_test_graph(is_directed=True)\n    bfw = DirectedBreadthFirstNeighbours(g)\n    graph_nodes = g.node_ids_to_ilocs(list(g.nodes()))\n    for _ in range(50):\n        node = random.choice(graph_nodes)\n        in_size = [random.randint(0, 2) for _ in range(3)]\n        out_size = [random.randint(0, 2) for _ in range(3)]\n        subgraph = bfw.run(nodes=[node], n=1, in_size=in_size, out_size=out_size)\n        assert (len(subgraph) == 1)\n        assert (len(subgraph[0]) == 15)\n        assert (len(subgraph[0][0]) == 1)\n        assert (len(subgraph[0][1]) == in_size[0])\n        assert (len(subgraph[0][2]) == out_size[0])\n        assert (len(subgraph[0][3]) == (in_size[0] * in_size[1]))\n        assert (len(subgraph[0][4]) == (in_size[0] * out_size[1]))\n        assert (len(subgraph[0][5]) == (out_size[0] * in_size[1]))\n        assert (len(subgraph[0][6]) == (out_size[0] * out_size[1]))\n        assert (len(subgraph[0][7]) == ((in_size[0] * in_size[1]) * in_size[2]))\n        assert (len(subgraph[0][8]) == ((in_size[0] * in_size[1]) * out_size[2]))\n        assert (len(subgraph[0][9]) == ((in_size[0] * out_size[1]) * in_size[2]))\n        assert (len(subgraph[0][10]) == ((in_size[0] * out_size[1]) * out_size[2]))\n        assert (len(subgraph[0][11]) == ((out_size[0] * in_size[1]) * in_size[2]))\n        assert (len(subgraph[0][12]) == ((out_size[0] * in_size[1]) * out_size[2]))\n        assert (len(subgraph[0][13]) == ((out_size[0] * out_size[1]) * in_size[2]))\n        assert (len(subgraph[0][14]) == ((out_size[0] * out_size[1]) * out_size[2]))", "masked_code": "def test_three_hops(self):\n    g = create_test_graph(is_directed=True)\n    bfw = DirectedBreadthFirstNeighbours(g)\n    graph_nodes = g.node_ids_to_ilocs(list(g.nodes()))\n    for _ in range(50):\n        node = random.choice(graph_nodes)\n        in_size = [random.randint(0, 2) for _ in range(3)]\n        out_size = [random.randint(0, 2) for _ in range(3)]\n        subgraph = bfw.run(nodes=[node], n=1, in_size=in_size, out_size=out_size)\n        assert (len(subgraph) == 1)\n        assert (len(subgraph[0]) == 15)\n        assert (len(subgraph[0][0]) == 1)\n        assert (len(subgraph[0][1]) == in_size[0])\n        assert (len(subgraph[0][2]) == out_size[0])\n        assert (len(subgraph[0][3]) == (in_size[0] * in_size[1]))\n        assert (len(subgraph[0][4]) == (in_size[0] * out_size[1]))\n        assert (len(subgraph[0][5]) == '???')\n        assert (len(subgraph[0][6]) == (out_size[0] * out_size[1]))\n        assert (len(subgraph[0][7]) == ((in_size[0] * in_size[1]) * in_size[2]))\n        assert (len(subgraph[0][8]) == ((in_size[0] * in_size[1]) * out_size[2]))\n        assert (len(subgraph[0][9]) == ((in_size[0] * out_size[1]) * in_size[2]))\n        assert (len(subgraph[0][10]) == ((in_size[0] * out_size[1]) * out_size[2]))\n        assert (len(subgraph[0][11]) == ((out_size[0] * in_size[1]) * in_size[2]))\n        assert (len(subgraph[0][12]) == ((out_size[0] * in_size[1]) * out_size[2]))\n        assert (len(subgraph[0][13]) == ((out_size[0] * out_size[1]) * in_size[2]))\n        assert (len(subgraph[0][14]) == ((out_size[0] * out_size[1]) * out_size[2]))", "ground_truth": "(out_size[0] * in_size[1])", "quality_analysis": {"complexity_score": 24, "left_complexity": 12, "right_complexity": 12, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_346", "reponame": "stellargraph", "testpath": "tests/data/test_directed_breadth_first_sampler.py", "testname": "test_directed_breadth_first_sampler.py", "classname": "TestDirectedBreadthFirstNeighbours", "funcname": "test_three_hops", "imports": ["import random", "import pytest", "import pandas as pd", "import numpy as np", "from stellargraph.data.explorer import DirectedBreadthFirstNeighbours", "from stellargraph.core.graph import StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_three_hops(self):\n    g = create_test_graph(is_directed=True)\n    bfw = DirectedBreadthFirstNeighbours(g)\n    graph_nodes = g.node_ids_to_ilocs(list(g.nodes()))\n    for _ in range(50):\n        node = random.choice(graph_nodes)\n        in_size = [random.randint(0, 2) for _ in range(3)]\n        out_size = [random.randint(0, 2) for _ in range(3)]\n        subgraph = bfw.run(nodes=[node], n=1, in_size=in_size, out_size=out_size)\n        assert (len(subgraph) == 1)\n        assert (len(subgraph[0]) == 15)\n        assert (len(subgraph[0][0]) == 1)\n        assert (len(subgraph[0][1]) == in_size[0])\n        assert (len(subgraph[0][2]) == out_size[0])\n        assert (len(subgraph[0][3]) == (in_size[0] * in_size[1]))\n        assert (len(subgraph[0][4]) == (in_size[0] * out_size[1]))\n        assert (len(subgraph[0][5]) == (out_size[0] * in_size[1]))\n        assert (len(subgraph[0][6]) == (out_size[0] * out_size[1]))\n        assert (len(subgraph[0][7]) == ((in_size[0] * in_size[1]) * in_size[2]))\n        assert (len(subgraph[0][8]) == ((in_size[0] * in_size[1]) * out_size[2]))\n        assert (len(subgraph[0][9]) == ((in_size[0] * out_size[1]) * in_size[2]))\n        assert (len(subgraph[0][10]) == ((in_size[0] * out_size[1]) * out_size[2]))\n        assert (len(subgraph[0][11]) == ((out_size[0] * in_size[1]) * in_size[2]))\n        assert (len(subgraph[0][12]) == ((out_size[0] * in_size[1]) * out_size[2]))\n        assert (len(subgraph[0][13]) == ((out_size[0] * out_size[1]) * in_size[2]))\n        assert (len(subgraph[0][14]) == ((out_size[0] * out_size[1]) * out_size[2]))", "masked_code": "def test_three_hops(self):\n    g = create_test_graph(is_directed=True)\n    bfw = DirectedBreadthFirstNeighbours(g)\n    graph_nodes = g.node_ids_to_ilocs(list(g.nodes()))\n    for _ in range(50):\n        node = random.choice(graph_nodes)\n        in_size = [random.randint(0, 2) for _ in range(3)]\n        out_size = [random.randint(0, 2) for _ in range(3)]\n        subgraph = bfw.run(nodes=[node], n=1, in_size=in_size, out_size=out_size)\n        assert (len(subgraph) == 1)\n        assert (len(subgraph[0]) == 15)\n        assert (len(subgraph[0][0]) == 1)\n        assert (len(subgraph[0][1]) == in_size[0])\n        assert (len(subgraph[0][2]) == out_size[0])\n        assert (len(subgraph[0][3]) == (in_size[0] * in_size[1]))\n        assert (len(subgraph[0][4]) == (in_size[0] * out_size[1]))\n        assert (len(subgraph[0][5]) == (out_size[0] * in_size[1]))\n        assert (len(subgraph[0][6]) == '???')\n        assert (len(subgraph[0][7]) == ((in_size[0] * in_size[1]) * in_size[2]))\n        assert (len(subgraph[0][8]) == ((in_size[0] * in_size[1]) * out_size[2]))\n        assert (len(subgraph[0][9]) == ((in_size[0] * out_size[1]) * in_size[2]))\n        assert (len(subgraph[0][10]) == ((in_size[0] * out_size[1]) * out_size[2]))\n        assert (len(subgraph[0][11]) == ((out_size[0] * in_size[1]) * in_size[2]))\n        assert (len(subgraph[0][12]) == ((out_size[0] * in_size[1]) * out_size[2]))\n        assert (len(subgraph[0][13]) == ((out_size[0] * out_size[1]) * in_size[2]))\n        assert (len(subgraph[0][14]) == ((out_size[0] * out_size[1]) * out_size[2]))", "ground_truth": "(out_size[0] * out_size[1])", "quality_analysis": {"complexity_score": 24, "left_complexity": 12, "right_complexity": 12, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_347", "reponame": "stellargraph", "testpath": "tests/data/test_directed_breadth_first_sampler.py", "testname": "test_directed_breadth_first_sampler.py", "classname": "TestDirectedBreadthFirstNeighbours", "funcname": "test_three_hops", "imports": ["import random", "import pytest", "import pandas as pd", "import numpy as np", "from stellargraph.data.explorer import DirectedBreadthFirstNeighbours", "from stellargraph.core.graph import StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_three_hops(self):\n    g = create_test_graph(is_directed=True)\n    bfw = DirectedBreadthFirstNeighbours(g)\n    graph_nodes = g.node_ids_to_ilocs(list(g.nodes()))\n    for _ in range(50):\n        node = random.choice(graph_nodes)\n        in_size = [random.randint(0, 2) for _ in range(3)]\n        out_size = [random.randint(0, 2) for _ in range(3)]\n        subgraph = bfw.run(nodes=[node], n=1, in_size=in_size, out_size=out_size)\n        assert (len(subgraph) == 1)\n        assert (len(subgraph[0]) == 15)\n        assert (len(subgraph[0][0]) == 1)\n        assert (len(subgraph[0][1]) == in_size[0])\n        assert (len(subgraph[0][2]) == out_size[0])\n        assert (len(subgraph[0][3]) == (in_size[0] * in_size[1]))\n        assert (len(subgraph[0][4]) == (in_size[0] * out_size[1]))\n        assert (len(subgraph[0][5]) == (out_size[0] * in_size[1]))\n        assert (len(subgraph[0][6]) == (out_size[0] * out_size[1]))\n        assert (len(subgraph[0][7]) == ((in_size[0] * in_size[1]) * in_size[2]))\n        assert (len(subgraph[0][8]) == ((in_size[0] * in_size[1]) * out_size[2]))\n        assert (len(subgraph[0][9]) == ((in_size[0] * out_size[1]) * in_size[2]))\n        assert (len(subgraph[0][10]) == ((in_size[0] * out_size[1]) * out_size[2]))\n        assert (len(subgraph[0][11]) == ((out_size[0] * in_size[1]) * in_size[2]))\n        assert (len(subgraph[0][12]) == ((out_size[0] * in_size[1]) * out_size[2]))\n        assert (len(subgraph[0][13]) == ((out_size[0] * out_size[1]) * in_size[2]))\n        assert (len(subgraph[0][14]) == ((out_size[0] * out_size[1]) * out_size[2]))", "masked_code": "def test_three_hops(self):\n    g = create_test_graph(is_directed=True)\n    bfw = DirectedBreadthFirstNeighbours(g)\n    graph_nodes = g.node_ids_to_ilocs(list(g.nodes()))\n    for _ in range(50):\n        node = random.choice(graph_nodes)\n        in_size = [random.randint(0, 2) for _ in range(3)]\n        out_size = [random.randint(0, 2) for _ in range(3)]\n        subgraph = bfw.run(nodes=[node], n=1, in_size=in_size, out_size=out_size)\n        assert (len(subgraph) == 1)\n        assert (len(subgraph[0]) == 15)\n        assert (len(subgraph[0][0]) == 1)\n        assert (len(subgraph[0][1]) == in_size[0])\n        assert (len(subgraph[0][2]) == out_size[0])\n        assert (len(subgraph[0][3]) == (in_size[0] * in_size[1]))\n        assert (len(subgraph[0][4]) == (in_size[0] * out_size[1]))\n        assert (len(subgraph[0][5]) == (out_size[0] * in_size[1]))\n        assert (len(subgraph[0][6]) == (out_size[0] * out_size[1]))\n        assert (len(subgraph[0][7]) == '???')\n        assert (len(subgraph[0][8]) == ((in_size[0] * in_size[1]) * out_size[2]))\n        assert (len(subgraph[0][9]) == ((in_size[0] * out_size[1]) * in_size[2]))\n        assert (len(subgraph[0][10]) == ((in_size[0] * out_size[1]) * out_size[2]))\n        assert (len(subgraph[0][11]) == ((out_size[0] * in_size[1]) * in_size[2]))\n        assert (len(subgraph[0][12]) == ((out_size[0] * in_size[1]) * out_size[2]))\n        assert (len(subgraph[0][13]) == ((out_size[0] * out_size[1]) * in_size[2]))\n        assert (len(subgraph[0][14]) == ((out_size[0] * out_size[1]) * out_size[2]))", "ground_truth": "((in_size[0] * in_size[1]) * in_size[2])", "quality_analysis": {"complexity_score": 31, "left_complexity": 12, "right_complexity": 19, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_348", "reponame": "stellargraph", "testpath": "tests/data/test_directed_breadth_first_sampler.py", "testname": "test_directed_breadth_first_sampler.py", "classname": "TestDirectedBreadthFirstNeighbours", "funcname": "test_three_hops", "imports": ["import random", "import pytest", "import pandas as pd", "import numpy as np", "from stellargraph.data.explorer import DirectedBreadthFirstNeighbours", "from stellargraph.core.graph import StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_three_hops(self):\n    g = create_test_graph(is_directed=True)\n    bfw = DirectedBreadthFirstNeighbours(g)\n    graph_nodes = g.node_ids_to_ilocs(list(g.nodes()))\n    for _ in range(50):\n        node = random.choice(graph_nodes)\n        in_size = [random.randint(0, 2) for _ in range(3)]\n        out_size = [random.randint(0, 2) for _ in range(3)]\n        subgraph = bfw.run(nodes=[node], n=1, in_size=in_size, out_size=out_size)\n        assert (len(subgraph) == 1)\n        assert (len(subgraph[0]) == 15)\n        assert (len(subgraph[0][0]) == 1)\n        assert (len(subgraph[0][1]) == in_size[0])\n        assert (len(subgraph[0][2]) == out_size[0])\n        assert (len(subgraph[0][3]) == (in_size[0] * in_size[1]))\n        assert (len(subgraph[0][4]) == (in_size[0] * out_size[1]))\n        assert (len(subgraph[0][5]) == (out_size[0] * in_size[1]))\n        assert (len(subgraph[0][6]) == (out_size[0] * out_size[1]))\n        assert (len(subgraph[0][7]) == ((in_size[0] * in_size[1]) * in_size[2]))\n        assert (len(subgraph[0][8]) == ((in_size[0] * in_size[1]) * out_size[2]))\n        assert (len(subgraph[0][9]) == ((in_size[0] * out_size[1]) * in_size[2]))\n        assert (len(subgraph[0][10]) == ((in_size[0] * out_size[1]) * out_size[2]))\n        assert (len(subgraph[0][11]) == ((out_size[0] * in_size[1]) * in_size[2]))\n        assert (len(subgraph[0][12]) == ((out_size[0] * in_size[1]) * out_size[2]))\n        assert (len(subgraph[0][13]) == ((out_size[0] * out_size[1]) * in_size[2]))\n        assert (len(subgraph[0][14]) == ((out_size[0] * out_size[1]) * out_size[2]))", "masked_code": "def test_three_hops(self):\n    g = create_test_graph(is_directed=True)\n    bfw = DirectedBreadthFirstNeighbours(g)\n    graph_nodes = g.node_ids_to_ilocs(list(g.nodes()))\n    for _ in range(50):\n        node = random.choice(graph_nodes)\n        in_size = [random.randint(0, 2) for _ in range(3)]\n        out_size = [random.randint(0, 2) for _ in range(3)]\n        subgraph = bfw.run(nodes=[node], n=1, in_size=in_size, out_size=out_size)\n        assert (len(subgraph) == 1)\n        assert (len(subgraph[0]) == 15)\n        assert (len(subgraph[0][0]) == 1)\n        assert (len(subgraph[0][1]) == in_size[0])\n        assert (len(subgraph[0][2]) == out_size[0])\n        assert (len(subgraph[0][3]) == (in_size[0] * in_size[1]))\n        assert (len(subgraph[0][4]) == (in_size[0] * out_size[1]))\n        assert (len(subgraph[0][5]) == (out_size[0] * in_size[1]))\n        assert (len(subgraph[0][6]) == (out_size[0] * out_size[1]))\n        assert (len(subgraph[0][7]) == ((in_size[0] * in_size[1]) * in_size[2]))\n        assert (len(subgraph[0][8]) == '???')\n        assert (len(subgraph[0][9]) == ((in_size[0] * out_size[1]) * in_size[2]))\n        assert (len(subgraph[0][10]) == ((in_size[0] * out_size[1]) * out_size[2]))\n        assert (len(subgraph[0][11]) == ((out_size[0] * in_size[1]) * in_size[2]))\n        assert (len(subgraph[0][12]) == ((out_size[0] * in_size[1]) * out_size[2]))\n        assert (len(subgraph[0][13]) == ((out_size[0] * out_size[1]) * in_size[2]))\n        assert (len(subgraph[0][14]) == ((out_size[0] * out_size[1]) * out_size[2]))", "ground_truth": "((in_size[0] * in_size[1]) * out_size[2])", "quality_analysis": {"complexity_score": 31, "left_complexity": 12, "right_complexity": 19, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_349", "reponame": "stellargraph", "testpath": "tests/data/test_directed_breadth_first_sampler.py", "testname": "test_directed_breadth_first_sampler.py", "classname": "TestDirectedBreadthFirstNeighbours", "funcname": "test_three_hops", "imports": ["import random", "import pytest", "import pandas as pd", "import numpy as np", "from stellargraph.data.explorer import DirectedBreadthFirstNeighbours", "from stellargraph.core.graph import StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_three_hops(self):\n    g = create_test_graph(is_directed=True)\n    bfw = DirectedBreadthFirstNeighbours(g)\n    graph_nodes = g.node_ids_to_ilocs(list(g.nodes()))\n    for _ in range(50):\n        node = random.choice(graph_nodes)\n        in_size = [random.randint(0, 2) for _ in range(3)]\n        out_size = [random.randint(0, 2) for _ in range(3)]\n        subgraph = bfw.run(nodes=[node], n=1, in_size=in_size, out_size=out_size)\n        assert (len(subgraph) == 1)\n        assert (len(subgraph[0]) == 15)\n        assert (len(subgraph[0][0]) == 1)\n        assert (len(subgraph[0][1]) == in_size[0])\n        assert (len(subgraph[0][2]) == out_size[0])\n        assert (len(subgraph[0][3]) == (in_size[0] * in_size[1]))\n        assert (len(subgraph[0][4]) == (in_size[0] * out_size[1]))\n        assert (len(subgraph[0][5]) == (out_size[0] * in_size[1]))\n        assert (len(subgraph[0][6]) == (out_size[0] * out_size[1]))\n        assert (len(subgraph[0][7]) == ((in_size[0] * in_size[1]) * in_size[2]))\n        assert (len(subgraph[0][8]) == ((in_size[0] * in_size[1]) * out_size[2]))\n        assert (len(subgraph[0][9]) == ((in_size[0] * out_size[1]) * in_size[2]))\n        assert (len(subgraph[0][10]) == ((in_size[0] * out_size[1]) * out_size[2]))\n        assert (len(subgraph[0][11]) == ((out_size[0] * in_size[1]) * in_size[2]))\n        assert (len(subgraph[0][12]) == ((out_size[0] * in_size[1]) * out_size[2]))\n        assert (len(subgraph[0][13]) == ((out_size[0] * out_size[1]) * in_size[2]))\n        assert (len(subgraph[0][14]) == ((out_size[0] * out_size[1]) * out_size[2]))", "masked_code": "def test_three_hops(self):\n    g = create_test_graph(is_directed=True)\n    bfw = DirectedBreadthFirstNeighbours(g)\n    graph_nodes = g.node_ids_to_ilocs(list(g.nodes()))\n    for _ in range(50):\n        node = random.choice(graph_nodes)\n        in_size = [random.randint(0, 2) for _ in range(3)]\n        out_size = [random.randint(0, 2) for _ in range(3)]\n        subgraph = bfw.run(nodes=[node], n=1, in_size=in_size, out_size=out_size)\n        assert (len(subgraph) == 1)\n        assert (len(subgraph[0]) == 15)\n        assert (len(subgraph[0][0]) == 1)\n        assert (len(subgraph[0][1]) == in_size[0])\n        assert (len(subgraph[0][2]) == out_size[0])\n        assert (len(subgraph[0][3]) == (in_size[0] * in_size[1]))\n        assert (len(subgraph[0][4]) == (in_size[0] * out_size[1]))\n        assert (len(subgraph[0][5]) == (out_size[0] * in_size[1]))\n        assert (len(subgraph[0][6]) == (out_size[0] * out_size[1]))\n        assert (len(subgraph[0][7]) == ((in_size[0] * in_size[1]) * in_size[2]))\n        assert (len(subgraph[0][8]) == ((in_size[0] * in_size[1]) * out_size[2]))\n        assert (len(subgraph[0][9]) == '???')\n        assert (len(subgraph[0][10]) == ((in_size[0] * out_size[1]) * out_size[2]))\n        assert (len(subgraph[0][11]) == ((out_size[0] * in_size[1]) * in_size[2]))\n        assert (len(subgraph[0][12]) == ((out_size[0] * in_size[1]) * out_size[2]))\n        assert (len(subgraph[0][13]) == ((out_size[0] * out_size[1]) * in_size[2]))\n        assert (len(subgraph[0][14]) == ((out_size[0] * out_size[1]) * out_size[2]))", "ground_truth": "((in_size[0] * out_size[1]) * in_size[2])", "quality_analysis": {"complexity_score": 31, "left_complexity": 12, "right_complexity": 19, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_350", "reponame": "stellargraph", "testpath": "tests/data/test_directed_breadth_first_sampler.py", "testname": "test_directed_breadth_first_sampler.py", "classname": "TestDirectedBreadthFirstNeighbours", "funcname": "test_three_hops", "imports": ["import random", "import pytest", "import pandas as pd", "import numpy as np", "from stellargraph.data.explorer import DirectedBreadthFirstNeighbours", "from stellargraph.core.graph import StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_three_hops(self):\n    g = create_test_graph(is_directed=True)\n    bfw = DirectedBreadthFirstNeighbours(g)\n    graph_nodes = g.node_ids_to_ilocs(list(g.nodes()))\n    for _ in range(50):\n        node = random.choice(graph_nodes)\n        in_size = [random.randint(0, 2) for _ in range(3)]\n        out_size = [random.randint(0, 2) for _ in range(3)]\n        subgraph = bfw.run(nodes=[node], n=1, in_size=in_size, out_size=out_size)\n        assert (len(subgraph) == 1)\n        assert (len(subgraph[0]) == 15)\n        assert (len(subgraph[0][0]) == 1)\n        assert (len(subgraph[0][1]) == in_size[0])\n        assert (len(subgraph[0][2]) == out_size[0])\n        assert (len(subgraph[0][3]) == (in_size[0] * in_size[1]))\n        assert (len(subgraph[0][4]) == (in_size[0] * out_size[1]))\n        assert (len(subgraph[0][5]) == (out_size[0] * in_size[1]))\n        assert (len(subgraph[0][6]) == (out_size[0] * out_size[1]))\n        assert (len(subgraph[0][7]) == ((in_size[0] * in_size[1]) * in_size[2]))\n        assert (len(subgraph[0][8]) == ((in_size[0] * in_size[1]) * out_size[2]))\n        assert (len(subgraph[0][9]) == ((in_size[0] * out_size[1]) * in_size[2]))\n        assert (len(subgraph[0][10]) == ((in_size[0] * out_size[1]) * out_size[2]))\n        assert (len(subgraph[0][11]) == ((out_size[0] * in_size[1]) * in_size[2]))\n        assert (len(subgraph[0][12]) == ((out_size[0] * in_size[1]) * out_size[2]))\n        assert (len(subgraph[0][13]) == ((out_size[0] * out_size[1]) * in_size[2]))\n        assert (len(subgraph[0][14]) == ((out_size[0] * out_size[1]) * out_size[2]))", "masked_code": "def test_three_hops(self):\n    g = create_test_graph(is_directed=True)\n    bfw = DirectedBreadthFirstNeighbours(g)\n    graph_nodes = g.node_ids_to_ilocs(list(g.nodes()))\n    for _ in range(50):\n        node = random.choice(graph_nodes)\n        in_size = [random.randint(0, 2) for _ in range(3)]\n        out_size = [random.randint(0, 2) for _ in range(3)]\n        subgraph = bfw.run(nodes=[node], n=1, in_size=in_size, out_size=out_size)\n        assert (len(subgraph) == 1)\n        assert (len(subgraph[0]) == 15)\n        assert (len(subgraph[0][0]) == 1)\n        assert (len(subgraph[0][1]) == in_size[0])\n        assert (len(subgraph[0][2]) == out_size[0])\n        assert (len(subgraph[0][3]) == (in_size[0] * in_size[1]))\n        assert (len(subgraph[0][4]) == (in_size[0] * out_size[1]))\n        assert (len(subgraph[0][5]) == (out_size[0] * in_size[1]))\n        assert (len(subgraph[0][6]) == (out_size[0] * out_size[1]))\n        assert (len(subgraph[0][7]) == ((in_size[0] * in_size[1]) * in_size[2]))\n        assert (len(subgraph[0][8]) == ((in_size[0] * in_size[1]) * out_size[2]))\n        assert (len(subgraph[0][9]) == ((in_size[0] * out_size[1]) * in_size[2]))\n        assert (len(subgraph[0][10]) == '???')\n        assert (len(subgraph[0][11]) == ((out_size[0] * in_size[1]) * in_size[2]))\n        assert (len(subgraph[0][12]) == ((out_size[0] * in_size[1]) * out_size[2]))\n        assert (len(subgraph[0][13]) == ((out_size[0] * out_size[1]) * in_size[2]))\n        assert (len(subgraph[0][14]) == ((out_size[0] * out_size[1]) * out_size[2]))", "ground_truth": "((in_size[0] * out_size[1]) * out_size[2])", "quality_analysis": {"complexity_score": 31, "left_complexity": 12, "right_complexity": 19, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_351", "reponame": "stellargraph", "testpath": "tests/data/test_directed_breadth_first_sampler.py", "testname": "test_directed_breadth_first_sampler.py", "classname": "TestDirectedBreadthFirstNeighbours", "funcname": "test_three_hops", "imports": ["import random", "import pytest", "import pandas as pd", "import numpy as np", "from stellargraph.data.explorer import DirectedBreadthFirstNeighbours", "from stellargraph.core.graph import StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_three_hops(self):\n    g = create_test_graph(is_directed=True)\n    bfw = DirectedBreadthFirstNeighbours(g)\n    graph_nodes = g.node_ids_to_ilocs(list(g.nodes()))\n    for _ in range(50):\n        node = random.choice(graph_nodes)\n        in_size = [random.randint(0, 2) for _ in range(3)]\n        out_size = [random.randint(0, 2) for _ in range(3)]\n        subgraph = bfw.run(nodes=[node], n=1, in_size=in_size, out_size=out_size)\n        assert (len(subgraph) == 1)\n        assert (len(subgraph[0]) == 15)\n        assert (len(subgraph[0][0]) == 1)\n        assert (len(subgraph[0][1]) == in_size[0])\n        assert (len(subgraph[0][2]) == out_size[0])\n        assert (len(subgraph[0][3]) == (in_size[0] * in_size[1]))\n        assert (len(subgraph[0][4]) == (in_size[0] * out_size[1]))\n        assert (len(subgraph[0][5]) == (out_size[0] * in_size[1]))\n        assert (len(subgraph[0][6]) == (out_size[0] * out_size[1]))\n        assert (len(subgraph[0][7]) == ((in_size[0] * in_size[1]) * in_size[2]))\n        assert (len(subgraph[0][8]) == ((in_size[0] * in_size[1]) * out_size[2]))\n        assert (len(subgraph[0][9]) == ((in_size[0] * out_size[1]) * in_size[2]))\n        assert (len(subgraph[0][10]) == ((in_size[0] * out_size[1]) * out_size[2]))\n        assert (len(subgraph[0][11]) == ((out_size[0] * in_size[1]) * in_size[2]))\n        assert (len(subgraph[0][12]) == ((out_size[0] * in_size[1]) * out_size[2]))\n        assert (len(subgraph[0][13]) == ((out_size[0] * out_size[1]) * in_size[2]))\n        assert (len(subgraph[0][14]) == ((out_size[0] * out_size[1]) * out_size[2]))", "masked_code": "def test_three_hops(self):\n    g = create_test_graph(is_directed=True)\n    bfw = DirectedBreadthFirstNeighbours(g)\n    graph_nodes = g.node_ids_to_ilocs(list(g.nodes()))\n    for _ in range(50):\n        node = random.choice(graph_nodes)\n        in_size = [random.randint(0, 2) for _ in range(3)]\n        out_size = [random.randint(0, 2) for _ in range(3)]\n        subgraph = bfw.run(nodes=[node], n=1, in_size=in_size, out_size=out_size)\n        assert (len(subgraph) == 1)\n        assert (len(subgraph[0]) == 15)\n        assert (len(subgraph[0][0]) == 1)\n        assert (len(subgraph[0][1]) == in_size[0])\n        assert (len(subgraph[0][2]) == out_size[0])\n        assert (len(subgraph[0][3]) == (in_size[0] * in_size[1]))\n        assert (len(subgraph[0][4]) == (in_size[0] * out_size[1]))\n        assert (len(subgraph[0][5]) == (out_size[0] * in_size[1]))\n        assert (len(subgraph[0][6]) == (out_size[0] * out_size[1]))\n        assert (len(subgraph[0][7]) == ((in_size[0] * in_size[1]) * in_size[2]))\n        assert (len(subgraph[0][8]) == ((in_size[0] * in_size[1]) * out_size[2]))\n        assert (len(subgraph[0][9]) == ((in_size[0] * out_size[1]) * in_size[2]))\n        assert (len(subgraph[0][10]) == ((in_size[0] * out_size[1]) * out_size[2]))\n        assert (len(subgraph[0][11]) == '???')\n        assert (len(subgraph[0][12]) == ((out_size[0] * in_size[1]) * out_size[2]))\n        assert (len(subgraph[0][13]) == ((out_size[0] * out_size[1]) * in_size[2]))\n        assert (len(subgraph[0][14]) == ((out_size[0] * out_size[1]) * out_size[2]))", "ground_truth": "((out_size[0] * in_size[1]) * in_size[2])", "quality_analysis": {"complexity_score": 31, "left_complexity": 12, "right_complexity": 19, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_352", "reponame": "stellargraph", "testpath": "tests/data/test_directed_breadth_first_sampler.py", "testname": "test_directed_breadth_first_sampler.py", "classname": "TestDirectedBreadthFirstNeighbours", "funcname": "test_three_hops", "imports": ["import random", "import pytest", "import pandas as pd", "import numpy as np", "from stellargraph.data.explorer import DirectedBreadthFirstNeighbours", "from stellargraph.core.graph import StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_three_hops(self):\n    g = create_test_graph(is_directed=True)\n    bfw = DirectedBreadthFirstNeighbours(g)\n    graph_nodes = g.node_ids_to_ilocs(list(g.nodes()))\n    for _ in range(50):\n        node = random.choice(graph_nodes)\n        in_size = [random.randint(0, 2) for _ in range(3)]\n        out_size = [random.randint(0, 2) for _ in range(3)]\n        subgraph = bfw.run(nodes=[node], n=1, in_size=in_size, out_size=out_size)\n        assert (len(subgraph) == 1)\n        assert (len(subgraph[0]) == 15)\n        assert (len(subgraph[0][0]) == 1)\n        assert (len(subgraph[0][1]) == in_size[0])\n        assert (len(subgraph[0][2]) == out_size[0])\n        assert (len(subgraph[0][3]) == (in_size[0] * in_size[1]))\n        assert (len(subgraph[0][4]) == (in_size[0] * out_size[1]))\n        assert (len(subgraph[0][5]) == (out_size[0] * in_size[1]))\n        assert (len(subgraph[0][6]) == (out_size[0] * out_size[1]))\n        assert (len(subgraph[0][7]) == ((in_size[0] * in_size[1]) * in_size[2]))\n        assert (len(subgraph[0][8]) == ((in_size[0] * in_size[1]) * out_size[2]))\n        assert (len(subgraph[0][9]) == ((in_size[0] * out_size[1]) * in_size[2]))\n        assert (len(subgraph[0][10]) == ((in_size[0] * out_size[1]) * out_size[2]))\n        assert (len(subgraph[0][11]) == ((out_size[0] * in_size[1]) * in_size[2]))\n        assert (len(subgraph[0][12]) == ((out_size[0] * in_size[1]) * out_size[2]))\n        assert (len(subgraph[0][13]) == ((out_size[0] * out_size[1]) * in_size[2]))\n        assert (len(subgraph[0][14]) == ((out_size[0] * out_size[1]) * out_size[2]))", "masked_code": "def test_three_hops(self):\n    g = create_test_graph(is_directed=True)\n    bfw = DirectedBreadthFirstNeighbours(g)\n    graph_nodes = g.node_ids_to_ilocs(list(g.nodes()))\n    for _ in range(50):\n        node = random.choice(graph_nodes)\n        in_size = [random.randint(0, 2) for _ in range(3)]\n        out_size = [random.randint(0, 2) for _ in range(3)]\n        subgraph = bfw.run(nodes=[node], n=1, in_size=in_size, out_size=out_size)\n        assert (len(subgraph) == 1)\n        assert (len(subgraph[0]) == 15)\n        assert (len(subgraph[0][0]) == 1)\n        assert (len(subgraph[0][1]) == in_size[0])\n        assert (len(subgraph[0][2]) == out_size[0])\n        assert (len(subgraph[0][3]) == (in_size[0] * in_size[1]))\n        assert (len(subgraph[0][4]) == (in_size[0] * out_size[1]))\n        assert (len(subgraph[0][5]) == (out_size[0] * in_size[1]))\n        assert (len(subgraph[0][6]) == (out_size[0] * out_size[1]))\n        assert (len(subgraph[0][7]) == ((in_size[0] * in_size[1]) * in_size[2]))\n        assert (len(subgraph[0][8]) == ((in_size[0] * in_size[1]) * out_size[2]))\n        assert (len(subgraph[0][9]) == ((in_size[0] * out_size[1]) * in_size[2]))\n        assert (len(subgraph[0][10]) == ((in_size[0] * out_size[1]) * out_size[2]))\n        assert (len(subgraph[0][11]) == ((out_size[0] * in_size[1]) * in_size[2]))\n        assert (len(subgraph[0][12]) == '???')\n        assert (len(subgraph[0][13]) == ((out_size[0] * out_size[1]) * in_size[2]))\n        assert (len(subgraph[0][14]) == ((out_size[0] * out_size[1]) * out_size[2]))", "ground_truth": "((out_size[0] * in_size[1]) * out_size[2])", "quality_analysis": {"complexity_score": 31, "left_complexity": 12, "right_complexity": 19, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_353", "reponame": "stellargraph", "testpath": "tests/data/test_directed_breadth_first_sampler.py", "testname": "test_directed_breadth_first_sampler.py", "classname": "TestDirectedBreadthFirstNeighbours", "funcname": "test_three_hops", "imports": ["import random", "import pytest", "import pandas as pd", "import numpy as np", "from stellargraph.data.explorer import DirectedBreadthFirstNeighbours", "from stellargraph.core.graph import StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_three_hops(self):\n    g = create_test_graph(is_directed=True)\n    bfw = DirectedBreadthFirstNeighbours(g)\n    graph_nodes = g.node_ids_to_ilocs(list(g.nodes()))\n    for _ in range(50):\n        node = random.choice(graph_nodes)\n        in_size = [random.randint(0, 2) for _ in range(3)]\n        out_size = [random.randint(0, 2) for _ in range(3)]\n        subgraph = bfw.run(nodes=[node], n=1, in_size=in_size, out_size=out_size)\n        assert (len(subgraph) == 1)\n        assert (len(subgraph[0]) == 15)\n        assert (len(subgraph[0][0]) == 1)\n        assert (len(subgraph[0][1]) == in_size[0])\n        assert (len(subgraph[0][2]) == out_size[0])\n        assert (len(subgraph[0][3]) == (in_size[0] * in_size[1]))\n        assert (len(subgraph[0][4]) == (in_size[0] * out_size[1]))\n        assert (len(subgraph[0][5]) == (out_size[0] * in_size[1]))\n        assert (len(subgraph[0][6]) == (out_size[0] * out_size[1]))\n        assert (len(subgraph[0][7]) == ((in_size[0] * in_size[1]) * in_size[2]))\n        assert (len(subgraph[0][8]) == ((in_size[0] * in_size[1]) * out_size[2]))\n        assert (len(subgraph[0][9]) == ((in_size[0] * out_size[1]) * in_size[2]))\n        assert (len(subgraph[0][10]) == ((in_size[0] * out_size[1]) * out_size[2]))\n        assert (len(subgraph[0][11]) == ((out_size[0] * in_size[1]) * in_size[2]))\n        assert (len(subgraph[0][12]) == ((out_size[0] * in_size[1]) * out_size[2]))\n        assert (len(subgraph[0][13]) == ((out_size[0] * out_size[1]) * in_size[2]))\n        assert (len(subgraph[0][14]) == ((out_size[0] * out_size[1]) * out_size[2]))", "masked_code": "def test_three_hops(self):\n    g = create_test_graph(is_directed=True)\n    bfw = DirectedBreadthFirstNeighbours(g)\n    graph_nodes = g.node_ids_to_ilocs(list(g.nodes()))\n    for _ in range(50):\n        node = random.choice(graph_nodes)\n        in_size = [random.randint(0, 2) for _ in range(3)]\n        out_size = [random.randint(0, 2) for _ in range(3)]\n        subgraph = bfw.run(nodes=[node], n=1, in_size=in_size, out_size=out_size)\n        assert (len(subgraph) == 1)\n        assert (len(subgraph[0]) == 15)\n        assert (len(subgraph[0][0]) == 1)\n        assert (len(subgraph[0][1]) == in_size[0])\n        assert (len(subgraph[0][2]) == out_size[0])\n        assert (len(subgraph[0][3]) == (in_size[0] * in_size[1]))\n        assert (len(subgraph[0][4]) == (in_size[0] * out_size[1]))\n        assert (len(subgraph[0][5]) == (out_size[0] * in_size[1]))\n        assert (len(subgraph[0][6]) == (out_size[0] * out_size[1]))\n        assert (len(subgraph[0][7]) == ((in_size[0] * in_size[1]) * in_size[2]))\n        assert (len(subgraph[0][8]) == ((in_size[0] * in_size[1]) * out_size[2]))\n        assert (len(subgraph[0][9]) == ((in_size[0] * out_size[1]) * in_size[2]))\n        assert (len(subgraph[0][10]) == ((in_size[0] * out_size[1]) * out_size[2]))\n        assert (len(subgraph[0][11]) == ((out_size[0] * in_size[1]) * in_size[2]))\n        assert (len(subgraph[0][12]) == ((out_size[0] * in_size[1]) * out_size[2]))\n        assert (len(subgraph[0][13]) == '???')\n        assert (len(subgraph[0][14]) == ((out_size[0] * out_size[1]) * out_size[2]))", "ground_truth": "((out_size[0] * out_size[1]) * in_size[2])", "quality_analysis": {"complexity_score": 31, "left_complexity": 12, "right_complexity": 19, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_354", "reponame": "stellargraph", "testpath": "tests/data/test_directed_breadth_first_sampler.py", "testname": "test_directed_breadth_first_sampler.py", "classname": "TestDirectedBreadthFirstNeighbours", "funcname": "test_three_hops", "imports": ["import random", "import pytest", "import pandas as pd", "import numpy as np", "from stellargraph.data.explorer import DirectedBreadthFirstNeighbours", "from stellargraph.core.graph import StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_three_hops(self):\n    g = create_test_graph(is_directed=True)\n    bfw = DirectedBreadthFirstNeighbours(g)\n    graph_nodes = g.node_ids_to_ilocs(list(g.nodes()))\n    for _ in range(50):\n        node = random.choice(graph_nodes)\n        in_size = [random.randint(0, 2) for _ in range(3)]\n        out_size = [random.randint(0, 2) for _ in range(3)]\n        subgraph = bfw.run(nodes=[node], n=1, in_size=in_size, out_size=out_size)\n        assert (len(subgraph) == 1)\n        assert (len(subgraph[0]) == 15)\n        assert (len(subgraph[0][0]) == 1)\n        assert (len(subgraph[0][1]) == in_size[0])\n        assert (len(subgraph[0][2]) == out_size[0])\n        assert (len(subgraph[0][3]) == (in_size[0] * in_size[1]))\n        assert (len(subgraph[0][4]) == (in_size[0] * out_size[1]))\n        assert (len(subgraph[0][5]) == (out_size[0] * in_size[1]))\n        assert (len(subgraph[0][6]) == (out_size[0] * out_size[1]))\n        assert (len(subgraph[0][7]) == ((in_size[0] * in_size[1]) * in_size[2]))\n        assert (len(subgraph[0][8]) == ((in_size[0] * in_size[1]) * out_size[2]))\n        assert (len(subgraph[0][9]) == ((in_size[0] * out_size[1]) * in_size[2]))\n        assert (len(subgraph[0][10]) == ((in_size[0] * out_size[1]) * out_size[2]))\n        assert (len(subgraph[0][11]) == ((out_size[0] * in_size[1]) * in_size[2]))\n        assert (len(subgraph[0][12]) == ((out_size[0] * in_size[1]) * out_size[2]))\n        assert (len(subgraph[0][13]) == ((out_size[0] * out_size[1]) * in_size[2]))\n        assert (len(subgraph[0][14]) == ((out_size[0] * out_size[1]) * out_size[2]))", "masked_code": "def test_three_hops(self):\n    g = create_test_graph(is_directed=True)\n    bfw = DirectedBreadthFirstNeighbours(g)\n    graph_nodes = g.node_ids_to_ilocs(list(g.nodes()))\n    for _ in range(50):\n        node = random.choice(graph_nodes)\n        in_size = [random.randint(0, 2) for _ in range(3)]\n        out_size = [random.randint(0, 2) for _ in range(3)]\n        subgraph = bfw.run(nodes=[node], n=1, in_size=in_size, out_size=out_size)\n        assert (len(subgraph) == 1)\n        assert (len(subgraph[0]) == 15)\n        assert (len(subgraph[0][0]) == 1)\n        assert (len(subgraph[0][1]) == in_size[0])\n        assert (len(subgraph[0][2]) == out_size[0])\n        assert (len(subgraph[0][3]) == (in_size[0] * in_size[1]))\n        assert (len(subgraph[0][4]) == (in_size[0] * out_size[1]))\n        assert (len(subgraph[0][5]) == (out_size[0] * in_size[1]))\n        assert (len(subgraph[0][6]) == (out_size[0] * out_size[1]))\n        assert (len(subgraph[0][7]) == ((in_size[0] * in_size[1]) * in_size[2]))\n        assert (len(subgraph[0][8]) == ((in_size[0] * in_size[1]) * out_size[2]))\n        assert (len(subgraph[0][9]) == ((in_size[0] * out_size[1]) * in_size[2]))\n        assert (len(subgraph[0][10]) == ((in_size[0] * out_size[1]) * out_size[2]))\n        assert (len(subgraph[0][11]) == ((out_size[0] * in_size[1]) * in_size[2]))\n        assert (len(subgraph[0][12]) == ((out_size[0] * in_size[1]) * out_size[2]))\n        assert (len(subgraph[0][13]) == ((out_size[0] * out_size[1]) * in_size[2]))\n        assert (len(subgraph[0][14]) == '???')", "ground_truth": "((out_size[0] * out_size[1]) * out_size[2])", "quality_analysis": {"complexity_score": 31, "left_complexity": 12, "right_complexity": 19, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_355", "reponame": "stellargraph", "testpath": "tests/data/test_directed_breadth_first_sampler.py", "testname": "test_directed_breadth_first_sampler.py", "classname": "TestDirectedBreadthFirstNeighbours", "funcname": "test_weighted_all_zero", "imports": ["import random", "import pytest", "import pandas as pd", "import numpy as np", "from stellargraph.data.explorer import DirectedBreadthFirstNeighbours", "from stellargraph.core.graph import StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_weighted_all_zero(self):\n    edges = pd.DataFrame({'source': [0, 0], 'target': [1, 2], 'weight': [0.0, 0]})\n    g = StellarDiGraph(edges=edges)\n    bfw = DirectedBreadthFirstNeighbours(g)\n    walks = bfw.run(nodes=[0], n=10, in_size=[20, 20], out_size=[20, 20], weighted=True)\n    assert (len(walks) == 10)\n    for walk in walks:\n        assert (len(walk) == 7)\n        assert (walk[0] == [0])\n        for hop in walk:\n            np.testing.assert_array_equal(hop[1:], (- 1))", "masked_code": "def test_weighted_all_zero(self):\n    edges = pd.DataFrame({'source': [0, 0], 'target': [1, 2], 'weight': [0.0, 0]})\n    g = StellarDiGraph(edges=edges)\n    bfw = DirectedBreadthFirstNeighbours(g)\n    walks = bfw.run(nodes=[0], n=10, in_size=[20, 20], out_size=[20, 20], weighted=True)\n    assert (len(walks) == '???')\n    for walk in walks:\n        assert (len(walk) == 7)\n        assert (walk[0] == [0])\n        for hop in walk:\n            np.testing.assert_array_equal(hop[1:], (- 1))", "ground_truth": "10", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_356", "reponame": "stellargraph", "testpath": "tests/data/test_directed_breadth_first_sampler.py", "testname": "test_directed_breadth_first_sampler.py", "classname": "TestDirectedBreadthFirstNeighbours", "funcname": "test_weighted_all_zero", "imports": ["import random", "import pytest", "import pandas as pd", "import numpy as np", "from stellargraph.data.explorer import DirectedBreadthFirstNeighbours", "from stellargraph.core.graph import StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_weighted_all_zero(self):\n    edges = pd.DataFrame({'source': [0, 0], 'target': [1, 2], 'weight': [0.0, 0]})\n    g = StellarDiGraph(edges=edges)\n    bfw = DirectedBreadthFirstNeighbours(g)\n    walks = bfw.run(nodes=[0], n=10, in_size=[20, 20], out_size=[20, 20], weighted=True)\n    assert (len(walks) == 10)\n    for walk in walks:\n        assert (len(walk) == 7)\n        assert (walk[0] == [0])\n        for hop in walk:\n            np.testing.assert_array_equal(hop[1:], (- 1))", "masked_code": "def test_weighted_all_zero(self):\n    edges = pd.DataFrame({'source': [0, 0], 'target': [1, 2], 'weight': [0.0, 0]})\n    g = StellarDiGraph(edges=edges)\n    bfw = DirectedBreadthFirstNeighbours(g)\n    walks = bfw.run(nodes=[0], n=10, in_size=[20, 20], out_size=[20, 20], weighted=True)\n    assert (len(walks) == 10)\n    for walk in walks:\n        assert (len(walk) == '???')\n        assert (walk[0] == [0])\n        for hop in walk:\n            np.testing.assert_array_equal(hop[1:], (- 1))", "ground_truth": "7", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_357", "reponame": "stellargraph", "testpath": "tests/data/test_directed_breadth_first_sampler.py", "testname": "test_directed_breadth_first_sampler.py", "classname": "TestDirectedBreadthFirstNeighbours", "funcname": "test_weighted_all_zero", "imports": ["import random", "import pytest", "import pandas as pd", "import numpy as np", "from stellargraph.data.explorer import DirectedBreadthFirstNeighbours", "from stellargraph.core.graph import StellarDiGraph", "from ..test_utils.graphs import create_test_graph, tree_graph, example_graph_random, weighted_tree"], "code": "def test_weighted_all_zero(self):\n    edges = pd.DataFrame({'source': [0, 0], 'target': [1, 2], 'weight': [0.0, 0]})\n    g = StellarDiGraph(edges=edges)\n    bfw = DirectedBreadthFirstNeighbours(g)\n    walks = bfw.run(nodes=[0], n=10, in_size=[20, 20], out_size=[20, 20], weighted=True)\n    assert (len(walks) == 10)\n    for walk in walks:\n        assert (len(walk) == 7)\n        assert (walk[0] == [0])\n        for hop in walk:\n            np.testing.assert_array_equal(hop[1:], (- 1))", "masked_code": "def test_weighted_all_zero(self):\n    edges = pd.DataFrame({'source': [0, 0], 'target': [1, 2], 'weight': [0.0, 0]})\n    g = StellarDiGraph(edges=edges)\n    bfw = DirectedBreadthFirstNeighbours(g)\n    walks = bfw.run(nodes=[0], n=10, in_size=[20, 20], out_size=[20, 20], weighted=True)\n    assert (len(walks) == 10)\n    for walk in walks:\n        assert (len(walk) == 7)\n        assert (walk[0] == '???')\n        for hop in walk:\n            np.testing.assert_array_equal(hop[1:], (- 1))", "ground_truth": "[0]", "quality_analysis": {"complexity_score": 8, "left_complexity": 5, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_358", "reponame": "stellargraph", "testpath": "tests/data/test_edge_splitter.py", "testname": "test_edge_splitter.py", "classname": "TestEdgeSplitterHomogeneous", "funcname": "test_split_data_global", "imports": ["import pytest", "import os", "import numpy as np", "import networkx as nx", "from stellargraph import StellarGraph", "from stellargraph.data.edge_splitter import EdgeSplitter", "from stellargraph.data.epgm import EPGM", "import random", "import datetime", "from datetime import datetime, timedelta", "from ..test_utils import flaky_xfail_mark", "from ..test_utils.graphs import example_graph_random"], "code": "def test_split_data_global(self, cora):\n    (g, es_obj) = cora\n    p = 0.1\n    (g_test, edge_data_ids_test, edge_data_labels_test) = es_obj.train_test_split(p=p, method='global', keep_connected=True)\n    num_sampled_positives = np.sum((edge_data_labels_test == 1))\n    num_sampled_negatives = np.sum((edge_data_labels_test == 0))\n    assert (num_sampled_positives > 0)\n    assert (num_sampled_negatives > 0)\n    assert (len(edge_data_ids_test) == len(edge_data_labels_test))\n    assert ((num_sampled_positives - num_sampled_negatives) == 0)\n    assert (len(g_test.edges()) < len(g.edges()))\n    assert nx.is_connected(g_test)\n    with pytest.raises(ValueError):\n        (g_test, edge_data_ids_test, edge_data_labels_test) = es_obj.train_test_split(p=0.8, method='global', keep_connected=True)", "masked_code": "def test_split_data_global(self, cora):\n    (g, es_obj) = cora\n    p = 0.1\n    (g_test, edge_data_ids_test, edge_data_labels_test) = es_obj.train_test_split(p=p, method='global', keep_connected=True)\n    num_sampled_positives = np.sum((edge_data_labels_test == 1))\n    num_sampled_negatives = np.sum((edge_data_labels_test == 0))\n    assert (num_sampled_positives > 0)\n    assert (num_sampled_negatives > 0)\n    assert (len(edge_data_ids_test) == '???')\n    assert ((num_sampled_positives - num_sampled_negatives) == 0)\n    assert (len(g_test.edges()) < len(g.edges()))\n    assert nx.is_connected(g_test)\n    with pytest.raises(ValueError):\n        (g_test, edge_data_ids_test, edge_data_labels_test) = es_obj.train_test_split(p=0.8, method='global', keep_connected=True)", "ground_truth": "len(edge_data_labels_test)", "quality_analysis": {"complexity_score": 8, "left_complexity": 4, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_359", "reponame": "stellargraph", "testpath": "tests/data/test_edge_splitter.py", "testname": "test_edge_splitter.py", "classname": "TestEdgeSplitterHomogeneous", "funcname": "test_split_data_local", "imports": ["import pytest", "import os", "import numpy as np", "import networkx as nx", "from stellargraph import StellarGraph", "from stellargraph.data.edge_splitter import EdgeSplitter", "from stellargraph.data.epgm import EPGM", "import random", "import datetime", "from datetime import datetime, timedelta", "from ..test_utils import flaky_xfail_mark", "from ..test_utils.graphs import example_graph_random"], "code": "def test_split_data_local(self, cora):\n    (g, es_obj) = cora\n    p = 0.1\n    (g_test, edge_data_ids_test, edge_data_labels_test) = es_obj.train_test_split(p=p, method='local', keep_connected=True)\n    num_sampled_positives = np.sum((edge_data_labels_test == 1))\n    num_sampled_negatives = np.sum((edge_data_labels_test == 0))\n    assert (num_sampled_positives > 0)\n    assert (num_sampled_negatives > 0)\n    assert (len(edge_data_ids_test) == len(edge_data_labels_test))\n    assert ((num_sampled_positives - num_sampled_negatives) == 0)\n    assert (len(g_test.edges()) < len(g.edges()))\n    assert nx.is_connected(g_test)\n    sampling_probs = [0.0, 0.0, 0.1, 0.2, 0.5, 0.2]\n    (g_test, edge_data_ids_test, edge_data_labels_test) = es_obj.train_test_split(p=p, method='local', probs=sampling_probs, keep_connected=True)\n    num_sampled_positives = np.sum((edge_data_labels_test == 1))\n    num_sampled_negatives = np.sum((edge_data_labels_test == 0))\n    assert (num_sampled_positives > 0)\n    assert (num_sampled_negatives > 0)\n    assert (len(edge_data_ids_test) == len(edge_data_labels_test))\n    assert ((num_sampled_positives - num_sampled_negatives) == 0)\n    assert (len(g_test.edges()) < len(g.edges()))\n    assert nx.is_connected(g_test)\n    with pytest.raises(ValueError):\n        es_obj.train_test_split(p=0.8, method='local', probs=sampling_probs, keep_connected=True)\n    sampling_probs = [0.2, 0.1, 0.2, 0.5, 0.2]\n    with pytest.raises(ValueError):\n        es_obj.train_test_split(p=p, method='local', probs=sampling_probs)", "masked_code": "def test_split_data_local(self, cora):\n    (g, es_obj) = cora\n    p = 0.1\n    (g_test, edge_data_ids_test, edge_data_labels_test) = es_obj.train_test_split(p=p, method='local', keep_connected=True)\n    num_sampled_positives = np.sum((edge_data_labels_test == 1))\n    num_sampled_negatives = np.sum((edge_data_labels_test == 0))\n    assert (num_sampled_positives > 0)\n    assert (num_sampled_negatives > 0)\n    assert (len(edge_data_ids_test) == '???')\n    assert ((num_sampled_positives - num_sampled_negatives) == 0)\n    assert (len(g_test.edges()) < len(g.edges()))\n    assert nx.is_connected(g_test)\n    sampling_probs = [0.0, 0.0, 0.1, 0.2, 0.5, 0.2]\n    (g_test, edge_data_ids_test, edge_data_labels_test) = es_obj.train_test_split(p=p, method='local', probs=sampling_probs, keep_connected=True)\n    num_sampled_positives = np.sum((edge_data_labels_test == 1))\n    num_sampled_negatives = np.sum((edge_data_labels_test == 0))\n    assert (num_sampled_positives > 0)\n    assert (num_sampled_negatives > 0)\n    assert (len(edge_data_ids_test) == len(edge_data_labels_test))\n    assert ((num_sampled_positives - num_sampled_negatives) == 0)\n    assert (len(g_test.edges()) < len(g.edges()))\n    assert nx.is_connected(g_test)\n    with pytest.raises(ValueError):\n        es_obj.train_test_split(p=0.8, method='local', probs=sampling_probs, keep_connected=True)\n    sampling_probs = [0.2, 0.1, 0.2, 0.5, 0.2]\n    with pytest.raises(ValueError):\n        es_obj.train_test_split(p=p, method='local', probs=sampling_probs)", "ground_truth": "len(edge_data_labels_test)", "quality_analysis": {"complexity_score": 8, "left_complexity": 4, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_360", "reponame": "stellargraph", "testpath": "tests/data/test_edge_splitter.py", "testname": "test_edge_splitter.py", "classname": "TestEdgeSplitterHomogeneous", "funcname": "test_split_data_local", "imports": ["import pytest", "import os", "import numpy as np", "import networkx as nx", "from stellargraph import StellarGraph", "from stellargraph.data.edge_splitter import EdgeSplitter", "from stellargraph.data.epgm import EPGM", "import random", "import datetime", "from datetime import datetime, timedelta", "from ..test_utils import flaky_xfail_mark", "from ..test_utils.graphs import example_graph_random"], "code": "def test_split_data_local(self, cora):\n    (g, es_obj) = cora\n    p = 0.1\n    (g_test, edge_data_ids_test, edge_data_labels_test) = es_obj.train_test_split(p=p, method='local', keep_connected=True)\n    num_sampled_positives = np.sum((edge_data_labels_test == 1))\n    num_sampled_negatives = np.sum((edge_data_labels_test == 0))\n    assert (num_sampled_positives > 0)\n    assert (num_sampled_negatives > 0)\n    assert (len(edge_data_ids_test) == len(edge_data_labels_test))\n    assert ((num_sampled_positives - num_sampled_negatives) == 0)\n    assert (len(g_test.edges()) < len(g.edges()))\n    assert nx.is_connected(g_test)\n    sampling_probs = [0.0, 0.0, 0.1, 0.2, 0.5, 0.2]\n    (g_test, edge_data_ids_test, edge_data_labels_test) = es_obj.train_test_split(p=p, method='local', probs=sampling_probs, keep_connected=True)\n    num_sampled_positives = np.sum((edge_data_labels_test == 1))\n    num_sampled_negatives = np.sum((edge_data_labels_test == 0))\n    assert (num_sampled_positives > 0)\n    assert (num_sampled_negatives > 0)\n    assert (len(edge_data_ids_test) == len(edge_data_labels_test))\n    assert ((num_sampled_positives - num_sampled_negatives) == 0)\n    assert (len(g_test.edges()) < len(g.edges()))\n    assert nx.is_connected(g_test)\n    with pytest.raises(ValueError):\n        es_obj.train_test_split(p=0.8, method='local', probs=sampling_probs, keep_connected=True)\n    sampling_probs = [0.2, 0.1, 0.2, 0.5, 0.2]\n    with pytest.raises(ValueError):\n        es_obj.train_test_split(p=p, method='local', probs=sampling_probs)", "masked_code": "def test_split_data_local(self, cora):\n    (g, es_obj) = cora\n    p = 0.1\n    (g_test, edge_data_ids_test, edge_data_labels_test) = es_obj.train_test_split(p=p, method='local', keep_connected=True)\n    num_sampled_positives = np.sum((edge_data_labels_test == 1))\n    num_sampled_negatives = np.sum((edge_data_labels_test == 0))\n    assert (num_sampled_positives > 0)\n    assert (num_sampled_negatives > 0)\n    assert (len(edge_data_ids_test) == len(edge_data_labels_test))\n    assert ((num_sampled_positives - num_sampled_negatives) == 0)\n    assert (len(g_test.edges()) < len(g.edges()))\n    assert nx.is_connected(g_test)\n    sampling_probs = [0.0, 0.0, 0.1, 0.2, 0.5, 0.2]\n    (g_test, edge_data_ids_test, edge_data_labels_test) = es_obj.train_test_split(p=p, method='local', probs=sampling_probs, keep_connected=True)\n    num_sampled_positives = np.sum((edge_data_labels_test == 1))\n    num_sampled_negatives = np.sum((edge_data_labels_test == 0))\n    assert (num_sampled_positives > 0)\n    assert (num_sampled_negatives > 0)\n    assert (len(edge_data_ids_test) == '???')\n    assert ((num_sampled_positives - num_sampled_negatives) == 0)\n    assert (len(g_test.edges()) < len(g.edges()))\n    assert nx.is_connected(g_test)\n    with pytest.raises(ValueError):\n        es_obj.train_test_split(p=0.8, method='local', probs=sampling_probs, keep_connected=True)\n    sampling_probs = [0.2, 0.1, 0.2, 0.5, 0.2]\n    with pytest.raises(ValueError):\n        es_obj.train_test_split(p=p, method='local', probs=sampling_probs)", "ground_truth": "len(edge_data_labels_test)", "quality_analysis": {"complexity_score": 8, "left_complexity": 4, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_361", "reponame": "stellargraph", "testpath": "tests/data/test_edge_splitter.py", "testname": "test_edge_splitter.py", "classname": "TestEdgeSplitterHeterogeneous", "funcname": "test_split_data_global", "imports": ["import pytest", "import os", "import numpy as np", "import networkx as nx", "from stellargraph import StellarGraph", "from stellargraph.data.edge_splitter import EdgeSplitter", "from stellargraph.data.epgm import EPGM", "import random", "import datetime", "from datetime import datetime, timedelta", "from ..test_utils import flaky_xfail_mark", "from ..test_utils.graphs import example_graph_random"], "code": "def test_split_data_global(self, heterogeneous_graph):\n    (g, es_obj) = heterogeneous_graph\n    p = 0.1\n    (g_test, edge_data_ids_test, edge_data_labels_test) = es_obj.train_test_split(p=p, method='global', keep_connected=True)\n    num_sampled_positives = np.sum((edge_data_labels_test == 1))\n    num_sampled_negatives = np.sum((edge_data_labels_test == 0))\n    assert (num_sampled_positives > 0)\n    assert (num_sampled_negatives > 0)\n    assert (len(edge_data_ids_test) == len(edge_data_labels_test))\n    assert ((num_sampled_positives - num_sampled_negatives) == 0)\n    assert (len(g_test.edges()) < len(g.edges()))\n    assert nx.is_connected(g_test)", "masked_code": "def test_split_data_global(self, heterogeneous_graph):\n    (g, es_obj) = heterogeneous_graph\n    p = 0.1\n    (g_test, edge_data_ids_test, edge_data_labels_test) = es_obj.train_test_split(p=p, method='global', keep_connected=True)\n    num_sampled_positives = np.sum((edge_data_labels_test == 1))\n    num_sampled_negatives = np.sum((edge_data_labels_test == 0))\n    assert (num_sampled_positives > 0)\n    assert (num_sampled_negatives > 0)\n    assert (len(edge_data_ids_test) == '???')\n    assert ((num_sampled_positives - num_sampled_negatives) == 0)\n    assert (len(g_test.edges()) < len(g.edges()))\n    assert nx.is_connected(g_test)", "ground_truth": "len(edge_data_labels_test)", "quality_analysis": {"complexity_score": 8, "left_complexity": 4, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_362", "reponame": "stellargraph", "testpath": "tests/data/test_edge_splitter.py", "testname": "test_edge_splitter.py", "classname": "TestEdgeSplitterHeterogeneous", "funcname": "test_split_data_local", "imports": ["import pytest", "import os", "import numpy as np", "import networkx as nx", "from stellargraph import StellarGraph", "from stellargraph.data.edge_splitter import EdgeSplitter", "from stellargraph.data.epgm import EPGM", "import random", "import datetime", "from datetime import datetime, timedelta", "from ..test_utils import flaky_xfail_mark", "from ..test_utils.graphs import example_graph_random"], "code": "def test_split_data_local(self, heterogeneous_graph):\n    (g, es_obj) = heterogeneous_graph\n    p = 0.1\n    (g_test, edge_data_ids_test, edge_data_labels_test) = es_obj.train_test_split(p=p, method='local', keep_connected=True)\n    num_sampled_positives = np.sum((edge_data_labels_test == 1))\n    num_sampled_negatives = np.sum((edge_data_labels_test == 0))\n    assert (num_sampled_positives > 0)\n    assert (num_sampled_negatives > 0)\n    assert (len(edge_data_ids_test) == len(edge_data_labels_test))\n    assert ((num_sampled_positives - num_sampled_negatives) == 0)\n    assert (len(g_test.edges()) < len(g.edges()))\n    assert nx.is_connected(g_test)", "masked_code": "def test_split_data_local(self, heterogeneous_graph):\n    (g, es_obj) = heterogeneous_graph\n    p = 0.1\n    (g_test, edge_data_ids_test, edge_data_labels_test) = es_obj.train_test_split(p=p, method='local', keep_connected=True)\n    num_sampled_positives = np.sum((edge_data_labels_test == 1))\n    num_sampled_negatives = np.sum((edge_data_labels_test == 0))\n    assert (num_sampled_positives > 0)\n    assert (num_sampled_negatives > 0)\n    assert (len(edge_data_ids_test) == '???')\n    assert ((num_sampled_positives - num_sampled_negatives) == 0)\n    assert (len(g_test.edges()) < len(g.edges()))\n    assert nx.is_connected(g_test)", "ground_truth": "len(edge_data_labels_test)", "quality_analysis": {"complexity_score": 8, "left_complexity": 4, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_363", "reponame": "stellargraph", "testpath": "tests/data/test_epgm.py", "testname": "test_epgm.py", "classname": "Test_EPGM_IO_Homogeneous", "funcname": "test_load_epgm", "imports": ["import pytest", "import os", "import numpy as np", "from stellargraph.data.epgm import EPGM"], "code": "def test_load_epgm(self):\n    'Test that the EPGM is loaded correctly from epgm path'\n    G_epgm = EPGM(self.input_dir)\n    print(self.input_dir)\n    assert ('graphs' in G_epgm.G.keys())\n    assert ('vertices' in G_epgm.G.keys())\n    assert ('edges' in G_epgm.G.keys())\n    assert (len(G_epgm.G['graphs']) > 0)\n    graph_id = G_epgm.G['graphs'][0]['id']\n    assert (self.target_attribute in G_epgm.node_attributes(graph_id, self.node_type))\n    n_nodes = 2708\n    nodes = G_epgm.G['vertices']\n    assert (len(nodes) == n_nodes)\n    assert (sum([('data' in v) for v in nodes]) == n_nodes)\n    subjects = np.unique([v['data'][self.target_attribute] for v in nodes])\n    assert (len(subjects) == 7)", "masked_code": "def test_load_epgm(self):\n    'Test that the EPGM is loaded correctly from epgm path'\n    G_epgm = EPGM(self.input_dir)\n    print(self.input_dir)\n    assert ('graphs' in G_epgm.G.keys())\n    assert ('vertices' in G_epgm.G.keys())\n    assert ('edges' in G_epgm.G.keys())\n    assert (len(G_epgm.G['graphs']) > 0)\n    graph_id = G_epgm.G['graphs'][0]['id']\n    assert (self.target_attribute in G_epgm.node_attributes(graph_id, self.node_type))\n    n_nodes = 2708\n    nodes = G_epgm.G['vertices']\n    assert (len(nodes) == '???')\n    assert (sum([('data' in v) for v in nodes]) == n_nodes)\n    subjects = np.unique([v['data'][self.target_attribute] for v in nodes])\n    assert (len(subjects) == 7)", "ground_truth": "n_nodes", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_364", "reponame": "stellargraph", "testpath": "tests/data/test_epgm.py", "testname": "test_epgm.py", "classname": "Test_EPGM_IO_Homogeneous", "funcname": "test_load_epgm", "imports": ["import pytest", "import os", "import numpy as np", "from stellargraph.data.epgm import EPGM"], "code": "def test_load_epgm(self):\n    'Test that the EPGM is loaded correctly from epgm path'\n    G_epgm = EPGM(self.input_dir)\n    print(self.input_dir)\n    assert ('graphs' in G_epgm.G.keys())\n    assert ('vertices' in G_epgm.G.keys())\n    assert ('edges' in G_epgm.G.keys())\n    assert (len(G_epgm.G['graphs']) > 0)\n    graph_id = G_epgm.G['graphs'][0]['id']\n    assert (self.target_attribute in G_epgm.node_attributes(graph_id, self.node_type))\n    n_nodes = 2708\n    nodes = G_epgm.G['vertices']\n    assert (len(nodes) == n_nodes)\n    assert (sum([('data' in v) for v in nodes]) == n_nodes)\n    subjects = np.unique([v['data'][self.target_attribute] for v in nodes])\n    assert (len(subjects) == 7)", "masked_code": "def test_load_epgm(self):\n    'Test that the EPGM is loaded correctly from epgm path'\n    G_epgm = EPGM(self.input_dir)\n    print(self.input_dir)\n    assert ('graphs' in G_epgm.G.keys())\n    assert ('vertices' in G_epgm.G.keys())\n    assert ('edges' in G_epgm.G.keys())\n    assert (len(G_epgm.G['graphs']) > 0)\n    graph_id = G_epgm.G['graphs'][0]['id']\n    assert (self.target_attribute in G_epgm.node_attributes(graph_id, self.node_type))\n    n_nodes = 2708\n    nodes = G_epgm.G['vertices']\n    assert (len(nodes) == n_nodes)\n    assert (sum([('data' in v) for v in nodes]) == '???')\n    subjects = np.unique([v['data'][self.target_attribute] for v in nodes])\n    assert (len(subjects) == 7)", "ground_truth": "n_nodes", "quality_analysis": {"complexity_score": 4, "left_complexity": 3, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_365", "reponame": "stellargraph", "testpath": "tests/data/test_epgm.py", "testname": "test_epgm.py", "classname": "Test_EPGM_IO_Homogeneous", "funcname": "test_load_epgm", "imports": ["import pytest", "import os", "import numpy as np", "from stellargraph.data.epgm import EPGM"], "code": "def test_load_epgm(self):\n    'Test that the EPGM is loaded correctly from epgm path'\n    G_epgm = EPGM(self.input_dir)\n    print(self.input_dir)\n    assert ('graphs' in G_epgm.G.keys())\n    assert ('vertices' in G_epgm.G.keys())\n    assert ('edges' in G_epgm.G.keys())\n    assert (len(G_epgm.G['graphs']) > 0)\n    graph_id = G_epgm.G['graphs'][0]['id']\n    assert (self.target_attribute in G_epgm.node_attributes(graph_id, self.node_type))\n    n_nodes = 2708\n    nodes = G_epgm.G['vertices']\n    assert (len(nodes) == n_nodes)\n    assert (sum([('data' in v) for v in nodes]) == n_nodes)\n    subjects = np.unique([v['data'][self.target_attribute] for v in nodes])\n    assert (len(subjects) == 7)", "masked_code": "def test_load_epgm(self):\n    'Test that the EPGM is loaded correctly from epgm path'\n    G_epgm = EPGM(self.input_dir)\n    print(self.input_dir)\n    assert ('graphs' in G_epgm.G.keys())\n    assert ('vertices' in G_epgm.G.keys())\n    assert ('edges' in G_epgm.G.keys())\n    assert (len(G_epgm.G['graphs']) > 0)\n    graph_id = G_epgm.G['graphs'][0]['id']\n    assert (self.target_attribute in G_epgm.node_attributes(graph_id, self.node_type))\n    n_nodes = 2708\n    nodes = G_epgm.G['vertices']\n    assert (len(nodes) == n_nodes)\n    assert (sum([('data' in v) for v in nodes]) == n_nodes)\n    subjects = np.unique([v['data'][self.target_attribute] for v in nodes])\n    assert (len(subjects) == '???')", "ground_truth": "7", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_366", "reponame": "stellargraph", "testpath": "tests/data/test_epgm.py", "testname": "test_epgm.py", "classname": "Test_EPGM_IO_Homogeneous", "funcname": "test_node_attributes", "imports": ["import pytest", "import os", "import numpy as np", "from stellargraph.data.epgm import EPGM"], "code": "def test_node_attributes(self):\n    'Test the .node_attributes() method'\n    G_epgm = EPGM(self.input_dir)\n    graph_id = G_epgm.G['graphs'][0]['id']\n    node_attributes = G_epgm.node_attributes(graph_id, self.node_type)\n    assert (self.target_attribute in node_attributes)\n    if self.epgm_input:\n        assert (len(node_attributes) == 1433), 'There should be 1433 unique node attributes; found {}'.format(len(node_attributes))\n    else:\n        assert (len(node_attributes) == 1434), 'There should be 1434 unique node attributes; found {}'.format(len(node_attributes))\n    assert (len(G_epgm.node_attributes(graph_id, 'person')) == 0)\n    with pytest.raises(TypeError):\n        G_epgm.node_attributes(graph_id)", "masked_code": "def test_node_attributes(self):\n    'Test the .node_attributes() method'\n    G_epgm = EPGM(self.input_dir)\n    graph_id = G_epgm.G['graphs'][0]['id']\n    node_attributes = G_epgm.node_attributes(graph_id, self.node_type)\n    assert (self.target_attribute in node_attributes)\n    if self.epgm_input:\n        assert (len(node_attributes) == '???'), 'There should be 1433 unique node attributes; found {}'.format(len(node_attributes))\n    else:\n        assert (len(node_attributes) == 1434), 'There should be 1434 unique node attributes; found {}'.format(len(node_attributes))\n    assert (len(G_epgm.node_attributes(graph_id, 'person')) == 0)\n    with pytest.raises(TypeError):\n        G_epgm.node_attributes(graph_id)", "ground_truth": "1433", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_367", "reponame": "stellargraph", "testpath": "tests/data/test_epgm.py", "testname": "test_epgm.py", "classname": "Test_EPGM_IO_Homogeneous", "funcname": "test_node_attributes", "imports": ["import pytest", "import os", "import numpy as np", "from stellargraph.data.epgm import EPGM"], "code": "def test_node_attributes(self):\n    'Test the .node_attributes() method'\n    G_epgm = EPGM(self.input_dir)\n    graph_id = G_epgm.G['graphs'][0]['id']\n    node_attributes = G_epgm.node_attributes(graph_id, self.node_type)\n    assert (self.target_attribute in node_attributes)\n    if self.epgm_input:\n        assert (len(node_attributes) == 1433), 'There should be 1433 unique node attributes; found {}'.format(len(node_attributes))\n    else:\n        assert (len(node_attributes) == 1434), 'There should be 1434 unique node attributes; found {}'.format(len(node_attributes))\n    assert (len(G_epgm.node_attributes(graph_id, 'person')) == 0)\n    with pytest.raises(TypeError):\n        G_epgm.node_attributes(graph_id)", "masked_code": "def test_node_attributes(self):\n    'Test the .node_attributes() method'\n    G_epgm = EPGM(self.input_dir)\n    graph_id = G_epgm.G['graphs'][0]['id']\n    node_attributes = G_epgm.node_attributes(graph_id, self.node_type)\n    assert (self.target_attribute in node_attributes)\n    if self.epgm_input:\n        assert (len(node_attributes) == 1433), 'There should be 1433 unique node attributes; found {}'.format(len(node_attributes))\n    else:\n        assert (len(node_attributes) == '???'), 'There should be 1434 unique node attributes; found {}'.format(len(node_attributes))\n    assert (len(G_epgm.node_attributes(graph_id, 'person')) == 0)\n    with pytest.raises(TypeError):\n        G_epgm.node_attributes(graph_id)", "ground_truth": "1434", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_368", "reponame": "stellargraph", "testpath": "tests/data/test_epgm.py", "testname": "test_epgm.py", "classname": "Test_EPGM_IO_Heterogeneous", "funcname": "test_load_epgm", "imports": ["import pytest", "import os", "import numpy as np", "from stellargraph.data.epgm import EPGM"], "code": "def test_load_epgm(self):\n    'Test that the EPGM is loaded correctly from epgm path'\n    G_epgm = EPGM(self.input_dir)\n    assert ('graphs' in G_epgm.G.keys())\n    assert ('vertices' in G_epgm.G.keys())\n    assert ('edges' in G_epgm.G.keys())\n    assert (len(G_epgm.G['graphs']) > 0)\n    graph_id = G_epgm.G['graphs'][0]['id']\n    assert (self.target_attribute in G_epgm.node_attributes(graph_id, self.node_type))\n    n_nodes = 260\n    nodes = G_epgm.G['vertices']\n    assert (len(nodes) == n_nodes)\n    assert (sum([('data' in v) for v in nodes]) == n_nodes)\n    labels_all = [v['data'].get(self.target_attribute) for v in nodes]\n    labels = list(filter((lambda l: (l is not None)), labels_all))\n    assert (len(np.unique(labels)) == 3)", "masked_code": "def test_load_epgm(self):\n    'Test that the EPGM is loaded correctly from epgm path'\n    G_epgm = EPGM(self.input_dir)\n    assert ('graphs' in G_epgm.G.keys())\n    assert ('vertices' in G_epgm.G.keys())\n    assert ('edges' in G_epgm.G.keys())\n    assert (len(G_epgm.G['graphs']) > 0)\n    graph_id = G_epgm.G['graphs'][0]['id']\n    assert (self.target_attribute in G_epgm.node_attributes(graph_id, self.node_type))\n    n_nodes = 260\n    nodes = G_epgm.G['vertices']\n    assert (len(nodes) == '???')\n    assert (sum([('data' in v) for v in nodes]) == n_nodes)\n    labels_all = [v['data'].get(self.target_attribute) for v in nodes]\n    labels = list(filter((lambda l: (l is not None)), labels_all))\n    assert (len(np.unique(labels)) == 3)", "ground_truth": "n_nodes", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_369", "reponame": "stellargraph", "testpath": "tests/data/test_epgm.py", "testname": "test_epgm.py", "classname": "Test_EPGM_IO_Heterogeneous", "funcname": "test_load_epgm", "imports": ["import pytest", "import os", "import numpy as np", "from stellargraph.data.epgm import EPGM"], "code": "def test_load_epgm(self):\n    'Test that the EPGM is loaded correctly from epgm path'\n    G_epgm = EPGM(self.input_dir)\n    assert ('graphs' in G_epgm.G.keys())\n    assert ('vertices' in G_epgm.G.keys())\n    assert ('edges' in G_epgm.G.keys())\n    assert (len(G_epgm.G['graphs']) > 0)\n    graph_id = G_epgm.G['graphs'][0]['id']\n    assert (self.target_attribute in G_epgm.node_attributes(graph_id, self.node_type))\n    n_nodes = 260\n    nodes = G_epgm.G['vertices']\n    assert (len(nodes) == n_nodes)\n    assert (sum([('data' in v) for v in nodes]) == n_nodes)\n    labels_all = [v['data'].get(self.target_attribute) for v in nodes]\n    labels = list(filter((lambda l: (l is not None)), labels_all))\n    assert (len(np.unique(labels)) == 3)", "masked_code": "def test_load_epgm(self):\n    'Test that the EPGM is loaded correctly from epgm path'\n    G_epgm = EPGM(self.input_dir)\n    assert ('graphs' in G_epgm.G.keys())\n    assert ('vertices' in G_epgm.G.keys())\n    assert ('edges' in G_epgm.G.keys())\n    assert (len(G_epgm.G['graphs']) > 0)\n    graph_id = G_epgm.G['graphs'][0]['id']\n    assert (self.target_attribute in G_epgm.node_attributes(graph_id, self.node_type))\n    n_nodes = 260\n    nodes = G_epgm.G['vertices']\n    assert (len(nodes) == n_nodes)\n    assert (sum([('data' in v) for v in nodes]) == '???')\n    labels_all = [v['data'].get(self.target_attribute) for v in nodes]\n    labels = list(filter((lambda l: (l is not None)), labels_all))\n    assert (len(np.unique(labels)) == 3)", "ground_truth": "n_nodes", "quality_analysis": {"complexity_score": 4, "left_complexity": 3, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_370", "reponame": "stellargraph", "testpath": "tests/data/test_epgm.py", "testname": "test_epgm.py", "classname": "Test_EPGM_IO_Heterogeneous", "funcname": "test_load_epgm", "imports": ["import pytest", "import os", "import numpy as np", "from stellargraph.data.epgm import EPGM"], "code": "def test_load_epgm(self):\n    'Test that the EPGM is loaded correctly from epgm path'\n    G_epgm = EPGM(self.input_dir)\n    assert ('graphs' in G_epgm.G.keys())\n    assert ('vertices' in G_epgm.G.keys())\n    assert ('edges' in G_epgm.G.keys())\n    assert (len(G_epgm.G['graphs']) > 0)\n    graph_id = G_epgm.G['graphs'][0]['id']\n    assert (self.target_attribute in G_epgm.node_attributes(graph_id, self.node_type))\n    n_nodes = 260\n    nodes = G_epgm.G['vertices']\n    assert (len(nodes) == n_nodes)\n    assert (sum([('data' in v) for v in nodes]) == n_nodes)\n    labels_all = [v['data'].get(self.target_attribute) for v in nodes]\n    labels = list(filter((lambda l: (l is not None)), labels_all))\n    assert (len(np.unique(labels)) == 3)", "masked_code": "def test_load_epgm(self):\n    'Test that the EPGM is loaded correctly from epgm path'\n    G_epgm = EPGM(self.input_dir)\n    assert ('graphs' in G_epgm.G.keys())\n    assert ('vertices' in G_epgm.G.keys())\n    assert ('edges' in G_epgm.G.keys())\n    assert (len(G_epgm.G['graphs']) > 0)\n    graph_id = G_epgm.G['graphs'][0]['id']\n    assert (self.target_attribute in G_epgm.node_attributes(graph_id, self.node_type))\n    n_nodes = 260\n    nodes = G_epgm.G['vertices']\n    assert (len(nodes) == n_nodes)\n    assert (sum([('data' in v) for v in nodes]) == n_nodes)\n    labels_all = [v['data'].get(self.target_attribute) for v in nodes]\n    labels = list(filter((lambda l: (l is not None)), labels_all))\n    assert (len(np.unique(labels)) == '???')", "ground_truth": "3", "quality_analysis": {"complexity_score": 8, "left_complexity": 7, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_371", "reponame": "stellargraph", "testpath": "tests/data/test_epgm.py", "testname": "test_epgm.py", "classname": "Test_EPGM_IO_Heterogeneous", "funcname": "test_node_types", "imports": ["import pytest", "import os", "import numpy as np", "from stellargraph.data.epgm import EPGM"], "code": "def test_node_types(self):\n    'Test the .node_types() method'\n    G_epgm = EPGM(self.input_dir)\n    graph_id = G_epgm.G['graphs'][0]['id']\n    node_types = G_epgm.node_types(graph_id)\n    assert (len(node_types) == 3)\n    assert ('person' in node_types)\n    assert ('paper' in node_types)\n    assert ('venue' in node_types)\n    with pytest.raises(Exception):\n        G_epgm.node_types('invalid_graph_id')", "masked_code": "def test_node_types(self):\n    'Test the .node_types() method'\n    G_epgm = EPGM(self.input_dir)\n    graph_id = G_epgm.G['graphs'][0]['id']\n    node_types = G_epgm.node_types(graph_id)\n    assert (len(node_types) == '???')\n    assert ('person' in node_types)\n    assert ('paper' in node_types)\n    assert ('venue' in node_types)\n    with pytest.raises(Exception):\n        G_epgm.node_types('invalid_graph_id')", "ground_truth": "3", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_372", "reponame": "stellargraph", "testpath": "tests/data/test_heterogeneous_breadth_first_walker.py", "testname": "test_heterogeneous_breadth_first_walker.py", "classname": "TestSampledHeterogeneousBreadthFirstWalk", "funcname": "test_walk_generation_single_root_node_loner", "imports": ["import pandas as pd", "import numpy as np", "import pytest", "from stellargraph.data.explorer import SampledHeterogeneousBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph", "from ..test_utils.graphs import example_graph_random"], "code": "def test_walk_generation_single_root_node_loner(self):\n    '\\n        Tests that the sampler behaves correctly when a root node is isolated with no self loop\\n        Returns:\\n\\n        '\n    g = create_test_graph(self_loop=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs([0])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 3)\n    assert (subgraphs[0][0][0] == g.node_ids_to_ilocs([0])[0])\n    assert (len(subgraphs[0][1]) == 0)\n    assert (len(subgraphs[0][2]) == 0)\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 9)\n    assert (subgraphs[0][0][0] == g.node_ids_to_ilocs([0])[0])\n    assert (len(subgraphs[0][1]) == 2)\n    assert all([(x == (- 1)) for x in subgraphs[0][1]])\n    assert (len(subgraphs[0][2]) == 2)\n    assert all([(x == (- 1)) for x in subgraphs[0][2]])", "masked_code": "def test_walk_generation_single_root_node_loner(self):\n    '\\n        Tests that the sampler behaves correctly when a root node is isolated with no self loop\\n        Returns:\\n\\n        '\n    g = create_test_graph(self_loop=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs([0])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == '???')\n    assert (subgraphs[0][0][0] == g.node_ids_to_ilocs([0])[0])\n    assert (len(subgraphs[0][1]) == 0)\n    assert (len(subgraphs[0][2]) == 0)\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 9)\n    assert (subgraphs[0][0][0] == g.node_ids_to_ilocs([0])[0])\n    assert (len(subgraphs[0][1]) == 2)\n    assert all([(x == (- 1)) for x in subgraphs[0][1]])\n    assert (len(subgraphs[0][2]) == 2)\n    assert all([(x == (- 1)) for x in subgraphs[0][2]])", "ground_truth": "3", "quality_analysis": {"complexity_score": 9, "left_complexity": 8, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_373", "reponame": "stellargraph", "testpath": "tests/data/test_heterogeneous_breadth_first_walker.py", "testname": "test_heterogeneous_breadth_first_walker.py", "classname": "TestSampledHeterogeneousBreadthFirstWalk", "funcname": "test_walk_generation_single_root_node_loner", "imports": ["import pandas as pd", "import numpy as np", "import pytest", "from stellargraph.data.explorer import SampledHeterogeneousBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph", "from ..test_utils.graphs import example_graph_random"], "code": "def test_walk_generation_single_root_node_loner(self):\n    '\\n        Tests that the sampler behaves correctly when a root node is isolated with no self loop\\n        Returns:\\n\\n        '\n    g = create_test_graph(self_loop=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs([0])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 3)\n    assert (subgraphs[0][0][0] == g.node_ids_to_ilocs([0])[0])\n    assert (len(subgraphs[0][1]) == 0)\n    assert (len(subgraphs[0][2]) == 0)\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 9)\n    assert (subgraphs[0][0][0] == g.node_ids_to_ilocs([0])[0])\n    assert (len(subgraphs[0][1]) == 2)\n    assert all([(x == (- 1)) for x in subgraphs[0][1]])\n    assert (len(subgraphs[0][2]) == 2)\n    assert all([(x == (- 1)) for x in subgraphs[0][2]])", "masked_code": "def test_walk_generation_single_root_node_loner(self):\n    '\\n        Tests that the sampler behaves correctly when a root node is isolated with no self loop\\n        Returns:\\n\\n        '\n    g = create_test_graph(self_loop=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs([0])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 3)\n    assert (subgraphs[0][0][0] == '???')\n    assert (len(subgraphs[0][1]) == 0)\n    assert (len(subgraphs[0][2]) == 0)\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 9)\n    assert (subgraphs[0][0][0] == g.node_ids_to_ilocs([0])[0])\n    assert (len(subgraphs[0][1]) == 2)\n    assert all([(x == (- 1)) for x in subgraphs[0][1]])\n    assert (len(subgraphs[0][2]) == 2)\n    assert all([(x == (- 1)) for x in subgraphs[0][2]])", "ground_truth": "g.node_ids_to_ilocs([0])[0]", "quality_analysis": {"complexity_score": 23, "left_complexity": 13, "right_complexity": 10, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_374", "reponame": "stellargraph", "testpath": "tests/data/test_heterogeneous_breadth_first_walker.py", "testname": "test_heterogeneous_breadth_first_walker.py", "classname": "TestSampledHeterogeneousBreadthFirstWalk", "funcname": "test_walk_generation_single_root_node_loner", "imports": ["import pandas as pd", "import numpy as np", "import pytest", "from stellargraph.data.explorer import SampledHeterogeneousBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph", "from ..test_utils.graphs import example_graph_random"], "code": "def test_walk_generation_single_root_node_loner(self):\n    '\\n        Tests that the sampler behaves correctly when a root node is isolated with no self loop\\n        Returns:\\n\\n        '\n    g = create_test_graph(self_loop=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs([0])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 3)\n    assert (subgraphs[0][0][0] == g.node_ids_to_ilocs([0])[0])\n    assert (len(subgraphs[0][1]) == 0)\n    assert (len(subgraphs[0][2]) == 0)\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 9)\n    assert (subgraphs[0][0][0] == g.node_ids_to_ilocs([0])[0])\n    assert (len(subgraphs[0][1]) == 2)\n    assert all([(x == (- 1)) for x in subgraphs[0][1]])\n    assert (len(subgraphs[0][2]) == 2)\n    assert all([(x == (- 1)) for x in subgraphs[0][2]])", "masked_code": "def test_walk_generation_single_root_node_loner(self):\n    '\\n        Tests that the sampler behaves correctly when a root node is isolated with no self loop\\n        Returns:\\n\\n        '\n    g = create_test_graph(self_loop=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs([0])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 3)\n    assert (subgraphs[0][0][0] == g.node_ids_to_ilocs([0])[0])\n    assert (len(subgraphs[0][1]) == 0)\n    assert (len(subgraphs[0][2]) == 0)\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == '???')\n    assert (subgraphs[0][0][0] == g.node_ids_to_ilocs([0])[0])\n    assert (len(subgraphs[0][1]) == 2)\n    assert all([(x == (- 1)) for x in subgraphs[0][1]])\n    assert (len(subgraphs[0][2]) == 2)\n    assert all([(x == (- 1)) for x in subgraphs[0][2]])", "ground_truth": "9", "quality_analysis": {"complexity_score": 9, "left_complexity": 8, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_375", "reponame": "stellargraph", "testpath": "tests/data/test_heterogeneous_breadth_first_walker.py", "testname": "test_heterogeneous_breadth_first_walker.py", "classname": "TestSampledHeterogeneousBreadthFirstWalk", "funcname": "test_walk_generation_single_root_node_loner", "imports": ["import pandas as pd", "import numpy as np", "import pytest", "from stellargraph.data.explorer import SampledHeterogeneousBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph", "from ..test_utils.graphs import example_graph_random"], "code": "def test_walk_generation_single_root_node_loner(self):\n    '\\n        Tests that the sampler behaves correctly when a root node is isolated with no self loop\\n        Returns:\\n\\n        '\n    g = create_test_graph(self_loop=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs([0])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 3)\n    assert (subgraphs[0][0][0] == g.node_ids_to_ilocs([0])[0])\n    assert (len(subgraphs[0][1]) == 0)\n    assert (len(subgraphs[0][2]) == 0)\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 9)\n    assert (subgraphs[0][0][0] == g.node_ids_to_ilocs([0])[0])\n    assert (len(subgraphs[0][1]) == 2)\n    assert all([(x == (- 1)) for x in subgraphs[0][1]])\n    assert (len(subgraphs[0][2]) == 2)\n    assert all([(x == (- 1)) for x in subgraphs[0][2]])", "masked_code": "def test_walk_generation_single_root_node_loner(self):\n    '\\n        Tests that the sampler behaves correctly when a root node is isolated with no self loop\\n        Returns:\\n\\n        '\n    g = create_test_graph(self_loop=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs([0])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 3)\n    assert (subgraphs[0][0][0] == g.node_ids_to_ilocs([0])[0])\n    assert (len(subgraphs[0][1]) == 0)\n    assert (len(subgraphs[0][2]) == 0)\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 9)\n    assert (subgraphs[0][0][0] == '???')\n    assert (len(subgraphs[0][1]) == 2)\n    assert all([(x == (- 1)) for x in subgraphs[0][1]])\n    assert (len(subgraphs[0][2]) == 2)\n    assert all([(x == (- 1)) for x in subgraphs[0][2]])", "ground_truth": "g.node_ids_to_ilocs([0])[0]", "quality_analysis": {"complexity_score": 23, "left_complexity": 13, "right_complexity": 10, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_376", "reponame": "stellargraph", "testpath": "tests/data/test_heterogeneous_breadth_first_walker.py", "testname": "test_heterogeneous_breadth_first_walker.py", "classname": "TestSampledHeterogeneousBreadthFirstWalk", "funcname": "test_walk_generation_single_root_node_self_loner", "imports": ["import pandas as pd", "import numpy as np", "import pytest", "from stellargraph.data.explorer import SampledHeterogeneousBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph", "from ..test_utils.graphs import example_graph_random"], "code": "def test_walk_generation_single_root_node_self_loner(self):\n    g = create_test_graph(self_loop=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs([7])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 3)\n    assert (subgraphs[0][0][0] == nodes[0])\n    assert (len(subgraphs[0][1]) == 0)\n    assert (len(subgraphs[0][2]) == 0)\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 3)\n    assert (subgraphs[0][0][0] == nodes[0])\n    assert (subgraphs[0][1][0] == nodes[0])\n    assert (len(subgraphs[0][2]) == 1)\n    assert (subgraphs[0][2] == [(- 1)])\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 9)\n    for level in subgraphs[0]:\n        assert (type(level) == list)\n        if (len(level) > 0):\n            for value in level:\n                assert ((value == nodes[0]) or (value == (- 1)))\n    n_size = [2, 2, 3]\n    subgraphs2 = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs2) == 1)\n    assert (len(subgraphs2[0]) == 29)\n    assert all([(subgraphs[0][ii] == subgraphs2[0][ii]) for ii in range(len(subgraphs))])\n    for level in subgraphs2[0]:\n        assert (type(level) == list)\n        if (len(level) > 0):\n            for value in level:\n                assert ((value == nodes[0]) or (value == (- 1)))", "masked_code": "def test_walk_generation_single_root_node_self_loner(self):\n    g = create_test_graph(self_loop=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs([7])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == '???')\n    assert (subgraphs[0][0][0] == nodes[0])\n    assert (len(subgraphs[0][1]) == 0)\n    assert (len(subgraphs[0][2]) == 0)\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 3)\n    assert (subgraphs[0][0][0] == nodes[0])\n    assert (subgraphs[0][1][0] == nodes[0])\n    assert (len(subgraphs[0][2]) == 1)\n    assert (subgraphs[0][2] == [(- 1)])\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 9)\n    for level in subgraphs[0]:\n        assert (type(level) == list)\n        if (len(level) > 0):\n            for value in level:\n                assert ((value == nodes[0]) or (value == (- 1)))\n    n_size = [2, 2, 3]\n    subgraphs2 = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs2) == 1)\n    assert (len(subgraphs2[0]) == 29)\n    assert all([(subgraphs[0][ii] == subgraphs2[0][ii]) for ii in range(len(subgraphs))])\n    for level in subgraphs2[0]:\n        assert (type(level) == list)\n        if (len(level) > 0):\n            for value in level:\n                assert ((value == nodes[0]) or (value == (- 1)))", "ground_truth": "3", "quality_analysis": {"complexity_score": 9, "left_complexity": 8, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_377", "reponame": "stellargraph", "testpath": "tests/data/test_heterogeneous_breadth_first_walker.py", "testname": "test_heterogeneous_breadth_first_walker.py", "classname": "TestSampledHeterogeneousBreadthFirstWalk", "funcname": "test_walk_generation_single_root_node_self_loner", "imports": ["import pandas as pd", "import numpy as np", "import pytest", "from stellargraph.data.explorer import SampledHeterogeneousBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph", "from ..test_utils.graphs import example_graph_random"], "code": "def test_walk_generation_single_root_node_self_loner(self):\n    g = create_test_graph(self_loop=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs([7])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 3)\n    assert (subgraphs[0][0][0] == nodes[0])\n    assert (len(subgraphs[0][1]) == 0)\n    assert (len(subgraphs[0][2]) == 0)\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 3)\n    assert (subgraphs[0][0][0] == nodes[0])\n    assert (subgraphs[0][1][0] == nodes[0])\n    assert (len(subgraphs[0][2]) == 1)\n    assert (subgraphs[0][2] == [(- 1)])\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 9)\n    for level in subgraphs[0]:\n        assert (type(level) == list)\n        if (len(level) > 0):\n            for value in level:\n                assert ((value == nodes[0]) or (value == (- 1)))\n    n_size = [2, 2, 3]\n    subgraphs2 = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs2) == 1)\n    assert (len(subgraphs2[0]) == 29)\n    assert all([(subgraphs[0][ii] == subgraphs2[0][ii]) for ii in range(len(subgraphs))])\n    for level in subgraphs2[0]:\n        assert (type(level) == list)\n        if (len(level) > 0):\n            for value in level:\n                assert ((value == nodes[0]) or (value == (- 1)))", "masked_code": "def test_walk_generation_single_root_node_self_loner(self):\n    g = create_test_graph(self_loop=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs([7])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 3)\n    assert (subgraphs[0][0][0] == '???')\n    assert (len(subgraphs[0][1]) == 0)\n    assert (len(subgraphs[0][2]) == 0)\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 3)\n    assert (subgraphs[0][0][0] == nodes[0])\n    assert (subgraphs[0][1][0] == nodes[0])\n    assert (len(subgraphs[0][2]) == 1)\n    assert (subgraphs[0][2] == [(- 1)])\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 9)\n    for level in subgraphs[0]:\n        assert (type(level) == list)\n        if (len(level) > 0):\n            for value in level:\n                assert ((value == nodes[0]) or (value == (- 1)))\n    n_size = [2, 2, 3]\n    subgraphs2 = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs2) == 1)\n    assert (len(subgraphs2[0]) == 29)\n    assert all([(subgraphs[0][ii] == subgraphs2[0][ii]) for ii in range(len(subgraphs))])\n    for level in subgraphs2[0]:\n        assert (type(level) == list)\n        if (len(level) > 0):\n            for value in level:\n                assert ((value == nodes[0]) or (value == (- 1)))", "ground_truth": "nodes[0]", "quality_analysis": {"complexity_score": 18, "left_complexity": 13, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_378", "reponame": "stellargraph", "testpath": "tests/data/test_heterogeneous_breadth_first_walker.py", "testname": "test_heterogeneous_breadth_first_walker.py", "classname": "TestSampledHeterogeneousBreadthFirstWalk", "funcname": "test_walk_generation_single_root_node_self_loner", "imports": ["import pandas as pd", "import numpy as np", "import pytest", "from stellargraph.data.explorer import SampledHeterogeneousBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph", "from ..test_utils.graphs import example_graph_random"], "code": "def test_walk_generation_single_root_node_self_loner(self):\n    g = create_test_graph(self_loop=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs([7])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 3)\n    assert (subgraphs[0][0][0] == nodes[0])\n    assert (len(subgraphs[0][1]) == 0)\n    assert (len(subgraphs[0][2]) == 0)\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 3)\n    assert (subgraphs[0][0][0] == nodes[0])\n    assert (subgraphs[0][1][0] == nodes[0])\n    assert (len(subgraphs[0][2]) == 1)\n    assert (subgraphs[0][2] == [(- 1)])\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 9)\n    for level in subgraphs[0]:\n        assert (type(level) == list)\n        if (len(level) > 0):\n            for value in level:\n                assert ((value == nodes[0]) or (value == (- 1)))\n    n_size = [2, 2, 3]\n    subgraphs2 = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs2) == 1)\n    assert (len(subgraphs2[0]) == 29)\n    assert all([(subgraphs[0][ii] == subgraphs2[0][ii]) for ii in range(len(subgraphs))])\n    for level in subgraphs2[0]:\n        assert (type(level) == list)\n        if (len(level) > 0):\n            for value in level:\n                assert ((value == nodes[0]) or (value == (- 1)))", "masked_code": "def test_walk_generation_single_root_node_self_loner(self):\n    g = create_test_graph(self_loop=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs([7])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 3)\n    assert (subgraphs[0][0][0] == nodes[0])\n    assert (len(subgraphs[0][1]) == 0)\n    assert (len(subgraphs[0][2]) == 0)\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == '???')\n    assert (subgraphs[0][0][0] == nodes[0])\n    assert (subgraphs[0][1][0] == nodes[0])\n    assert (len(subgraphs[0][2]) == 1)\n    assert (subgraphs[0][2] == [(- 1)])\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 9)\n    for level in subgraphs[0]:\n        assert (type(level) == list)\n        if (len(level) > 0):\n            for value in level:\n                assert ((value == nodes[0]) or (value == (- 1)))\n    n_size = [2, 2, 3]\n    subgraphs2 = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs2) == 1)\n    assert (len(subgraphs2[0]) == 29)\n    assert all([(subgraphs[0][ii] == subgraphs2[0][ii]) for ii in range(len(subgraphs))])\n    for level in subgraphs2[0]:\n        assert (type(level) == list)\n        if (len(level) > 0):\n            for value in level:\n                assert ((value == nodes[0]) or (value == (- 1)))", "ground_truth": "3", "quality_analysis": {"complexity_score": 9, "left_complexity": 8, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_379", "reponame": "stellargraph", "testpath": "tests/data/test_heterogeneous_breadth_first_walker.py", "testname": "test_heterogeneous_breadth_first_walker.py", "classname": "TestSampledHeterogeneousBreadthFirstWalk", "funcname": "test_walk_generation_single_root_node_self_loner", "imports": ["import pandas as pd", "import numpy as np", "import pytest", "from stellargraph.data.explorer import SampledHeterogeneousBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph", "from ..test_utils.graphs import example_graph_random"], "code": "def test_walk_generation_single_root_node_self_loner(self):\n    g = create_test_graph(self_loop=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs([7])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 3)\n    assert (subgraphs[0][0][0] == nodes[0])\n    assert (len(subgraphs[0][1]) == 0)\n    assert (len(subgraphs[0][2]) == 0)\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 3)\n    assert (subgraphs[0][0][0] == nodes[0])\n    assert (subgraphs[0][1][0] == nodes[0])\n    assert (len(subgraphs[0][2]) == 1)\n    assert (subgraphs[0][2] == [(- 1)])\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 9)\n    for level in subgraphs[0]:\n        assert (type(level) == list)\n        if (len(level) > 0):\n            for value in level:\n                assert ((value == nodes[0]) or (value == (- 1)))\n    n_size = [2, 2, 3]\n    subgraphs2 = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs2) == 1)\n    assert (len(subgraphs2[0]) == 29)\n    assert all([(subgraphs[0][ii] == subgraphs2[0][ii]) for ii in range(len(subgraphs))])\n    for level in subgraphs2[0]:\n        assert (type(level) == list)\n        if (len(level) > 0):\n            for value in level:\n                assert ((value == nodes[0]) or (value == (- 1)))", "masked_code": "def test_walk_generation_single_root_node_self_loner(self):\n    g = create_test_graph(self_loop=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs([7])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 3)\n    assert (subgraphs[0][0][0] == nodes[0])\n    assert (len(subgraphs[0][1]) == 0)\n    assert (len(subgraphs[0][2]) == 0)\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 3)\n    assert (subgraphs[0][0][0] == '???')\n    assert (subgraphs[0][1][0] == nodes[0])\n    assert (len(subgraphs[0][2]) == 1)\n    assert (subgraphs[0][2] == [(- 1)])\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 9)\n    for level in subgraphs[0]:\n        assert (type(level) == list)\n        if (len(level) > 0):\n            for value in level:\n                assert ((value == nodes[0]) or (value == (- 1)))\n    n_size = [2, 2, 3]\n    subgraphs2 = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs2) == 1)\n    assert (len(subgraphs2[0]) == 29)\n    assert all([(subgraphs[0][ii] == subgraphs2[0][ii]) for ii in range(len(subgraphs))])\n    for level in subgraphs2[0]:\n        assert (type(level) == list)\n        if (len(level) > 0):\n            for value in level:\n                assert ((value == nodes[0]) or (value == (- 1)))", "ground_truth": "nodes[0]", "quality_analysis": {"complexity_score": 18, "left_complexity": 13, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_380", "reponame": "stellargraph", "testpath": "tests/data/test_heterogeneous_breadth_first_walker.py", "testname": "test_heterogeneous_breadth_first_walker.py", "classname": "TestSampledHeterogeneousBreadthFirstWalk", "funcname": "test_walk_generation_single_root_node_self_loner", "imports": ["import pandas as pd", "import numpy as np", "import pytest", "from stellargraph.data.explorer import SampledHeterogeneousBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph", "from ..test_utils.graphs import example_graph_random"], "code": "def test_walk_generation_single_root_node_self_loner(self):\n    g = create_test_graph(self_loop=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs([7])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 3)\n    assert (subgraphs[0][0][0] == nodes[0])\n    assert (len(subgraphs[0][1]) == 0)\n    assert (len(subgraphs[0][2]) == 0)\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 3)\n    assert (subgraphs[0][0][0] == nodes[0])\n    assert (subgraphs[0][1][0] == nodes[0])\n    assert (len(subgraphs[0][2]) == 1)\n    assert (subgraphs[0][2] == [(- 1)])\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 9)\n    for level in subgraphs[0]:\n        assert (type(level) == list)\n        if (len(level) > 0):\n            for value in level:\n                assert ((value == nodes[0]) or (value == (- 1)))\n    n_size = [2, 2, 3]\n    subgraphs2 = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs2) == 1)\n    assert (len(subgraphs2[0]) == 29)\n    assert all([(subgraphs[0][ii] == subgraphs2[0][ii]) for ii in range(len(subgraphs))])\n    for level in subgraphs2[0]:\n        assert (type(level) == list)\n        if (len(level) > 0):\n            for value in level:\n                assert ((value == nodes[0]) or (value == (- 1)))", "masked_code": "def test_walk_generation_single_root_node_self_loner(self):\n    g = create_test_graph(self_loop=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs([7])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 3)\n    assert (subgraphs[0][0][0] == nodes[0])\n    assert (len(subgraphs[0][1]) == 0)\n    assert (len(subgraphs[0][2]) == 0)\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 3)\n    assert (subgraphs[0][0][0] == nodes[0])\n    assert (subgraphs[0][1][0] == '???')\n    assert (len(subgraphs[0][2]) == 1)\n    assert (subgraphs[0][2] == [(- 1)])\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 9)\n    for level in subgraphs[0]:\n        assert (type(level) == list)\n        if (len(level) > 0):\n            for value in level:\n                assert ((value == nodes[0]) or (value == (- 1)))\n    n_size = [2, 2, 3]\n    subgraphs2 = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs2) == 1)\n    assert (len(subgraphs2[0]) == 29)\n    assert all([(subgraphs[0][ii] == subgraphs2[0][ii]) for ii in range(len(subgraphs))])\n    for level in subgraphs2[0]:\n        assert (type(level) == list)\n        if (len(level) > 0):\n            for value in level:\n                assert ((value == nodes[0]) or (value == (- 1)))", "ground_truth": "nodes[0]", "quality_analysis": {"complexity_score": 18, "left_complexity": 13, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_381", "reponame": "stellargraph", "testpath": "tests/data/test_heterogeneous_breadth_first_walker.py", "testname": "test_heterogeneous_breadth_first_walker.py", "classname": "TestSampledHeterogeneousBreadthFirstWalk", "funcname": "test_walk_generation_single_root_node_self_loner", "imports": ["import pandas as pd", "import numpy as np", "import pytest", "from stellargraph.data.explorer import SampledHeterogeneousBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph", "from ..test_utils.graphs import example_graph_random"], "code": "def test_walk_generation_single_root_node_self_loner(self):\n    g = create_test_graph(self_loop=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs([7])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 3)\n    assert (subgraphs[0][0][0] == nodes[0])\n    assert (len(subgraphs[0][1]) == 0)\n    assert (len(subgraphs[0][2]) == 0)\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 3)\n    assert (subgraphs[0][0][0] == nodes[0])\n    assert (subgraphs[0][1][0] == nodes[0])\n    assert (len(subgraphs[0][2]) == 1)\n    assert (subgraphs[0][2] == [(- 1)])\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 9)\n    for level in subgraphs[0]:\n        assert (type(level) == list)\n        if (len(level) > 0):\n            for value in level:\n                assert ((value == nodes[0]) or (value == (- 1)))\n    n_size = [2, 2, 3]\n    subgraphs2 = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs2) == 1)\n    assert (len(subgraphs2[0]) == 29)\n    assert all([(subgraphs[0][ii] == subgraphs2[0][ii]) for ii in range(len(subgraphs))])\n    for level in subgraphs2[0]:\n        assert (type(level) == list)\n        if (len(level) > 0):\n            for value in level:\n                assert ((value == nodes[0]) or (value == (- 1)))", "masked_code": "def test_walk_generation_single_root_node_self_loner(self):\n    g = create_test_graph(self_loop=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs([7])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 3)\n    assert (subgraphs[0][0][0] == nodes[0])\n    assert (len(subgraphs[0][1]) == 0)\n    assert (len(subgraphs[0][2]) == 0)\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 3)\n    assert (subgraphs[0][0][0] == nodes[0])\n    assert (subgraphs[0][1][0] == nodes[0])\n    assert (len(subgraphs[0][2]) == 1)\n    assert (subgraphs[0][2] == '???')\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 9)\n    for level in subgraphs[0]:\n        assert (type(level) == list)\n        if (len(level) > 0):\n            for value in level:\n                assert ((value == nodes[0]) or (value == (- 1)))\n    n_size = [2, 2, 3]\n    subgraphs2 = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs2) == 1)\n    assert (len(subgraphs2[0]) == 29)\n    assert all([(subgraphs[0][ii] == subgraphs2[0][ii]) for ii in range(len(subgraphs))])\n    for level in subgraphs2[0]:\n        assert (type(level) == list)\n        if (len(level) > 0):\n            for value in level:\n                assert ((value == nodes[0]) or (value == (- 1)))", "ground_truth": "[(- 1)]", "quality_analysis": {"complexity_score": 14, "left_complexity": 9, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_382", "reponame": "stellargraph", "testpath": "tests/data/test_heterogeneous_breadth_first_walker.py", "testname": "test_heterogeneous_breadth_first_walker.py", "classname": "TestSampledHeterogeneousBreadthFirstWalk", "funcname": "test_walk_generation_single_root_node_self_loner", "imports": ["import pandas as pd", "import numpy as np", "import pytest", "from stellargraph.data.explorer import SampledHeterogeneousBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph", "from ..test_utils.graphs import example_graph_random"], "code": "def test_walk_generation_single_root_node_self_loner(self):\n    g = create_test_graph(self_loop=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs([7])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 3)\n    assert (subgraphs[0][0][0] == nodes[0])\n    assert (len(subgraphs[0][1]) == 0)\n    assert (len(subgraphs[0][2]) == 0)\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 3)\n    assert (subgraphs[0][0][0] == nodes[0])\n    assert (subgraphs[0][1][0] == nodes[0])\n    assert (len(subgraphs[0][2]) == 1)\n    assert (subgraphs[0][2] == [(- 1)])\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 9)\n    for level in subgraphs[0]:\n        assert (type(level) == list)\n        if (len(level) > 0):\n            for value in level:\n                assert ((value == nodes[0]) or (value == (- 1)))\n    n_size = [2, 2, 3]\n    subgraphs2 = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs2) == 1)\n    assert (len(subgraphs2[0]) == 29)\n    assert all([(subgraphs[0][ii] == subgraphs2[0][ii]) for ii in range(len(subgraphs))])\n    for level in subgraphs2[0]:\n        assert (type(level) == list)\n        if (len(level) > 0):\n            for value in level:\n                assert ((value == nodes[0]) or (value == (- 1)))", "masked_code": "def test_walk_generation_single_root_node_self_loner(self):\n    g = create_test_graph(self_loop=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs([7])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 3)\n    assert (subgraphs[0][0][0] == nodes[0])\n    assert (len(subgraphs[0][1]) == 0)\n    assert (len(subgraphs[0][2]) == 0)\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 3)\n    assert (subgraphs[0][0][0] == nodes[0])\n    assert (subgraphs[0][1][0] == nodes[0])\n    assert (len(subgraphs[0][2]) == 1)\n    assert (subgraphs[0][2] == [(- 1)])\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == '???')\n    for level in subgraphs[0]:\n        assert (type(level) == list)\n        if (len(level) > 0):\n            for value in level:\n                assert ((value == nodes[0]) or (value == (- 1)))\n    n_size = [2, 2, 3]\n    subgraphs2 = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs2) == 1)\n    assert (len(subgraphs2[0]) == 29)\n    assert all([(subgraphs[0][ii] == subgraphs2[0][ii]) for ii in range(len(subgraphs))])\n    for level in subgraphs2[0]:\n        assert (type(level) == list)\n        if (len(level) > 0):\n            for value in level:\n                assert ((value == nodes[0]) or (value == (- 1)))", "ground_truth": "9", "quality_analysis": {"complexity_score": 9, "left_complexity": 8, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_383", "reponame": "stellargraph", "testpath": "tests/data/test_heterogeneous_breadth_first_walker.py", "testname": "test_heterogeneous_breadth_first_walker.py", "classname": "TestSampledHeterogeneousBreadthFirstWalk", "funcname": "test_walk_generation_single_root_node_self_loner", "imports": ["import pandas as pd", "import numpy as np", "import pytest", "from stellargraph.data.explorer import SampledHeterogeneousBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph", "from ..test_utils.graphs import example_graph_random"], "code": "def test_walk_generation_single_root_node_self_loner(self):\n    g = create_test_graph(self_loop=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs([7])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 3)\n    assert (subgraphs[0][0][0] == nodes[0])\n    assert (len(subgraphs[0][1]) == 0)\n    assert (len(subgraphs[0][2]) == 0)\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 3)\n    assert (subgraphs[0][0][0] == nodes[0])\n    assert (subgraphs[0][1][0] == nodes[0])\n    assert (len(subgraphs[0][2]) == 1)\n    assert (subgraphs[0][2] == [(- 1)])\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 9)\n    for level in subgraphs[0]:\n        assert (type(level) == list)\n        if (len(level) > 0):\n            for value in level:\n                assert ((value == nodes[0]) or (value == (- 1)))\n    n_size = [2, 2, 3]\n    subgraphs2 = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs2) == 1)\n    assert (len(subgraphs2[0]) == 29)\n    assert all([(subgraphs[0][ii] == subgraphs2[0][ii]) for ii in range(len(subgraphs))])\n    for level in subgraphs2[0]:\n        assert (type(level) == list)\n        if (len(level) > 0):\n            for value in level:\n                assert ((value == nodes[0]) or (value == (- 1)))", "masked_code": "def test_walk_generation_single_root_node_self_loner(self):\n    g = create_test_graph(self_loop=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs([7])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 3)\n    assert (subgraphs[0][0][0] == nodes[0])\n    assert (len(subgraphs[0][1]) == 0)\n    assert (len(subgraphs[0][2]) == 0)\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 3)\n    assert (subgraphs[0][0][0] == nodes[0])\n    assert (subgraphs[0][1][0] == nodes[0])\n    assert (len(subgraphs[0][2]) == 1)\n    assert (subgraphs[0][2] == [(- 1)])\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 9)\n    for level in subgraphs[0]:\n        assert (type(level) == list)\n        if (len(level) > 0):\n            for value in level:\n                assert ((value == nodes[0]) or (value == (- 1)))\n    n_size = [2, 2, 3]\n    subgraphs2 = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs2) == 1)\n    assert (len(subgraphs2[0]) == '???')\n    assert all([(subgraphs[0][ii] == subgraphs2[0][ii]) for ii in range(len(subgraphs))])\n    for level in subgraphs2[0]:\n        assert (type(level) == list)\n        if (len(level) > 0):\n            for value in level:\n                assert ((value == nodes[0]) or (value == (- 1)))", "ground_truth": "29", "quality_analysis": {"complexity_score": 9, "left_complexity": 8, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_384", "reponame": "stellargraph", "testpath": "tests/data/test_heterogeneous_breadth_first_walker.py", "testname": "test_heterogeneous_breadth_first_walker.py", "classname": "TestSampledHeterogeneousBreadthFirstWalk", "funcname": "test_walk_generation_single_root_node_self_loner", "imports": ["import pandas as pd", "import numpy as np", "import pytest", "from stellargraph.data.explorer import SampledHeterogeneousBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph", "from ..test_utils.graphs import example_graph_random"], "code": "def test_walk_generation_single_root_node_self_loner(self):\n    g = create_test_graph(self_loop=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs([7])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 3)\n    assert (subgraphs[0][0][0] == nodes[0])\n    assert (len(subgraphs[0][1]) == 0)\n    assert (len(subgraphs[0][2]) == 0)\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 3)\n    assert (subgraphs[0][0][0] == nodes[0])\n    assert (subgraphs[0][1][0] == nodes[0])\n    assert (len(subgraphs[0][2]) == 1)\n    assert (subgraphs[0][2] == [(- 1)])\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 9)\n    for level in subgraphs[0]:\n        assert (type(level) == list)\n        if (len(level) > 0):\n            for value in level:\n                assert ((value == nodes[0]) or (value == (- 1)))\n    n_size = [2, 2, 3]\n    subgraphs2 = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs2) == 1)\n    assert (len(subgraphs2[0]) == 29)\n    assert all([(subgraphs[0][ii] == subgraphs2[0][ii]) for ii in range(len(subgraphs))])\n    for level in subgraphs2[0]:\n        assert (type(level) == list)\n        if (len(level) > 0):\n            for value in level:\n                assert ((value == nodes[0]) or (value == (- 1)))", "masked_code": "def test_walk_generation_single_root_node_self_loner(self):\n    g = create_test_graph(self_loop=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs([7])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 3)\n    assert (subgraphs[0][0][0] == nodes[0])\n    assert (len(subgraphs[0][1]) == 0)\n    assert (len(subgraphs[0][2]) == 0)\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 3)\n    assert (subgraphs[0][0][0] == nodes[0])\n    assert (subgraphs[0][1][0] == nodes[0])\n    assert (len(subgraphs[0][2]) == 1)\n    assert (subgraphs[0][2] == [(- 1)])\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 9)\n    for level in subgraphs[0]:\n        assert (type(level) == '???')\n        if (len(level) > 0):\n            for value in level:\n                assert ((value == nodes[0]) or (value == (- 1)))\n    n_size = [2, 2, 3]\n    subgraphs2 = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs2) == 1)\n    assert (len(subgraphs2[0]) == 29)\n    assert all([(subgraphs[0][ii] == subgraphs2[0][ii]) for ii in range(len(subgraphs))])\n    for level in subgraphs2[0]:\n        assert (type(level) == list)\n        if (len(level) > 0):\n            for value in level:\n                assert ((value == nodes[0]) or (value == (- 1)))", "ground_truth": "list", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_385", "reponame": "stellargraph", "testpath": "tests/data/test_heterogeneous_breadth_first_walker.py", "testname": "test_heterogeneous_breadth_first_walker.py", "classname": "TestSampledHeterogeneousBreadthFirstWalk", "funcname": "test_walk_generation_single_root_node_self_loner", "imports": ["import pandas as pd", "import numpy as np", "import pytest", "from stellargraph.data.explorer import SampledHeterogeneousBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph", "from ..test_utils.graphs import example_graph_random"], "code": "def test_walk_generation_single_root_node_self_loner(self):\n    g = create_test_graph(self_loop=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs([7])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 3)\n    assert (subgraphs[0][0][0] == nodes[0])\n    assert (len(subgraphs[0][1]) == 0)\n    assert (len(subgraphs[0][2]) == 0)\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 3)\n    assert (subgraphs[0][0][0] == nodes[0])\n    assert (subgraphs[0][1][0] == nodes[0])\n    assert (len(subgraphs[0][2]) == 1)\n    assert (subgraphs[0][2] == [(- 1)])\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 9)\n    for level in subgraphs[0]:\n        assert (type(level) == list)\n        if (len(level) > 0):\n            for value in level:\n                assert ((value == nodes[0]) or (value == (- 1)))\n    n_size = [2, 2, 3]\n    subgraphs2 = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs2) == 1)\n    assert (len(subgraphs2[0]) == 29)\n    assert all([(subgraphs[0][ii] == subgraphs2[0][ii]) for ii in range(len(subgraphs))])\n    for level in subgraphs2[0]:\n        assert (type(level) == list)\n        if (len(level) > 0):\n            for value in level:\n                assert ((value == nodes[0]) or (value == (- 1)))", "masked_code": "def test_walk_generation_single_root_node_self_loner(self):\n    g = create_test_graph(self_loop=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n    nodes = g.node_ids_to_ilocs([7])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 3)\n    assert (subgraphs[0][0][0] == nodes[0])\n    assert (len(subgraphs[0][1]) == 0)\n    assert (len(subgraphs[0][2]) == 0)\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 3)\n    assert (subgraphs[0][0][0] == nodes[0])\n    assert (subgraphs[0][1][0] == nodes[0])\n    assert (len(subgraphs[0][2]) == 1)\n    assert (subgraphs[0][2] == [(- 1)])\n    n_size = [2, 2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 9)\n    for level in subgraphs[0]:\n        assert (type(level) == list)\n        if (len(level) > 0):\n            for value in level:\n                assert ((value == nodes[0]) or (value == (- 1)))\n    n_size = [2, 2, 3]\n    subgraphs2 = bfw.run(nodes=nodes, n=n, n_size=n_size)\n    assert (len(subgraphs2) == 1)\n    assert (len(subgraphs2[0]) == 29)\n    assert all([(subgraphs[0][ii] == subgraphs2[0][ii]) for ii in range(len(subgraphs))])\n    for level in subgraphs2[0]:\n        assert (type(level) == '???')\n        if (len(level) > 0):\n            for value in level:\n                assert ((value == nodes[0]) or (value == (- 1)))", "ground_truth": "list", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_386", "reponame": "stellargraph", "testpath": "tests/data/test_heterogeneous_breadth_first_walker.py", "testname": "test_heterogeneous_breadth_first_walker.py", "classname": "TestSampledHeterogeneousBreadthFirstWalk", "funcname": "test_walk_generation_single_root_node", "imports": ["import pandas as pd", "import numpy as np", "import pytest", "from stellargraph.data.explorer import SampledHeterogeneousBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph", "from ..test_utils.graphs import example_graph_random"], "code": "def test_walk_generation_single_root_node(self):\n    g = create_test_graph(self_loop=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n\n    def _conv(ns):\n        return [((- 1) if (n is None) else g.node_ids_to_ilocs([n])[0]) for n in ns]\n    nodes = _conv([3])\n    n = 1\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=42)\n    assert (len(subgraphs) == n)\n    valid_result = [[_conv([3]), _conv(['5', 1])]]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=42)\n    assert (len(subgraphs) == n)\n    valid_result = [[_conv([3]), _conv(['5', 1, 1])]]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n_size = [1, 1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=42)\n    assert (len(subgraphs) == n)\n    valid_result = [[_conv([3]), _conv(['5']), _conv([1]), _conv([3])]]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    nodes = _conv(['5'])\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=42)\n    assert (len(subgraphs) == n)\n    valid_result = [[['5'], [4, 1], [3, 3], ['5', '5', '5'], [2, 2, 2], [4, '5', 4], [2, 3, 3], [1, '5', '5'], [1, '5', '5']]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    nodes = _conv(['5'])\n    n_size = [2, 3]\n    n = 3\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=42)\n    assert (len(subgraphs) == n)\n    valid_result = [[['5'], [4, 1], [3, 3], ['5', '5', '5'], [2, 2, 2], [4, '5', 4], [2, 3, 3], [1, '5', '5'], [1, '5', '5']], [['5'], [1, 1], [6, 3], [4, 4, '5'], [3, 3, 3], ['5', '5', 4], [3, 3, 3], ['5', '5', '5'], [1, 1, 1]], [['5'], [1, 1], [3, 3], ['5', 4, 4], [2, 2, 3], ['5', '5', 4], [3, 2, 2], ['5', '5', '5'], ['5', '5', '5']]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    g = create_test_graph(multi=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n    nodes = _conv([1])\n    n = 1\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=19893839)\n    assert (len(subgraphs) == n)\n    valid_result = [[[1], [4, 4], [4, 4], [2, 2]]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    _recursive_items_equal(subgraphs, valid_result)\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=19893839)\n    assert (len(subgraphs) == n)\n    valid_result = [[[1], [4, 4], ['5', '5'], [2, 2], [1, 1, 1], ['5', 1, 1], [2, 2, 2], [1, 1, 1], [1, '5', 1], [2, 2, 2], [7, 7, 7], [4, 1, 1], [6, 3, 6], [7, 7, 7], [1, 4, 1], [6, 6, 6], [4, 1, 1], [1, 1, 1]]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    nodes = _conv([1])\n    n_size = [2, 0]\n    n = 2\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=19893839)\n    assert (len(subgraphs) == n)\n    valid_result = [[[1], [4, 4], ['5', '5'], [2, 2], [], [], [], [], [], [], [], [], [], [], [], [], [], []], [[1], [4, 4], [4, 4], [2, 2], [], [], [], [], [], [], [], [], [], [], [], [], [], []]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)", "masked_code": "def test_walk_generation_single_root_node(self):\n    g = create_test_graph(self_loop=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n\n    def _conv(ns):\n        return [((- 1) if (n is None) else g.node_ids_to_ilocs([n])[0]) for n in ns]\n    nodes = _conv([3])\n    n = 1\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=42)\n    assert (len(subgraphs) == '???')\n    valid_result = [[_conv([3]), _conv(['5', 1])]]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=42)\n    assert (len(subgraphs) == n)\n    valid_result = [[_conv([3]), _conv(['5', 1, 1])]]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n_size = [1, 1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=42)\n    assert (len(subgraphs) == n)\n    valid_result = [[_conv([3]), _conv(['5']), _conv([1]), _conv([3])]]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    nodes = _conv(['5'])\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=42)\n    assert (len(subgraphs) == n)\n    valid_result = [[['5'], [4, 1], [3, 3], ['5', '5', '5'], [2, 2, 2], [4, '5', 4], [2, 3, 3], [1, '5', '5'], [1, '5', '5']]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    nodes = _conv(['5'])\n    n_size = [2, 3]\n    n = 3\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=42)\n    assert (len(subgraphs) == n)\n    valid_result = [[['5'], [4, 1], [3, 3], ['5', '5', '5'], [2, 2, 2], [4, '5', 4], [2, 3, 3], [1, '5', '5'], [1, '5', '5']], [['5'], [1, 1], [6, 3], [4, 4, '5'], [3, 3, 3], ['5', '5', 4], [3, 3, 3], ['5', '5', '5'], [1, 1, 1]], [['5'], [1, 1], [3, 3], ['5', 4, 4], [2, 2, 3], ['5', '5', 4], [3, 2, 2], ['5', '5', '5'], ['5', '5', '5']]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    g = create_test_graph(multi=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n    nodes = _conv([1])\n    n = 1\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=19893839)\n    assert (len(subgraphs) == n)\n    valid_result = [[[1], [4, 4], [4, 4], [2, 2]]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    _recursive_items_equal(subgraphs, valid_result)\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=19893839)\n    assert (len(subgraphs) == n)\n    valid_result = [[[1], [4, 4], ['5', '5'], [2, 2], [1, 1, 1], ['5', 1, 1], [2, 2, 2], [1, 1, 1], [1, '5', 1], [2, 2, 2], [7, 7, 7], [4, 1, 1], [6, 3, 6], [7, 7, 7], [1, 4, 1], [6, 6, 6], [4, 1, 1], [1, 1, 1]]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    nodes = _conv([1])\n    n_size = [2, 0]\n    n = 2\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=19893839)\n    assert (len(subgraphs) == n)\n    valid_result = [[[1], [4, 4], ['5', '5'], [2, 2], [], [], [], [], [], [], [], [], [], [], [], [], [], []], [[1], [4, 4], [4, 4], [2, 2], [], [], [], [], [], [], [], [], [], [], [], [], [], []]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)", "ground_truth": "n", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_387", "reponame": "stellargraph", "testpath": "tests/data/test_heterogeneous_breadth_first_walker.py", "testname": "test_heterogeneous_breadth_first_walker.py", "classname": "TestSampledHeterogeneousBreadthFirstWalk", "funcname": "test_walk_generation_single_root_node", "imports": ["import pandas as pd", "import numpy as np", "import pytest", "from stellargraph.data.explorer import SampledHeterogeneousBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph", "from ..test_utils.graphs import example_graph_random"], "code": "def test_walk_generation_single_root_node(self):\n    g = create_test_graph(self_loop=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n\n    def _conv(ns):\n        return [((- 1) if (n is None) else g.node_ids_to_ilocs([n])[0]) for n in ns]\n    nodes = _conv([3])\n    n = 1\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=42)\n    assert (len(subgraphs) == n)\n    valid_result = [[_conv([3]), _conv(['5', 1])]]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=42)\n    assert (len(subgraphs) == n)\n    valid_result = [[_conv([3]), _conv(['5', 1, 1])]]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n_size = [1, 1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=42)\n    assert (len(subgraphs) == n)\n    valid_result = [[_conv([3]), _conv(['5']), _conv([1]), _conv([3])]]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    nodes = _conv(['5'])\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=42)\n    assert (len(subgraphs) == n)\n    valid_result = [[['5'], [4, 1], [3, 3], ['5', '5', '5'], [2, 2, 2], [4, '5', 4], [2, 3, 3], [1, '5', '5'], [1, '5', '5']]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    nodes = _conv(['5'])\n    n_size = [2, 3]\n    n = 3\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=42)\n    assert (len(subgraphs) == n)\n    valid_result = [[['5'], [4, 1], [3, 3], ['5', '5', '5'], [2, 2, 2], [4, '5', 4], [2, 3, 3], [1, '5', '5'], [1, '5', '5']], [['5'], [1, 1], [6, 3], [4, 4, '5'], [3, 3, 3], ['5', '5', 4], [3, 3, 3], ['5', '5', '5'], [1, 1, 1]], [['5'], [1, 1], [3, 3], ['5', 4, 4], [2, 2, 3], ['5', '5', 4], [3, 2, 2], ['5', '5', '5'], ['5', '5', '5']]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    g = create_test_graph(multi=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n    nodes = _conv([1])\n    n = 1\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=19893839)\n    assert (len(subgraphs) == n)\n    valid_result = [[[1], [4, 4], [4, 4], [2, 2]]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    _recursive_items_equal(subgraphs, valid_result)\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=19893839)\n    assert (len(subgraphs) == n)\n    valid_result = [[[1], [4, 4], ['5', '5'], [2, 2], [1, 1, 1], ['5', 1, 1], [2, 2, 2], [1, 1, 1], [1, '5', 1], [2, 2, 2], [7, 7, 7], [4, 1, 1], [6, 3, 6], [7, 7, 7], [1, 4, 1], [6, 6, 6], [4, 1, 1], [1, 1, 1]]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    nodes = _conv([1])\n    n_size = [2, 0]\n    n = 2\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=19893839)\n    assert (len(subgraphs) == n)\n    valid_result = [[[1], [4, 4], ['5', '5'], [2, 2], [], [], [], [], [], [], [], [], [], [], [], [], [], []], [[1], [4, 4], [4, 4], [2, 2], [], [], [], [], [], [], [], [], [], [], [], [], [], []]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)", "masked_code": "def test_walk_generation_single_root_node(self):\n    g = create_test_graph(self_loop=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n\n    def _conv(ns):\n        return [((- 1) if (n is None) else g.node_ids_to_ilocs([n])[0]) for n in ns]\n    nodes = _conv([3])\n    n = 1\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=42)\n    assert (len(subgraphs) == n)\n    valid_result = [[_conv([3]), _conv(['5', 1])]]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=42)\n    assert (len(subgraphs) == '???')\n    valid_result = [[_conv([3]), _conv(['5', 1, 1])]]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n_size = [1, 1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=42)\n    assert (len(subgraphs) == n)\n    valid_result = [[_conv([3]), _conv(['5']), _conv([1]), _conv([3])]]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    nodes = _conv(['5'])\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=42)\n    assert (len(subgraphs) == n)\n    valid_result = [[['5'], [4, 1], [3, 3], ['5', '5', '5'], [2, 2, 2], [4, '5', 4], [2, 3, 3], [1, '5', '5'], [1, '5', '5']]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    nodes = _conv(['5'])\n    n_size = [2, 3]\n    n = 3\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=42)\n    assert (len(subgraphs) == n)\n    valid_result = [[['5'], [4, 1], [3, 3], ['5', '5', '5'], [2, 2, 2], [4, '5', 4], [2, 3, 3], [1, '5', '5'], [1, '5', '5']], [['5'], [1, 1], [6, 3], [4, 4, '5'], [3, 3, 3], ['5', '5', 4], [3, 3, 3], ['5', '5', '5'], [1, 1, 1]], [['5'], [1, 1], [3, 3], ['5', 4, 4], [2, 2, 3], ['5', '5', 4], [3, 2, 2], ['5', '5', '5'], ['5', '5', '5']]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    g = create_test_graph(multi=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n    nodes = _conv([1])\n    n = 1\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=19893839)\n    assert (len(subgraphs) == n)\n    valid_result = [[[1], [4, 4], [4, 4], [2, 2]]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    _recursive_items_equal(subgraphs, valid_result)\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=19893839)\n    assert (len(subgraphs) == n)\n    valid_result = [[[1], [4, 4], ['5', '5'], [2, 2], [1, 1, 1], ['5', 1, 1], [2, 2, 2], [1, 1, 1], [1, '5', 1], [2, 2, 2], [7, 7, 7], [4, 1, 1], [6, 3, 6], [7, 7, 7], [1, 4, 1], [6, 6, 6], [4, 1, 1], [1, 1, 1]]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    nodes = _conv([1])\n    n_size = [2, 0]\n    n = 2\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=19893839)\n    assert (len(subgraphs) == n)\n    valid_result = [[[1], [4, 4], ['5', '5'], [2, 2], [], [], [], [], [], [], [], [], [], [], [], [], [], []], [[1], [4, 4], [4, 4], [2, 2], [], [], [], [], [], [], [], [], [], [], [], [], [], []]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)", "ground_truth": "n", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_388", "reponame": "stellargraph", "testpath": "tests/data/test_heterogeneous_breadth_first_walker.py", "testname": "test_heterogeneous_breadth_first_walker.py", "classname": "TestSampledHeterogeneousBreadthFirstWalk", "funcname": "test_walk_generation_single_root_node", "imports": ["import pandas as pd", "import numpy as np", "import pytest", "from stellargraph.data.explorer import SampledHeterogeneousBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph", "from ..test_utils.graphs import example_graph_random"], "code": "def test_walk_generation_single_root_node(self):\n    g = create_test_graph(self_loop=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n\n    def _conv(ns):\n        return [((- 1) if (n is None) else g.node_ids_to_ilocs([n])[0]) for n in ns]\n    nodes = _conv([3])\n    n = 1\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=42)\n    assert (len(subgraphs) == n)\n    valid_result = [[_conv([3]), _conv(['5', 1])]]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=42)\n    assert (len(subgraphs) == n)\n    valid_result = [[_conv([3]), _conv(['5', 1, 1])]]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n_size = [1, 1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=42)\n    assert (len(subgraphs) == n)\n    valid_result = [[_conv([3]), _conv(['5']), _conv([1]), _conv([3])]]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    nodes = _conv(['5'])\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=42)\n    assert (len(subgraphs) == n)\n    valid_result = [[['5'], [4, 1], [3, 3], ['5', '5', '5'], [2, 2, 2], [4, '5', 4], [2, 3, 3], [1, '5', '5'], [1, '5', '5']]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    nodes = _conv(['5'])\n    n_size = [2, 3]\n    n = 3\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=42)\n    assert (len(subgraphs) == n)\n    valid_result = [[['5'], [4, 1], [3, 3], ['5', '5', '5'], [2, 2, 2], [4, '5', 4], [2, 3, 3], [1, '5', '5'], [1, '5', '5']], [['5'], [1, 1], [6, 3], [4, 4, '5'], [3, 3, 3], ['5', '5', 4], [3, 3, 3], ['5', '5', '5'], [1, 1, 1]], [['5'], [1, 1], [3, 3], ['5', 4, 4], [2, 2, 3], ['5', '5', 4], [3, 2, 2], ['5', '5', '5'], ['5', '5', '5']]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    g = create_test_graph(multi=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n    nodes = _conv([1])\n    n = 1\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=19893839)\n    assert (len(subgraphs) == n)\n    valid_result = [[[1], [4, 4], [4, 4], [2, 2]]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    _recursive_items_equal(subgraphs, valid_result)\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=19893839)\n    assert (len(subgraphs) == n)\n    valid_result = [[[1], [4, 4], ['5', '5'], [2, 2], [1, 1, 1], ['5', 1, 1], [2, 2, 2], [1, 1, 1], [1, '5', 1], [2, 2, 2], [7, 7, 7], [4, 1, 1], [6, 3, 6], [7, 7, 7], [1, 4, 1], [6, 6, 6], [4, 1, 1], [1, 1, 1]]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    nodes = _conv([1])\n    n_size = [2, 0]\n    n = 2\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=19893839)\n    assert (len(subgraphs) == n)\n    valid_result = [[[1], [4, 4], ['5', '5'], [2, 2], [], [], [], [], [], [], [], [], [], [], [], [], [], []], [[1], [4, 4], [4, 4], [2, 2], [], [], [], [], [], [], [], [], [], [], [], [], [], []]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)", "masked_code": "def test_walk_generation_single_root_node(self):\n    g = create_test_graph(self_loop=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n\n    def _conv(ns):\n        return [((- 1) if (n is None) else g.node_ids_to_ilocs([n])[0]) for n in ns]\n    nodes = _conv([3])\n    n = 1\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=42)\n    assert (len(subgraphs) == n)\n    valid_result = [[_conv([3]), _conv(['5', 1])]]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=42)\n    assert (len(subgraphs) == n)\n    valid_result = [[_conv([3]), _conv(['5', 1, 1])]]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n_size = [1, 1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=42)\n    assert (len(subgraphs) == '???')\n    valid_result = [[_conv([3]), _conv(['5']), _conv([1]), _conv([3])]]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    nodes = _conv(['5'])\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=42)\n    assert (len(subgraphs) == n)\n    valid_result = [[['5'], [4, 1], [3, 3], ['5', '5', '5'], [2, 2, 2], [4, '5', 4], [2, 3, 3], [1, '5', '5'], [1, '5', '5']]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    nodes = _conv(['5'])\n    n_size = [2, 3]\n    n = 3\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=42)\n    assert (len(subgraphs) == n)\n    valid_result = [[['5'], [4, 1], [3, 3], ['5', '5', '5'], [2, 2, 2], [4, '5', 4], [2, 3, 3], [1, '5', '5'], [1, '5', '5']], [['5'], [1, 1], [6, 3], [4, 4, '5'], [3, 3, 3], ['5', '5', 4], [3, 3, 3], ['5', '5', '5'], [1, 1, 1]], [['5'], [1, 1], [3, 3], ['5', 4, 4], [2, 2, 3], ['5', '5', 4], [3, 2, 2], ['5', '5', '5'], ['5', '5', '5']]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    g = create_test_graph(multi=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n    nodes = _conv([1])\n    n = 1\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=19893839)\n    assert (len(subgraphs) == n)\n    valid_result = [[[1], [4, 4], [4, 4], [2, 2]]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    _recursive_items_equal(subgraphs, valid_result)\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=19893839)\n    assert (len(subgraphs) == n)\n    valid_result = [[[1], [4, 4], ['5', '5'], [2, 2], [1, 1, 1], ['5', 1, 1], [2, 2, 2], [1, 1, 1], [1, '5', 1], [2, 2, 2], [7, 7, 7], [4, 1, 1], [6, 3, 6], [7, 7, 7], [1, 4, 1], [6, 6, 6], [4, 1, 1], [1, 1, 1]]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    nodes = _conv([1])\n    n_size = [2, 0]\n    n = 2\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=19893839)\n    assert (len(subgraphs) == n)\n    valid_result = [[[1], [4, 4], ['5', '5'], [2, 2], [], [], [], [], [], [], [], [], [], [], [], [], [], []], [[1], [4, 4], [4, 4], [2, 2], [], [], [], [], [], [], [], [], [], [], [], [], [], []]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)", "ground_truth": "n", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_389", "reponame": "stellargraph", "testpath": "tests/data/test_heterogeneous_breadth_first_walker.py", "testname": "test_heterogeneous_breadth_first_walker.py", "classname": "TestSampledHeterogeneousBreadthFirstWalk", "funcname": "test_walk_generation_single_root_node", "imports": ["import pandas as pd", "import numpy as np", "import pytest", "from stellargraph.data.explorer import SampledHeterogeneousBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph", "from ..test_utils.graphs import example_graph_random"], "code": "def test_walk_generation_single_root_node(self):\n    g = create_test_graph(self_loop=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n\n    def _conv(ns):\n        return [((- 1) if (n is None) else g.node_ids_to_ilocs([n])[0]) for n in ns]\n    nodes = _conv([3])\n    n = 1\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=42)\n    assert (len(subgraphs) == n)\n    valid_result = [[_conv([3]), _conv(['5', 1])]]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=42)\n    assert (len(subgraphs) == n)\n    valid_result = [[_conv([3]), _conv(['5', 1, 1])]]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n_size = [1, 1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=42)\n    assert (len(subgraphs) == n)\n    valid_result = [[_conv([3]), _conv(['5']), _conv([1]), _conv([3])]]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    nodes = _conv(['5'])\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=42)\n    assert (len(subgraphs) == n)\n    valid_result = [[['5'], [4, 1], [3, 3], ['5', '5', '5'], [2, 2, 2], [4, '5', 4], [2, 3, 3], [1, '5', '5'], [1, '5', '5']]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    nodes = _conv(['5'])\n    n_size = [2, 3]\n    n = 3\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=42)\n    assert (len(subgraphs) == n)\n    valid_result = [[['5'], [4, 1], [3, 3], ['5', '5', '5'], [2, 2, 2], [4, '5', 4], [2, 3, 3], [1, '5', '5'], [1, '5', '5']], [['5'], [1, 1], [6, 3], [4, 4, '5'], [3, 3, 3], ['5', '5', 4], [3, 3, 3], ['5', '5', '5'], [1, 1, 1]], [['5'], [1, 1], [3, 3], ['5', 4, 4], [2, 2, 3], ['5', '5', 4], [3, 2, 2], ['5', '5', '5'], ['5', '5', '5']]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    g = create_test_graph(multi=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n    nodes = _conv([1])\n    n = 1\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=19893839)\n    assert (len(subgraphs) == n)\n    valid_result = [[[1], [4, 4], [4, 4], [2, 2]]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    _recursive_items_equal(subgraphs, valid_result)\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=19893839)\n    assert (len(subgraphs) == n)\n    valid_result = [[[1], [4, 4], ['5', '5'], [2, 2], [1, 1, 1], ['5', 1, 1], [2, 2, 2], [1, 1, 1], [1, '5', 1], [2, 2, 2], [7, 7, 7], [4, 1, 1], [6, 3, 6], [7, 7, 7], [1, 4, 1], [6, 6, 6], [4, 1, 1], [1, 1, 1]]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    nodes = _conv([1])\n    n_size = [2, 0]\n    n = 2\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=19893839)\n    assert (len(subgraphs) == n)\n    valid_result = [[[1], [4, 4], ['5', '5'], [2, 2], [], [], [], [], [], [], [], [], [], [], [], [], [], []], [[1], [4, 4], [4, 4], [2, 2], [], [], [], [], [], [], [], [], [], [], [], [], [], []]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)", "masked_code": "def test_walk_generation_single_root_node(self):\n    g = create_test_graph(self_loop=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n\n    def _conv(ns):\n        return [((- 1) if (n is None) else g.node_ids_to_ilocs([n])[0]) for n in ns]\n    nodes = _conv([3])\n    n = 1\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=42)\n    assert (len(subgraphs) == n)\n    valid_result = [[_conv([3]), _conv(['5', 1])]]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=42)\n    assert (len(subgraphs) == n)\n    valid_result = [[_conv([3]), _conv(['5', 1, 1])]]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n_size = [1, 1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=42)\n    assert (len(subgraphs) == n)\n    valid_result = [[_conv([3]), _conv(['5']), _conv([1]), _conv([3])]]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    nodes = _conv(['5'])\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=42)\n    assert (len(subgraphs) == '???')\n    valid_result = [[['5'], [4, 1], [3, 3], ['5', '5', '5'], [2, 2, 2], [4, '5', 4], [2, 3, 3], [1, '5', '5'], [1, '5', '5']]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    nodes = _conv(['5'])\n    n_size = [2, 3]\n    n = 3\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=42)\n    assert (len(subgraphs) == n)\n    valid_result = [[['5'], [4, 1], [3, 3], ['5', '5', '5'], [2, 2, 2], [4, '5', 4], [2, 3, 3], [1, '5', '5'], [1, '5', '5']], [['5'], [1, 1], [6, 3], [4, 4, '5'], [3, 3, 3], ['5', '5', 4], [3, 3, 3], ['5', '5', '5'], [1, 1, 1]], [['5'], [1, 1], [3, 3], ['5', 4, 4], [2, 2, 3], ['5', '5', 4], [3, 2, 2], ['5', '5', '5'], ['5', '5', '5']]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    g = create_test_graph(multi=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n    nodes = _conv([1])\n    n = 1\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=19893839)\n    assert (len(subgraphs) == n)\n    valid_result = [[[1], [4, 4], [4, 4], [2, 2]]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    _recursive_items_equal(subgraphs, valid_result)\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=19893839)\n    assert (len(subgraphs) == n)\n    valid_result = [[[1], [4, 4], ['5', '5'], [2, 2], [1, 1, 1], ['5', 1, 1], [2, 2, 2], [1, 1, 1], [1, '5', 1], [2, 2, 2], [7, 7, 7], [4, 1, 1], [6, 3, 6], [7, 7, 7], [1, 4, 1], [6, 6, 6], [4, 1, 1], [1, 1, 1]]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    nodes = _conv([1])\n    n_size = [2, 0]\n    n = 2\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=19893839)\n    assert (len(subgraphs) == n)\n    valid_result = [[[1], [4, 4], ['5', '5'], [2, 2], [], [], [], [], [], [], [], [], [], [], [], [], [], []], [[1], [4, 4], [4, 4], [2, 2], [], [], [], [], [], [], [], [], [], [], [], [], [], []]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)", "ground_truth": "n", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_390", "reponame": "stellargraph", "testpath": "tests/data/test_heterogeneous_breadth_first_walker.py", "testname": "test_heterogeneous_breadth_first_walker.py", "classname": "TestSampledHeterogeneousBreadthFirstWalk", "funcname": "test_walk_generation_single_root_node", "imports": ["import pandas as pd", "import numpy as np", "import pytest", "from stellargraph.data.explorer import SampledHeterogeneousBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph", "from ..test_utils.graphs import example_graph_random"], "code": "def test_walk_generation_single_root_node(self):\n    g = create_test_graph(self_loop=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n\n    def _conv(ns):\n        return [((- 1) if (n is None) else g.node_ids_to_ilocs([n])[0]) for n in ns]\n    nodes = _conv([3])\n    n = 1\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=42)\n    assert (len(subgraphs) == n)\n    valid_result = [[_conv([3]), _conv(['5', 1])]]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=42)\n    assert (len(subgraphs) == n)\n    valid_result = [[_conv([3]), _conv(['5', 1, 1])]]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n_size = [1, 1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=42)\n    assert (len(subgraphs) == n)\n    valid_result = [[_conv([3]), _conv(['5']), _conv([1]), _conv([3])]]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    nodes = _conv(['5'])\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=42)\n    assert (len(subgraphs) == n)\n    valid_result = [[['5'], [4, 1], [3, 3], ['5', '5', '5'], [2, 2, 2], [4, '5', 4], [2, 3, 3], [1, '5', '5'], [1, '5', '5']]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    nodes = _conv(['5'])\n    n_size = [2, 3]\n    n = 3\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=42)\n    assert (len(subgraphs) == n)\n    valid_result = [[['5'], [4, 1], [3, 3], ['5', '5', '5'], [2, 2, 2], [4, '5', 4], [2, 3, 3], [1, '5', '5'], [1, '5', '5']], [['5'], [1, 1], [6, 3], [4, 4, '5'], [3, 3, 3], ['5', '5', 4], [3, 3, 3], ['5', '5', '5'], [1, 1, 1]], [['5'], [1, 1], [3, 3], ['5', 4, 4], [2, 2, 3], ['5', '5', 4], [3, 2, 2], ['5', '5', '5'], ['5', '5', '5']]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    g = create_test_graph(multi=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n    nodes = _conv([1])\n    n = 1\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=19893839)\n    assert (len(subgraphs) == n)\n    valid_result = [[[1], [4, 4], [4, 4], [2, 2]]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    _recursive_items_equal(subgraphs, valid_result)\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=19893839)\n    assert (len(subgraphs) == n)\n    valid_result = [[[1], [4, 4], ['5', '5'], [2, 2], [1, 1, 1], ['5', 1, 1], [2, 2, 2], [1, 1, 1], [1, '5', 1], [2, 2, 2], [7, 7, 7], [4, 1, 1], [6, 3, 6], [7, 7, 7], [1, 4, 1], [6, 6, 6], [4, 1, 1], [1, 1, 1]]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    nodes = _conv([1])\n    n_size = [2, 0]\n    n = 2\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=19893839)\n    assert (len(subgraphs) == n)\n    valid_result = [[[1], [4, 4], ['5', '5'], [2, 2], [], [], [], [], [], [], [], [], [], [], [], [], [], []], [[1], [4, 4], [4, 4], [2, 2], [], [], [], [], [], [], [], [], [], [], [], [], [], []]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)", "masked_code": "def test_walk_generation_single_root_node(self):\n    g = create_test_graph(self_loop=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n\n    def _conv(ns):\n        return [((- 1) if (n is None) else g.node_ids_to_ilocs([n])[0]) for n in ns]\n    nodes = _conv([3])\n    n = 1\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=42)\n    assert (len(subgraphs) == n)\n    valid_result = [[_conv([3]), _conv(['5', 1])]]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=42)\n    assert (len(subgraphs) == n)\n    valid_result = [[_conv([3]), _conv(['5', 1, 1])]]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n_size = [1, 1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=42)\n    assert (len(subgraphs) == n)\n    valid_result = [[_conv([3]), _conv(['5']), _conv([1]), _conv([3])]]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    nodes = _conv(['5'])\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=42)\n    assert (len(subgraphs) == n)\n    valid_result = [[['5'], [4, 1], [3, 3], ['5', '5', '5'], [2, 2, 2], [4, '5', 4], [2, 3, 3], [1, '5', '5'], [1, '5', '5']]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    nodes = _conv(['5'])\n    n_size = [2, 3]\n    n = 3\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=42)\n    assert (len(subgraphs) == '???')\n    valid_result = [[['5'], [4, 1], [3, 3], ['5', '5', '5'], [2, 2, 2], [4, '5', 4], [2, 3, 3], [1, '5', '5'], [1, '5', '5']], [['5'], [1, 1], [6, 3], [4, 4, '5'], [3, 3, 3], ['5', '5', 4], [3, 3, 3], ['5', '5', '5'], [1, 1, 1]], [['5'], [1, 1], [3, 3], ['5', 4, 4], [2, 2, 3], ['5', '5', 4], [3, 2, 2], ['5', '5', '5'], ['5', '5', '5']]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    g = create_test_graph(multi=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n    nodes = _conv([1])\n    n = 1\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=19893839)\n    assert (len(subgraphs) == n)\n    valid_result = [[[1], [4, 4], [4, 4], [2, 2]]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    _recursive_items_equal(subgraphs, valid_result)\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=19893839)\n    assert (len(subgraphs) == n)\n    valid_result = [[[1], [4, 4], ['5', '5'], [2, 2], [1, 1, 1], ['5', 1, 1], [2, 2, 2], [1, 1, 1], [1, '5', 1], [2, 2, 2], [7, 7, 7], [4, 1, 1], [6, 3, 6], [7, 7, 7], [1, 4, 1], [6, 6, 6], [4, 1, 1], [1, 1, 1]]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    nodes = _conv([1])\n    n_size = [2, 0]\n    n = 2\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=19893839)\n    assert (len(subgraphs) == n)\n    valid_result = [[[1], [4, 4], ['5', '5'], [2, 2], [], [], [], [], [], [], [], [], [], [], [], [], [], []], [[1], [4, 4], [4, 4], [2, 2], [], [], [], [], [], [], [], [], [], [], [], [], [], []]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)", "ground_truth": "n", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_391", "reponame": "stellargraph", "testpath": "tests/data/test_heterogeneous_breadth_first_walker.py", "testname": "test_heterogeneous_breadth_first_walker.py", "classname": "TestSampledHeterogeneousBreadthFirstWalk", "funcname": "test_walk_generation_single_root_node", "imports": ["import pandas as pd", "import numpy as np", "import pytest", "from stellargraph.data.explorer import SampledHeterogeneousBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph", "from ..test_utils.graphs import example_graph_random"], "code": "def test_walk_generation_single_root_node(self):\n    g = create_test_graph(self_loop=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n\n    def _conv(ns):\n        return [((- 1) if (n is None) else g.node_ids_to_ilocs([n])[0]) for n in ns]\n    nodes = _conv([3])\n    n = 1\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=42)\n    assert (len(subgraphs) == n)\n    valid_result = [[_conv([3]), _conv(['5', 1])]]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=42)\n    assert (len(subgraphs) == n)\n    valid_result = [[_conv([3]), _conv(['5', 1, 1])]]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n_size = [1, 1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=42)\n    assert (len(subgraphs) == n)\n    valid_result = [[_conv([3]), _conv(['5']), _conv([1]), _conv([3])]]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    nodes = _conv(['5'])\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=42)\n    assert (len(subgraphs) == n)\n    valid_result = [[['5'], [4, 1], [3, 3], ['5', '5', '5'], [2, 2, 2], [4, '5', 4], [2, 3, 3], [1, '5', '5'], [1, '5', '5']]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    nodes = _conv(['5'])\n    n_size = [2, 3]\n    n = 3\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=42)\n    assert (len(subgraphs) == n)\n    valid_result = [[['5'], [4, 1], [3, 3], ['5', '5', '5'], [2, 2, 2], [4, '5', 4], [2, 3, 3], [1, '5', '5'], [1, '5', '5']], [['5'], [1, 1], [6, 3], [4, 4, '5'], [3, 3, 3], ['5', '5', 4], [3, 3, 3], ['5', '5', '5'], [1, 1, 1]], [['5'], [1, 1], [3, 3], ['5', 4, 4], [2, 2, 3], ['5', '5', 4], [3, 2, 2], ['5', '5', '5'], ['5', '5', '5']]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    g = create_test_graph(multi=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n    nodes = _conv([1])\n    n = 1\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=19893839)\n    assert (len(subgraphs) == n)\n    valid_result = [[[1], [4, 4], [4, 4], [2, 2]]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    _recursive_items_equal(subgraphs, valid_result)\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=19893839)\n    assert (len(subgraphs) == n)\n    valid_result = [[[1], [4, 4], ['5', '5'], [2, 2], [1, 1, 1], ['5', 1, 1], [2, 2, 2], [1, 1, 1], [1, '5', 1], [2, 2, 2], [7, 7, 7], [4, 1, 1], [6, 3, 6], [7, 7, 7], [1, 4, 1], [6, 6, 6], [4, 1, 1], [1, 1, 1]]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    nodes = _conv([1])\n    n_size = [2, 0]\n    n = 2\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=19893839)\n    assert (len(subgraphs) == n)\n    valid_result = [[[1], [4, 4], ['5', '5'], [2, 2], [], [], [], [], [], [], [], [], [], [], [], [], [], []], [[1], [4, 4], [4, 4], [2, 2], [], [], [], [], [], [], [], [], [], [], [], [], [], []]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)", "masked_code": "def test_walk_generation_single_root_node(self):\n    g = create_test_graph(self_loop=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n\n    def _conv(ns):\n        return [((- 1) if (n is None) else g.node_ids_to_ilocs([n])[0]) for n in ns]\n    nodes = _conv([3])\n    n = 1\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=42)\n    assert (len(subgraphs) == n)\n    valid_result = [[_conv([3]), _conv(['5', 1])]]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=42)\n    assert (len(subgraphs) == n)\n    valid_result = [[_conv([3]), _conv(['5', 1, 1])]]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n_size = [1, 1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=42)\n    assert (len(subgraphs) == n)\n    valid_result = [[_conv([3]), _conv(['5']), _conv([1]), _conv([3])]]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    nodes = _conv(['5'])\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=42)\n    assert (len(subgraphs) == n)\n    valid_result = [[['5'], [4, 1], [3, 3], ['5', '5', '5'], [2, 2, 2], [4, '5', 4], [2, 3, 3], [1, '5', '5'], [1, '5', '5']]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    nodes = _conv(['5'])\n    n_size = [2, 3]\n    n = 3\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=42)\n    assert (len(subgraphs) == n)\n    valid_result = [[['5'], [4, 1], [3, 3], ['5', '5', '5'], [2, 2, 2], [4, '5', 4], [2, 3, 3], [1, '5', '5'], [1, '5', '5']], [['5'], [1, 1], [6, 3], [4, 4, '5'], [3, 3, 3], ['5', '5', 4], [3, 3, 3], ['5', '5', '5'], [1, 1, 1]], [['5'], [1, 1], [3, 3], ['5', 4, 4], [2, 2, 3], ['5', '5', 4], [3, 2, 2], ['5', '5', '5'], ['5', '5', '5']]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    g = create_test_graph(multi=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n    nodes = _conv([1])\n    n = 1\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=19893839)\n    assert (len(subgraphs) == '???')\n    valid_result = [[[1], [4, 4], [4, 4], [2, 2]]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    _recursive_items_equal(subgraphs, valid_result)\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=19893839)\n    assert (len(subgraphs) == n)\n    valid_result = [[[1], [4, 4], ['5', '5'], [2, 2], [1, 1, 1], ['5', 1, 1], [2, 2, 2], [1, 1, 1], [1, '5', 1], [2, 2, 2], [7, 7, 7], [4, 1, 1], [6, 3, 6], [7, 7, 7], [1, 4, 1], [6, 6, 6], [4, 1, 1], [1, 1, 1]]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    nodes = _conv([1])\n    n_size = [2, 0]\n    n = 2\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=19893839)\n    assert (len(subgraphs) == n)\n    valid_result = [[[1], [4, 4], ['5', '5'], [2, 2], [], [], [], [], [], [], [], [], [], [], [], [], [], []], [[1], [4, 4], [4, 4], [2, 2], [], [], [], [], [], [], [], [], [], [], [], [], [], []]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)", "ground_truth": "n", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_392", "reponame": "stellargraph", "testpath": "tests/data/test_heterogeneous_breadth_first_walker.py", "testname": "test_heterogeneous_breadth_first_walker.py", "classname": "TestSampledHeterogeneousBreadthFirstWalk", "funcname": "test_walk_generation_single_root_node", "imports": ["import pandas as pd", "import numpy as np", "import pytest", "from stellargraph.data.explorer import SampledHeterogeneousBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph", "from ..test_utils.graphs import example_graph_random"], "code": "def test_walk_generation_single_root_node(self):\n    g = create_test_graph(self_loop=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n\n    def _conv(ns):\n        return [((- 1) if (n is None) else g.node_ids_to_ilocs([n])[0]) for n in ns]\n    nodes = _conv([3])\n    n = 1\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=42)\n    assert (len(subgraphs) == n)\n    valid_result = [[_conv([3]), _conv(['5', 1])]]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=42)\n    assert (len(subgraphs) == n)\n    valid_result = [[_conv([3]), _conv(['5', 1, 1])]]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n_size = [1, 1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=42)\n    assert (len(subgraphs) == n)\n    valid_result = [[_conv([3]), _conv(['5']), _conv([1]), _conv([3])]]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    nodes = _conv(['5'])\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=42)\n    assert (len(subgraphs) == n)\n    valid_result = [[['5'], [4, 1], [3, 3], ['5', '5', '5'], [2, 2, 2], [4, '5', 4], [2, 3, 3], [1, '5', '5'], [1, '5', '5']]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    nodes = _conv(['5'])\n    n_size = [2, 3]\n    n = 3\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=42)\n    assert (len(subgraphs) == n)\n    valid_result = [[['5'], [4, 1], [3, 3], ['5', '5', '5'], [2, 2, 2], [4, '5', 4], [2, 3, 3], [1, '5', '5'], [1, '5', '5']], [['5'], [1, 1], [6, 3], [4, 4, '5'], [3, 3, 3], ['5', '5', 4], [3, 3, 3], ['5', '5', '5'], [1, 1, 1]], [['5'], [1, 1], [3, 3], ['5', 4, 4], [2, 2, 3], ['5', '5', 4], [3, 2, 2], ['5', '5', '5'], ['5', '5', '5']]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    g = create_test_graph(multi=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n    nodes = _conv([1])\n    n = 1\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=19893839)\n    assert (len(subgraphs) == n)\n    valid_result = [[[1], [4, 4], [4, 4], [2, 2]]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    _recursive_items_equal(subgraphs, valid_result)\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=19893839)\n    assert (len(subgraphs) == n)\n    valid_result = [[[1], [4, 4], ['5', '5'], [2, 2], [1, 1, 1], ['5', 1, 1], [2, 2, 2], [1, 1, 1], [1, '5', 1], [2, 2, 2], [7, 7, 7], [4, 1, 1], [6, 3, 6], [7, 7, 7], [1, 4, 1], [6, 6, 6], [4, 1, 1], [1, 1, 1]]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    nodes = _conv([1])\n    n_size = [2, 0]\n    n = 2\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=19893839)\n    assert (len(subgraphs) == n)\n    valid_result = [[[1], [4, 4], ['5', '5'], [2, 2], [], [], [], [], [], [], [], [], [], [], [], [], [], []], [[1], [4, 4], [4, 4], [2, 2], [], [], [], [], [], [], [], [], [], [], [], [], [], []]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)", "masked_code": "def test_walk_generation_single_root_node(self):\n    g = create_test_graph(self_loop=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n\n    def _conv(ns):\n        return [((- 1) if (n is None) else g.node_ids_to_ilocs([n])[0]) for n in ns]\n    nodes = _conv([3])\n    n = 1\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=42)\n    assert (len(subgraphs) == n)\n    valid_result = [[_conv([3]), _conv(['5', 1])]]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=42)\n    assert (len(subgraphs) == n)\n    valid_result = [[_conv([3]), _conv(['5', 1, 1])]]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n_size = [1, 1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=42)\n    assert (len(subgraphs) == n)\n    valid_result = [[_conv([3]), _conv(['5']), _conv([1]), _conv([3])]]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    nodes = _conv(['5'])\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=42)\n    assert (len(subgraphs) == n)\n    valid_result = [[['5'], [4, 1], [3, 3], ['5', '5', '5'], [2, 2, 2], [4, '5', 4], [2, 3, 3], [1, '5', '5'], [1, '5', '5']]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    nodes = _conv(['5'])\n    n_size = [2, 3]\n    n = 3\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=42)\n    assert (len(subgraphs) == n)\n    valid_result = [[['5'], [4, 1], [3, 3], ['5', '5', '5'], [2, 2, 2], [4, '5', 4], [2, 3, 3], [1, '5', '5'], [1, '5', '5']], [['5'], [1, 1], [6, 3], [4, 4, '5'], [3, 3, 3], ['5', '5', 4], [3, 3, 3], ['5', '5', '5'], [1, 1, 1]], [['5'], [1, 1], [3, 3], ['5', 4, 4], [2, 2, 3], ['5', '5', 4], [3, 2, 2], ['5', '5', '5'], ['5', '5', '5']]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    g = create_test_graph(multi=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n    nodes = _conv([1])\n    n = 1\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=19893839)\n    assert (len(subgraphs) == n)\n    valid_result = [[[1], [4, 4], [4, 4], [2, 2]]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    _recursive_items_equal(subgraphs, valid_result)\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=19893839)\n    assert (len(subgraphs) == '???')\n    valid_result = [[[1], [4, 4], ['5', '5'], [2, 2], [1, 1, 1], ['5', 1, 1], [2, 2, 2], [1, 1, 1], [1, '5', 1], [2, 2, 2], [7, 7, 7], [4, 1, 1], [6, 3, 6], [7, 7, 7], [1, 4, 1], [6, 6, 6], [4, 1, 1], [1, 1, 1]]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    nodes = _conv([1])\n    n_size = [2, 0]\n    n = 2\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=19893839)\n    assert (len(subgraphs) == n)\n    valid_result = [[[1], [4, 4], ['5', '5'], [2, 2], [], [], [], [], [], [], [], [], [], [], [], [], [], []], [[1], [4, 4], [4, 4], [2, 2], [], [], [], [], [], [], [], [], [], [], [], [], [], []]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)", "ground_truth": "n", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_393", "reponame": "stellargraph", "testpath": "tests/data/test_heterogeneous_breadth_first_walker.py", "testname": "test_heterogeneous_breadth_first_walker.py", "classname": "TestSampledHeterogeneousBreadthFirstWalk", "funcname": "test_walk_generation_single_root_node", "imports": ["import pandas as pd", "import numpy as np", "import pytest", "from stellargraph.data.explorer import SampledHeterogeneousBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph", "from ..test_utils.graphs import example_graph_random"], "code": "def test_walk_generation_single_root_node(self):\n    g = create_test_graph(self_loop=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n\n    def _conv(ns):\n        return [((- 1) if (n is None) else g.node_ids_to_ilocs([n])[0]) for n in ns]\n    nodes = _conv([3])\n    n = 1\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=42)\n    assert (len(subgraphs) == n)\n    valid_result = [[_conv([3]), _conv(['5', 1])]]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=42)\n    assert (len(subgraphs) == n)\n    valid_result = [[_conv([3]), _conv(['5', 1, 1])]]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n_size = [1, 1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=42)\n    assert (len(subgraphs) == n)\n    valid_result = [[_conv([3]), _conv(['5']), _conv([1]), _conv([3])]]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    nodes = _conv(['5'])\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=42)\n    assert (len(subgraphs) == n)\n    valid_result = [[['5'], [4, 1], [3, 3], ['5', '5', '5'], [2, 2, 2], [4, '5', 4], [2, 3, 3], [1, '5', '5'], [1, '5', '5']]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    nodes = _conv(['5'])\n    n_size = [2, 3]\n    n = 3\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=42)\n    assert (len(subgraphs) == n)\n    valid_result = [[['5'], [4, 1], [3, 3], ['5', '5', '5'], [2, 2, 2], [4, '5', 4], [2, 3, 3], [1, '5', '5'], [1, '5', '5']], [['5'], [1, 1], [6, 3], [4, 4, '5'], [3, 3, 3], ['5', '5', 4], [3, 3, 3], ['5', '5', '5'], [1, 1, 1]], [['5'], [1, 1], [3, 3], ['5', 4, 4], [2, 2, 3], ['5', '5', 4], [3, 2, 2], ['5', '5', '5'], ['5', '5', '5']]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    g = create_test_graph(multi=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n    nodes = _conv([1])\n    n = 1\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=19893839)\n    assert (len(subgraphs) == n)\n    valid_result = [[[1], [4, 4], [4, 4], [2, 2]]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    _recursive_items_equal(subgraphs, valid_result)\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=19893839)\n    assert (len(subgraphs) == n)\n    valid_result = [[[1], [4, 4], ['5', '5'], [2, 2], [1, 1, 1], ['5', 1, 1], [2, 2, 2], [1, 1, 1], [1, '5', 1], [2, 2, 2], [7, 7, 7], [4, 1, 1], [6, 3, 6], [7, 7, 7], [1, 4, 1], [6, 6, 6], [4, 1, 1], [1, 1, 1]]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    nodes = _conv([1])\n    n_size = [2, 0]\n    n = 2\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=19893839)\n    assert (len(subgraphs) == n)\n    valid_result = [[[1], [4, 4], ['5', '5'], [2, 2], [], [], [], [], [], [], [], [], [], [], [], [], [], []], [[1], [4, 4], [4, 4], [2, 2], [], [], [], [], [], [], [], [], [], [], [], [], [], []]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)", "masked_code": "def test_walk_generation_single_root_node(self):\n    g = create_test_graph(self_loop=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n\n    def _conv(ns):\n        return [((- 1) if (n is None) else g.node_ids_to_ilocs([n])[0]) for n in ns]\n    nodes = _conv([3])\n    n = 1\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=42)\n    assert (len(subgraphs) == n)\n    valid_result = [[_conv([3]), _conv(['5', 1])]]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n_size = [3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=42)\n    assert (len(subgraphs) == n)\n    valid_result = [[_conv([3]), _conv(['5', 1, 1])]]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n_size = [1, 1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=42)\n    assert (len(subgraphs) == n)\n    valid_result = [[_conv([3]), _conv(['5']), _conv([1]), _conv([3])]]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    nodes = _conv(['5'])\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=42)\n    assert (len(subgraphs) == n)\n    valid_result = [[['5'], [4, 1], [3, 3], ['5', '5', '5'], [2, 2, 2], [4, '5', 4], [2, 3, 3], [1, '5', '5'], [1, '5', '5']]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    nodes = _conv(['5'])\n    n_size = [2, 3]\n    n = 3\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=42)\n    assert (len(subgraphs) == n)\n    valid_result = [[['5'], [4, 1], [3, 3], ['5', '5', '5'], [2, 2, 2], [4, '5', 4], [2, 3, 3], [1, '5', '5'], [1, '5', '5']], [['5'], [1, 1], [6, 3], [4, 4, '5'], [3, 3, 3], ['5', '5', 4], [3, 3, 3], ['5', '5', '5'], [1, 1, 1]], [['5'], [1, 1], [3, 3], ['5', 4, 4], [2, 2, 3], ['5', '5', 4], [3, 2, 2], ['5', '5', '5'], ['5', '5', '5']]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    g = create_test_graph(multi=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n    nodes = _conv([1])\n    n = 1\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=19893839)\n    assert (len(subgraphs) == n)\n    valid_result = [[[1], [4, 4], [4, 4], [2, 2]]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    _recursive_items_equal(subgraphs, valid_result)\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=19893839)\n    assert (len(subgraphs) == n)\n    valid_result = [[[1], [4, 4], ['5', '5'], [2, 2], [1, 1, 1], ['5', 1, 1], [2, 2, 2], [1, 1, 1], [1, '5', 1], [2, 2, 2], [7, 7, 7], [4, 1, 1], [6, 3, 6], [7, 7, 7], [1, 4, 1], [6, 6, 6], [4, 1, 1], [1, 1, 1]]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    nodes = _conv([1])\n    n_size = [2, 0]\n    n = 2\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=19893839)\n    assert (len(subgraphs) == '???')\n    valid_result = [[[1], [4, 4], ['5', '5'], [2, 2], [], [], [], [], [], [], [], [], [], [], [], [], [], []], [[1], [4, 4], [4, 4], [2, 2], [], [], [], [], [], [], [], [], [], [], [], [], [], []]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)", "ground_truth": "n", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_394", "reponame": "stellargraph", "testpath": "tests/data/test_heterogeneous_breadth_first_walker.py", "testname": "test_heterogeneous_breadth_first_walker.py", "classname": "TestSampledHeterogeneousBreadthFirstWalk", "funcname": "test_walk_generation_many_root_nodes", "imports": ["import pandas as pd", "import numpy as np", "import pytest", "from stellargraph.data.explorer import SampledHeterogeneousBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph", "from ..test_utils.graphs import example_graph_random"], "code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph(self_loop=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n\n    def _conv(ns):\n        return [((- 1) if (n is None) else g.node_ids_to_ilocs([n])[0]) for n in ns]\n    nodes = _conv([0, 7])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 3)\n        assert (subgraph[0][0] == nodes[i])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 3)\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 3)\n    valid_result = [[_conv([0]), [(- 1), (- 1)], [(- 1), (- 1)]], [_conv([7]), _conv([7, 7]), [(- 1), (- 1)]]]\n    assert _recursive_items_equal(valid_result, subgraphs)\n    n_size = [2, 2]\n    nodes = _conv([0, 4])\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    assert (subgraphs[0][0][0] == nodes[0])\n    valid_result = [[[0], [None, None], [None, None], [None, None], [None, None], [None, None], [None, None], [None, None], [None, None]], [[4], ['5', 1], [2, 2], [1, 1], [6, 3], [4, 4], [2, 3], [1, 1], [4, 4]]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n_size = [2, 3]\n    nodes = _conv([1, 6])\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    assert (subgraphs[0][0][0] == nodes[0])\n    valid_result = [[[1], ['5', 4], [3, 3], [1, 1, '5'], [2, 2, 2], [1, 4, 1], [3, 6, 6], [1, '5', '5'], [1, '5', 1]], [[6], ['5', '5'], [4, 4, 1], [6, 3, 6], [4, 4, 1], [6, 6, 3]]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n = 5\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    g = create_test_graph(multi=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n    nodes = _conv([1, 6])\n    n = 1\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))\n    valid_result = [[[1], [4, 4], [4, 4], [2, 2]], [[6], ['5', '5']]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n = 1\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))\n    nodes = _conv([4, '5', 0])\n    n = 1\n    n_size = [3, 3, 1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))\n    n = 99\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))", "masked_code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph(self_loop=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n\n    def _conv(ns):\n        return [((- 1) if (n is None) else g.node_ids_to_ilocs([n])[0]) for n in ns]\n    nodes = _conv([0, 7])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == '???')\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 3)\n        assert (subgraph[0][0] == nodes[i])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 3)\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 3)\n    valid_result = [[_conv([0]), [(- 1), (- 1)], [(- 1), (- 1)]], [_conv([7]), _conv([7, 7]), [(- 1), (- 1)]]]\n    assert _recursive_items_equal(valid_result, subgraphs)\n    n_size = [2, 2]\n    nodes = _conv([0, 4])\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    assert (subgraphs[0][0][0] == nodes[0])\n    valid_result = [[[0], [None, None], [None, None], [None, None], [None, None], [None, None], [None, None], [None, None], [None, None]], [[4], ['5', 1], [2, 2], [1, 1], [6, 3], [4, 4], [2, 3], [1, 1], [4, 4]]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n_size = [2, 3]\n    nodes = _conv([1, 6])\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    assert (subgraphs[0][0][0] == nodes[0])\n    valid_result = [[[1], ['5', 4], [3, 3], [1, 1, '5'], [2, 2, 2], [1, 4, 1], [3, 6, 6], [1, '5', '5'], [1, '5', 1]], [[6], ['5', '5'], [4, 4, 1], [6, 3, 6], [4, 4, 1], [6, 6, 3]]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n = 5\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    g = create_test_graph(multi=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n    nodes = _conv([1, 6])\n    n = 1\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))\n    valid_result = [[[1], [4, 4], [4, 4], [2, 2]], [[6], ['5', '5']]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n = 1\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))\n    nodes = _conv([4, '5', 0])\n    n = 1\n    n_size = [3, 3, 1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))\n    n = 99\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))", "ground_truth": "(len(nodes) * n)", "quality_analysis": {"complexity_score": 11, "left_complexity": 4, "right_complexity": 7, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_395", "reponame": "stellargraph", "testpath": "tests/data/test_heterogeneous_breadth_first_walker.py", "testname": "test_heterogeneous_breadth_first_walker.py", "classname": "TestSampledHeterogeneousBreadthFirstWalk", "funcname": "test_walk_generation_many_root_nodes", "imports": ["import pandas as pd", "import numpy as np", "import pytest", "from stellargraph.data.explorer import SampledHeterogeneousBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph", "from ..test_utils.graphs import example_graph_random"], "code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph(self_loop=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n\n    def _conv(ns):\n        return [((- 1) if (n is None) else g.node_ids_to_ilocs([n])[0]) for n in ns]\n    nodes = _conv([0, 7])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 3)\n        assert (subgraph[0][0] == nodes[i])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 3)\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 3)\n    valid_result = [[_conv([0]), [(- 1), (- 1)], [(- 1), (- 1)]], [_conv([7]), _conv([7, 7]), [(- 1), (- 1)]]]\n    assert _recursive_items_equal(valid_result, subgraphs)\n    n_size = [2, 2]\n    nodes = _conv([0, 4])\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    assert (subgraphs[0][0][0] == nodes[0])\n    valid_result = [[[0], [None, None], [None, None], [None, None], [None, None], [None, None], [None, None], [None, None], [None, None]], [[4], ['5', 1], [2, 2], [1, 1], [6, 3], [4, 4], [2, 3], [1, 1], [4, 4]]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n_size = [2, 3]\n    nodes = _conv([1, 6])\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    assert (subgraphs[0][0][0] == nodes[0])\n    valid_result = [[[1], ['5', 4], [3, 3], [1, 1, '5'], [2, 2, 2], [1, 4, 1], [3, 6, 6], [1, '5', '5'], [1, '5', 1]], [[6], ['5', '5'], [4, 4, 1], [6, 3, 6], [4, 4, 1], [6, 6, 3]]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n = 5\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    g = create_test_graph(multi=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n    nodes = _conv([1, 6])\n    n = 1\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))\n    valid_result = [[[1], [4, 4], [4, 4], [2, 2]], [[6], ['5', '5']]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n = 1\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))\n    nodes = _conv([4, '5', 0])\n    n = 1\n    n_size = [3, 3, 1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))\n    n = 99\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))", "masked_code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph(self_loop=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n\n    def _conv(ns):\n        return [((- 1) if (n is None) else g.node_ids_to_ilocs([n])[0]) for n in ns]\n    nodes = _conv([0, 7])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 3)\n        assert (subgraph[0][0] == nodes[i])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == '???')\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 3)\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 3)\n    valid_result = [[_conv([0]), [(- 1), (- 1)], [(- 1), (- 1)]], [_conv([7]), _conv([7, 7]), [(- 1), (- 1)]]]\n    assert _recursive_items_equal(valid_result, subgraphs)\n    n_size = [2, 2]\n    nodes = _conv([0, 4])\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    assert (subgraphs[0][0][0] == nodes[0])\n    valid_result = [[[0], [None, None], [None, None], [None, None], [None, None], [None, None], [None, None], [None, None], [None, None]], [[4], ['5', 1], [2, 2], [1, 1], [6, 3], [4, 4], [2, 3], [1, 1], [4, 4]]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n_size = [2, 3]\n    nodes = _conv([1, 6])\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    assert (subgraphs[0][0][0] == nodes[0])\n    valid_result = [[[1], ['5', 4], [3, 3], [1, 1, '5'], [2, 2, 2], [1, 4, 1], [3, 6, 6], [1, '5', '5'], [1, '5', 1]], [[6], ['5', '5'], [4, 4, 1], [6, 3, 6], [4, 4, 1], [6, 6, 3]]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n = 5\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    g = create_test_graph(multi=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n    nodes = _conv([1, 6])\n    n = 1\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))\n    valid_result = [[[1], [4, 4], [4, 4], [2, 2]], [[6], ['5', '5']]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n = 1\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))\n    nodes = _conv([4, '5', 0])\n    n = 1\n    n_size = [3, 3, 1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))\n    n = 99\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))", "ground_truth": "(len(nodes) * n)", "quality_analysis": {"complexity_score": 11, "left_complexity": 4, "right_complexity": 7, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_396", "reponame": "stellargraph", "testpath": "tests/data/test_heterogeneous_breadth_first_walker.py", "testname": "test_heterogeneous_breadth_first_walker.py", "classname": "TestSampledHeterogeneousBreadthFirstWalk", "funcname": "test_walk_generation_many_root_nodes", "imports": ["import pandas as pd", "import numpy as np", "import pytest", "from stellargraph.data.explorer import SampledHeterogeneousBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph", "from ..test_utils.graphs import example_graph_random"], "code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph(self_loop=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n\n    def _conv(ns):\n        return [((- 1) if (n is None) else g.node_ids_to_ilocs([n])[0]) for n in ns]\n    nodes = _conv([0, 7])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 3)\n        assert (subgraph[0][0] == nodes[i])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 3)\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 3)\n    valid_result = [[_conv([0]), [(- 1), (- 1)], [(- 1), (- 1)]], [_conv([7]), _conv([7, 7]), [(- 1), (- 1)]]]\n    assert _recursive_items_equal(valid_result, subgraphs)\n    n_size = [2, 2]\n    nodes = _conv([0, 4])\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    assert (subgraphs[0][0][0] == nodes[0])\n    valid_result = [[[0], [None, None], [None, None], [None, None], [None, None], [None, None], [None, None], [None, None], [None, None]], [[4], ['5', 1], [2, 2], [1, 1], [6, 3], [4, 4], [2, 3], [1, 1], [4, 4]]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n_size = [2, 3]\n    nodes = _conv([1, 6])\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    assert (subgraphs[0][0][0] == nodes[0])\n    valid_result = [[[1], ['5', 4], [3, 3], [1, 1, '5'], [2, 2, 2], [1, 4, 1], [3, 6, 6], [1, '5', '5'], [1, '5', 1]], [[6], ['5', '5'], [4, 4, 1], [6, 3, 6], [4, 4, 1], [6, 6, 3]]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n = 5\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    g = create_test_graph(multi=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n    nodes = _conv([1, 6])\n    n = 1\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))\n    valid_result = [[[1], [4, 4], [4, 4], [2, 2]], [[6], ['5', '5']]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n = 1\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))\n    nodes = _conv([4, '5', 0])\n    n = 1\n    n_size = [3, 3, 1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))\n    n = 99\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))", "masked_code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph(self_loop=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n\n    def _conv(ns):\n        return [((- 1) if (n is None) else g.node_ids_to_ilocs([n])[0]) for n in ns]\n    nodes = _conv([0, 7])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 3)\n        assert (subgraph[0][0] == nodes[i])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 3)\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == '???')\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 3)\n    valid_result = [[_conv([0]), [(- 1), (- 1)], [(- 1), (- 1)]], [_conv([7]), _conv([7, 7]), [(- 1), (- 1)]]]\n    assert _recursive_items_equal(valid_result, subgraphs)\n    n_size = [2, 2]\n    nodes = _conv([0, 4])\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    assert (subgraphs[0][0][0] == nodes[0])\n    valid_result = [[[0], [None, None], [None, None], [None, None], [None, None], [None, None], [None, None], [None, None], [None, None]], [[4], ['5', 1], [2, 2], [1, 1], [6, 3], [4, 4], [2, 3], [1, 1], [4, 4]]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n_size = [2, 3]\n    nodes = _conv([1, 6])\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    assert (subgraphs[0][0][0] == nodes[0])\n    valid_result = [[[1], ['5', 4], [3, 3], [1, 1, '5'], [2, 2, 2], [1, 4, 1], [3, 6, 6], [1, '5', '5'], [1, '5', 1]], [[6], ['5', '5'], [4, 4, 1], [6, 3, 6], [4, 4, 1], [6, 6, 3]]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n = 5\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    g = create_test_graph(multi=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n    nodes = _conv([1, 6])\n    n = 1\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))\n    valid_result = [[[1], [4, 4], [4, 4], [2, 2]], [[6], ['5', '5']]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n = 1\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))\n    nodes = _conv([4, '5', 0])\n    n = 1\n    n_size = [3, 3, 1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))\n    n = 99\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))", "ground_truth": "(len(nodes) * n)", "quality_analysis": {"complexity_score": 11, "left_complexity": 4, "right_complexity": 7, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_397", "reponame": "stellargraph", "testpath": "tests/data/test_heterogeneous_breadth_first_walker.py", "testname": "test_heterogeneous_breadth_first_walker.py", "classname": "TestSampledHeterogeneousBreadthFirstWalk", "funcname": "test_walk_generation_many_root_nodes", "imports": ["import pandas as pd", "import numpy as np", "import pytest", "from stellargraph.data.explorer import SampledHeterogeneousBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph", "from ..test_utils.graphs import example_graph_random"], "code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph(self_loop=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n\n    def _conv(ns):\n        return [((- 1) if (n is None) else g.node_ids_to_ilocs([n])[0]) for n in ns]\n    nodes = _conv([0, 7])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 3)\n        assert (subgraph[0][0] == nodes[i])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 3)\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 3)\n    valid_result = [[_conv([0]), [(- 1), (- 1)], [(- 1), (- 1)]], [_conv([7]), _conv([7, 7]), [(- 1), (- 1)]]]\n    assert _recursive_items_equal(valid_result, subgraphs)\n    n_size = [2, 2]\n    nodes = _conv([0, 4])\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    assert (subgraphs[0][0][0] == nodes[0])\n    valid_result = [[[0], [None, None], [None, None], [None, None], [None, None], [None, None], [None, None], [None, None], [None, None]], [[4], ['5', 1], [2, 2], [1, 1], [6, 3], [4, 4], [2, 3], [1, 1], [4, 4]]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n_size = [2, 3]\n    nodes = _conv([1, 6])\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    assert (subgraphs[0][0][0] == nodes[0])\n    valid_result = [[[1], ['5', 4], [3, 3], [1, 1, '5'], [2, 2, 2], [1, 4, 1], [3, 6, 6], [1, '5', '5'], [1, '5', 1]], [[6], ['5', '5'], [4, 4, 1], [6, 3, 6], [4, 4, 1], [6, 6, 3]]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n = 5\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    g = create_test_graph(multi=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n    nodes = _conv([1, 6])\n    n = 1\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))\n    valid_result = [[[1], [4, 4], [4, 4], [2, 2]], [[6], ['5', '5']]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n = 1\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))\n    nodes = _conv([4, '5', 0])\n    n = 1\n    n_size = [3, 3, 1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))\n    n = 99\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))", "masked_code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph(self_loop=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n\n    def _conv(ns):\n        return [((- 1) if (n is None) else g.node_ids_to_ilocs([n])[0]) for n in ns]\n    nodes = _conv([0, 7])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 3)\n        assert (subgraph[0][0] == nodes[i])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 3)\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 3)\n    valid_result = [[_conv([0]), [(- 1), (- 1)], [(- 1), (- 1)]], [_conv([7]), _conv([7, 7]), [(- 1), (- 1)]]]\n    assert _recursive_items_equal(valid_result, subgraphs)\n    n_size = [2, 2]\n    nodes = _conv([0, 4])\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == '???')\n    assert (subgraphs[0][0][0] == nodes[0])\n    valid_result = [[[0], [None, None], [None, None], [None, None], [None, None], [None, None], [None, None], [None, None], [None, None]], [[4], ['5', 1], [2, 2], [1, 1], [6, 3], [4, 4], [2, 3], [1, 1], [4, 4]]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n_size = [2, 3]\n    nodes = _conv([1, 6])\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    assert (subgraphs[0][0][0] == nodes[0])\n    valid_result = [[[1], ['5', 4], [3, 3], [1, 1, '5'], [2, 2, 2], [1, 4, 1], [3, 6, 6], [1, '5', '5'], [1, '5', 1]], [[6], ['5', '5'], [4, 4, 1], [6, 3, 6], [4, 4, 1], [6, 6, 3]]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n = 5\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    g = create_test_graph(multi=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n    nodes = _conv([1, 6])\n    n = 1\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))\n    valid_result = [[[1], [4, 4], [4, 4], [2, 2]], [[6], ['5', '5']]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n = 1\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))\n    nodes = _conv([4, '5', 0])\n    n = 1\n    n_size = [3, 3, 1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))\n    n = 99\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))", "ground_truth": "(len(nodes) * n)", "quality_analysis": {"complexity_score": 11, "left_complexity": 4, "right_complexity": 7, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_398", "reponame": "stellargraph", "testpath": "tests/data/test_heterogeneous_breadth_first_walker.py", "testname": "test_heterogeneous_breadth_first_walker.py", "classname": "TestSampledHeterogeneousBreadthFirstWalk", "funcname": "test_walk_generation_many_root_nodes", "imports": ["import pandas as pd", "import numpy as np", "import pytest", "from stellargraph.data.explorer import SampledHeterogeneousBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph", "from ..test_utils.graphs import example_graph_random"], "code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph(self_loop=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n\n    def _conv(ns):\n        return [((- 1) if (n is None) else g.node_ids_to_ilocs([n])[0]) for n in ns]\n    nodes = _conv([0, 7])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 3)\n        assert (subgraph[0][0] == nodes[i])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 3)\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 3)\n    valid_result = [[_conv([0]), [(- 1), (- 1)], [(- 1), (- 1)]], [_conv([7]), _conv([7, 7]), [(- 1), (- 1)]]]\n    assert _recursive_items_equal(valid_result, subgraphs)\n    n_size = [2, 2]\n    nodes = _conv([0, 4])\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    assert (subgraphs[0][0][0] == nodes[0])\n    valid_result = [[[0], [None, None], [None, None], [None, None], [None, None], [None, None], [None, None], [None, None], [None, None]], [[4], ['5', 1], [2, 2], [1, 1], [6, 3], [4, 4], [2, 3], [1, 1], [4, 4]]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n_size = [2, 3]\n    nodes = _conv([1, 6])\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    assert (subgraphs[0][0][0] == nodes[0])\n    valid_result = [[[1], ['5', 4], [3, 3], [1, 1, '5'], [2, 2, 2], [1, 4, 1], [3, 6, 6], [1, '5', '5'], [1, '5', 1]], [[6], ['5', '5'], [4, 4, 1], [6, 3, 6], [4, 4, 1], [6, 6, 3]]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n = 5\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    g = create_test_graph(multi=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n    nodes = _conv([1, 6])\n    n = 1\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))\n    valid_result = [[[1], [4, 4], [4, 4], [2, 2]], [[6], ['5', '5']]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n = 1\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))\n    nodes = _conv([4, '5', 0])\n    n = 1\n    n_size = [3, 3, 1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))\n    n = 99\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))", "masked_code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph(self_loop=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n\n    def _conv(ns):\n        return [((- 1) if (n is None) else g.node_ids_to_ilocs([n])[0]) for n in ns]\n    nodes = _conv([0, 7])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 3)\n        assert (subgraph[0][0] == nodes[i])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 3)\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 3)\n    valid_result = [[_conv([0]), [(- 1), (- 1)], [(- 1), (- 1)]], [_conv([7]), _conv([7, 7]), [(- 1), (- 1)]]]\n    assert _recursive_items_equal(valid_result, subgraphs)\n    n_size = [2, 2]\n    nodes = _conv([0, 4])\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    assert (subgraphs[0][0][0] == '???')\n    valid_result = [[[0], [None, None], [None, None], [None, None], [None, None], [None, None], [None, None], [None, None], [None, None]], [[4], ['5', 1], [2, 2], [1, 1], [6, 3], [4, 4], [2, 3], [1, 1], [4, 4]]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n_size = [2, 3]\n    nodes = _conv([1, 6])\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    assert (subgraphs[0][0][0] == nodes[0])\n    valid_result = [[[1], ['5', 4], [3, 3], [1, 1, '5'], [2, 2, 2], [1, 4, 1], [3, 6, 6], [1, '5', '5'], [1, '5', 1]], [[6], ['5', '5'], [4, 4, 1], [6, 3, 6], [4, 4, 1], [6, 6, 3]]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n = 5\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    g = create_test_graph(multi=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n    nodes = _conv([1, 6])\n    n = 1\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))\n    valid_result = [[[1], [4, 4], [4, 4], [2, 2]], [[6], ['5', '5']]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n = 1\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))\n    nodes = _conv([4, '5', 0])\n    n = 1\n    n_size = [3, 3, 1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))\n    n = 99\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))", "ground_truth": "nodes[0]", "quality_analysis": {"complexity_score": 18, "left_complexity": 13, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_399", "reponame": "stellargraph", "testpath": "tests/data/test_heterogeneous_breadth_first_walker.py", "testname": "test_heterogeneous_breadth_first_walker.py", "classname": "TestSampledHeterogeneousBreadthFirstWalk", "funcname": "test_walk_generation_many_root_nodes", "imports": ["import pandas as pd", "import numpy as np", "import pytest", "from stellargraph.data.explorer import SampledHeterogeneousBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph", "from ..test_utils.graphs import example_graph_random"], "code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph(self_loop=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n\n    def _conv(ns):\n        return [((- 1) if (n is None) else g.node_ids_to_ilocs([n])[0]) for n in ns]\n    nodes = _conv([0, 7])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 3)\n        assert (subgraph[0][0] == nodes[i])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 3)\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 3)\n    valid_result = [[_conv([0]), [(- 1), (- 1)], [(- 1), (- 1)]], [_conv([7]), _conv([7, 7]), [(- 1), (- 1)]]]\n    assert _recursive_items_equal(valid_result, subgraphs)\n    n_size = [2, 2]\n    nodes = _conv([0, 4])\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    assert (subgraphs[0][0][0] == nodes[0])\n    valid_result = [[[0], [None, None], [None, None], [None, None], [None, None], [None, None], [None, None], [None, None], [None, None]], [[4], ['5', 1], [2, 2], [1, 1], [6, 3], [4, 4], [2, 3], [1, 1], [4, 4]]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n_size = [2, 3]\n    nodes = _conv([1, 6])\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    assert (subgraphs[0][0][0] == nodes[0])\n    valid_result = [[[1], ['5', 4], [3, 3], [1, 1, '5'], [2, 2, 2], [1, 4, 1], [3, 6, 6], [1, '5', '5'], [1, '5', 1]], [[6], ['5', '5'], [4, 4, 1], [6, 3, 6], [4, 4, 1], [6, 6, 3]]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n = 5\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    g = create_test_graph(multi=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n    nodes = _conv([1, 6])\n    n = 1\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))\n    valid_result = [[[1], [4, 4], [4, 4], [2, 2]], [[6], ['5', '5']]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n = 1\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))\n    nodes = _conv([4, '5', 0])\n    n = 1\n    n_size = [3, 3, 1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))\n    n = 99\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))", "masked_code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph(self_loop=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n\n    def _conv(ns):\n        return [((- 1) if (n is None) else g.node_ids_to_ilocs([n])[0]) for n in ns]\n    nodes = _conv([0, 7])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 3)\n        assert (subgraph[0][0] == nodes[i])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 3)\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 3)\n    valid_result = [[_conv([0]), [(- 1), (- 1)], [(- 1), (- 1)]], [_conv([7]), _conv([7, 7]), [(- 1), (- 1)]]]\n    assert _recursive_items_equal(valid_result, subgraphs)\n    n_size = [2, 2]\n    nodes = _conv([0, 4])\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    assert (subgraphs[0][0][0] == nodes[0])\n    valid_result = [[[0], [None, None], [None, None], [None, None], [None, None], [None, None], [None, None], [None, None], [None, None]], [[4], ['5', 1], [2, 2], [1, 1], [6, 3], [4, 4], [2, 3], [1, 1], [4, 4]]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n_size = [2, 3]\n    nodes = _conv([1, 6])\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == '???')\n    assert (subgraphs[0][0][0] == nodes[0])\n    valid_result = [[[1], ['5', 4], [3, 3], [1, 1, '5'], [2, 2, 2], [1, 4, 1], [3, 6, 6], [1, '5', '5'], [1, '5', 1]], [[6], ['5', '5'], [4, 4, 1], [6, 3, 6], [4, 4, 1], [6, 6, 3]]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n = 5\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    g = create_test_graph(multi=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n    nodes = _conv([1, 6])\n    n = 1\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))\n    valid_result = [[[1], [4, 4], [4, 4], [2, 2]], [[6], ['5', '5']]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n = 1\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))\n    nodes = _conv([4, '5', 0])\n    n = 1\n    n_size = [3, 3, 1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))\n    n = 99\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))", "ground_truth": "(len(nodes) * n)", "quality_analysis": {"complexity_score": 11, "left_complexity": 4, "right_complexity": 7, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_400", "reponame": "stellargraph", "testpath": "tests/data/test_heterogeneous_breadth_first_walker.py", "testname": "test_heterogeneous_breadth_first_walker.py", "classname": "TestSampledHeterogeneousBreadthFirstWalk", "funcname": "test_walk_generation_many_root_nodes", "imports": ["import pandas as pd", "import numpy as np", "import pytest", "from stellargraph.data.explorer import SampledHeterogeneousBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph", "from ..test_utils.graphs import example_graph_random"], "code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph(self_loop=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n\n    def _conv(ns):\n        return [((- 1) if (n is None) else g.node_ids_to_ilocs([n])[0]) for n in ns]\n    nodes = _conv([0, 7])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 3)\n        assert (subgraph[0][0] == nodes[i])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 3)\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 3)\n    valid_result = [[_conv([0]), [(- 1), (- 1)], [(- 1), (- 1)]], [_conv([7]), _conv([7, 7]), [(- 1), (- 1)]]]\n    assert _recursive_items_equal(valid_result, subgraphs)\n    n_size = [2, 2]\n    nodes = _conv([0, 4])\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    assert (subgraphs[0][0][0] == nodes[0])\n    valid_result = [[[0], [None, None], [None, None], [None, None], [None, None], [None, None], [None, None], [None, None], [None, None]], [[4], ['5', 1], [2, 2], [1, 1], [6, 3], [4, 4], [2, 3], [1, 1], [4, 4]]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n_size = [2, 3]\n    nodes = _conv([1, 6])\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    assert (subgraphs[0][0][0] == nodes[0])\n    valid_result = [[[1], ['5', 4], [3, 3], [1, 1, '5'], [2, 2, 2], [1, 4, 1], [3, 6, 6], [1, '5', '5'], [1, '5', 1]], [[6], ['5', '5'], [4, 4, 1], [6, 3, 6], [4, 4, 1], [6, 6, 3]]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n = 5\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    g = create_test_graph(multi=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n    nodes = _conv([1, 6])\n    n = 1\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))\n    valid_result = [[[1], [4, 4], [4, 4], [2, 2]], [[6], ['5', '5']]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n = 1\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))\n    nodes = _conv([4, '5', 0])\n    n = 1\n    n_size = [3, 3, 1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))\n    n = 99\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))", "masked_code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph(self_loop=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n\n    def _conv(ns):\n        return [((- 1) if (n is None) else g.node_ids_to_ilocs([n])[0]) for n in ns]\n    nodes = _conv([0, 7])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 3)\n        assert (subgraph[0][0] == nodes[i])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 3)\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 3)\n    valid_result = [[_conv([0]), [(- 1), (- 1)], [(- 1), (- 1)]], [_conv([7]), _conv([7, 7]), [(- 1), (- 1)]]]\n    assert _recursive_items_equal(valid_result, subgraphs)\n    n_size = [2, 2]\n    nodes = _conv([0, 4])\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    assert (subgraphs[0][0][0] == nodes[0])\n    valid_result = [[[0], [None, None], [None, None], [None, None], [None, None], [None, None], [None, None], [None, None], [None, None]], [[4], ['5', 1], [2, 2], [1, 1], [6, 3], [4, 4], [2, 3], [1, 1], [4, 4]]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n_size = [2, 3]\n    nodes = _conv([1, 6])\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    assert (subgraphs[0][0][0] == '???')\n    valid_result = [[[1], ['5', 4], [3, 3], [1, 1, '5'], [2, 2, 2], [1, 4, 1], [3, 6, 6], [1, '5', '5'], [1, '5', 1]], [[6], ['5', '5'], [4, 4, 1], [6, 3, 6], [4, 4, 1], [6, 6, 3]]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n = 5\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    g = create_test_graph(multi=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n    nodes = _conv([1, 6])\n    n = 1\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))\n    valid_result = [[[1], [4, 4], [4, 4], [2, 2]], [[6], ['5', '5']]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n = 1\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))\n    nodes = _conv([4, '5', 0])\n    n = 1\n    n_size = [3, 3, 1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))\n    n = 99\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))", "ground_truth": "nodes[0]", "quality_analysis": {"complexity_score": 18, "left_complexity": 13, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_401", "reponame": "stellargraph", "testpath": "tests/data/test_heterogeneous_breadth_first_walker.py", "testname": "test_heterogeneous_breadth_first_walker.py", "classname": "TestSampledHeterogeneousBreadthFirstWalk", "funcname": "test_walk_generation_many_root_nodes", "imports": ["import pandas as pd", "import numpy as np", "import pytest", "from stellargraph.data.explorer import SampledHeterogeneousBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph", "from ..test_utils.graphs import example_graph_random"], "code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph(self_loop=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n\n    def _conv(ns):\n        return [((- 1) if (n is None) else g.node_ids_to_ilocs([n])[0]) for n in ns]\n    nodes = _conv([0, 7])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 3)\n        assert (subgraph[0][0] == nodes[i])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 3)\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 3)\n    valid_result = [[_conv([0]), [(- 1), (- 1)], [(- 1), (- 1)]], [_conv([7]), _conv([7, 7]), [(- 1), (- 1)]]]\n    assert _recursive_items_equal(valid_result, subgraphs)\n    n_size = [2, 2]\n    nodes = _conv([0, 4])\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    assert (subgraphs[0][0][0] == nodes[0])\n    valid_result = [[[0], [None, None], [None, None], [None, None], [None, None], [None, None], [None, None], [None, None], [None, None]], [[4], ['5', 1], [2, 2], [1, 1], [6, 3], [4, 4], [2, 3], [1, 1], [4, 4]]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n_size = [2, 3]\n    nodes = _conv([1, 6])\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    assert (subgraphs[0][0][0] == nodes[0])\n    valid_result = [[[1], ['5', 4], [3, 3], [1, 1, '5'], [2, 2, 2], [1, 4, 1], [3, 6, 6], [1, '5', '5'], [1, '5', 1]], [[6], ['5', '5'], [4, 4, 1], [6, 3, 6], [4, 4, 1], [6, 6, 3]]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n = 5\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    g = create_test_graph(multi=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n    nodes = _conv([1, 6])\n    n = 1\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))\n    valid_result = [[[1], [4, 4], [4, 4], [2, 2]], [[6], ['5', '5']]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n = 1\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))\n    nodes = _conv([4, '5', 0])\n    n = 1\n    n_size = [3, 3, 1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))\n    n = 99\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))", "masked_code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph(self_loop=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n\n    def _conv(ns):\n        return [((- 1) if (n is None) else g.node_ids_to_ilocs([n])[0]) for n in ns]\n    nodes = _conv([0, 7])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 3)\n        assert (subgraph[0][0] == nodes[i])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 3)\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 3)\n    valid_result = [[_conv([0]), [(- 1), (- 1)], [(- 1), (- 1)]], [_conv([7]), _conv([7, 7]), [(- 1), (- 1)]]]\n    assert _recursive_items_equal(valid_result, subgraphs)\n    n_size = [2, 2]\n    nodes = _conv([0, 4])\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    assert (subgraphs[0][0][0] == nodes[0])\n    valid_result = [[[0], [None, None], [None, None], [None, None], [None, None], [None, None], [None, None], [None, None], [None, None]], [[4], ['5', 1], [2, 2], [1, 1], [6, 3], [4, 4], [2, 3], [1, 1], [4, 4]]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n_size = [2, 3]\n    nodes = _conv([1, 6])\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    assert (subgraphs[0][0][0] == nodes[0])\n    valid_result = [[[1], ['5', 4], [3, 3], [1, 1, '5'], [2, 2, 2], [1, 4, 1], [3, 6, 6], [1, '5', '5'], [1, '5', 1]], [[6], ['5', '5'], [4, 4, 1], [6, 3, 6], [4, 4, 1], [6, 6, 3]]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n = 5\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == '???')\n    g = create_test_graph(multi=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n    nodes = _conv([1, 6])\n    n = 1\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))\n    valid_result = [[[1], [4, 4], [4, 4], [2, 2]], [[6], ['5', '5']]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n = 1\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))\n    nodes = _conv([4, '5', 0])\n    n = 1\n    n_size = [3, 3, 1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))\n    n = 99\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))", "ground_truth": "(len(nodes) * n)", "quality_analysis": {"complexity_score": 11, "left_complexity": 4, "right_complexity": 7, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_402", "reponame": "stellargraph", "testpath": "tests/data/test_heterogeneous_breadth_first_walker.py", "testname": "test_heterogeneous_breadth_first_walker.py", "classname": "TestSampledHeterogeneousBreadthFirstWalk", "funcname": "test_walk_generation_many_root_nodes", "imports": ["import pandas as pd", "import numpy as np", "import pytest", "from stellargraph.data.explorer import SampledHeterogeneousBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph", "from ..test_utils.graphs import example_graph_random"], "code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph(self_loop=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n\n    def _conv(ns):\n        return [((- 1) if (n is None) else g.node_ids_to_ilocs([n])[0]) for n in ns]\n    nodes = _conv([0, 7])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 3)\n        assert (subgraph[0][0] == nodes[i])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 3)\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 3)\n    valid_result = [[_conv([0]), [(- 1), (- 1)], [(- 1), (- 1)]], [_conv([7]), _conv([7, 7]), [(- 1), (- 1)]]]\n    assert _recursive_items_equal(valid_result, subgraphs)\n    n_size = [2, 2]\n    nodes = _conv([0, 4])\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    assert (subgraphs[0][0][0] == nodes[0])\n    valid_result = [[[0], [None, None], [None, None], [None, None], [None, None], [None, None], [None, None], [None, None], [None, None]], [[4], ['5', 1], [2, 2], [1, 1], [6, 3], [4, 4], [2, 3], [1, 1], [4, 4]]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n_size = [2, 3]\n    nodes = _conv([1, 6])\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    assert (subgraphs[0][0][0] == nodes[0])\n    valid_result = [[[1], ['5', 4], [3, 3], [1, 1, '5'], [2, 2, 2], [1, 4, 1], [3, 6, 6], [1, '5', '5'], [1, '5', 1]], [[6], ['5', '5'], [4, 4, 1], [6, 3, 6], [4, 4, 1], [6, 6, 3]]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n = 5\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    g = create_test_graph(multi=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n    nodes = _conv([1, 6])\n    n = 1\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))\n    valid_result = [[[1], [4, 4], [4, 4], [2, 2]], [[6], ['5', '5']]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n = 1\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))\n    nodes = _conv([4, '5', 0])\n    n = 1\n    n_size = [3, 3, 1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))\n    n = 99\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))", "masked_code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph(self_loop=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n\n    def _conv(ns):\n        return [((- 1) if (n is None) else g.node_ids_to_ilocs([n])[0]) for n in ns]\n    nodes = _conv([0, 7])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 3)\n        assert (subgraph[0][0] == nodes[i])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 3)\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 3)\n    valid_result = [[_conv([0]), [(- 1), (- 1)], [(- 1), (- 1)]], [_conv([7]), _conv([7, 7]), [(- 1), (- 1)]]]\n    assert _recursive_items_equal(valid_result, subgraphs)\n    n_size = [2, 2]\n    nodes = _conv([0, 4])\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    assert (subgraphs[0][0][0] == nodes[0])\n    valid_result = [[[0], [None, None], [None, None], [None, None], [None, None], [None, None], [None, None], [None, None], [None, None]], [[4], ['5', 1], [2, 2], [1, 1], [6, 3], [4, 4], [2, 3], [1, 1], [4, 4]]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n_size = [2, 3]\n    nodes = _conv([1, 6])\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    assert (subgraphs[0][0][0] == nodes[0])\n    valid_result = [[[1], ['5', 4], [3, 3], [1, 1, '5'], [2, 2, 2], [1, 4, 1], [3, 6, 6], [1, '5', '5'], [1, '5', 1]], [[6], ['5', '5'], [4, 4, 1], [6, 3, 6], [4, 4, 1], [6, 6, 3]]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n = 5\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    g = create_test_graph(multi=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n    nodes = _conv([1, 6])\n    n = 1\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == '???')\n    valid_result = [[[1], [4, 4], [4, 4], [2, 2]], [[6], ['5', '5']]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n = 1\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))\n    nodes = _conv([4, '5', 0])\n    n = 1\n    n_size = [3, 3, 1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))\n    n = 99\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))", "ground_truth": "(n * len(nodes))", "quality_analysis": {"complexity_score": 11, "left_complexity": 4, "right_complexity": 7, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_403", "reponame": "stellargraph", "testpath": "tests/data/test_heterogeneous_breadth_first_walker.py", "testname": "test_heterogeneous_breadth_first_walker.py", "classname": "TestSampledHeterogeneousBreadthFirstWalk", "funcname": "test_walk_generation_many_root_nodes", "imports": ["import pandas as pd", "import numpy as np", "import pytest", "from stellargraph.data.explorer import SampledHeterogeneousBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph", "from ..test_utils.graphs import example_graph_random"], "code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph(self_loop=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n\n    def _conv(ns):\n        return [((- 1) if (n is None) else g.node_ids_to_ilocs([n])[0]) for n in ns]\n    nodes = _conv([0, 7])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 3)\n        assert (subgraph[0][0] == nodes[i])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 3)\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 3)\n    valid_result = [[_conv([0]), [(- 1), (- 1)], [(- 1), (- 1)]], [_conv([7]), _conv([7, 7]), [(- 1), (- 1)]]]\n    assert _recursive_items_equal(valid_result, subgraphs)\n    n_size = [2, 2]\n    nodes = _conv([0, 4])\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    assert (subgraphs[0][0][0] == nodes[0])\n    valid_result = [[[0], [None, None], [None, None], [None, None], [None, None], [None, None], [None, None], [None, None], [None, None]], [[4], ['5', 1], [2, 2], [1, 1], [6, 3], [4, 4], [2, 3], [1, 1], [4, 4]]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n_size = [2, 3]\n    nodes = _conv([1, 6])\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    assert (subgraphs[0][0][0] == nodes[0])\n    valid_result = [[[1], ['5', 4], [3, 3], [1, 1, '5'], [2, 2, 2], [1, 4, 1], [3, 6, 6], [1, '5', '5'], [1, '5', 1]], [[6], ['5', '5'], [4, 4, 1], [6, 3, 6], [4, 4, 1], [6, 6, 3]]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n = 5\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    g = create_test_graph(multi=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n    nodes = _conv([1, 6])\n    n = 1\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))\n    valid_result = [[[1], [4, 4], [4, 4], [2, 2]], [[6], ['5', '5']]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n = 1\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))\n    nodes = _conv([4, '5', 0])\n    n = 1\n    n_size = [3, 3, 1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))\n    n = 99\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))", "masked_code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph(self_loop=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n\n    def _conv(ns):\n        return [((- 1) if (n is None) else g.node_ids_to_ilocs([n])[0]) for n in ns]\n    nodes = _conv([0, 7])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 3)\n        assert (subgraph[0][0] == nodes[i])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 3)\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 3)\n    valid_result = [[_conv([0]), [(- 1), (- 1)], [(- 1), (- 1)]], [_conv([7]), _conv([7, 7]), [(- 1), (- 1)]]]\n    assert _recursive_items_equal(valid_result, subgraphs)\n    n_size = [2, 2]\n    nodes = _conv([0, 4])\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    assert (subgraphs[0][0][0] == nodes[0])\n    valid_result = [[[0], [None, None], [None, None], [None, None], [None, None], [None, None], [None, None], [None, None], [None, None]], [[4], ['5', 1], [2, 2], [1, 1], [6, 3], [4, 4], [2, 3], [1, 1], [4, 4]]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n_size = [2, 3]\n    nodes = _conv([1, 6])\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    assert (subgraphs[0][0][0] == nodes[0])\n    valid_result = [[[1], ['5', 4], [3, 3], [1, 1, '5'], [2, 2, 2], [1, 4, 1], [3, 6, 6], [1, '5', '5'], [1, '5', 1]], [[6], ['5', '5'], [4, 4, 1], [6, 3, 6], [4, 4, 1], [6, 6, 3]]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n = 5\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    g = create_test_graph(multi=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n    nodes = _conv([1, 6])\n    n = 1\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))\n    valid_result = [[[1], [4, 4], [4, 4], [2, 2]], [[6], ['5', '5']]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n = 1\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == '???')\n    nodes = _conv([4, '5', 0])\n    n = 1\n    n_size = [3, 3, 1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))\n    n = 99\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))", "ground_truth": "(n * len(nodes))", "quality_analysis": {"complexity_score": 11, "left_complexity": 4, "right_complexity": 7, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_404", "reponame": "stellargraph", "testpath": "tests/data/test_heterogeneous_breadth_first_walker.py", "testname": "test_heterogeneous_breadth_first_walker.py", "classname": "TestSampledHeterogeneousBreadthFirstWalk", "funcname": "test_walk_generation_many_root_nodes", "imports": ["import pandas as pd", "import numpy as np", "import pytest", "from stellargraph.data.explorer import SampledHeterogeneousBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph", "from ..test_utils.graphs import example_graph_random"], "code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph(self_loop=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n\n    def _conv(ns):\n        return [((- 1) if (n is None) else g.node_ids_to_ilocs([n])[0]) for n in ns]\n    nodes = _conv([0, 7])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 3)\n        assert (subgraph[0][0] == nodes[i])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 3)\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 3)\n    valid_result = [[_conv([0]), [(- 1), (- 1)], [(- 1), (- 1)]], [_conv([7]), _conv([7, 7]), [(- 1), (- 1)]]]\n    assert _recursive_items_equal(valid_result, subgraphs)\n    n_size = [2, 2]\n    nodes = _conv([0, 4])\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    assert (subgraphs[0][0][0] == nodes[0])\n    valid_result = [[[0], [None, None], [None, None], [None, None], [None, None], [None, None], [None, None], [None, None], [None, None]], [[4], ['5', 1], [2, 2], [1, 1], [6, 3], [4, 4], [2, 3], [1, 1], [4, 4]]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n_size = [2, 3]\n    nodes = _conv([1, 6])\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    assert (subgraphs[0][0][0] == nodes[0])\n    valid_result = [[[1], ['5', 4], [3, 3], [1, 1, '5'], [2, 2, 2], [1, 4, 1], [3, 6, 6], [1, '5', '5'], [1, '5', 1]], [[6], ['5', '5'], [4, 4, 1], [6, 3, 6], [4, 4, 1], [6, 6, 3]]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n = 5\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    g = create_test_graph(multi=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n    nodes = _conv([1, 6])\n    n = 1\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))\n    valid_result = [[[1], [4, 4], [4, 4], [2, 2]], [[6], ['5', '5']]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n = 1\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))\n    nodes = _conv([4, '5', 0])\n    n = 1\n    n_size = [3, 3, 1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))\n    n = 99\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))", "masked_code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph(self_loop=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n\n    def _conv(ns):\n        return [((- 1) if (n is None) else g.node_ids_to_ilocs([n])[0]) for n in ns]\n    nodes = _conv([0, 7])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 3)\n        assert (subgraph[0][0] == nodes[i])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 3)\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 3)\n    valid_result = [[_conv([0]), [(- 1), (- 1)], [(- 1), (- 1)]], [_conv([7]), _conv([7, 7]), [(- 1), (- 1)]]]\n    assert _recursive_items_equal(valid_result, subgraphs)\n    n_size = [2, 2]\n    nodes = _conv([0, 4])\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    assert (subgraphs[0][0][0] == nodes[0])\n    valid_result = [[[0], [None, None], [None, None], [None, None], [None, None], [None, None], [None, None], [None, None], [None, None]], [[4], ['5', 1], [2, 2], [1, 1], [6, 3], [4, 4], [2, 3], [1, 1], [4, 4]]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n_size = [2, 3]\n    nodes = _conv([1, 6])\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    assert (subgraphs[0][0][0] == nodes[0])\n    valid_result = [[[1], ['5', 4], [3, 3], [1, 1, '5'], [2, 2, 2], [1, 4, 1], [3, 6, 6], [1, '5', '5'], [1, '5', 1]], [[6], ['5', '5'], [4, 4, 1], [6, 3, 6], [4, 4, 1], [6, 6, 3]]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n = 5\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    g = create_test_graph(multi=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n    nodes = _conv([1, 6])\n    n = 1\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))\n    valid_result = [[[1], [4, 4], [4, 4], [2, 2]], [[6], ['5', '5']]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n = 1\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))\n    nodes = _conv([4, '5', 0])\n    n = 1\n    n_size = [3, 3, 1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == '???')\n    n = 99\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))", "ground_truth": "(n * len(nodes))", "quality_analysis": {"complexity_score": 11, "left_complexity": 4, "right_complexity": 7, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_405", "reponame": "stellargraph", "testpath": "tests/data/test_heterogeneous_breadth_first_walker.py", "testname": "test_heterogeneous_breadth_first_walker.py", "classname": "TestSampledHeterogeneousBreadthFirstWalk", "funcname": "test_walk_generation_many_root_nodes", "imports": ["import pandas as pd", "import numpy as np", "import pytest", "from stellargraph.data.explorer import SampledHeterogeneousBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph", "from ..test_utils.graphs import example_graph_random"], "code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph(self_loop=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n\n    def _conv(ns):\n        return [((- 1) if (n is None) else g.node_ids_to_ilocs([n])[0]) for n in ns]\n    nodes = _conv([0, 7])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 3)\n        assert (subgraph[0][0] == nodes[i])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 3)\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 3)\n    valid_result = [[_conv([0]), [(- 1), (- 1)], [(- 1), (- 1)]], [_conv([7]), _conv([7, 7]), [(- 1), (- 1)]]]\n    assert _recursive_items_equal(valid_result, subgraphs)\n    n_size = [2, 2]\n    nodes = _conv([0, 4])\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    assert (subgraphs[0][0][0] == nodes[0])\n    valid_result = [[[0], [None, None], [None, None], [None, None], [None, None], [None, None], [None, None], [None, None], [None, None]], [[4], ['5', 1], [2, 2], [1, 1], [6, 3], [4, 4], [2, 3], [1, 1], [4, 4]]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n_size = [2, 3]\n    nodes = _conv([1, 6])\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    assert (subgraphs[0][0][0] == nodes[0])\n    valid_result = [[[1], ['5', 4], [3, 3], [1, 1, '5'], [2, 2, 2], [1, 4, 1], [3, 6, 6], [1, '5', '5'], [1, '5', 1]], [[6], ['5', '5'], [4, 4, 1], [6, 3, 6], [4, 4, 1], [6, 6, 3]]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n = 5\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    g = create_test_graph(multi=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n    nodes = _conv([1, 6])\n    n = 1\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))\n    valid_result = [[[1], [4, 4], [4, 4], [2, 2]], [[6], ['5', '5']]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n = 1\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))\n    nodes = _conv([4, '5', 0])\n    n = 1\n    n_size = [3, 3, 1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))\n    n = 99\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))", "masked_code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph(self_loop=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n\n    def _conv(ns):\n        return [((- 1) if (n is None) else g.node_ids_to_ilocs([n])[0]) for n in ns]\n    nodes = _conv([0, 7])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 3)\n        assert (subgraph[0][0] == nodes[i])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 3)\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 3)\n    valid_result = [[_conv([0]), [(- 1), (- 1)], [(- 1), (- 1)]], [_conv([7]), _conv([7, 7]), [(- 1), (- 1)]]]\n    assert _recursive_items_equal(valid_result, subgraphs)\n    n_size = [2, 2]\n    nodes = _conv([0, 4])\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    assert (subgraphs[0][0][0] == nodes[0])\n    valid_result = [[[0], [None, None], [None, None], [None, None], [None, None], [None, None], [None, None], [None, None], [None, None]], [[4], ['5', 1], [2, 2], [1, 1], [6, 3], [4, 4], [2, 3], [1, 1], [4, 4]]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n_size = [2, 3]\n    nodes = _conv([1, 6])\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    assert (subgraphs[0][0][0] == nodes[0])\n    valid_result = [[[1], ['5', 4], [3, 3], [1, 1, '5'], [2, 2, 2], [1, 4, 1], [3, 6, 6], [1, '5', '5'], [1, '5', 1]], [[6], ['5', '5'], [4, 4, 1], [6, 3, 6], [4, 4, 1], [6, 6, 3]]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n = 5\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    g = create_test_graph(multi=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n    nodes = _conv([1, 6])\n    n = 1\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))\n    valid_result = [[[1], [4, 4], [4, 4], [2, 2]], [[6], ['5', '5']]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n = 1\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))\n    nodes = _conv([4, '5', 0])\n    n = 1\n    n_size = [3, 3, 1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))\n    n = 99\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == '???')", "ground_truth": "(n * len(nodes))", "quality_analysis": {"complexity_score": 11, "left_complexity": 4, "right_complexity": 7, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_406", "reponame": "stellargraph", "testpath": "tests/data/test_heterogeneous_breadth_first_walker.py", "testname": "test_heterogeneous_breadth_first_walker.py", "classname": "TestSampledHeterogeneousBreadthFirstWalk", "funcname": "test_walk_generation_many_root_nodes", "imports": ["import pandas as pd", "import numpy as np", "import pytest", "from stellargraph.data.explorer import SampledHeterogeneousBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph", "from ..test_utils.graphs import example_graph_random"], "code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph(self_loop=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n\n    def _conv(ns):\n        return [((- 1) if (n is None) else g.node_ids_to_ilocs([n])[0]) for n in ns]\n    nodes = _conv([0, 7])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 3)\n        assert (subgraph[0][0] == nodes[i])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 3)\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 3)\n    valid_result = [[_conv([0]), [(- 1), (- 1)], [(- 1), (- 1)]], [_conv([7]), _conv([7, 7]), [(- 1), (- 1)]]]\n    assert _recursive_items_equal(valid_result, subgraphs)\n    n_size = [2, 2]\n    nodes = _conv([0, 4])\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    assert (subgraphs[0][0][0] == nodes[0])\n    valid_result = [[[0], [None, None], [None, None], [None, None], [None, None], [None, None], [None, None], [None, None], [None, None]], [[4], ['5', 1], [2, 2], [1, 1], [6, 3], [4, 4], [2, 3], [1, 1], [4, 4]]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n_size = [2, 3]\n    nodes = _conv([1, 6])\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    assert (subgraphs[0][0][0] == nodes[0])\n    valid_result = [[[1], ['5', 4], [3, 3], [1, 1, '5'], [2, 2, 2], [1, 4, 1], [3, 6, 6], [1, '5', '5'], [1, '5', 1]], [[6], ['5', '5'], [4, 4, 1], [6, 3, 6], [4, 4, 1], [6, 6, 3]]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n = 5\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    g = create_test_graph(multi=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n    nodes = _conv([1, 6])\n    n = 1\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))\n    valid_result = [[[1], [4, 4], [4, 4], [2, 2]], [[6], ['5', '5']]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n = 1\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))\n    nodes = _conv([4, '5', 0])\n    n = 1\n    n_size = [3, 3, 1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))\n    n = 99\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))", "masked_code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph(self_loop=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n\n    def _conv(ns):\n        return [((- 1) if (n is None) else g.node_ids_to_ilocs([n])[0]) for n in ns]\n    nodes = _conv([0, 7])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == '???')\n        assert (subgraph[0][0] == nodes[i])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 3)\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 3)\n    valid_result = [[_conv([0]), [(- 1), (- 1)], [(- 1), (- 1)]], [_conv([7]), _conv([7, 7]), [(- 1), (- 1)]]]\n    assert _recursive_items_equal(valid_result, subgraphs)\n    n_size = [2, 2]\n    nodes = _conv([0, 4])\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    assert (subgraphs[0][0][0] == nodes[0])\n    valid_result = [[[0], [None, None], [None, None], [None, None], [None, None], [None, None], [None, None], [None, None], [None, None]], [[4], ['5', 1], [2, 2], [1, 1], [6, 3], [4, 4], [2, 3], [1, 1], [4, 4]]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n_size = [2, 3]\n    nodes = _conv([1, 6])\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    assert (subgraphs[0][0][0] == nodes[0])\n    valid_result = [[[1], ['5', 4], [3, 3], [1, 1, '5'], [2, 2, 2], [1, 4, 1], [3, 6, 6], [1, '5', '5'], [1, '5', 1]], [[6], ['5', '5'], [4, 4, 1], [6, 3, 6], [4, 4, 1], [6, 6, 3]]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n = 5\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    g = create_test_graph(multi=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n    nodes = _conv([1, 6])\n    n = 1\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))\n    valid_result = [[[1], [4, 4], [4, 4], [2, 2]], [[6], ['5', '5']]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n = 1\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))\n    nodes = _conv([4, '5', 0])\n    n = 1\n    n_size = [3, 3, 1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))\n    n = 99\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))", "ground_truth": "3", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_407", "reponame": "stellargraph", "testpath": "tests/data/test_heterogeneous_breadth_first_walker.py", "testname": "test_heterogeneous_breadth_first_walker.py", "classname": "TestSampledHeterogeneousBreadthFirstWalk", "funcname": "test_walk_generation_many_root_nodes", "imports": ["import pandas as pd", "import numpy as np", "import pytest", "from stellargraph.data.explorer import SampledHeterogeneousBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph", "from ..test_utils.graphs import example_graph_random"], "code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph(self_loop=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n\n    def _conv(ns):\n        return [((- 1) if (n is None) else g.node_ids_to_ilocs([n])[0]) for n in ns]\n    nodes = _conv([0, 7])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 3)\n        assert (subgraph[0][0] == nodes[i])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 3)\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 3)\n    valid_result = [[_conv([0]), [(- 1), (- 1)], [(- 1), (- 1)]], [_conv([7]), _conv([7, 7]), [(- 1), (- 1)]]]\n    assert _recursive_items_equal(valid_result, subgraphs)\n    n_size = [2, 2]\n    nodes = _conv([0, 4])\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    assert (subgraphs[0][0][0] == nodes[0])\n    valid_result = [[[0], [None, None], [None, None], [None, None], [None, None], [None, None], [None, None], [None, None], [None, None]], [[4], ['5', 1], [2, 2], [1, 1], [6, 3], [4, 4], [2, 3], [1, 1], [4, 4]]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n_size = [2, 3]\n    nodes = _conv([1, 6])\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    assert (subgraphs[0][0][0] == nodes[0])\n    valid_result = [[[1], ['5', 4], [3, 3], [1, 1, '5'], [2, 2, 2], [1, 4, 1], [3, 6, 6], [1, '5', '5'], [1, '5', 1]], [[6], ['5', '5'], [4, 4, 1], [6, 3, 6], [4, 4, 1], [6, 6, 3]]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n = 5\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    g = create_test_graph(multi=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n    nodes = _conv([1, 6])\n    n = 1\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))\n    valid_result = [[[1], [4, 4], [4, 4], [2, 2]], [[6], ['5', '5']]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n = 1\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))\n    nodes = _conv([4, '5', 0])\n    n = 1\n    n_size = [3, 3, 1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))\n    n = 99\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))", "masked_code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph(self_loop=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n\n    def _conv(ns):\n        return [((- 1) if (n is None) else g.node_ids_to_ilocs([n])[0]) for n in ns]\n    nodes = _conv([0, 7])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 3)\n        assert (subgraph[0][0] == '???')\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 3)\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 3)\n    valid_result = [[_conv([0]), [(- 1), (- 1)], [(- 1), (- 1)]], [_conv([7]), _conv([7, 7]), [(- 1), (- 1)]]]\n    assert _recursive_items_equal(valid_result, subgraphs)\n    n_size = [2, 2]\n    nodes = _conv([0, 4])\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    assert (subgraphs[0][0][0] == nodes[0])\n    valid_result = [[[0], [None, None], [None, None], [None, None], [None, None], [None, None], [None, None], [None, None], [None, None]], [[4], ['5', 1], [2, 2], [1, 1], [6, 3], [4, 4], [2, 3], [1, 1], [4, 4]]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n_size = [2, 3]\n    nodes = _conv([1, 6])\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    assert (subgraphs[0][0][0] == nodes[0])\n    valid_result = [[[1], ['5', 4], [3, 3], [1, 1, '5'], [2, 2, 2], [1, 4, 1], [3, 6, 6], [1, '5', '5'], [1, '5', 1]], [[6], ['5', '5'], [4, 4, 1], [6, 3, 6], [4, 4, 1], [6, 6, 3]]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n = 5\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    g = create_test_graph(multi=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n    nodes = _conv([1, 6])\n    n = 1\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))\n    valid_result = [[[1], [4, 4], [4, 4], [2, 2]], [[6], ['5', '5']]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n = 1\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))\n    nodes = _conv([4, '5', 0])\n    n = 1\n    n_size = [3, 3, 1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))\n    n = 99\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))", "ground_truth": "nodes[i]", "quality_analysis": {"complexity_score": 14, "left_complexity": 9, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_408", "reponame": "stellargraph", "testpath": "tests/data/test_heterogeneous_breadth_first_walker.py", "testname": "test_heterogeneous_breadth_first_walker.py", "classname": "TestSampledHeterogeneousBreadthFirstWalk", "funcname": "test_walk_generation_many_root_nodes", "imports": ["import pandas as pd", "import numpy as np", "import pytest", "from stellargraph.data.explorer import SampledHeterogeneousBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph", "from ..test_utils.graphs import example_graph_random"], "code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph(self_loop=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n\n    def _conv(ns):\n        return [((- 1) if (n is None) else g.node_ids_to_ilocs([n])[0]) for n in ns]\n    nodes = _conv([0, 7])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 3)\n        assert (subgraph[0][0] == nodes[i])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 3)\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 3)\n    valid_result = [[_conv([0]), [(- 1), (- 1)], [(- 1), (- 1)]], [_conv([7]), _conv([7, 7]), [(- 1), (- 1)]]]\n    assert _recursive_items_equal(valid_result, subgraphs)\n    n_size = [2, 2]\n    nodes = _conv([0, 4])\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    assert (subgraphs[0][0][0] == nodes[0])\n    valid_result = [[[0], [None, None], [None, None], [None, None], [None, None], [None, None], [None, None], [None, None], [None, None]], [[4], ['5', 1], [2, 2], [1, 1], [6, 3], [4, 4], [2, 3], [1, 1], [4, 4]]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n_size = [2, 3]\n    nodes = _conv([1, 6])\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    assert (subgraphs[0][0][0] == nodes[0])\n    valid_result = [[[1], ['5', 4], [3, 3], [1, 1, '5'], [2, 2, 2], [1, 4, 1], [3, 6, 6], [1, '5', '5'], [1, '5', 1]], [[6], ['5', '5'], [4, 4, 1], [6, 3, 6], [4, 4, 1], [6, 6, 3]]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n = 5\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    g = create_test_graph(multi=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n    nodes = _conv([1, 6])\n    n = 1\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))\n    valid_result = [[[1], [4, 4], [4, 4], [2, 2]], [[6], ['5', '5']]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n = 1\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))\n    nodes = _conv([4, '5', 0])\n    n = 1\n    n_size = [3, 3, 1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))\n    n = 99\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))", "masked_code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph(self_loop=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n\n    def _conv(ns):\n        return [((- 1) if (n is None) else g.node_ids_to_ilocs([n])[0]) for n in ns]\n    nodes = _conv([0, 7])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 3)\n        assert (subgraph[0][0] == nodes[i])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == '???')\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 3)\n    valid_result = [[_conv([0]), [(- 1), (- 1)], [(- 1), (- 1)]], [_conv([7]), _conv([7, 7]), [(- 1), (- 1)]]]\n    assert _recursive_items_equal(valid_result, subgraphs)\n    n_size = [2, 2]\n    nodes = _conv([0, 4])\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    assert (subgraphs[0][0][0] == nodes[0])\n    valid_result = [[[0], [None, None], [None, None], [None, None], [None, None], [None, None], [None, None], [None, None], [None, None]], [[4], ['5', 1], [2, 2], [1, 1], [6, 3], [4, 4], [2, 3], [1, 1], [4, 4]]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n_size = [2, 3]\n    nodes = _conv([1, 6])\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    assert (subgraphs[0][0][0] == nodes[0])\n    valid_result = [[[1], ['5', 4], [3, 3], [1, 1, '5'], [2, 2, 2], [1, 4, 1], [3, 6, 6], [1, '5', '5'], [1, '5', 1]], [[6], ['5', '5'], [4, 4, 1], [6, 3, 6], [4, 4, 1], [6, 6, 3]]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n = 5\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    g = create_test_graph(multi=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n    nodes = _conv([1, 6])\n    n = 1\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))\n    valid_result = [[[1], [4, 4], [4, 4], [2, 2]], [[6], ['5', '5']]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n = 1\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))\n    nodes = _conv([4, '5', 0])\n    n = 1\n    n_size = [3, 3, 1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))\n    n = 99\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))", "ground_truth": "3", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_409", "reponame": "stellargraph", "testpath": "tests/data/test_heterogeneous_breadth_first_walker.py", "testname": "test_heterogeneous_breadth_first_walker.py", "classname": "TestSampledHeterogeneousBreadthFirstWalk", "funcname": "test_walk_generation_many_root_nodes", "imports": ["import pandas as pd", "import numpy as np", "import pytest", "from stellargraph.data.explorer import SampledHeterogeneousBreadthFirstWalk", "from stellargraph.core.graph import StellarGraph", "from ..test_utils.graphs import example_graph_random"], "code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph(self_loop=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n\n    def _conv(ns):\n        return [((- 1) if (n is None) else g.node_ids_to_ilocs([n])[0]) for n in ns]\n    nodes = _conv([0, 7])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 3)\n        assert (subgraph[0][0] == nodes[i])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 3)\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 3)\n    valid_result = [[_conv([0]), [(- 1), (- 1)], [(- 1), (- 1)]], [_conv([7]), _conv([7, 7]), [(- 1), (- 1)]]]\n    assert _recursive_items_equal(valid_result, subgraphs)\n    n_size = [2, 2]\n    nodes = _conv([0, 4])\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    assert (subgraphs[0][0][0] == nodes[0])\n    valid_result = [[[0], [None, None], [None, None], [None, None], [None, None], [None, None], [None, None], [None, None], [None, None]], [[4], ['5', 1], [2, 2], [1, 1], [6, 3], [4, 4], [2, 3], [1, 1], [4, 4]]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n_size = [2, 3]\n    nodes = _conv([1, 6])\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    assert (subgraphs[0][0][0] == nodes[0])\n    valid_result = [[[1], ['5', 4], [3, 3], [1, 1, '5'], [2, 2, 2], [1, 4, 1], [3, 6, 6], [1, '5', '5'], [1, '5', 1]], [[6], ['5', '5'], [4, 4, 1], [6, 3, 6], [4, 4, 1], [6, 6, 3]]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n = 5\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    g = create_test_graph(multi=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n    nodes = _conv([1, 6])\n    n = 1\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))\n    valid_result = [[[1], [4, 4], [4, 4], [2, 2]], [[6], ['5', '5']]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n = 1\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))\n    nodes = _conv([4, '5', 0])\n    n = 1\n    n_size = [3, 3, 1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))\n    n = 99\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))", "masked_code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph(self_loop=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n\n    def _conv(ns):\n        return [((- 1) if (n is None) else g.node_ids_to_ilocs([n])[0]) for n in ns]\n    nodes = _conv([0, 7])\n    n = 1\n    n_size = [0]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 3)\n        assert (subgraph[0][0] == nodes[i])\n    n_size = [1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == 3)\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == '???')\n    valid_result = [[_conv([0]), [(- 1), (- 1)], [(- 1), (- 1)]], [_conv([7]), _conv([7, 7]), [(- 1), (- 1)]]]\n    assert _recursive_items_equal(valid_result, subgraphs)\n    n_size = [2, 2]\n    nodes = _conv([0, 4])\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    assert (subgraphs[0][0][0] == nodes[0])\n    valid_result = [[[0], [None, None], [None, None], [None, None], [None, None], [None, None], [None, None], [None, None], [None, None]], [[4], ['5', 1], [2, 2], [1, 1], [6, 3], [4, 4], [2, 3], [1, 1], [4, 4]]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n_size = [2, 3]\n    nodes = _conv([1, 6])\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    assert (subgraphs[0][0][0] == nodes[0])\n    valid_result = [[[1], ['5', 4], [3, 3], [1, 1, '5'], [2, 2, 2], [1, 4, 1], [3, 6, 6], [1, '5', '5'], [1, '5', 1]], [[6], ['5', '5'], [4, 4, 1], [6, 3, 6], [4, 4, 1], [6, 6, 3]]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n = 5\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (len(nodes) * n))\n    g = create_test_graph(multi=True)\n    bfw = SampledHeterogeneousBreadthFirstWalk(g)\n    nodes = _conv([1, 6])\n    n = 1\n    n_size = [2]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))\n    valid_result = [[[1], [4, 4], [4, 4], [2, 2]], [[6], ['5', '5']]]\n    valid_result = [[_conv(x) for x in y] for y in valid_result]\n    assert _recursive_items_equal(subgraphs, valid_result)\n    n = 1\n    n_size = [2, 3]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))\n    nodes = _conv([4, '5', 0])\n    n = 1\n    n_size = [3, 3, 1]\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))\n    n = 99\n    subgraphs = bfw.run(nodes=nodes, n=n, n_size=n_size, seed=999)\n    assert (len(subgraphs) == (n * len(nodes)))", "ground_truth": "3", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_410", "reponame": "stellargraph", "testpath": "tests/data/test_metapath_walker.py", "testname": "test_metapath_walker.py", "classname": "TestMetaPathWalk", "funcname": "test_walk_generation_single_root_node_loner", "imports": ["import pandas as pd", "import numpy as np", "import pytest", "from stellargraph.data.explorer import UniformRandomMetaPathWalk", "from stellargraph.core.graph import StellarGraph", "from ..test_utils.graphs import example_graph_random"], "code": "def test_walk_generation_single_root_node_loner(self):\n    g = create_test_graph()\n    mrw = UniformRandomMetaPathWalk(g)\n    seed = None\n    nodes = ['loner']\n    n = 1\n    length = 5\n    metapaths = [['s', 'n', 's']]\n    walks = mrw.run(nodes=nodes, n=n, length=length, metapaths=metapaths, seed=seed)\n    assert (len(walks) == n)\n    assert (len(walks[0]) == 1)\n    n = 5\n    walks = mrw.run(nodes=nodes, n=n, length=length, metapaths=metapaths, seed=seed)\n    assert (len(walks) == n)\n    for walk in walks:\n        assert (len(walk) == 1)", "masked_code": "def test_walk_generation_single_root_node_loner(self):\n    g = create_test_graph()\n    mrw = UniformRandomMetaPathWalk(g)\n    seed = None\n    nodes = ['loner']\n    n = 1\n    length = 5\n    metapaths = [['s', 'n', 's']]\n    walks = mrw.run(nodes=nodes, n=n, length=length, metapaths=metapaths, seed=seed)\n    assert (len(walks) == '???')\n    assert (len(walks[0]) == 1)\n    n = 5\n    walks = mrw.run(nodes=nodes, n=n, length=length, metapaths=metapaths, seed=seed)\n    assert (len(walks) == n)\n    for walk in walks:\n        assert (len(walk) == 1)", "ground_truth": "n", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_411", "reponame": "stellargraph", "testpath": "tests/data/test_metapath_walker.py", "testname": "test_metapath_walker.py", "classname": "TestMetaPathWalk", "funcname": "test_walk_generation_single_root_node_loner", "imports": ["import pandas as pd", "import numpy as np", "import pytest", "from stellargraph.data.explorer import UniformRandomMetaPathWalk", "from stellargraph.core.graph import StellarGraph", "from ..test_utils.graphs import example_graph_random"], "code": "def test_walk_generation_single_root_node_loner(self):\n    g = create_test_graph()\n    mrw = UniformRandomMetaPathWalk(g)\n    seed = None\n    nodes = ['loner']\n    n = 1\n    length = 5\n    metapaths = [['s', 'n', 's']]\n    walks = mrw.run(nodes=nodes, n=n, length=length, metapaths=metapaths, seed=seed)\n    assert (len(walks) == n)\n    assert (len(walks[0]) == 1)\n    n = 5\n    walks = mrw.run(nodes=nodes, n=n, length=length, metapaths=metapaths, seed=seed)\n    assert (len(walks) == n)\n    for walk in walks:\n        assert (len(walk) == 1)", "masked_code": "def test_walk_generation_single_root_node_loner(self):\n    g = create_test_graph()\n    mrw = UniformRandomMetaPathWalk(g)\n    seed = None\n    nodes = ['loner']\n    n = 1\n    length = 5\n    metapaths = [['s', 'n', 's']]\n    walks = mrw.run(nodes=nodes, n=n, length=length, metapaths=metapaths, seed=seed)\n    assert (len(walks) == n)\n    assert (len(walks[0]) == 1)\n    n = 5\n    walks = mrw.run(nodes=nodes, n=n, length=length, metapaths=metapaths, seed=seed)\n    assert (len(walks) == '???')\n    for walk in walks:\n        assert (len(walk) == 1)", "ground_truth": "n", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_412", "reponame": "stellargraph", "testpath": "tests/data/test_metapath_walker.py", "testname": "test_metapath_walker.py", "classname": "TestMetaPathWalk", "funcname": "test_walk_generation_single_root_node_self_loner", "imports": ["import pandas as pd", "import numpy as np", "import pytest", "from stellargraph.data.explorer import UniformRandomMetaPathWalk", "from stellargraph.core.graph import StellarGraph", "from ..test_utils.graphs import example_graph_random"], "code": "def test_walk_generation_single_root_node_self_loner(self):\n    g = create_test_graph()\n    mrw = UniformRandomMetaPathWalk(g)\n    seed = None\n    nodes = ['self loner']\n    n = 1\n    length = 10\n    metapaths = [['s', 'n', 'n', 's']]\n    walks = mrw.run(nodes=nodes, n=n, length=length, metapaths=metapaths, seed=seed)\n    assert (len(walks) == n)\n    assert (len(walks[0]) == 1)\n    metapaths = [['s', 's']]\n    walks = mrw.run(nodes=nodes, n=n, length=length, metapaths=metapaths, seed=seed)\n    assert (len(walks) == n)\n    assert (len(walks[0]) == length)\n    for node in walks[0]:\n        assert (node == 'self loner')", "masked_code": "def test_walk_generation_single_root_node_self_loner(self):\n    g = create_test_graph()\n    mrw = UniformRandomMetaPathWalk(g)\n    seed = None\n    nodes = ['self loner']\n    n = 1\n    length = 10\n    metapaths = [['s', 'n', 'n', 's']]\n    walks = mrw.run(nodes=nodes, n=n, length=length, metapaths=metapaths, seed=seed)\n    assert (len(walks) == '???')\n    assert (len(walks[0]) == 1)\n    metapaths = [['s', 's']]\n    walks = mrw.run(nodes=nodes, n=n, length=length, metapaths=metapaths, seed=seed)\n    assert (len(walks) == n)\n    assert (len(walks[0]) == length)\n    for node in walks[0]:\n        assert (node == 'self loner')", "ground_truth": "n", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_413", "reponame": "stellargraph", "testpath": "tests/data/test_metapath_walker.py", "testname": "test_metapath_walker.py", "classname": "TestMetaPathWalk", "funcname": "test_walk_generation_single_root_node_self_loner", "imports": ["import pandas as pd", "import numpy as np", "import pytest", "from stellargraph.data.explorer import UniformRandomMetaPathWalk", "from stellargraph.core.graph import StellarGraph", "from ..test_utils.graphs import example_graph_random"], "code": "def test_walk_generation_single_root_node_self_loner(self):\n    g = create_test_graph()\n    mrw = UniformRandomMetaPathWalk(g)\n    seed = None\n    nodes = ['self loner']\n    n = 1\n    length = 10\n    metapaths = [['s', 'n', 'n', 's']]\n    walks = mrw.run(nodes=nodes, n=n, length=length, metapaths=metapaths, seed=seed)\n    assert (len(walks) == n)\n    assert (len(walks[0]) == 1)\n    metapaths = [['s', 's']]\n    walks = mrw.run(nodes=nodes, n=n, length=length, metapaths=metapaths, seed=seed)\n    assert (len(walks) == n)\n    assert (len(walks[0]) == length)\n    for node in walks[0]:\n        assert (node == 'self loner')", "masked_code": "def test_walk_generation_single_root_node_self_loner(self):\n    g = create_test_graph()\n    mrw = UniformRandomMetaPathWalk(g)\n    seed = None\n    nodes = ['self loner']\n    n = 1\n    length = 10\n    metapaths = [['s', 'n', 'n', 's']]\n    walks = mrw.run(nodes=nodes, n=n, length=length, metapaths=metapaths, seed=seed)\n    assert (len(walks) == n)\n    assert (len(walks[0]) == 1)\n    metapaths = [['s', 's']]\n    walks = mrw.run(nodes=nodes, n=n, length=length, metapaths=metapaths, seed=seed)\n    assert (len(walks) == '???')\n    assert (len(walks[0]) == length)\n    for node in walks[0]:\n        assert (node == 'self loner')", "ground_truth": "n", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_414", "reponame": "stellargraph", "testpath": "tests/data/test_metapath_walker.py", "testname": "test_metapath_walker.py", "classname": "TestMetaPathWalk", "funcname": "test_walk_generation_single_root_node_self_loner", "imports": ["import pandas as pd", "import numpy as np", "import pytest", "from stellargraph.data.explorer import UniformRandomMetaPathWalk", "from stellargraph.core.graph import StellarGraph", "from ..test_utils.graphs import example_graph_random"], "code": "def test_walk_generation_single_root_node_self_loner(self):\n    g = create_test_graph()\n    mrw = UniformRandomMetaPathWalk(g)\n    seed = None\n    nodes = ['self loner']\n    n = 1\n    length = 10\n    metapaths = [['s', 'n', 'n', 's']]\n    walks = mrw.run(nodes=nodes, n=n, length=length, metapaths=metapaths, seed=seed)\n    assert (len(walks) == n)\n    assert (len(walks[0]) == 1)\n    metapaths = [['s', 's']]\n    walks = mrw.run(nodes=nodes, n=n, length=length, metapaths=metapaths, seed=seed)\n    assert (len(walks) == n)\n    assert (len(walks[0]) == length)\n    for node in walks[0]:\n        assert (node == 'self loner')", "masked_code": "def test_walk_generation_single_root_node_self_loner(self):\n    g = create_test_graph()\n    mrw = UniformRandomMetaPathWalk(g)\n    seed = None\n    nodes = ['self loner']\n    n = 1\n    length = 10\n    metapaths = [['s', 'n', 'n', 's']]\n    walks = mrw.run(nodes=nodes, n=n, length=length, metapaths=metapaths, seed=seed)\n    assert (len(walks) == n)\n    assert (len(walks[0]) == 1)\n    metapaths = [['s', 's']]\n    walks = mrw.run(nodes=nodes, n=n, length=length, metapaths=metapaths, seed=seed)\n    assert (len(walks) == n)\n    assert (len(walks[0]) == '???')\n    for node in walks[0]:\n        assert (node == 'self loner')", "ground_truth": "length", "quality_analysis": {"complexity_score": 9, "left_complexity": 8, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_415", "reponame": "stellargraph", "testpath": "tests/data/test_metapath_walker.py", "testname": "test_metapath_walker.py", "classname": "TestMetaPathWalk", "funcname": "test_walk_generation_single_root_node", "imports": ["import pandas as pd", "import numpy as np", "import pytest", "from stellargraph.data.explorer import UniformRandomMetaPathWalk", "from stellargraph.core.graph import StellarGraph", "from ..test_utils.graphs import example_graph_random"], "code": "def test_walk_generation_single_root_node(self):\n    g = create_test_graph()\n    mrw = UniformRandomMetaPathWalk(g)\n    nodes = ['0']\n    n = 1\n    length = 15\n    metapaths = [['s', 'n', 'n', 's']]\n    seed = 42\n    walks = mrw.run(nodes=nodes, n=n, length=length, metapaths=metapaths, seed=seed)\n    assert (len(walks) == n)\n    assert (len(walks[0]) <= length)\n    n = 5\n    walks = mrw.run(nodes=nodes, n=n, length=length, metapaths=metapaths, seed=seed)\n    assert (len(walks) == n)\n    assert (len(walks[0]) <= length)\n    metapaths = [['s', 'n', 's'], ['s', 'n', 'n', 's']]\n    n = 1\n    walks = mrw.run(nodes=nodes, n=n, length=length, metapaths=metapaths, seed=seed)\n    assert (len(walks) == (n * len(metapaths)))\n    for walk in walks:\n        assert (len(walk) <= length)\n    metapaths = [['s', 'n', 's'], ['s', 'n', 'n', 's']]\n    n = 5\n    length = 100\n    walks = mrw.run(nodes=nodes, n=n, length=length, metapaths=metapaths, seed=seed)\n    assert (len(walks) == (n * len(metapaths)))\n    for walk in walks:\n        assert (len(walk) <= length)\n    nodes = [8]\n    metapaths = [['s', 'n', 's'], ['s', 'n', 'n', 's']]\n    n = 5\n    length = 100\n    walks = mrw.run(nodes=nodes, n=n, length=length, metapaths=metapaths, seed=seed)\n    assert (len(walks) == 0)", "masked_code": "def test_walk_generation_single_root_node(self):\n    g = create_test_graph()\n    mrw = UniformRandomMetaPathWalk(g)\n    nodes = ['0']\n    n = 1\n    length = 15\n    metapaths = [['s', 'n', 'n', 's']]\n    seed = 42\n    walks = mrw.run(nodes=nodes, n=n, length=length, metapaths=metapaths, seed=seed)\n    assert (len(walks) == '???')\n    assert (len(walks[0]) <= length)\n    n = 5\n    walks = mrw.run(nodes=nodes, n=n, length=length, metapaths=metapaths, seed=seed)\n    assert (len(walks) == n)\n    assert (len(walks[0]) <= length)\n    metapaths = [['s', 'n', 's'], ['s', 'n', 'n', 's']]\n    n = 1\n    walks = mrw.run(nodes=nodes, n=n, length=length, metapaths=metapaths, seed=seed)\n    assert (len(walks) == (n * len(metapaths)))\n    for walk in walks:\n        assert (len(walk) <= length)\n    metapaths = [['s', 'n', 's'], ['s', 'n', 'n', 's']]\n    n = 5\n    length = 100\n    walks = mrw.run(nodes=nodes, n=n, length=length, metapaths=metapaths, seed=seed)\n    assert (len(walks) == (n * len(metapaths)))\n    for walk in walks:\n        assert (len(walk) <= length)\n    nodes = [8]\n    metapaths = [['s', 'n', 's'], ['s', 'n', 'n', 's']]\n    n = 5\n    length = 100\n    walks = mrw.run(nodes=nodes, n=n, length=length, metapaths=metapaths, seed=seed)\n    assert (len(walks) == 0)", "ground_truth": "n", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_416", "reponame": "stellargraph", "testpath": "tests/data/test_metapath_walker.py", "testname": "test_metapath_walker.py", "classname": "TestMetaPathWalk", "funcname": "test_walk_generation_single_root_node", "imports": ["import pandas as pd", "import numpy as np", "import pytest", "from stellargraph.data.explorer import UniformRandomMetaPathWalk", "from stellargraph.core.graph import StellarGraph", "from ..test_utils.graphs import example_graph_random"], "code": "def test_walk_generation_single_root_node(self):\n    g = create_test_graph()\n    mrw = UniformRandomMetaPathWalk(g)\n    nodes = ['0']\n    n = 1\n    length = 15\n    metapaths = [['s', 'n', 'n', 's']]\n    seed = 42\n    walks = mrw.run(nodes=nodes, n=n, length=length, metapaths=metapaths, seed=seed)\n    assert (len(walks) == n)\n    assert (len(walks[0]) <= length)\n    n = 5\n    walks = mrw.run(nodes=nodes, n=n, length=length, metapaths=metapaths, seed=seed)\n    assert (len(walks) == n)\n    assert (len(walks[0]) <= length)\n    metapaths = [['s', 'n', 's'], ['s', 'n', 'n', 's']]\n    n = 1\n    walks = mrw.run(nodes=nodes, n=n, length=length, metapaths=metapaths, seed=seed)\n    assert (len(walks) == (n * len(metapaths)))\n    for walk in walks:\n        assert (len(walk) <= length)\n    metapaths = [['s', 'n', 's'], ['s', 'n', 'n', 's']]\n    n = 5\n    length = 100\n    walks = mrw.run(nodes=nodes, n=n, length=length, metapaths=metapaths, seed=seed)\n    assert (len(walks) == (n * len(metapaths)))\n    for walk in walks:\n        assert (len(walk) <= length)\n    nodes = [8]\n    metapaths = [['s', 'n', 's'], ['s', 'n', 'n', 's']]\n    n = 5\n    length = 100\n    walks = mrw.run(nodes=nodes, n=n, length=length, metapaths=metapaths, seed=seed)\n    assert (len(walks) == 0)", "masked_code": "def test_walk_generation_single_root_node(self):\n    g = create_test_graph()\n    mrw = UniformRandomMetaPathWalk(g)\n    nodes = ['0']\n    n = 1\n    length = 15\n    metapaths = [['s', 'n', 'n', 's']]\n    seed = 42\n    walks = mrw.run(nodes=nodes, n=n, length=length, metapaths=metapaths, seed=seed)\n    assert (len(walks) == n)\n    assert (len(walks[0]) <= length)\n    n = 5\n    walks = mrw.run(nodes=nodes, n=n, length=length, metapaths=metapaths, seed=seed)\n    assert (len(walks) == '???')\n    assert (len(walks[0]) <= length)\n    metapaths = [['s', 'n', 's'], ['s', 'n', 'n', 's']]\n    n = 1\n    walks = mrw.run(nodes=nodes, n=n, length=length, metapaths=metapaths, seed=seed)\n    assert (len(walks) == (n * len(metapaths)))\n    for walk in walks:\n        assert (len(walk) <= length)\n    metapaths = [['s', 'n', 's'], ['s', 'n', 'n', 's']]\n    n = 5\n    length = 100\n    walks = mrw.run(nodes=nodes, n=n, length=length, metapaths=metapaths, seed=seed)\n    assert (len(walks) == (n * len(metapaths)))\n    for walk in walks:\n        assert (len(walk) <= length)\n    nodes = [8]\n    metapaths = [['s', 'n', 's'], ['s', 'n', 'n', 's']]\n    n = 5\n    length = 100\n    walks = mrw.run(nodes=nodes, n=n, length=length, metapaths=metapaths, seed=seed)\n    assert (len(walks) == 0)", "ground_truth": "n", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_417", "reponame": "stellargraph", "testpath": "tests/data/test_metapath_walker.py", "testname": "test_metapath_walker.py", "classname": "TestMetaPathWalk", "funcname": "test_walk_generation_single_root_node", "imports": ["import pandas as pd", "import numpy as np", "import pytest", "from stellargraph.data.explorer import UniformRandomMetaPathWalk", "from stellargraph.core.graph import StellarGraph", "from ..test_utils.graphs import example_graph_random"], "code": "def test_walk_generation_single_root_node(self):\n    g = create_test_graph()\n    mrw = UniformRandomMetaPathWalk(g)\n    nodes = ['0']\n    n = 1\n    length = 15\n    metapaths = [['s', 'n', 'n', 's']]\n    seed = 42\n    walks = mrw.run(nodes=nodes, n=n, length=length, metapaths=metapaths, seed=seed)\n    assert (len(walks) == n)\n    assert (len(walks[0]) <= length)\n    n = 5\n    walks = mrw.run(nodes=nodes, n=n, length=length, metapaths=metapaths, seed=seed)\n    assert (len(walks) == n)\n    assert (len(walks[0]) <= length)\n    metapaths = [['s', 'n', 's'], ['s', 'n', 'n', 's']]\n    n = 1\n    walks = mrw.run(nodes=nodes, n=n, length=length, metapaths=metapaths, seed=seed)\n    assert (len(walks) == (n * len(metapaths)))\n    for walk in walks:\n        assert (len(walk) <= length)\n    metapaths = [['s', 'n', 's'], ['s', 'n', 'n', 's']]\n    n = 5\n    length = 100\n    walks = mrw.run(nodes=nodes, n=n, length=length, metapaths=metapaths, seed=seed)\n    assert (len(walks) == (n * len(metapaths)))\n    for walk in walks:\n        assert (len(walk) <= length)\n    nodes = [8]\n    metapaths = [['s', 'n', 's'], ['s', 'n', 'n', 's']]\n    n = 5\n    length = 100\n    walks = mrw.run(nodes=nodes, n=n, length=length, metapaths=metapaths, seed=seed)\n    assert (len(walks) == 0)", "masked_code": "def test_walk_generation_single_root_node(self):\n    g = create_test_graph()\n    mrw = UniformRandomMetaPathWalk(g)\n    nodes = ['0']\n    n = 1\n    length = 15\n    metapaths = [['s', 'n', 'n', 's']]\n    seed = 42\n    walks = mrw.run(nodes=nodes, n=n, length=length, metapaths=metapaths, seed=seed)\n    assert (len(walks) == n)\n    assert (len(walks[0]) <= length)\n    n = 5\n    walks = mrw.run(nodes=nodes, n=n, length=length, metapaths=metapaths, seed=seed)\n    assert (len(walks) == n)\n    assert (len(walks[0]) <= length)\n    metapaths = [['s', 'n', 's'], ['s', 'n', 'n', 's']]\n    n = 1\n    walks = mrw.run(nodes=nodes, n=n, length=length, metapaths=metapaths, seed=seed)\n    assert (len(walks) == '???')\n    for walk in walks:\n        assert (len(walk) <= length)\n    metapaths = [['s', 'n', 's'], ['s', 'n', 'n', 's']]\n    n = 5\n    length = 100\n    walks = mrw.run(nodes=nodes, n=n, length=length, metapaths=metapaths, seed=seed)\n    assert (len(walks) == (n * len(metapaths)))\n    for walk in walks:\n        assert (len(walk) <= length)\n    nodes = [8]\n    metapaths = [['s', 'n', 's'], ['s', 'n', 'n', 's']]\n    n = 5\n    length = 100\n    walks = mrw.run(nodes=nodes, n=n, length=length, metapaths=metapaths, seed=seed)\n    assert (len(walks) == 0)", "ground_truth": "(n * len(metapaths))", "quality_analysis": {"complexity_score": 11, "left_complexity": 4, "right_complexity": 7, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_418", "reponame": "stellargraph", "testpath": "tests/data/test_metapath_walker.py", "testname": "test_metapath_walker.py", "classname": "TestMetaPathWalk", "funcname": "test_walk_generation_single_root_node", "imports": ["import pandas as pd", "import numpy as np", "import pytest", "from stellargraph.data.explorer import UniformRandomMetaPathWalk", "from stellargraph.core.graph import StellarGraph", "from ..test_utils.graphs import example_graph_random"], "code": "def test_walk_generation_single_root_node(self):\n    g = create_test_graph()\n    mrw = UniformRandomMetaPathWalk(g)\n    nodes = ['0']\n    n = 1\n    length = 15\n    metapaths = [['s', 'n', 'n', 's']]\n    seed = 42\n    walks = mrw.run(nodes=nodes, n=n, length=length, metapaths=metapaths, seed=seed)\n    assert (len(walks) == n)\n    assert (len(walks[0]) <= length)\n    n = 5\n    walks = mrw.run(nodes=nodes, n=n, length=length, metapaths=metapaths, seed=seed)\n    assert (len(walks) == n)\n    assert (len(walks[0]) <= length)\n    metapaths = [['s', 'n', 's'], ['s', 'n', 'n', 's']]\n    n = 1\n    walks = mrw.run(nodes=nodes, n=n, length=length, metapaths=metapaths, seed=seed)\n    assert (len(walks) == (n * len(metapaths)))\n    for walk in walks:\n        assert (len(walk) <= length)\n    metapaths = [['s', 'n', 's'], ['s', 'n', 'n', 's']]\n    n = 5\n    length = 100\n    walks = mrw.run(nodes=nodes, n=n, length=length, metapaths=metapaths, seed=seed)\n    assert (len(walks) == (n * len(metapaths)))\n    for walk in walks:\n        assert (len(walk) <= length)\n    nodes = [8]\n    metapaths = [['s', 'n', 's'], ['s', 'n', 'n', 's']]\n    n = 5\n    length = 100\n    walks = mrw.run(nodes=nodes, n=n, length=length, metapaths=metapaths, seed=seed)\n    assert (len(walks) == 0)", "masked_code": "def test_walk_generation_single_root_node(self):\n    g = create_test_graph()\n    mrw = UniformRandomMetaPathWalk(g)\n    nodes = ['0']\n    n = 1\n    length = 15\n    metapaths = [['s', 'n', 'n', 's']]\n    seed = 42\n    walks = mrw.run(nodes=nodes, n=n, length=length, metapaths=metapaths, seed=seed)\n    assert (len(walks) == n)\n    assert (len(walks[0]) <= length)\n    n = 5\n    walks = mrw.run(nodes=nodes, n=n, length=length, metapaths=metapaths, seed=seed)\n    assert (len(walks) == n)\n    assert (len(walks[0]) <= length)\n    metapaths = [['s', 'n', 's'], ['s', 'n', 'n', 's']]\n    n = 1\n    walks = mrw.run(nodes=nodes, n=n, length=length, metapaths=metapaths, seed=seed)\n    assert (len(walks) == (n * len(metapaths)))\n    for walk in walks:\n        assert (len(walk) <= length)\n    metapaths = [['s', 'n', 's'], ['s', 'n', 'n', 's']]\n    n = 5\n    length = 100\n    walks = mrw.run(nodes=nodes, n=n, length=length, metapaths=metapaths, seed=seed)\n    assert (len(walks) == '???')\n    for walk in walks:\n        assert (len(walk) <= length)\n    nodes = [8]\n    metapaths = [['s', 'n', 's'], ['s', 'n', 'n', 's']]\n    n = 5\n    length = 100\n    walks = mrw.run(nodes=nodes, n=n, length=length, metapaths=metapaths, seed=seed)\n    assert (len(walks) == 0)", "ground_truth": "(n * len(metapaths))", "quality_analysis": {"complexity_score": 11, "left_complexity": 4, "right_complexity": 7, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_419", "reponame": "stellargraph", "testpath": "tests/data/test_metapath_walker.py", "testname": "test_metapath_walker.py", "classname": "TestMetaPathWalk", "funcname": "test_walk_generation_many_root_nodes", "imports": ["import pandas as pd", "import numpy as np", "import pytest", "from stellargraph.data.explorer import UniformRandomMetaPathWalk", "from stellargraph.core.graph import StellarGraph", "from ..test_utils.graphs import example_graph_random"], "code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph()\n    mrw = UniformRandomMetaPathWalk(g)\n    nodes = ['0', 2]\n    n = 1\n    length = 15\n    metapaths = [['s', 'n', 'n', 's']]\n    seed = 42\n    walks = mrw.run(nodes=nodes, n=n, length=length, metapaths=metapaths, seed=seed)\n    assert (len(walks) == 1)\n    assert (len(walks[0]) <= length)\n    metapaths = [['s', 'n', 'n', 's'], ['n', 'n', 's', 'n']]\n    walks = mrw.run(nodes=nodes, n=n, length=length, metapaths=metapaths, seed=seed)\n    assert (len(walks) == 2)\n    for walk in walks:\n        assert (len(walk) <= length)\n    n = 2\n    nodes = ['0', '5']\n    metapaths = [['s', 'n', 'n', 's']]\n    walks = mrw.run(nodes=nodes, n=n, length=length, metapaths=metapaths, seed=seed)\n    assert (len(walks) == (n * len(nodes)))\n    for walk in walks:\n        assert (len(walk) <= length)\n    n = 2\n    nodes = ['0', '5', 1, 6]\n    metapaths = [['s', 'n', 'n', 's']]\n    walks = mrw.run(nodes=nodes, n=n, length=length, metapaths=metapaths, seed=seed)\n    assert (len(walks) == (n * 2))\n    for walk in walks:\n        assert (len(walk) <= length)\n    n = 5\n    nodes = ['0', '5', 1, 6]\n    metapaths = [['s', 'n', 'n', 's'], ['n', 's', 'n'], ['n', 'n']]\n    walks = mrw.run(nodes=nodes, n=n, length=length, metapaths=metapaths, seed=seed)\n    assert (len(walks) == (n * 6))\n    for walk in walks:\n        assert (len(walk) <= length)", "masked_code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph()\n    mrw = UniformRandomMetaPathWalk(g)\n    nodes = ['0', 2]\n    n = 1\n    length = 15\n    metapaths = [['s', 'n', 'n', 's']]\n    seed = 42\n    walks = mrw.run(nodes=nodes, n=n, length=length, metapaths=metapaths, seed=seed)\n    assert (len(walks) == 1)\n    assert (len(walks[0]) <= length)\n    metapaths = [['s', 'n', 'n', 's'], ['n', 'n', 's', 'n']]\n    walks = mrw.run(nodes=nodes, n=n, length=length, metapaths=metapaths, seed=seed)\n    assert (len(walks) == 2)\n    for walk in walks:\n        assert (len(walk) <= length)\n    n = 2\n    nodes = ['0', '5']\n    metapaths = [['s', 'n', 'n', 's']]\n    walks = mrw.run(nodes=nodes, n=n, length=length, metapaths=metapaths, seed=seed)\n    assert (len(walks) == '???')\n    for walk in walks:\n        assert (len(walk) <= length)\n    n = 2\n    nodes = ['0', '5', 1, 6]\n    metapaths = [['s', 'n', 'n', 's']]\n    walks = mrw.run(nodes=nodes, n=n, length=length, metapaths=metapaths, seed=seed)\n    assert (len(walks) == (n * 2))\n    for walk in walks:\n        assert (len(walk) <= length)\n    n = 5\n    nodes = ['0', '5', 1, 6]\n    metapaths = [['s', 'n', 'n', 's'], ['n', 's', 'n'], ['n', 'n']]\n    walks = mrw.run(nodes=nodes, n=n, length=length, metapaths=metapaths, seed=seed)\n    assert (len(walks) == (n * 6))\n    for walk in walks:\n        assert (len(walk) <= length)", "ground_truth": "(n * len(nodes))", "quality_analysis": {"complexity_score": 11, "left_complexity": 4, "right_complexity": 7, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_420", "reponame": "stellargraph", "testpath": "tests/data/test_metapath_walker.py", "testname": "test_metapath_walker.py", "classname": "TestMetaPathWalk", "funcname": "test_walk_generation_many_root_nodes", "imports": ["import pandas as pd", "import numpy as np", "import pytest", "from stellargraph.data.explorer import UniformRandomMetaPathWalk", "from stellargraph.core.graph import StellarGraph", "from ..test_utils.graphs import example_graph_random"], "code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph()\n    mrw = UniformRandomMetaPathWalk(g)\n    nodes = ['0', 2]\n    n = 1\n    length = 15\n    metapaths = [['s', 'n', 'n', 's']]\n    seed = 42\n    walks = mrw.run(nodes=nodes, n=n, length=length, metapaths=metapaths, seed=seed)\n    assert (len(walks) == 1)\n    assert (len(walks[0]) <= length)\n    metapaths = [['s', 'n', 'n', 's'], ['n', 'n', 's', 'n']]\n    walks = mrw.run(nodes=nodes, n=n, length=length, metapaths=metapaths, seed=seed)\n    assert (len(walks) == 2)\n    for walk in walks:\n        assert (len(walk) <= length)\n    n = 2\n    nodes = ['0', '5']\n    metapaths = [['s', 'n', 'n', 's']]\n    walks = mrw.run(nodes=nodes, n=n, length=length, metapaths=metapaths, seed=seed)\n    assert (len(walks) == (n * len(nodes)))\n    for walk in walks:\n        assert (len(walk) <= length)\n    n = 2\n    nodes = ['0', '5', 1, 6]\n    metapaths = [['s', 'n', 'n', 's']]\n    walks = mrw.run(nodes=nodes, n=n, length=length, metapaths=metapaths, seed=seed)\n    assert (len(walks) == (n * 2))\n    for walk in walks:\n        assert (len(walk) <= length)\n    n = 5\n    nodes = ['0', '5', 1, 6]\n    metapaths = [['s', 'n', 'n', 's'], ['n', 's', 'n'], ['n', 'n']]\n    walks = mrw.run(nodes=nodes, n=n, length=length, metapaths=metapaths, seed=seed)\n    assert (len(walks) == (n * 6))\n    for walk in walks:\n        assert (len(walk) <= length)", "masked_code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph()\n    mrw = UniformRandomMetaPathWalk(g)\n    nodes = ['0', 2]\n    n = 1\n    length = 15\n    metapaths = [['s', 'n', 'n', 's']]\n    seed = 42\n    walks = mrw.run(nodes=nodes, n=n, length=length, metapaths=metapaths, seed=seed)\n    assert (len(walks) == 1)\n    assert (len(walks[0]) <= length)\n    metapaths = [['s', 'n', 'n', 's'], ['n', 'n', 's', 'n']]\n    walks = mrw.run(nodes=nodes, n=n, length=length, metapaths=metapaths, seed=seed)\n    assert (len(walks) == 2)\n    for walk in walks:\n        assert (len(walk) <= length)\n    n = 2\n    nodes = ['0', '5']\n    metapaths = [['s', 'n', 'n', 's']]\n    walks = mrw.run(nodes=nodes, n=n, length=length, metapaths=metapaths, seed=seed)\n    assert (len(walks) == (n * len(nodes)))\n    for walk in walks:\n        assert (len(walk) <= length)\n    n = 2\n    nodes = ['0', '5', 1, 6]\n    metapaths = [['s', 'n', 'n', 's']]\n    walks = mrw.run(nodes=nodes, n=n, length=length, metapaths=metapaths, seed=seed)\n    assert (len(walks) == '???')\n    for walk in walks:\n        assert (len(walk) <= length)\n    n = 5\n    nodes = ['0', '5', 1, 6]\n    metapaths = [['s', 'n', 'n', 's'], ['n', 's', 'n'], ['n', 'n']]\n    walks = mrw.run(nodes=nodes, n=n, length=length, metapaths=metapaths, seed=seed)\n    assert (len(walks) == (n * 6))\n    for walk in walks:\n        assert (len(walk) <= length)", "ground_truth": "(n * 2)", "quality_analysis": {"complexity_score": 8, "left_complexity": 4, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_421", "reponame": "stellargraph", "testpath": "tests/data/test_metapath_walker.py", "testname": "test_metapath_walker.py", "classname": "TestMetaPathWalk", "funcname": "test_walk_generation_many_root_nodes", "imports": ["import pandas as pd", "import numpy as np", "import pytest", "from stellargraph.data.explorer import UniformRandomMetaPathWalk", "from stellargraph.core.graph import StellarGraph", "from ..test_utils.graphs import example_graph_random"], "code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph()\n    mrw = UniformRandomMetaPathWalk(g)\n    nodes = ['0', 2]\n    n = 1\n    length = 15\n    metapaths = [['s', 'n', 'n', 's']]\n    seed = 42\n    walks = mrw.run(nodes=nodes, n=n, length=length, metapaths=metapaths, seed=seed)\n    assert (len(walks) == 1)\n    assert (len(walks[0]) <= length)\n    metapaths = [['s', 'n', 'n', 's'], ['n', 'n', 's', 'n']]\n    walks = mrw.run(nodes=nodes, n=n, length=length, metapaths=metapaths, seed=seed)\n    assert (len(walks) == 2)\n    for walk in walks:\n        assert (len(walk) <= length)\n    n = 2\n    nodes = ['0', '5']\n    metapaths = [['s', 'n', 'n', 's']]\n    walks = mrw.run(nodes=nodes, n=n, length=length, metapaths=metapaths, seed=seed)\n    assert (len(walks) == (n * len(nodes)))\n    for walk in walks:\n        assert (len(walk) <= length)\n    n = 2\n    nodes = ['0', '5', 1, 6]\n    metapaths = [['s', 'n', 'n', 's']]\n    walks = mrw.run(nodes=nodes, n=n, length=length, metapaths=metapaths, seed=seed)\n    assert (len(walks) == (n * 2))\n    for walk in walks:\n        assert (len(walk) <= length)\n    n = 5\n    nodes = ['0', '5', 1, 6]\n    metapaths = [['s', 'n', 'n', 's'], ['n', 's', 'n'], ['n', 'n']]\n    walks = mrw.run(nodes=nodes, n=n, length=length, metapaths=metapaths, seed=seed)\n    assert (len(walks) == (n * 6))\n    for walk in walks:\n        assert (len(walk) <= length)", "masked_code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph()\n    mrw = UniformRandomMetaPathWalk(g)\n    nodes = ['0', 2]\n    n = 1\n    length = 15\n    metapaths = [['s', 'n', 'n', 's']]\n    seed = 42\n    walks = mrw.run(nodes=nodes, n=n, length=length, metapaths=metapaths, seed=seed)\n    assert (len(walks) == 1)\n    assert (len(walks[0]) <= length)\n    metapaths = [['s', 'n', 'n', 's'], ['n', 'n', 's', 'n']]\n    walks = mrw.run(nodes=nodes, n=n, length=length, metapaths=metapaths, seed=seed)\n    assert (len(walks) == 2)\n    for walk in walks:\n        assert (len(walk) <= length)\n    n = 2\n    nodes = ['0', '5']\n    metapaths = [['s', 'n', 'n', 's']]\n    walks = mrw.run(nodes=nodes, n=n, length=length, metapaths=metapaths, seed=seed)\n    assert (len(walks) == (n * len(nodes)))\n    for walk in walks:\n        assert (len(walk) <= length)\n    n = 2\n    nodes = ['0', '5', 1, 6]\n    metapaths = [['s', 'n', 'n', 's']]\n    walks = mrw.run(nodes=nodes, n=n, length=length, metapaths=metapaths, seed=seed)\n    assert (len(walks) == (n * 2))\n    for walk in walks:\n        assert (len(walk) <= length)\n    n = 5\n    nodes = ['0', '5', 1, 6]\n    metapaths = [['s', 'n', 'n', 's'], ['n', 's', 'n'], ['n', 'n']]\n    walks = mrw.run(nodes=nodes, n=n, length=length, metapaths=metapaths, seed=seed)\n    assert (len(walks) == '???')\n    for walk in walks:\n        assert (len(walk) <= length)", "ground_truth": "(n * 6)", "quality_analysis": {"complexity_score": 8, "left_complexity": 4, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_422", "reponame": "stellargraph", "testpath": "tests/data/test_metapath_walker.py", "testname": "test_metapath_walker.py", "classname": "TestMetaPathWalk", "funcname": "test_init_parameters", "imports": ["import pandas as pd", "import numpy as np", "import pytest", "from stellargraph.data.explorer import UniformRandomMetaPathWalk", "from stellargraph.core.graph import StellarGraph", "from ..test_utils.graphs import example_graph_random"], "code": "def test_init_parameters(self):\n    g = create_test_graph()\n    n = 2\n    length = 15\n    metapaths = [['s', 'n', 'n', 's']]\n    seed = 42\n    nodes = ['0', '5']\n    mrw = UniformRandomMetaPathWalk(g, n=n, length=length, metapaths=metapaths, seed=seed)\n    mrw_no_params = UniformRandomMetaPathWalk(g)\n    run_1 = mrw.run(nodes=nodes)\n    run_2 = mrw_no_params.run(nodes=nodes, n=n, length=length, metapaths=metapaths, seed=seed)\n    assert (len(run_1) == len(run_2))\n    for (w1, w2) in zip(run_1, run_2):\n        np.testing.assert_array_equal(w1, w2)", "masked_code": "def test_init_parameters(self):\n    g = create_test_graph()\n    n = 2\n    length = 15\n    metapaths = [['s', 'n', 'n', 's']]\n    seed = 42\n    nodes = ['0', '5']\n    mrw = UniformRandomMetaPathWalk(g, n=n, length=length, metapaths=metapaths, seed=seed)\n    mrw_no_params = UniformRandomMetaPathWalk(g)\n    run_1 = mrw.run(nodes=nodes)\n    run_2 = mrw_no_params.run(nodes=nodes, n=n, length=length, metapaths=metapaths, seed=seed)\n    assert (len(run_1) == '???')\n    for (w1, w2) in zip(run_1, run_2):\n        np.testing.assert_array_equal(w1, w2)", "ground_truth": "len(run_2)", "quality_analysis": {"complexity_score": 8, "left_complexity": 4, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_423", "reponame": "stellargraph", "testpath": "tests/data/test_temporal_random_walker.py", "testname": "test_temporal_random_walker.py", "classname": null, "funcname": "test_exp_biases_extreme", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "import networkx as nx", "from stellargraph.data.explorer import TemporalRandomWalk", "from stellargraph.core.graph import StellarGraph"], "code": "def test_exp_biases_extreme(temporal_graph):\n    rw = TemporalRandomWalk(temporal_graph)\n    large_times = [100000, 100001]\n    biases = rw._exp_biases(large_times, t_0=0, decay=True)\n    assert (sum(biases) == pytest.approx(1))\n    small_times = [1e-06, 2e-06]\n    biases = rw._exp_biases(small_times, t_0=0, decay=True)\n    assert (sum(biases) == pytest.approx(1))", "masked_code": "def test_exp_biases_extreme(temporal_graph):\n    rw = TemporalRandomWalk(temporal_graph)\n    large_times = [100000, 100001]\n    biases = rw._exp_biases(large_times, t_0=0, decay=True)\n    assert (sum(biases) == '???')\n    small_times = [1e-06, 2e-06]\n    biases = rw._exp_biases(small_times, t_0=0, decay=True)\n    assert (sum(biases) == pytest.approx(1))", "ground_truth": "pytest.approx(1)", "quality_analysis": {"complexity_score": 8, "left_complexity": 4, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_424", "reponame": "stellargraph", "testpath": "tests/data/test_temporal_random_walker.py", "testname": "test_temporal_random_walker.py", "classname": null, "funcname": "test_exp_biases_extreme", "imports": ["import pandas as pd", "import pytest", "import numpy as np", "import networkx as nx", "from stellargraph.data.explorer import TemporalRandomWalk", "from stellargraph.core.graph import StellarGraph"], "code": "def test_exp_biases_extreme(temporal_graph):\n    rw = TemporalRandomWalk(temporal_graph)\n    large_times = [100000, 100001]\n    biases = rw._exp_biases(large_times, t_0=0, decay=True)\n    assert (sum(biases) == pytest.approx(1))\n    small_times = [1e-06, 2e-06]\n    biases = rw._exp_biases(small_times, t_0=0, decay=True)\n    assert (sum(biases) == pytest.approx(1))", "masked_code": "def test_exp_biases_extreme(temporal_graph):\n    rw = TemporalRandomWalk(temporal_graph)\n    large_times = [100000, 100001]\n    biases = rw._exp_biases(large_times, t_0=0, decay=True)\n    assert (sum(biases) == pytest.approx(1))\n    small_times = [1e-06, 2e-06]\n    biases = rw._exp_biases(small_times, t_0=0, decay=True)\n    assert (sum(biases) == '???')", "ground_truth": "pytest.approx(1)", "quality_analysis": {"complexity_score": 8, "left_complexity": 4, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_425", "reponame": "stellargraph", "testpath": "tests/data/test_uniform_random_walker.py", "testname": "test_uniform_random_walker.py", "classname": "TestUniformRandomWalk", "funcname": "test_walk_generation_single_root_node", "imports": ["import pytest", "import numpy as np", "from stellargraph.data.explorer import UniformRandomWalk", "from ..test_utils.graphs import create_test_graph, example_graph_random"], "code": "def test_walk_generation_single_root_node(self):\n    g = create_test_graph()\n    urw = UniformRandomWalk(g)\n    nodes = ['0']\n    n = 1\n    length = 1\n    seed = 42\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs[0]) == length)\n    length = 2\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n    length = 2\n    n = 2\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n    n = 3\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)", "masked_code": "def test_walk_generation_single_root_node(self):\n    g = create_test_graph()\n    urw = UniformRandomWalk(g)\n    nodes = ['0']\n    n = 1\n    length = 1\n    seed = 42\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs[0]) == '???')\n    length = 2\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n    length = 2\n    n = 2\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n    n = 3\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)", "ground_truth": "length", "quality_analysis": {"complexity_score": 9, "left_complexity": 8, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_426", "reponame": "stellargraph", "testpath": "tests/data/test_uniform_random_walker.py", "testname": "test_uniform_random_walker.py", "classname": "TestUniformRandomWalk", "funcname": "test_walk_generation_single_root_node", "imports": ["import pytest", "import numpy as np", "from stellargraph.data.explorer import UniformRandomWalk", "from ..test_utils.graphs import create_test_graph, example_graph_random"], "code": "def test_walk_generation_single_root_node(self):\n    g = create_test_graph()\n    urw = UniformRandomWalk(g)\n    nodes = ['0']\n    n = 1\n    length = 1\n    seed = 42\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs[0]) == length)\n    length = 2\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n    length = 2\n    n = 2\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n    n = 3\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)", "masked_code": "def test_walk_generation_single_root_node(self):\n    g = create_test_graph()\n    urw = UniformRandomWalk(g)\n    nodes = ['0']\n    n = 1\n    length = 1\n    seed = 42\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs[0]) == length)\n    length = 2\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n    length = 2\n    n = 2\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == '???')\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n    n = 3\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)", "ground_truth": "n", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_427", "reponame": "stellargraph", "testpath": "tests/data/test_uniform_random_walker.py", "testname": "test_uniform_random_walker.py", "classname": "TestUniformRandomWalk", "funcname": "test_walk_generation_single_root_node", "imports": ["import pytest", "import numpy as np", "from stellargraph.data.explorer import UniformRandomWalk", "from ..test_utils.graphs import create_test_graph, example_graph_random"], "code": "def test_walk_generation_single_root_node(self):\n    g = create_test_graph()\n    urw = UniformRandomWalk(g)\n    nodes = ['0']\n    n = 1\n    length = 1\n    seed = 42\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs[0]) == length)\n    length = 2\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n    length = 2\n    n = 2\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n    n = 3\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)", "masked_code": "def test_walk_generation_single_root_node(self):\n    g = create_test_graph()\n    urw = UniformRandomWalk(g)\n    nodes = ['0']\n    n = 1\n    length = 1\n    seed = 42\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs[0]) == length)\n    length = 2\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n    length = 2\n    n = 2\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n    n = 3\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == '???')\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)", "ground_truth": "n", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_428", "reponame": "stellargraph", "testpath": "tests/data/test_uniform_random_walker.py", "testname": "test_uniform_random_walker.py", "classname": "TestUniformRandomWalk", "funcname": "test_walk_generation_single_root_node", "imports": ["import pytest", "import numpy as np", "from stellargraph.data.explorer import UniformRandomWalk", "from ..test_utils.graphs import create_test_graph, example_graph_random"], "code": "def test_walk_generation_single_root_node(self):\n    g = create_test_graph()\n    urw = UniformRandomWalk(g)\n    nodes = ['0']\n    n = 1\n    length = 1\n    seed = 42\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs[0]) == length)\n    length = 2\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n    length = 2\n    n = 2\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n    n = 3\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)", "masked_code": "def test_walk_generation_single_root_node(self):\n    g = create_test_graph()\n    urw = UniformRandomWalk(g)\n    nodes = ['0']\n    n = 1\n    length = 1\n    seed = 42\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs[0]) == length)\n    length = 2\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == '???')\n    length = 2\n    n = 2\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n    n = 3\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)", "ground_truth": "length", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_429", "reponame": "stellargraph", "testpath": "tests/data/test_uniform_random_walker.py", "testname": "test_uniform_random_walker.py", "classname": "TestUniformRandomWalk", "funcname": "test_walk_generation_single_root_node", "imports": ["import pytest", "import numpy as np", "from stellargraph.data.explorer import UniformRandomWalk", "from ..test_utils.graphs import create_test_graph, example_graph_random"], "code": "def test_walk_generation_single_root_node(self):\n    g = create_test_graph()\n    urw = UniformRandomWalk(g)\n    nodes = ['0']\n    n = 1\n    length = 1\n    seed = 42\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs[0]) == length)\n    length = 2\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n    length = 2\n    n = 2\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n    n = 3\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)", "masked_code": "def test_walk_generation_single_root_node(self):\n    g = create_test_graph()\n    urw = UniformRandomWalk(g)\n    nodes = ['0']\n    n = 1\n    length = 1\n    seed = 42\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs[0]) == length)\n    length = 2\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n    length = 2\n    n = 2\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == '???')\n    n = 3\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)", "ground_truth": "length", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_430", "reponame": "stellargraph", "testpath": "tests/data/test_uniform_random_walker.py", "testname": "test_uniform_random_walker.py", "classname": "TestUniformRandomWalk", "funcname": "test_walk_generation_single_root_node", "imports": ["import pytest", "import numpy as np", "from stellargraph.data.explorer import UniformRandomWalk", "from ..test_utils.graphs import create_test_graph, example_graph_random"], "code": "def test_walk_generation_single_root_node(self):\n    g = create_test_graph()\n    urw = UniformRandomWalk(g)\n    nodes = ['0']\n    n = 1\n    length = 1\n    seed = 42\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs[0]) == length)\n    length = 2\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n    length = 2\n    n = 2\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n    n = 3\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)", "masked_code": "def test_walk_generation_single_root_node(self):\n    g = create_test_graph()\n    urw = UniformRandomWalk(g)\n    nodes = ['0']\n    n = 1\n    length = 1\n    seed = 42\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs[0]) == length)\n    length = 2\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n    length = 2\n    n = 2\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n    n = 3\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == '???')", "ground_truth": "length", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_431", "reponame": "stellargraph", "testpath": "tests/data/test_uniform_random_walker.py", "testname": "test_uniform_random_walker.py", "classname": "TestUniformRandomWalk", "funcname": "test_walk_generation_many_root_nodes", "imports": ["import pytest", "import numpy as np", "from stellargraph.data.explorer import UniformRandomWalk", "from ..test_utils.graphs import create_test_graph, example_graph_random"], "code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph()\n    urw = UniformRandomWalk(g)\n    nodes = ['0', 2]\n    n = 1\n    length = 1\n    seed = None\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == length)\n        assert (subgraph[0] == nodes[i])\n    length = 2\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)\n    n = 2\n    length = 2\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)\n    length = 3\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)\n    n = 5\n    length = 10\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)", "masked_code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph()\n    urw = UniformRandomWalk(g)\n    nodes = ['0', 2]\n    n = 1\n    length = 1\n    seed = None\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == '???')\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == length)\n        assert (subgraph[0] == nodes[i])\n    length = 2\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)\n    n = 2\n    length = 2\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)\n    length = 3\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)\n    n = 5\n    length = 10\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)", "ground_truth": "(n * len(nodes))", "quality_analysis": {"complexity_score": 11, "left_complexity": 4, "right_complexity": 7, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_432", "reponame": "stellargraph", "testpath": "tests/data/test_uniform_random_walker.py", "testname": "test_uniform_random_walker.py", "classname": "TestUniformRandomWalk", "funcname": "test_walk_generation_many_root_nodes", "imports": ["import pytest", "import numpy as np", "from stellargraph.data.explorer import UniformRandomWalk", "from ..test_utils.graphs import create_test_graph, example_graph_random"], "code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph()\n    urw = UniformRandomWalk(g)\n    nodes = ['0', 2]\n    n = 1\n    length = 1\n    seed = None\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == length)\n        assert (subgraph[0] == nodes[i])\n    length = 2\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)\n    n = 2\n    length = 2\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)\n    length = 3\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)\n    n = 5\n    length = 10\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)", "masked_code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph()\n    urw = UniformRandomWalk(g)\n    nodes = ['0', 2]\n    n = 1\n    length = 1\n    seed = None\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == length)\n        assert (subgraph[0] == nodes[i])\n    length = 2\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == '???')\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)\n    n = 2\n    length = 2\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)\n    length = 3\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)\n    n = 5\n    length = 10\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)", "ground_truth": "(n * len(nodes))", "quality_analysis": {"complexity_score": 11, "left_complexity": 4, "right_complexity": 7, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_433", "reponame": "stellargraph", "testpath": "tests/data/test_uniform_random_walker.py", "testname": "test_uniform_random_walker.py", "classname": "TestUniformRandomWalk", "funcname": "test_walk_generation_many_root_nodes", "imports": ["import pytest", "import numpy as np", "from stellargraph.data.explorer import UniformRandomWalk", "from ..test_utils.graphs import create_test_graph, example_graph_random"], "code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph()\n    urw = UniformRandomWalk(g)\n    nodes = ['0', 2]\n    n = 1\n    length = 1\n    seed = None\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == length)\n        assert (subgraph[0] == nodes[i])\n    length = 2\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)\n    n = 2\n    length = 2\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)\n    length = 3\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)\n    n = 5\n    length = 10\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)", "masked_code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph()\n    urw = UniformRandomWalk(g)\n    nodes = ['0', 2]\n    n = 1\n    length = 1\n    seed = None\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == length)\n        assert (subgraph[0] == nodes[i])\n    length = 2\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)\n    n = 2\n    length = 2\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == '???')\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)\n    length = 3\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)\n    n = 5\n    length = 10\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)", "ground_truth": "(n * len(nodes))", "quality_analysis": {"complexity_score": 11, "left_complexity": 4, "right_complexity": 7, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_434", "reponame": "stellargraph", "testpath": "tests/data/test_uniform_random_walker.py", "testname": "test_uniform_random_walker.py", "classname": "TestUniformRandomWalk", "funcname": "test_walk_generation_many_root_nodes", "imports": ["import pytest", "import numpy as np", "from stellargraph.data.explorer import UniformRandomWalk", "from ..test_utils.graphs import create_test_graph, example_graph_random"], "code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph()\n    urw = UniformRandomWalk(g)\n    nodes = ['0', 2]\n    n = 1\n    length = 1\n    seed = None\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == length)\n        assert (subgraph[0] == nodes[i])\n    length = 2\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)\n    n = 2\n    length = 2\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)\n    length = 3\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)\n    n = 5\n    length = 10\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)", "masked_code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph()\n    urw = UniformRandomWalk(g)\n    nodes = ['0', 2]\n    n = 1\n    length = 1\n    seed = None\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == length)\n        assert (subgraph[0] == nodes[i])\n    length = 2\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)\n    n = 2\n    length = 2\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)\n    length = 3\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == '???')\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)\n    n = 5\n    length = 10\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)", "ground_truth": "(n * len(nodes))", "quality_analysis": {"complexity_score": 11, "left_complexity": 4, "right_complexity": 7, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_435", "reponame": "stellargraph", "testpath": "tests/data/test_uniform_random_walker.py", "testname": "test_uniform_random_walker.py", "classname": "TestUniformRandomWalk", "funcname": "test_walk_generation_many_root_nodes", "imports": ["import pytest", "import numpy as np", "from stellargraph.data.explorer import UniformRandomWalk", "from ..test_utils.graphs import create_test_graph, example_graph_random"], "code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph()\n    urw = UniformRandomWalk(g)\n    nodes = ['0', 2]\n    n = 1\n    length = 1\n    seed = None\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == length)\n        assert (subgraph[0] == nodes[i])\n    length = 2\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)\n    n = 2\n    length = 2\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)\n    length = 3\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)\n    n = 5\n    length = 10\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)", "masked_code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph()\n    urw = UniformRandomWalk(g)\n    nodes = ['0', 2]\n    n = 1\n    length = 1\n    seed = None\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == length)\n        assert (subgraph[0] == nodes[i])\n    length = 2\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)\n    n = 2\n    length = 2\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)\n    length = 3\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)\n    n = 5\n    length = 10\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == '???')\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)", "ground_truth": "(n * len(nodes))", "quality_analysis": {"complexity_score": 11, "left_complexity": 4, "right_complexity": 7, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_436", "reponame": "stellargraph", "testpath": "tests/data/test_uniform_random_walker.py", "testname": "test_uniform_random_walker.py", "classname": "TestUniformRandomWalk", "funcname": "test_walk_generation_many_root_nodes", "imports": ["import pytest", "import numpy as np", "from stellargraph.data.explorer import UniformRandomWalk", "from ..test_utils.graphs import create_test_graph, example_graph_random"], "code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph()\n    urw = UniformRandomWalk(g)\n    nodes = ['0', 2]\n    n = 1\n    length = 1\n    seed = None\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == length)\n        assert (subgraph[0] == nodes[i])\n    length = 2\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)\n    n = 2\n    length = 2\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)\n    length = 3\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)\n    n = 5\n    length = 10\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)", "masked_code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph()\n    urw = UniformRandomWalk(g)\n    nodes = ['0', 2]\n    n = 1\n    length = 1\n    seed = None\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == '???')\n        assert (subgraph[0] == nodes[i])\n    length = 2\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)\n    n = 2\n    length = 2\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)\n    length = 3\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)\n    n = 5\n    length = 10\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)", "ground_truth": "length", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_437", "reponame": "stellargraph", "testpath": "tests/data/test_uniform_random_walker.py", "testname": "test_uniform_random_walker.py", "classname": "TestUniformRandomWalk", "funcname": "test_walk_generation_many_root_nodes", "imports": ["import pytest", "import numpy as np", "from stellargraph.data.explorer import UniformRandomWalk", "from ..test_utils.graphs import create_test_graph, example_graph_random"], "code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph()\n    urw = UniformRandomWalk(g)\n    nodes = ['0', 2]\n    n = 1\n    length = 1\n    seed = None\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == length)\n        assert (subgraph[0] == nodes[i])\n    length = 2\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)\n    n = 2\n    length = 2\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)\n    length = 3\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)\n    n = 5\n    length = 10\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)", "masked_code": "def test_walk_generation_many_root_nodes(self):\n    g = create_test_graph()\n    urw = UniformRandomWalk(g)\n    nodes = ['0', 2]\n    n = 1\n    length = 1\n    seed = None\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for (i, subgraph) in enumerate(subgraphs):\n        assert (len(subgraph) == length)\n        assert (subgraph[0] == '???')\n    length = 2\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)\n    n = 2\n    length = 2\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)\n    length = 3\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)\n    n = 5\n    length = 10\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == (n * len(nodes)))\n    for subgraph in subgraphs:\n        assert (len(subgraph) <= length)", "ground_truth": "nodes[i]", "quality_analysis": {"complexity_score": 10, "left_complexity": 5, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_438", "reponame": "stellargraph", "testpath": "tests/data/test_uniform_random_walker.py", "testname": "test_uniform_random_walker.py", "classname": "TestUniformRandomWalk", "funcname": "test_walk_generation_loner_root_node", "imports": ["import pytest", "import numpy as np", "from stellargraph.data.explorer import UniformRandomWalk", "from ..test_utils.graphs import create_test_graph, example_graph_random"], "code": "def test_walk_generation_loner_root_node(self):\n    g = create_test_graph()\n    urw = UniformRandomWalk(g)\n    nodes = ['loner']\n    n = 1\n    length = 1\n    seed = None\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 1)\n    n = 10\n    length = 1\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n    n = 10\n    length = 10\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)", "masked_code": "def test_walk_generation_loner_root_node(self):\n    g = create_test_graph()\n    urw = UniformRandomWalk(g)\n    nodes = ['loner']\n    n = 1\n    length = 1\n    seed = None\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 1)\n    n = 10\n    length = 1\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == '???')\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n    n = 10\n    length = 10\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)", "ground_truth": "n", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_439", "reponame": "stellargraph", "testpath": "tests/data/test_uniform_random_walker.py", "testname": "test_uniform_random_walker.py", "classname": "TestUniformRandomWalk", "funcname": "test_walk_generation_loner_root_node", "imports": ["import pytest", "import numpy as np", "from stellargraph.data.explorer import UniformRandomWalk", "from ..test_utils.graphs import create_test_graph, example_graph_random"], "code": "def test_walk_generation_loner_root_node(self):\n    g = create_test_graph()\n    urw = UniformRandomWalk(g)\n    nodes = ['loner']\n    n = 1\n    length = 1\n    seed = None\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 1)\n    n = 10\n    length = 1\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n    n = 10\n    length = 10\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)", "masked_code": "def test_walk_generation_loner_root_node(self):\n    g = create_test_graph()\n    urw = UniformRandomWalk(g)\n    nodes = ['loner']\n    n = 1\n    length = 1\n    seed = None\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 1)\n    n = 10\n    length = 1\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)\n    n = 10\n    length = 10\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == '???')\n    for subgraph in subgraphs:\n        assert (len(subgraph) == 1)", "ground_truth": "n", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_440", "reponame": "stellargraph", "testpath": "tests/data/test_uniform_random_walker.py", "testname": "test_uniform_random_walker.py", "classname": "TestUniformRandomWalk", "funcname": "test_walk_generation_self_loner_root_node", "imports": ["import pytest", "import numpy as np", "from stellargraph.data.explorer import UniformRandomWalk", "from ..test_utils.graphs import create_test_graph, example_graph_random"], "code": "def test_walk_generation_self_loner_root_node(self):\n    g = create_test_graph()\n    urw = UniformRandomWalk(g)\n    nodes = ['self loner']\n    n = 1\n    length = 1\n    seed = None\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 1)\n    n = 10\n    length = 1\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n        for node in subgraph:\n            assert (node == 'self loner')\n    n = 1\n    length = 99\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n        for node in subgraph:\n            assert (node == 'self loner')\n    n = 10\n    length = 10\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n        for node in subgraph:\n            assert (node == 'self loner')", "masked_code": "def test_walk_generation_self_loner_root_node(self):\n    g = create_test_graph()\n    urw = UniformRandomWalk(g)\n    nodes = ['self loner']\n    n = 1\n    length = 1\n    seed = None\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 1)\n    n = 10\n    length = 1\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == '???')\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n        for node in subgraph:\n            assert (node == 'self loner')\n    n = 1\n    length = 99\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n        for node in subgraph:\n            assert (node == 'self loner')\n    n = 10\n    length = 10\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n        for node in subgraph:\n            assert (node == 'self loner')", "ground_truth": "n", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_441", "reponame": "stellargraph", "testpath": "tests/data/test_uniform_random_walker.py", "testname": "test_uniform_random_walker.py", "classname": "TestUniformRandomWalk", "funcname": "test_walk_generation_self_loner_root_node", "imports": ["import pytest", "import numpy as np", "from stellargraph.data.explorer import UniformRandomWalk", "from ..test_utils.graphs import create_test_graph, example_graph_random"], "code": "def test_walk_generation_self_loner_root_node(self):\n    g = create_test_graph()\n    urw = UniformRandomWalk(g)\n    nodes = ['self loner']\n    n = 1\n    length = 1\n    seed = None\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 1)\n    n = 10\n    length = 1\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n        for node in subgraph:\n            assert (node == 'self loner')\n    n = 1\n    length = 99\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n        for node in subgraph:\n            assert (node == 'self loner')\n    n = 10\n    length = 10\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n        for node in subgraph:\n            assert (node == 'self loner')", "masked_code": "def test_walk_generation_self_loner_root_node(self):\n    g = create_test_graph()\n    urw = UniformRandomWalk(g)\n    nodes = ['self loner']\n    n = 1\n    length = 1\n    seed = None\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 1)\n    n = 10\n    length = 1\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n        for node in subgraph:\n            assert (node == 'self loner')\n    n = 1\n    length = 99\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == '???')\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n        for node in subgraph:\n            assert (node == 'self loner')\n    n = 10\n    length = 10\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n        for node in subgraph:\n            assert (node == 'self loner')", "ground_truth": "n", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_442", "reponame": "stellargraph", "testpath": "tests/data/test_uniform_random_walker.py", "testname": "test_uniform_random_walker.py", "classname": "TestUniformRandomWalk", "funcname": "test_walk_generation_self_loner_root_node", "imports": ["import pytest", "import numpy as np", "from stellargraph.data.explorer import UniformRandomWalk", "from ..test_utils.graphs import create_test_graph, example_graph_random"], "code": "def test_walk_generation_self_loner_root_node(self):\n    g = create_test_graph()\n    urw = UniformRandomWalk(g)\n    nodes = ['self loner']\n    n = 1\n    length = 1\n    seed = None\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 1)\n    n = 10\n    length = 1\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n        for node in subgraph:\n            assert (node == 'self loner')\n    n = 1\n    length = 99\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n        for node in subgraph:\n            assert (node == 'self loner')\n    n = 10\n    length = 10\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n        for node in subgraph:\n            assert (node == 'self loner')", "masked_code": "def test_walk_generation_self_loner_root_node(self):\n    g = create_test_graph()\n    urw = UniformRandomWalk(g)\n    nodes = ['self loner']\n    n = 1\n    length = 1\n    seed = None\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 1)\n    n = 10\n    length = 1\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n        for node in subgraph:\n            assert (node == 'self loner')\n    n = 1\n    length = 99\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n        for node in subgraph:\n            assert (node == 'self loner')\n    n = 10\n    length = 10\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == '???')\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n        for node in subgraph:\n            assert (node == 'self loner')", "ground_truth": "n", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_443", "reponame": "stellargraph", "testpath": "tests/data/test_uniform_random_walker.py", "testname": "test_uniform_random_walker.py", "classname": "TestUniformRandomWalk", "funcname": "test_walk_generation_self_loner_root_node", "imports": ["import pytest", "import numpy as np", "from stellargraph.data.explorer import UniformRandomWalk", "from ..test_utils.graphs import create_test_graph, example_graph_random"], "code": "def test_walk_generation_self_loner_root_node(self):\n    g = create_test_graph()\n    urw = UniformRandomWalk(g)\n    nodes = ['self loner']\n    n = 1\n    length = 1\n    seed = None\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 1)\n    n = 10\n    length = 1\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n        for node in subgraph:\n            assert (node == 'self loner')\n    n = 1\n    length = 99\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n        for node in subgraph:\n            assert (node == 'self loner')\n    n = 10\n    length = 10\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n        for node in subgraph:\n            assert (node == 'self loner')", "masked_code": "def test_walk_generation_self_loner_root_node(self):\n    g = create_test_graph()\n    urw = UniformRandomWalk(g)\n    nodes = ['self loner']\n    n = 1\n    length = 1\n    seed = None\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 1)\n    n = 10\n    length = 1\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == '???')\n        for node in subgraph:\n            assert (node == 'self loner')\n    n = 1\n    length = 99\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n        for node in subgraph:\n            assert (node == 'self loner')\n    n = 10\n    length = 10\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n        for node in subgraph:\n            assert (node == 'self loner')", "ground_truth": "length", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_444", "reponame": "stellargraph", "testpath": "tests/data/test_uniform_random_walker.py", "testname": "test_uniform_random_walker.py", "classname": "TestUniformRandomWalk", "funcname": "test_walk_generation_self_loner_root_node", "imports": ["import pytest", "import numpy as np", "from stellargraph.data.explorer import UniformRandomWalk", "from ..test_utils.graphs import create_test_graph, example_graph_random"], "code": "def test_walk_generation_self_loner_root_node(self):\n    g = create_test_graph()\n    urw = UniformRandomWalk(g)\n    nodes = ['self loner']\n    n = 1\n    length = 1\n    seed = None\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 1)\n    n = 10\n    length = 1\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n        for node in subgraph:\n            assert (node == 'self loner')\n    n = 1\n    length = 99\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n        for node in subgraph:\n            assert (node == 'self loner')\n    n = 10\n    length = 10\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n        for node in subgraph:\n            assert (node == 'self loner')", "masked_code": "def test_walk_generation_self_loner_root_node(self):\n    g = create_test_graph()\n    urw = UniformRandomWalk(g)\n    nodes = ['self loner']\n    n = 1\n    length = 1\n    seed = None\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 1)\n    n = 10\n    length = 1\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n        for node in subgraph:\n            assert (node == 'self loner')\n    n = 1\n    length = 99\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == '???')\n        for node in subgraph:\n            assert (node == 'self loner')\n    n = 10\n    length = 10\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n        for node in subgraph:\n            assert (node == 'self loner')", "ground_truth": "length", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_445", "reponame": "stellargraph", "testpath": "tests/data/test_uniform_random_walker.py", "testname": "test_uniform_random_walker.py", "classname": "TestUniformRandomWalk", "funcname": "test_walk_generation_self_loner_root_node", "imports": ["import pytest", "import numpy as np", "from stellargraph.data.explorer import UniformRandomWalk", "from ..test_utils.graphs import create_test_graph, example_graph_random"], "code": "def test_walk_generation_self_loner_root_node(self):\n    g = create_test_graph()\n    urw = UniformRandomWalk(g)\n    nodes = ['self loner']\n    n = 1\n    length = 1\n    seed = None\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 1)\n    n = 10\n    length = 1\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n        for node in subgraph:\n            assert (node == 'self loner')\n    n = 1\n    length = 99\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n        for node in subgraph:\n            assert (node == 'self loner')\n    n = 10\n    length = 10\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n        for node in subgraph:\n            assert (node == 'self loner')", "masked_code": "def test_walk_generation_self_loner_root_node(self):\n    g = create_test_graph()\n    urw = UniformRandomWalk(g)\n    nodes = ['self loner']\n    n = 1\n    length = 1\n    seed = None\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == 1)\n    assert (len(subgraphs[0]) == 1)\n    n = 10\n    length = 1\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n        for node in subgraph:\n            assert (node == 'self loner')\n    n = 1\n    length = 99\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == length)\n        for node in subgraph:\n            assert (node == 'self loner')\n    n = 10\n    length = 10\n    subgraphs = urw.run(nodes=nodes, n=n, length=length, seed=seed)\n    assert (len(subgraphs) == n)\n    for subgraph in subgraphs:\n        assert (len(subgraph) == '???')\n        for node in subgraph:\n            assert (node == 'self loner')", "ground_truth": "length", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_446", "reponame": "stellargraph", "testpath": "tests/data/test_unsupervised_sampler.py", "testname": "test_unsupervised_sampler.py", "classname": null, "funcname": "test_init_parameters", "imports": ["import pytest", "import numpy as np", "from collections import defaultdict", "from stellargraph.data.unsupervised_sampler import UnsupervisedSampler", "from stellargraph.data.explorer import UniformRandomWalk", "from ..test_utils.graphs import line_graph"], "code": "def test_init_parameters(line_graph):\n    with pytest.raises(ValueError):\n        UnsupervisedSampler(G=None)\n    with pytest.raises(ValueError):\n        UnsupervisedSampler(G=line_graph, length=1)\n    with pytest.raises(ValueError):\n        UnsupervisedSampler(G=line_graph, number_of_walks=0)\n    with pytest.raises(ValueError):\n        UnsupervisedSampler(G=line_graph, nodes=1)\n    sampler = UnsupervisedSampler(G=line_graph, nodes=None)\n    assert (sampler.nodes == list(line_graph.nodes()))", "masked_code": "def test_init_parameters(line_graph):\n    with pytest.raises(ValueError):\n        UnsupervisedSampler(G=None)\n    with pytest.raises(ValueError):\n        UnsupervisedSampler(G=line_graph, length=1)\n    with pytest.raises(ValueError):\n        UnsupervisedSampler(G=line_graph, number_of_walks=0)\n    with pytest.raises(ValueError):\n        UnsupervisedSampler(G=line_graph, nodes=1)\n    sampler = UnsupervisedSampler(G=line_graph, nodes=None)\n    assert (sampler.nodes == '???')", "ground_truth": "list(line_graph.nodes())", "quality_analysis": {"complexity_score": 8, "left_complexity": 2, "right_complexity": 6, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_447", "reponame": "stellargraph", "testpath": "tests/data/test_unsupervised_sampler.py", "testname": "test_unsupervised_sampler.py", "classname": null, "funcname": "test_run_batch_sizes", "imports": ["import pytest", "import numpy as np", "from collections import defaultdict", "from stellargraph.data.unsupervised_sampler import UnsupervisedSampler", "from stellargraph.data.explorer import UniformRandomWalk", "from ..test_utils.graphs import line_graph"], "code": "def test_run_batch_sizes(line_graph):\n    batch_size = 4\n    sampler = UnsupervisedSampler(G=line_graph, length=2, number_of_walks=2)\n    batches = sampler.run(batch_size)\n    assert (len(batches) == np.ceil(((len(line_graph.nodes()) * 4) / batch_size)))\n    for (ids, labels) in batches[:(- 1)]:\n        assert (len(ids) == len(labels) == batch_size)\n    (ids, labels) = batches[(- 1)]\n    assert (len(ids) == len(labels))\n    assert (len(ids) <= batch_size)", "masked_code": "def test_run_batch_sizes(line_graph):\n    batch_size = 4\n    sampler = UnsupervisedSampler(G=line_graph, length=2, number_of_walks=2)\n    batches = sampler.run(batch_size)\n    assert (len(batches) == '???')\n    for (ids, labels) in batches[:(- 1)]:\n        assert (len(ids) == len(labels) == batch_size)\n    (ids, labels) = batches[(- 1)]\n    assert (len(ids) == len(labels))\n    assert (len(ids) <= batch_size)", "ground_truth": "np.ceil(((len(line_graph.nodes()) * 4) / batch_size))", "quality_analysis": {"complexity_score": 19, "left_complexity": 4, "right_complexity": 15, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_448", "reponame": "stellargraph", "testpath": "tests/data/test_unsupervised_sampler.py", "testname": "test_unsupervised_sampler.py", "classname": null, "funcname": "test_run_batch_sizes", "imports": ["import pytest", "import numpy as np", "from collections import defaultdict", "from stellargraph.data.unsupervised_sampler import UnsupervisedSampler", "from stellargraph.data.explorer import UniformRandomWalk", "from ..test_utils.graphs import line_graph"], "code": "def test_run_batch_sizes(line_graph):\n    batch_size = 4\n    sampler = UnsupervisedSampler(G=line_graph, length=2, number_of_walks=2)\n    batches = sampler.run(batch_size)\n    assert (len(batches) == np.ceil(((len(line_graph.nodes()) * 4) / batch_size)))\n    for (ids, labels) in batches[:(- 1)]:\n        assert (len(ids) == len(labels) == batch_size)\n    (ids, labels) = batches[(- 1)]\n    assert (len(ids) == len(labels))\n    assert (len(ids) <= batch_size)", "masked_code": "def test_run_batch_sizes(line_graph):\n    batch_size = 4\n    sampler = UnsupervisedSampler(G=line_graph, length=2, number_of_walks=2)\n    batches = sampler.run(batch_size)\n    assert (len(batches) == np.ceil(((len(line_graph.nodes()) * 4) / batch_size)))\n    for (ids, labels) in batches[:(- 1)]:\n        assert (len(ids) == len(labels) == batch_size)\n    (ids, labels) = batches[(- 1)]\n    assert (len(ids) == '???')\n    assert (len(ids) <= batch_size)", "ground_truth": "len(labels)", "quality_analysis": {"complexity_score": 8, "left_complexity": 4, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_449", "reponame": "stellargraph", "testpath": "tests/data/test_unsupervised_sampler.py", "testname": "test_unsupervised_sampler.py", "classname": null, "funcname": "test_run_batch_sizes", "imports": ["import pytest", "import numpy as np", "from collections import defaultdict", "from stellargraph.data.unsupervised_sampler import UnsupervisedSampler", "from stellargraph.data.explorer import UniformRandomWalk", "from ..test_utils.graphs import line_graph"], "code": "def test_run_batch_sizes(line_graph):\n    batch_size = 4\n    sampler = UnsupervisedSampler(G=line_graph, length=2, number_of_walks=2)\n    batches = sampler.run(batch_size)\n    assert (len(batches) == np.ceil(((len(line_graph.nodes()) * 4) / batch_size)))\n    for (ids, labels) in batches[:(- 1)]:\n        assert (len(ids) == len(labels) == batch_size)\n    (ids, labels) = batches[(- 1)]\n    assert (len(ids) == len(labels))\n    assert (len(ids) <= batch_size)", "masked_code": "def test_run_batch_sizes(line_graph):\n    batch_size = 4\n    sampler = UnsupervisedSampler(G=line_graph, length=2, number_of_walks=2)\n    batches = sampler.run(batch_size)\n    assert (len(batches) == np.ceil(((len(line_graph.nodes()) * 4) / batch_size)))\n    for (ids, labels) in batches[:(- 1)]:\n        assert (len(ids) == '???' == batch_size)\n    (ids, labels) = batches[(- 1)]\n    assert (len(ids) == len(labels))\n    assert (len(ids) <= batch_size)", "ground_truth": "len(labels)", "quality_analysis": {"complexity_score": 8, "left_complexity": 4, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_450", "reponame": "stellargraph", "testpath": "tests/data/test_unsupervised_sampler.py", "testname": "test_unsupervised_sampler.py", "classname": null, "funcname": "test_run_context_pairs", "imports": ["import pytest", "import numpy as np", "from collections import defaultdict", "from stellargraph.data.unsupervised_sampler import UnsupervisedSampler", "from stellargraph.data.explorer import UniformRandomWalk", "from ..test_utils.graphs import line_graph"], "code": "def test_run_context_pairs(line_graph):\n    batch_size = 4\n    sampler = UnsupervisedSampler(G=line_graph, length=2, number_of_walks=2)\n    batches = sampler.run(batch_size)\n    grouped_by_target = defaultdict(list)\n    for (ids, labels) in batches:\n        for ((target, context), label) in zip(ids, labels):\n            grouped_by_target[target].append((context, label))\n    assert (len(grouped_by_target) == len(line_graph.nodes()))\n    for (target, sampled) in grouped_by_target.items():\n        assert (len(sampled) == 4)\n        for (context, label) in sampled:\n            if (label == 1):\n                assert (context in set(line_graph.neighbors(target)))", "masked_code": "def test_run_context_pairs(line_graph):\n    batch_size = 4\n    sampler = UnsupervisedSampler(G=line_graph, length=2, number_of_walks=2)\n    batches = sampler.run(batch_size)\n    grouped_by_target = defaultdict(list)\n    for (ids, labels) in batches:\n        for ((target, context), label) in zip(ids, labels):\n            grouped_by_target[target].append((context, label))\n    assert (len(grouped_by_target) == '???')\n    for (target, sampled) in grouped_by_target.items():\n        assert (len(sampled) == 4)\n        for (context, label) in sampled:\n            if (label == 1):\n                assert (context in set(line_graph.neighbors(target)))", "ground_truth": "len(line_graph.nodes())", "quality_analysis": {"complexity_score": 10, "left_complexity": 4, "right_complexity": 6, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_451", "reponame": "stellargraph", "testpath": "tests/data/test_unsupervised_sampler.py", "testname": "test_unsupervised_sampler.py", "classname": null, "funcname": "test_run_context_pairs", "imports": ["import pytest", "import numpy as np", "from collections import defaultdict", "from stellargraph.data.unsupervised_sampler import UnsupervisedSampler", "from stellargraph.data.explorer import UniformRandomWalk", "from ..test_utils.graphs import line_graph"], "code": "def test_run_context_pairs(line_graph):\n    batch_size = 4\n    sampler = UnsupervisedSampler(G=line_graph, length=2, number_of_walks=2)\n    batches = sampler.run(batch_size)\n    grouped_by_target = defaultdict(list)\n    for (ids, labels) in batches:\n        for ((target, context), label) in zip(ids, labels):\n            grouped_by_target[target].append((context, label))\n    assert (len(grouped_by_target) == len(line_graph.nodes()))\n    for (target, sampled) in grouped_by_target.items():\n        assert (len(sampled) == 4)\n        for (context, label) in sampled:\n            if (label == 1):\n                assert (context in set(line_graph.neighbors(target)))", "masked_code": "def test_run_context_pairs(line_graph):\n    batch_size = 4\n    sampler = UnsupervisedSampler(G=line_graph, length=2, number_of_walks=2)\n    batches = sampler.run(batch_size)\n    grouped_by_target = defaultdict(list)\n    for (ids, labels) in batches:\n        for ((target, context), label) in zip(ids, labels):\n            grouped_by_target[target].append((context, label))\n    assert (len(grouped_by_target) == len(line_graph.nodes()))\n    for (target, sampled) in grouped_by_target.items():\n        assert (len(sampled) == '???')\n        for (context, label) in sampled:\n            if (label == 1):\n                assert (context in set(line_graph.neighbors(target)))", "ground_truth": "4", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_452", "reponame": "stellargraph", "testpath": "tests/data/test_unsupervised_sampler.py", "testname": "test_unsupervised_sampler.py", "classname": null, "funcname": "test_walker_uniform_random", "imports": ["import pytest", "import numpy as np", "from collections import defaultdict", "from stellargraph.data.unsupervised_sampler import UnsupervisedSampler", "from stellargraph.data.explorer import UniformRandomWalk", "from ..test_utils.graphs import line_graph"], "code": "def test_walker_uniform_random(line_graph):\n    length = 3\n    number_of_walks = 2\n    batch_size = 4\n    walker = UniformRandomWalk(line_graph, n=number_of_walks, length=length)\n    sampler = UnsupervisedSampler(line_graph, walker=walker)\n    batches = sampler.run(batch_size)\n    expected_num_batches = np.ceil(((((line_graph.number_of_nodes() * number_of_walks) * (length - 1)) * 2) / batch_size))\n    assert (len(batches) == expected_num_batches)", "masked_code": "def test_walker_uniform_random(line_graph):\n    length = 3\n    number_of_walks = 2\n    batch_size = 4\n    walker = UniformRandomWalk(line_graph, n=number_of_walks, length=length)\n    sampler = UnsupervisedSampler(line_graph, walker=walker)\n    batches = sampler.run(batch_size)\n    expected_num_batches = np.ceil(((((line_graph.number_of_nodes() * number_of_walks) * (length - 1)) * 2) / batch_size))\n    assert (len(batches) == '???')", "ground_truth": "expected_num_batches", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_453", "reponame": "stellargraph", "testpath": "tests/data/test_unsupervised_sampler.py", "testname": "test_unsupervised_sampler.py", "classname": null, "funcname": "test_walker_custom", "imports": ["import pytest", "import numpy as np", "from collections import defaultdict", "from stellargraph.data.unsupervised_sampler import UnsupervisedSampler", "from stellargraph.data.explorer import UniformRandomWalk", "from ..test_utils.graphs import line_graph"], "code": "def test_walker_custom(line_graph):\n    walker = CustomWalker()\n    sampler = UnsupervisedSampler(line_graph, walker=walker)\n    batches = sampler.run(2)\n    assert (len(batches) == line_graph.number_of_nodes())\n    for (context_pairs, labels) in batches:\n        for (node, neighbour) in context_pairs[(labels == 1)]:\n            assert (node == neighbour)", "masked_code": "def test_walker_custom(line_graph):\n    walker = CustomWalker()\n    sampler = UnsupervisedSampler(line_graph, walker=walker)\n    batches = sampler.run(2)\n    assert (len(batches) == '???')\n    for (context_pairs, labels) in batches:\n        for (node, neighbour) in context_pairs[(labels == 1)]:\n            assert (node == neighbour)", "ground_truth": "line_graph.number_of_nodes()", "quality_analysis": {"complexity_score": 7, "left_complexity": 4, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_454", "reponame": "stellargraph", "testpath": "tests/datasets/test_datasets.py", "testname": "test_datasets.py", "classname": null, "funcname": "test_environment_path_override", "imports": ["import pytest", "import tempfile", "import os", "import sys", "import numpy as np", "from stellargraph.datasets import *", "from urllib.error import URLError", "from stellargraph.datasets.dataset_loader import DatasetLoader", "from urllib.request import urlretrieve", "from unittest.mock import patch"], "code": "def test_environment_path_override(monkeypatch) -> None:\n    with tempfile.TemporaryDirectory() as new_datasets_path:\n        monkeypatch.setenv('STELLARGRAPH_DATASETS_PATH', new_datasets_path)\n        dataset = CiteSeer()\n        assert (dataset.base_directory == os.path.join(new_datasets_path, dataset.directory_name))\n        dataset.download()", "masked_code": "def test_environment_path_override(monkeypatch) -> None:\n    with tempfile.TemporaryDirectory() as new_datasets_path:\n        monkeypatch.setenv('STELLARGRAPH_DATASETS_PATH', new_datasets_path)\n        dataset = CiteSeer()\n        assert (dataset.base_directory == '???')\n        dataset.download()", "ground_truth": "os.path.join(new_datasets_path, dataset.directory_name)", "quality_analysis": {"complexity_score": 8, "left_complexity": 2, "right_complexity": 6, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_455", "reponame": "stellargraph", "testpath": "tests/datasets/test_datasets.py", "testname": "test_datasets.py", "classname": null, "funcname": "test_blogcatalog3_load", "imports": ["import pytest", "import tempfile", "import os", "import sys", "import numpy as np", "from stellargraph.datasets import *", "from urllib.error import URLError", "from stellargraph.datasets.dataset_loader import DatasetLoader", "from urllib.request import urlretrieve", "from unittest.mock import patch"], "code": "def test_blogcatalog3_load() -> None:\n    g = BlogCatalog3().load()\n    n_users = 10312\n    n_groups = 39\n    n_friendships = 333983\n    n_belongs_to = 14476\n    assert (g.number_of_nodes() == (n_users + n_groups))\n    assert (g.number_of_edges() == (n_friendships + n_belongs_to))\n    assert (list(g.nodes(node_type='user')) == [f'u{x}' for x in range(1, (n_users + 1))])\n    assert (list(g.nodes(node_type='group')) == [f'g{x}' for x in range(1, (n_groups + 1))])", "masked_code": "def test_blogcatalog3_load() -> None:\n    g = BlogCatalog3().load()\n    n_users = 10312\n    n_groups = 39\n    n_friendships = 333983\n    n_belongs_to = 14476\n    assert (g.number_of_nodes() == '???')\n    assert (g.number_of_edges() == (n_friendships + n_belongs_to))\n    assert (list(g.nodes(node_type='user')) == [f'u{x}' for x in range(1, (n_users + 1))])\n    assert (list(g.nodes(node_type='group')) == [f'g{x}' for x in range(1, (n_groups + 1))])", "ground_truth": "(n_users + n_groups)", "quality_analysis": {"complexity_score": 7, "left_complexity": 3, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_456", "reponame": "stellargraph", "testpath": "tests/datasets/test_datasets.py", "testname": "test_datasets.py", "classname": null, "funcname": "test_blogcatalog3_load", "imports": ["import pytest", "import tempfile", "import os", "import sys", "import numpy as np", "from stellargraph.datasets import *", "from urllib.error import URLError", "from stellargraph.datasets.dataset_loader import DatasetLoader", "from urllib.request import urlretrieve", "from unittest.mock import patch"], "code": "def test_blogcatalog3_load() -> None:\n    g = BlogCatalog3().load()\n    n_users = 10312\n    n_groups = 39\n    n_friendships = 333983\n    n_belongs_to = 14476\n    assert (g.number_of_nodes() == (n_users + n_groups))\n    assert (g.number_of_edges() == (n_friendships + n_belongs_to))\n    assert (list(g.nodes(node_type='user')) == [f'u{x}' for x in range(1, (n_users + 1))])\n    assert (list(g.nodes(node_type='group')) == [f'g{x}' for x in range(1, (n_groups + 1))])", "masked_code": "def test_blogcatalog3_load() -> None:\n    g = BlogCatalog3().load()\n    n_users = 10312\n    n_groups = 39\n    n_friendships = 333983\n    n_belongs_to = 14476\n    assert (g.number_of_nodes() == (n_users + n_groups))\n    assert (g.number_of_edges() == '???')\n    assert (list(g.nodes(node_type='user')) == [f'u{x}' for x in range(1, (n_users + 1))])\n    assert (list(g.nodes(node_type='group')) == [f'g{x}' for x in range(1, (n_groups + 1))])", "ground_truth": "(n_friendships + n_belongs_to)", "quality_analysis": {"complexity_score": 7, "left_complexity": 3, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_457", "reponame": "stellargraph", "testpath": "tests/datasets/test_datasets.py", "testname": "test_datasets.py", "classname": null, "funcname": "test_blogcatalog3_load", "imports": ["import pytest", "import tempfile", "import os", "import sys", "import numpy as np", "from stellargraph.datasets import *", "from urllib.error import URLError", "from stellargraph.datasets.dataset_loader import DatasetLoader", "from urllib.request import urlretrieve", "from unittest.mock import patch"], "code": "def test_blogcatalog3_load() -> None:\n    g = BlogCatalog3().load()\n    n_users = 10312\n    n_groups = 39\n    n_friendships = 333983\n    n_belongs_to = 14476\n    assert (g.number_of_nodes() == (n_users + n_groups))\n    assert (g.number_of_edges() == (n_friendships + n_belongs_to))\n    assert (list(g.nodes(node_type='user')) == [f'u{x}' for x in range(1, (n_users + 1))])\n    assert (list(g.nodes(node_type='group')) == [f'g{x}' for x in range(1, (n_groups + 1))])", "masked_code": "def test_blogcatalog3_load() -> None:\n    g = BlogCatalog3().load()\n    n_users = 10312\n    n_groups = 39\n    n_friendships = 333983\n    n_belongs_to = 14476\n    assert (g.number_of_nodes() == (n_users + n_groups))\n    assert (g.number_of_edges() == (n_friendships + n_belongs_to))\n    assert (list(g.nodes(node_type='user')) == '???')\n    assert (list(g.nodes(node_type='group')) == [f'g{x}' for x in range(1, (n_groups + 1))])", "ground_truth": "[f'u{x}' for x in range(1, (n_users + 1))]", "quality_analysis": {"complexity_score": 6, "left_complexity": 6, "right_complexity": 0, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_458", "reponame": "stellargraph", "testpath": "tests/datasets/test_datasets.py", "testname": "test_datasets.py", "classname": null, "funcname": "test_blogcatalog3_load", "imports": ["import pytest", "import tempfile", "import os", "import sys", "import numpy as np", "from stellargraph.datasets import *", "from urllib.error import URLError", "from stellargraph.datasets.dataset_loader import DatasetLoader", "from urllib.request import urlretrieve", "from unittest.mock import patch"], "code": "def test_blogcatalog3_load() -> None:\n    g = BlogCatalog3().load()\n    n_users = 10312\n    n_groups = 39\n    n_friendships = 333983\n    n_belongs_to = 14476\n    assert (g.number_of_nodes() == (n_users + n_groups))\n    assert (g.number_of_edges() == (n_friendships + n_belongs_to))\n    assert (list(g.nodes(node_type='user')) == [f'u{x}' for x in range(1, (n_users + 1))])\n    assert (list(g.nodes(node_type='group')) == [f'g{x}' for x in range(1, (n_groups + 1))])", "masked_code": "def test_blogcatalog3_load() -> None:\n    g = BlogCatalog3().load()\n    n_users = 10312\n    n_groups = 39\n    n_friendships = 333983\n    n_belongs_to = 14476\n    assert (g.number_of_nodes() == (n_users + n_groups))\n    assert (g.number_of_edges() == (n_friendships + n_belongs_to))\n    assert (list(g.nodes(node_type='user')) == [f'u{x}' for x in range(1, (n_users + 1))])\n    assert (list(g.nodes(node_type='group')) == '???')", "ground_truth": "[f'g{x}' for x in range(1, (n_groups + 1))]", "quality_analysis": {"complexity_score": 6, "left_complexity": 6, "right_complexity": 0, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_459", "reponame": "stellargraph", "testpath": "tests/datasets/test_datasets.py", "testname": "test_datasets.py", "classname": null, "funcname": "test_movielens_load", "imports": ["import pytest", "import tempfile", "import os", "import sys", "import numpy as np", "from stellargraph.datasets import *", "from urllib.error import URLError", "from stellargraph.datasets.dataset_loader import DatasetLoader", "from urllib.request import urlretrieve", "from unittest.mock import patch"], "code": "def test_movielens_load() -> None:\n    (g, edges_with_ratings) = MovieLens().load()\n    n_users = 943\n    n_movies = 1682\n    n_ratings = 100000\n    assert (g.number_of_nodes() == (n_users + n_movies))\n    assert (g.number_of_edges() == n_ratings)\n    assert (len(g.nodes(node_type='user')) == n_users)\n    assert (len(g.nodes(node_type='movie')) == n_movies)\n    assert (len(edges_with_ratings) == n_ratings)\n    assert (list(edges_with_ratings.columns) == ['user_id', 'movie_id', 'rating'])", "masked_code": "def test_movielens_load() -> None:\n    (g, edges_with_ratings) = MovieLens().load()\n    n_users = 943\n    n_movies = 1682\n    n_ratings = 100000\n    assert (g.number_of_nodes() == '???')\n    assert (g.number_of_edges() == n_ratings)\n    assert (len(g.nodes(node_type='user')) == n_users)\n    assert (len(g.nodes(node_type='movie')) == n_movies)\n    assert (len(edges_with_ratings) == n_ratings)\n    assert (list(edges_with_ratings.columns) == ['user_id', 'movie_id', 'rating'])", "ground_truth": "(n_users + n_movies)", "quality_analysis": {"complexity_score": 7, "left_complexity": 3, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_460", "reponame": "stellargraph", "testpath": "tests/datasets/test_datasets.py", "testname": "test_datasets.py", "classname": null, "funcname": "test_movielens_load", "imports": ["import pytest", "import tempfile", "import os", "import sys", "import numpy as np", "from stellargraph.datasets import *", "from urllib.error import URLError", "from stellargraph.datasets.dataset_loader import DatasetLoader", "from urllib.request import urlretrieve", "from unittest.mock import patch"], "code": "def test_movielens_load() -> None:\n    (g, edges_with_ratings) = MovieLens().load()\n    n_users = 943\n    n_movies = 1682\n    n_ratings = 100000\n    assert (g.number_of_nodes() == (n_users + n_movies))\n    assert (g.number_of_edges() == n_ratings)\n    assert (len(g.nodes(node_type='user')) == n_users)\n    assert (len(g.nodes(node_type='movie')) == n_movies)\n    assert (len(edges_with_ratings) == n_ratings)\n    assert (list(edges_with_ratings.columns) == ['user_id', 'movie_id', 'rating'])", "masked_code": "def test_movielens_load() -> None:\n    (g, edges_with_ratings) = MovieLens().load()\n    n_users = 943\n    n_movies = 1682\n    n_ratings = 100000\n    assert (g.number_of_nodes() == (n_users + n_movies))\n    assert (g.number_of_edges() == '???')\n    assert (len(g.nodes(node_type='user')) == n_users)\n    assert (len(g.nodes(node_type='movie')) == n_movies)\n    assert (len(edges_with_ratings) == n_ratings)\n    assert (list(edges_with_ratings.columns) == ['user_id', 'movie_id', 'rating'])", "ground_truth": "n_ratings", "quality_analysis": {"complexity_score": 4, "left_complexity": 3, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_461", "reponame": "stellargraph", "testpath": "tests/datasets/test_datasets.py", "testname": "test_datasets.py", "classname": null, "funcname": "test_movielens_load", "imports": ["import pytest", "import tempfile", "import os", "import sys", "import numpy as np", "from stellargraph.datasets import *", "from urllib.error import URLError", "from stellargraph.datasets.dataset_loader import DatasetLoader", "from urllib.request import urlretrieve", "from unittest.mock import patch"], "code": "def test_movielens_load() -> None:\n    (g, edges_with_ratings) = MovieLens().load()\n    n_users = 943\n    n_movies = 1682\n    n_ratings = 100000\n    assert (g.number_of_nodes() == (n_users + n_movies))\n    assert (g.number_of_edges() == n_ratings)\n    assert (len(g.nodes(node_type='user')) == n_users)\n    assert (len(g.nodes(node_type='movie')) == n_movies)\n    assert (len(edges_with_ratings) == n_ratings)\n    assert (list(edges_with_ratings.columns) == ['user_id', 'movie_id', 'rating'])", "masked_code": "def test_movielens_load() -> None:\n    (g, edges_with_ratings) = MovieLens().load()\n    n_users = 943\n    n_movies = 1682\n    n_ratings = 100000\n    assert (g.number_of_nodes() == (n_users + n_movies))\n    assert (g.number_of_edges() == n_ratings)\n    assert (len(g.nodes(node_type='user')) == '???')\n    assert (len(g.nodes(node_type='movie')) == n_movies)\n    assert (len(edges_with_ratings) == n_ratings)\n    assert (list(edges_with_ratings.columns) == ['user_id', 'movie_id', 'rating'])", "ground_truth": "n_users", "quality_analysis": {"complexity_score": 7, "left_complexity": 6, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_462", "reponame": "stellargraph", "testpath": "tests/datasets/test_datasets.py", "testname": "test_datasets.py", "classname": null, "funcname": "test_movielens_load", "imports": ["import pytest", "import tempfile", "import os", "import sys", "import numpy as np", "from stellargraph.datasets import *", "from urllib.error import URLError", "from stellargraph.datasets.dataset_loader import DatasetLoader", "from urllib.request import urlretrieve", "from unittest.mock import patch"], "code": "def test_movielens_load() -> None:\n    (g, edges_with_ratings) = MovieLens().load()\n    n_users = 943\n    n_movies = 1682\n    n_ratings = 100000\n    assert (g.number_of_nodes() == (n_users + n_movies))\n    assert (g.number_of_edges() == n_ratings)\n    assert (len(g.nodes(node_type='user')) == n_users)\n    assert (len(g.nodes(node_type='movie')) == n_movies)\n    assert (len(edges_with_ratings) == n_ratings)\n    assert (list(edges_with_ratings.columns) == ['user_id', 'movie_id', 'rating'])", "masked_code": "def test_movielens_load() -> None:\n    (g, edges_with_ratings) = MovieLens().load()\n    n_users = 943\n    n_movies = 1682\n    n_ratings = 100000\n    assert (g.number_of_nodes() == (n_users + n_movies))\n    assert (g.number_of_edges() == n_ratings)\n    assert (len(g.nodes(node_type='user')) == n_users)\n    assert (len(g.nodes(node_type='movie')) == '???')\n    assert (len(edges_with_ratings) == n_ratings)\n    assert (list(edges_with_ratings.columns) == ['user_id', 'movie_id', 'rating'])", "ground_truth": "n_movies", "quality_analysis": {"complexity_score": 7, "left_complexity": 6, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_463", "reponame": "stellargraph", "testpath": "tests/datasets/test_datasets.py", "testname": "test_datasets.py", "classname": null, "funcname": "test_movielens_load", "imports": ["import pytest", "import tempfile", "import os", "import sys", "import numpy as np", "from stellargraph.datasets import *", "from urllib.error import URLError", "from stellargraph.datasets.dataset_loader import DatasetLoader", "from urllib.request import urlretrieve", "from unittest.mock import patch"], "code": "def test_movielens_load() -> None:\n    (g, edges_with_ratings) = MovieLens().load()\n    n_users = 943\n    n_movies = 1682\n    n_ratings = 100000\n    assert (g.number_of_nodes() == (n_users + n_movies))\n    assert (g.number_of_edges() == n_ratings)\n    assert (len(g.nodes(node_type='user')) == n_users)\n    assert (len(g.nodes(node_type='movie')) == n_movies)\n    assert (len(edges_with_ratings) == n_ratings)\n    assert (list(edges_with_ratings.columns) == ['user_id', 'movie_id', 'rating'])", "masked_code": "def test_movielens_load() -> None:\n    (g, edges_with_ratings) = MovieLens().load()\n    n_users = 943\n    n_movies = 1682\n    n_ratings = 100000\n    assert (g.number_of_nodes() == (n_users + n_movies))\n    assert (g.number_of_edges() == n_ratings)\n    assert (len(g.nodes(node_type='user')) == n_users)\n    assert (len(g.nodes(node_type='movie')) == n_movies)\n    assert (len(edges_with_ratings) == '???')\n    assert (list(edges_with_ratings.columns) == ['user_id', 'movie_id', 'rating'])", "ground_truth": "n_ratings", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_464", "reponame": "stellargraph", "testpath": "tests/datasets/test_datasets.py", "testname": "test_datasets.py", "classname": null, "funcname": "test_movielens_load", "imports": ["import pytest", "import tempfile", "import os", "import sys", "import numpy as np", "from stellargraph.datasets import *", "from urllib.error import URLError", "from stellargraph.datasets.dataset_loader import DatasetLoader", "from urllib.request import urlretrieve", "from unittest.mock import patch"], "code": "def test_movielens_load() -> None:\n    (g, edges_with_ratings) = MovieLens().load()\n    n_users = 943\n    n_movies = 1682\n    n_ratings = 100000\n    assert (g.number_of_nodes() == (n_users + n_movies))\n    assert (g.number_of_edges() == n_ratings)\n    assert (len(g.nodes(node_type='user')) == n_users)\n    assert (len(g.nodes(node_type='movie')) == n_movies)\n    assert (len(edges_with_ratings) == n_ratings)\n    assert (list(edges_with_ratings.columns) == ['user_id', 'movie_id', 'rating'])", "masked_code": "def test_movielens_load() -> None:\n    (g, edges_with_ratings) = MovieLens().load()\n    n_users = 943\n    n_movies = 1682\n    n_ratings = 100000\n    assert (g.number_of_nodes() == (n_users + n_movies))\n    assert (g.number_of_edges() == n_ratings)\n    assert (len(g.nodes(node_type='user')) == n_users)\n    assert (len(g.nodes(node_type='movie')) == n_movies)\n    assert (len(edges_with_ratings) == n_ratings)\n    assert (list(edges_with_ratings.columns) == '???')", "ground_truth": "['user_id', 'movie_id', 'rating']", "quality_analysis": {"complexity_score": 10, "left_complexity": 5, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_465", "reponame": "stellargraph", "testpath": "tests/datasets/test_datasets.py", "testname": "test_datasets.py", "classname": null, "funcname": "test_cora_load", "imports": ["import pytest", "import tempfile", "import os", "import sys", "import numpy as np", "from stellargraph.datasets import *", "from urllib.error import URLError", "from stellargraph.datasets.dataset_loader import DatasetLoader", "from urllib.request import urlretrieve", "from unittest.mock import patch"], "code": "@pytest.mark.parametrize('is_directed', [False, True])\n@pytest.mark.parametrize('largest_cc_only', [False, True])\n@pytest.mark.parametrize('subject_as_feature', [False, True])\n@pytest.mark.xfail((sys.platform == 'win32'), reason='FIXME #1698')\ndef test_cora_load(is_directed, largest_cc_only, subject_as_feature) -> None:\n    (g, subjects) = Cora().load(is_directed, largest_cc_only, subject_as_feature)\n    if largest_cc_only:\n        expected_nodes = 2485\n        expected_edges = 5209\n    else:\n        expected_nodes = 2708\n        expected_edges = 5429\n    base_feature_size = 1433\n    if subject_as_feature:\n        feature_size = (base_feature_size + 7)\n    else:\n        feature_size = base_feature_size\n    assert (g.nodes().dtype == np.int64)\n    assert (g.is_directed() == is_directed)\n    assert (g.number_of_nodes() == expected_nodes)\n    assert (g.number_of_edges() == expected_edges)\n    assert (g.node_feature_sizes() == {'paper': feature_size})\n    assert (len(subjects) == g.number_of_nodes())\n    assert (set(subjects.index) == set(g.nodes()))\n    assert (set(subjects) == {'Case_Based', 'Genetic_Algorithms', 'Neural_Networks', 'Probabilistic_Methods', 'Reinforcement_Learning', 'Rule_Learning', 'Theory'})", "masked_code": "@pytest.mark.parametrize('is_directed', [False, True])\n@pytest.mark.parametrize('largest_cc_only', [False, True])\n@pytest.mark.parametrize('subject_as_feature', [False, True])\n@pytest.mark.xfail((sys.platform == 'win32'), reason='FIXME #1698')\ndef test_cora_load(is_directed, largest_cc_only, subject_as_feature) -> None:\n    (g, subjects) = Cora().load(is_directed, largest_cc_only, subject_as_feature)\n    if largest_cc_only:\n        expected_nodes = 2485\n        expected_edges = 5209\n    else:\n        expected_nodes = 2708\n        expected_edges = 5429\n    base_feature_size = 1433\n    if subject_as_feature:\n        feature_size = (base_feature_size + 7)\n    else:\n        feature_size = base_feature_size\n    assert (g.nodes().dtype == '???')\n    assert (g.is_directed() == is_directed)\n    assert (g.number_of_nodes() == expected_nodes)\n    assert (g.number_of_edges() == expected_edges)\n    assert (g.node_feature_sizes() == {'paper': feature_size})\n    assert (len(subjects) == g.number_of_nodes())\n    assert (set(subjects.index) == set(g.nodes()))\n    assert (set(subjects) == {'Case_Based', 'Genetic_Algorithms', 'Neural_Networks', 'Probabilistic_Methods', 'Reinforcement_Learning', 'Rule_Learning', 'Theory'})", "ground_truth": "np.int64", "quality_analysis": {"complexity_score": 4, "left_complexity": 2, "right_complexity": 2, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_466", "reponame": "stellargraph", "testpath": "tests/datasets/test_datasets.py", "testname": "test_datasets.py", "classname": null, "funcname": "test_cora_load", "imports": ["import pytest", "import tempfile", "import os", "import sys", "import numpy as np", "from stellargraph.datasets import *", "from urllib.error import URLError", "from stellargraph.datasets.dataset_loader import DatasetLoader", "from urllib.request import urlretrieve", "from unittest.mock import patch"], "code": "@pytest.mark.parametrize('is_directed', [False, True])\n@pytest.mark.parametrize('largest_cc_only', [False, True])\n@pytest.mark.parametrize('subject_as_feature', [False, True])\n@pytest.mark.xfail((sys.platform == 'win32'), reason='FIXME #1698')\ndef test_cora_load(is_directed, largest_cc_only, subject_as_feature) -> None:\n    (g, subjects) = Cora().load(is_directed, largest_cc_only, subject_as_feature)\n    if largest_cc_only:\n        expected_nodes = 2485\n        expected_edges = 5209\n    else:\n        expected_nodes = 2708\n        expected_edges = 5429\n    base_feature_size = 1433\n    if subject_as_feature:\n        feature_size = (base_feature_size + 7)\n    else:\n        feature_size = base_feature_size\n    assert (g.nodes().dtype == np.int64)\n    assert (g.is_directed() == is_directed)\n    assert (g.number_of_nodes() == expected_nodes)\n    assert (g.number_of_edges() == expected_edges)\n    assert (g.node_feature_sizes() == {'paper': feature_size})\n    assert (len(subjects) == g.number_of_nodes())\n    assert (set(subjects.index) == set(g.nodes()))\n    assert (set(subjects) == {'Case_Based', 'Genetic_Algorithms', 'Neural_Networks', 'Probabilistic_Methods', 'Reinforcement_Learning', 'Rule_Learning', 'Theory'})", "masked_code": "@pytest.mark.parametrize('is_directed', [False, True])\n@pytest.mark.parametrize('largest_cc_only', [False, True])\n@pytest.mark.parametrize('subject_as_feature', [False, True])\n@pytest.mark.xfail((sys.platform == 'win32'), reason='FIXME #1698')\ndef test_cora_load(is_directed, largest_cc_only, subject_as_feature) -> None:\n    (g, subjects) = Cora().load(is_directed, largest_cc_only, subject_as_feature)\n    if largest_cc_only:\n        expected_nodes = 2485\n        expected_edges = 5209\n    else:\n        expected_nodes = 2708\n        expected_edges = 5429\n    base_feature_size = 1433\n    if subject_as_feature:\n        feature_size = (base_feature_size + 7)\n    else:\n        feature_size = base_feature_size\n    assert (g.nodes().dtype == np.int64)\n    assert (g.is_directed() == '???')\n    assert (g.number_of_nodes() == expected_nodes)\n    assert (g.number_of_edges() == expected_edges)\n    assert (g.node_feature_sizes() == {'paper': feature_size})\n    assert (len(subjects) == g.number_of_nodes())\n    assert (set(subjects.index) == set(g.nodes()))\n    assert (set(subjects) == {'Case_Based', 'Genetic_Algorithms', 'Neural_Networks', 'Probabilistic_Methods', 'Reinforcement_Learning', 'Rule_Learning', 'Theory'})", "ground_truth": "is_directed", "quality_analysis": {"complexity_score": 4, "left_complexity": 3, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_467", "reponame": "stellargraph", "testpath": "tests/datasets/test_datasets.py", "testname": "test_datasets.py", "classname": null, "funcname": "test_cora_load", "imports": ["import pytest", "import tempfile", "import os", "import sys", "import numpy as np", "from stellargraph.datasets import *", "from urllib.error import URLError", "from stellargraph.datasets.dataset_loader import DatasetLoader", "from urllib.request import urlretrieve", "from unittest.mock import patch"], "code": "@pytest.mark.parametrize('is_directed', [False, True])\n@pytest.mark.parametrize('largest_cc_only', [False, True])\n@pytest.mark.parametrize('subject_as_feature', [False, True])\n@pytest.mark.xfail((sys.platform == 'win32'), reason='FIXME #1698')\ndef test_cora_load(is_directed, largest_cc_only, subject_as_feature) -> None:\n    (g, subjects) = Cora().load(is_directed, largest_cc_only, subject_as_feature)\n    if largest_cc_only:\n        expected_nodes = 2485\n        expected_edges = 5209\n    else:\n        expected_nodes = 2708\n        expected_edges = 5429\n    base_feature_size = 1433\n    if subject_as_feature:\n        feature_size = (base_feature_size + 7)\n    else:\n        feature_size = base_feature_size\n    assert (g.nodes().dtype == np.int64)\n    assert (g.is_directed() == is_directed)\n    assert (g.number_of_nodes() == expected_nodes)\n    assert (g.number_of_edges() == expected_edges)\n    assert (g.node_feature_sizes() == {'paper': feature_size})\n    assert (len(subjects) == g.number_of_nodes())\n    assert (set(subjects.index) == set(g.nodes()))\n    assert (set(subjects) == {'Case_Based', 'Genetic_Algorithms', 'Neural_Networks', 'Probabilistic_Methods', 'Reinforcement_Learning', 'Rule_Learning', 'Theory'})", "masked_code": "@pytest.mark.parametrize('is_directed', [False, True])\n@pytest.mark.parametrize('largest_cc_only', [False, True])\n@pytest.mark.parametrize('subject_as_feature', [False, True])\n@pytest.mark.xfail((sys.platform == 'win32'), reason='FIXME #1698')\ndef test_cora_load(is_directed, largest_cc_only, subject_as_feature) -> None:\n    (g, subjects) = Cora().load(is_directed, largest_cc_only, subject_as_feature)\n    if largest_cc_only:\n        expected_nodes = 2485\n        expected_edges = 5209\n    else:\n        expected_nodes = 2708\n        expected_edges = 5429\n    base_feature_size = 1433\n    if subject_as_feature:\n        feature_size = (base_feature_size + 7)\n    else:\n        feature_size = base_feature_size\n    assert (g.nodes().dtype == np.int64)\n    assert (g.is_directed() == is_directed)\n    assert (g.number_of_nodes() == '???')\n    assert (g.number_of_edges() == expected_edges)\n    assert (g.node_feature_sizes() == {'paper': feature_size})\n    assert (len(subjects) == g.number_of_nodes())\n    assert (set(subjects.index) == set(g.nodes()))\n    assert (set(subjects) == {'Case_Based', 'Genetic_Algorithms', 'Neural_Networks', 'Probabilistic_Methods', 'Reinforcement_Learning', 'Rule_Learning', 'Theory'})", "ground_truth": "expected_nodes", "quality_analysis": {"complexity_score": 4, "left_complexity": 3, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_468", "reponame": "stellargraph", "testpath": "tests/datasets/test_datasets.py", "testname": "test_datasets.py", "classname": null, "funcname": "test_cora_load", "imports": ["import pytest", "import tempfile", "import os", "import sys", "import numpy as np", "from stellargraph.datasets import *", "from urllib.error import URLError", "from stellargraph.datasets.dataset_loader import DatasetLoader", "from urllib.request import urlretrieve", "from unittest.mock import patch"], "code": "@pytest.mark.parametrize('is_directed', [False, True])\n@pytest.mark.parametrize('largest_cc_only', [False, True])\n@pytest.mark.parametrize('subject_as_feature', [False, True])\n@pytest.mark.xfail((sys.platform == 'win32'), reason='FIXME #1698')\ndef test_cora_load(is_directed, largest_cc_only, subject_as_feature) -> None:\n    (g, subjects) = Cora().load(is_directed, largest_cc_only, subject_as_feature)\n    if largest_cc_only:\n        expected_nodes = 2485\n        expected_edges = 5209\n    else:\n        expected_nodes = 2708\n        expected_edges = 5429\n    base_feature_size = 1433\n    if subject_as_feature:\n        feature_size = (base_feature_size + 7)\n    else:\n        feature_size = base_feature_size\n    assert (g.nodes().dtype == np.int64)\n    assert (g.is_directed() == is_directed)\n    assert (g.number_of_nodes() == expected_nodes)\n    assert (g.number_of_edges() == expected_edges)\n    assert (g.node_feature_sizes() == {'paper': feature_size})\n    assert (len(subjects) == g.number_of_nodes())\n    assert (set(subjects.index) == set(g.nodes()))\n    assert (set(subjects) == {'Case_Based', 'Genetic_Algorithms', 'Neural_Networks', 'Probabilistic_Methods', 'Reinforcement_Learning', 'Rule_Learning', 'Theory'})", "masked_code": "@pytest.mark.parametrize('is_directed', [False, True])\n@pytest.mark.parametrize('largest_cc_only', [False, True])\n@pytest.mark.parametrize('subject_as_feature', [False, True])\n@pytest.mark.xfail((sys.platform == 'win32'), reason='FIXME #1698')\ndef test_cora_load(is_directed, largest_cc_only, subject_as_feature) -> None:\n    (g, subjects) = Cora().load(is_directed, largest_cc_only, subject_as_feature)\n    if largest_cc_only:\n        expected_nodes = 2485\n        expected_edges = 5209\n    else:\n        expected_nodes = 2708\n        expected_edges = 5429\n    base_feature_size = 1433\n    if subject_as_feature:\n        feature_size = (base_feature_size + 7)\n    else:\n        feature_size = base_feature_size\n    assert (g.nodes().dtype == np.int64)\n    assert (g.is_directed() == is_directed)\n    assert (g.number_of_nodes() == expected_nodes)\n    assert (g.number_of_edges() == '???')\n    assert (g.node_feature_sizes() == {'paper': feature_size})\n    assert (len(subjects) == g.number_of_nodes())\n    assert (set(subjects.index) == set(g.nodes()))\n    assert (set(subjects) == {'Case_Based', 'Genetic_Algorithms', 'Neural_Networks', 'Probabilistic_Methods', 'Reinforcement_Learning', 'Rule_Learning', 'Theory'})", "ground_truth": "expected_edges", "quality_analysis": {"complexity_score": 4, "left_complexity": 3, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_469", "reponame": "stellargraph", "testpath": "tests/datasets/test_datasets.py", "testname": "test_datasets.py", "classname": null, "funcname": "test_cora_load", "imports": ["import pytest", "import tempfile", "import os", "import sys", "import numpy as np", "from stellargraph.datasets import *", "from urllib.error import URLError", "from stellargraph.datasets.dataset_loader import DatasetLoader", "from urllib.request import urlretrieve", "from unittest.mock import patch"], "code": "@pytest.mark.parametrize('is_directed', [False, True])\n@pytest.mark.parametrize('largest_cc_only', [False, True])\n@pytest.mark.parametrize('subject_as_feature', [False, True])\n@pytest.mark.xfail((sys.platform == 'win32'), reason='FIXME #1698')\ndef test_cora_load(is_directed, largest_cc_only, subject_as_feature) -> None:\n    (g, subjects) = Cora().load(is_directed, largest_cc_only, subject_as_feature)\n    if largest_cc_only:\n        expected_nodes = 2485\n        expected_edges = 5209\n    else:\n        expected_nodes = 2708\n        expected_edges = 5429\n    base_feature_size = 1433\n    if subject_as_feature:\n        feature_size = (base_feature_size + 7)\n    else:\n        feature_size = base_feature_size\n    assert (g.nodes().dtype == np.int64)\n    assert (g.is_directed() == is_directed)\n    assert (g.number_of_nodes() == expected_nodes)\n    assert (g.number_of_edges() == expected_edges)\n    assert (g.node_feature_sizes() == {'paper': feature_size})\n    assert (len(subjects) == g.number_of_nodes())\n    assert (set(subjects.index) == set(g.nodes()))\n    assert (set(subjects) == {'Case_Based', 'Genetic_Algorithms', 'Neural_Networks', 'Probabilistic_Methods', 'Reinforcement_Learning', 'Rule_Learning', 'Theory'})", "masked_code": "@pytest.mark.parametrize('is_directed', [False, True])\n@pytest.mark.parametrize('largest_cc_only', [False, True])\n@pytest.mark.parametrize('subject_as_feature', [False, True])\n@pytest.mark.xfail((sys.platform == 'win32'), reason='FIXME #1698')\ndef test_cora_load(is_directed, largest_cc_only, subject_as_feature) -> None:\n    (g, subjects) = Cora().load(is_directed, largest_cc_only, subject_as_feature)\n    if largest_cc_only:\n        expected_nodes = 2485\n        expected_edges = 5209\n    else:\n        expected_nodes = 2708\n        expected_edges = 5429\n    base_feature_size = 1433\n    if subject_as_feature:\n        feature_size = (base_feature_size + 7)\n    else:\n        feature_size = base_feature_size\n    assert (g.nodes().dtype == np.int64)\n    assert (g.is_directed() == is_directed)\n    assert (g.number_of_nodes() == expected_nodes)\n    assert (g.number_of_edges() == expected_edges)\n    assert (g.node_feature_sizes() == '???')\n    assert (len(subjects) == g.number_of_nodes())\n    assert (set(subjects.index) == set(g.nodes()))\n    assert (set(subjects) == {'Case_Based', 'Genetic_Algorithms', 'Neural_Networks', 'Probabilistic_Methods', 'Reinforcement_Learning', 'Rule_Learning', 'Theory'})", "ground_truth": "{'paper': feature_size}", "quality_analysis": {"complexity_score": 8, "left_complexity": 3, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_470", "reponame": "stellargraph", "testpath": "tests/datasets/test_datasets.py", "testname": "test_datasets.py", "classname": null, "funcname": "test_cora_load", "imports": ["import pytest", "import tempfile", "import os", "import sys", "import numpy as np", "from stellargraph.datasets import *", "from urllib.error import URLError", "from stellargraph.datasets.dataset_loader import DatasetLoader", "from urllib.request import urlretrieve", "from unittest.mock import patch"], "code": "@pytest.mark.parametrize('is_directed', [False, True])\n@pytest.mark.parametrize('largest_cc_only', [False, True])\n@pytest.mark.parametrize('subject_as_feature', [False, True])\n@pytest.mark.xfail((sys.platform == 'win32'), reason='FIXME #1698')\ndef test_cora_load(is_directed, largest_cc_only, subject_as_feature) -> None:\n    (g, subjects) = Cora().load(is_directed, largest_cc_only, subject_as_feature)\n    if largest_cc_only:\n        expected_nodes = 2485\n        expected_edges = 5209\n    else:\n        expected_nodes = 2708\n        expected_edges = 5429\n    base_feature_size = 1433\n    if subject_as_feature:\n        feature_size = (base_feature_size + 7)\n    else:\n        feature_size = base_feature_size\n    assert (g.nodes().dtype == np.int64)\n    assert (g.is_directed() == is_directed)\n    assert (g.number_of_nodes() == expected_nodes)\n    assert (g.number_of_edges() == expected_edges)\n    assert (g.node_feature_sizes() == {'paper': feature_size})\n    assert (len(subjects) == g.number_of_nodes())\n    assert (set(subjects.index) == set(g.nodes()))\n    assert (set(subjects) == {'Case_Based', 'Genetic_Algorithms', 'Neural_Networks', 'Probabilistic_Methods', 'Reinforcement_Learning', 'Rule_Learning', 'Theory'})", "masked_code": "@pytest.mark.parametrize('is_directed', [False, True])\n@pytest.mark.parametrize('largest_cc_only', [False, True])\n@pytest.mark.parametrize('subject_as_feature', [False, True])\n@pytest.mark.xfail((sys.platform == 'win32'), reason='FIXME #1698')\ndef test_cora_load(is_directed, largest_cc_only, subject_as_feature) -> None:\n    (g, subjects) = Cora().load(is_directed, largest_cc_only, subject_as_feature)\n    if largest_cc_only:\n        expected_nodes = 2485\n        expected_edges = 5209\n    else:\n        expected_nodes = 2708\n        expected_edges = 5429\n    base_feature_size = 1433\n    if subject_as_feature:\n        feature_size = (base_feature_size + 7)\n    else:\n        feature_size = base_feature_size\n    assert (g.nodes().dtype == np.int64)\n    assert (g.is_directed() == is_directed)\n    assert (g.number_of_nodes() == expected_nodes)\n    assert (g.number_of_edges() == expected_edges)\n    assert (g.node_feature_sizes() == {'paper': feature_size})\n    assert (len(subjects) == '???')\n    assert (set(subjects.index) == set(g.nodes()))\n    assert (set(subjects) == {'Case_Based', 'Genetic_Algorithms', 'Neural_Networks', 'Probabilistic_Methods', 'Reinforcement_Learning', 'Rule_Learning', 'Theory'})", "ground_truth": "g.number_of_nodes()", "quality_analysis": {"complexity_score": 7, "left_complexity": 4, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_471", "reponame": "stellargraph", "testpath": "tests/datasets/test_datasets.py", "testname": "test_datasets.py", "classname": null, "funcname": "test_cora_load", "imports": ["import pytest", "import tempfile", "import os", "import sys", "import numpy as np", "from stellargraph.datasets import *", "from urllib.error import URLError", "from stellargraph.datasets.dataset_loader import DatasetLoader", "from urllib.request import urlretrieve", "from unittest.mock import patch"], "code": "@pytest.mark.parametrize('is_directed', [False, True])\n@pytest.mark.parametrize('largest_cc_only', [False, True])\n@pytest.mark.parametrize('subject_as_feature', [False, True])\n@pytest.mark.xfail((sys.platform == 'win32'), reason='FIXME #1698')\ndef test_cora_load(is_directed, largest_cc_only, subject_as_feature) -> None:\n    (g, subjects) = Cora().load(is_directed, largest_cc_only, subject_as_feature)\n    if largest_cc_only:\n        expected_nodes = 2485\n        expected_edges = 5209\n    else:\n        expected_nodes = 2708\n        expected_edges = 5429\n    base_feature_size = 1433\n    if subject_as_feature:\n        feature_size = (base_feature_size + 7)\n    else:\n        feature_size = base_feature_size\n    assert (g.nodes().dtype == np.int64)\n    assert (g.is_directed() == is_directed)\n    assert (g.number_of_nodes() == expected_nodes)\n    assert (g.number_of_edges() == expected_edges)\n    assert (g.node_feature_sizes() == {'paper': feature_size})\n    assert (len(subjects) == g.number_of_nodes())\n    assert (set(subjects.index) == set(g.nodes()))\n    assert (set(subjects) == {'Case_Based', 'Genetic_Algorithms', 'Neural_Networks', 'Probabilistic_Methods', 'Reinforcement_Learning', 'Rule_Learning', 'Theory'})", "masked_code": "@pytest.mark.parametrize('is_directed', [False, True])\n@pytest.mark.parametrize('largest_cc_only', [False, True])\n@pytest.mark.parametrize('subject_as_feature', [False, True])\n@pytest.mark.xfail((sys.platform == 'win32'), reason='FIXME #1698')\ndef test_cora_load(is_directed, largest_cc_only, subject_as_feature) -> None:\n    (g, subjects) = Cora().load(is_directed, largest_cc_only, subject_as_feature)\n    if largest_cc_only:\n        expected_nodes = 2485\n        expected_edges = 5209\n    else:\n        expected_nodes = 2708\n        expected_edges = 5429\n    base_feature_size = 1433\n    if subject_as_feature:\n        feature_size = (base_feature_size + 7)\n    else:\n        feature_size = base_feature_size\n    assert (g.nodes().dtype == np.int64)\n    assert (g.is_directed() == is_directed)\n    assert (g.number_of_nodes() == expected_nodes)\n    assert (g.number_of_edges() == expected_edges)\n    assert (g.node_feature_sizes() == {'paper': feature_size})\n    assert (len(subjects) == g.number_of_nodes())\n    assert (set(subjects.index) == '???')\n    assert (set(subjects) == {'Case_Based', 'Genetic_Algorithms', 'Neural_Networks', 'Probabilistic_Methods', 'Reinforcement_Learning', 'Rule_Learning', 'Theory'})", "ground_truth": "set(g.nodes())", "quality_analysis": {"complexity_score": 11, "left_complexity": 5, "right_complexity": 6, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_472", "reponame": "stellargraph", "testpath": "tests/datasets/test_datasets.py", "testname": "test_datasets.py", "classname": null, "funcname": "test_cora_load", "imports": ["import pytest", "import tempfile", "import os", "import sys", "import numpy as np", "from stellargraph.datasets import *", "from urllib.error import URLError", "from stellargraph.datasets.dataset_loader import DatasetLoader", "from urllib.request import urlretrieve", "from unittest.mock import patch"], "code": "@pytest.mark.parametrize('is_directed', [False, True])\n@pytest.mark.parametrize('largest_cc_only', [False, True])\n@pytest.mark.parametrize('subject_as_feature', [False, True])\n@pytest.mark.xfail((sys.platform == 'win32'), reason='FIXME #1698')\ndef test_cora_load(is_directed, largest_cc_only, subject_as_feature) -> None:\n    (g, subjects) = Cora().load(is_directed, largest_cc_only, subject_as_feature)\n    if largest_cc_only:\n        expected_nodes = 2485\n        expected_edges = 5209\n    else:\n        expected_nodes = 2708\n        expected_edges = 5429\n    base_feature_size = 1433\n    if subject_as_feature:\n        feature_size = (base_feature_size + 7)\n    else:\n        feature_size = base_feature_size\n    assert (g.nodes().dtype == np.int64)\n    assert (g.is_directed() == is_directed)\n    assert (g.number_of_nodes() == expected_nodes)\n    assert (g.number_of_edges() == expected_edges)\n    assert (g.node_feature_sizes() == {'paper': feature_size})\n    assert (len(subjects) == g.number_of_nodes())\n    assert (set(subjects.index) == set(g.nodes()))\n    assert (set(subjects) == {'Case_Based', 'Genetic_Algorithms', 'Neural_Networks', 'Probabilistic_Methods', 'Reinforcement_Learning', 'Rule_Learning', 'Theory'})", "masked_code": "@pytest.mark.parametrize('is_directed', [False, True])\n@pytest.mark.parametrize('largest_cc_only', [False, True])\n@pytest.mark.parametrize('subject_as_feature', [False, True])\n@pytest.mark.xfail((sys.platform == 'win32'), reason='FIXME #1698')\ndef test_cora_load(is_directed, largest_cc_only, subject_as_feature) -> None:\n    (g, subjects) = Cora().load(is_directed, largest_cc_only, subject_as_feature)\n    if largest_cc_only:\n        expected_nodes = 2485\n        expected_edges = 5209\n    else:\n        expected_nodes = 2708\n        expected_edges = 5429\n    base_feature_size = 1433\n    if subject_as_feature:\n        feature_size = (base_feature_size + 7)\n    else:\n        feature_size = base_feature_size\n    assert (g.nodes().dtype == np.int64)\n    assert (g.is_directed() == is_directed)\n    assert (g.number_of_nodes() == expected_nodes)\n    assert (g.number_of_edges() == expected_edges)\n    assert (g.node_feature_sizes() == {'paper': feature_size})\n    assert (len(subjects) == g.number_of_nodes())\n    assert (set(subjects.index) == set(g.nodes()))\n    assert (set(subjects) == '???')", "ground_truth": "{'Case_Based', 'Genetic_Algorithms', 'Neural_Networks', 'Probabilistic_Methods', 'Reinforcement_Learning', 'Rule_Learning', 'Theory'}", "quality_analysis": {"complexity_score": 4, "left_complexity": 4, "right_complexity": 0, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_473", "reponame": "stellargraph", "testpath": "tests/datasets/test_datasets.py", "testname": "test_datasets.py", "classname": null, "funcname": "test_cora_load_str", "imports": ["import pytest", "import tempfile", "import os", "import sys", "import numpy as np", "from stellargraph.datasets import *", "from urllib.error import URLError", "from stellargraph.datasets.dataset_loader import DatasetLoader", "from urllib.request import urlretrieve", "from unittest.mock import patch"], "code": "def test_cora_load_str() -> None:\n    (g, subjects) = Cora().load(str_node_ids=True)\n    assert (type(g.nodes()[0]) == str)\n    assert all(((type(n) == str) for n in g.nodes()))\n    assert (set(subjects.index) == set(g.nodes()))", "masked_code": "def test_cora_load_str() -> None:\n    (g, subjects) = Cora().load(str_node_ids=True)\n    assert (type(g.nodes()[0]) == '???')\n    assert all(((type(n) == str) for n in g.nodes()))\n    assert (set(subjects.index) == set(g.nodes()))", "ground_truth": "str", "quality_analysis": {"complexity_score": 11, "left_complexity": 10, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_474", "reponame": "stellargraph", "testpath": "tests/datasets/test_datasets.py", "testname": "test_datasets.py", "classname": null, "funcname": "test_cora_load_str", "imports": ["import pytest", "import tempfile", "import os", "import sys", "import numpy as np", "from stellargraph.datasets import *", "from urllib.error import URLError", "from stellargraph.datasets.dataset_loader import DatasetLoader", "from urllib.request import urlretrieve", "from unittest.mock import patch"], "code": "def test_cora_load_str() -> None:\n    (g, subjects) = Cora().load(str_node_ids=True)\n    assert (type(g.nodes()[0]) == str)\n    assert all(((type(n) == str) for n in g.nodes()))\n    assert (set(subjects.index) == set(g.nodes()))", "masked_code": "def test_cora_load_str() -> None:\n    (g, subjects) = Cora().load(str_node_ids=True)\n    assert (type(g.nodes()[0]) == str)\n    assert all(((type(n) == str) for n in g.nodes()))\n    assert (set(subjects.index) == '???')", "ground_truth": "set(g.nodes())", "quality_analysis": {"complexity_score": 11, "left_complexity": 5, "right_complexity": 6, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_475", "reponame": "stellargraph", "testpath": "tests/datasets/test_datasets.py", "testname": "test_datasets.py", "classname": null, "funcname": "test_aifb_load", "imports": ["import pytest", "import tempfile", "import os", "import sys", "import numpy as np", "from stellargraph.datasets import *", "from urllib.error import URLError", "from stellargraph.datasets.dataset_loader import DatasetLoader", "from urllib.request import urlretrieve", "from unittest.mock import patch"], "code": "def test_aifb_load() -> None:\n    (g, affiliation) = AIFB().load()\n    assert (g.number_of_nodes() == 8285)\n    assert (g.number_of_edges() == 29043)\n    assert (len(set((et for (_, _, et) in g.edges(include_edge_type=True)))) == (47 - 2))\n    assert (g.node_feature_sizes() == {'default': 8285})\n    assert (len(affiliation) == 178)", "masked_code": "def test_aifb_load() -> None:\n    (g, affiliation) = AIFB().load()\n    assert (g.number_of_nodes() == '???')\n    assert (g.number_of_edges() == 29043)\n    assert (len(set((et for (_, _, et) in g.edges(include_edge_type=True)))) == (47 - 2))\n    assert (g.node_feature_sizes() == {'default': 8285})\n    assert (len(affiliation) == 178)", "ground_truth": "8285", "quality_analysis": {"complexity_score": 4, "left_complexity": 3, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_476", "reponame": "stellargraph", "testpath": "tests/datasets/test_datasets.py", "testname": "test_datasets.py", "classname": null, "funcname": "test_aifb_load", "imports": ["import pytest", "import tempfile", "import os", "import sys", "import numpy as np", "from stellargraph.datasets import *", "from urllib.error import URLError", "from stellargraph.datasets.dataset_loader import DatasetLoader", "from urllib.request import urlretrieve", "from unittest.mock import patch"], "code": "def test_aifb_load() -> None:\n    (g, affiliation) = AIFB().load()\n    assert (g.number_of_nodes() == 8285)\n    assert (g.number_of_edges() == 29043)\n    assert (len(set((et for (_, _, et) in g.edges(include_edge_type=True)))) == (47 - 2))\n    assert (g.node_feature_sizes() == {'default': 8285})\n    assert (len(affiliation) == 178)", "masked_code": "def test_aifb_load() -> None:\n    (g, affiliation) = AIFB().load()\n    assert (g.number_of_nodes() == 8285)\n    assert (g.number_of_edges() == '???')\n    assert (len(set((et for (_, _, et) in g.edges(include_edge_type=True)))) == (47 - 2))\n    assert (g.node_feature_sizes() == {'default': 8285})\n    assert (len(affiliation) == 178)", "ground_truth": "29043", "quality_analysis": {"complexity_score": 4, "left_complexity": 3, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_477", "reponame": "stellargraph", "testpath": "tests/datasets/test_datasets.py", "testname": "test_datasets.py", "classname": null, "funcname": "test_aifb_load", "imports": ["import pytest", "import tempfile", "import os", "import sys", "import numpy as np", "from stellargraph.datasets import *", "from urllib.error import URLError", "from stellargraph.datasets.dataset_loader import DatasetLoader", "from urllib.request import urlretrieve", "from unittest.mock import patch"], "code": "def test_aifb_load() -> None:\n    (g, affiliation) = AIFB().load()\n    assert (g.number_of_nodes() == 8285)\n    assert (g.number_of_edges() == 29043)\n    assert (len(set((et for (_, _, et) in g.edges(include_edge_type=True)))) == (47 - 2))\n    assert (g.node_feature_sizes() == {'default': 8285})\n    assert (len(affiliation) == 178)", "masked_code": "def test_aifb_load() -> None:\n    (g, affiliation) = AIFB().load()\n    assert (g.number_of_nodes() == 8285)\n    assert (g.number_of_edges() == 29043)\n    assert (len(set((et for (_, _, et) in g.edges(include_edge_type=True)))) == '???')\n    assert (g.node_feature_sizes() == {'default': 8285})\n    assert (len(affiliation) == 178)", "ground_truth": "(47 - 2)", "quality_analysis": {"complexity_score": 10, "left_complexity": 6, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_478", "reponame": "stellargraph", "testpath": "tests/datasets/test_datasets.py", "testname": "test_datasets.py", "classname": null, "funcname": "test_aifb_load", "imports": ["import pytest", "import tempfile", "import os", "import sys", "import numpy as np", "from stellargraph.datasets import *", "from urllib.error import URLError", "from stellargraph.datasets.dataset_loader import DatasetLoader", "from urllib.request import urlretrieve", "from unittest.mock import patch"], "code": "def test_aifb_load() -> None:\n    (g, affiliation) = AIFB().load()\n    assert (g.number_of_nodes() == 8285)\n    assert (g.number_of_edges() == 29043)\n    assert (len(set((et for (_, _, et) in g.edges(include_edge_type=True)))) == (47 - 2))\n    assert (g.node_feature_sizes() == {'default': 8285})\n    assert (len(affiliation) == 178)", "masked_code": "def test_aifb_load() -> None:\n    (g, affiliation) = AIFB().load()\n    assert (g.number_of_nodes() == 8285)\n    assert (g.number_of_edges() == 29043)\n    assert (len(set((et for (_, _, et) in g.edges(include_edge_type=True)))) == (47 - 2))\n    assert (g.node_feature_sizes() == '???')\n    assert (len(affiliation) == 178)", "ground_truth": "{'default': 8285}", "quality_analysis": {"complexity_score": 8, "left_complexity": 3, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_479", "reponame": "stellargraph", "testpath": "tests/datasets/test_datasets.py", "testname": "test_datasets.py", "classname": null, "funcname": "test_aifb_load", "imports": ["import pytest", "import tempfile", "import os", "import sys", "import numpy as np", "from stellargraph.datasets import *", "from urllib.error import URLError", "from stellargraph.datasets.dataset_loader import DatasetLoader", "from urllib.request import urlretrieve", "from unittest.mock import patch"], "code": "def test_aifb_load() -> None:\n    (g, affiliation) = AIFB().load()\n    assert (g.number_of_nodes() == 8285)\n    assert (g.number_of_edges() == 29043)\n    assert (len(set((et for (_, _, et) in g.edges(include_edge_type=True)))) == (47 - 2))\n    assert (g.node_feature_sizes() == {'default': 8285})\n    assert (len(affiliation) == 178)", "masked_code": "def test_aifb_load() -> None:\n    (g, affiliation) = AIFB().load()\n    assert (g.number_of_nodes() == 8285)\n    assert (g.number_of_edges() == 29043)\n    assert (len(set((et for (_, _, et) in g.edges(include_edge_type=True)))) == (47 - 2))\n    assert (g.node_feature_sizes() == {'default': 8285})\n    assert (len(affiliation) == '???')", "ground_truth": "178", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_480", "reponame": "stellargraph", "testpath": "tests/datasets/test_datasets.py", "testname": "test_datasets.py", "classname": null, "funcname": "test_citeseer_load", "imports": ["import pytest", "import tempfile", "import os", "import sys", "import numpy as np", "from stellargraph.datasets import *", "from urllib.error import URLError", "from stellargraph.datasets.dataset_loader import DatasetLoader", "from urllib.request import urlretrieve", "from unittest.mock import patch"], "code": "@pytest.mark.parametrize('largest_cc_only', [False, True])\ndef test_citeseer_load(largest_cc_only) -> None:\n    (g, subjects) = CiteSeer().load(largest_cc_only)\n    if largest_cc_only:\n        expected_nodes = 2110\n        expected_edges = 3757\n    else:\n        expected_nodes = 3312\n        expected_edges = 4715\n    assert (g.number_of_nodes() == expected_nodes)\n    assert (g.number_of_edges() == expected_edges)\n    assert (len(subjects) == g.number_of_nodes())\n    assert (set(subjects.index) == set(g.nodes()))\n    assert (set(subjects) == {'AI', 'Agents', 'DB', 'HCI', 'IR', 'ML'})", "masked_code": "@pytest.mark.parametrize('largest_cc_only', [False, True])\ndef test_citeseer_load(largest_cc_only) -> None:\n    (g, subjects) = CiteSeer().load(largest_cc_only)\n    if largest_cc_only:\n        expected_nodes = 2110\n        expected_edges = 3757\n    else:\n        expected_nodes = 3312\n        expected_edges = 4715\n    assert (g.number_of_nodes() == '???')\n    assert (g.number_of_edges() == expected_edges)\n    assert (len(subjects) == g.number_of_nodes())\n    assert (set(subjects.index) == set(g.nodes()))\n    assert (set(subjects) == {'AI', 'Agents', 'DB', 'HCI', 'IR', 'ML'})", "ground_truth": "expected_nodes", "quality_analysis": {"complexity_score": 4, "left_complexity": 3, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_481", "reponame": "stellargraph", "testpath": "tests/datasets/test_datasets.py", "testname": "test_datasets.py", "classname": null, "funcname": "test_citeseer_load", "imports": ["import pytest", "import tempfile", "import os", "import sys", "import numpy as np", "from stellargraph.datasets import *", "from urllib.error import URLError", "from stellargraph.datasets.dataset_loader import DatasetLoader", "from urllib.request import urlretrieve", "from unittest.mock import patch"], "code": "@pytest.mark.parametrize('largest_cc_only', [False, True])\ndef test_citeseer_load(largest_cc_only) -> None:\n    (g, subjects) = CiteSeer().load(largest_cc_only)\n    if largest_cc_only:\n        expected_nodes = 2110\n        expected_edges = 3757\n    else:\n        expected_nodes = 3312\n        expected_edges = 4715\n    assert (g.number_of_nodes() == expected_nodes)\n    assert (g.number_of_edges() == expected_edges)\n    assert (len(subjects) == g.number_of_nodes())\n    assert (set(subjects.index) == set(g.nodes()))\n    assert (set(subjects) == {'AI', 'Agents', 'DB', 'HCI', 'IR', 'ML'})", "masked_code": "@pytest.mark.parametrize('largest_cc_only', [False, True])\ndef test_citeseer_load(largest_cc_only) -> None:\n    (g, subjects) = CiteSeer().load(largest_cc_only)\n    if largest_cc_only:\n        expected_nodes = 2110\n        expected_edges = 3757\n    else:\n        expected_nodes = 3312\n        expected_edges = 4715\n    assert (g.number_of_nodes() == expected_nodes)\n    assert (g.number_of_edges() == '???')\n    assert (len(subjects) == g.number_of_nodes())\n    assert (set(subjects.index) == set(g.nodes()))\n    assert (set(subjects) == {'AI', 'Agents', 'DB', 'HCI', 'IR', 'ML'})", "ground_truth": "expected_edges", "quality_analysis": {"complexity_score": 4, "left_complexity": 3, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_482", "reponame": "stellargraph", "testpath": "tests/datasets/test_datasets.py", "testname": "test_datasets.py", "classname": null, "funcname": "test_citeseer_load", "imports": ["import pytest", "import tempfile", "import os", "import sys", "import numpy as np", "from stellargraph.datasets import *", "from urllib.error import URLError", "from stellargraph.datasets.dataset_loader import DatasetLoader", "from urllib.request import urlretrieve", "from unittest.mock import patch"], "code": "@pytest.mark.parametrize('largest_cc_only', [False, True])\ndef test_citeseer_load(largest_cc_only) -> None:\n    (g, subjects) = CiteSeer().load(largest_cc_only)\n    if largest_cc_only:\n        expected_nodes = 2110\n        expected_edges = 3757\n    else:\n        expected_nodes = 3312\n        expected_edges = 4715\n    assert (g.number_of_nodes() == expected_nodes)\n    assert (g.number_of_edges() == expected_edges)\n    assert (len(subjects) == g.number_of_nodes())\n    assert (set(subjects.index) == set(g.nodes()))\n    assert (set(subjects) == {'AI', 'Agents', 'DB', 'HCI', 'IR', 'ML'})", "masked_code": "@pytest.mark.parametrize('largest_cc_only', [False, True])\ndef test_citeseer_load(largest_cc_only) -> None:\n    (g, subjects) = CiteSeer().load(largest_cc_only)\n    if largest_cc_only:\n        expected_nodes = 2110\n        expected_edges = 3757\n    else:\n        expected_nodes = 3312\n        expected_edges = 4715\n    assert (g.number_of_nodes() == expected_nodes)\n    assert (g.number_of_edges() == expected_edges)\n    assert (len(subjects) == '???')\n    assert (set(subjects.index) == set(g.nodes()))\n    assert (set(subjects) == {'AI', 'Agents', 'DB', 'HCI', 'IR', 'ML'})", "ground_truth": "g.number_of_nodes()", "quality_analysis": {"complexity_score": 7, "left_complexity": 4, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_483", "reponame": "stellargraph", "testpath": "tests/datasets/test_datasets.py", "testname": "test_datasets.py", "classname": null, "funcname": "test_citeseer_load", "imports": ["import pytest", "import tempfile", "import os", "import sys", "import numpy as np", "from stellargraph.datasets import *", "from urllib.error import URLError", "from stellargraph.datasets.dataset_loader import DatasetLoader", "from urllib.request import urlretrieve", "from unittest.mock import patch"], "code": "@pytest.mark.parametrize('largest_cc_only', [False, True])\ndef test_citeseer_load(largest_cc_only) -> None:\n    (g, subjects) = CiteSeer().load(largest_cc_only)\n    if largest_cc_only:\n        expected_nodes = 2110\n        expected_edges = 3757\n    else:\n        expected_nodes = 3312\n        expected_edges = 4715\n    assert (g.number_of_nodes() == expected_nodes)\n    assert (g.number_of_edges() == expected_edges)\n    assert (len(subjects) == g.number_of_nodes())\n    assert (set(subjects.index) == set(g.nodes()))\n    assert (set(subjects) == {'AI', 'Agents', 'DB', 'HCI', 'IR', 'ML'})", "masked_code": "@pytest.mark.parametrize('largest_cc_only', [False, True])\ndef test_citeseer_load(largest_cc_only) -> None:\n    (g, subjects) = CiteSeer().load(largest_cc_only)\n    if largest_cc_only:\n        expected_nodes = 2110\n        expected_edges = 3757\n    else:\n        expected_nodes = 3312\n        expected_edges = 4715\n    assert (g.number_of_nodes() == expected_nodes)\n    assert (g.number_of_edges() == expected_edges)\n    assert (len(subjects) == g.number_of_nodes())\n    assert (set(subjects.index) == '???')\n    assert (set(subjects) == {'AI', 'Agents', 'DB', 'HCI', 'IR', 'ML'})", "ground_truth": "set(g.nodes())", "quality_analysis": {"complexity_score": 11, "left_complexity": 5, "right_complexity": 6, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_484", "reponame": "stellargraph", "testpath": "tests/datasets/test_datasets.py", "testname": "test_datasets.py", "classname": null, "funcname": "test_citeseer_load", "imports": ["import pytest", "import tempfile", "import os", "import sys", "import numpy as np", "from stellargraph.datasets import *", "from urllib.error import URLError", "from stellargraph.datasets.dataset_loader import DatasetLoader", "from urllib.request import urlretrieve", "from unittest.mock import patch"], "code": "@pytest.mark.parametrize('largest_cc_only', [False, True])\ndef test_citeseer_load(largest_cc_only) -> None:\n    (g, subjects) = CiteSeer().load(largest_cc_only)\n    if largest_cc_only:\n        expected_nodes = 2110\n        expected_edges = 3757\n    else:\n        expected_nodes = 3312\n        expected_edges = 4715\n    assert (g.number_of_nodes() == expected_nodes)\n    assert (g.number_of_edges() == expected_edges)\n    assert (len(subjects) == g.number_of_nodes())\n    assert (set(subjects.index) == set(g.nodes()))\n    assert (set(subjects) == {'AI', 'Agents', 'DB', 'HCI', 'IR', 'ML'})", "masked_code": "@pytest.mark.parametrize('largest_cc_only', [False, True])\ndef test_citeseer_load(largest_cc_only) -> None:\n    (g, subjects) = CiteSeer().load(largest_cc_only)\n    if largest_cc_only:\n        expected_nodes = 2110\n        expected_edges = 3757\n    else:\n        expected_nodes = 3312\n        expected_edges = 4715\n    assert (g.number_of_nodes() == expected_nodes)\n    assert (g.number_of_edges() == expected_edges)\n    assert (len(subjects) == g.number_of_nodes())\n    assert (set(subjects.index) == set(g.nodes()))\n    assert (set(subjects) == '???')", "ground_truth": "{'AI', 'Agents', 'DB', 'HCI', 'IR', 'ML'}", "quality_analysis": {"complexity_score": 4, "left_complexity": 4, "right_complexity": 0, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_485", "reponame": "stellargraph", "testpath": "tests/datasets/test_datasets.py", "testname": "test_datasets.py", "classname": null, "funcname": "test_pubmeddiabetes_load", "imports": ["import pytest", "import tempfile", "import os", "import sys", "import numpy as np", "from stellargraph.datasets import *", "from urllib.error import URLError", "from stellargraph.datasets.dataset_loader import DatasetLoader", "from urllib.request import urlretrieve", "from unittest.mock import patch"], "code": "def test_pubmeddiabetes_load() -> None:\n    (g, labels) = PubMedDiabetes().load()\n    n_nodes = 19717\n    assert (g.number_of_nodes() == n_nodes)\n    assert (g.number_of_edges() == 44338)\n    assert (g.node_feature_sizes() == {'paper': 500})\n    assert (len(labels) == n_nodes)\n    assert (set(labels.index) == set(g.nodes()))", "masked_code": "def test_pubmeddiabetes_load() -> None:\n    (g, labels) = PubMedDiabetes().load()\n    n_nodes = 19717\n    assert (g.number_of_nodes() == '???')\n    assert (g.number_of_edges() == 44338)\n    assert (g.node_feature_sizes() == {'paper': 500})\n    assert (len(labels) == n_nodes)\n    assert (set(labels.index) == set(g.nodes()))", "ground_truth": "n_nodes", "quality_analysis": {"complexity_score": 4, "left_complexity": 3, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_486", "reponame": "stellargraph", "testpath": "tests/datasets/test_datasets.py", "testname": "test_datasets.py", "classname": null, "funcname": "test_pubmeddiabetes_load", "imports": ["import pytest", "import tempfile", "import os", "import sys", "import numpy as np", "from stellargraph.datasets import *", "from urllib.error import URLError", "from stellargraph.datasets.dataset_loader import DatasetLoader", "from urllib.request import urlretrieve", "from unittest.mock import patch"], "code": "def test_pubmeddiabetes_load() -> None:\n    (g, labels) = PubMedDiabetes().load()\n    n_nodes = 19717\n    assert (g.number_of_nodes() == n_nodes)\n    assert (g.number_of_edges() == 44338)\n    assert (g.node_feature_sizes() == {'paper': 500})\n    assert (len(labels) == n_nodes)\n    assert (set(labels.index) == set(g.nodes()))", "masked_code": "def test_pubmeddiabetes_load() -> None:\n    (g, labels) = PubMedDiabetes().load()\n    n_nodes = 19717\n    assert (g.number_of_nodes() == n_nodes)\n    assert (g.number_of_edges() == '???')\n    assert (g.node_feature_sizes() == {'paper': 500})\n    assert (len(labels) == n_nodes)\n    assert (set(labels.index) == set(g.nodes()))", "ground_truth": "44338", "quality_analysis": {"complexity_score": 4, "left_complexity": 3, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_487", "reponame": "stellargraph", "testpath": "tests/datasets/test_datasets.py", "testname": "test_datasets.py", "classname": null, "funcname": "test_pubmeddiabetes_load", "imports": ["import pytest", "import tempfile", "import os", "import sys", "import numpy as np", "from stellargraph.datasets import *", "from urllib.error import URLError", "from stellargraph.datasets.dataset_loader import DatasetLoader", "from urllib.request import urlretrieve", "from unittest.mock import patch"], "code": "def test_pubmeddiabetes_load() -> None:\n    (g, labels) = PubMedDiabetes().load()\n    n_nodes = 19717\n    assert (g.number_of_nodes() == n_nodes)\n    assert (g.number_of_edges() == 44338)\n    assert (g.node_feature_sizes() == {'paper': 500})\n    assert (len(labels) == n_nodes)\n    assert (set(labels.index) == set(g.nodes()))", "masked_code": "def test_pubmeddiabetes_load() -> None:\n    (g, labels) = PubMedDiabetes().load()\n    n_nodes = 19717\n    assert (g.number_of_nodes() == n_nodes)\n    assert (g.number_of_edges() == 44338)\n    assert (g.node_feature_sizes() == '???')\n    assert (len(labels) == n_nodes)\n    assert (set(labels.index) == set(g.nodes()))", "ground_truth": "{'paper': 500}", "quality_analysis": {"complexity_score": 8, "left_complexity": 3, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_488", "reponame": "stellargraph", "testpath": "tests/datasets/test_datasets.py", "testname": "test_datasets.py", "classname": null, "funcname": "test_pubmeddiabetes_load", "imports": ["import pytest", "import tempfile", "import os", "import sys", "import numpy as np", "from stellargraph.datasets import *", "from urllib.error import URLError", "from stellargraph.datasets.dataset_loader import DatasetLoader", "from urllib.request import urlretrieve", "from unittest.mock import patch"], "code": "def test_pubmeddiabetes_load() -> None:\n    (g, labels) = PubMedDiabetes().load()\n    n_nodes = 19717\n    assert (g.number_of_nodes() == n_nodes)\n    assert (g.number_of_edges() == 44338)\n    assert (g.node_feature_sizes() == {'paper': 500})\n    assert (len(labels) == n_nodes)\n    assert (set(labels.index) == set(g.nodes()))", "masked_code": "def test_pubmeddiabetes_load() -> None:\n    (g, labels) = PubMedDiabetes().load()\n    n_nodes = 19717\n    assert (g.number_of_nodes() == n_nodes)\n    assert (g.number_of_edges() == 44338)\n    assert (g.node_feature_sizes() == {'paper': 500})\n    assert (len(labels) == '???')\n    assert (set(labels.index) == set(g.nodes()))", "ground_truth": "n_nodes", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_489", "reponame": "stellargraph", "testpath": "tests/datasets/test_datasets.py", "testname": "test_datasets.py", "classname": null, "funcname": "test_pubmeddiabetes_load", "imports": ["import pytest", "import tempfile", "import os", "import sys", "import numpy as np", "from stellargraph.datasets import *", "from urllib.error import URLError", "from stellargraph.datasets.dataset_loader import DatasetLoader", "from urllib.request import urlretrieve", "from unittest.mock import patch"], "code": "def test_pubmeddiabetes_load() -> None:\n    (g, labels) = PubMedDiabetes().load()\n    n_nodes = 19717\n    assert (g.number_of_nodes() == n_nodes)\n    assert (g.number_of_edges() == 44338)\n    assert (g.node_feature_sizes() == {'paper': 500})\n    assert (len(labels) == n_nodes)\n    assert (set(labels.index) == set(g.nodes()))", "masked_code": "def test_pubmeddiabetes_load() -> None:\n    (g, labels) = PubMedDiabetes().load()\n    n_nodes = 19717\n    assert (g.number_of_nodes() == n_nodes)\n    assert (g.number_of_edges() == 44338)\n    assert (g.node_feature_sizes() == {'paper': 500})\n    assert (len(labels) == n_nodes)\n    assert (set(labels.index) == '???')", "ground_truth": "set(g.nodes())", "quality_analysis": {"complexity_score": 11, "left_complexity": 5, "right_complexity": 6, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_490", "reponame": "stellargraph", "testpath": "tests/datasets/test_datasets.py", "testname": "test_datasets.py", "classname": null, "funcname": "test_ia_enron_employees_load", "imports": ["import pytest", "import tempfile", "import os", "import sys", "import numpy as np", "from stellargraph.datasets import *", "from urllib.error import URLError", "from stellargraph.datasets.dataset_loader import DatasetLoader", "from urllib.request import urlretrieve", "from unittest.mock import patch"], "code": "def test_ia_enron_employees_load() -> None:\n    (graph, edges) = IAEnronEmployees().load()\n    n_nodes = 151\n    n_edges = 50572\n    assert (graph.number_of_nodes() == n_nodes)\n    assert (graph.number_of_edges() == n_edges)\n    assert (len(edges) == n_edges)\n    assert (set(edges.columns) == {'source', 'target', 'time'})", "masked_code": "def test_ia_enron_employees_load() -> None:\n    (graph, edges) = IAEnronEmployees().load()\n    n_nodes = 151\n    n_edges = 50572\n    assert (graph.number_of_nodes() == '???')\n    assert (graph.number_of_edges() == n_edges)\n    assert (len(edges) == n_edges)\n    assert (set(edges.columns) == {'source', 'target', 'time'})", "ground_truth": "n_nodes", "quality_analysis": {"complexity_score": 4, "left_complexity": 3, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_491", "reponame": "stellargraph", "testpath": "tests/datasets/test_datasets.py", "testname": "test_datasets.py", "classname": null, "funcname": "test_ia_enron_employees_load", "imports": ["import pytest", "import tempfile", "import os", "import sys", "import numpy as np", "from stellargraph.datasets import *", "from urllib.error import URLError", "from stellargraph.datasets.dataset_loader import DatasetLoader", "from urllib.request import urlretrieve", "from unittest.mock import patch"], "code": "def test_ia_enron_employees_load() -> None:\n    (graph, edges) = IAEnronEmployees().load()\n    n_nodes = 151\n    n_edges = 50572\n    assert (graph.number_of_nodes() == n_nodes)\n    assert (graph.number_of_edges() == n_edges)\n    assert (len(edges) == n_edges)\n    assert (set(edges.columns) == {'source', 'target', 'time'})", "masked_code": "def test_ia_enron_employees_load() -> None:\n    (graph, edges) = IAEnronEmployees().load()\n    n_nodes = 151\n    n_edges = 50572\n    assert (graph.number_of_nodes() == n_nodes)\n    assert (graph.number_of_edges() == '???')\n    assert (len(edges) == n_edges)\n    assert (set(edges.columns) == {'source', 'target', 'time'})", "ground_truth": "n_edges", "quality_analysis": {"complexity_score": 4, "left_complexity": 3, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_492", "reponame": "stellargraph", "testpath": "tests/datasets/test_datasets.py", "testname": "test_datasets.py", "classname": null, "funcname": "test_ia_enron_employees_load", "imports": ["import pytest", "import tempfile", "import os", "import sys", "import numpy as np", "from stellargraph.datasets import *", "from urllib.error import URLError", "from stellargraph.datasets.dataset_loader import DatasetLoader", "from urllib.request import urlretrieve", "from unittest.mock import patch"], "code": "def test_ia_enron_employees_load() -> None:\n    (graph, edges) = IAEnronEmployees().load()\n    n_nodes = 151\n    n_edges = 50572\n    assert (graph.number_of_nodes() == n_nodes)\n    assert (graph.number_of_edges() == n_edges)\n    assert (len(edges) == n_edges)\n    assert (set(edges.columns) == {'source', 'target', 'time'})", "masked_code": "def test_ia_enron_employees_load() -> None:\n    (graph, edges) = IAEnronEmployees().load()\n    n_nodes = 151\n    n_edges = 50572\n    assert (graph.number_of_nodes() == n_nodes)\n    assert (graph.number_of_edges() == n_edges)\n    assert (len(edges) == '???')\n    assert (set(edges.columns) == {'source', 'target', 'time'})", "ground_truth": "n_edges", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_493", "reponame": "stellargraph", "testpath": "tests/datasets/test_datasets.py", "testname": "test_datasets.py", "classname": null, "funcname": "test_ia_enron_employees_load", "imports": ["import pytest", "import tempfile", "import os", "import sys", "import numpy as np", "from stellargraph.datasets import *", "from urllib.error import URLError", "from stellargraph.datasets.dataset_loader import DatasetLoader", "from urllib.request import urlretrieve", "from unittest.mock import patch"], "code": "def test_ia_enron_employees_load() -> None:\n    (graph, edges) = IAEnronEmployees().load()\n    n_nodes = 151\n    n_edges = 50572\n    assert (graph.number_of_nodes() == n_nodes)\n    assert (graph.number_of_edges() == n_edges)\n    assert (len(edges) == n_edges)\n    assert (set(edges.columns) == {'source', 'target', 'time'})", "masked_code": "def test_ia_enron_employees_load() -> None:\n    (graph, edges) = IAEnronEmployees().load()\n    n_nodes = 151\n    n_edges = 50572\n    assert (graph.number_of_nodes() == n_nodes)\n    assert (graph.number_of_edges() == n_edges)\n    assert (len(edges) == n_edges)\n    assert (set(edges.columns) == '???')", "ground_truth": "{'source', 'target', 'time'}", "quality_analysis": {"complexity_score": 5, "left_complexity": 5, "right_complexity": 0, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_494", "reponame": "stellargraph", "testpath": "tests/layer/test_appnp.py", "testname": "test_appnp.py", "classname": null, "funcname": "test_APPNP_edge_cases", "imports": ["from stellargraph.layer.appnp import *", "from stellargraph.mapper import FullBatchNodeGenerator, FullBatchLinkGenerator", "from stellargraph import StellarGraph", "from stellargraph.core.utils import GCN_Aadj_feats_op", "import networkx as nx", "import pandas as pd", "import numpy as np", "from tensorflow import keras", "import pytest", "from ..test_utils.graphs import create_graph_features", "from .. import test_utils"], "code": "def test_APPNP_edge_cases():\n    (G, features) = create_graph_features()\n    generator = FullBatchNodeGenerator(G, sparse=False, method='gcn')\n    try:\n        appnpModel = APPNP([2, 2], generator=generator, activations=['relu'], dropout=0.5)\n    except ValueError as e:\n        error = e\n    assert (str(error) == 'The number of layers should equal the number of activations')\n    try:\n        appnpModel = APPNP([2], generator=[0, 1], activations=['relu'], dropout=0.5)\n    except TypeError as e:\n        error = e\n    assert (str(error) == f'Generator should be a instance of FullBatchNodeGenerator, FullBatchLinkGenerator or ClusterNodeGenerator')\n    try:\n        appnpModel = APPNP([2], generator=generator, activations=['relu'], dropout=0.0, approx_iter=(- 1))\n    except ValueError as e:\n        error = e\n    assert (str(error) == 'approx_iter should be a positive integer')\n    try:\n        appnpModel = APPNP([2], generator=generator, activations=['relu'], dropout=0.0, approx_iter=1.2)\n    except ValueError as e:\n        error = e\n    assert (str(error) == 'approx_iter should be a positive integer')\n    try:\n        appnpModel = APPNP([2], generator=generator, activations=['relu'], dropout=0.0, teleport_probability=1.2)\n    except ValueError as e:\n        error = e\n    assert (str(error) == 'teleport_probability should be between 0 and 1 (inclusive)')\n    try:\n        appnpModel = APPNP([2], generator=generator, activations=['relu'], dropout=0.0, teleport_probability=1.2)\n    except ValueError as e:\n        error = e\n    assert (str(error) == 'teleport_probability should be between 0 and 1 (inclusive)')", "masked_code": "def test_APPNP_edge_cases():\n    (G, features) = create_graph_features()\n    generator = FullBatchNodeGenerator(G, sparse=False, method='gcn')\n    try:\n        appnpModel = APPNP([2, 2], generator=generator, activations=['relu'], dropout=0.5)\n    except ValueError as e:\n        error = e\n    assert (str(error) == '???')\n    try:\n        appnpModel = APPNP([2], generator=[0, 1], activations=['relu'], dropout=0.5)\n    except TypeError as e:\n        error = e\n    assert (str(error) == f'Generator should be a instance of FullBatchNodeGenerator, FullBatchLinkGenerator or ClusterNodeGenerator')\n    try:\n        appnpModel = APPNP([2], generator=generator, activations=['relu'], dropout=0.0, approx_iter=(- 1))\n    except ValueError as e:\n        error = e\n    assert (str(error) == 'approx_iter should be a positive integer')\n    try:\n        appnpModel = APPNP([2], generator=generator, activations=['relu'], dropout=0.0, approx_iter=1.2)\n    except ValueError as e:\n        error = e\n    assert (str(error) == 'approx_iter should be a positive integer')\n    try:\n        appnpModel = APPNP([2], generator=generator, activations=['relu'], dropout=0.0, teleport_probability=1.2)\n    except ValueError as e:\n        error = e\n    assert (str(error) == 'teleport_probability should be between 0 and 1 (inclusive)')\n    try:\n        appnpModel = APPNP([2], generator=generator, activations=['relu'], dropout=0.0, teleport_probability=1.2)\n    except ValueError as e:\n        error = e\n    assert (str(error) == 'teleport_probability should be between 0 and 1 (inclusive)')", "ground_truth": "'The number of layers should equal the number of activations'", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_495", "reponame": "stellargraph", "testpath": "tests/layer/test_appnp.py", "testname": "test_appnp.py", "classname": null, "funcname": "test_APPNP_edge_cases", "imports": ["from stellargraph.layer.appnp import *", "from stellargraph.mapper import FullBatchNodeGenerator, FullBatchLinkGenerator", "from stellargraph import StellarGraph", "from stellargraph.core.utils import GCN_Aadj_feats_op", "import networkx as nx", "import pandas as pd", "import numpy as np", "from tensorflow import keras", "import pytest", "from ..test_utils.graphs import create_graph_features", "from .. import test_utils"], "code": "def test_APPNP_edge_cases():\n    (G, features) = create_graph_features()\n    generator = FullBatchNodeGenerator(G, sparse=False, method='gcn')\n    try:\n        appnpModel = APPNP([2, 2], generator=generator, activations=['relu'], dropout=0.5)\n    except ValueError as e:\n        error = e\n    assert (str(error) == 'The number of layers should equal the number of activations')\n    try:\n        appnpModel = APPNP([2], generator=[0, 1], activations=['relu'], dropout=0.5)\n    except TypeError as e:\n        error = e\n    assert (str(error) == f'Generator should be a instance of FullBatchNodeGenerator, FullBatchLinkGenerator or ClusterNodeGenerator')\n    try:\n        appnpModel = APPNP([2], generator=generator, activations=['relu'], dropout=0.0, approx_iter=(- 1))\n    except ValueError as e:\n        error = e\n    assert (str(error) == 'approx_iter should be a positive integer')\n    try:\n        appnpModel = APPNP([2], generator=generator, activations=['relu'], dropout=0.0, approx_iter=1.2)\n    except ValueError as e:\n        error = e\n    assert (str(error) == 'approx_iter should be a positive integer')\n    try:\n        appnpModel = APPNP([2], generator=generator, activations=['relu'], dropout=0.0, teleport_probability=1.2)\n    except ValueError as e:\n        error = e\n    assert (str(error) == 'teleport_probability should be between 0 and 1 (inclusive)')\n    try:\n        appnpModel = APPNP([2], generator=generator, activations=['relu'], dropout=0.0, teleport_probability=1.2)\n    except ValueError as e:\n        error = e\n    assert (str(error) == 'teleport_probability should be between 0 and 1 (inclusive)')", "masked_code": "def test_APPNP_edge_cases():\n    (G, features) = create_graph_features()\n    generator = FullBatchNodeGenerator(G, sparse=False, method='gcn')\n    try:\n        appnpModel = APPNP([2, 2], generator=generator, activations=['relu'], dropout=0.5)\n    except ValueError as e:\n        error = e\n    assert (str(error) == 'The number of layers should equal the number of activations')\n    try:\n        appnpModel = APPNP([2], generator=[0, 1], activations=['relu'], dropout=0.5)\n    except TypeError as e:\n        error = e\n    assert (str(error) == '???')\n    try:\n        appnpModel = APPNP([2], generator=generator, activations=['relu'], dropout=0.0, approx_iter=(- 1))\n    except ValueError as e:\n        error = e\n    assert (str(error) == 'approx_iter should be a positive integer')\n    try:\n        appnpModel = APPNP([2], generator=generator, activations=['relu'], dropout=0.0, approx_iter=1.2)\n    except ValueError as e:\n        error = e\n    assert (str(error) == 'approx_iter should be a positive integer')\n    try:\n        appnpModel = APPNP([2], generator=generator, activations=['relu'], dropout=0.0, teleport_probability=1.2)\n    except ValueError as e:\n        error = e\n    assert (str(error) == 'teleport_probability should be between 0 and 1 (inclusive)')\n    try:\n        appnpModel = APPNP([2], generator=generator, activations=['relu'], dropout=0.0, teleport_probability=1.2)\n    except ValueError as e:\n        error = e\n    assert (str(error) == 'teleport_probability should be between 0 and 1 (inclusive)')", "ground_truth": "f'Generator should be a instance of FullBatchNodeGenerator, FullBatchLinkGenerator or ClusterNodeGenerator'", "quality_analysis": {"complexity_score": 4, "left_complexity": 4, "right_complexity": 0, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_496", "reponame": "stellargraph", "testpath": "tests/layer/test_appnp.py", "testname": "test_appnp.py", "classname": null, "funcname": "test_APPNP_edge_cases", "imports": ["from stellargraph.layer.appnp import *", "from stellargraph.mapper import FullBatchNodeGenerator, FullBatchLinkGenerator", "from stellargraph import StellarGraph", "from stellargraph.core.utils import GCN_Aadj_feats_op", "import networkx as nx", "import pandas as pd", "import numpy as np", "from tensorflow import keras", "import pytest", "from ..test_utils.graphs import create_graph_features", "from .. import test_utils"], "code": "def test_APPNP_edge_cases():\n    (G, features) = create_graph_features()\n    generator = FullBatchNodeGenerator(G, sparse=False, method='gcn')\n    try:\n        appnpModel = APPNP([2, 2], generator=generator, activations=['relu'], dropout=0.5)\n    except ValueError as e:\n        error = e\n    assert (str(error) == 'The number of layers should equal the number of activations')\n    try:\n        appnpModel = APPNP([2], generator=[0, 1], activations=['relu'], dropout=0.5)\n    except TypeError as e:\n        error = e\n    assert (str(error) == f'Generator should be a instance of FullBatchNodeGenerator, FullBatchLinkGenerator or ClusterNodeGenerator')\n    try:\n        appnpModel = APPNP([2], generator=generator, activations=['relu'], dropout=0.0, approx_iter=(- 1))\n    except ValueError as e:\n        error = e\n    assert (str(error) == 'approx_iter should be a positive integer')\n    try:\n        appnpModel = APPNP([2], generator=generator, activations=['relu'], dropout=0.0, approx_iter=1.2)\n    except ValueError as e:\n        error = e\n    assert (str(error) == 'approx_iter should be a positive integer')\n    try:\n        appnpModel = APPNP([2], generator=generator, activations=['relu'], dropout=0.0, teleport_probability=1.2)\n    except ValueError as e:\n        error = e\n    assert (str(error) == 'teleport_probability should be between 0 and 1 (inclusive)')\n    try:\n        appnpModel = APPNP([2], generator=generator, activations=['relu'], dropout=0.0, teleport_probability=1.2)\n    except ValueError as e:\n        error = e\n    assert (str(error) == 'teleport_probability should be between 0 and 1 (inclusive)')", "masked_code": "def test_APPNP_edge_cases():\n    (G, features) = create_graph_features()\n    generator = FullBatchNodeGenerator(G, sparse=False, method='gcn')\n    try:\n        appnpModel = APPNP([2, 2], generator=generator, activations=['relu'], dropout=0.5)\n    except ValueError as e:\n        error = e\n    assert (str(error) == 'The number of layers should equal the number of activations')\n    try:\n        appnpModel = APPNP([2], generator=[0, 1], activations=['relu'], dropout=0.5)\n    except TypeError as e:\n        error = e\n    assert (str(error) == f'Generator should be a instance of FullBatchNodeGenerator, FullBatchLinkGenerator or ClusterNodeGenerator')\n    try:\n        appnpModel = APPNP([2], generator=generator, activations=['relu'], dropout=0.0, approx_iter=(- 1))\n    except ValueError as e:\n        error = e\n    assert (str(error) == '???')\n    try:\n        appnpModel = APPNP([2], generator=generator, activations=['relu'], dropout=0.0, approx_iter=1.2)\n    except ValueError as e:\n        error = e\n    assert (str(error) == 'approx_iter should be a positive integer')\n    try:\n        appnpModel = APPNP([2], generator=generator, activations=['relu'], dropout=0.0, teleport_probability=1.2)\n    except ValueError as e:\n        error = e\n    assert (str(error) == 'teleport_probability should be between 0 and 1 (inclusive)')\n    try:\n        appnpModel = APPNP([2], generator=generator, activations=['relu'], dropout=0.0, teleport_probability=1.2)\n    except ValueError as e:\n        error = e\n    assert (str(error) == 'teleport_probability should be between 0 and 1 (inclusive)')", "ground_truth": "'approx_iter should be a positive integer'", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_497", "reponame": "stellargraph", "testpath": "tests/layer/test_appnp.py", "testname": "test_appnp.py", "classname": null, "funcname": "test_APPNP_edge_cases", "imports": ["from stellargraph.layer.appnp import *", "from stellargraph.mapper import FullBatchNodeGenerator, FullBatchLinkGenerator", "from stellargraph import StellarGraph", "from stellargraph.core.utils import GCN_Aadj_feats_op", "import networkx as nx", "import pandas as pd", "import numpy as np", "from tensorflow import keras", "import pytest", "from ..test_utils.graphs import create_graph_features", "from .. import test_utils"], "code": "def test_APPNP_edge_cases():\n    (G, features) = create_graph_features()\n    generator = FullBatchNodeGenerator(G, sparse=False, method='gcn')\n    try:\n        appnpModel = APPNP([2, 2], generator=generator, activations=['relu'], dropout=0.5)\n    except ValueError as e:\n        error = e\n    assert (str(error) == 'The number of layers should equal the number of activations')\n    try:\n        appnpModel = APPNP([2], generator=[0, 1], activations=['relu'], dropout=0.5)\n    except TypeError as e:\n        error = e\n    assert (str(error) == f'Generator should be a instance of FullBatchNodeGenerator, FullBatchLinkGenerator or ClusterNodeGenerator')\n    try:\n        appnpModel = APPNP([2], generator=generator, activations=['relu'], dropout=0.0, approx_iter=(- 1))\n    except ValueError as e:\n        error = e\n    assert (str(error) == 'approx_iter should be a positive integer')\n    try:\n        appnpModel = APPNP([2], generator=generator, activations=['relu'], dropout=0.0, approx_iter=1.2)\n    except ValueError as e:\n        error = e\n    assert (str(error) == 'approx_iter should be a positive integer')\n    try:\n        appnpModel = APPNP([2], generator=generator, activations=['relu'], dropout=0.0, teleport_probability=1.2)\n    except ValueError as e:\n        error = e\n    assert (str(error) == 'teleport_probability should be between 0 and 1 (inclusive)')\n    try:\n        appnpModel = APPNP([2], generator=generator, activations=['relu'], dropout=0.0, teleport_probability=1.2)\n    except ValueError as e:\n        error = e\n    assert (str(error) == 'teleport_probability should be between 0 and 1 (inclusive)')", "masked_code": "def test_APPNP_edge_cases():\n    (G, features) = create_graph_features()\n    generator = FullBatchNodeGenerator(G, sparse=False, method='gcn')\n    try:\n        appnpModel = APPNP([2, 2], generator=generator, activations=['relu'], dropout=0.5)\n    except ValueError as e:\n        error = e\n    assert (str(error) == 'The number of layers should equal the number of activations')\n    try:\n        appnpModel = APPNP([2], generator=[0, 1], activations=['relu'], dropout=0.5)\n    except TypeError as e:\n        error = e\n    assert (str(error) == f'Generator should be a instance of FullBatchNodeGenerator, FullBatchLinkGenerator or ClusterNodeGenerator')\n    try:\n        appnpModel = APPNP([2], generator=generator, activations=['relu'], dropout=0.0, approx_iter=(- 1))\n    except ValueError as e:\n        error = e\n    assert (str(error) == 'approx_iter should be a positive integer')\n    try:\n        appnpModel = APPNP([2], generator=generator, activations=['relu'], dropout=0.0, approx_iter=1.2)\n    except ValueError as e:\n        error = e\n    assert (str(error) == '???')\n    try:\n        appnpModel = APPNP([2], generator=generator, activations=['relu'], dropout=0.0, teleport_probability=1.2)\n    except ValueError as e:\n        error = e\n    assert (str(error) == 'teleport_probability should be between 0 and 1 (inclusive)')\n    try:\n        appnpModel = APPNP([2], generator=generator, activations=['relu'], dropout=0.0, teleport_probability=1.2)\n    except ValueError as e:\n        error = e\n    assert (str(error) == 'teleport_probability should be between 0 and 1 (inclusive)')", "ground_truth": "'approx_iter should be a positive integer'", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_498", "reponame": "stellargraph", "testpath": "tests/layer/test_appnp.py", "testname": "test_appnp.py", "classname": null, "funcname": "test_APPNP_edge_cases", "imports": ["from stellargraph.layer.appnp import *", "from stellargraph.mapper import FullBatchNodeGenerator, FullBatchLinkGenerator", "from stellargraph import StellarGraph", "from stellargraph.core.utils import GCN_Aadj_feats_op", "import networkx as nx", "import pandas as pd", "import numpy as np", "from tensorflow import keras", "import pytest", "from ..test_utils.graphs import create_graph_features", "from .. import test_utils"], "code": "def test_APPNP_edge_cases():\n    (G, features) = create_graph_features()\n    generator = FullBatchNodeGenerator(G, sparse=False, method='gcn')\n    try:\n        appnpModel = APPNP([2, 2], generator=generator, activations=['relu'], dropout=0.5)\n    except ValueError as e:\n        error = e\n    assert (str(error) == 'The number of layers should equal the number of activations')\n    try:\n        appnpModel = APPNP([2], generator=[0, 1], activations=['relu'], dropout=0.5)\n    except TypeError as e:\n        error = e\n    assert (str(error) == f'Generator should be a instance of FullBatchNodeGenerator, FullBatchLinkGenerator or ClusterNodeGenerator')\n    try:\n        appnpModel = APPNP([2], generator=generator, activations=['relu'], dropout=0.0, approx_iter=(- 1))\n    except ValueError as e:\n        error = e\n    assert (str(error) == 'approx_iter should be a positive integer')\n    try:\n        appnpModel = APPNP([2], generator=generator, activations=['relu'], dropout=0.0, approx_iter=1.2)\n    except ValueError as e:\n        error = e\n    assert (str(error) == 'approx_iter should be a positive integer')\n    try:\n        appnpModel = APPNP([2], generator=generator, activations=['relu'], dropout=0.0, teleport_probability=1.2)\n    except ValueError as e:\n        error = e\n    assert (str(error) == 'teleport_probability should be between 0 and 1 (inclusive)')\n    try:\n        appnpModel = APPNP([2], generator=generator, activations=['relu'], dropout=0.0, teleport_probability=1.2)\n    except ValueError as e:\n        error = e\n    assert (str(error) == 'teleport_probability should be between 0 and 1 (inclusive)')", "masked_code": "def test_APPNP_edge_cases():\n    (G, features) = create_graph_features()\n    generator = FullBatchNodeGenerator(G, sparse=False, method='gcn')\n    try:\n        appnpModel = APPNP([2, 2], generator=generator, activations=['relu'], dropout=0.5)\n    except ValueError as e:\n        error = e\n    assert (str(error) == 'The number of layers should equal the number of activations')\n    try:\n        appnpModel = APPNP([2], generator=[0, 1], activations=['relu'], dropout=0.5)\n    except TypeError as e:\n        error = e\n    assert (str(error) == f'Generator should be a instance of FullBatchNodeGenerator, FullBatchLinkGenerator or ClusterNodeGenerator')\n    try:\n        appnpModel = APPNP([2], generator=generator, activations=['relu'], dropout=0.0, approx_iter=(- 1))\n    except ValueError as e:\n        error = e\n    assert (str(error) == 'approx_iter should be a positive integer')\n    try:\n        appnpModel = APPNP([2], generator=generator, activations=['relu'], dropout=0.0, approx_iter=1.2)\n    except ValueError as e:\n        error = e\n    assert (str(error) == 'approx_iter should be a positive integer')\n    try:\n        appnpModel = APPNP([2], generator=generator, activations=['relu'], dropout=0.0, teleport_probability=1.2)\n    except ValueError as e:\n        error = e\n    assert (str(error) == '???')\n    try:\n        appnpModel = APPNP([2], generator=generator, activations=['relu'], dropout=0.0, teleport_probability=1.2)\n    except ValueError as e:\n        error = e\n    assert (str(error) == 'teleport_probability should be between 0 and 1 (inclusive)')", "ground_truth": "'teleport_probability should be between 0 and 1 (inclusive)'", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_499", "reponame": "stellargraph", "testpath": "tests/layer/test_appnp.py", "testname": "test_appnp.py", "classname": null, "funcname": "test_APPNP_edge_cases", "imports": ["from stellargraph.layer.appnp import *", "from stellargraph.mapper import FullBatchNodeGenerator, FullBatchLinkGenerator", "from stellargraph import StellarGraph", "from stellargraph.core.utils import GCN_Aadj_feats_op", "import networkx as nx", "import pandas as pd", "import numpy as np", "from tensorflow import keras", "import pytest", "from ..test_utils.graphs import create_graph_features", "from .. import test_utils"], "code": "def test_APPNP_edge_cases():\n    (G, features) = create_graph_features()\n    generator = FullBatchNodeGenerator(G, sparse=False, method='gcn')\n    try:\n        appnpModel = APPNP([2, 2], generator=generator, activations=['relu'], dropout=0.5)\n    except ValueError as e:\n        error = e\n    assert (str(error) == 'The number of layers should equal the number of activations')\n    try:\n        appnpModel = APPNP([2], generator=[0, 1], activations=['relu'], dropout=0.5)\n    except TypeError as e:\n        error = e\n    assert (str(error) == f'Generator should be a instance of FullBatchNodeGenerator, FullBatchLinkGenerator or ClusterNodeGenerator')\n    try:\n        appnpModel = APPNP([2], generator=generator, activations=['relu'], dropout=0.0, approx_iter=(- 1))\n    except ValueError as e:\n        error = e\n    assert (str(error) == 'approx_iter should be a positive integer')\n    try:\n        appnpModel = APPNP([2], generator=generator, activations=['relu'], dropout=0.0, approx_iter=1.2)\n    except ValueError as e:\n        error = e\n    assert (str(error) == 'approx_iter should be a positive integer')\n    try:\n        appnpModel = APPNP([2], generator=generator, activations=['relu'], dropout=0.0, teleport_probability=1.2)\n    except ValueError as e:\n        error = e\n    assert (str(error) == 'teleport_probability should be between 0 and 1 (inclusive)')\n    try:\n        appnpModel = APPNP([2], generator=generator, activations=['relu'], dropout=0.0, teleport_probability=1.2)\n    except ValueError as e:\n        error = e\n    assert (str(error) == 'teleport_probability should be between 0 and 1 (inclusive)')", "masked_code": "def test_APPNP_edge_cases():\n    (G, features) = create_graph_features()\n    generator = FullBatchNodeGenerator(G, sparse=False, method='gcn')\n    try:\n        appnpModel = APPNP([2, 2], generator=generator, activations=['relu'], dropout=0.5)\n    except ValueError as e:\n        error = e\n    assert (str(error) == 'The number of layers should equal the number of activations')\n    try:\n        appnpModel = APPNP([2], generator=[0, 1], activations=['relu'], dropout=0.5)\n    except TypeError as e:\n        error = e\n    assert (str(error) == f'Generator should be a instance of FullBatchNodeGenerator, FullBatchLinkGenerator or ClusterNodeGenerator')\n    try:\n        appnpModel = APPNP([2], generator=generator, activations=['relu'], dropout=0.0, approx_iter=(- 1))\n    except ValueError as e:\n        error = e\n    assert (str(error) == 'approx_iter should be a positive integer')\n    try:\n        appnpModel = APPNP([2], generator=generator, activations=['relu'], dropout=0.0, approx_iter=1.2)\n    except ValueError as e:\n        error = e\n    assert (str(error) == 'approx_iter should be a positive integer')\n    try:\n        appnpModel = APPNP([2], generator=generator, activations=['relu'], dropout=0.0, teleport_probability=1.2)\n    except ValueError as e:\n        error = e\n    assert (str(error) == 'teleport_probability should be between 0 and 1 (inclusive)')\n    try:\n        appnpModel = APPNP([2], generator=generator, activations=['relu'], dropout=0.0, teleport_probability=1.2)\n    except ValueError as e:\n        error = e\n    assert (str(error) == '???')", "ground_truth": "'teleport_probability should be between 0 and 1 (inclusive)'", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_500", "reponame": "stellargraph", "testpath": "tests/layer/test_appnp.py", "testname": "test_appnp.py", "classname": null, "funcname": "test_APPNP_apply_dense", "imports": ["from stellargraph.layer.appnp import *", "from stellargraph.mapper import FullBatchNodeGenerator, FullBatchLinkGenerator", "from stellargraph import StellarGraph", "from stellargraph.core.utils import GCN_Aadj_feats_op", "import networkx as nx", "import pandas as pd", "import numpy as np", "from tensorflow import keras", "import pytest", "from ..test_utils.graphs import create_graph_features", "from .. import test_utils"], "code": "def test_APPNP_apply_dense():\n    (G, features) = create_graph_features()\n    adj = G.to_adjacency_matrix()\n    (features, adj) = GCN_Aadj_feats_op(features, adj)\n    adj = np.array(adj.todense()[(None, :, :)])\n    generator = FullBatchNodeGenerator(G, sparse=False, method='gcn')\n    appnpModel = APPNP([2], generator=generator, activations=['relu'], dropout=0.5)\n    (x_in, x_out) = appnpModel.in_out_tensors()\n    model = keras.Model(inputs=x_in, outputs=x_out)\n    out_indices = np.array([[0, 1]], dtype='int32')\n    preds_1 = model.predict([features[(None, :, :)], out_indices, adj])\n    assert (preds_1.shape == (1, 2, 2))\n    preds_2 = model.predict(generator.flow(['a', 'b']))\n    assert (preds_2.shape == (1, 2, 2))\n    assert (preds_1 == pytest.approx(preds_2))", "masked_code": "def test_APPNP_apply_dense():\n    (G, features) = create_graph_features()\n    adj = G.to_adjacency_matrix()\n    (features, adj) = GCN_Aadj_feats_op(features, adj)\n    adj = np.array(adj.todense()[(None, :, :)])\n    generator = FullBatchNodeGenerator(G, sparse=False, method='gcn')\n    appnpModel = APPNP([2], generator=generator, activations=['relu'], dropout=0.5)\n    (x_in, x_out) = appnpModel.in_out_tensors()\n    model = keras.Model(inputs=x_in, outputs=x_out)\n    out_indices = np.array([[0, 1]], dtype='int32')\n    preds_1 = model.predict([features[(None, :, :)], out_indices, adj])\n    assert (preds_1.shape == '???')\n    preds_2 = model.predict(generator.flow(['a', 'b']))\n    assert (preds_2.shape == (1, 2, 2))\n    assert (preds_1 == pytest.approx(preds_2))", "ground_truth": "(1, 2, 2)", "quality_analysis": {"complexity_score": 7, "left_complexity": 2, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_501", "reponame": "stellargraph", "testpath": "tests/layer/test_appnp.py", "testname": "test_appnp.py", "classname": null, "funcname": "test_APPNP_apply_dense", "imports": ["from stellargraph.layer.appnp import *", "from stellargraph.mapper import FullBatchNodeGenerator, FullBatchLinkGenerator", "from stellargraph import StellarGraph", "from stellargraph.core.utils import GCN_Aadj_feats_op", "import networkx as nx", "import pandas as pd", "import numpy as np", "from tensorflow import keras", "import pytest", "from ..test_utils.graphs import create_graph_features", "from .. import test_utils"], "code": "def test_APPNP_apply_dense():\n    (G, features) = create_graph_features()\n    adj = G.to_adjacency_matrix()\n    (features, adj) = GCN_Aadj_feats_op(features, adj)\n    adj = np.array(adj.todense()[(None, :, :)])\n    generator = FullBatchNodeGenerator(G, sparse=False, method='gcn')\n    appnpModel = APPNP([2], generator=generator, activations=['relu'], dropout=0.5)\n    (x_in, x_out) = appnpModel.in_out_tensors()\n    model = keras.Model(inputs=x_in, outputs=x_out)\n    out_indices = np.array([[0, 1]], dtype='int32')\n    preds_1 = model.predict([features[(None, :, :)], out_indices, adj])\n    assert (preds_1.shape == (1, 2, 2))\n    preds_2 = model.predict(generator.flow(['a', 'b']))\n    assert (preds_2.shape == (1, 2, 2))\n    assert (preds_1 == pytest.approx(preds_2))", "masked_code": "def test_APPNP_apply_dense():\n    (G, features) = create_graph_features()\n    adj = G.to_adjacency_matrix()\n    (features, adj) = GCN_Aadj_feats_op(features, adj)\n    adj = np.array(adj.todense()[(None, :, :)])\n    generator = FullBatchNodeGenerator(G, sparse=False, method='gcn')\n    appnpModel = APPNP([2], generator=generator, activations=['relu'], dropout=0.5)\n    (x_in, x_out) = appnpModel.in_out_tensors()\n    model = keras.Model(inputs=x_in, outputs=x_out)\n    out_indices = np.array([[0, 1]], dtype='int32')\n    preds_1 = model.predict([features[(None, :, :)], out_indices, adj])\n    assert (preds_1.shape == (1, 2, 2))\n    preds_2 = model.predict(generator.flow(['a', 'b']))\n    assert (preds_2.shape == '???')\n    assert (preds_1 == pytest.approx(preds_2))", "ground_truth": "(1, 2, 2)", "quality_analysis": {"complexity_score": 7, "left_complexity": 2, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_502", "reponame": "stellargraph", "testpath": "tests/layer/test_appnp.py", "testname": "test_appnp.py", "classname": null, "funcname": "test_APPNP_apply_sparse", "imports": ["from stellargraph.layer.appnp import *", "from stellargraph.mapper import FullBatchNodeGenerator, FullBatchLinkGenerator", "from stellargraph import StellarGraph", "from stellargraph.core.utils import GCN_Aadj_feats_op", "import networkx as nx", "import pandas as pd", "import numpy as np", "from tensorflow import keras", "import pytest", "from ..test_utils.graphs import create_graph_features", "from .. import test_utils"], "code": "def test_APPNP_apply_sparse():\n    (G, features) = create_graph_features()\n    adj = G.to_adjacency_matrix()\n    (features, adj) = GCN_Aadj_feats_op(features, adj)\n    adj = adj.tocoo()\n    A_indices = np.expand_dims(np.hstack((adj.row[(:, None)], adj.col[(:, None)])).astype(np.int64), 0)\n    A_values = np.expand_dims(adj.data, 0)\n    generator = FullBatchNodeGenerator(G, sparse=True, method='gcn')\n    appnpnModel = APPNP([2], generator=generator, activations=['relu'], dropout=0.5)\n    (x_in, x_out) = appnpnModel.in_out_tensors()\n    model = keras.Model(inputs=x_in, outputs=x_out)\n    out_indices = np.array([[0, 1]], dtype='int32')\n    preds_1 = model.predict([features[(None, :, :)], out_indices, A_indices, A_values])\n    assert (preds_1.shape == (1, 2, 2))\n    preds_2 = model.predict(generator.flow(['a', 'b']))\n    assert (preds_2.shape == (1, 2, 2))\n    assert (preds_1 == pytest.approx(preds_2))", "masked_code": "def test_APPNP_apply_sparse():\n    (G, features) = create_graph_features()\n    adj = G.to_adjacency_matrix()\n    (features, adj) = GCN_Aadj_feats_op(features, adj)\n    adj = adj.tocoo()\n    A_indices = np.expand_dims(np.hstack((adj.row[(:, None)], adj.col[(:, None)])).astype(np.int64), 0)\n    A_values = np.expand_dims(adj.data, 0)\n    generator = FullBatchNodeGenerator(G, sparse=True, method='gcn')\n    appnpnModel = APPNP([2], generator=generator, activations=['relu'], dropout=0.5)\n    (x_in, x_out) = appnpnModel.in_out_tensors()\n    model = keras.Model(inputs=x_in, outputs=x_out)\n    out_indices = np.array([[0, 1]], dtype='int32')\n    preds_1 = model.predict([features[(None, :, :)], out_indices, A_indices, A_values])\n    assert (preds_1.shape == '???')\n    preds_2 = model.predict(generator.flow(['a', 'b']))\n    assert (preds_2.shape == (1, 2, 2))\n    assert (preds_1 == pytest.approx(preds_2))", "ground_truth": "(1, 2, 2)", "quality_analysis": {"complexity_score": 7, "left_complexity": 2, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_503", "reponame": "stellargraph", "testpath": "tests/layer/test_appnp.py", "testname": "test_appnp.py", "classname": null, "funcname": "test_APPNP_apply_sparse", "imports": ["from stellargraph.layer.appnp import *", "from stellargraph.mapper import FullBatchNodeGenerator, FullBatchLinkGenerator", "from stellargraph import StellarGraph", "from stellargraph.core.utils import GCN_Aadj_feats_op", "import networkx as nx", "import pandas as pd", "import numpy as np", "from tensorflow import keras", "import pytest", "from ..test_utils.graphs import create_graph_features", "from .. import test_utils"], "code": "def test_APPNP_apply_sparse():\n    (G, features) = create_graph_features()\n    adj = G.to_adjacency_matrix()\n    (features, adj) = GCN_Aadj_feats_op(features, adj)\n    adj = adj.tocoo()\n    A_indices = np.expand_dims(np.hstack((adj.row[(:, None)], adj.col[(:, None)])).astype(np.int64), 0)\n    A_values = np.expand_dims(adj.data, 0)\n    generator = FullBatchNodeGenerator(G, sparse=True, method='gcn')\n    appnpnModel = APPNP([2], generator=generator, activations=['relu'], dropout=0.5)\n    (x_in, x_out) = appnpnModel.in_out_tensors()\n    model = keras.Model(inputs=x_in, outputs=x_out)\n    out_indices = np.array([[0, 1]], dtype='int32')\n    preds_1 = model.predict([features[(None, :, :)], out_indices, A_indices, A_values])\n    assert (preds_1.shape == (1, 2, 2))\n    preds_2 = model.predict(generator.flow(['a', 'b']))\n    assert (preds_2.shape == (1, 2, 2))\n    assert (preds_1 == pytest.approx(preds_2))", "masked_code": "def test_APPNP_apply_sparse():\n    (G, features) = create_graph_features()\n    adj = G.to_adjacency_matrix()\n    (features, adj) = GCN_Aadj_feats_op(features, adj)\n    adj = adj.tocoo()\n    A_indices = np.expand_dims(np.hstack((adj.row[(:, None)], adj.col[(:, None)])).astype(np.int64), 0)\n    A_values = np.expand_dims(adj.data, 0)\n    generator = FullBatchNodeGenerator(G, sparse=True, method='gcn')\n    appnpnModel = APPNP([2], generator=generator, activations=['relu'], dropout=0.5)\n    (x_in, x_out) = appnpnModel.in_out_tensors()\n    model = keras.Model(inputs=x_in, outputs=x_out)\n    out_indices = np.array([[0, 1]], dtype='int32')\n    preds_1 = model.predict([features[(None, :, :)], out_indices, A_indices, A_values])\n    assert (preds_1.shape == (1, 2, 2))\n    preds_2 = model.predict(generator.flow(['a', 'b']))\n    assert (preds_2.shape == '???')\n    assert (preds_1 == pytest.approx(preds_2))", "ground_truth": "(1, 2, 2)", "quality_analysis": {"complexity_score": 7, "left_complexity": 2, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_504", "reponame": "stellargraph", "testpath": "tests/layer/test_appnp.py", "testname": "test_appnp.py", "classname": null, "funcname": "test_APPNP_linkmodel_apply_dense", "imports": ["from stellargraph.layer.appnp import *", "from stellargraph.mapper import FullBatchNodeGenerator, FullBatchLinkGenerator", "from stellargraph import StellarGraph", "from stellargraph.core.utils import GCN_Aadj_feats_op", "import networkx as nx", "import pandas as pd", "import numpy as np", "from tensorflow import keras", "import pytest", "from ..test_utils.graphs import create_graph_features", "from .. import test_utils"], "code": "def test_APPNP_linkmodel_apply_dense():\n    (G, features) = create_graph_features()\n    adj = G.to_adjacency_matrix()\n    adj = np.array(adj.todense()[(None, :, :)])\n    generator = FullBatchLinkGenerator(G, sparse=False, method='none')\n    appnpnModel = APPNP([3], generator, activations=['relu'], dropout=0.5)\n    (x_in, x_out) = appnpnModel.in_out_tensors()\n    model = keras.Model(inputs=x_in, outputs=x_out)\n    out_indices = np.array([[[0, 1], [1, 2]]], dtype='int32')\n    preds_1 = model.predict([features[(None, :, :)], out_indices, adj])\n    assert (preds_1.shape == (1, 2, 2, 3))\n    preds_2 = model.predict(generator.flow([('a', 'b'), ('b', 'c')]))\n    assert (preds_2.shape == (1, 2, 2, 3))\n    assert (preds_1 == pytest.approx(preds_2))", "masked_code": "def test_APPNP_linkmodel_apply_dense():\n    (G, features) = create_graph_features()\n    adj = G.to_adjacency_matrix()\n    adj = np.array(adj.todense()[(None, :, :)])\n    generator = FullBatchLinkGenerator(G, sparse=False, method='none')\n    appnpnModel = APPNP([3], generator, activations=['relu'], dropout=0.5)\n    (x_in, x_out) = appnpnModel.in_out_tensors()\n    model = keras.Model(inputs=x_in, outputs=x_out)\n    out_indices = np.array([[[0, 1], [1, 2]]], dtype='int32')\n    preds_1 = model.predict([features[(None, :, :)], out_indices, adj])\n    assert (preds_1.shape == '???')\n    preds_2 = model.predict(generator.flow([('a', 'b'), ('b', 'c')]))\n    assert (preds_2.shape == (1, 2, 2, 3))\n    assert (preds_1 == pytest.approx(preds_2))", "ground_truth": "(1, 2, 2, 3)", "quality_analysis": {"complexity_score": 8, "left_complexity": 2, "right_complexity": 6, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_505", "reponame": "stellargraph", "testpath": "tests/layer/test_appnp.py", "testname": "test_appnp.py", "classname": null, "funcname": "test_APPNP_linkmodel_apply_dense", "imports": ["from stellargraph.layer.appnp import *", "from stellargraph.mapper import FullBatchNodeGenerator, FullBatchLinkGenerator", "from stellargraph import StellarGraph", "from stellargraph.core.utils import GCN_Aadj_feats_op", "import networkx as nx", "import pandas as pd", "import numpy as np", "from tensorflow import keras", "import pytest", "from ..test_utils.graphs import create_graph_features", "from .. import test_utils"], "code": "def test_APPNP_linkmodel_apply_dense():\n    (G, features) = create_graph_features()\n    adj = G.to_adjacency_matrix()\n    adj = np.array(adj.todense()[(None, :, :)])\n    generator = FullBatchLinkGenerator(G, sparse=False, method='none')\n    appnpnModel = APPNP([3], generator, activations=['relu'], dropout=0.5)\n    (x_in, x_out) = appnpnModel.in_out_tensors()\n    model = keras.Model(inputs=x_in, outputs=x_out)\n    out_indices = np.array([[[0, 1], [1, 2]]], dtype='int32')\n    preds_1 = model.predict([features[(None, :, :)], out_indices, adj])\n    assert (preds_1.shape == (1, 2, 2, 3))\n    preds_2 = model.predict(generator.flow([('a', 'b'), ('b', 'c')]))\n    assert (preds_2.shape == (1, 2, 2, 3))\n    assert (preds_1 == pytest.approx(preds_2))", "masked_code": "def test_APPNP_linkmodel_apply_dense():\n    (G, features) = create_graph_features()\n    adj = G.to_adjacency_matrix()\n    adj = np.array(adj.todense()[(None, :, :)])\n    generator = FullBatchLinkGenerator(G, sparse=False, method='none')\n    appnpnModel = APPNP([3], generator, activations=['relu'], dropout=0.5)\n    (x_in, x_out) = appnpnModel.in_out_tensors()\n    model = keras.Model(inputs=x_in, outputs=x_out)\n    out_indices = np.array([[[0, 1], [1, 2]]], dtype='int32')\n    preds_1 = model.predict([features[(None, :, :)], out_indices, adj])\n    assert (preds_1.shape == (1, 2, 2, 3))\n    preds_2 = model.predict(generator.flow([('a', 'b'), ('b', 'c')]))\n    assert (preds_2.shape == '???')\n    assert (preds_1 == pytest.approx(preds_2))", "ground_truth": "(1, 2, 2, 3)", "quality_analysis": {"complexity_score": 8, "left_complexity": 2, "right_complexity": 6, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_506", "reponame": "stellargraph", "testpath": "tests/layer/test_appnp.py", "testname": "test_appnp.py", "classname": null, "funcname": "test_APPNP_linkmodel_apply_sparse", "imports": ["from stellargraph.layer.appnp import *", "from stellargraph.mapper import FullBatchNodeGenerator, FullBatchLinkGenerator", "from stellargraph import StellarGraph", "from stellargraph.core.utils import GCN_Aadj_feats_op", "import networkx as nx", "import pandas as pd", "import numpy as np", "from tensorflow import keras", "import pytest", "from ..test_utils.graphs import create_graph_features", "from .. import test_utils"], "code": "def test_APPNP_linkmodel_apply_sparse():\n    (G, features) = create_graph_features()\n    adj = G.to_adjacency_matrix()\n    (features, adj) = GCN_Aadj_feats_op(features, adj)\n    adj = adj.tocoo()\n    A_indices = np.expand_dims(np.hstack((adj.row[(:, None)], adj.col[(:, None)])).astype(np.int64), 0)\n    A_values = np.expand_dims(adj.data, 0)\n    generator = FullBatchLinkGenerator(G, sparse=True, method='gcn')\n    appnpnModel = APPNP(layer_sizes=[3], activations=['relu'], generator=generator, dropout=0.5)\n    (x_in, x_out) = appnpnModel.in_out_tensors()\n    model = keras.Model(inputs=x_in, outputs=x_out)\n    out_indices = np.array([[[0, 1], [1, 2]]], dtype='int32')\n    preds_1 = model.predict([features[(None, :, :)], out_indices, A_indices, A_values])\n    assert (preds_1.shape == (1, 2, 2, 3))\n    preds_2 = model.predict(generator.flow([('a', 'b'), ('b', 'c')]))\n    assert (preds_2.shape == (1, 2, 2, 3))\n    assert (preds_1 == pytest.approx(preds_2))", "masked_code": "def test_APPNP_linkmodel_apply_sparse():\n    (G, features) = create_graph_features()\n    adj = G.to_adjacency_matrix()\n    (features, adj) = GCN_Aadj_feats_op(features, adj)\n    adj = adj.tocoo()\n    A_indices = np.expand_dims(np.hstack((adj.row[(:, None)], adj.col[(:, None)])).astype(np.int64), 0)\n    A_values = np.expand_dims(adj.data, 0)\n    generator = FullBatchLinkGenerator(G, sparse=True, method='gcn')\n    appnpnModel = APPNP(layer_sizes=[3], activations=['relu'], generator=generator, dropout=0.5)\n    (x_in, x_out) = appnpnModel.in_out_tensors()\n    model = keras.Model(inputs=x_in, outputs=x_out)\n    out_indices = np.array([[[0, 1], [1, 2]]], dtype='int32')\n    preds_1 = model.predict([features[(None, :, :)], out_indices, A_indices, A_values])\n    assert (preds_1.shape == '???')\n    preds_2 = model.predict(generator.flow([('a', 'b'), ('b', 'c')]))\n    assert (preds_2.shape == (1, 2, 2, 3))\n    assert (preds_1 == pytest.approx(preds_2))", "ground_truth": "(1, 2, 2, 3)", "quality_analysis": {"complexity_score": 8, "left_complexity": 2, "right_complexity": 6, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_507", "reponame": "stellargraph", "testpath": "tests/layer/test_appnp.py", "testname": "test_appnp.py", "classname": null, "funcname": "test_APPNP_linkmodel_apply_sparse", "imports": ["from stellargraph.layer.appnp import *", "from stellargraph.mapper import FullBatchNodeGenerator, FullBatchLinkGenerator", "from stellargraph import StellarGraph", "from stellargraph.core.utils import GCN_Aadj_feats_op", "import networkx as nx", "import pandas as pd", "import numpy as np", "from tensorflow import keras", "import pytest", "from ..test_utils.graphs import create_graph_features", "from .. import test_utils"], "code": "def test_APPNP_linkmodel_apply_sparse():\n    (G, features) = create_graph_features()\n    adj = G.to_adjacency_matrix()\n    (features, adj) = GCN_Aadj_feats_op(features, adj)\n    adj = adj.tocoo()\n    A_indices = np.expand_dims(np.hstack((adj.row[(:, None)], adj.col[(:, None)])).astype(np.int64), 0)\n    A_values = np.expand_dims(adj.data, 0)\n    generator = FullBatchLinkGenerator(G, sparse=True, method='gcn')\n    appnpnModel = APPNP(layer_sizes=[3], activations=['relu'], generator=generator, dropout=0.5)\n    (x_in, x_out) = appnpnModel.in_out_tensors()\n    model = keras.Model(inputs=x_in, outputs=x_out)\n    out_indices = np.array([[[0, 1], [1, 2]]], dtype='int32')\n    preds_1 = model.predict([features[(None, :, :)], out_indices, A_indices, A_values])\n    assert (preds_1.shape == (1, 2, 2, 3))\n    preds_2 = model.predict(generator.flow([('a', 'b'), ('b', 'c')]))\n    assert (preds_2.shape == (1, 2, 2, 3))\n    assert (preds_1 == pytest.approx(preds_2))", "masked_code": "def test_APPNP_linkmodel_apply_sparse():\n    (G, features) = create_graph_features()\n    adj = G.to_adjacency_matrix()\n    (features, adj) = GCN_Aadj_feats_op(features, adj)\n    adj = adj.tocoo()\n    A_indices = np.expand_dims(np.hstack((adj.row[(:, None)], adj.col[(:, None)])).astype(np.int64), 0)\n    A_values = np.expand_dims(adj.data, 0)\n    generator = FullBatchLinkGenerator(G, sparse=True, method='gcn')\n    appnpnModel = APPNP(layer_sizes=[3], activations=['relu'], generator=generator, dropout=0.5)\n    (x_in, x_out) = appnpnModel.in_out_tensors()\n    model = keras.Model(inputs=x_in, outputs=x_out)\n    out_indices = np.array([[[0, 1], [1, 2]]], dtype='int32')\n    preds_1 = model.predict([features[(None, :, :)], out_indices, A_indices, A_values])\n    assert (preds_1.shape == (1, 2, 2, 3))\n    preds_2 = model.predict(generator.flow([('a', 'b'), ('b', 'c')]))\n    assert (preds_2.shape == '???')\n    assert (preds_1 == pytest.approx(preds_2))", "ground_truth": "(1, 2, 2, 3)", "quality_analysis": {"complexity_score": 8, "left_complexity": 2, "right_complexity": 6, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_508", "reponame": "stellargraph", "testpath": "tests/layer/test_appnp.py", "testname": "test_appnp.py", "classname": null, "funcname": "test_APPNP_apply_propagate_model_dense", "imports": ["from stellargraph.layer.appnp import *", "from stellargraph.mapper import FullBatchNodeGenerator, FullBatchLinkGenerator", "from stellargraph import StellarGraph", "from stellargraph.core.utils import GCN_Aadj_feats_op", "import networkx as nx", "import pandas as pd", "import numpy as np", "from tensorflow import keras", "import pytest", "from ..test_utils.graphs import create_graph_features", "from .. import test_utils"], "code": "def test_APPNP_apply_propagate_model_dense():\n    (G, features) = create_graph_features()\n    adj = G.to_adjacency_matrix()\n    (features, adj) = GCN_Aadj_feats_op(features, adj)\n    adj = np.array(adj.todense()[(None, :, :)])\n    generator = FullBatchNodeGenerator(G, sparse=False, method='gcn')\n    appnpnModel = APPNP([2], generator=generator, activations=['relu'], dropout=0.5)\n    fully_connected_model = keras.Sequential()\n    fully_connected_model.add(Dense(2))\n    (x_in, x_out) = appnpnModel.propagate_model(fully_connected_model)\n    model = keras.Model(inputs=x_in, outputs=x_out)\n    out_indices = np.array([[0, 1]], dtype='int32')\n    preds_1 = model.predict([features[(None, :, :)], out_indices, adj])\n    assert (preds_1.shape == (1, 2, 2))\n    preds_2 = model.predict(generator.flow(['a', 'b']))\n    assert (preds_2.shape == (1, 2, 2))\n    assert (preds_1 == pytest.approx(preds_2))", "masked_code": "def test_APPNP_apply_propagate_model_dense():\n    (G, features) = create_graph_features()\n    adj = G.to_adjacency_matrix()\n    (features, adj) = GCN_Aadj_feats_op(features, adj)\n    adj = np.array(adj.todense()[(None, :, :)])\n    generator = FullBatchNodeGenerator(G, sparse=False, method='gcn')\n    appnpnModel = APPNP([2], generator=generator, activations=['relu'], dropout=0.5)\n    fully_connected_model = keras.Sequential()\n    fully_connected_model.add(Dense(2))\n    (x_in, x_out) = appnpnModel.propagate_model(fully_connected_model)\n    model = keras.Model(inputs=x_in, outputs=x_out)\n    out_indices = np.array([[0, 1]], dtype='int32')\n    preds_1 = model.predict([features[(None, :, :)], out_indices, adj])\n    assert (preds_1.shape == '???')\n    preds_2 = model.predict(generator.flow(['a', 'b']))\n    assert (preds_2.shape == (1, 2, 2))\n    assert (preds_1 == pytest.approx(preds_2))", "ground_truth": "(1, 2, 2)", "quality_analysis": {"complexity_score": 7, "left_complexity": 2, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_509", "reponame": "stellargraph", "testpath": "tests/layer/test_appnp.py", "testname": "test_appnp.py", "classname": null, "funcname": "test_APPNP_apply_propagate_model_dense", "imports": ["from stellargraph.layer.appnp import *", "from stellargraph.mapper import FullBatchNodeGenerator, FullBatchLinkGenerator", "from stellargraph import StellarGraph", "from stellargraph.core.utils import GCN_Aadj_feats_op", "import networkx as nx", "import pandas as pd", "import numpy as np", "from tensorflow import keras", "import pytest", "from ..test_utils.graphs import create_graph_features", "from .. import test_utils"], "code": "def test_APPNP_apply_propagate_model_dense():\n    (G, features) = create_graph_features()\n    adj = G.to_adjacency_matrix()\n    (features, adj) = GCN_Aadj_feats_op(features, adj)\n    adj = np.array(adj.todense()[(None, :, :)])\n    generator = FullBatchNodeGenerator(G, sparse=False, method='gcn')\n    appnpnModel = APPNP([2], generator=generator, activations=['relu'], dropout=0.5)\n    fully_connected_model = keras.Sequential()\n    fully_connected_model.add(Dense(2))\n    (x_in, x_out) = appnpnModel.propagate_model(fully_connected_model)\n    model = keras.Model(inputs=x_in, outputs=x_out)\n    out_indices = np.array([[0, 1]], dtype='int32')\n    preds_1 = model.predict([features[(None, :, :)], out_indices, adj])\n    assert (preds_1.shape == (1, 2, 2))\n    preds_2 = model.predict(generator.flow(['a', 'b']))\n    assert (preds_2.shape == (1, 2, 2))\n    assert (preds_1 == pytest.approx(preds_2))", "masked_code": "def test_APPNP_apply_propagate_model_dense():\n    (G, features) = create_graph_features()\n    adj = G.to_adjacency_matrix()\n    (features, adj) = GCN_Aadj_feats_op(features, adj)\n    adj = np.array(adj.todense()[(None, :, :)])\n    generator = FullBatchNodeGenerator(G, sparse=False, method='gcn')\n    appnpnModel = APPNP([2], generator=generator, activations=['relu'], dropout=0.5)\n    fully_connected_model = keras.Sequential()\n    fully_connected_model.add(Dense(2))\n    (x_in, x_out) = appnpnModel.propagate_model(fully_connected_model)\n    model = keras.Model(inputs=x_in, outputs=x_out)\n    out_indices = np.array([[0, 1]], dtype='int32')\n    preds_1 = model.predict([features[(None, :, :)], out_indices, adj])\n    assert (preds_1.shape == (1, 2, 2))\n    preds_2 = model.predict(generator.flow(['a', 'b']))\n    assert (preds_2.shape == '???')\n    assert (preds_1 == pytest.approx(preds_2))", "ground_truth": "(1, 2, 2)", "quality_analysis": {"complexity_score": 7, "left_complexity": 2, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_510", "reponame": "stellargraph", "testpath": "tests/layer/test_appnp.py", "testname": "test_appnp.py", "classname": null, "funcname": "test_APPNP_apply_propagate_model_sparse", "imports": ["from stellargraph.layer.appnp import *", "from stellargraph.mapper import FullBatchNodeGenerator, FullBatchLinkGenerator", "from stellargraph import StellarGraph", "from stellargraph.core.utils import GCN_Aadj_feats_op", "import networkx as nx", "import pandas as pd", "import numpy as np", "from tensorflow import keras", "import pytest", "from ..test_utils.graphs import create_graph_features", "from .. import test_utils"], "code": "def test_APPNP_apply_propagate_model_sparse():\n    (G, features) = create_graph_features()\n    adj = G.to_adjacency_matrix()\n    (features, adj) = GCN_Aadj_feats_op(features, adj)\n    adj = adj.tocoo()\n    A_indices = np.expand_dims(np.hstack((adj.row[(:, None)], adj.col[(:, None)])).astype(np.int64), 0)\n    A_values = np.expand_dims(adj.data, 0)\n    generator = FullBatchNodeGenerator(G, sparse=True, method='gcn')\n    appnpnModel = APPNP([2], generator=generator, activations=['relu'], dropout=0.5)\n    fully_connected_model = keras.Sequential()\n    fully_connected_model.add(Dense(2))\n    (x_in, x_out) = appnpnModel.propagate_model(fully_connected_model)\n    model = keras.Model(inputs=x_in, outputs=x_out)\n    out_indices = np.array([[0, 1]], dtype='int32')\n    preds_1 = model.predict([features[(None, :, :)], out_indices, A_indices, A_values])\n    assert (preds_1.shape == (1, 2, 2))\n    preds_2 = model.predict(generator.flow(['a', 'b']))\n    assert (preds_2.shape == (1, 2, 2))\n    assert (preds_1 == pytest.approx(preds_2))", "masked_code": "def test_APPNP_apply_propagate_model_sparse():\n    (G, features) = create_graph_features()\n    adj = G.to_adjacency_matrix()\n    (features, adj) = GCN_Aadj_feats_op(features, adj)\n    adj = adj.tocoo()\n    A_indices = np.expand_dims(np.hstack((adj.row[(:, None)], adj.col[(:, None)])).astype(np.int64), 0)\n    A_values = np.expand_dims(adj.data, 0)\n    generator = FullBatchNodeGenerator(G, sparse=True, method='gcn')\n    appnpnModel = APPNP([2], generator=generator, activations=['relu'], dropout=0.5)\n    fully_connected_model = keras.Sequential()\n    fully_connected_model.add(Dense(2))\n    (x_in, x_out) = appnpnModel.propagate_model(fully_connected_model)\n    model = keras.Model(inputs=x_in, outputs=x_out)\n    out_indices = np.array([[0, 1]], dtype='int32')\n    preds_1 = model.predict([features[(None, :, :)], out_indices, A_indices, A_values])\n    assert (preds_1.shape == '???')\n    preds_2 = model.predict(generator.flow(['a', 'b']))\n    assert (preds_2.shape == (1, 2, 2))\n    assert (preds_1 == pytest.approx(preds_2))", "ground_truth": "(1, 2, 2)", "quality_analysis": {"complexity_score": 7, "left_complexity": 2, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_511", "reponame": "stellargraph", "testpath": "tests/layer/test_appnp.py", "testname": "test_appnp.py", "classname": null, "funcname": "test_APPNP_apply_propagate_model_sparse", "imports": ["from stellargraph.layer.appnp import *", "from stellargraph.mapper import FullBatchNodeGenerator, FullBatchLinkGenerator", "from stellargraph import StellarGraph", "from stellargraph.core.utils import GCN_Aadj_feats_op", "import networkx as nx", "import pandas as pd", "import numpy as np", "from tensorflow import keras", "import pytest", "from ..test_utils.graphs import create_graph_features", "from .. import test_utils"], "code": "def test_APPNP_apply_propagate_model_sparse():\n    (G, features) = create_graph_features()\n    adj = G.to_adjacency_matrix()\n    (features, adj) = GCN_Aadj_feats_op(features, adj)\n    adj = adj.tocoo()\n    A_indices = np.expand_dims(np.hstack((adj.row[(:, None)], adj.col[(:, None)])).astype(np.int64), 0)\n    A_values = np.expand_dims(adj.data, 0)\n    generator = FullBatchNodeGenerator(G, sparse=True, method='gcn')\n    appnpnModel = APPNP([2], generator=generator, activations=['relu'], dropout=0.5)\n    fully_connected_model = keras.Sequential()\n    fully_connected_model.add(Dense(2))\n    (x_in, x_out) = appnpnModel.propagate_model(fully_connected_model)\n    model = keras.Model(inputs=x_in, outputs=x_out)\n    out_indices = np.array([[0, 1]], dtype='int32')\n    preds_1 = model.predict([features[(None, :, :)], out_indices, A_indices, A_values])\n    assert (preds_1.shape == (1, 2, 2))\n    preds_2 = model.predict(generator.flow(['a', 'b']))\n    assert (preds_2.shape == (1, 2, 2))\n    assert (preds_1 == pytest.approx(preds_2))", "masked_code": "def test_APPNP_apply_propagate_model_sparse():\n    (G, features) = create_graph_features()\n    adj = G.to_adjacency_matrix()\n    (features, adj) = GCN_Aadj_feats_op(features, adj)\n    adj = adj.tocoo()\n    A_indices = np.expand_dims(np.hstack((adj.row[(:, None)], adj.col[(:, None)])).astype(np.int64), 0)\n    A_values = np.expand_dims(adj.data, 0)\n    generator = FullBatchNodeGenerator(G, sparse=True, method='gcn')\n    appnpnModel = APPNP([2], generator=generator, activations=['relu'], dropout=0.5)\n    fully_connected_model = keras.Sequential()\n    fully_connected_model.add(Dense(2))\n    (x_in, x_out) = appnpnModel.propagate_model(fully_connected_model)\n    model = keras.Model(inputs=x_in, outputs=x_out)\n    out_indices = np.array([[0, 1]], dtype='int32')\n    preds_1 = model.predict([features[(None, :, :)], out_indices, A_indices, A_values])\n    assert (preds_1.shape == (1, 2, 2))\n    preds_2 = model.predict(generator.flow(['a', 'b']))\n    assert (preds_2.shape == '???')\n    assert (preds_1 == pytest.approx(preds_2))", "ground_truth": "(1, 2, 2)", "quality_analysis": {"complexity_score": 7, "left_complexity": 2, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_512", "reponame": "stellargraph", "testpath": "tests/layer/test_attri2vec.py", "testname": "test_attri2vec.py", "classname": null, "funcname": "test_attri2vec_constructor", "imports": ["from stellargraph.core.graph import StellarGraph", "from stellargraph.mapper import Attri2VecNodeGenerator", "from stellargraph.layer.attri2vec import *", "from tensorflow import keras", "import numpy as np", "import networkx as nx", "import pytest", "from ..test_utils.graphs import example_graph", "from .. import test_utils"], "code": "def test_attri2vec_constructor():\n    attri2vec = Attri2Vec(layer_sizes=[4], input_dim=2, node_num=4, multiplicity=2, normalize='l2')\n    assert (attri2vec.dims == [2, 4])\n    assert (attri2vec.input_node_num == 4)\n    assert (attri2vec.n_layers == 1)\n    assert (attri2vec.bias == False)\n    with pytest.raises(ValueError):\n        Attri2Vec(layer_sizes=[4], input_dim=2, node_num=4, multiplicity=2, activation='unknown')\n    with pytest.raises(ValueError):\n        Attri2Vec(layer_sizes=[4], input_dim=2, node_num=4, multiplicity=2, normalize=(lambda x: x))\n    with pytest.raises(ValueError):\n        Attri2Vec(layer_sizes=[4], input_dim=2, node_num=4, multiplicity=2, normalize='unknown')\n    with pytest.raises(ValueError):\n        Attri2Vec(layer_sizes=[4])\n    G = example_graph(feature_size=3)\n    gen = Attri2VecNodeGenerator(G, batch_size=2)\n    attri2vec = Attri2Vec(layer_sizes=[4, 8], generator=gen, bias=True)\n    assert (attri2vec.dims == [3, 4, 8])\n    assert (attri2vec.input_node_num == 4)\n    assert (attri2vec.n_layers == 2)\n    assert attri2vec.bias", "masked_code": "def test_attri2vec_constructor():\n    attri2vec = Attri2Vec(layer_sizes=[4], input_dim=2, node_num=4, multiplicity=2, normalize='l2')\n    assert (attri2vec.dims == '???')\n    assert (attri2vec.input_node_num == 4)\n    assert (attri2vec.n_layers == 1)\n    assert (attri2vec.bias == False)\n    with pytest.raises(ValueError):\n        Attri2Vec(layer_sizes=[4], input_dim=2, node_num=4, multiplicity=2, activation='unknown')\n    with pytest.raises(ValueError):\n        Attri2Vec(layer_sizes=[4], input_dim=2, node_num=4, multiplicity=2, normalize=(lambda x: x))\n    with pytest.raises(ValueError):\n        Attri2Vec(layer_sizes=[4], input_dim=2, node_num=4, multiplicity=2, normalize='unknown')\n    with pytest.raises(ValueError):\n        Attri2Vec(layer_sizes=[4])\n    G = example_graph(feature_size=3)\n    gen = Attri2VecNodeGenerator(G, batch_size=2)\n    attri2vec = Attri2Vec(layer_sizes=[4, 8], generator=gen, bias=True)\n    assert (attri2vec.dims == [3, 4, 8])\n    assert (attri2vec.input_node_num == 4)\n    assert (attri2vec.n_layers == 2)\n    assert attri2vec.bias", "ground_truth": "[2, 4]", "quality_analysis": {"complexity_score": 6, "left_complexity": 2, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_513", "reponame": "stellargraph", "testpath": "tests/layer/test_attri2vec.py", "testname": "test_attri2vec.py", "classname": null, "funcname": "test_attri2vec_constructor", "imports": ["from stellargraph.core.graph import StellarGraph", "from stellargraph.mapper import Attri2VecNodeGenerator", "from stellargraph.layer.attri2vec import *", "from tensorflow import keras", "import numpy as np", "import networkx as nx", "import pytest", "from ..test_utils.graphs import example_graph", "from .. import test_utils"], "code": "def test_attri2vec_constructor():\n    attri2vec = Attri2Vec(layer_sizes=[4], input_dim=2, node_num=4, multiplicity=2, normalize='l2')\n    assert (attri2vec.dims == [2, 4])\n    assert (attri2vec.input_node_num == 4)\n    assert (attri2vec.n_layers == 1)\n    assert (attri2vec.bias == False)\n    with pytest.raises(ValueError):\n        Attri2Vec(layer_sizes=[4], input_dim=2, node_num=4, multiplicity=2, activation='unknown')\n    with pytest.raises(ValueError):\n        Attri2Vec(layer_sizes=[4], input_dim=2, node_num=4, multiplicity=2, normalize=(lambda x: x))\n    with pytest.raises(ValueError):\n        Attri2Vec(layer_sizes=[4], input_dim=2, node_num=4, multiplicity=2, normalize='unknown')\n    with pytest.raises(ValueError):\n        Attri2Vec(layer_sizes=[4])\n    G = example_graph(feature_size=3)\n    gen = Attri2VecNodeGenerator(G, batch_size=2)\n    attri2vec = Attri2Vec(layer_sizes=[4, 8], generator=gen, bias=True)\n    assert (attri2vec.dims == [3, 4, 8])\n    assert (attri2vec.input_node_num == 4)\n    assert (attri2vec.n_layers == 2)\n    assert attri2vec.bias", "masked_code": "def test_attri2vec_constructor():\n    attri2vec = Attri2Vec(layer_sizes=[4], input_dim=2, node_num=4, multiplicity=2, normalize='l2')\n    assert (attri2vec.dims == [2, 4])\n    assert (attri2vec.input_node_num == '???')\n    assert (attri2vec.n_layers == 1)\n    assert (attri2vec.bias == False)\n    with pytest.raises(ValueError):\n        Attri2Vec(layer_sizes=[4], input_dim=2, node_num=4, multiplicity=2, activation='unknown')\n    with pytest.raises(ValueError):\n        Attri2Vec(layer_sizes=[4], input_dim=2, node_num=4, multiplicity=2, normalize=(lambda x: x))\n    with pytest.raises(ValueError):\n        Attri2Vec(layer_sizes=[4], input_dim=2, node_num=4, multiplicity=2, normalize='unknown')\n    with pytest.raises(ValueError):\n        Attri2Vec(layer_sizes=[4])\n    G = example_graph(feature_size=3)\n    gen = Attri2VecNodeGenerator(G, batch_size=2)\n    attri2vec = Attri2Vec(layer_sizes=[4, 8], generator=gen, bias=True)\n    assert (attri2vec.dims == [3, 4, 8])\n    assert (attri2vec.input_node_num == 4)\n    assert (attri2vec.n_layers == 2)\n    assert attri2vec.bias", "ground_truth": "4", "quality_analysis": {"complexity_score": 3, "left_complexity": 2, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_514", "reponame": "stellargraph", "testpath": "tests/layer/test_attri2vec.py", "testname": "test_attri2vec.py", "classname": null, "funcname": "test_attri2vec_constructor", "imports": ["from stellargraph.core.graph import StellarGraph", "from stellargraph.mapper import Attri2VecNodeGenerator", "from stellargraph.layer.attri2vec import *", "from tensorflow import keras", "import numpy as np", "import networkx as nx", "import pytest", "from ..test_utils.graphs import example_graph", "from .. import test_utils"], "code": "def test_attri2vec_constructor():\n    attri2vec = Attri2Vec(layer_sizes=[4], input_dim=2, node_num=4, multiplicity=2, normalize='l2')\n    assert (attri2vec.dims == [2, 4])\n    assert (attri2vec.input_node_num == 4)\n    assert (attri2vec.n_layers == 1)\n    assert (attri2vec.bias == False)\n    with pytest.raises(ValueError):\n        Attri2Vec(layer_sizes=[4], input_dim=2, node_num=4, multiplicity=2, activation='unknown')\n    with pytest.raises(ValueError):\n        Attri2Vec(layer_sizes=[4], input_dim=2, node_num=4, multiplicity=2, normalize=(lambda x: x))\n    with pytest.raises(ValueError):\n        Attri2Vec(layer_sizes=[4], input_dim=2, node_num=4, multiplicity=2, normalize='unknown')\n    with pytest.raises(ValueError):\n        Attri2Vec(layer_sizes=[4])\n    G = example_graph(feature_size=3)\n    gen = Attri2VecNodeGenerator(G, batch_size=2)\n    attri2vec = Attri2Vec(layer_sizes=[4, 8], generator=gen, bias=True)\n    assert (attri2vec.dims == [3, 4, 8])\n    assert (attri2vec.input_node_num == 4)\n    assert (attri2vec.n_layers == 2)\n    assert attri2vec.bias", "masked_code": "def test_attri2vec_constructor():\n    attri2vec = Attri2Vec(layer_sizes=[4], input_dim=2, node_num=4, multiplicity=2, normalize='l2')\n    assert (attri2vec.dims == [2, 4])\n    assert (attri2vec.input_node_num == 4)\n    assert (attri2vec.n_layers == 1)\n    assert (attri2vec.bias == False)\n    with pytest.raises(ValueError):\n        Attri2Vec(layer_sizes=[4], input_dim=2, node_num=4, multiplicity=2, activation='unknown')\n    with pytest.raises(ValueError):\n        Attri2Vec(layer_sizes=[4], input_dim=2, node_num=4, multiplicity=2, normalize=(lambda x: x))\n    with pytest.raises(ValueError):\n        Attri2Vec(layer_sizes=[4], input_dim=2, node_num=4, multiplicity=2, normalize='unknown')\n    with pytest.raises(ValueError):\n        Attri2Vec(layer_sizes=[4])\n    G = example_graph(feature_size=3)\n    gen = Attri2VecNodeGenerator(G, batch_size=2)\n    attri2vec = Attri2Vec(layer_sizes=[4, 8], generator=gen, bias=True)\n    assert (attri2vec.dims == '???')\n    assert (attri2vec.input_node_num == 4)\n    assert (attri2vec.n_layers == 2)\n    assert attri2vec.bias", "ground_truth": "[3, 4, 8]", "quality_analysis": {"complexity_score": 7, "left_complexity": 2, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_515", "reponame": "stellargraph", "testpath": "tests/layer/test_attri2vec.py", "testname": "test_attri2vec.py", "classname": null, "funcname": "test_attri2vec_constructor", "imports": ["from stellargraph.core.graph import StellarGraph", "from stellargraph.mapper import Attri2VecNodeGenerator", "from stellargraph.layer.attri2vec import *", "from tensorflow import keras", "import numpy as np", "import networkx as nx", "import pytest", "from ..test_utils.graphs import example_graph", "from .. import test_utils"], "code": "def test_attri2vec_constructor():\n    attri2vec = Attri2Vec(layer_sizes=[4], input_dim=2, node_num=4, multiplicity=2, normalize='l2')\n    assert (attri2vec.dims == [2, 4])\n    assert (attri2vec.input_node_num == 4)\n    assert (attri2vec.n_layers == 1)\n    assert (attri2vec.bias == False)\n    with pytest.raises(ValueError):\n        Attri2Vec(layer_sizes=[4], input_dim=2, node_num=4, multiplicity=2, activation='unknown')\n    with pytest.raises(ValueError):\n        Attri2Vec(layer_sizes=[4], input_dim=2, node_num=4, multiplicity=2, normalize=(lambda x: x))\n    with pytest.raises(ValueError):\n        Attri2Vec(layer_sizes=[4], input_dim=2, node_num=4, multiplicity=2, normalize='unknown')\n    with pytest.raises(ValueError):\n        Attri2Vec(layer_sizes=[4])\n    G = example_graph(feature_size=3)\n    gen = Attri2VecNodeGenerator(G, batch_size=2)\n    attri2vec = Attri2Vec(layer_sizes=[4, 8], generator=gen, bias=True)\n    assert (attri2vec.dims == [3, 4, 8])\n    assert (attri2vec.input_node_num == 4)\n    assert (attri2vec.n_layers == 2)\n    assert attri2vec.bias", "masked_code": "def test_attri2vec_constructor():\n    attri2vec = Attri2Vec(layer_sizes=[4], input_dim=2, node_num=4, multiplicity=2, normalize='l2')\n    assert (attri2vec.dims == [2, 4])\n    assert (attri2vec.input_node_num == 4)\n    assert (attri2vec.n_layers == 1)\n    assert (attri2vec.bias == False)\n    with pytest.raises(ValueError):\n        Attri2Vec(layer_sizes=[4], input_dim=2, node_num=4, multiplicity=2, activation='unknown')\n    with pytest.raises(ValueError):\n        Attri2Vec(layer_sizes=[4], input_dim=2, node_num=4, multiplicity=2, normalize=(lambda x: x))\n    with pytest.raises(ValueError):\n        Attri2Vec(layer_sizes=[4], input_dim=2, node_num=4, multiplicity=2, normalize='unknown')\n    with pytest.raises(ValueError):\n        Attri2Vec(layer_sizes=[4])\n    G = example_graph(feature_size=3)\n    gen = Attri2VecNodeGenerator(G, batch_size=2)\n    attri2vec = Attri2Vec(layer_sizes=[4, 8], generator=gen, bias=True)\n    assert (attri2vec.dims == [3, 4, 8])\n    assert (attri2vec.input_node_num == '???')\n    assert (attri2vec.n_layers == 2)\n    assert attri2vec.bias", "ground_truth": "4", "quality_analysis": {"complexity_score": 3, "left_complexity": 2, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_516", "reponame": "stellargraph", "testpath": "tests/layer/test_attri2vec.py", "testname": "test_attri2vec.py", "classname": null, "funcname": "test_attri2vec_apply", "imports": ["from stellargraph.core.graph import StellarGraph", "from stellargraph.mapper import Attri2VecNodeGenerator", "from stellargraph.layer.attri2vec import *", "from tensorflow import keras", "import numpy as np", "import networkx as nx", "import pytest", "from ..test_utils.graphs import example_graph", "from .. import test_utils"], "code": "def test_attri2vec_apply():\n    attri2vec = Attri2Vec(layer_sizes=[2, 2, 2], bias=False, input_dim=2, node_num=4, multiplicity=2, activation='linear', normalize=None)\n    model = keras.Model(*attri2vec.in_out_tensors())\n    model.set_weights([np.ones_like(w) for w in model.get_weights()])\n    x = np.array([[1, 2]])\n    expected = np.array([[12, 12]])\n    inp = keras.Input(shape=(2,))\n    out = attri2vec(inp)\n    model1 = keras.Model(inputs=inp, outputs=out)\n    actual = model1.predict(x)\n    assert (expected == pytest.approx(actual))\n    (xinp, xout) = attri2vec.in_out_tensors(multiplicity=1)\n    model2 = keras.Model(inputs=xinp, outputs=xout)\n    assert (pytest.approx(expected) == model2.predict(x))\n    x1 = np.array([[3, 1]])\n    x2 = np.array([[2]])\n    y1 = np.array([[16, 16]])\n    y2 = np.array([[1, 1]])\n    (xinp, xout) = attri2vec.in_out_tensors()\n    model3 = keras.Model(inputs=xinp, outputs=xout)\n    actual = model3.predict([x1, x2])\n    assert (pytest.approx(y1) == actual[0])\n    assert (pytest.approx(y2) == actual[1])\n    (xinp, xout) = attri2vec.in_out_tensors()\n    model4 = keras.Model(inputs=xinp, outputs=xout)\n    actual = model4.predict([x1, x2])\n    assert (pytest.approx(y1) == actual[0])\n    assert (pytest.approx(y2) == actual[1])", "masked_code": "def test_attri2vec_apply():\n    attri2vec = Attri2Vec(layer_sizes=[2, 2, 2], bias=False, input_dim=2, node_num=4, multiplicity=2, activation='linear', normalize=None)\n    model = keras.Model(*attri2vec.in_out_tensors())\n    model.set_weights([np.ones_like(w) for w in model.get_weights()])\n    x = np.array([[1, 2]])\n    expected = np.array([[12, 12]])\n    inp = keras.Input(shape=(2,))\n    out = attri2vec(inp)\n    model1 = keras.Model(inputs=inp, outputs=out)\n    actual = model1.predict(x)\n    assert (expected == pytest.approx(actual))\n    (xinp, xout) = attri2vec.in_out_tensors(multiplicity=1)\n    model2 = keras.Model(inputs=xinp, outputs=xout)\n    assert (pytest.approx(expected) == '???')\n    x1 = np.array([[3, 1]])\n    x2 = np.array([[2]])\n    y1 = np.array([[16, 16]])\n    y2 = np.array([[1, 1]])\n    (xinp, xout) = attri2vec.in_out_tensors()\n    model3 = keras.Model(inputs=xinp, outputs=xout)\n    actual = model3.predict([x1, x2])\n    assert (pytest.approx(y1) == actual[0])\n    assert (pytest.approx(y2) == actual[1])\n    (xinp, xout) = attri2vec.in_out_tensors()\n    model4 = keras.Model(inputs=xinp, outputs=xout)\n    actual = model4.predict([x1, x2])\n    assert (pytest.approx(y1) == actual[0])\n    assert (pytest.approx(y2) == actual[1])", "ground_truth": "model2.predict(x)", "quality_analysis": {"complexity_score": 8, "left_complexity": 4, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_517", "reponame": "stellargraph", "testpath": "tests/layer/test_attri2vec.py", "testname": "test_attri2vec.py", "classname": null, "funcname": "test_attri2vec_apply", "imports": ["from stellargraph.core.graph import StellarGraph", "from stellargraph.mapper import Attri2VecNodeGenerator", "from stellargraph.layer.attri2vec import *", "from tensorflow import keras", "import numpy as np", "import networkx as nx", "import pytest", "from ..test_utils.graphs import example_graph", "from .. import test_utils"], "code": "def test_attri2vec_apply():\n    attri2vec = Attri2Vec(layer_sizes=[2, 2, 2], bias=False, input_dim=2, node_num=4, multiplicity=2, activation='linear', normalize=None)\n    model = keras.Model(*attri2vec.in_out_tensors())\n    model.set_weights([np.ones_like(w) for w in model.get_weights()])\n    x = np.array([[1, 2]])\n    expected = np.array([[12, 12]])\n    inp = keras.Input(shape=(2,))\n    out = attri2vec(inp)\n    model1 = keras.Model(inputs=inp, outputs=out)\n    actual = model1.predict(x)\n    assert (expected == pytest.approx(actual))\n    (xinp, xout) = attri2vec.in_out_tensors(multiplicity=1)\n    model2 = keras.Model(inputs=xinp, outputs=xout)\n    assert (pytest.approx(expected) == model2.predict(x))\n    x1 = np.array([[3, 1]])\n    x2 = np.array([[2]])\n    y1 = np.array([[16, 16]])\n    y2 = np.array([[1, 1]])\n    (xinp, xout) = attri2vec.in_out_tensors()\n    model3 = keras.Model(inputs=xinp, outputs=xout)\n    actual = model3.predict([x1, x2])\n    assert (pytest.approx(y1) == actual[0])\n    assert (pytest.approx(y2) == actual[1])\n    (xinp, xout) = attri2vec.in_out_tensors()\n    model4 = keras.Model(inputs=xinp, outputs=xout)\n    actual = model4.predict([x1, x2])\n    assert (pytest.approx(y1) == actual[0])\n    assert (pytest.approx(y2) == actual[1])", "masked_code": "def test_attri2vec_apply():\n    attri2vec = Attri2Vec(layer_sizes=[2, 2, 2], bias=False, input_dim=2, node_num=4, multiplicity=2, activation='linear', normalize=None)\n    model = keras.Model(*attri2vec.in_out_tensors())\n    model.set_weights([np.ones_like(w) for w in model.get_weights()])\n    x = np.array([[1, 2]])\n    expected = np.array([[12, 12]])\n    inp = keras.Input(shape=(2,))\n    out = attri2vec(inp)\n    model1 = keras.Model(inputs=inp, outputs=out)\n    actual = model1.predict(x)\n    assert (expected == pytest.approx(actual))\n    (xinp, xout) = attri2vec.in_out_tensors(multiplicity=1)\n    model2 = keras.Model(inputs=xinp, outputs=xout)\n    assert (pytest.approx(expected) == model2.predict(x))\n    x1 = np.array([[3, 1]])\n    x2 = np.array([[2]])\n    y1 = np.array([[16, 16]])\n    y2 = np.array([[1, 1]])\n    (xinp, xout) = attri2vec.in_out_tensors()\n    model3 = keras.Model(inputs=xinp, outputs=xout)\n    actual = model3.predict([x1, x2])\n    assert (pytest.approx(y1) == '???')\n    assert (pytest.approx(y2) == actual[1])\n    (xinp, xout) = attri2vec.in_out_tensors()\n    model4 = keras.Model(inputs=xinp, outputs=xout)\n    actual = model4.predict([x1, x2])\n    assert (pytest.approx(y1) == actual[0])\n    assert (pytest.approx(y2) == actual[1])", "ground_truth": "actual[0]", "quality_analysis": {"complexity_score": 9, "left_complexity": 4, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_518", "reponame": "stellargraph", "testpath": "tests/layer/test_attri2vec.py", "testname": "test_attri2vec.py", "classname": null, "funcname": "test_attri2vec_apply", "imports": ["from stellargraph.core.graph import StellarGraph", "from stellargraph.mapper import Attri2VecNodeGenerator", "from stellargraph.layer.attri2vec import *", "from tensorflow import keras", "import numpy as np", "import networkx as nx", "import pytest", "from ..test_utils.graphs import example_graph", "from .. import test_utils"], "code": "def test_attri2vec_apply():\n    attri2vec = Attri2Vec(layer_sizes=[2, 2, 2], bias=False, input_dim=2, node_num=4, multiplicity=2, activation='linear', normalize=None)\n    model = keras.Model(*attri2vec.in_out_tensors())\n    model.set_weights([np.ones_like(w) for w in model.get_weights()])\n    x = np.array([[1, 2]])\n    expected = np.array([[12, 12]])\n    inp = keras.Input(shape=(2,))\n    out = attri2vec(inp)\n    model1 = keras.Model(inputs=inp, outputs=out)\n    actual = model1.predict(x)\n    assert (expected == pytest.approx(actual))\n    (xinp, xout) = attri2vec.in_out_tensors(multiplicity=1)\n    model2 = keras.Model(inputs=xinp, outputs=xout)\n    assert (pytest.approx(expected) == model2.predict(x))\n    x1 = np.array([[3, 1]])\n    x2 = np.array([[2]])\n    y1 = np.array([[16, 16]])\n    y2 = np.array([[1, 1]])\n    (xinp, xout) = attri2vec.in_out_tensors()\n    model3 = keras.Model(inputs=xinp, outputs=xout)\n    actual = model3.predict([x1, x2])\n    assert (pytest.approx(y1) == actual[0])\n    assert (pytest.approx(y2) == actual[1])\n    (xinp, xout) = attri2vec.in_out_tensors()\n    model4 = keras.Model(inputs=xinp, outputs=xout)\n    actual = model4.predict([x1, x2])\n    assert (pytest.approx(y1) == actual[0])\n    assert (pytest.approx(y2) == actual[1])", "masked_code": "def test_attri2vec_apply():\n    attri2vec = Attri2Vec(layer_sizes=[2, 2, 2], bias=False, input_dim=2, node_num=4, multiplicity=2, activation='linear', normalize=None)\n    model = keras.Model(*attri2vec.in_out_tensors())\n    model.set_weights([np.ones_like(w) for w in model.get_weights()])\n    x = np.array([[1, 2]])\n    expected = np.array([[12, 12]])\n    inp = keras.Input(shape=(2,))\n    out = attri2vec(inp)\n    model1 = keras.Model(inputs=inp, outputs=out)\n    actual = model1.predict(x)\n    assert (expected == pytest.approx(actual))\n    (xinp, xout) = attri2vec.in_out_tensors(multiplicity=1)\n    model2 = keras.Model(inputs=xinp, outputs=xout)\n    assert (pytest.approx(expected) == model2.predict(x))\n    x1 = np.array([[3, 1]])\n    x2 = np.array([[2]])\n    y1 = np.array([[16, 16]])\n    y2 = np.array([[1, 1]])\n    (xinp, xout) = attri2vec.in_out_tensors()\n    model3 = keras.Model(inputs=xinp, outputs=xout)\n    actual = model3.predict([x1, x2])\n    assert (pytest.approx(y1) == actual[0])\n    assert (pytest.approx(y2) == '???')\n    (xinp, xout) = attri2vec.in_out_tensors()\n    model4 = keras.Model(inputs=xinp, outputs=xout)\n    actual = model4.predict([x1, x2])\n    assert (pytest.approx(y1) == actual[0])\n    assert (pytest.approx(y2) == actual[1])", "ground_truth": "actual[1]", "quality_analysis": {"complexity_score": 9, "left_complexity": 4, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_519", "reponame": "stellargraph", "testpath": "tests/layer/test_attri2vec.py", "testname": "test_attri2vec.py", "classname": null, "funcname": "test_attri2vec_apply", "imports": ["from stellargraph.core.graph import StellarGraph", "from stellargraph.mapper import Attri2VecNodeGenerator", "from stellargraph.layer.attri2vec import *", "from tensorflow import keras", "import numpy as np", "import networkx as nx", "import pytest", "from ..test_utils.graphs import example_graph", "from .. import test_utils"], "code": "def test_attri2vec_apply():\n    attri2vec = Attri2Vec(layer_sizes=[2, 2, 2], bias=False, input_dim=2, node_num=4, multiplicity=2, activation='linear', normalize=None)\n    model = keras.Model(*attri2vec.in_out_tensors())\n    model.set_weights([np.ones_like(w) for w in model.get_weights()])\n    x = np.array([[1, 2]])\n    expected = np.array([[12, 12]])\n    inp = keras.Input(shape=(2,))\n    out = attri2vec(inp)\n    model1 = keras.Model(inputs=inp, outputs=out)\n    actual = model1.predict(x)\n    assert (expected == pytest.approx(actual))\n    (xinp, xout) = attri2vec.in_out_tensors(multiplicity=1)\n    model2 = keras.Model(inputs=xinp, outputs=xout)\n    assert (pytest.approx(expected) == model2.predict(x))\n    x1 = np.array([[3, 1]])\n    x2 = np.array([[2]])\n    y1 = np.array([[16, 16]])\n    y2 = np.array([[1, 1]])\n    (xinp, xout) = attri2vec.in_out_tensors()\n    model3 = keras.Model(inputs=xinp, outputs=xout)\n    actual = model3.predict([x1, x2])\n    assert (pytest.approx(y1) == actual[0])\n    assert (pytest.approx(y2) == actual[1])\n    (xinp, xout) = attri2vec.in_out_tensors()\n    model4 = keras.Model(inputs=xinp, outputs=xout)\n    actual = model4.predict([x1, x2])\n    assert (pytest.approx(y1) == actual[0])\n    assert (pytest.approx(y2) == actual[1])", "masked_code": "def test_attri2vec_apply():\n    attri2vec = Attri2Vec(layer_sizes=[2, 2, 2], bias=False, input_dim=2, node_num=4, multiplicity=2, activation='linear', normalize=None)\n    model = keras.Model(*attri2vec.in_out_tensors())\n    model.set_weights([np.ones_like(w) for w in model.get_weights()])\n    x = np.array([[1, 2]])\n    expected = np.array([[12, 12]])\n    inp = keras.Input(shape=(2,))\n    out = attri2vec(inp)\n    model1 = keras.Model(inputs=inp, outputs=out)\n    actual = model1.predict(x)\n    assert (expected == pytest.approx(actual))\n    (xinp, xout) = attri2vec.in_out_tensors(multiplicity=1)\n    model2 = keras.Model(inputs=xinp, outputs=xout)\n    assert (pytest.approx(expected) == model2.predict(x))\n    x1 = np.array([[3, 1]])\n    x2 = np.array([[2]])\n    y1 = np.array([[16, 16]])\n    y2 = np.array([[1, 1]])\n    (xinp, xout) = attri2vec.in_out_tensors()\n    model3 = keras.Model(inputs=xinp, outputs=xout)\n    actual = model3.predict([x1, x2])\n    assert (pytest.approx(y1) == actual[0])\n    assert (pytest.approx(y2) == actual[1])\n    (xinp, xout) = attri2vec.in_out_tensors()\n    model4 = keras.Model(inputs=xinp, outputs=xout)\n    actual = model4.predict([x1, x2])\n    assert (pytest.approx(y1) == '???')\n    assert (pytest.approx(y2) == actual[1])", "ground_truth": "actual[0]", "quality_analysis": {"complexity_score": 9, "left_complexity": 4, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_520", "reponame": "stellargraph", "testpath": "tests/layer/test_attri2vec.py", "testname": "test_attri2vec.py", "classname": null, "funcname": "test_attri2vec_apply", "imports": ["from stellargraph.core.graph import StellarGraph", "from stellargraph.mapper import Attri2VecNodeGenerator", "from stellargraph.layer.attri2vec import *", "from tensorflow import keras", "import numpy as np", "import networkx as nx", "import pytest", "from ..test_utils.graphs import example_graph", "from .. import test_utils"], "code": "def test_attri2vec_apply():\n    attri2vec = Attri2Vec(layer_sizes=[2, 2, 2], bias=False, input_dim=2, node_num=4, multiplicity=2, activation='linear', normalize=None)\n    model = keras.Model(*attri2vec.in_out_tensors())\n    model.set_weights([np.ones_like(w) for w in model.get_weights()])\n    x = np.array([[1, 2]])\n    expected = np.array([[12, 12]])\n    inp = keras.Input(shape=(2,))\n    out = attri2vec(inp)\n    model1 = keras.Model(inputs=inp, outputs=out)\n    actual = model1.predict(x)\n    assert (expected == pytest.approx(actual))\n    (xinp, xout) = attri2vec.in_out_tensors(multiplicity=1)\n    model2 = keras.Model(inputs=xinp, outputs=xout)\n    assert (pytest.approx(expected) == model2.predict(x))\n    x1 = np.array([[3, 1]])\n    x2 = np.array([[2]])\n    y1 = np.array([[16, 16]])\n    y2 = np.array([[1, 1]])\n    (xinp, xout) = attri2vec.in_out_tensors()\n    model3 = keras.Model(inputs=xinp, outputs=xout)\n    actual = model3.predict([x1, x2])\n    assert (pytest.approx(y1) == actual[0])\n    assert (pytest.approx(y2) == actual[1])\n    (xinp, xout) = attri2vec.in_out_tensors()\n    model4 = keras.Model(inputs=xinp, outputs=xout)\n    actual = model4.predict([x1, x2])\n    assert (pytest.approx(y1) == actual[0])\n    assert (pytest.approx(y2) == actual[1])", "masked_code": "def test_attri2vec_apply():\n    attri2vec = Attri2Vec(layer_sizes=[2, 2, 2], bias=False, input_dim=2, node_num=4, multiplicity=2, activation='linear', normalize=None)\n    model = keras.Model(*attri2vec.in_out_tensors())\n    model.set_weights([np.ones_like(w) for w in model.get_weights()])\n    x = np.array([[1, 2]])\n    expected = np.array([[12, 12]])\n    inp = keras.Input(shape=(2,))\n    out = attri2vec(inp)\n    model1 = keras.Model(inputs=inp, outputs=out)\n    actual = model1.predict(x)\n    assert (expected == pytest.approx(actual))\n    (xinp, xout) = attri2vec.in_out_tensors(multiplicity=1)\n    model2 = keras.Model(inputs=xinp, outputs=xout)\n    assert (pytest.approx(expected) == model2.predict(x))\n    x1 = np.array([[3, 1]])\n    x2 = np.array([[2]])\n    y1 = np.array([[16, 16]])\n    y2 = np.array([[1, 1]])\n    (xinp, xout) = attri2vec.in_out_tensors()\n    model3 = keras.Model(inputs=xinp, outputs=xout)\n    actual = model3.predict([x1, x2])\n    assert (pytest.approx(y1) == actual[0])\n    assert (pytest.approx(y2) == actual[1])\n    (xinp, xout) = attri2vec.in_out_tensors()\n    model4 = keras.Model(inputs=xinp, outputs=xout)\n    actual = model4.predict([x1, x2])\n    assert (pytest.approx(y1) == actual[0])\n    assert (pytest.approx(y2) == '???')", "ground_truth": "actual[1]", "quality_analysis": {"complexity_score": 9, "left_complexity": 4, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_521", "reponame": "stellargraph", "testpath": "tests/layer/test_cluster_gcn.py", "testname": "test_cluster_gcn.py", "classname": null, "funcname": "test_ClusterGCN_init", "imports": ["from tensorflow.keras import backend as K", "from stellargraph.layer.cluster_gcn import *", "from stellargraph.mapper import ClusterNodeGenerator", "from stellargraph.core.graph import StellarGraph", "import pandas as pd", "import numpy as np", "from tensorflow import keras", "import tensorflow as tf", "import pytest", "from ..test_utils.graphs import create_graph_features", "from .. import test_utils"], "code": "def test_ClusterGCN_init():\n    (G, features) = create_graph_features()\n    generator = ClusterNodeGenerator(G)\n    cluster_gcn_model = ClusterGCN(layer_sizes=[2], generator=generator, activations=['relu'], dropout=0.5)\n    assert (cluster_gcn_model.layer_sizes == [2])\n    assert (cluster_gcn_model.activations == ['relu'])\n    assert (cluster_gcn_model.dropout == 0.5)", "masked_code": "def test_ClusterGCN_init():\n    (G, features) = create_graph_features()\n    generator = ClusterNodeGenerator(G)\n    cluster_gcn_model = ClusterGCN(layer_sizes=[2], generator=generator, activations=['relu'], dropout=0.5)\n    assert (cluster_gcn_model.layer_sizes == '???')\n    assert (cluster_gcn_model.activations == ['relu'])\n    assert (cluster_gcn_model.dropout == 0.5)", "ground_truth": "[2]", "quality_analysis": {"complexity_score": 5, "left_complexity": 2, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_522", "reponame": "stellargraph", "testpath": "tests/layer/test_cluster_gcn.py", "testname": "test_cluster_gcn.py", "classname": null, "funcname": "test_ClusterGCN_init", "imports": ["from tensorflow.keras import backend as K", "from stellargraph.layer.cluster_gcn import *", "from stellargraph.mapper import ClusterNodeGenerator", "from stellargraph.core.graph import StellarGraph", "import pandas as pd", "import numpy as np", "from tensorflow import keras", "import tensorflow as tf", "import pytest", "from ..test_utils.graphs import create_graph_features", "from .. import test_utils"], "code": "def test_ClusterGCN_init():\n    (G, features) = create_graph_features()\n    generator = ClusterNodeGenerator(G)\n    cluster_gcn_model = ClusterGCN(layer_sizes=[2], generator=generator, activations=['relu'], dropout=0.5)\n    assert (cluster_gcn_model.layer_sizes == [2])\n    assert (cluster_gcn_model.activations == ['relu'])\n    assert (cluster_gcn_model.dropout == 0.5)", "masked_code": "def test_ClusterGCN_init():\n    (G, features) = create_graph_features()\n    generator = ClusterNodeGenerator(G)\n    cluster_gcn_model = ClusterGCN(layer_sizes=[2], generator=generator, activations=['relu'], dropout=0.5)\n    assert (cluster_gcn_model.layer_sizes == [2])\n    assert (cluster_gcn_model.activations == '???')\n    assert (cluster_gcn_model.dropout == 0.5)", "ground_truth": "['relu']", "quality_analysis": {"complexity_score": 5, "left_complexity": 2, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_523", "reponame": "stellargraph", "testpath": "tests/layer/test_cluster_gcn.py", "testname": "test_cluster_gcn.py", "classname": null, "funcname": "test_ClusterGCN_init", "imports": ["from tensorflow.keras import backend as K", "from stellargraph.layer.cluster_gcn import *", "from stellargraph.mapper import ClusterNodeGenerator", "from stellargraph.core.graph import StellarGraph", "import pandas as pd", "import numpy as np", "from tensorflow import keras", "import tensorflow as tf", "import pytest", "from ..test_utils.graphs import create_graph_features", "from .. import test_utils"], "code": "def test_ClusterGCN_init():\n    (G, features) = create_graph_features()\n    generator = ClusterNodeGenerator(G)\n    cluster_gcn_model = ClusterGCN(layer_sizes=[2], generator=generator, activations=['relu'], dropout=0.5)\n    assert (cluster_gcn_model.layer_sizes == [2])\n    assert (cluster_gcn_model.activations == ['relu'])\n    assert (cluster_gcn_model.dropout == 0.5)", "masked_code": "def test_ClusterGCN_init():\n    (G, features) = create_graph_features()\n    generator = ClusterNodeGenerator(G)\n    cluster_gcn_model = ClusterGCN(layer_sizes=[2], generator=generator, activations=['relu'], dropout=0.5)\n    assert (cluster_gcn_model.layer_sizes == [2])\n    assert (cluster_gcn_model.activations == ['relu'])\n    assert (cluster_gcn_model.dropout == '???')", "ground_truth": "0.5", "quality_analysis": {"complexity_score": 3, "left_complexity": 2, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_524", "reponame": "stellargraph", "testpath": "tests/layer/test_cluster_gcn.py", "testname": "test_cluster_gcn.py", "classname": null, "funcname": "test_ClusterGCN_apply", "imports": ["from tensorflow.keras import backend as K", "from stellargraph.layer.cluster_gcn import *", "from stellargraph.mapper import ClusterNodeGenerator", "from stellargraph.core.graph import StellarGraph", "import pandas as pd", "import numpy as np", "from tensorflow import keras", "import tensorflow as tf", "import pytest", "from ..test_utils.graphs import create_graph_features", "from .. import test_utils"], "code": "def test_ClusterGCN_apply():\n    (G, _) = create_graph_features()\n    generator = ClusterNodeGenerator(G)\n    cluster_gcn_model = ClusterGCN(layer_sizes=[2], generator=generator, activations=['relu'], dropout=0.0)\n    (x_in, x_out) = cluster_gcn_model.in_out_tensors()\n    model = keras.Model(inputs=x_in, outputs=x_out)\n    preds_2 = model.predict(generator.flow(['a', 'b', 'c']))\n    assert (preds_2.shape == (1, 3, 2))", "masked_code": "def test_ClusterGCN_apply():\n    (G, _) = create_graph_features()\n    generator = ClusterNodeGenerator(G)\n    cluster_gcn_model = ClusterGCN(layer_sizes=[2], generator=generator, activations=['relu'], dropout=0.0)\n    (x_in, x_out) = cluster_gcn_model.in_out_tensors()\n    model = keras.Model(inputs=x_in, outputs=x_out)\n    preds_2 = model.predict(generator.flow(['a', 'b', 'c']))\n    assert (preds_2.shape == '???')", "ground_truth": "(1, 3, 2)", "quality_analysis": {"complexity_score": 7, "left_complexity": 2, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_525", "reponame": "stellargraph", "testpath": "tests/layer/test_cluster_gcn.py", "testname": "test_cluster_gcn.py", "classname": null, "funcname": "test_ClusterGCN_activations", "imports": ["from tensorflow.keras import backend as K", "from stellargraph.layer.cluster_gcn import *", "from stellargraph.mapper import ClusterNodeGenerator", "from stellargraph.core.graph import StellarGraph", "import pandas as pd", "import numpy as np", "from tensorflow import keras", "import tensorflow as tf", "import pytest", "from ..test_utils.graphs import create_graph_features", "from .. import test_utils"], "code": "def test_ClusterGCN_activations():\n    (G, _) = create_graph_features()\n    generator = ClusterNodeGenerator(G)\n    cluster_gcn = ClusterGCN(layer_sizes=[2], generator=generator, activations=['relu'])\n    assert (cluster_gcn.activations == ['relu'])\n    cluster_gcn = ClusterGCN(layer_sizes=[2, 2], generator=generator, activations=['relu', 'relu'])\n    assert (cluster_gcn.activations == ['relu', 'relu'])\n    cluster_gcn = ClusterGCN(layer_sizes=[2], generator=generator, activations=['linear'])\n    assert (cluster_gcn.activations == ['linear'])\n    with pytest.raises(TypeError):\n        ClusterGCN(layer_sizes=[2], generator=generator)\n    with pytest.raises(ValueError):\n        ClusterGCN(layer_sizes=[2], generator=generator, activations=['relu', 'linear'])\n    with pytest.raises(ValueError):\n        ClusterGCN(layer_sizes=[2, 2], generator=generator, activations=['relu'])\n    with pytest.raises(ValueError):\n        ClusterGCN(layer_sizes=[2], generator=generator, activations=['bleach'])", "masked_code": "def test_ClusterGCN_activations():\n    (G, _) = create_graph_features()\n    generator = ClusterNodeGenerator(G)\n    cluster_gcn = ClusterGCN(layer_sizes=[2], generator=generator, activations=['relu'])\n    assert (cluster_gcn.activations == '???')\n    cluster_gcn = ClusterGCN(layer_sizes=[2, 2], generator=generator, activations=['relu', 'relu'])\n    assert (cluster_gcn.activations == ['relu', 'relu'])\n    cluster_gcn = ClusterGCN(layer_sizes=[2], generator=generator, activations=['linear'])\n    assert (cluster_gcn.activations == ['linear'])\n    with pytest.raises(TypeError):\n        ClusterGCN(layer_sizes=[2], generator=generator)\n    with pytest.raises(ValueError):\n        ClusterGCN(layer_sizes=[2], generator=generator, activations=['relu', 'linear'])\n    with pytest.raises(ValueError):\n        ClusterGCN(layer_sizes=[2, 2], generator=generator, activations=['relu'])\n    with pytest.raises(ValueError):\n        ClusterGCN(layer_sizes=[2], generator=generator, activations=['bleach'])", "ground_truth": "['relu']", "quality_analysis": {"complexity_score": 5, "left_complexity": 2, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_526", "reponame": "stellargraph", "testpath": "tests/layer/test_cluster_gcn.py", "testname": "test_cluster_gcn.py", "classname": null, "funcname": "test_ClusterGCN_activations", "imports": ["from tensorflow.keras import backend as K", "from stellargraph.layer.cluster_gcn import *", "from stellargraph.mapper import ClusterNodeGenerator", "from stellargraph.core.graph import StellarGraph", "import pandas as pd", "import numpy as np", "from tensorflow import keras", "import tensorflow as tf", "import pytest", "from ..test_utils.graphs import create_graph_features", "from .. import test_utils"], "code": "def test_ClusterGCN_activations():\n    (G, _) = create_graph_features()\n    generator = ClusterNodeGenerator(G)\n    cluster_gcn = ClusterGCN(layer_sizes=[2], generator=generator, activations=['relu'])\n    assert (cluster_gcn.activations == ['relu'])\n    cluster_gcn = ClusterGCN(layer_sizes=[2, 2], generator=generator, activations=['relu', 'relu'])\n    assert (cluster_gcn.activations == ['relu', 'relu'])\n    cluster_gcn = ClusterGCN(layer_sizes=[2], generator=generator, activations=['linear'])\n    assert (cluster_gcn.activations == ['linear'])\n    with pytest.raises(TypeError):\n        ClusterGCN(layer_sizes=[2], generator=generator)\n    with pytest.raises(ValueError):\n        ClusterGCN(layer_sizes=[2], generator=generator, activations=['relu', 'linear'])\n    with pytest.raises(ValueError):\n        ClusterGCN(layer_sizes=[2, 2], generator=generator, activations=['relu'])\n    with pytest.raises(ValueError):\n        ClusterGCN(layer_sizes=[2], generator=generator, activations=['bleach'])", "masked_code": "def test_ClusterGCN_activations():\n    (G, _) = create_graph_features()\n    generator = ClusterNodeGenerator(G)\n    cluster_gcn = ClusterGCN(layer_sizes=[2], generator=generator, activations=['relu'])\n    assert (cluster_gcn.activations == ['relu'])\n    cluster_gcn = ClusterGCN(layer_sizes=[2, 2], generator=generator, activations=['relu', 'relu'])\n    assert (cluster_gcn.activations == '???')\n    cluster_gcn = ClusterGCN(layer_sizes=[2], generator=generator, activations=['linear'])\n    assert (cluster_gcn.activations == ['linear'])\n    with pytest.raises(TypeError):\n        ClusterGCN(layer_sizes=[2], generator=generator)\n    with pytest.raises(ValueError):\n        ClusterGCN(layer_sizes=[2], generator=generator, activations=['relu', 'linear'])\n    with pytest.raises(ValueError):\n        ClusterGCN(layer_sizes=[2, 2], generator=generator, activations=['relu'])\n    with pytest.raises(ValueError):\n        ClusterGCN(layer_sizes=[2], generator=generator, activations=['bleach'])", "ground_truth": "['relu', 'relu']", "quality_analysis": {"complexity_score": 6, "left_complexity": 2, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_527", "reponame": "stellargraph", "testpath": "tests/layer/test_cluster_gcn.py", "testname": "test_cluster_gcn.py", "classname": null, "funcname": "test_ClusterGCN_activations", "imports": ["from tensorflow.keras import backend as K", "from stellargraph.layer.cluster_gcn import *", "from stellargraph.mapper import ClusterNodeGenerator", "from stellargraph.core.graph import StellarGraph", "import pandas as pd", "import numpy as np", "from tensorflow import keras", "import tensorflow as tf", "import pytest", "from ..test_utils.graphs import create_graph_features", "from .. import test_utils"], "code": "def test_ClusterGCN_activations():\n    (G, _) = create_graph_features()\n    generator = ClusterNodeGenerator(G)\n    cluster_gcn = ClusterGCN(layer_sizes=[2], generator=generator, activations=['relu'])\n    assert (cluster_gcn.activations == ['relu'])\n    cluster_gcn = ClusterGCN(layer_sizes=[2, 2], generator=generator, activations=['relu', 'relu'])\n    assert (cluster_gcn.activations == ['relu', 'relu'])\n    cluster_gcn = ClusterGCN(layer_sizes=[2], generator=generator, activations=['linear'])\n    assert (cluster_gcn.activations == ['linear'])\n    with pytest.raises(TypeError):\n        ClusterGCN(layer_sizes=[2], generator=generator)\n    with pytest.raises(ValueError):\n        ClusterGCN(layer_sizes=[2], generator=generator, activations=['relu', 'linear'])\n    with pytest.raises(ValueError):\n        ClusterGCN(layer_sizes=[2, 2], generator=generator, activations=['relu'])\n    with pytest.raises(ValueError):\n        ClusterGCN(layer_sizes=[2], generator=generator, activations=['bleach'])", "masked_code": "def test_ClusterGCN_activations():\n    (G, _) = create_graph_features()\n    generator = ClusterNodeGenerator(G)\n    cluster_gcn = ClusterGCN(layer_sizes=[2], generator=generator, activations=['relu'])\n    assert (cluster_gcn.activations == ['relu'])\n    cluster_gcn = ClusterGCN(layer_sizes=[2, 2], generator=generator, activations=['relu', 'relu'])\n    assert (cluster_gcn.activations == ['relu', 'relu'])\n    cluster_gcn = ClusterGCN(layer_sizes=[2], generator=generator, activations=['linear'])\n    assert (cluster_gcn.activations == '???')\n    with pytest.raises(TypeError):\n        ClusterGCN(layer_sizes=[2], generator=generator)\n    with pytest.raises(ValueError):\n        ClusterGCN(layer_sizes=[2], generator=generator, activations=['relu', 'linear'])\n    with pytest.raises(ValueError):\n        ClusterGCN(layer_sizes=[2, 2], generator=generator, activations=['relu'])\n    with pytest.raises(ValueError):\n        ClusterGCN(layer_sizes=[2], generator=generator, activations=['bleach'])", "ground_truth": "['linear']", "quality_analysis": {"complexity_score": 5, "left_complexity": 2, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_528", "reponame": "stellargraph", "testpath": "tests/layer/test_cluster_models.py", "testname": "test_cluster_models.py", "classname": null, "funcname": "test_fullbatch_cluster_models", "imports": ["from stellargraph.layer import APPNP, GAT, GCN", "from stellargraph.mapper import ClusterNodeGenerator", "import tensorflow as tf", "import numpy as np", "from ..test_utils.graphs import example_graph_random", "import pytest"], "code": "@pytest.mark.parametrize('model_type', [APPNP, GAT, GCN])\ndef test_fullbatch_cluster_models(model_type):\n    G = example_graph_random(n_nodes=50)\n    generator = ClusterNodeGenerator(G, clusters=10)\n    nodes = G.nodes()[:40]\n    gen = generator.flow(nodes, targets=np.ones(len(nodes)))\n    gnn = model_type(generator=generator, layer_sizes=[16, 16, 1], activations=['relu', 'relu', 'relu'])\n    model = tf.keras.Model(*gnn.in_out_tensors())\n    model.compile(optimizer='adam', loss='binary_crossentropy')\n    history = model.fit(gen, validation_data=gen, epochs=2)\n    results = model.evaluate(gen)\n    (x_in, x_out) = gnn.in_out_tensors()\n    x_out_flat = tf.squeeze(x_out, 0)\n    embedding_model = tf.keras.Model(inputs=x_in, outputs=x_out_flat)\n    predictions = embedding_model.predict(gen)\n    assert (predictions.shape == (len(nodes), 1))", "masked_code": "@pytest.mark.parametrize('model_type', [APPNP, GAT, GCN])\ndef test_fullbatch_cluster_models(model_type):\n    G = example_graph_random(n_nodes=50)\n    generator = ClusterNodeGenerator(G, clusters=10)\n    nodes = G.nodes()[:40]\n    gen = generator.flow(nodes, targets=np.ones(len(nodes)))\n    gnn = model_type(generator=generator, layer_sizes=[16, 16, 1], activations=['relu', 'relu', 'relu'])\n    model = tf.keras.Model(*gnn.in_out_tensors())\n    model.compile(optimizer='adam', loss='binary_crossentropy')\n    history = model.fit(gen, validation_data=gen, epochs=2)\n    results = model.evaluate(gen)\n    (x_in, x_out) = gnn.in_out_tensors()\n    x_out_flat = tf.squeeze(x_out, 0)\n    embedding_model = tf.keras.Model(inputs=x_in, outputs=x_out_flat)\n    predictions = embedding_model.predict(gen)\n    assert (predictions.shape == '???')", "ground_truth": "(len(nodes), 1)", "quality_analysis": {"complexity_score": 9, "left_complexity": 2, "right_complexity": 7, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_529", "reponame": "stellargraph", "testpath": "tests/layer/test_deep_graph_infomax.py", "testname": "test_deep_graph_infomax.py", "classname": null, "funcname": "test_dgi", "imports": ["from stellargraph.layer import *", "from stellargraph.mapper import *", "from ..test_utils.graphs import example_graph_random", "from .. import require_gpu, test_utils", "import tensorflow as tf", "import pytest", "import numpy as np"], "code": "@pytest.mark.parametrize('model_type', [GCN, APPNP, GAT, PPNP, GraphSAGE, DirectedGraphSAGE, HinSAGE, RGCN])\n@pytest.mark.parametrize('sparse', [False, True])\ndef test_dgi(model_type, sparse):\n    (base_generator, base_model, nodes) = _model_data(model_type, sparse)\n    corrupted_generator = CorruptedGenerator(base_generator)\n    gen = corrupted_generator.flow(nodes)\n    infomax = DeepGraphInfomax(base_model, corrupted_generator)\n    model = tf.keras.Model(*infomax.in_out_tensors())\n    model.compile(loss=tf.nn.sigmoid_cross_entropy_with_logits, optimizer='Adam')\n    model.fit(gen)\n    emb_model = tf.keras.Model(*base_model.in_out_tensors())\n    embeddings = emb_model.predict(base_generator.flow(nodes))\n    if isinstance(base_generator, (FullBatchNodeGenerator, RelationalFullBatchNodeGenerator)):\n        assert (embeddings.shape == (1, len(nodes), 16))\n    else:\n        assert (embeddings.shape == (len(nodes), 16))", "masked_code": "@pytest.mark.parametrize('model_type', [GCN, APPNP, GAT, PPNP, GraphSAGE, DirectedGraphSAGE, HinSAGE, RGCN])\n@pytest.mark.parametrize('sparse', [False, True])\ndef test_dgi(model_type, sparse):\n    (base_generator, base_model, nodes) = _model_data(model_type, sparse)\n    corrupted_generator = CorruptedGenerator(base_generator)\n    gen = corrupted_generator.flow(nodes)\n    infomax = DeepGraphInfomax(base_model, corrupted_generator)\n    model = tf.keras.Model(*infomax.in_out_tensors())\n    model.compile(loss=tf.nn.sigmoid_cross_entropy_with_logits, optimizer='Adam')\n    model.fit(gen)\n    emb_model = tf.keras.Model(*base_model.in_out_tensors())\n    embeddings = emb_model.predict(base_generator.flow(nodes))\n    if isinstance(base_generator, (FullBatchNodeGenerator, RelationalFullBatchNodeGenerator)):\n        assert (embeddings.shape == '???')\n    else:\n        assert (embeddings.shape == (len(nodes), 16))", "ground_truth": "(1, len(nodes), 16)", "quality_analysis": {"complexity_score": 10, "left_complexity": 2, "right_complexity": 8, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_530", "reponame": "stellargraph", "testpath": "tests/layer/test_deep_graph_infomax.py", "testname": "test_deep_graph_infomax.py", "classname": null, "funcname": "test_dgi", "imports": ["from stellargraph.layer import *", "from stellargraph.mapper import *", "from ..test_utils.graphs import example_graph_random", "from .. import require_gpu, test_utils", "import tensorflow as tf", "import pytest", "import numpy as np"], "code": "@pytest.mark.parametrize('model_type', [GCN, APPNP, GAT, PPNP, GraphSAGE, DirectedGraphSAGE, HinSAGE, RGCN])\n@pytest.mark.parametrize('sparse', [False, True])\ndef test_dgi(model_type, sparse):\n    (base_generator, base_model, nodes) = _model_data(model_type, sparse)\n    corrupted_generator = CorruptedGenerator(base_generator)\n    gen = corrupted_generator.flow(nodes)\n    infomax = DeepGraphInfomax(base_model, corrupted_generator)\n    model = tf.keras.Model(*infomax.in_out_tensors())\n    model.compile(loss=tf.nn.sigmoid_cross_entropy_with_logits, optimizer='Adam')\n    model.fit(gen)\n    emb_model = tf.keras.Model(*base_model.in_out_tensors())\n    embeddings = emb_model.predict(base_generator.flow(nodes))\n    if isinstance(base_generator, (FullBatchNodeGenerator, RelationalFullBatchNodeGenerator)):\n        assert (embeddings.shape == (1, len(nodes), 16))\n    else:\n        assert (embeddings.shape == (len(nodes), 16))", "masked_code": "@pytest.mark.parametrize('model_type', [GCN, APPNP, GAT, PPNP, GraphSAGE, DirectedGraphSAGE, HinSAGE, RGCN])\n@pytest.mark.parametrize('sparse', [False, True])\ndef test_dgi(model_type, sparse):\n    (base_generator, base_model, nodes) = _model_data(model_type, sparse)\n    corrupted_generator = CorruptedGenerator(base_generator)\n    gen = corrupted_generator.flow(nodes)\n    infomax = DeepGraphInfomax(base_model, corrupted_generator)\n    model = tf.keras.Model(*infomax.in_out_tensors())\n    model.compile(loss=tf.nn.sigmoid_cross_entropy_with_logits, optimizer='Adam')\n    model.fit(gen)\n    emb_model = tf.keras.Model(*base_model.in_out_tensors())\n    embeddings = emb_model.predict(base_generator.flow(nodes))\n    if isinstance(base_generator, (FullBatchNodeGenerator, RelationalFullBatchNodeGenerator)):\n        assert (embeddings.shape == (1, len(nodes), 16))\n    else:\n        assert (embeddings.shape == '???')", "ground_truth": "(len(nodes), 16)", "quality_analysis": {"complexity_score": 9, "left_complexity": 2, "right_complexity": 7, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_531", "reponame": "stellargraph", "testpath": "tests/layer/test_gcn.py", "testname": "test_gcn.py", "classname": null, "funcname": "test_GraphConvolution_config", "imports": ["import stellargraph as sg", "from stellargraph.layer.gcn import *", "from stellargraph.mapper import FullBatchNodeGenerator, FullBatchLinkGenerator", "from stellargraph.core.graph import StellarGraph", "from stellargraph.core.utils import GCN_Aadj_feats_op", "import networkx as nx", "import pandas as pd", "import numpy as np", "from tensorflow import keras", "import tensorflow as tf", "import pytest", "from ..test_utils.graphs import create_graph_features", "from .. import test_utils"], "code": "def test_GraphConvolution_config():\n    gcn_layer = GraphConvolution(units=16)\n    conf = gcn_layer.get_config()\n    assert (conf['units'] == 16)\n    assert (conf['activation'] == 'linear')\n    assert (conf['use_bias'] == True)\n    assert (conf['kernel_initializer']['class_name'] == 'GlorotUniform')\n    assert (conf['bias_initializer']['class_name'] == 'Zeros')\n    assert (conf['kernel_regularizer'] == None)\n    assert (conf['bias_regularizer'] == None)\n    assert (conf['kernel_constraint'] == None)\n    assert (conf['bias_constraint'] == None)", "masked_code": "def test_GraphConvolution_config():\n    gcn_layer = GraphConvolution(units=16)\n    conf = gcn_layer.get_config()\n    assert (conf['units'] == '???')\n    assert (conf['activation'] == 'linear')\n    assert (conf['use_bias'] == True)\n    assert (conf['kernel_initializer']['class_name'] == 'GlorotUniform')\n    assert (conf['bias_initializer']['class_name'] == 'Zeros')\n    assert (conf['kernel_regularizer'] == None)\n    assert (conf['bias_regularizer'] == None)\n    assert (conf['kernel_constraint'] == None)\n    assert (conf['bias_constraint'] == None)", "ground_truth": "16", "quality_analysis": {"complexity_score": 6, "left_complexity": 5, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_532", "reponame": "stellargraph", "testpath": "tests/layer/test_gcn.py", "testname": "test_gcn.py", "classname": null, "funcname": "test_GraphConvolution_config", "imports": ["import stellargraph as sg", "from stellargraph.layer.gcn import *", "from stellargraph.mapper import FullBatchNodeGenerator, FullBatchLinkGenerator", "from stellargraph.core.graph import StellarGraph", "from stellargraph.core.utils import GCN_Aadj_feats_op", "import networkx as nx", "import pandas as pd", "import numpy as np", "from tensorflow import keras", "import tensorflow as tf", "import pytest", "from ..test_utils.graphs import create_graph_features", "from .. import test_utils"], "code": "def test_GraphConvolution_config():\n    gcn_layer = GraphConvolution(units=16)\n    conf = gcn_layer.get_config()\n    assert (conf['units'] == 16)\n    assert (conf['activation'] == 'linear')\n    assert (conf['use_bias'] == True)\n    assert (conf['kernel_initializer']['class_name'] == 'GlorotUniform')\n    assert (conf['bias_initializer']['class_name'] == 'Zeros')\n    assert (conf['kernel_regularizer'] == None)\n    assert (conf['bias_regularizer'] == None)\n    assert (conf['kernel_constraint'] == None)\n    assert (conf['bias_constraint'] == None)", "masked_code": "def test_GraphConvolution_config():\n    gcn_layer = GraphConvolution(units=16)\n    conf = gcn_layer.get_config()\n    assert (conf['units'] == 16)\n    assert (conf['activation'] == '???')\n    assert (conf['use_bias'] == True)\n    assert (conf['kernel_initializer']['class_name'] == 'GlorotUniform')\n    assert (conf['bias_initializer']['class_name'] == 'Zeros')\n    assert (conf['kernel_regularizer'] == None)\n    assert (conf['bias_regularizer'] == None)\n    assert (conf['kernel_constraint'] == None)\n    assert (conf['bias_constraint'] == None)", "ground_truth": "'linear'", "quality_analysis": {"complexity_score": 6, "left_complexity": 5, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_533", "reponame": "stellargraph", "testpath": "tests/layer/test_gcn.py", "testname": "test_gcn.py", "classname": null, "funcname": "test_GraphConvolution_config", "imports": ["import stellargraph as sg", "from stellargraph.layer.gcn import *", "from stellargraph.mapper import FullBatchNodeGenerator, FullBatchLinkGenerator", "from stellargraph.core.graph import StellarGraph", "from stellargraph.core.utils import GCN_Aadj_feats_op", "import networkx as nx", "import pandas as pd", "import numpy as np", "from tensorflow import keras", "import tensorflow as tf", "import pytest", "from ..test_utils.graphs import create_graph_features", "from .. import test_utils"], "code": "def test_GraphConvolution_config():\n    gcn_layer = GraphConvolution(units=16)\n    conf = gcn_layer.get_config()\n    assert (conf['units'] == 16)\n    assert (conf['activation'] == 'linear')\n    assert (conf['use_bias'] == True)\n    assert (conf['kernel_initializer']['class_name'] == 'GlorotUniform')\n    assert (conf['bias_initializer']['class_name'] == 'Zeros')\n    assert (conf['kernel_regularizer'] == None)\n    assert (conf['bias_regularizer'] == None)\n    assert (conf['kernel_constraint'] == None)\n    assert (conf['bias_constraint'] == None)", "masked_code": "def test_GraphConvolution_config():\n    gcn_layer = GraphConvolution(units=16)\n    conf = gcn_layer.get_config()\n    assert (conf['units'] == 16)\n    assert (conf['activation'] == 'linear')\n    assert (conf['use_bias'] == True)\n    assert (conf['kernel_initializer']['class_name'] == '???')\n    assert (conf['bias_initializer']['class_name'] == 'Zeros')\n    assert (conf['kernel_regularizer'] == None)\n    assert (conf['bias_regularizer'] == None)\n    assert (conf['kernel_constraint'] == None)\n    assert (conf['bias_constraint'] == None)", "ground_truth": "'GlorotUniform'", "quality_analysis": {"complexity_score": 10, "left_complexity": 9, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_534", "reponame": "stellargraph", "testpath": "tests/layer/test_gcn.py", "testname": "test_gcn.py", "classname": null, "funcname": "test_GraphConvolution_config", "imports": ["import stellargraph as sg", "from stellargraph.layer.gcn import *", "from stellargraph.mapper import FullBatchNodeGenerator, FullBatchLinkGenerator", "from stellargraph.core.graph import StellarGraph", "from stellargraph.core.utils import GCN_Aadj_feats_op", "import networkx as nx", "import pandas as pd", "import numpy as np", "from tensorflow import keras", "import tensorflow as tf", "import pytest", "from ..test_utils.graphs import create_graph_features", "from .. import test_utils"], "code": "def test_GraphConvolution_config():\n    gcn_layer = GraphConvolution(units=16)\n    conf = gcn_layer.get_config()\n    assert (conf['units'] == 16)\n    assert (conf['activation'] == 'linear')\n    assert (conf['use_bias'] == True)\n    assert (conf['kernel_initializer']['class_name'] == 'GlorotUniform')\n    assert (conf['bias_initializer']['class_name'] == 'Zeros')\n    assert (conf['kernel_regularizer'] == None)\n    assert (conf['bias_regularizer'] == None)\n    assert (conf['kernel_constraint'] == None)\n    assert (conf['bias_constraint'] == None)", "masked_code": "def test_GraphConvolution_config():\n    gcn_layer = GraphConvolution(units=16)\n    conf = gcn_layer.get_config()\n    assert (conf['units'] == 16)\n    assert (conf['activation'] == 'linear')\n    assert (conf['use_bias'] == True)\n    assert (conf['kernel_initializer']['class_name'] == 'GlorotUniform')\n    assert (conf['bias_initializer']['class_name'] == '???')\n    assert (conf['kernel_regularizer'] == None)\n    assert (conf['bias_regularizer'] == None)\n    assert (conf['kernel_constraint'] == None)\n    assert (conf['bias_constraint'] == None)", "ground_truth": "'Zeros'", "quality_analysis": {"complexity_score": 10, "left_complexity": 9, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_535", "reponame": "stellargraph", "testpath": "tests/layer/test_gcn.py", "testname": "test_gcn.py", "classname": null, "funcname": "test_GraphConvolution_config", "imports": ["import stellargraph as sg", "from stellargraph.layer.gcn import *", "from stellargraph.mapper import FullBatchNodeGenerator, FullBatchLinkGenerator", "from stellargraph.core.graph import StellarGraph", "from stellargraph.core.utils import GCN_Aadj_feats_op", "import networkx as nx", "import pandas as pd", "import numpy as np", "from tensorflow import keras", "import tensorflow as tf", "import pytest", "from ..test_utils.graphs import create_graph_features", "from .. import test_utils"], "code": "def test_GraphConvolution_config():\n    gcn_layer = GraphConvolution(units=16)\n    conf = gcn_layer.get_config()\n    assert (conf['units'] == 16)\n    assert (conf['activation'] == 'linear')\n    assert (conf['use_bias'] == True)\n    assert (conf['kernel_initializer']['class_name'] == 'GlorotUniform')\n    assert (conf['bias_initializer']['class_name'] == 'Zeros')\n    assert (conf['kernel_regularizer'] == None)\n    assert (conf['bias_regularizer'] == None)\n    assert (conf['kernel_constraint'] == None)\n    assert (conf['bias_constraint'] == None)", "masked_code": "def test_GraphConvolution_config():\n    gcn_layer = GraphConvolution(units=16)\n    conf = gcn_layer.get_config()\n    assert (conf['units'] == 16)\n    assert (conf['activation'] == 'linear')\n    assert (conf['use_bias'] == True)\n    assert (conf['kernel_initializer']['class_name'] == 'GlorotUniform')\n    assert (conf['bias_initializer']['class_name'] == 'Zeros')\n    assert (conf['kernel_regularizer'] == '???')\n    assert (conf['bias_regularizer'] == None)\n    assert (conf['kernel_constraint'] == None)\n    assert (conf['bias_constraint'] == None)", "ground_truth": "None", "quality_analysis": {"complexity_score": 6, "left_complexity": 5, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_536", "reponame": "stellargraph", "testpath": "tests/layer/test_gcn.py", "testname": "test_gcn.py", "classname": null, "funcname": "test_GraphConvolution_config", "imports": ["import stellargraph as sg", "from stellargraph.layer.gcn import *", "from stellargraph.mapper import FullBatchNodeGenerator, FullBatchLinkGenerator", "from stellargraph.core.graph import StellarGraph", "from stellargraph.core.utils import GCN_Aadj_feats_op", "import networkx as nx", "import pandas as pd", "import numpy as np", "from tensorflow import keras", "import tensorflow as tf", "import pytest", "from ..test_utils.graphs import create_graph_features", "from .. import test_utils"], "code": "def test_GraphConvolution_config():\n    gcn_layer = GraphConvolution(units=16)\n    conf = gcn_layer.get_config()\n    assert (conf['units'] == 16)\n    assert (conf['activation'] == 'linear')\n    assert (conf['use_bias'] == True)\n    assert (conf['kernel_initializer']['class_name'] == 'GlorotUniform')\n    assert (conf['bias_initializer']['class_name'] == 'Zeros')\n    assert (conf['kernel_regularizer'] == None)\n    assert (conf['bias_regularizer'] == None)\n    assert (conf['kernel_constraint'] == None)\n    assert (conf['bias_constraint'] == None)", "masked_code": "def test_GraphConvolution_config():\n    gcn_layer = GraphConvolution(units=16)\n    conf = gcn_layer.get_config()\n    assert (conf['units'] == 16)\n    assert (conf['activation'] == 'linear')\n    assert (conf['use_bias'] == True)\n    assert (conf['kernel_initializer']['class_name'] == 'GlorotUniform')\n    assert (conf['bias_initializer']['class_name'] == 'Zeros')\n    assert (conf['kernel_regularizer'] == None)\n    assert (conf['bias_regularizer'] == '???')\n    assert (conf['kernel_constraint'] == None)\n    assert (conf['bias_constraint'] == None)", "ground_truth": "None", "quality_analysis": {"complexity_score": 6, "left_complexity": 5, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_537", "reponame": "stellargraph", "testpath": "tests/layer/test_gcn.py", "testname": "test_gcn.py", "classname": null, "funcname": "test_GraphConvolution_config", "imports": ["import stellargraph as sg", "from stellargraph.layer.gcn import *", "from stellargraph.mapper import FullBatchNodeGenerator, FullBatchLinkGenerator", "from stellargraph.core.graph import StellarGraph", "from stellargraph.core.utils import GCN_Aadj_feats_op", "import networkx as nx", "import pandas as pd", "import numpy as np", "from tensorflow import keras", "import tensorflow as tf", "import pytest", "from ..test_utils.graphs import create_graph_features", "from .. import test_utils"], "code": "def test_GraphConvolution_config():\n    gcn_layer = GraphConvolution(units=16)\n    conf = gcn_layer.get_config()\n    assert (conf['units'] == 16)\n    assert (conf['activation'] == 'linear')\n    assert (conf['use_bias'] == True)\n    assert (conf['kernel_initializer']['class_name'] == 'GlorotUniform')\n    assert (conf['bias_initializer']['class_name'] == 'Zeros')\n    assert (conf['kernel_regularizer'] == None)\n    assert (conf['bias_regularizer'] == None)\n    assert (conf['kernel_constraint'] == None)\n    assert (conf['bias_constraint'] == None)", "masked_code": "def test_GraphConvolution_config():\n    gcn_layer = GraphConvolution(units=16)\n    conf = gcn_layer.get_config()\n    assert (conf['units'] == 16)\n    assert (conf['activation'] == 'linear')\n    assert (conf['use_bias'] == True)\n    assert (conf['kernel_initializer']['class_name'] == 'GlorotUniform')\n    assert (conf['bias_initializer']['class_name'] == 'Zeros')\n    assert (conf['kernel_regularizer'] == None)\n    assert (conf['bias_regularizer'] == None)\n    assert (conf['kernel_constraint'] == '???')\n    assert (conf['bias_constraint'] == None)", "ground_truth": "None", "quality_analysis": {"complexity_score": 6, "left_complexity": 5, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_538", "reponame": "stellargraph", "testpath": "tests/layer/test_gcn.py", "testname": "test_gcn.py", "classname": null, "funcname": "test_GraphConvolution_config", "imports": ["import stellargraph as sg", "from stellargraph.layer.gcn import *", "from stellargraph.mapper import FullBatchNodeGenerator, FullBatchLinkGenerator", "from stellargraph.core.graph import StellarGraph", "from stellargraph.core.utils import GCN_Aadj_feats_op", "import networkx as nx", "import pandas as pd", "import numpy as np", "from tensorflow import keras", "import tensorflow as tf", "import pytest", "from ..test_utils.graphs import create_graph_features", "from .. import test_utils"], "code": "def test_GraphConvolution_config():\n    gcn_layer = GraphConvolution(units=16)\n    conf = gcn_layer.get_config()\n    assert (conf['units'] == 16)\n    assert (conf['activation'] == 'linear')\n    assert (conf['use_bias'] == True)\n    assert (conf['kernel_initializer']['class_name'] == 'GlorotUniform')\n    assert (conf['bias_initializer']['class_name'] == 'Zeros')\n    assert (conf['kernel_regularizer'] == None)\n    assert (conf['bias_regularizer'] == None)\n    assert (conf['kernel_constraint'] == None)\n    assert (conf['bias_constraint'] == None)", "masked_code": "def test_GraphConvolution_config():\n    gcn_layer = GraphConvolution(units=16)\n    conf = gcn_layer.get_config()\n    assert (conf['units'] == 16)\n    assert (conf['activation'] == 'linear')\n    assert (conf['use_bias'] == True)\n    assert (conf['kernel_initializer']['class_name'] == 'GlorotUniform')\n    assert (conf['bias_initializer']['class_name'] == 'Zeros')\n    assert (conf['kernel_regularizer'] == None)\n    assert (conf['bias_regularizer'] == None)\n    assert (conf['kernel_constraint'] == None)\n    assert (conf['bias_constraint'] == '???')", "ground_truth": "None", "quality_analysis": {"complexity_score": 6, "left_complexity": 5, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_539", "reponame": "stellargraph", "testpath": "tests/layer/test_gcn.py", "testname": "test_gcn.py", "classname": null, "funcname": "test_GraphConvolution_init", "imports": ["import stellargraph as sg", "from stellargraph.layer.gcn import *", "from stellargraph.mapper import FullBatchNodeGenerator, FullBatchLinkGenerator", "from stellargraph.core.graph import StellarGraph", "from stellargraph.core.utils import GCN_Aadj_feats_op", "import networkx as nx", "import pandas as pd", "import numpy as np", "from tensorflow import keras", "import tensorflow as tf", "import pytest", "from ..test_utils.graphs import create_graph_features", "from .. import test_utils"], "code": "def test_GraphConvolution_init():\n    gcn_layer = GraphConvolution(units=16, activation='relu')\n    assert (gcn_layer.units == 16)\n    assert (gcn_layer.use_bias == True)\n    assert (gcn_layer.get_config()['activation'] == 'relu')", "masked_code": "def test_GraphConvolution_init():\n    gcn_layer = GraphConvolution(units=16, activation='relu')\n    assert (gcn_layer.units == '???')\n    assert (gcn_layer.use_bias == True)\n    assert (gcn_layer.get_config()['activation'] == 'relu')", "ground_truth": "16", "quality_analysis": {"complexity_score": 3, "left_complexity": 2, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_540", "reponame": "stellargraph", "testpath": "tests/layer/test_gcn.py", "testname": "test_gcn.py", "classname": null, "funcname": "test_GraphConvolution_init", "imports": ["import stellargraph as sg", "from stellargraph.layer.gcn import *", "from stellargraph.mapper import FullBatchNodeGenerator, FullBatchLinkGenerator", "from stellargraph.core.graph import StellarGraph", "from stellargraph.core.utils import GCN_Aadj_feats_op", "import networkx as nx", "import pandas as pd", "import numpy as np", "from tensorflow import keras", "import tensorflow as tf", "import pytest", "from ..test_utils.graphs import create_graph_features", "from .. import test_utils"], "code": "def test_GraphConvolution_init():\n    gcn_layer = GraphConvolution(units=16, activation='relu')\n    assert (gcn_layer.units == 16)\n    assert (gcn_layer.use_bias == True)\n    assert (gcn_layer.get_config()['activation'] == 'relu')", "masked_code": "def test_GraphConvolution_init():\n    gcn_layer = GraphConvolution(units=16, activation='relu')\n    assert (gcn_layer.units == 16)\n    assert (gcn_layer.use_bias == True)\n    assert (gcn_layer.get_config()['activation'] == '???')", "ground_truth": "'relu'", "quality_analysis": {"complexity_score": 8, "left_complexity": 7, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_541", "reponame": "stellargraph", "testpath": "tests/layer/test_gcn.py", "testname": "test_gcn.py", "classname": null, "funcname": "test_GraphConvolution_dense", "imports": ["import stellargraph as sg", "from stellargraph.layer.gcn import *", "from stellargraph.mapper import FullBatchNodeGenerator, FullBatchLinkGenerator", "from stellargraph.core.graph import StellarGraph", "from stellargraph.core.utils import GCN_Aadj_feats_op", "import networkx as nx", "import pandas as pd", "import numpy as np", "from tensorflow import keras", "import tensorflow as tf", "import pytest", "from ..test_utils.graphs import create_graph_features", "from .. import test_utils"], "code": "def test_GraphConvolution_dense():\n    (G, features) = create_graph_features()\n    x_t = Input(batch_shape=((1,) + features.shape), name='X')\n    A_t = Input(batch_shape=(1, 3, 3), name='A')\n    adj = G.to_adjacency_matrix().toarray()[(None, :, :)]\n    x = features[(None, :, :)]\n    out = GraphConvolution(2)([x_t, A_t])\n    model = keras.Model(inputs=[x_t, A_t], outputs=out)\n    preds = model.predict([x, adj], batch_size=1)\n    assert (preds.shape == (1, 3, 2))\n    x_t = Input(batch_shape=((10,) + features.shape))\n    A_t = Input(batch_shape=(10, 3, 3))\n    input_data = [np.broadcast_to(x, x_t.shape), np.broadcast_to(adj, A_t.shape)]\n    out = GraphConvolution(2)([x_t, A_t])\n    model = keras.Model(inputs=[x_t, A_t], outputs=out)\n    preds = model.predict(input_data, batch_size=10)\n    assert (preds.shape == (10, 3, 2))\n    for i in range(1, 10):\n        np.testing.assert_array_equal(preds[(i, ...)], preds[(0, ...)])", "masked_code": "def test_GraphConvolution_dense():\n    (G, features) = create_graph_features()\n    x_t = Input(batch_shape=((1,) + features.shape), name='X')\n    A_t = Input(batch_shape=(1, 3, 3), name='A')\n    adj = G.to_adjacency_matrix().toarray()[(None, :, :)]\n    x = features[(None, :, :)]\n    out = GraphConvolution(2)([x_t, A_t])\n    model = keras.Model(inputs=[x_t, A_t], outputs=out)\n    preds = model.predict([x, adj], batch_size=1)\n    assert (preds.shape == '???')\n    x_t = Input(batch_shape=((10,) + features.shape))\n    A_t = Input(batch_shape=(10, 3, 3))\n    input_data = [np.broadcast_to(x, x_t.shape), np.broadcast_to(adj, A_t.shape)]\n    out = GraphConvolution(2)([x_t, A_t])\n    model = keras.Model(inputs=[x_t, A_t], outputs=out)\n    preds = model.predict(input_data, batch_size=10)\n    assert (preds.shape == (10, 3, 2))\n    for i in range(1, 10):\n        np.testing.assert_array_equal(preds[(i, ...)], preds[(0, ...)])", "ground_truth": "(1, 3, 2)", "quality_analysis": {"complexity_score": 7, "left_complexity": 2, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_542", "reponame": "stellargraph", "testpath": "tests/layer/test_gcn.py", "testname": "test_gcn.py", "classname": null, "funcname": "test_GraphConvolution_dense", "imports": ["import stellargraph as sg", "from stellargraph.layer.gcn import *", "from stellargraph.mapper import FullBatchNodeGenerator, FullBatchLinkGenerator", "from stellargraph.core.graph import StellarGraph", "from stellargraph.core.utils import GCN_Aadj_feats_op", "import networkx as nx", "import pandas as pd", "import numpy as np", "from tensorflow import keras", "import tensorflow as tf", "import pytest", "from ..test_utils.graphs import create_graph_features", "from .. import test_utils"], "code": "def test_GraphConvolution_dense():\n    (G, features) = create_graph_features()\n    x_t = Input(batch_shape=((1,) + features.shape), name='X')\n    A_t = Input(batch_shape=(1, 3, 3), name='A')\n    adj = G.to_adjacency_matrix().toarray()[(None, :, :)]\n    x = features[(None, :, :)]\n    out = GraphConvolution(2)([x_t, A_t])\n    model = keras.Model(inputs=[x_t, A_t], outputs=out)\n    preds = model.predict([x, adj], batch_size=1)\n    assert (preds.shape == (1, 3, 2))\n    x_t = Input(batch_shape=((10,) + features.shape))\n    A_t = Input(batch_shape=(10, 3, 3))\n    input_data = [np.broadcast_to(x, x_t.shape), np.broadcast_to(adj, A_t.shape)]\n    out = GraphConvolution(2)([x_t, A_t])\n    model = keras.Model(inputs=[x_t, A_t], outputs=out)\n    preds = model.predict(input_data, batch_size=10)\n    assert (preds.shape == (10, 3, 2))\n    for i in range(1, 10):\n        np.testing.assert_array_equal(preds[(i, ...)], preds[(0, ...)])", "masked_code": "def test_GraphConvolution_dense():\n    (G, features) = create_graph_features()\n    x_t = Input(batch_shape=((1,) + features.shape), name='X')\n    A_t = Input(batch_shape=(1, 3, 3), name='A')\n    adj = G.to_adjacency_matrix().toarray()[(None, :, :)]\n    x = features[(None, :, :)]\n    out = GraphConvolution(2)([x_t, A_t])\n    model = keras.Model(inputs=[x_t, A_t], outputs=out)\n    preds = model.predict([x, adj], batch_size=1)\n    assert (preds.shape == (1, 3, 2))\n    x_t = Input(batch_shape=((10,) + features.shape))\n    A_t = Input(batch_shape=(10, 3, 3))\n    input_data = [np.broadcast_to(x, x_t.shape), np.broadcast_to(adj, A_t.shape)]\n    out = GraphConvolution(2)([x_t, A_t])\n    model = keras.Model(inputs=[x_t, A_t], outputs=out)\n    preds = model.predict(input_data, batch_size=10)\n    assert (preds.shape == '???')\n    for i in range(1, 10):\n        np.testing.assert_array_equal(preds[(i, ...)], preds[(0, ...)])", "ground_truth": "(10, 3, 2)", "quality_analysis": {"complexity_score": 7, "left_complexity": 2, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_543", "reponame": "stellargraph", "testpath": "tests/layer/test_gcn.py", "testname": "test_gcn.py", "classname": null, "funcname": "test_GraphConvolution_sparse", "imports": ["import stellargraph as sg", "from stellargraph.layer.gcn import *", "from stellargraph.mapper import FullBatchNodeGenerator, FullBatchLinkGenerator", "from stellargraph.core.graph import StellarGraph", "from stellargraph.core.utils import GCN_Aadj_feats_op", "import networkx as nx", "import pandas as pd", "import numpy as np", "from tensorflow import keras", "import tensorflow as tf", "import pytest", "from ..test_utils.graphs import create_graph_features", "from .. import test_utils"], "code": "def test_GraphConvolution_sparse():\n    (G, features) = create_graph_features()\n    n_nodes = features.shape[0]\n    x_t = Input(batch_shape=((1,) + features.shape))\n    A_ind = Input(batch_shape=(1, None, 2), dtype='int64')\n    A_val = Input(batch_shape=(1, None), dtype='float32')\n    A_mat = SqueezedSparseConversion(shape=(n_nodes, n_nodes), dtype=A_val.dtype)([A_ind, A_val])\n    out = GraphConvolution(2)([x_t, A_mat])\n    adj = G.to_adjacency_matrix().tocoo()\n    A_indices = np.expand_dims(np.hstack((adj.row[(:, None)], adj.col[(:, None)])).astype(np.int64), 0)\n    A_values = np.expand_dims(adj.data, 0)\n    out_indices = np.array([[0, 1]], dtype='int32')\n    x = features[(None, :, :)]\n    model = keras.Model(inputs=[x_t, A_ind, A_val], outputs=out)\n    preds = model.predict([x, A_indices, A_values], batch_size=1)\n    assert (preds.shape == (1, 3, 2))\n    x_t_10 = Input(batch_shape=((10,) + features.shape))\n    with pytest.raises(ValueError, match='features: expected batch dimension = 1 .* found features batch dimension 10'):\n        GraphConvolution(2)([x_t_10, A_mat])\n    A_mat = keras.layers.Lambda((lambda x: tf.sparse.expand_dims(x, axis=0)))(A_mat)\n    with pytest.raises(ValueError, match='adjacency: expected a single adjacency matrix .* found adjacency tensor of rank 3'):\n        GraphConvolution(2)([x_t, A_mat])", "masked_code": "def test_GraphConvolution_sparse():\n    (G, features) = create_graph_features()\n    n_nodes = features.shape[0]\n    x_t = Input(batch_shape=((1,) + features.shape))\n    A_ind = Input(batch_shape=(1, None, 2), dtype='int64')\n    A_val = Input(batch_shape=(1, None), dtype='float32')\n    A_mat = SqueezedSparseConversion(shape=(n_nodes, n_nodes), dtype=A_val.dtype)([A_ind, A_val])\n    out = GraphConvolution(2)([x_t, A_mat])\n    adj = G.to_adjacency_matrix().tocoo()\n    A_indices = np.expand_dims(np.hstack((adj.row[(:, None)], adj.col[(:, None)])).astype(np.int64), 0)\n    A_values = np.expand_dims(adj.data, 0)\n    out_indices = np.array([[0, 1]], dtype='int32')\n    x = features[(None, :, :)]\n    model = keras.Model(inputs=[x_t, A_ind, A_val], outputs=out)\n    preds = model.predict([x, A_indices, A_values], batch_size=1)\n    assert (preds.shape == '???')\n    x_t_10 = Input(batch_shape=((10,) + features.shape))\n    with pytest.raises(ValueError, match='features: expected batch dimension = 1 .* found features batch dimension 10'):\n        GraphConvolution(2)([x_t_10, A_mat])\n    A_mat = keras.layers.Lambda((lambda x: tf.sparse.expand_dims(x, axis=0)))(A_mat)\n    with pytest.raises(ValueError, match='adjacency: expected a single adjacency matrix .* found adjacency tensor of rank 3'):\n        GraphConvolution(2)([x_t, A_mat])", "ground_truth": "(1, 3, 2)", "quality_analysis": {"complexity_score": 7, "left_complexity": 2, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_544", "reponame": "stellargraph", "testpath": "tests/layer/test_gcn.py", "testname": "test_gcn.py", "classname": null, "funcname": "test_GCN_init", "imports": ["import stellargraph as sg", "from stellargraph.layer.gcn import *", "from stellargraph.mapper import FullBatchNodeGenerator, FullBatchLinkGenerator", "from stellargraph.core.graph import StellarGraph", "from stellargraph.core.utils import GCN_Aadj_feats_op", "import networkx as nx", "import pandas as pd", "import numpy as np", "from tensorflow import keras", "import tensorflow as tf", "import pytest", "from ..test_utils.graphs import create_graph_features", "from .. import test_utils"], "code": "def test_GCN_init():\n    (G, _) = create_graph_features()\n    generator = FullBatchNodeGenerator(G)\n    gcnModel = GCN([2], generator, activations=['relu'], dropout=0.5)\n    assert (gcnModel.layer_sizes == [2])\n    assert (gcnModel.activations == ['relu'])\n    assert (gcnModel.dropout == 0.5)", "masked_code": "def test_GCN_init():\n    (G, _) = create_graph_features()\n    generator = FullBatchNodeGenerator(G)\n    gcnModel = GCN([2], generator, activations=['relu'], dropout=0.5)\n    assert (gcnModel.layer_sizes == '???')\n    assert (gcnModel.activations == ['relu'])\n    assert (gcnModel.dropout == 0.5)", "ground_truth": "[2]", "quality_analysis": {"complexity_score": 5, "left_complexity": 2, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_545", "reponame": "stellargraph", "testpath": "tests/layer/test_gcn.py", "testname": "test_gcn.py", "classname": null, "funcname": "test_GCN_init", "imports": ["import stellargraph as sg", "from stellargraph.layer.gcn import *", "from stellargraph.mapper import FullBatchNodeGenerator, FullBatchLinkGenerator", "from stellargraph.core.graph import StellarGraph", "from stellargraph.core.utils import GCN_Aadj_feats_op", "import networkx as nx", "import pandas as pd", "import numpy as np", "from tensorflow import keras", "import tensorflow as tf", "import pytest", "from ..test_utils.graphs import create_graph_features", "from .. import test_utils"], "code": "def test_GCN_init():\n    (G, _) = create_graph_features()\n    generator = FullBatchNodeGenerator(G)\n    gcnModel = GCN([2], generator, activations=['relu'], dropout=0.5)\n    assert (gcnModel.layer_sizes == [2])\n    assert (gcnModel.activations == ['relu'])\n    assert (gcnModel.dropout == 0.5)", "masked_code": "def test_GCN_init():\n    (G, _) = create_graph_features()\n    generator = FullBatchNodeGenerator(G)\n    gcnModel = GCN([2], generator, activations=['relu'], dropout=0.5)\n    assert (gcnModel.layer_sizes == [2])\n    assert (gcnModel.activations == '???')\n    assert (gcnModel.dropout == 0.5)", "ground_truth": "['relu']", "quality_analysis": {"complexity_score": 5, "left_complexity": 2, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_546", "reponame": "stellargraph", "testpath": "tests/layer/test_gcn.py", "testname": "test_gcn.py", "classname": null, "funcname": "test_GCN_init", "imports": ["import stellargraph as sg", "from stellargraph.layer.gcn import *", "from stellargraph.mapper import FullBatchNodeGenerator, FullBatchLinkGenerator", "from stellargraph.core.graph import StellarGraph", "from stellargraph.core.utils import GCN_Aadj_feats_op", "import networkx as nx", "import pandas as pd", "import numpy as np", "from tensorflow import keras", "import tensorflow as tf", "import pytest", "from ..test_utils.graphs import create_graph_features", "from .. import test_utils"], "code": "def test_GCN_init():\n    (G, _) = create_graph_features()\n    generator = FullBatchNodeGenerator(G)\n    gcnModel = GCN([2], generator, activations=['relu'], dropout=0.5)\n    assert (gcnModel.layer_sizes == [2])\n    assert (gcnModel.activations == ['relu'])\n    assert (gcnModel.dropout == 0.5)", "masked_code": "def test_GCN_init():\n    (G, _) = create_graph_features()\n    generator = FullBatchNodeGenerator(G)\n    gcnModel = GCN([2], generator, activations=['relu'], dropout=0.5)\n    assert (gcnModel.layer_sizes == [2])\n    assert (gcnModel.activations == ['relu'])\n    assert (gcnModel.dropout == '???')", "ground_truth": "0.5", "quality_analysis": {"complexity_score": 3, "left_complexity": 2, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_547", "reponame": "stellargraph", "testpath": "tests/layer/test_gcn.py", "testname": "test_gcn.py", "classname": null, "funcname": "test_GCN_apply_dense", "imports": ["import stellargraph as sg", "from stellargraph.layer.gcn import *", "from stellargraph.mapper import FullBatchNodeGenerator, FullBatchLinkGenerator", "from stellargraph.core.graph import StellarGraph", "from stellargraph.core.utils import GCN_Aadj_feats_op", "import networkx as nx", "import pandas as pd", "import numpy as np", "from tensorflow import keras", "import tensorflow as tf", "import pytest", "from ..test_utils.graphs import create_graph_features", "from .. import test_utils"], "code": "def test_GCN_apply_dense():\n    (G, features) = create_graph_features()\n    adj = G.to_adjacency_matrix().toarray()[(None, :, :)]\n    n_nodes = features.shape[0]\n    generator = FullBatchNodeGenerator(G, sparse=False, method='none')\n    gcnModel = GCN([2], generator, activations=['relu'], dropout=0.5)\n    (x_in, x_out) = gcnModel.in_out_tensors()\n    model = keras.Model(inputs=x_in, outputs=x_out)\n    out_indices = np.array([[0, 1]], dtype='int32')\n    preds_1 = model.predict([features[(None, :, :)], out_indices, adj])\n    assert (preds_1.shape == (1, 2, 2))\n    preds_2 = model.predict(generator.flow(['a', 'b']))\n    assert (preds_2.shape == (1, 2, 2))\n    assert (preds_1 == pytest.approx(preds_2))", "masked_code": "def test_GCN_apply_dense():\n    (G, features) = create_graph_features()\n    adj = G.to_adjacency_matrix().toarray()[(None, :, :)]\n    n_nodes = features.shape[0]\n    generator = FullBatchNodeGenerator(G, sparse=False, method='none')\n    gcnModel = GCN([2], generator, activations=['relu'], dropout=0.5)\n    (x_in, x_out) = gcnModel.in_out_tensors()\n    model = keras.Model(inputs=x_in, outputs=x_out)\n    out_indices = np.array([[0, 1]], dtype='int32')\n    preds_1 = model.predict([features[(None, :, :)], out_indices, adj])\n    assert (preds_1.shape == '???')\n    preds_2 = model.predict(generator.flow(['a', 'b']))\n    assert (preds_2.shape == (1, 2, 2))\n    assert (preds_1 == pytest.approx(preds_2))", "ground_truth": "(1, 2, 2)", "quality_analysis": {"complexity_score": 7, "left_complexity": 2, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_548", "reponame": "stellargraph", "testpath": "tests/layer/test_gcn.py", "testname": "test_gcn.py", "classname": null, "funcname": "test_GCN_apply_dense", "imports": ["import stellargraph as sg", "from stellargraph.layer.gcn import *", "from stellargraph.mapper import FullBatchNodeGenerator, FullBatchLinkGenerator", "from stellargraph.core.graph import StellarGraph", "from stellargraph.core.utils import GCN_Aadj_feats_op", "import networkx as nx", "import pandas as pd", "import numpy as np", "from tensorflow import keras", "import tensorflow as tf", "import pytest", "from ..test_utils.graphs import create_graph_features", "from .. import test_utils"], "code": "def test_GCN_apply_dense():\n    (G, features) = create_graph_features()\n    adj = G.to_adjacency_matrix().toarray()[(None, :, :)]\n    n_nodes = features.shape[0]\n    generator = FullBatchNodeGenerator(G, sparse=False, method='none')\n    gcnModel = GCN([2], generator, activations=['relu'], dropout=0.5)\n    (x_in, x_out) = gcnModel.in_out_tensors()\n    model = keras.Model(inputs=x_in, outputs=x_out)\n    out_indices = np.array([[0, 1]], dtype='int32')\n    preds_1 = model.predict([features[(None, :, :)], out_indices, adj])\n    assert (preds_1.shape == (1, 2, 2))\n    preds_2 = model.predict(generator.flow(['a', 'b']))\n    assert (preds_2.shape == (1, 2, 2))\n    assert (preds_1 == pytest.approx(preds_2))", "masked_code": "def test_GCN_apply_dense():\n    (G, features) = create_graph_features()\n    adj = G.to_adjacency_matrix().toarray()[(None, :, :)]\n    n_nodes = features.shape[0]\n    generator = FullBatchNodeGenerator(G, sparse=False, method='none')\n    gcnModel = GCN([2], generator, activations=['relu'], dropout=0.5)\n    (x_in, x_out) = gcnModel.in_out_tensors()\n    model = keras.Model(inputs=x_in, outputs=x_out)\n    out_indices = np.array([[0, 1]], dtype='int32')\n    preds_1 = model.predict([features[(None, :, :)], out_indices, adj])\n    assert (preds_1.shape == (1, 2, 2))\n    preds_2 = model.predict(generator.flow(['a', 'b']))\n    assert (preds_2.shape == '???')\n    assert (preds_1 == pytest.approx(preds_2))", "ground_truth": "(1, 2, 2)", "quality_analysis": {"complexity_score": 7, "left_complexity": 2, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_549", "reponame": "stellargraph", "testpath": "tests/layer/test_gcn.py", "testname": "test_gcn.py", "classname": null, "funcname": "test_GCN_apply_sparse", "imports": ["import stellargraph as sg", "from stellargraph.layer.gcn import *", "from stellargraph.mapper import FullBatchNodeGenerator, FullBatchLinkGenerator", "from stellargraph.core.graph import StellarGraph", "from stellargraph.core.utils import GCN_Aadj_feats_op", "import networkx as nx", "import pandas as pd", "import numpy as np", "from tensorflow import keras", "import tensorflow as tf", "import pytest", "from ..test_utils.graphs import create_graph_features", "from .. import test_utils"], "code": "def test_GCN_apply_sparse():\n    (G, features) = create_graph_features()\n    adj = G.to_adjacency_matrix()\n    (features, adj) = GCN_Aadj_feats_op(features, adj)\n    adj = adj.tocoo()\n    A_indices = np.expand_dims(np.hstack((adj.row[(:, None)], adj.col[(:, None)])).astype(np.int64), 0)\n    A_values = np.expand_dims(adj.data, 0)\n    generator = FullBatchNodeGenerator(G, sparse=True, method='gcn')\n    gcnModel = GCN(layer_sizes=[2], activations=['relu'], generator=generator, dropout=0.5)\n    (x_in, x_out) = gcnModel.in_out_tensors()\n    model = keras.Model(inputs=x_in, outputs=x_out)\n    out_indices = np.array([[0, 1]], dtype='int32')\n    preds_1 = model.predict([features[(None, :, :)], out_indices, A_indices, A_values])\n    assert (preds_1.shape == (1, 2, 2))\n    preds_2 = model.predict(generator.flow(['a', 'b']))\n    assert (preds_2.shape == (1, 2, 2))\n    assert (preds_1 == pytest.approx(preds_2))", "masked_code": "def test_GCN_apply_sparse():\n    (G, features) = create_graph_features()\n    adj = G.to_adjacency_matrix()\n    (features, adj) = GCN_Aadj_feats_op(features, adj)\n    adj = adj.tocoo()\n    A_indices = np.expand_dims(np.hstack((adj.row[(:, None)], adj.col[(:, None)])).astype(np.int64), 0)\n    A_values = np.expand_dims(adj.data, 0)\n    generator = FullBatchNodeGenerator(G, sparse=True, method='gcn')\n    gcnModel = GCN(layer_sizes=[2], activations=['relu'], generator=generator, dropout=0.5)\n    (x_in, x_out) = gcnModel.in_out_tensors()\n    model = keras.Model(inputs=x_in, outputs=x_out)\n    out_indices = np.array([[0, 1]], dtype='int32')\n    preds_1 = model.predict([features[(None, :, :)], out_indices, A_indices, A_values])\n    assert (preds_1.shape == '???')\n    preds_2 = model.predict(generator.flow(['a', 'b']))\n    assert (preds_2.shape == (1, 2, 2))\n    assert (preds_1 == pytest.approx(preds_2))", "ground_truth": "(1, 2, 2)", "quality_analysis": {"complexity_score": 7, "left_complexity": 2, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_550", "reponame": "stellargraph", "testpath": "tests/layer/test_gcn.py", "testname": "test_gcn.py", "classname": null, "funcname": "test_GCN_apply_sparse", "imports": ["import stellargraph as sg", "from stellargraph.layer.gcn import *", "from stellargraph.mapper import FullBatchNodeGenerator, FullBatchLinkGenerator", "from stellargraph.core.graph import StellarGraph", "from stellargraph.core.utils import GCN_Aadj_feats_op", "import networkx as nx", "import pandas as pd", "import numpy as np", "from tensorflow import keras", "import tensorflow as tf", "import pytest", "from ..test_utils.graphs import create_graph_features", "from .. import test_utils"], "code": "def test_GCN_apply_sparse():\n    (G, features) = create_graph_features()\n    adj = G.to_adjacency_matrix()\n    (features, adj) = GCN_Aadj_feats_op(features, adj)\n    adj = adj.tocoo()\n    A_indices = np.expand_dims(np.hstack((adj.row[(:, None)], adj.col[(:, None)])).astype(np.int64), 0)\n    A_values = np.expand_dims(adj.data, 0)\n    generator = FullBatchNodeGenerator(G, sparse=True, method='gcn')\n    gcnModel = GCN(layer_sizes=[2], activations=['relu'], generator=generator, dropout=0.5)\n    (x_in, x_out) = gcnModel.in_out_tensors()\n    model = keras.Model(inputs=x_in, outputs=x_out)\n    out_indices = np.array([[0, 1]], dtype='int32')\n    preds_1 = model.predict([features[(None, :, :)], out_indices, A_indices, A_values])\n    assert (preds_1.shape == (1, 2, 2))\n    preds_2 = model.predict(generator.flow(['a', 'b']))\n    assert (preds_2.shape == (1, 2, 2))\n    assert (preds_1 == pytest.approx(preds_2))", "masked_code": "def test_GCN_apply_sparse():\n    (G, features) = create_graph_features()\n    adj = G.to_adjacency_matrix()\n    (features, adj) = GCN_Aadj_feats_op(features, adj)\n    adj = adj.tocoo()\n    A_indices = np.expand_dims(np.hstack((adj.row[(:, None)], adj.col[(:, None)])).astype(np.int64), 0)\n    A_values = np.expand_dims(adj.data, 0)\n    generator = FullBatchNodeGenerator(G, sparse=True, method='gcn')\n    gcnModel = GCN(layer_sizes=[2], activations=['relu'], generator=generator, dropout=0.5)\n    (x_in, x_out) = gcnModel.in_out_tensors()\n    model = keras.Model(inputs=x_in, outputs=x_out)\n    out_indices = np.array([[0, 1]], dtype='int32')\n    preds_1 = model.predict([features[(None, :, :)], out_indices, A_indices, A_values])\n    assert (preds_1.shape == (1, 2, 2))\n    preds_2 = model.predict(generator.flow(['a', 'b']))\n    assert (preds_2.shape == '???')\n    assert (preds_1 == pytest.approx(preds_2))", "ground_truth": "(1, 2, 2)", "quality_analysis": {"complexity_score": 7, "left_complexity": 2, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_551", "reponame": "stellargraph", "testpath": "tests/layer/test_gcn.py", "testname": "test_gcn.py", "classname": null, "funcname": "test_GCN_linkmodel_apply_dense", "imports": ["import stellargraph as sg", "from stellargraph.layer.gcn import *", "from stellargraph.mapper import FullBatchNodeGenerator, FullBatchLinkGenerator", "from stellargraph.core.graph import StellarGraph", "from stellargraph.core.utils import GCN_Aadj_feats_op", "import networkx as nx", "import pandas as pd", "import numpy as np", "from tensorflow import keras", "import tensorflow as tf", "import pytest", "from ..test_utils.graphs import create_graph_features", "from .. import test_utils"], "code": "def test_GCN_linkmodel_apply_dense():\n    (G, features) = create_graph_features()\n    adj = G.to_adjacency_matrix().toarray()[(None, :, :)]\n    n_nodes = features.shape[0]\n    generator = FullBatchLinkGenerator(G, sparse=False, method='none')\n    gcnModel = GCN([3], generator, activations=['relu'], dropout=0.5)\n    (x_in, x_out) = gcnModel.in_out_tensors()\n    model = keras.Model(inputs=x_in, outputs=x_out)\n    out_indices = np.array([[[0, 1], [1, 2]]], dtype='int32')\n    preds_1 = model.predict([features[(None, :, :)], out_indices, adj])\n    assert (preds_1.shape == (1, 2, 2, 3))\n    preds_2 = model.predict(generator.flow([('a', 'b'), ('b', 'c')]))\n    assert (preds_2.shape == (1, 2, 2, 3))\n    assert (preds_1 == pytest.approx(preds_2))", "masked_code": "def test_GCN_linkmodel_apply_dense():\n    (G, features) = create_graph_features()\n    adj = G.to_adjacency_matrix().toarray()[(None, :, :)]\n    n_nodes = features.shape[0]\n    generator = FullBatchLinkGenerator(G, sparse=False, method='none')\n    gcnModel = GCN([3], generator, activations=['relu'], dropout=0.5)\n    (x_in, x_out) = gcnModel.in_out_tensors()\n    model = keras.Model(inputs=x_in, outputs=x_out)\n    out_indices = np.array([[[0, 1], [1, 2]]], dtype='int32')\n    preds_1 = model.predict([features[(None, :, :)], out_indices, adj])\n    assert (preds_1.shape == '???')\n    preds_2 = model.predict(generator.flow([('a', 'b'), ('b', 'c')]))\n    assert (preds_2.shape == (1, 2, 2, 3))\n    assert (preds_1 == pytest.approx(preds_2))", "ground_truth": "(1, 2, 2, 3)", "quality_analysis": {"complexity_score": 8, "left_complexity": 2, "right_complexity": 6, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_552", "reponame": "stellargraph", "testpath": "tests/layer/test_gcn.py", "testname": "test_gcn.py", "classname": null, "funcname": "test_GCN_linkmodel_apply_dense", "imports": ["import stellargraph as sg", "from stellargraph.layer.gcn import *", "from stellargraph.mapper import FullBatchNodeGenerator, FullBatchLinkGenerator", "from stellargraph.core.graph import StellarGraph", "from stellargraph.core.utils import GCN_Aadj_feats_op", "import networkx as nx", "import pandas as pd", "import numpy as np", "from tensorflow import keras", "import tensorflow as tf", "import pytest", "from ..test_utils.graphs import create_graph_features", "from .. import test_utils"], "code": "def test_GCN_linkmodel_apply_dense():\n    (G, features) = create_graph_features()\n    adj = G.to_adjacency_matrix().toarray()[(None, :, :)]\n    n_nodes = features.shape[0]\n    generator = FullBatchLinkGenerator(G, sparse=False, method='none')\n    gcnModel = GCN([3], generator, activations=['relu'], dropout=0.5)\n    (x_in, x_out) = gcnModel.in_out_tensors()\n    model = keras.Model(inputs=x_in, outputs=x_out)\n    out_indices = np.array([[[0, 1], [1, 2]]], dtype='int32')\n    preds_1 = model.predict([features[(None, :, :)], out_indices, adj])\n    assert (preds_1.shape == (1, 2, 2, 3))\n    preds_2 = model.predict(generator.flow([('a', 'b'), ('b', 'c')]))\n    assert (preds_2.shape == (1, 2, 2, 3))\n    assert (preds_1 == pytest.approx(preds_2))", "masked_code": "def test_GCN_linkmodel_apply_dense():\n    (G, features) = create_graph_features()\n    adj = G.to_adjacency_matrix().toarray()[(None, :, :)]\n    n_nodes = features.shape[0]\n    generator = FullBatchLinkGenerator(G, sparse=False, method='none')\n    gcnModel = GCN([3], generator, activations=['relu'], dropout=0.5)\n    (x_in, x_out) = gcnModel.in_out_tensors()\n    model = keras.Model(inputs=x_in, outputs=x_out)\n    out_indices = np.array([[[0, 1], [1, 2]]], dtype='int32')\n    preds_1 = model.predict([features[(None, :, :)], out_indices, adj])\n    assert (preds_1.shape == (1, 2, 2, 3))\n    preds_2 = model.predict(generator.flow([('a', 'b'), ('b', 'c')]))\n    assert (preds_2.shape == '???')\n    assert (preds_1 == pytest.approx(preds_2))", "ground_truth": "(1, 2, 2, 3)", "quality_analysis": {"complexity_score": 8, "left_complexity": 2, "right_complexity": 6, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_553", "reponame": "stellargraph", "testpath": "tests/layer/test_gcn.py", "testname": "test_gcn.py", "classname": null, "funcname": "test_GCN_linkmodel_apply_sparse", "imports": ["import stellargraph as sg", "from stellargraph.layer.gcn import *", "from stellargraph.mapper import FullBatchNodeGenerator, FullBatchLinkGenerator", "from stellargraph.core.graph import StellarGraph", "from stellargraph.core.utils import GCN_Aadj_feats_op", "import networkx as nx", "import pandas as pd", "import numpy as np", "from tensorflow import keras", "import tensorflow as tf", "import pytest", "from ..test_utils.graphs import create_graph_features", "from .. import test_utils"], "code": "def test_GCN_linkmodel_apply_sparse():\n    (G, features) = create_graph_features()\n    adj = G.to_adjacency_matrix()\n    (features, adj) = GCN_Aadj_feats_op(features, adj)\n    adj = adj.tocoo()\n    A_indices = np.expand_dims(np.hstack((adj.row[(:, None)], adj.col[(:, None)])).astype(np.int64), 0)\n    A_values = np.expand_dims(adj.data, 0)\n    generator = FullBatchLinkGenerator(G, sparse=True, method='gcn')\n    gcnModel = GCN(layer_sizes=[3], activations=['relu'], generator=generator, dropout=0.5)\n    (x_in, x_out) = gcnModel.in_out_tensors()\n    model = keras.Model(inputs=x_in, outputs=x_out)\n    out_indices = np.array([[[0, 1], [1, 2]]], dtype='int32')\n    preds_1 = model.predict([features[(None, :, :)], out_indices, A_indices, A_values])\n    assert (preds_1.shape == (1, 2, 2, 3))\n    preds_2 = model.predict(generator.flow([('a', 'b'), ('b', 'c')]))\n    assert (preds_2.shape == (1, 2, 2, 3))\n    assert (preds_1 == pytest.approx(preds_2))", "masked_code": "def test_GCN_linkmodel_apply_sparse():\n    (G, features) = create_graph_features()\n    adj = G.to_adjacency_matrix()\n    (features, adj) = GCN_Aadj_feats_op(features, adj)\n    adj = adj.tocoo()\n    A_indices = np.expand_dims(np.hstack((adj.row[(:, None)], adj.col[(:, None)])).astype(np.int64), 0)\n    A_values = np.expand_dims(adj.data, 0)\n    generator = FullBatchLinkGenerator(G, sparse=True, method='gcn')\n    gcnModel = GCN(layer_sizes=[3], activations=['relu'], generator=generator, dropout=0.5)\n    (x_in, x_out) = gcnModel.in_out_tensors()\n    model = keras.Model(inputs=x_in, outputs=x_out)\n    out_indices = np.array([[[0, 1], [1, 2]]], dtype='int32')\n    preds_1 = model.predict([features[(None, :, :)], out_indices, A_indices, A_values])\n    assert (preds_1.shape == '???')\n    preds_2 = model.predict(generator.flow([('a', 'b'), ('b', 'c')]))\n    assert (preds_2.shape == (1, 2, 2, 3))\n    assert (preds_1 == pytest.approx(preds_2))", "ground_truth": "(1, 2, 2, 3)", "quality_analysis": {"complexity_score": 8, "left_complexity": 2, "right_complexity": 6, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_554", "reponame": "stellargraph", "testpath": "tests/layer/test_gcn.py", "testname": "test_gcn.py", "classname": null, "funcname": "test_GCN_linkmodel_apply_sparse", "imports": ["import stellargraph as sg", "from stellargraph.layer.gcn import *", "from stellargraph.mapper import FullBatchNodeGenerator, FullBatchLinkGenerator", "from stellargraph.core.graph import StellarGraph", "from stellargraph.core.utils import GCN_Aadj_feats_op", "import networkx as nx", "import pandas as pd", "import numpy as np", "from tensorflow import keras", "import tensorflow as tf", "import pytest", "from ..test_utils.graphs import create_graph_features", "from .. import test_utils"], "code": "def test_GCN_linkmodel_apply_sparse():\n    (G, features) = create_graph_features()\n    adj = G.to_adjacency_matrix()\n    (features, adj) = GCN_Aadj_feats_op(features, adj)\n    adj = adj.tocoo()\n    A_indices = np.expand_dims(np.hstack((adj.row[(:, None)], adj.col[(:, None)])).astype(np.int64), 0)\n    A_values = np.expand_dims(adj.data, 0)\n    generator = FullBatchLinkGenerator(G, sparse=True, method='gcn')\n    gcnModel = GCN(layer_sizes=[3], activations=['relu'], generator=generator, dropout=0.5)\n    (x_in, x_out) = gcnModel.in_out_tensors()\n    model = keras.Model(inputs=x_in, outputs=x_out)\n    out_indices = np.array([[[0, 1], [1, 2]]], dtype='int32')\n    preds_1 = model.predict([features[(None, :, :)], out_indices, A_indices, A_values])\n    assert (preds_1.shape == (1, 2, 2, 3))\n    preds_2 = model.predict(generator.flow([('a', 'b'), ('b', 'c')]))\n    assert (preds_2.shape == (1, 2, 2, 3))\n    assert (preds_1 == pytest.approx(preds_2))", "masked_code": "def test_GCN_linkmodel_apply_sparse():\n    (G, features) = create_graph_features()\n    adj = G.to_adjacency_matrix()\n    (features, adj) = GCN_Aadj_feats_op(features, adj)\n    adj = adj.tocoo()\n    A_indices = np.expand_dims(np.hstack((adj.row[(:, None)], adj.col[(:, None)])).astype(np.int64), 0)\n    A_values = np.expand_dims(adj.data, 0)\n    generator = FullBatchLinkGenerator(G, sparse=True, method='gcn')\n    gcnModel = GCN(layer_sizes=[3], activations=['relu'], generator=generator, dropout=0.5)\n    (x_in, x_out) = gcnModel.in_out_tensors()\n    model = keras.Model(inputs=x_in, outputs=x_out)\n    out_indices = np.array([[[0, 1], [1, 2]]], dtype='int32')\n    preds_1 = model.predict([features[(None, :, :)], out_indices, A_indices, A_values])\n    assert (preds_1.shape == (1, 2, 2, 3))\n    preds_2 = model.predict(generator.flow([('a', 'b'), ('b', 'c')]))\n    assert (preds_2.shape == '???')\n    assert (preds_1 == pytest.approx(preds_2))", "ground_truth": "(1, 2, 2, 3)", "quality_analysis": {"complexity_score": 8, "left_complexity": 2, "right_complexity": 6, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_555", "reponame": "stellargraph", "testpath": "tests/layer/test_gcn.py", "testname": "test_gcn.py", "classname": null, "funcname": "test_GCN_activations", "imports": ["import stellargraph as sg", "from stellargraph.layer.gcn import *", "from stellargraph.mapper import FullBatchNodeGenerator, FullBatchLinkGenerator", "from stellargraph.core.graph import StellarGraph", "from stellargraph.core.utils import GCN_Aadj_feats_op", "import networkx as nx", "import pandas as pd", "import numpy as np", "from tensorflow import keras", "import tensorflow as tf", "import pytest", "from ..test_utils.graphs import create_graph_features", "from .. import test_utils"], "code": "def test_GCN_activations():\n    (G, features) = create_graph_features()\n    adj = G.to_adjacency_matrix().toarray()[(None, :, :)]\n    n_nodes = features.shape[0]\n    generator = FullBatchNodeGenerator(G, sparse=False, method='none')\n    gcn = GCN([2], generator)\n    assert (gcn.activations == ['relu'])\n    gcn = GCN([2, 2], generator)\n    assert (gcn.activations == ['relu', 'relu'])\n    gcn = GCN([2], generator, activations=['linear'])\n    assert (gcn.activations == ['linear'])\n    with pytest.raises(ValueError):\n        gcn = GCN([2], generator, activations=['relu', 'linear'])\n    with pytest.raises(ValueError):\n        gcn = GCN([2, 2], generator, activations=['relu'])\n    with pytest.raises(ValueError):\n        gcn = GCN([2], generator, activations=['bleach'])", "masked_code": "def test_GCN_activations():\n    (G, features) = create_graph_features()\n    adj = G.to_adjacency_matrix().toarray()[(None, :, :)]\n    n_nodes = features.shape[0]\n    generator = FullBatchNodeGenerator(G, sparse=False, method='none')\n    gcn = GCN([2], generator)\n    assert (gcn.activations == '???')\n    gcn = GCN([2, 2], generator)\n    assert (gcn.activations == ['relu', 'relu'])\n    gcn = GCN([2], generator, activations=['linear'])\n    assert (gcn.activations == ['linear'])\n    with pytest.raises(ValueError):\n        gcn = GCN([2], generator, activations=['relu', 'linear'])\n    with pytest.raises(ValueError):\n        gcn = GCN([2, 2], generator, activations=['relu'])\n    with pytest.raises(ValueError):\n        gcn = GCN([2], generator, activations=['bleach'])", "ground_truth": "['relu']", "quality_analysis": {"complexity_score": 5, "left_complexity": 2, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_556", "reponame": "stellargraph", "testpath": "tests/layer/test_gcn.py", "testname": "test_gcn.py", "classname": null, "funcname": "test_GCN_activations", "imports": ["import stellargraph as sg", "from stellargraph.layer.gcn import *", "from stellargraph.mapper import FullBatchNodeGenerator, FullBatchLinkGenerator", "from stellargraph.core.graph import StellarGraph", "from stellargraph.core.utils import GCN_Aadj_feats_op", "import networkx as nx", "import pandas as pd", "import numpy as np", "from tensorflow import keras", "import tensorflow as tf", "import pytest", "from ..test_utils.graphs import create_graph_features", "from .. import test_utils"], "code": "def test_GCN_activations():\n    (G, features) = create_graph_features()\n    adj = G.to_adjacency_matrix().toarray()[(None, :, :)]\n    n_nodes = features.shape[0]\n    generator = FullBatchNodeGenerator(G, sparse=False, method='none')\n    gcn = GCN([2], generator)\n    assert (gcn.activations == ['relu'])\n    gcn = GCN([2, 2], generator)\n    assert (gcn.activations == ['relu', 'relu'])\n    gcn = GCN([2], generator, activations=['linear'])\n    assert (gcn.activations == ['linear'])\n    with pytest.raises(ValueError):\n        gcn = GCN([2], generator, activations=['relu', 'linear'])\n    with pytest.raises(ValueError):\n        gcn = GCN([2, 2], generator, activations=['relu'])\n    with pytest.raises(ValueError):\n        gcn = GCN([2], generator, activations=['bleach'])", "masked_code": "def test_GCN_activations():\n    (G, features) = create_graph_features()\n    adj = G.to_adjacency_matrix().toarray()[(None, :, :)]\n    n_nodes = features.shape[0]\n    generator = FullBatchNodeGenerator(G, sparse=False, method='none')\n    gcn = GCN([2], generator)\n    assert (gcn.activations == ['relu'])\n    gcn = GCN([2, 2], generator)\n    assert (gcn.activations == '???')\n    gcn = GCN([2], generator, activations=['linear'])\n    assert (gcn.activations == ['linear'])\n    with pytest.raises(ValueError):\n        gcn = GCN([2], generator, activations=['relu', 'linear'])\n    with pytest.raises(ValueError):\n        gcn = GCN([2, 2], generator, activations=['relu'])\n    with pytest.raises(ValueError):\n        gcn = GCN([2], generator, activations=['bleach'])", "ground_truth": "['relu', 'relu']", "quality_analysis": {"complexity_score": 6, "left_complexity": 2, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_557", "reponame": "stellargraph", "testpath": "tests/layer/test_gcn.py", "testname": "test_gcn.py", "classname": null, "funcname": "test_GCN_activations", "imports": ["import stellargraph as sg", "from stellargraph.layer.gcn import *", "from stellargraph.mapper import FullBatchNodeGenerator, FullBatchLinkGenerator", "from stellargraph.core.graph import StellarGraph", "from stellargraph.core.utils import GCN_Aadj_feats_op", "import networkx as nx", "import pandas as pd", "import numpy as np", "from tensorflow import keras", "import tensorflow as tf", "import pytest", "from ..test_utils.graphs import create_graph_features", "from .. import test_utils"], "code": "def test_GCN_activations():\n    (G, features) = create_graph_features()\n    adj = G.to_adjacency_matrix().toarray()[(None, :, :)]\n    n_nodes = features.shape[0]\n    generator = FullBatchNodeGenerator(G, sparse=False, method='none')\n    gcn = GCN([2], generator)\n    assert (gcn.activations == ['relu'])\n    gcn = GCN([2, 2], generator)\n    assert (gcn.activations == ['relu', 'relu'])\n    gcn = GCN([2], generator, activations=['linear'])\n    assert (gcn.activations == ['linear'])\n    with pytest.raises(ValueError):\n        gcn = GCN([2], generator, activations=['relu', 'linear'])\n    with pytest.raises(ValueError):\n        gcn = GCN([2, 2], generator, activations=['relu'])\n    with pytest.raises(ValueError):\n        gcn = GCN([2], generator, activations=['bleach'])", "masked_code": "def test_GCN_activations():\n    (G, features) = create_graph_features()\n    adj = G.to_adjacency_matrix().toarray()[(None, :, :)]\n    n_nodes = features.shape[0]\n    generator = FullBatchNodeGenerator(G, sparse=False, method='none')\n    gcn = GCN([2], generator)\n    assert (gcn.activations == ['relu'])\n    gcn = GCN([2, 2], generator)\n    assert (gcn.activations == ['relu', 'relu'])\n    gcn = GCN([2], generator, activations=['linear'])\n    assert (gcn.activations == '???')\n    with pytest.raises(ValueError):\n        gcn = GCN([2], generator, activations=['relu', 'linear'])\n    with pytest.raises(ValueError):\n        gcn = GCN([2, 2], generator, activations=['relu'])\n    with pytest.raises(ValueError):\n        gcn = GCN([2], generator, activations=['bleach'])", "ground_truth": "['linear']", "quality_analysis": {"complexity_score": 5, "left_complexity": 2, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_558", "reponame": "stellargraph", "testpath": "tests/layer/test_gcn_lstm.py", "testname": "test_gcn_lstm.py", "classname": null, "funcname": "test_GraphConvolution_config", "imports": ["import numpy as np", "import pandas as pd", "import pytest", "from tensorflow.keras import Model", "from stellargraph import StellarGraph, IndexedArray", "from stellargraph.layer import GCN_LSTM", "from stellargraph.layer import FixedAdjacencyGraphConvolution", "from stellargraph.mapper import SlidingFeaturesNodeGenerator", "from .. import test_utils"], "code": "def test_GraphConvolution_config():\n    (_, _, a) = get_timeseries_graph_data()\n    gc_layer = FixedAdjacencyGraphConvolution(units=10, A=a, activation='relu')\n    conf = gc_layer.get_config()\n    assert (conf['units'] == 10)\n    assert (conf['activation'] == 'relu')\n    assert (conf['use_bias'] == True)\n    assert (conf['kernel_initializer']['class_name'] == 'GlorotUniform')\n    assert (conf['bias_initializer']['class_name'] == 'Zeros')\n    assert (conf['kernel_regularizer'] == None)\n    assert (conf['bias_regularizer'] == None)\n    assert (conf['kernel_constraint'] == None)\n    assert (conf['bias_constraint'] == None)", "masked_code": "def test_GraphConvolution_config():\n    (_, _, a) = get_timeseries_graph_data()\n    gc_layer = FixedAdjacencyGraphConvolution(units=10, A=a, activation='relu')\n    conf = gc_layer.get_config()\n    assert (conf['units'] == '???')\n    assert (conf['activation'] == 'relu')\n    assert (conf['use_bias'] == True)\n    assert (conf['kernel_initializer']['class_name'] == 'GlorotUniform')\n    assert (conf['bias_initializer']['class_name'] == 'Zeros')\n    assert (conf['kernel_regularizer'] == None)\n    assert (conf['bias_regularizer'] == None)\n    assert (conf['kernel_constraint'] == None)\n    assert (conf['bias_constraint'] == None)", "ground_truth": "10", "quality_analysis": {"complexity_score": 6, "left_complexity": 5, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_559", "reponame": "stellargraph", "testpath": "tests/layer/test_gcn_lstm.py", "testname": "test_gcn_lstm.py", "classname": null, "funcname": "test_GraphConvolution_config", "imports": ["import numpy as np", "import pandas as pd", "import pytest", "from tensorflow.keras import Model", "from stellargraph import StellarGraph, IndexedArray", "from stellargraph.layer import GCN_LSTM", "from stellargraph.layer import FixedAdjacencyGraphConvolution", "from stellargraph.mapper import SlidingFeaturesNodeGenerator", "from .. import test_utils"], "code": "def test_GraphConvolution_config():\n    (_, _, a) = get_timeseries_graph_data()\n    gc_layer = FixedAdjacencyGraphConvolution(units=10, A=a, activation='relu')\n    conf = gc_layer.get_config()\n    assert (conf['units'] == 10)\n    assert (conf['activation'] == 'relu')\n    assert (conf['use_bias'] == True)\n    assert (conf['kernel_initializer']['class_name'] == 'GlorotUniform')\n    assert (conf['bias_initializer']['class_name'] == 'Zeros')\n    assert (conf['kernel_regularizer'] == None)\n    assert (conf['bias_regularizer'] == None)\n    assert (conf['kernel_constraint'] == None)\n    assert (conf['bias_constraint'] == None)", "masked_code": "def test_GraphConvolution_config():\n    (_, _, a) = get_timeseries_graph_data()\n    gc_layer = FixedAdjacencyGraphConvolution(units=10, A=a, activation='relu')\n    conf = gc_layer.get_config()\n    assert (conf['units'] == 10)\n    assert (conf['activation'] == '???')\n    assert (conf['use_bias'] == True)\n    assert (conf['kernel_initializer']['class_name'] == 'GlorotUniform')\n    assert (conf['bias_initializer']['class_name'] == 'Zeros')\n    assert (conf['kernel_regularizer'] == None)\n    assert (conf['bias_regularizer'] == None)\n    assert (conf['kernel_constraint'] == None)\n    assert (conf['bias_constraint'] == None)", "ground_truth": "'relu'", "quality_analysis": {"complexity_score": 6, "left_complexity": 5, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_560", "reponame": "stellargraph", "testpath": "tests/layer/test_gcn_lstm.py", "testname": "test_gcn_lstm.py", "classname": null, "funcname": "test_GraphConvolution_config", "imports": ["import numpy as np", "import pandas as pd", "import pytest", "from tensorflow.keras import Model", "from stellargraph import StellarGraph, IndexedArray", "from stellargraph.layer import GCN_LSTM", "from stellargraph.layer import FixedAdjacencyGraphConvolution", "from stellargraph.mapper import SlidingFeaturesNodeGenerator", "from .. import test_utils"], "code": "def test_GraphConvolution_config():\n    (_, _, a) = get_timeseries_graph_data()\n    gc_layer = FixedAdjacencyGraphConvolution(units=10, A=a, activation='relu')\n    conf = gc_layer.get_config()\n    assert (conf['units'] == 10)\n    assert (conf['activation'] == 'relu')\n    assert (conf['use_bias'] == True)\n    assert (conf['kernel_initializer']['class_name'] == 'GlorotUniform')\n    assert (conf['bias_initializer']['class_name'] == 'Zeros')\n    assert (conf['kernel_regularizer'] == None)\n    assert (conf['bias_regularizer'] == None)\n    assert (conf['kernel_constraint'] == None)\n    assert (conf['bias_constraint'] == None)", "masked_code": "def test_GraphConvolution_config():\n    (_, _, a) = get_timeseries_graph_data()\n    gc_layer = FixedAdjacencyGraphConvolution(units=10, A=a, activation='relu')\n    conf = gc_layer.get_config()\n    assert (conf['units'] == 10)\n    assert (conf['activation'] == 'relu')\n    assert (conf['use_bias'] == True)\n    assert (conf['kernel_initializer']['class_name'] == '???')\n    assert (conf['bias_initializer']['class_name'] == 'Zeros')\n    assert (conf['kernel_regularizer'] == None)\n    assert (conf['bias_regularizer'] == None)\n    assert (conf['kernel_constraint'] == None)\n    assert (conf['bias_constraint'] == None)", "ground_truth": "'GlorotUniform'", "quality_analysis": {"complexity_score": 10, "left_complexity": 9, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_561", "reponame": "stellargraph", "testpath": "tests/layer/test_gcn_lstm.py", "testname": "test_gcn_lstm.py", "classname": null, "funcname": "test_GraphConvolution_config", "imports": ["import numpy as np", "import pandas as pd", "import pytest", "from tensorflow.keras import Model", "from stellargraph import StellarGraph, IndexedArray", "from stellargraph.layer import GCN_LSTM", "from stellargraph.layer import FixedAdjacencyGraphConvolution", "from stellargraph.mapper import SlidingFeaturesNodeGenerator", "from .. import test_utils"], "code": "def test_GraphConvolution_config():\n    (_, _, a) = get_timeseries_graph_data()\n    gc_layer = FixedAdjacencyGraphConvolution(units=10, A=a, activation='relu')\n    conf = gc_layer.get_config()\n    assert (conf['units'] == 10)\n    assert (conf['activation'] == 'relu')\n    assert (conf['use_bias'] == True)\n    assert (conf['kernel_initializer']['class_name'] == 'GlorotUniform')\n    assert (conf['bias_initializer']['class_name'] == 'Zeros')\n    assert (conf['kernel_regularizer'] == None)\n    assert (conf['bias_regularizer'] == None)\n    assert (conf['kernel_constraint'] == None)\n    assert (conf['bias_constraint'] == None)", "masked_code": "def test_GraphConvolution_config():\n    (_, _, a) = get_timeseries_graph_data()\n    gc_layer = FixedAdjacencyGraphConvolution(units=10, A=a, activation='relu')\n    conf = gc_layer.get_config()\n    assert (conf['units'] == 10)\n    assert (conf['activation'] == 'relu')\n    assert (conf['use_bias'] == True)\n    assert (conf['kernel_initializer']['class_name'] == 'GlorotUniform')\n    assert (conf['bias_initializer']['class_name'] == '???')\n    assert (conf['kernel_regularizer'] == None)\n    assert (conf['bias_regularizer'] == None)\n    assert (conf['kernel_constraint'] == None)\n    assert (conf['bias_constraint'] == None)", "ground_truth": "'Zeros'", "quality_analysis": {"complexity_score": 10, "left_complexity": 9, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_562", "reponame": "stellargraph", "testpath": "tests/layer/test_gcn_lstm.py", "testname": "test_gcn_lstm.py", "classname": null, "funcname": "test_GraphConvolution_config", "imports": ["import numpy as np", "import pandas as pd", "import pytest", "from tensorflow.keras import Model", "from stellargraph import StellarGraph, IndexedArray", "from stellargraph.layer import GCN_LSTM", "from stellargraph.layer import FixedAdjacencyGraphConvolution", "from stellargraph.mapper import SlidingFeaturesNodeGenerator", "from .. import test_utils"], "code": "def test_GraphConvolution_config():\n    (_, _, a) = get_timeseries_graph_data()\n    gc_layer = FixedAdjacencyGraphConvolution(units=10, A=a, activation='relu')\n    conf = gc_layer.get_config()\n    assert (conf['units'] == 10)\n    assert (conf['activation'] == 'relu')\n    assert (conf['use_bias'] == True)\n    assert (conf['kernel_initializer']['class_name'] == 'GlorotUniform')\n    assert (conf['bias_initializer']['class_name'] == 'Zeros')\n    assert (conf['kernel_regularizer'] == None)\n    assert (conf['bias_regularizer'] == None)\n    assert (conf['kernel_constraint'] == None)\n    assert (conf['bias_constraint'] == None)", "masked_code": "def test_GraphConvolution_config():\n    (_, _, a) = get_timeseries_graph_data()\n    gc_layer = FixedAdjacencyGraphConvolution(units=10, A=a, activation='relu')\n    conf = gc_layer.get_config()\n    assert (conf['units'] == 10)\n    assert (conf['activation'] == 'relu')\n    assert (conf['use_bias'] == True)\n    assert (conf['kernel_initializer']['class_name'] == 'GlorotUniform')\n    assert (conf['bias_initializer']['class_name'] == 'Zeros')\n    assert (conf['kernel_regularizer'] == '???')\n    assert (conf['bias_regularizer'] == None)\n    assert (conf['kernel_constraint'] == None)\n    assert (conf['bias_constraint'] == None)", "ground_truth": "None", "quality_analysis": {"complexity_score": 6, "left_complexity": 5, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_563", "reponame": "stellargraph", "testpath": "tests/layer/test_gcn_lstm.py", "testname": "test_gcn_lstm.py", "classname": null, "funcname": "test_GraphConvolution_config", "imports": ["import numpy as np", "import pandas as pd", "import pytest", "from tensorflow.keras import Model", "from stellargraph import StellarGraph, IndexedArray", "from stellargraph.layer import GCN_LSTM", "from stellargraph.layer import FixedAdjacencyGraphConvolution", "from stellargraph.mapper import SlidingFeaturesNodeGenerator", "from .. import test_utils"], "code": "def test_GraphConvolution_config():\n    (_, _, a) = get_timeseries_graph_data()\n    gc_layer = FixedAdjacencyGraphConvolution(units=10, A=a, activation='relu')\n    conf = gc_layer.get_config()\n    assert (conf['units'] == 10)\n    assert (conf['activation'] == 'relu')\n    assert (conf['use_bias'] == True)\n    assert (conf['kernel_initializer']['class_name'] == 'GlorotUniform')\n    assert (conf['bias_initializer']['class_name'] == 'Zeros')\n    assert (conf['kernel_regularizer'] == None)\n    assert (conf['bias_regularizer'] == None)\n    assert (conf['kernel_constraint'] == None)\n    assert (conf['bias_constraint'] == None)", "masked_code": "def test_GraphConvolution_config():\n    (_, _, a) = get_timeseries_graph_data()\n    gc_layer = FixedAdjacencyGraphConvolution(units=10, A=a, activation='relu')\n    conf = gc_layer.get_config()\n    assert (conf['units'] == 10)\n    assert (conf['activation'] == 'relu')\n    assert (conf['use_bias'] == True)\n    assert (conf['kernel_initializer']['class_name'] == 'GlorotUniform')\n    assert (conf['bias_initializer']['class_name'] == 'Zeros')\n    assert (conf['kernel_regularizer'] == None)\n    assert (conf['bias_regularizer'] == '???')\n    assert (conf['kernel_constraint'] == None)\n    assert (conf['bias_constraint'] == None)", "ground_truth": "None", "quality_analysis": {"complexity_score": 6, "left_complexity": 5, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_564", "reponame": "stellargraph", "testpath": "tests/layer/test_gcn_lstm.py", "testname": "test_gcn_lstm.py", "classname": null, "funcname": "test_GraphConvolution_config", "imports": ["import numpy as np", "import pandas as pd", "import pytest", "from tensorflow.keras import Model", "from stellargraph import StellarGraph, IndexedArray", "from stellargraph.layer import GCN_LSTM", "from stellargraph.layer import FixedAdjacencyGraphConvolution", "from stellargraph.mapper import SlidingFeaturesNodeGenerator", "from .. import test_utils"], "code": "def test_GraphConvolution_config():\n    (_, _, a) = get_timeseries_graph_data()\n    gc_layer = FixedAdjacencyGraphConvolution(units=10, A=a, activation='relu')\n    conf = gc_layer.get_config()\n    assert (conf['units'] == 10)\n    assert (conf['activation'] == 'relu')\n    assert (conf['use_bias'] == True)\n    assert (conf['kernel_initializer']['class_name'] == 'GlorotUniform')\n    assert (conf['bias_initializer']['class_name'] == 'Zeros')\n    assert (conf['kernel_regularizer'] == None)\n    assert (conf['bias_regularizer'] == None)\n    assert (conf['kernel_constraint'] == None)\n    assert (conf['bias_constraint'] == None)", "masked_code": "def test_GraphConvolution_config():\n    (_, _, a) = get_timeseries_graph_data()\n    gc_layer = FixedAdjacencyGraphConvolution(units=10, A=a, activation='relu')\n    conf = gc_layer.get_config()\n    assert (conf['units'] == 10)\n    assert (conf['activation'] == 'relu')\n    assert (conf['use_bias'] == True)\n    assert (conf['kernel_initializer']['class_name'] == 'GlorotUniform')\n    assert (conf['bias_initializer']['class_name'] == 'Zeros')\n    assert (conf['kernel_regularizer'] == None)\n    assert (conf['bias_regularizer'] == None)\n    assert (conf['kernel_constraint'] == '???')\n    assert (conf['bias_constraint'] == None)", "ground_truth": "None", "quality_analysis": {"complexity_score": 6, "left_complexity": 5, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_565", "reponame": "stellargraph", "testpath": "tests/layer/test_gcn_lstm.py", "testname": "test_gcn_lstm.py", "classname": null, "funcname": "test_GraphConvolution_config", "imports": ["import numpy as np", "import pandas as pd", "import pytest", "from tensorflow.keras import Model", "from stellargraph import StellarGraph, IndexedArray", "from stellargraph.layer import GCN_LSTM", "from stellargraph.layer import FixedAdjacencyGraphConvolution", "from stellargraph.mapper import SlidingFeaturesNodeGenerator", "from .. import test_utils"], "code": "def test_GraphConvolution_config():\n    (_, _, a) = get_timeseries_graph_data()\n    gc_layer = FixedAdjacencyGraphConvolution(units=10, A=a, activation='relu')\n    conf = gc_layer.get_config()\n    assert (conf['units'] == 10)\n    assert (conf['activation'] == 'relu')\n    assert (conf['use_bias'] == True)\n    assert (conf['kernel_initializer']['class_name'] == 'GlorotUniform')\n    assert (conf['bias_initializer']['class_name'] == 'Zeros')\n    assert (conf['kernel_regularizer'] == None)\n    assert (conf['bias_regularizer'] == None)\n    assert (conf['kernel_constraint'] == None)\n    assert (conf['bias_constraint'] == None)", "masked_code": "def test_GraphConvolution_config():\n    (_, _, a) = get_timeseries_graph_data()\n    gc_layer = FixedAdjacencyGraphConvolution(units=10, A=a, activation='relu')\n    conf = gc_layer.get_config()\n    assert (conf['units'] == 10)\n    assert (conf['activation'] == 'relu')\n    assert (conf['use_bias'] == True)\n    assert (conf['kernel_initializer']['class_name'] == 'GlorotUniform')\n    assert (conf['bias_initializer']['class_name'] == 'Zeros')\n    assert (conf['kernel_regularizer'] == None)\n    assert (conf['bias_regularizer'] == None)\n    assert (conf['kernel_constraint'] == None)\n    assert (conf['bias_constraint'] == '???')", "ground_truth": "None", "quality_analysis": {"complexity_score": 6, "left_complexity": 5, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_566", "reponame": "stellargraph", "testpath": "tests/layer/test_gcn_lstm.py", "testname": "test_gcn_lstm.py", "classname": null, "funcname": "test_gcn_lstm_model_parameters", "imports": ["import numpy as np", "import pandas as pd", "import pytest", "from tensorflow.keras import Model", "from stellargraph import StellarGraph, IndexedArray", "from stellargraph.layer import GCN_LSTM", "from stellargraph.layer import FixedAdjacencyGraphConvolution", "from stellargraph.mapper import SlidingFeaturesNodeGenerator", "from .. import test_utils"], "code": "def test_gcn_lstm_model_parameters():\n    (fx, fy, a) = get_timeseries_graph_data()\n    gcn_lstm_model = GCN_LSTM(seq_len=fx.shape[(- 2)], adj=a, gc_layer_sizes=[2, 2], gc_activations=['relu', 'relu'], lstm_layer_sizes=[10], lstm_activations=['tanh'])\n    assert (gcn_lstm_model.gc_activations == ['relu', 'relu'])\n    assert (gcn_lstm_model.dropout == 0.5)\n    assert (gcn_lstm_model.lstm_activations == ['tanh'])\n    assert (gcn_lstm_model.lstm_layer_sizes == [10])\n    assert (len(gcn_lstm_model.lstm_layer_sizes) == len(gcn_lstm_model.lstm_activations))", "masked_code": "def test_gcn_lstm_model_parameters():\n    (fx, fy, a) = get_timeseries_graph_data()\n    gcn_lstm_model = GCN_LSTM(seq_len=fx.shape[(- 2)], adj=a, gc_layer_sizes=[2, 2], gc_activations=['relu', 'relu'], lstm_layer_sizes=[10], lstm_activations=['tanh'])\n    assert (gcn_lstm_model.gc_activations == '???')\n    assert (gcn_lstm_model.dropout == 0.5)\n    assert (gcn_lstm_model.lstm_activations == ['tanh'])\n    assert (gcn_lstm_model.lstm_layer_sizes == [10])\n    assert (len(gcn_lstm_model.lstm_layer_sizes) == len(gcn_lstm_model.lstm_activations))", "ground_truth": "['relu', 'relu']", "quality_analysis": {"complexity_score": 6, "left_complexity": 2, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_567", "reponame": "stellargraph", "testpath": "tests/layer/test_gcn_lstm.py", "testname": "test_gcn_lstm.py", "classname": null, "funcname": "test_gcn_lstm_model_parameters", "imports": ["import numpy as np", "import pandas as pd", "import pytest", "from tensorflow.keras import Model", "from stellargraph import StellarGraph, IndexedArray", "from stellargraph.layer import GCN_LSTM", "from stellargraph.layer import FixedAdjacencyGraphConvolution", "from stellargraph.mapper import SlidingFeaturesNodeGenerator", "from .. import test_utils"], "code": "def test_gcn_lstm_model_parameters():\n    (fx, fy, a) = get_timeseries_graph_data()\n    gcn_lstm_model = GCN_LSTM(seq_len=fx.shape[(- 2)], adj=a, gc_layer_sizes=[2, 2], gc_activations=['relu', 'relu'], lstm_layer_sizes=[10], lstm_activations=['tanh'])\n    assert (gcn_lstm_model.gc_activations == ['relu', 'relu'])\n    assert (gcn_lstm_model.dropout == 0.5)\n    assert (gcn_lstm_model.lstm_activations == ['tanh'])\n    assert (gcn_lstm_model.lstm_layer_sizes == [10])\n    assert (len(gcn_lstm_model.lstm_layer_sizes) == len(gcn_lstm_model.lstm_activations))", "masked_code": "def test_gcn_lstm_model_parameters():\n    (fx, fy, a) = get_timeseries_graph_data()\n    gcn_lstm_model = GCN_LSTM(seq_len=fx.shape[(- 2)], adj=a, gc_layer_sizes=[2, 2], gc_activations=['relu', 'relu'], lstm_layer_sizes=[10], lstm_activations=['tanh'])\n    assert (gcn_lstm_model.gc_activations == ['relu', 'relu'])\n    assert (gcn_lstm_model.dropout == '???')\n    assert (gcn_lstm_model.lstm_activations == ['tanh'])\n    assert (gcn_lstm_model.lstm_layer_sizes == [10])\n    assert (len(gcn_lstm_model.lstm_layer_sizes) == len(gcn_lstm_model.lstm_activations))", "ground_truth": "0.5", "quality_analysis": {"complexity_score": 3, "left_complexity": 2, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_568", "reponame": "stellargraph", "testpath": "tests/layer/test_gcn_lstm.py", "testname": "test_gcn_lstm.py", "classname": null, "funcname": "test_gcn_lstm_model_parameters", "imports": ["import numpy as np", "import pandas as pd", "import pytest", "from tensorflow.keras import Model", "from stellargraph import StellarGraph, IndexedArray", "from stellargraph.layer import GCN_LSTM", "from stellargraph.layer import FixedAdjacencyGraphConvolution", "from stellargraph.mapper import SlidingFeaturesNodeGenerator", "from .. import test_utils"], "code": "def test_gcn_lstm_model_parameters():\n    (fx, fy, a) = get_timeseries_graph_data()\n    gcn_lstm_model = GCN_LSTM(seq_len=fx.shape[(- 2)], adj=a, gc_layer_sizes=[2, 2], gc_activations=['relu', 'relu'], lstm_layer_sizes=[10], lstm_activations=['tanh'])\n    assert (gcn_lstm_model.gc_activations == ['relu', 'relu'])\n    assert (gcn_lstm_model.dropout == 0.5)\n    assert (gcn_lstm_model.lstm_activations == ['tanh'])\n    assert (gcn_lstm_model.lstm_layer_sizes == [10])\n    assert (len(gcn_lstm_model.lstm_layer_sizes) == len(gcn_lstm_model.lstm_activations))", "masked_code": "def test_gcn_lstm_model_parameters():\n    (fx, fy, a) = get_timeseries_graph_data()\n    gcn_lstm_model = GCN_LSTM(seq_len=fx.shape[(- 2)], adj=a, gc_layer_sizes=[2, 2], gc_activations=['relu', 'relu'], lstm_layer_sizes=[10], lstm_activations=['tanh'])\n    assert (gcn_lstm_model.gc_activations == ['relu', 'relu'])\n    assert (gcn_lstm_model.dropout == 0.5)\n    assert (gcn_lstm_model.lstm_activations == '???')\n    assert (gcn_lstm_model.lstm_layer_sizes == [10])\n    assert (len(gcn_lstm_model.lstm_layer_sizes) == len(gcn_lstm_model.lstm_activations))", "ground_truth": "['tanh']", "quality_analysis": {"complexity_score": 5, "left_complexity": 2, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_569", "reponame": "stellargraph", "testpath": "tests/layer/test_gcn_lstm.py", "testname": "test_gcn_lstm.py", "classname": null, "funcname": "test_gcn_lstm_model_parameters", "imports": ["import numpy as np", "import pandas as pd", "import pytest", "from tensorflow.keras import Model", "from stellargraph import StellarGraph, IndexedArray", "from stellargraph.layer import GCN_LSTM", "from stellargraph.layer import FixedAdjacencyGraphConvolution", "from stellargraph.mapper import SlidingFeaturesNodeGenerator", "from .. import test_utils"], "code": "def test_gcn_lstm_model_parameters():\n    (fx, fy, a) = get_timeseries_graph_data()\n    gcn_lstm_model = GCN_LSTM(seq_len=fx.shape[(- 2)], adj=a, gc_layer_sizes=[2, 2], gc_activations=['relu', 'relu'], lstm_layer_sizes=[10], lstm_activations=['tanh'])\n    assert (gcn_lstm_model.gc_activations == ['relu', 'relu'])\n    assert (gcn_lstm_model.dropout == 0.5)\n    assert (gcn_lstm_model.lstm_activations == ['tanh'])\n    assert (gcn_lstm_model.lstm_layer_sizes == [10])\n    assert (len(gcn_lstm_model.lstm_layer_sizes) == len(gcn_lstm_model.lstm_activations))", "masked_code": "def test_gcn_lstm_model_parameters():\n    (fx, fy, a) = get_timeseries_graph_data()\n    gcn_lstm_model = GCN_LSTM(seq_len=fx.shape[(- 2)], adj=a, gc_layer_sizes=[2, 2], gc_activations=['relu', 'relu'], lstm_layer_sizes=[10], lstm_activations=['tanh'])\n    assert (gcn_lstm_model.gc_activations == ['relu', 'relu'])\n    assert (gcn_lstm_model.dropout == 0.5)\n    assert (gcn_lstm_model.lstm_activations == ['tanh'])\n    assert (gcn_lstm_model.lstm_layer_sizes == '???')\n    assert (len(gcn_lstm_model.lstm_layer_sizes) == len(gcn_lstm_model.lstm_activations))", "ground_truth": "[10]", "quality_analysis": {"complexity_score": 5, "left_complexity": 2, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_570", "reponame": "stellargraph", "testpath": "tests/layer/test_gcn_lstm.py", "testname": "test_gcn_lstm.py", "classname": null, "funcname": "test_gcn_lstm_model_parameters", "imports": ["import numpy as np", "import pandas as pd", "import pytest", "from tensorflow.keras import Model", "from stellargraph import StellarGraph, IndexedArray", "from stellargraph.layer import GCN_LSTM", "from stellargraph.layer import FixedAdjacencyGraphConvolution", "from stellargraph.mapper import SlidingFeaturesNodeGenerator", "from .. import test_utils"], "code": "def test_gcn_lstm_model_parameters():\n    (fx, fy, a) = get_timeseries_graph_data()\n    gcn_lstm_model = GCN_LSTM(seq_len=fx.shape[(- 2)], adj=a, gc_layer_sizes=[2, 2], gc_activations=['relu', 'relu'], lstm_layer_sizes=[10], lstm_activations=['tanh'])\n    assert (gcn_lstm_model.gc_activations == ['relu', 'relu'])\n    assert (gcn_lstm_model.dropout == 0.5)\n    assert (gcn_lstm_model.lstm_activations == ['tanh'])\n    assert (gcn_lstm_model.lstm_layer_sizes == [10])\n    assert (len(gcn_lstm_model.lstm_layer_sizes) == len(gcn_lstm_model.lstm_activations))", "masked_code": "def test_gcn_lstm_model_parameters():\n    (fx, fy, a) = get_timeseries_graph_data()\n    gcn_lstm_model = GCN_LSTM(seq_len=fx.shape[(- 2)], adj=a, gc_layer_sizes=[2, 2], gc_activations=['relu', 'relu'], lstm_layer_sizes=[10], lstm_activations=['tanh'])\n    assert (gcn_lstm_model.gc_activations == ['relu', 'relu'])\n    assert (gcn_lstm_model.dropout == 0.5)\n    assert (gcn_lstm_model.lstm_activations == ['tanh'])\n    assert (gcn_lstm_model.lstm_layer_sizes == [10])\n    assert (len(gcn_lstm_model.lstm_layer_sizes) == '???')", "ground_truth": "len(gcn_lstm_model.lstm_activations)", "quality_analysis": {"complexity_score": 10, "left_complexity": 5, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_571", "reponame": "stellargraph", "testpath": "tests/layer/test_gcn_lstm.py", "testname": "test_gcn_lstm.py", "classname": null, "funcname": "test_gcn_lstm_activations", "imports": ["import numpy as np", "import pandas as pd", "import pytest", "from tensorflow.keras import Model", "from stellargraph import StellarGraph, IndexedArray", "from stellargraph.layer import GCN_LSTM", "from stellargraph.layer import FixedAdjacencyGraphConvolution", "from stellargraph.mapper import SlidingFeaturesNodeGenerator", "from .. import test_utils"], "code": "def test_gcn_lstm_activations():\n    (fx, fy, a) = get_timeseries_graph_data()\n    gcn_lstm_model = GCN_LSTM(seq_len=fx.shape[(- 2)], adj=a, gc_layer_sizes=[10, 10, 10, 10, 10], lstm_layer_sizes=[8, 16, 32, 64])\n    assert (gcn_lstm_model.gc_activations == ['relu', 'relu', 'relu', 'relu', 'relu'])\n    assert (gcn_lstm_model.lstm_activations == ['tanh', 'tanh', 'tanh', 'tanh'])\n    gcn_lstm_model = GCN_LSTM(seq_len=fx.shape[(- 2)], adj=a, gc_layer_sizes=[10], gc_activations=['relu'], lstm_layer_sizes=[8, 16, 32, 64])\n    assert (gcn_lstm_model.lstm_activations == ['tanh', 'tanh', 'tanh', 'tanh'])", "masked_code": "def test_gcn_lstm_activations():\n    (fx, fy, a) = get_timeseries_graph_data()\n    gcn_lstm_model = GCN_LSTM(seq_len=fx.shape[(- 2)], adj=a, gc_layer_sizes=[10, 10, 10, 10, 10], lstm_layer_sizes=[8, 16, 32, 64])\n    assert (gcn_lstm_model.gc_activations == '???')\n    assert (gcn_lstm_model.lstm_activations == ['tanh', 'tanh', 'tanh', 'tanh'])\n    gcn_lstm_model = GCN_LSTM(seq_len=fx.shape[(- 2)], adj=a, gc_layer_sizes=[10], gc_activations=['relu'], lstm_layer_sizes=[8, 16, 32, 64])\n    assert (gcn_lstm_model.lstm_activations == ['tanh', 'tanh', 'tanh', 'tanh'])", "ground_truth": "['relu', 'relu', 'relu', 'relu', 'relu']", "quality_analysis": {"complexity_score": 9, "left_complexity": 2, "right_complexity": 7, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_572", "reponame": "stellargraph", "testpath": "tests/layer/test_gcn_lstm.py", "testname": "test_gcn_lstm.py", "classname": null, "funcname": "test_gcn_lstm_activations", "imports": ["import numpy as np", "import pandas as pd", "import pytest", "from tensorflow.keras import Model", "from stellargraph import StellarGraph, IndexedArray", "from stellargraph.layer import GCN_LSTM", "from stellargraph.layer import FixedAdjacencyGraphConvolution", "from stellargraph.mapper import SlidingFeaturesNodeGenerator", "from .. import test_utils"], "code": "def test_gcn_lstm_activations():\n    (fx, fy, a) = get_timeseries_graph_data()\n    gcn_lstm_model = GCN_LSTM(seq_len=fx.shape[(- 2)], adj=a, gc_layer_sizes=[10, 10, 10, 10, 10], lstm_layer_sizes=[8, 16, 32, 64])\n    assert (gcn_lstm_model.gc_activations == ['relu', 'relu', 'relu', 'relu', 'relu'])\n    assert (gcn_lstm_model.lstm_activations == ['tanh', 'tanh', 'tanh', 'tanh'])\n    gcn_lstm_model = GCN_LSTM(seq_len=fx.shape[(- 2)], adj=a, gc_layer_sizes=[10], gc_activations=['relu'], lstm_layer_sizes=[8, 16, 32, 64])\n    assert (gcn_lstm_model.lstm_activations == ['tanh', 'tanh', 'tanh', 'tanh'])", "masked_code": "def test_gcn_lstm_activations():\n    (fx, fy, a) = get_timeseries_graph_data()\n    gcn_lstm_model = GCN_LSTM(seq_len=fx.shape[(- 2)], adj=a, gc_layer_sizes=[10, 10, 10, 10, 10], lstm_layer_sizes=[8, 16, 32, 64])\n    assert (gcn_lstm_model.gc_activations == ['relu', 'relu', 'relu', 'relu', 'relu'])\n    assert (gcn_lstm_model.lstm_activations == '???')\n    gcn_lstm_model = GCN_LSTM(seq_len=fx.shape[(- 2)], adj=a, gc_layer_sizes=[10], gc_activations=['relu'], lstm_layer_sizes=[8, 16, 32, 64])\n    assert (gcn_lstm_model.lstm_activations == ['tanh', 'tanh', 'tanh', 'tanh'])", "ground_truth": "['tanh', 'tanh', 'tanh', 'tanh']", "quality_analysis": {"complexity_score": 8, "left_complexity": 2, "right_complexity": 6, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_573", "reponame": "stellargraph", "testpath": "tests/layer/test_gcn_lstm.py", "testname": "test_gcn_lstm.py", "classname": null, "funcname": "test_gcn_lstm_activations", "imports": ["import numpy as np", "import pandas as pd", "import pytest", "from tensorflow.keras import Model", "from stellargraph import StellarGraph, IndexedArray", "from stellargraph.layer import GCN_LSTM", "from stellargraph.layer import FixedAdjacencyGraphConvolution", "from stellargraph.mapper import SlidingFeaturesNodeGenerator", "from .. import test_utils"], "code": "def test_gcn_lstm_activations():\n    (fx, fy, a) = get_timeseries_graph_data()\n    gcn_lstm_model = GCN_LSTM(seq_len=fx.shape[(- 2)], adj=a, gc_layer_sizes=[10, 10, 10, 10, 10], lstm_layer_sizes=[8, 16, 32, 64])\n    assert (gcn_lstm_model.gc_activations == ['relu', 'relu', 'relu', 'relu', 'relu'])\n    assert (gcn_lstm_model.lstm_activations == ['tanh', 'tanh', 'tanh', 'tanh'])\n    gcn_lstm_model = GCN_LSTM(seq_len=fx.shape[(- 2)], adj=a, gc_layer_sizes=[10], gc_activations=['relu'], lstm_layer_sizes=[8, 16, 32, 64])\n    assert (gcn_lstm_model.lstm_activations == ['tanh', 'tanh', 'tanh', 'tanh'])", "masked_code": "def test_gcn_lstm_activations():\n    (fx, fy, a) = get_timeseries_graph_data()\n    gcn_lstm_model = GCN_LSTM(seq_len=fx.shape[(- 2)], adj=a, gc_layer_sizes=[10, 10, 10, 10, 10], lstm_layer_sizes=[8, 16, 32, 64])\n    assert (gcn_lstm_model.gc_activations == ['relu', 'relu', 'relu', 'relu', 'relu'])\n    assert (gcn_lstm_model.lstm_activations == ['tanh', 'tanh', 'tanh', 'tanh'])\n    gcn_lstm_model = GCN_LSTM(seq_len=fx.shape[(- 2)], adj=a, gc_layer_sizes=[10], gc_activations=['relu'], lstm_layer_sizes=[8, 16, 32, 64])\n    assert (gcn_lstm_model.lstm_activations == '???')", "ground_truth": "['tanh', 'tanh', 'tanh', 'tanh']", "quality_analysis": {"complexity_score": 8, "left_complexity": 2, "right_complexity": 6, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_574", "reponame": "stellargraph", "testpath": "tests/layer/test_gcn_lstm.py", "testname": "test_gcn_lstm.py", "classname": null, "funcname": "test_gcn_lstm_layers", "imports": ["import numpy as np", "import pandas as pd", "import pytest", "from tensorflow.keras import Model", "from stellargraph import StellarGraph, IndexedArray", "from stellargraph.layer import GCN_LSTM", "from stellargraph.layer import FixedAdjacencyGraphConvolution", "from stellargraph.mapper import SlidingFeaturesNodeGenerator", "from .. import test_utils"], "code": "def test_gcn_lstm_layers():\n    (fx, fy, a) = get_timeseries_graph_data()\n    gcn_lstm_model = GCN_LSTM(seq_len=fx.shape[(- 2)], adj=a, gc_layer_sizes=[8, 8, 16], gc_activations=['relu', 'relu', 'relu'], lstm_layer_sizes=[8, 16, 32], lstm_activations=['tanh'])\n    assert (len(gcn_lstm_model._gc_layers) == len(gcn_lstm_model.gc_layer_sizes))\n    assert (len(gcn_lstm_model._lstm_layers) == len(gcn_lstm_model.lstm_layer_sizes))", "masked_code": "def test_gcn_lstm_layers():\n    (fx, fy, a) = get_timeseries_graph_data()\n    gcn_lstm_model = GCN_LSTM(seq_len=fx.shape[(- 2)], adj=a, gc_layer_sizes=[8, 8, 16], gc_activations=['relu', 'relu', 'relu'], lstm_layer_sizes=[8, 16, 32], lstm_activations=['tanh'])\n    assert (len(gcn_lstm_model._gc_layers) == '???')\n    assert (len(gcn_lstm_model._lstm_layers) == len(gcn_lstm_model.lstm_layer_sizes))", "ground_truth": "len(gcn_lstm_model.gc_layer_sizes)", "quality_analysis": {"complexity_score": 10, "left_complexity": 5, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_575", "reponame": "stellargraph", "testpath": "tests/layer/test_gcn_lstm.py", "testname": "test_gcn_lstm.py", "classname": null, "funcname": "test_gcn_lstm_layers", "imports": ["import numpy as np", "import pandas as pd", "import pytest", "from tensorflow.keras import Model", "from stellargraph import StellarGraph, IndexedArray", "from stellargraph.layer import GCN_LSTM", "from stellargraph.layer import FixedAdjacencyGraphConvolution", "from stellargraph.mapper import SlidingFeaturesNodeGenerator", "from .. import test_utils"], "code": "def test_gcn_lstm_layers():\n    (fx, fy, a) = get_timeseries_graph_data()\n    gcn_lstm_model = GCN_LSTM(seq_len=fx.shape[(- 2)], adj=a, gc_layer_sizes=[8, 8, 16], gc_activations=['relu', 'relu', 'relu'], lstm_layer_sizes=[8, 16, 32], lstm_activations=['tanh'])\n    assert (len(gcn_lstm_model._gc_layers) == len(gcn_lstm_model.gc_layer_sizes))\n    assert (len(gcn_lstm_model._lstm_layers) == len(gcn_lstm_model.lstm_layer_sizes))", "masked_code": "def test_gcn_lstm_layers():\n    (fx, fy, a) = get_timeseries_graph_data()\n    gcn_lstm_model = GCN_LSTM(seq_len=fx.shape[(- 2)], adj=a, gc_layer_sizes=[8, 8, 16], gc_activations=['relu', 'relu', 'relu'], lstm_layer_sizes=[8, 16, 32], lstm_activations=['tanh'])\n    assert (len(gcn_lstm_model._gc_layers) == len(gcn_lstm_model.gc_layer_sizes))\n    assert (len(gcn_lstm_model._lstm_layers) == '???')", "ground_truth": "len(gcn_lstm_model.lstm_layer_sizes)", "quality_analysis": {"complexity_score": 10, "left_complexity": 5, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_576", "reponame": "stellargraph", "testpath": "tests/layer/test_gcn_lstm.py", "testname": "test_gcn_lstm.py", "classname": null, "funcname": "test_gcn_lstm_model_input_output", "imports": ["import numpy as np", "import pandas as pd", "import pytest", "from tensorflow.keras import Model", "from stellargraph import StellarGraph, IndexedArray", "from stellargraph.layer import GCN_LSTM", "from stellargraph.layer import FixedAdjacencyGraphConvolution", "from stellargraph.mapper import SlidingFeaturesNodeGenerator", "from .. import test_utils"], "code": "def test_gcn_lstm_model_input_output():\n    (fx, fy, a) = get_timeseries_graph_data()\n    gcn_lstm_model = GCN_LSTM(seq_len=fx.shape[(- 1)], adj=a, gc_layer_sizes=[8, 8, 16], gc_activations=['relu', 'relu', 'relu'], lstm_layer_sizes=[8, 16, 32], lstm_activations=['tanh'])\n    (x_input, x_output) = gcn_lstm_model.in_out_tensors()\n    assert (x_input.shape[1] == fx.shape[1])\n    assert (x_input.shape[2] == fx.shape[2])\n    assert (x_output.shape[1] == fx.shape[(- 2)])", "masked_code": "def test_gcn_lstm_model_input_output():\n    (fx, fy, a) = get_timeseries_graph_data()\n    gcn_lstm_model = GCN_LSTM(seq_len=fx.shape[(- 1)], adj=a, gc_layer_sizes=[8, 8, 16], gc_activations=['relu', 'relu', 'relu'], lstm_layer_sizes=[8, 16, 32], lstm_activations=['tanh'])\n    (x_input, x_output) = gcn_lstm_model.in_out_tensors()\n    assert (x_input.shape[1] == '???')\n    assert (x_input.shape[2] == fx.shape[2])\n    assert (x_output.shape[1] == fx.shape[(- 2)])", "ground_truth": "fx.shape[1]", "quality_analysis": {"complexity_score": 12, "left_complexity": 6, "right_complexity": 6, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_577", "reponame": "stellargraph", "testpath": "tests/layer/test_gcn_lstm.py", "testname": "test_gcn_lstm.py", "classname": null, "funcname": "test_gcn_lstm_model_input_output", "imports": ["import numpy as np", "import pandas as pd", "import pytest", "from tensorflow.keras import Model", "from stellargraph import StellarGraph, IndexedArray", "from stellargraph.layer import GCN_LSTM", "from stellargraph.layer import FixedAdjacencyGraphConvolution", "from stellargraph.mapper import SlidingFeaturesNodeGenerator", "from .. import test_utils"], "code": "def test_gcn_lstm_model_input_output():\n    (fx, fy, a) = get_timeseries_graph_data()\n    gcn_lstm_model = GCN_LSTM(seq_len=fx.shape[(- 1)], adj=a, gc_layer_sizes=[8, 8, 16], gc_activations=['relu', 'relu', 'relu'], lstm_layer_sizes=[8, 16, 32], lstm_activations=['tanh'])\n    (x_input, x_output) = gcn_lstm_model.in_out_tensors()\n    assert (x_input.shape[1] == fx.shape[1])\n    assert (x_input.shape[2] == fx.shape[2])\n    assert (x_output.shape[1] == fx.shape[(- 2)])", "masked_code": "def test_gcn_lstm_model_input_output():\n    (fx, fy, a) = get_timeseries_graph_data()\n    gcn_lstm_model = GCN_LSTM(seq_len=fx.shape[(- 1)], adj=a, gc_layer_sizes=[8, 8, 16], gc_activations=['relu', 'relu', 'relu'], lstm_layer_sizes=[8, 16, 32], lstm_activations=['tanh'])\n    (x_input, x_output) = gcn_lstm_model.in_out_tensors()\n    assert (x_input.shape[1] == fx.shape[1])\n    assert (x_input.shape[2] == '???')\n    assert (x_output.shape[1] == fx.shape[(- 2)])", "ground_truth": "fx.shape[2]", "quality_analysis": {"complexity_score": 12, "left_complexity": 6, "right_complexity": 6, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_578", "reponame": "stellargraph", "testpath": "tests/layer/test_gcn_lstm.py", "testname": "test_gcn_lstm.py", "classname": null, "funcname": "test_gcn_lstm_model_input_output", "imports": ["import numpy as np", "import pandas as pd", "import pytest", "from tensorflow.keras import Model", "from stellargraph import StellarGraph, IndexedArray", "from stellargraph.layer import GCN_LSTM", "from stellargraph.layer import FixedAdjacencyGraphConvolution", "from stellargraph.mapper import SlidingFeaturesNodeGenerator", "from .. import test_utils"], "code": "def test_gcn_lstm_model_input_output():\n    (fx, fy, a) = get_timeseries_graph_data()\n    gcn_lstm_model = GCN_LSTM(seq_len=fx.shape[(- 1)], adj=a, gc_layer_sizes=[8, 8, 16], gc_activations=['relu', 'relu', 'relu'], lstm_layer_sizes=[8, 16, 32], lstm_activations=['tanh'])\n    (x_input, x_output) = gcn_lstm_model.in_out_tensors()\n    assert (x_input.shape[1] == fx.shape[1])\n    assert (x_input.shape[2] == fx.shape[2])\n    assert (x_output.shape[1] == fx.shape[(- 2)])", "masked_code": "def test_gcn_lstm_model_input_output():\n    (fx, fy, a) = get_timeseries_graph_data()\n    gcn_lstm_model = GCN_LSTM(seq_len=fx.shape[(- 1)], adj=a, gc_layer_sizes=[8, 8, 16], gc_activations=['relu', 'relu', 'relu'], lstm_layer_sizes=[8, 16, 32], lstm_activations=['tanh'])\n    (x_input, x_output) = gcn_lstm_model.in_out_tensors()\n    assert (x_input.shape[1] == fx.shape[1])\n    assert (x_input.shape[2] == fx.shape[2])\n    assert (x_output.shape[1] == '???')", "ground_truth": "fx.shape[(- 2)]", "quality_analysis": {"complexity_score": 14, "left_complexity": 6, "right_complexity": 8, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_579", "reponame": "stellargraph", "testpath": "tests/layer/test_gcn_lstm.py", "testname": "test_gcn_lstm.py", "classname": null, "funcname": "test_gcn_lstm_model", "imports": ["import numpy as np", "import pandas as pd", "import pytest", "from tensorflow.keras import Model", "from stellargraph import StellarGraph, IndexedArray", "from stellargraph.layer import GCN_LSTM", "from stellargraph.layer import FixedAdjacencyGraphConvolution", "from stellargraph.mapper import SlidingFeaturesNodeGenerator", "from .. import test_utils"], "code": "def test_gcn_lstm_model():\n    (fx, fy, a) = get_timeseries_graph_data()\n    gcn_lstm_model = GCN_LSTM(seq_len=fx.shape[(- 1)], adj=a, gc_layer_sizes=[8, 8, 16], gc_activations=['relu', 'relu', 'relu'], lstm_layer_sizes=[8, 16, 32], lstm_activations=['tanh'])\n    (x_input, x_output) = gcn_lstm_model.in_out_tensors()\n    model = Model(inputs=x_input, outputs=x_output)\n    model.compile(optimizer='adam', loss='mae', metrics=['mse'])\n    history = model.fit(fx, fy, epochs=5, batch_size=2, shuffle=True, verbose=0)\n    assert (history.params['epochs'] == 5)\n    assert (len(history.history['loss']) == 5)", "masked_code": "def test_gcn_lstm_model():\n    (fx, fy, a) = get_timeseries_graph_data()\n    gcn_lstm_model = GCN_LSTM(seq_len=fx.shape[(- 1)], adj=a, gc_layer_sizes=[8, 8, 16], gc_activations=['relu', 'relu', 'relu'], lstm_layer_sizes=[8, 16, 32], lstm_activations=['tanh'])\n    (x_input, x_output) = gcn_lstm_model.in_out_tensors()\n    model = Model(inputs=x_input, outputs=x_output)\n    model.compile(optimizer='adam', loss='mae', metrics=['mse'])\n    history = model.fit(fx, fy, epochs=5, batch_size=2, shuffle=True, verbose=0)\n    assert (history.params['epochs'] == '???')\n    assert (len(history.history['loss']) == 5)", "ground_truth": "5", "quality_analysis": {"complexity_score": 7, "left_complexity": 6, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_580", "reponame": "stellargraph", "testpath": "tests/layer/test_gcn_lstm.py", "testname": "test_gcn_lstm.py", "classname": null, "funcname": "test_gcn_lstm_model", "imports": ["import numpy as np", "import pandas as pd", "import pytest", "from tensorflow.keras import Model", "from stellargraph import StellarGraph, IndexedArray", "from stellargraph.layer import GCN_LSTM", "from stellargraph.layer import FixedAdjacencyGraphConvolution", "from stellargraph.mapper import SlidingFeaturesNodeGenerator", "from .. import test_utils"], "code": "def test_gcn_lstm_model():\n    (fx, fy, a) = get_timeseries_graph_data()\n    gcn_lstm_model = GCN_LSTM(seq_len=fx.shape[(- 1)], adj=a, gc_layer_sizes=[8, 8, 16], gc_activations=['relu', 'relu', 'relu'], lstm_layer_sizes=[8, 16, 32], lstm_activations=['tanh'])\n    (x_input, x_output) = gcn_lstm_model.in_out_tensors()\n    model = Model(inputs=x_input, outputs=x_output)\n    model.compile(optimizer='adam', loss='mae', metrics=['mse'])\n    history = model.fit(fx, fy, epochs=5, batch_size=2, shuffle=True, verbose=0)\n    assert (history.params['epochs'] == 5)\n    assert (len(history.history['loss']) == 5)", "masked_code": "def test_gcn_lstm_model():\n    (fx, fy, a) = get_timeseries_graph_data()\n    gcn_lstm_model = GCN_LSTM(seq_len=fx.shape[(- 1)], adj=a, gc_layer_sizes=[8, 8, 16], gc_activations=['relu', 'relu', 'relu'], lstm_layer_sizes=[8, 16, 32], lstm_activations=['tanh'])\n    (x_input, x_output) = gcn_lstm_model.in_out_tensors()\n    model = Model(inputs=x_input, outputs=x_output)\n    model.compile(optimizer='adam', loss='mae', metrics=['mse'])\n    history = model.fit(fx, fy, epochs=5, batch_size=2, shuffle=True, verbose=0)\n    assert (history.params['epochs'] == 5)\n    assert (len(history.history['loss']) == '???')", "ground_truth": "5", "quality_analysis": {"complexity_score": 10, "left_complexity": 9, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_581", "reponame": "stellargraph", "testpath": "tests/layer/test_gcn_lstm.py", "testname": "test_gcn_lstm.py", "classname": null, "funcname": "test_gcn_lstm_model_prediction", "imports": ["import numpy as np", "import pandas as pd", "import pytest", "from tensorflow.keras import Model", "from stellargraph import StellarGraph, IndexedArray", "from stellargraph.layer import GCN_LSTM", "from stellargraph.layer import FixedAdjacencyGraphConvolution", "from stellargraph.mapper import SlidingFeaturesNodeGenerator", "from .. import test_utils"], "code": "def test_gcn_lstm_model_prediction():\n    (fx, fy, a) = get_timeseries_graph_data()\n    gcn_lstm_model = GCN_LSTM(seq_len=fx.shape[(- 1)], adj=a, gc_layer_sizes=[8, 8, 16], gc_activations=['relu', 'relu', 'relu'], lstm_layer_sizes=[8, 16, 32], lstm_activations=['tanh'])\n    (x_input, x_output) = gcn_lstm_model.in_out_tensors()\n    model = Model(inputs=x_input, outputs=x_output)\n    test_sample = np.random.rand(1, 5, 4)\n    pred = model.predict(test_sample)\n    assert (pred.shape == (1, 5))", "masked_code": "def test_gcn_lstm_model_prediction():\n    (fx, fy, a) = get_timeseries_graph_data()\n    gcn_lstm_model = GCN_LSTM(seq_len=fx.shape[(- 1)], adj=a, gc_layer_sizes=[8, 8, 16], gc_activations=['relu', 'relu', 'relu'], lstm_layer_sizes=[8, 16, 32], lstm_activations=['tanh'])\n    (x_input, x_output) = gcn_lstm_model.in_out_tensors()\n    model = Model(inputs=x_input, outputs=x_output)\n    test_sample = np.random.rand(1, 5, 4)\n    pred = model.predict(test_sample)\n    assert (pred.shape == '???')", "ground_truth": "(1, 5)", "quality_analysis": {"complexity_score": 6, "left_complexity": 2, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_582", "reponame": "stellargraph", "testpath": "tests/layer/test_graphsage.py", "testname": "test_graphsage.py", "classname": null, "funcname": "test_mean_agg_constructor", "imports": ["from tensorflow import keras", "from tensorflow.keras import initializers, regularizers", "import tensorflow as tf", "import numpy as np", "import pytest", "from stellargraph.mapper import GraphSAGENodeGenerator", "from stellargraph.layer.graphsage import GraphSAGE, MeanAggregator, MaxPoolingAggregator, MeanPoolingAggregator, AttentionalAggregator", "from ..test_utils.graphs import example_graph", "from .. import test_utils"], "code": "def test_mean_agg_constructor():\n    agg = MeanAggregator(2)\n    assert (agg.output_dim == 2)\n    assert (not agg.has_bias)\n    config = agg.get_config()\n    assert (config['output_dim'] == 2)\n    assert (config['bias'] is False)\n    assert (config['act'] == 'relu')", "masked_code": "def test_mean_agg_constructor():\n    agg = MeanAggregator(2)\n    assert (agg.output_dim == 2)\n    assert (not agg.has_bias)\n    config = agg.get_config()\n    assert (config['output_dim'] == 2)\n    assert (config['bias'] is False)\n    assert (config['act'] == '???')", "ground_truth": "'relu'", "quality_analysis": {"complexity_score": 6, "left_complexity": 5, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_583", "reponame": "stellargraph", "testpath": "tests/layer/test_graphsage.py", "testname": "test_graphsage.py", "classname": null, "funcname": "test_mean_agg_constructor_1", "imports": ["from tensorflow import keras", "from tensorflow.keras import initializers, regularizers", "import tensorflow as tf", "import numpy as np", "import pytest", "from stellargraph.mapper import GraphSAGENodeGenerator", "from stellargraph.layer.graphsage import GraphSAGE, MeanAggregator, MaxPoolingAggregator, MeanPoolingAggregator, AttentionalAggregator", "from ..test_utils.graphs import example_graph", "from .. import test_utils"], "code": "def test_mean_agg_constructor_1():\n    agg = MeanAggregator(output_dim=4, bias=True, act=(lambda x: (x + 1)))\n    assert (agg.output_dim == 4)\n    assert agg.has_bias\n    assert (agg.act(2) == 3)", "masked_code": "def test_mean_agg_constructor_1():\n    agg = MeanAggregator(output_dim=4, bias=True, act=(lambda x: (x + 1)))\n    assert (agg.output_dim == '???')\n    assert agg.has_bias\n    assert (agg.act(2) == 3)", "ground_truth": "4", "quality_analysis": {"complexity_score": 3, "left_complexity": 2, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_584", "reponame": "stellargraph", "testpath": "tests/layer/test_graphsage.py", "testname": "test_graphsage.py", "classname": null, "funcname": "test_mean_agg_constructor_1", "imports": ["from tensorflow import keras", "from tensorflow.keras import initializers, regularizers", "import tensorflow as tf", "import numpy as np", "import pytest", "from stellargraph.mapper import GraphSAGENodeGenerator", "from stellargraph.layer.graphsage import GraphSAGE, MeanAggregator, MaxPoolingAggregator, MeanPoolingAggregator, AttentionalAggregator", "from ..test_utils.graphs import example_graph", "from .. import test_utils"], "code": "def test_mean_agg_constructor_1():\n    agg = MeanAggregator(output_dim=4, bias=True, act=(lambda x: (x + 1)))\n    assert (agg.output_dim == 4)\n    assert agg.has_bias\n    assert (agg.act(2) == 3)", "masked_code": "def test_mean_agg_constructor_1():\n    agg = MeanAggregator(output_dim=4, bias=True, act=(lambda x: (x + 1)))\n    assert (agg.output_dim == 4)\n    assert agg.has_bias\n    assert (agg.act(2) == '???')", "ground_truth": "3", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_585", "reponame": "stellargraph", "testpath": "tests/layer/test_graphsage.py", "testname": "test_graphsage.py", "classname": null, "funcname": "test_mean_agg_apply", "imports": ["from tensorflow import keras", "from tensorflow.keras import initializers, regularizers", "import tensorflow as tf", "import numpy as np", "import pytest", "from stellargraph.mapper import GraphSAGENodeGenerator", "from stellargraph.layer.graphsage import GraphSAGE, MeanAggregator, MaxPoolingAggregator, MeanPoolingAggregator, AttentionalAggregator", "from ..test_utils.graphs import example_graph", "from .. import test_utils"], "code": "def test_mean_agg_apply():\n    agg = MeanAggregator(5, bias=True, act=(lambda x: x), kernel_initializer='ones')\n    inp1 = keras.Input(shape=(1, 2))\n    inp2 = keras.Input(shape=(1, 2, 2))\n    out = agg([inp1, inp2])\n    assert (agg.weight_dims == [3, 2])\n    model = keras.Model(inputs=[inp1, inp2], outputs=out)\n    x1 = np.array([[[1, 1]]])\n    x2 = np.array([[[[2, 2], [3, 3]]]])\n    actual = model.predict([x1, x2])\n    expected = np.array([[[2, 2, 2, 5, 5]]])\n    assert (expected == pytest.approx(actual))", "masked_code": "def test_mean_agg_apply():\n    agg = MeanAggregator(5, bias=True, act=(lambda x: x), kernel_initializer='ones')\n    inp1 = keras.Input(shape=(1, 2))\n    inp2 = keras.Input(shape=(1, 2, 2))\n    out = agg([inp1, inp2])\n    assert (agg.weight_dims == '???')\n    model = keras.Model(inputs=[inp1, inp2], outputs=out)\n    x1 = np.array([[[1, 1]]])\n    x2 = np.array([[[[2, 2], [3, 3]]]])\n    actual = model.predict([x1, x2])\n    expected = np.array([[[2, 2, 2, 5, 5]]])\n    assert (expected == pytest.approx(actual))", "ground_truth": "[3, 2]", "quality_analysis": {"complexity_score": 6, "left_complexity": 2, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_586", "reponame": "stellargraph", "testpath": "tests/layer/test_graphsage.py", "testname": "test_graphsage.py", "classname": null, "funcname": "test_mean_agg_apply_groups", "imports": ["from tensorflow import keras", "from tensorflow.keras import initializers, regularizers", "import tensorflow as tf", "import numpy as np", "import pytest", "from stellargraph.mapper import GraphSAGENodeGenerator", "from stellargraph.layer.graphsage import GraphSAGE, MeanAggregator, MaxPoolingAggregator, MeanPoolingAggregator, AttentionalAggregator", "from ..test_utils.graphs import example_graph", "from .. import test_utils"], "code": "def test_mean_agg_apply_groups():\n    agg = MeanAggregator(11, bias=True, act=(lambda x: x), kernel_initializer='ones')\n    inp1 = keras.Input(shape=(1, 2))\n    inp2 = keras.Input(shape=(1, 2, 2))\n    inp3 = keras.Input(shape=(1, 2, 2))\n    out = agg([inp1, inp2, inp3])\n    assert (agg.weight_dims == [5, 3, 3])\n    model = keras.Model(inputs=[inp1, inp2, inp3], outputs=out)\n    x1 = np.array([[[1, 1]]])\n    x2 = np.array([[[[2, 2], [3, 3]]]])\n    x3 = np.array([[[[5, 5], [4, 4]]]])\n    actual = model.predict([x1, x2, x3])\n    print(actual)\n    expected = np.array([[((([2] * 5) + ([5] * 3)) + ([9] * 3))]])\n    assert (expected == pytest.approx(actual))", "masked_code": "def test_mean_agg_apply_groups():\n    agg = MeanAggregator(11, bias=True, act=(lambda x: x), kernel_initializer='ones')\n    inp1 = keras.Input(shape=(1, 2))\n    inp2 = keras.Input(shape=(1, 2, 2))\n    inp3 = keras.Input(shape=(1, 2, 2))\n    out = agg([inp1, inp2, inp3])\n    assert (agg.weight_dims == '???')\n    model = keras.Model(inputs=[inp1, inp2, inp3], outputs=out)\n    x1 = np.array([[[1, 1]]])\n    x2 = np.array([[[[2, 2], [3, 3]]]])\n    x3 = np.array([[[[5, 5], [4, 4]]]])\n    actual = model.predict([x1, x2, x3])\n    print(actual)\n    expected = np.array([[((([2] * 5) + ([5] * 3)) + ([9] * 3))]])\n    assert (expected == pytest.approx(actual))", "ground_truth": "[5, 3, 3]", "quality_analysis": {"complexity_score": 7, "left_complexity": 2, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_587", "reponame": "stellargraph", "testpath": "tests/layer/test_graphsage.py", "testname": "test_graphsage.py", "classname": null, "funcname": "test_maxpool_agg_constructor", "imports": ["from tensorflow import keras", "from tensorflow.keras import initializers, regularizers", "import tensorflow as tf", "import numpy as np", "import pytest", "from stellargraph.mapper import GraphSAGENodeGenerator", "from stellargraph.layer.graphsage import GraphSAGE, MeanAggregator, MaxPoolingAggregator, MeanPoolingAggregator, AttentionalAggregator", "from ..test_utils.graphs import example_graph", "from .. import test_utils"], "code": "def test_maxpool_agg_constructor():\n    agg = MaxPoolingAggregator(2, bias=False)\n    assert (agg.output_dim == 2)\n    assert (agg.hidden_dim == 2)\n    assert (not agg.has_bias)\n    assert (agg.act.__name__ == 'relu')\n    assert (agg.hidden_act.__name__ == 'relu')\n    config = agg.get_config()\n    assert (config['output_dim'] == 2)\n    assert (config['bias'] == False)\n    assert (config['act'] == 'relu')", "masked_code": "def test_maxpool_agg_constructor():\n    agg = MaxPoolingAggregator(2, bias=False)\n    assert (agg.output_dim == 2)\n    assert (agg.hidden_dim == 2)\n    assert (not agg.has_bias)\n    assert (agg.act.__name__ == '???')\n    assert (agg.hidden_act.__name__ == 'relu')\n    config = agg.get_config()\n    assert (config['output_dim'] == 2)\n    assert (config['bias'] == False)\n    assert (config['act'] == 'relu')", "ground_truth": "'relu'", "quality_analysis": {"complexity_score": 3, "left_complexity": 2, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_588", "reponame": "stellargraph", "testpath": "tests/layer/test_graphsage.py", "testname": "test_graphsage.py", "classname": null, "funcname": "test_maxpool_agg_constructor", "imports": ["from tensorflow import keras", "from tensorflow.keras import initializers, regularizers", "import tensorflow as tf", "import numpy as np", "import pytest", "from stellargraph.mapper import GraphSAGENodeGenerator", "from stellargraph.layer.graphsage import GraphSAGE, MeanAggregator, MaxPoolingAggregator, MeanPoolingAggregator, AttentionalAggregator", "from ..test_utils.graphs import example_graph", "from .. import test_utils"], "code": "def test_maxpool_agg_constructor():\n    agg = MaxPoolingAggregator(2, bias=False)\n    assert (agg.output_dim == 2)\n    assert (agg.hidden_dim == 2)\n    assert (not agg.has_bias)\n    assert (agg.act.__name__ == 'relu')\n    assert (agg.hidden_act.__name__ == 'relu')\n    config = agg.get_config()\n    assert (config['output_dim'] == 2)\n    assert (config['bias'] == False)\n    assert (config['act'] == 'relu')", "masked_code": "def test_maxpool_agg_constructor():\n    agg = MaxPoolingAggregator(2, bias=False)\n    assert (agg.output_dim == 2)\n    assert (agg.hidden_dim == 2)\n    assert (not agg.has_bias)\n    assert (agg.act.__name__ == 'relu')\n    assert (agg.hidden_act.__name__ == '???')\n    config = agg.get_config()\n    assert (config['output_dim'] == 2)\n    assert (config['bias'] == False)\n    assert (config['act'] == 'relu')", "ground_truth": "'relu'", "quality_analysis": {"complexity_score": 3, "left_complexity": 2, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_589", "reponame": "stellargraph", "testpath": "tests/layer/test_graphsage.py", "testname": "test_graphsage.py", "classname": null, "funcname": "test_maxpool_agg_constructor", "imports": ["from tensorflow import keras", "from tensorflow.keras import initializers, regularizers", "import tensorflow as tf", "import numpy as np", "import pytest", "from stellargraph.mapper import GraphSAGENodeGenerator", "from stellargraph.layer.graphsage import GraphSAGE, MeanAggregator, MaxPoolingAggregator, MeanPoolingAggregator, AttentionalAggregator", "from ..test_utils.graphs import example_graph", "from .. import test_utils"], "code": "def test_maxpool_agg_constructor():\n    agg = MaxPoolingAggregator(2, bias=False)\n    assert (agg.output_dim == 2)\n    assert (agg.hidden_dim == 2)\n    assert (not agg.has_bias)\n    assert (agg.act.__name__ == 'relu')\n    assert (agg.hidden_act.__name__ == 'relu')\n    config = agg.get_config()\n    assert (config['output_dim'] == 2)\n    assert (config['bias'] == False)\n    assert (config['act'] == 'relu')", "masked_code": "def test_maxpool_agg_constructor():\n    agg = MaxPoolingAggregator(2, bias=False)\n    assert (agg.output_dim == 2)\n    assert (agg.hidden_dim == 2)\n    assert (not agg.has_bias)\n    assert (agg.act.__name__ == 'relu')\n    assert (agg.hidden_act.__name__ == 'relu')\n    config = agg.get_config()\n    assert (config['output_dim'] == 2)\n    assert (config['bias'] == False)\n    assert (config['act'] == '???')", "ground_truth": "'relu'", "quality_analysis": {"complexity_score": 6, "left_complexity": 5, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_590", "reponame": "stellargraph", "testpath": "tests/layer/test_graphsage.py", "testname": "test_graphsage.py", "classname": null, "funcname": "test_maxpool_agg_constructor_1", "imports": ["from tensorflow import keras", "from tensorflow.keras import initializers, regularizers", "import tensorflow as tf", "import numpy as np", "import pytest", "from stellargraph.mapper import GraphSAGENodeGenerator", "from stellargraph.layer.graphsage import GraphSAGE, MeanAggregator, MaxPoolingAggregator, MeanPoolingAggregator, AttentionalAggregator", "from ..test_utils.graphs import example_graph", "from .. import test_utils"], "code": "def test_maxpool_agg_constructor_1():\n    agg = MaxPoolingAggregator(output_dim=4, bias=True, act=(lambda x: (x + 1)))\n    assert (agg.output_dim == 4)\n    assert (agg.hidden_dim == 4)\n    assert agg.has_bias\n    assert (agg.act(2) == 3)", "masked_code": "def test_maxpool_agg_constructor_1():\n    agg = MaxPoolingAggregator(output_dim=4, bias=True, act=(lambda x: (x + 1)))\n    assert (agg.output_dim == '???')\n    assert (agg.hidden_dim == 4)\n    assert agg.has_bias\n    assert (agg.act(2) == 3)", "ground_truth": "4", "quality_analysis": {"complexity_score": 3, "left_complexity": 2, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_591", "reponame": "stellargraph", "testpath": "tests/layer/test_graphsage.py", "testname": "test_graphsage.py", "classname": null, "funcname": "test_maxpool_agg_constructor_1", "imports": ["from tensorflow import keras", "from tensorflow.keras import initializers, regularizers", "import tensorflow as tf", "import numpy as np", "import pytest", "from stellargraph.mapper import GraphSAGENodeGenerator", "from stellargraph.layer.graphsage import GraphSAGE, MeanAggregator, MaxPoolingAggregator, MeanPoolingAggregator, AttentionalAggregator", "from ..test_utils.graphs import example_graph", "from .. import test_utils"], "code": "def test_maxpool_agg_constructor_1():\n    agg = MaxPoolingAggregator(output_dim=4, bias=True, act=(lambda x: (x + 1)))\n    assert (agg.output_dim == 4)\n    assert (agg.hidden_dim == 4)\n    assert agg.has_bias\n    assert (agg.act(2) == 3)", "masked_code": "def test_maxpool_agg_constructor_1():\n    agg = MaxPoolingAggregator(output_dim=4, bias=True, act=(lambda x: (x + 1)))\n    assert (agg.output_dim == 4)\n    assert (agg.hidden_dim == '???')\n    assert agg.has_bias\n    assert (agg.act(2) == 3)", "ground_truth": "4", "quality_analysis": {"complexity_score": 3, "left_complexity": 2, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_592", "reponame": "stellargraph", "testpath": "tests/layer/test_graphsage.py", "testname": "test_graphsage.py", "classname": null, "funcname": "test_maxpool_agg_constructor_1", "imports": ["from tensorflow import keras", "from tensorflow.keras import initializers, regularizers", "import tensorflow as tf", "import numpy as np", "import pytest", "from stellargraph.mapper import GraphSAGENodeGenerator", "from stellargraph.layer.graphsage import GraphSAGE, MeanAggregator, MaxPoolingAggregator, MeanPoolingAggregator, AttentionalAggregator", "from ..test_utils.graphs import example_graph", "from .. import test_utils"], "code": "def test_maxpool_agg_constructor_1():\n    agg = MaxPoolingAggregator(output_dim=4, bias=True, act=(lambda x: (x + 1)))\n    assert (agg.output_dim == 4)\n    assert (agg.hidden_dim == 4)\n    assert agg.has_bias\n    assert (agg.act(2) == 3)", "masked_code": "def test_maxpool_agg_constructor_1():\n    agg = MaxPoolingAggregator(output_dim=4, bias=True, act=(lambda x: (x + 1)))\n    assert (agg.output_dim == 4)\n    assert (agg.hidden_dim == 4)\n    assert agg.has_bias\n    assert (agg.act(2) == '???')", "ground_truth": "3", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_593", "reponame": "stellargraph", "testpath": "tests/layer/test_graphsage.py", "testname": "test_graphsage.py", "classname": null, "funcname": "test_maxpool_agg_apply_hidden_bias", "imports": ["from tensorflow import keras", "from tensorflow.keras import initializers, regularizers", "import tensorflow as tf", "import numpy as np", "import pytest", "from stellargraph.mapper import GraphSAGENodeGenerator", "from stellargraph.layer.graphsage import GraphSAGE, MeanAggregator, MaxPoolingAggregator, MeanPoolingAggregator, AttentionalAggregator", "from ..test_utils.graphs import example_graph", "from .. import test_utils"], "code": "def test_maxpool_agg_apply_hidden_bias():\n    agg = MaxPoolingAggregator(2, bias=False, act='linear', kernel_initializer='ones', bias_initializer='ones')\n    assert (agg.get_config()['kernel_initializer']['class_name'] == 'Ones')\n    assert (agg.get_config()['bias_initializer']['class_name'] == 'Ones')\n    inp1 = keras.Input(shape=(1, 2))\n    inp2 = keras.Input(shape=(1, 2, 2))\n    out = agg([inp1, inp2])\n    assert (agg.weight_dims == [1, 1])\n    x1 = np.array([[[1, 1]]])\n    x2 = np.array([[[[2, 2], [3, 3]]]])\n    model = keras.Model(inputs=[inp1, inp2], outputs=out)\n    actual = model.predict([x1, x2])\n    expected = np.array([[[2, 14]]])\n    assert (expected == pytest.approx(actual))", "masked_code": "def test_maxpool_agg_apply_hidden_bias():\n    agg = MaxPoolingAggregator(2, bias=False, act='linear', kernel_initializer='ones', bias_initializer='ones')\n    assert (agg.get_config()['kernel_initializer']['class_name'] == '???')\n    assert (agg.get_config()['bias_initializer']['class_name'] == 'Ones')\n    inp1 = keras.Input(shape=(1, 2))\n    inp2 = keras.Input(shape=(1, 2, 2))\n    out = agg([inp1, inp2])\n    assert (agg.weight_dims == [1, 1])\n    x1 = np.array([[[1, 1]]])\n    x2 = np.array([[[[2, 2], [3, 3]]]])\n    model = keras.Model(inputs=[inp1, inp2], outputs=out)\n    actual = model.predict([x1, x2])\n    expected = np.array([[[2, 14]]])\n    assert (expected == pytest.approx(actual))", "ground_truth": "'Ones'", "quality_analysis": {"complexity_score": 12, "left_complexity": 11, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_594", "reponame": "stellargraph", "testpath": "tests/layer/test_graphsage.py", "testname": "test_graphsage.py", "classname": null, "funcname": "test_maxpool_agg_apply_hidden_bias", "imports": ["from tensorflow import keras", "from tensorflow.keras import initializers, regularizers", "import tensorflow as tf", "import numpy as np", "import pytest", "from stellargraph.mapper import GraphSAGENodeGenerator", "from stellargraph.layer.graphsage import GraphSAGE, MeanAggregator, MaxPoolingAggregator, MeanPoolingAggregator, AttentionalAggregator", "from ..test_utils.graphs import example_graph", "from .. import test_utils"], "code": "def test_maxpool_agg_apply_hidden_bias():\n    agg = MaxPoolingAggregator(2, bias=False, act='linear', kernel_initializer='ones', bias_initializer='ones')\n    assert (agg.get_config()['kernel_initializer']['class_name'] == 'Ones')\n    assert (agg.get_config()['bias_initializer']['class_name'] == 'Ones')\n    inp1 = keras.Input(shape=(1, 2))\n    inp2 = keras.Input(shape=(1, 2, 2))\n    out = agg([inp1, inp2])\n    assert (agg.weight_dims == [1, 1])\n    x1 = np.array([[[1, 1]]])\n    x2 = np.array([[[[2, 2], [3, 3]]]])\n    model = keras.Model(inputs=[inp1, inp2], outputs=out)\n    actual = model.predict([x1, x2])\n    expected = np.array([[[2, 14]]])\n    assert (expected == pytest.approx(actual))", "masked_code": "def test_maxpool_agg_apply_hidden_bias():\n    agg = MaxPoolingAggregator(2, bias=False, act='linear', kernel_initializer='ones', bias_initializer='ones')\n    assert (agg.get_config()['kernel_initializer']['class_name'] == 'Ones')\n    assert (agg.get_config()['bias_initializer']['class_name'] == '???')\n    inp1 = keras.Input(shape=(1, 2))\n    inp2 = keras.Input(shape=(1, 2, 2))\n    out = agg([inp1, inp2])\n    assert (agg.weight_dims == [1, 1])\n    x1 = np.array([[[1, 1]]])\n    x2 = np.array([[[[2, 2], [3, 3]]]])\n    model = keras.Model(inputs=[inp1, inp2], outputs=out)\n    actual = model.predict([x1, x2])\n    expected = np.array([[[2, 14]]])\n    assert (expected == pytest.approx(actual))", "ground_truth": "'Ones'", "quality_analysis": {"complexity_score": 12, "left_complexity": 11, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_595", "reponame": "stellargraph", "testpath": "tests/layer/test_graphsage.py", "testname": "test_graphsage.py", "classname": null, "funcname": "test_maxpool_agg_apply_hidden_bias", "imports": ["from tensorflow import keras", "from tensorflow.keras import initializers, regularizers", "import tensorflow as tf", "import numpy as np", "import pytest", "from stellargraph.mapper import GraphSAGENodeGenerator", "from stellargraph.layer.graphsage import GraphSAGE, MeanAggregator, MaxPoolingAggregator, MeanPoolingAggregator, AttentionalAggregator", "from ..test_utils.graphs import example_graph", "from .. import test_utils"], "code": "def test_maxpool_agg_apply_hidden_bias():\n    agg = MaxPoolingAggregator(2, bias=False, act='linear', kernel_initializer='ones', bias_initializer='ones')\n    assert (agg.get_config()['kernel_initializer']['class_name'] == 'Ones')\n    assert (agg.get_config()['bias_initializer']['class_name'] == 'Ones')\n    inp1 = keras.Input(shape=(1, 2))\n    inp2 = keras.Input(shape=(1, 2, 2))\n    out = agg([inp1, inp2])\n    assert (agg.weight_dims == [1, 1])\n    x1 = np.array([[[1, 1]]])\n    x2 = np.array([[[[2, 2], [3, 3]]]])\n    model = keras.Model(inputs=[inp1, inp2], outputs=out)\n    actual = model.predict([x1, x2])\n    expected = np.array([[[2, 14]]])\n    assert (expected == pytest.approx(actual))", "masked_code": "def test_maxpool_agg_apply_hidden_bias():\n    agg = MaxPoolingAggregator(2, bias=False, act='linear', kernel_initializer='ones', bias_initializer='ones')\n    assert (agg.get_config()['kernel_initializer']['class_name'] == 'Ones')\n    assert (agg.get_config()['bias_initializer']['class_name'] == 'Ones')\n    inp1 = keras.Input(shape=(1, 2))\n    inp2 = keras.Input(shape=(1, 2, 2))\n    out = agg([inp1, inp2])\n    assert (agg.weight_dims == '???')\n    x1 = np.array([[[1, 1]]])\n    x2 = np.array([[[[2, 2], [3, 3]]]])\n    model = keras.Model(inputs=[inp1, inp2], outputs=out)\n    actual = model.predict([x1, x2])\n    expected = np.array([[[2, 14]]])\n    assert (expected == pytest.approx(actual))", "ground_truth": "[1, 1]", "quality_analysis": {"complexity_score": 6, "left_complexity": 2, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_596", "reponame": "stellargraph", "testpath": "tests/layer/test_graphsage.py", "testname": "test_graphsage.py", "classname": null, "funcname": "test_maxpool_agg_apply_no_bias", "imports": ["from tensorflow import keras", "from tensorflow.keras import initializers, regularizers", "import tensorflow as tf", "import numpy as np", "import pytest", "from stellargraph.mapper import GraphSAGENodeGenerator", "from stellargraph.layer.graphsage import GraphSAGE, MeanAggregator, MaxPoolingAggregator, MeanPoolingAggregator, AttentionalAggregator", "from ..test_utils.graphs import example_graph", "from .. import test_utils"], "code": "def test_maxpool_agg_apply_no_bias():\n    agg = MaxPoolingAggregator(2, act='linear', kernel_initializer='ones')\n    assert (agg.get_config()['kernel_initializer']['class_name'] == 'Ones')\n    assert (agg.get_config()['bias_initializer']['class_name'] == 'Zeros')\n    inp1 = keras.Input(shape=(1, 2))\n    inp2 = keras.Input(shape=(1, 2, 2))\n    out = agg([inp1, inp2])\n    assert (agg.weight_dims == [1, 1])\n    x1 = np.array([[[1, 1]]])\n    x2 = np.array([[[[2, 2], [3, 3]]]])\n    model = keras.Model(inputs=[inp1, inp2], outputs=out)\n    actual = model.predict([x1, x2])\n    expected = np.array([[[2, 12]]])\n    assert (expected == pytest.approx(actual))", "masked_code": "def test_maxpool_agg_apply_no_bias():\n    agg = MaxPoolingAggregator(2, act='linear', kernel_initializer='ones')\n    assert (agg.get_config()['kernel_initializer']['class_name'] == '???')\n    assert (agg.get_config()['bias_initializer']['class_name'] == 'Zeros')\n    inp1 = keras.Input(shape=(1, 2))\n    inp2 = keras.Input(shape=(1, 2, 2))\n    out = agg([inp1, inp2])\n    assert (agg.weight_dims == [1, 1])\n    x1 = np.array([[[1, 1]]])\n    x2 = np.array([[[[2, 2], [3, 3]]]])\n    model = keras.Model(inputs=[inp1, inp2], outputs=out)\n    actual = model.predict([x1, x2])\n    expected = np.array([[[2, 12]]])\n    assert (expected == pytest.approx(actual))", "ground_truth": "'Ones'", "quality_analysis": {"complexity_score": 12, "left_complexity": 11, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_597", "reponame": "stellargraph", "testpath": "tests/layer/test_graphsage.py", "testname": "test_graphsage.py", "classname": null, "funcname": "test_maxpool_agg_apply_no_bias", "imports": ["from tensorflow import keras", "from tensorflow.keras import initializers, regularizers", "import tensorflow as tf", "import numpy as np", "import pytest", "from stellargraph.mapper import GraphSAGENodeGenerator", "from stellargraph.layer.graphsage import GraphSAGE, MeanAggregator, MaxPoolingAggregator, MeanPoolingAggregator, AttentionalAggregator", "from ..test_utils.graphs import example_graph", "from .. import test_utils"], "code": "def test_maxpool_agg_apply_no_bias():\n    agg = MaxPoolingAggregator(2, act='linear', kernel_initializer='ones')\n    assert (agg.get_config()['kernel_initializer']['class_name'] == 'Ones')\n    assert (agg.get_config()['bias_initializer']['class_name'] == 'Zeros')\n    inp1 = keras.Input(shape=(1, 2))\n    inp2 = keras.Input(shape=(1, 2, 2))\n    out = agg([inp1, inp2])\n    assert (agg.weight_dims == [1, 1])\n    x1 = np.array([[[1, 1]]])\n    x2 = np.array([[[[2, 2], [3, 3]]]])\n    model = keras.Model(inputs=[inp1, inp2], outputs=out)\n    actual = model.predict([x1, x2])\n    expected = np.array([[[2, 12]]])\n    assert (expected == pytest.approx(actual))", "masked_code": "def test_maxpool_agg_apply_no_bias():\n    agg = MaxPoolingAggregator(2, act='linear', kernel_initializer='ones')\n    assert (agg.get_config()['kernel_initializer']['class_name'] == 'Ones')\n    assert (agg.get_config()['bias_initializer']['class_name'] == '???')\n    inp1 = keras.Input(shape=(1, 2))\n    inp2 = keras.Input(shape=(1, 2, 2))\n    out = agg([inp1, inp2])\n    assert (agg.weight_dims == [1, 1])\n    x1 = np.array([[[1, 1]]])\n    x2 = np.array([[[[2, 2], [3, 3]]]])\n    model = keras.Model(inputs=[inp1, inp2], outputs=out)\n    actual = model.predict([x1, x2])\n    expected = np.array([[[2, 12]]])\n    assert (expected == pytest.approx(actual))", "ground_truth": "'Zeros'", "quality_analysis": {"complexity_score": 12, "left_complexity": 11, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_598", "reponame": "stellargraph", "testpath": "tests/layer/test_graphsage.py", "testname": "test_graphsage.py", "classname": null, "funcname": "test_maxpool_agg_apply_no_bias", "imports": ["from tensorflow import keras", "from tensorflow.keras import initializers, regularizers", "import tensorflow as tf", "import numpy as np", "import pytest", "from stellargraph.mapper import GraphSAGENodeGenerator", "from stellargraph.layer.graphsage import GraphSAGE, MeanAggregator, MaxPoolingAggregator, MeanPoolingAggregator, AttentionalAggregator", "from ..test_utils.graphs import example_graph", "from .. import test_utils"], "code": "def test_maxpool_agg_apply_no_bias():\n    agg = MaxPoolingAggregator(2, act='linear', kernel_initializer='ones')\n    assert (agg.get_config()['kernel_initializer']['class_name'] == 'Ones')\n    assert (agg.get_config()['bias_initializer']['class_name'] == 'Zeros')\n    inp1 = keras.Input(shape=(1, 2))\n    inp2 = keras.Input(shape=(1, 2, 2))\n    out = agg([inp1, inp2])\n    assert (agg.weight_dims == [1, 1])\n    x1 = np.array([[[1, 1]]])\n    x2 = np.array([[[[2, 2], [3, 3]]]])\n    model = keras.Model(inputs=[inp1, inp2], outputs=out)\n    actual = model.predict([x1, x2])\n    expected = np.array([[[2, 12]]])\n    assert (expected == pytest.approx(actual))", "masked_code": "def test_maxpool_agg_apply_no_bias():\n    agg = MaxPoolingAggregator(2, act='linear', kernel_initializer='ones')\n    assert (agg.get_config()['kernel_initializer']['class_name'] == 'Ones')\n    assert (agg.get_config()['bias_initializer']['class_name'] == 'Zeros')\n    inp1 = keras.Input(shape=(1, 2))\n    inp2 = keras.Input(shape=(1, 2, 2))\n    out = agg([inp1, inp2])\n    assert (agg.weight_dims == '???')\n    x1 = np.array([[[1, 1]]])\n    x2 = np.array([[[[2, 2], [3, 3]]]])\n    model = keras.Model(inputs=[inp1, inp2], outputs=out)\n    actual = model.predict([x1, x2])\n    expected = np.array([[[2, 12]]])\n    assert (expected == pytest.approx(actual))", "ground_truth": "[1, 1]", "quality_analysis": {"complexity_score": 6, "left_complexity": 2, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_599", "reponame": "stellargraph", "testpath": "tests/layer/test_graphsage.py", "testname": "test_graphsage.py", "classname": null, "funcname": "test_meanpool_agg_constructor", "imports": ["from tensorflow import keras", "from tensorflow.keras import initializers, regularizers", "import tensorflow as tf", "import numpy as np", "import pytest", "from stellargraph.mapper import GraphSAGENodeGenerator", "from stellargraph.layer.graphsage import GraphSAGE, MeanAggregator, MaxPoolingAggregator, MeanPoolingAggregator, AttentionalAggregator", "from ..test_utils.graphs import example_graph", "from .. import test_utils"], "code": "def test_meanpool_agg_constructor():\n    agg = MeanPoolingAggregator(2, bias=False)\n    assert (agg.output_dim == 2)\n    assert (agg.hidden_dim == 2)\n    assert (not agg.has_bias)\n    assert (agg.act.__name__ == 'relu')\n    assert (agg.hidden_act.__name__ == 'relu')\n    config = agg.get_config()\n    assert (config['output_dim'] == 2)\n    assert (config['bias'] is False)\n    assert (config['act'] == 'relu')", "masked_code": "def test_meanpool_agg_constructor():\n    agg = MeanPoolingAggregator(2, bias=False)\n    assert (agg.output_dim == 2)\n    assert (agg.hidden_dim == 2)\n    assert (not agg.has_bias)\n    assert (agg.act.__name__ == '???')\n    assert (agg.hidden_act.__name__ == 'relu')\n    config = agg.get_config()\n    assert (config['output_dim'] == 2)\n    assert (config['bias'] is False)\n    assert (config['act'] == 'relu')", "ground_truth": "'relu'", "quality_analysis": {"complexity_score": 3, "left_complexity": 2, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_600", "reponame": "stellargraph", "testpath": "tests/layer/test_graphsage.py", "testname": "test_graphsage.py", "classname": null, "funcname": "test_meanpool_agg_constructor", "imports": ["from tensorflow import keras", "from tensorflow.keras import initializers, regularizers", "import tensorflow as tf", "import numpy as np", "import pytest", "from stellargraph.mapper import GraphSAGENodeGenerator", "from stellargraph.layer.graphsage import GraphSAGE, MeanAggregator, MaxPoolingAggregator, MeanPoolingAggregator, AttentionalAggregator", "from ..test_utils.graphs import example_graph", "from .. import test_utils"], "code": "def test_meanpool_agg_constructor():\n    agg = MeanPoolingAggregator(2, bias=False)\n    assert (agg.output_dim == 2)\n    assert (agg.hidden_dim == 2)\n    assert (not agg.has_bias)\n    assert (agg.act.__name__ == 'relu')\n    assert (agg.hidden_act.__name__ == 'relu')\n    config = agg.get_config()\n    assert (config['output_dim'] == 2)\n    assert (config['bias'] is False)\n    assert (config['act'] == 'relu')", "masked_code": "def test_meanpool_agg_constructor():\n    agg = MeanPoolingAggregator(2, bias=False)\n    assert (agg.output_dim == 2)\n    assert (agg.hidden_dim == 2)\n    assert (not agg.has_bias)\n    assert (agg.act.__name__ == 'relu')\n    assert (agg.hidden_act.__name__ == '???')\n    config = agg.get_config()\n    assert (config['output_dim'] == 2)\n    assert (config['bias'] is False)\n    assert (config['act'] == 'relu')", "ground_truth": "'relu'", "quality_analysis": {"complexity_score": 3, "left_complexity": 2, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_601", "reponame": "stellargraph", "testpath": "tests/layer/test_graphsage.py", "testname": "test_graphsage.py", "classname": null, "funcname": "test_meanpool_agg_constructor", "imports": ["from tensorflow import keras", "from tensorflow.keras import initializers, regularizers", "import tensorflow as tf", "import numpy as np", "import pytest", "from stellargraph.mapper import GraphSAGENodeGenerator", "from stellargraph.layer.graphsage import GraphSAGE, MeanAggregator, MaxPoolingAggregator, MeanPoolingAggregator, AttentionalAggregator", "from ..test_utils.graphs import example_graph", "from .. import test_utils"], "code": "def test_meanpool_agg_constructor():\n    agg = MeanPoolingAggregator(2, bias=False)\n    assert (agg.output_dim == 2)\n    assert (agg.hidden_dim == 2)\n    assert (not agg.has_bias)\n    assert (agg.act.__name__ == 'relu')\n    assert (agg.hidden_act.__name__ == 'relu')\n    config = agg.get_config()\n    assert (config['output_dim'] == 2)\n    assert (config['bias'] is False)\n    assert (config['act'] == 'relu')", "masked_code": "def test_meanpool_agg_constructor():\n    agg = MeanPoolingAggregator(2, bias=False)\n    assert (agg.output_dim == 2)\n    assert (agg.hidden_dim == 2)\n    assert (not agg.has_bias)\n    assert (agg.act.__name__ == 'relu')\n    assert (agg.hidden_act.__name__ == 'relu')\n    config = agg.get_config()\n    assert (config['output_dim'] == 2)\n    assert (config['bias'] is False)\n    assert (config['act'] == '???')", "ground_truth": "'relu'", "quality_analysis": {"complexity_score": 6, "left_complexity": 5, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_602", "reponame": "stellargraph", "testpath": "tests/layer/test_graphsage.py", "testname": "test_graphsage.py", "classname": null, "funcname": "test_meanpool_agg_constructor_1", "imports": ["from tensorflow import keras", "from tensorflow.keras import initializers, regularizers", "import tensorflow as tf", "import numpy as np", "import pytest", "from stellargraph.mapper import GraphSAGENodeGenerator", "from stellargraph.layer.graphsage import GraphSAGE, MeanAggregator, MaxPoolingAggregator, MeanPoolingAggregator, AttentionalAggregator", "from ..test_utils.graphs import example_graph", "from .. import test_utils"], "code": "def test_meanpool_agg_constructor_1():\n    agg = MeanPoolingAggregator(output_dim=4, bias=True, act=(lambda x: (x + 1)))\n    assert (agg.output_dim == 4)\n    assert (agg.hidden_dim == 4)\n    assert agg.has_bias\n    assert (agg.act(2) == 3)", "masked_code": "def test_meanpool_agg_constructor_1():\n    agg = MeanPoolingAggregator(output_dim=4, bias=True, act=(lambda x: (x + 1)))\n    assert (agg.output_dim == '???')\n    assert (agg.hidden_dim == 4)\n    assert agg.has_bias\n    assert (agg.act(2) == 3)", "ground_truth": "4", "quality_analysis": {"complexity_score": 3, "left_complexity": 2, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_603", "reponame": "stellargraph", "testpath": "tests/layer/test_graphsage.py", "testname": "test_graphsage.py", "classname": null, "funcname": "test_meanpool_agg_constructor_1", "imports": ["from tensorflow import keras", "from tensorflow.keras import initializers, regularizers", "import tensorflow as tf", "import numpy as np", "import pytest", "from stellargraph.mapper import GraphSAGENodeGenerator", "from stellargraph.layer.graphsage import GraphSAGE, MeanAggregator, MaxPoolingAggregator, MeanPoolingAggregator, AttentionalAggregator", "from ..test_utils.graphs import example_graph", "from .. import test_utils"], "code": "def test_meanpool_agg_constructor_1():\n    agg = MeanPoolingAggregator(output_dim=4, bias=True, act=(lambda x: (x + 1)))\n    assert (agg.output_dim == 4)\n    assert (agg.hidden_dim == 4)\n    assert agg.has_bias\n    assert (agg.act(2) == 3)", "masked_code": "def test_meanpool_agg_constructor_1():\n    agg = MeanPoolingAggregator(output_dim=4, bias=True, act=(lambda x: (x + 1)))\n    assert (agg.output_dim == 4)\n    assert (agg.hidden_dim == '???')\n    assert agg.has_bias\n    assert (agg.act(2) == 3)", "ground_truth": "4", "quality_analysis": {"complexity_score": 3, "left_complexity": 2, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_604", "reponame": "stellargraph", "testpath": "tests/layer/test_graphsage.py", "testname": "test_graphsage.py", "classname": null, "funcname": "test_meanpool_agg_constructor_1", "imports": ["from tensorflow import keras", "from tensorflow.keras import initializers, regularizers", "import tensorflow as tf", "import numpy as np", "import pytest", "from stellargraph.mapper import GraphSAGENodeGenerator", "from stellargraph.layer.graphsage import GraphSAGE, MeanAggregator, MaxPoolingAggregator, MeanPoolingAggregator, AttentionalAggregator", "from ..test_utils.graphs import example_graph", "from .. import test_utils"], "code": "def test_meanpool_agg_constructor_1():\n    agg = MeanPoolingAggregator(output_dim=4, bias=True, act=(lambda x: (x + 1)))\n    assert (agg.output_dim == 4)\n    assert (agg.hidden_dim == 4)\n    assert agg.has_bias\n    assert (agg.act(2) == 3)", "masked_code": "def test_meanpool_agg_constructor_1():\n    agg = MeanPoolingAggregator(output_dim=4, bias=True, act=(lambda x: (x + 1)))\n    assert (agg.output_dim == 4)\n    assert (agg.hidden_dim == 4)\n    assert agg.has_bias\n    assert (agg.act(2) == '???')", "ground_truth": "3", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_605", "reponame": "stellargraph", "testpath": "tests/layer/test_graphsage.py", "testname": "test_graphsage.py", "classname": null, "funcname": "test_meanpool_agg_apply_hidden_bias", "imports": ["from tensorflow import keras", "from tensorflow.keras import initializers, regularizers", "import tensorflow as tf", "import numpy as np", "import pytest", "from stellargraph.mapper import GraphSAGENodeGenerator", "from stellargraph.layer.graphsage import GraphSAGE, MeanAggregator, MaxPoolingAggregator, MeanPoolingAggregator, AttentionalAggregator", "from ..test_utils.graphs import example_graph", "from .. import test_utils"], "code": "def test_meanpool_agg_apply_hidden_bias():\n    agg = MeanPoolingAggregator(2, bias=False, act='linear', kernel_initializer='ones', bias_initializer='ones')\n    assert (agg.get_config()['kernel_initializer']['class_name'] == 'Ones')\n    assert (agg.get_config()['bias_initializer']['class_name'] == 'Ones')\n    inp1 = keras.Input(shape=(1, 2))\n    inp2 = keras.Input(shape=(1, 2, 2))\n    out = agg([inp1, inp2])\n    assert (agg.weight_dims == [1, 1])\n    x1 = np.array([[[1, 1]]])\n    x2 = np.array([[[[2, 2], [3, 3]]]])\n    model = keras.Model(inputs=[inp1, inp2], outputs=out)\n    actual = model.predict([x1, x2])\n    expected = np.array([[[2, 12]]])\n    assert (expected == pytest.approx(actual))", "masked_code": "def test_meanpool_agg_apply_hidden_bias():\n    agg = MeanPoolingAggregator(2, bias=False, act='linear', kernel_initializer='ones', bias_initializer='ones')\n    assert (agg.get_config()['kernel_initializer']['class_name'] == '???')\n    assert (agg.get_config()['bias_initializer']['class_name'] == 'Ones')\n    inp1 = keras.Input(shape=(1, 2))\n    inp2 = keras.Input(shape=(1, 2, 2))\n    out = agg([inp1, inp2])\n    assert (agg.weight_dims == [1, 1])\n    x1 = np.array([[[1, 1]]])\n    x2 = np.array([[[[2, 2], [3, 3]]]])\n    model = keras.Model(inputs=[inp1, inp2], outputs=out)\n    actual = model.predict([x1, x2])\n    expected = np.array([[[2, 12]]])\n    assert (expected == pytest.approx(actual))", "ground_truth": "'Ones'", "quality_analysis": {"complexity_score": 12, "left_complexity": 11, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_606", "reponame": "stellargraph", "testpath": "tests/layer/test_graphsage.py", "testname": "test_graphsage.py", "classname": null, "funcname": "test_meanpool_agg_apply_hidden_bias", "imports": ["from tensorflow import keras", "from tensorflow.keras import initializers, regularizers", "import tensorflow as tf", "import numpy as np", "import pytest", "from stellargraph.mapper import GraphSAGENodeGenerator", "from stellargraph.layer.graphsage import GraphSAGE, MeanAggregator, MaxPoolingAggregator, MeanPoolingAggregator, AttentionalAggregator", "from ..test_utils.graphs import example_graph", "from .. import test_utils"], "code": "def test_meanpool_agg_apply_hidden_bias():\n    agg = MeanPoolingAggregator(2, bias=False, act='linear', kernel_initializer='ones', bias_initializer='ones')\n    assert (agg.get_config()['kernel_initializer']['class_name'] == 'Ones')\n    assert (agg.get_config()['bias_initializer']['class_name'] == 'Ones')\n    inp1 = keras.Input(shape=(1, 2))\n    inp2 = keras.Input(shape=(1, 2, 2))\n    out = agg([inp1, inp2])\n    assert (agg.weight_dims == [1, 1])\n    x1 = np.array([[[1, 1]]])\n    x2 = np.array([[[[2, 2], [3, 3]]]])\n    model = keras.Model(inputs=[inp1, inp2], outputs=out)\n    actual = model.predict([x1, x2])\n    expected = np.array([[[2, 12]]])\n    assert (expected == pytest.approx(actual))", "masked_code": "def test_meanpool_agg_apply_hidden_bias():\n    agg = MeanPoolingAggregator(2, bias=False, act='linear', kernel_initializer='ones', bias_initializer='ones')\n    assert (agg.get_config()['kernel_initializer']['class_name'] == 'Ones')\n    assert (agg.get_config()['bias_initializer']['class_name'] == '???')\n    inp1 = keras.Input(shape=(1, 2))\n    inp2 = keras.Input(shape=(1, 2, 2))\n    out = agg([inp1, inp2])\n    assert (agg.weight_dims == [1, 1])\n    x1 = np.array([[[1, 1]]])\n    x2 = np.array([[[[2, 2], [3, 3]]]])\n    model = keras.Model(inputs=[inp1, inp2], outputs=out)\n    actual = model.predict([x1, x2])\n    expected = np.array([[[2, 12]]])\n    assert (expected == pytest.approx(actual))", "ground_truth": "'Ones'", "quality_analysis": {"complexity_score": 12, "left_complexity": 11, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_607", "reponame": "stellargraph", "testpath": "tests/layer/test_graphsage.py", "testname": "test_graphsage.py", "classname": null, "funcname": "test_meanpool_agg_apply_hidden_bias", "imports": ["from tensorflow import keras", "from tensorflow.keras import initializers, regularizers", "import tensorflow as tf", "import numpy as np", "import pytest", "from stellargraph.mapper import GraphSAGENodeGenerator", "from stellargraph.layer.graphsage import GraphSAGE, MeanAggregator, MaxPoolingAggregator, MeanPoolingAggregator, AttentionalAggregator", "from ..test_utils.graphs import example_graph", "from .. import test_utils"], "code": "def test_meanpool_agg_apply_hidden_bias():\n    agg = MeanPoolingAggregator(2, bias=False, act='linear', kernel_initializer='ones', bias_initializer='ones')\n    assert (agg.get_config()['kernel_initializer']['class_name'] == 'Ones')\n    assert (agg.get_config()['bias_initializer']['class_name'] == 'Ones')\n    inp1 = keras.Input(shape=(1, 2))\n    inp2 = keras.Input(shape=(1, 2, 2))\n    out = agg([inp1, inp2])\n    assert (agg.weight_dims == [1, 1])\n    x1 = np.array([[[1, 1]]])\n    x2 = np.array([[[[2, 2], [3, 3]]]])\n    model = keras.Model(inputs=[inp1, inp2], outputs=out)\n    actual = model.predict([x1, x2])\n    expected = np.array([[[2, 12]]])\n    assert (expected == pytest.approx(actual))", "masked_code": "def test_meanpool_agg_apply_hidden_bias():\n    agg = MeanPoolingAggregator(2, bias=False, act='linear', kernel_initializer='ones', bias_initializer='ones')\n    assert (agg.get_config()['kernel_initializer']['class_name'] == 'Ones')\n    assert (agg.get_config()['bias_initializer']['class_name'] == 'Ones')\n    inp1 = keras.Input(shape=(1, 2))\n    inp2 = keras.Input(shape=(1, 2, 2))\n    out = agg([inp1, inp2])\n    assert (agg.weight_dims == '???')\n    x1 = np.array([[[1, 1]]])\n    x2 = np.array([[[[2, 2], [3, 3]]]])\n    model = keras.Model(inputs=[inp1, inp2], outputs=out)\n    actual = model.predict([x1, x2])\n    expected = np.array([[[2, 12]]])\n    assert (expected == pytest.approx(actual))", "ground_truth": "[1, 1]", "quality_analysis": {"complexity_score": 6, "left_complexity": 2, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_608", "reponame": "stellargraph", "testpath": "tests/layer/test_graphsage.py", "testname": "test_graphsage.py", "classname": null, "funcname": "test_meanpool_agg_apply_no_bias", "imports": ["from tensorflow import keras", "from tensorflow.keras import initializers, regularizers", "import tensorflow as tf", "import numpy as np", "import pytest", "from stellargraph.mapper import GraphSAGENodeGenerator", "from stellargraph.layer.graphsage import GraphSAGE, MeanAggregator, MaxPoolingAggregator, MeanPoolingAggregator, AttentionalAggregator", "from ..test_utils.graphs import example_graph", "from .. import test_utils"], "code": "def test_meanpool_agg_apply_no_bias():\n    agg = MeanPoolingAggregator(2, act='linear', kernel_initializer='ones')\n    assert (agg.get_config()['kernel_initializer']['class_name'] == 'Ones')\n    assert (agg.get_config()['bias_initializer']['class_name'] == 'Zeros')\n    inp1 = keras.Input(shape=(1, 2))\n    inp2 = keras.Input(shape=(1, 2, 2))\n    out = agg([inp1, inp2])\n    assert (agg.weight_dims == [1, 1])\n    x1 = np.array([[[1, 1]]])\n    x2 = np.array([[[[2, 2], [3, 3]]]])\n    model = keras.Model(inputs=[inp1, inp2], outputs=out)\n    actual = model.predict([x1, x2])\n    expected = np.array([[[2, 10]]])\n    assert (expected == pytest.approx(actual))", "masked_code": "def test_meanpool_agg_apply_no_bias():\n    agg = MeanPoolingAggregator(2, act='linear', kernel_initializer='ones')\n    assert (agg.get_config()['kernel_initializer']['class_name'] == '???')\n    assert (agg.get_config()['bias_initializer']['class_name'] == 'Zeros')\n    inp1 = keras.Input(shape=(1, 2))\n    inp2 = keras.Input(shape=(1, 2, 2))\n    out = agg([inp1, inp2])\n    assert (agg.weight_dims == [1, 1])\n    x1 = np.array([[[1, 1]]])\n    x2 = np.array([[[[2, 2], [3, 3]]]])\n    model = keras.Model(inputs=[inp1, inp2], outputs=out)\n    actual = model.predict([x1, x2])\n    expected = np.array([[[2, 10]]])\n    assert (expected == pytest.approx(actual))", "ground_truth": "'Ones'", "quality_analysis": {"complexity_score": 12, "left_complexity": 11, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_609", "reponame": "stellargraph", "testpath": "tests/layer/test_graphsage.py", "testname": "test_graphsage.py", "classname": null, "funcname": "test_meanpool_agg_apply_no_bias", "imports": ["from tensorflow import keras", "from tensorflow.keras import initializers, regularizers", "import tensorflow as tf", "import numpy as np", "import pytest", "from stellargraph.mapper import GraphSAGENodeGenerator", "from stellargraph.layer.graphsage import GraphSAGE, MeanAggregator, MaxPoolingAggregator, MeanPoolingAggregator, AttentionalAggregator", "from ..test_utils.graphs import example_graph", "from .. import test_utils"], "code": "def test_meanpool_agg_apply_no_bias():\n    agg = MeanPoolingAggregator(2, act='linear', kernel_initializer='ones')\n    assert (agg.get_config()['kernel_initializer']['class_name'] == 'Ones')\n    assert (agg.get_config()['bias_initializer']['class_name'] == 'Zeros')\n    inp1 = keras.Input(shape=(1, 2))\n    inp2 = keras.Input(shape=(1, 2, 2))\n    out = agg([inp1, inp2])\n    assert (agg.weight_dims == [1, 1])\n    x1 = np.array([[[1, 1]]])\n    x2 = np.array([[[[2, 2], [3, 3]]]])\n    model = keras.Model(inputs=[inp1, inp2], outputs=out)\n    actual = model.predict([x1, x2])\n    expected = np.array([[[2, 10]]])\n    assert (expected == pytest.approx(actual))", "masked_code": "def test_meanpool_agg_apply_no_bias():\n    agg = MeanPoolingAggregator(2, act='linear', kernel_initializer='ones')\n    assert (agg.get_config()['kernel_initializer']['class_name'] == 'Ones')\n    assert (agg.get_config()['bias_initializer']['class_name'] == '???')\n    inp1 = keras.Input(shape=(1, 2))\n    inp2 = keras.Input(shape=(1, 2, 2))\n    out = agg([inp1, inp2])\n    assert (agg.weight_dims == [1, 1])\n    x1 = np.array([[[1, 1]]])\n    x2 = np.array([[[[2, 2], [3, 3]]]])\n    model = keras.Model(inputs=[inp1, inp2], outputs=out)\n    actual = model.predict([x1, x2])\n    expected = np.array([[[2, 10]]])\n    assert (expected == pytest.approx(actual))", "ground_truth": "'Zeros'", "quality_analysis": {"complexity_score": 12, "left_complexity": 11, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_610", "reponame": "stellargraph", "testpath": "tests/layer/test_graphsage.py", "testname": "test_graphsage.py", "classname": null, "funcname": "test_meanpool_agg_apply_no_bias", "imports": ["from tensorflow import keras", "from tensorflow.keras import initializers, regularizers", "import tensorflow as tf", "import numpy as np", "import pytest", "from stellargraph.mapper import GraphSAGENodeGenerator", "from stellargraph.layer.graphsage import GraphSAGE, MeanAggregator, MaxPoolingAggregator, MeanPoolingAggregator, AttentionalAggregator", "from ..test_utils.graphs import example_graph", "from .. import test_utils"], "code": "def test_meanpool_agg_apply_no_bias():\n    agg = MeanPoolingAggregator(2, act='linear', kernel_initializer='ones')\n    assert (agg.get_config()['kernel_initializer']['class_name'] == 'Ones')\n    assert (agg.get_config()['bias_initializer']['class_name'] == 'Zeros')\n    inp1 = keras.Input(shape=(1, 2))\n    inp2 = keras.Input(shape=(1, 2, 2))\n    out = agg([inp1, inp2])\n    assert (agg.weight_dims == [1, 1])\n    x1 = np.array([[[1, 1]]])\n    x2 = np.array([[[[2, 2], [3, 3]]]])\n    model = keras.Model(inputs=[inp1, inp2], outputs=out)\n    actual = model.predict([x1, x2])\n    expected = np.array([[[2, 10]]])\n    assert (expected == pytest.approx(actual))", "masked_code": "def test_meanpool_agg_apply_no_bias():\n    agg = MeanPoolingAggregator(2, act='linear', kernel_initializer='ones')\n    assert (agg.get_config()['kernel_initializer']['class_name'] == 'Ones')\n    assert (agg.get_config()['bias_initializer']['class_name'] == 'Zeros')\n    inp1 = keras.Input(shape=(1, 2))\n    inp2 = keras.Input(shape=(1, 2, 2))\n    out = agg([inp1, inp2])\n    assert (agg.weight_dims == '???')\n    x1 = np.array([[[1, 1]]])\n    x2 = np.array([[[[2, 2], [3, 3]]]])\n    model = keras.Model(inputs=[inp1, inp2], outputs=out)\n    actual = model.predict([x1, x2])\n    expected = np.array([[[2, 10]]])\n    assert (expected == pytest.approx(actual))", "ground_truth": "[1, 1]", "quality_analysis": {"complexity_score": 6, "left_complexity": 2, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_611", "reponame": "stellargraph", "testpath": "tests/layer/test_graphsage.py", "testname": "test_graphsage.py", "classname": null, "funcname": "test_meanpool_agg_zero_neighbours", "imports": ["from tensorflow import keras", "from tensorflow.keras import initializers, regularizers", "import tensorflow as tf", "import numpy as np", "import pytest", "from stellargraph.mapper import GraphSAGENodeGenerator", "from stellargraph.layer.graphsage import GraphSAGE, MeanAggregator, MaxPoolingAggregator, MeanPoolingAggregator, AttentionalAggregator", "from ..test_utils.graphs import example_graph", "from .. import test_utils"], "code": "def test_meanpool_agg_zero_neighbours():\n    agg = MeanPoolingAggregator(4, bias=False, act='linear', kernel_initializer='ones')\n    inp1 = keras.Input(shape=(1, 2))\n    inp2 = keras.Input(shape=(1, 0, 2))\n    out = agg([inp1, inp2])\n    assert (agg.weight_dims == [4, 0])\n    model = keras.Model(inputs=[inp1, inp2], outputs=out)\n    x1 = np.array([[[1, 1]]])\n    x2 = np.zeros((1, 1, 0, 2))\n    actual = model.predict([x1, x2])\n    expected = np.array([[[2, 2, 2, 2]]])\n    assert (expected == pytest.approx(actual))", "masked_code": "def test_meanpool_agg_zero_neighbours():\n    agg = MeanPoolingAggregator(4, bias=False, act='linear', kernel_initializer='ones')\n    inp1 = keras.Input(shape=(1, 2))\n    inp2 = keras.Input(shape=(1, 0, 2))\n    out = agg([inp1, inp2])\n    assert (agg.weight_dims == '???')\n    model = keras.Model(inputs=[inp1, inp2], outputs=out)\n    x1 = np.array([[[1, 1]]])\n    x2 = np.zeros((1, 1, 0, 2))\n    actual = model.predict([x1, x2])\n    expected = np.array([[[2, 2, 2, 2]]])\n    assert (expected == pytest.approx(actual))", "ground_truth": "[4, 0]", "quality_analysis": {"complexity_score": 6, "left_complexity": 2, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_612", "reponame": "stellargraph", "testpath": "tests/layer/test_graphsage.py", "testname": "test_graphsage.py", "classname": null, "funcname": "test_attn_agg_constructor", "imports": ["from tensorflow import keras", "from tensorflow.keras import initializers, regularizers", "import tensorflow as tf", "import numpy as np", "import pytest", "from stellargraph.mapper import GraphSAGENodeGenerator", "from stellargraph.layer.graphsage import GraphSAGE, MeanAggregator, MaxPoolingAggregator, MeanPoolingAggregator, AttentionalAggregator", "from ..test_utils.graphs import example_graph", "from .. import test_utils"], "code": "def test_attn_agg_constructor():\n    agg = AttentionalAggregator(2, bias=False)\n    assert (agg.output_dim == 2)\n    assert (not agg.has_bias)\n    assert (agg.act.__name__ == 'relu')\n    config = agg.get_config()\n    assert (config['output_dim'] == 2)\n    assert (config['bias'] is False)\n    assert (config['act'] == 'relu')", "masked_code": "def test_attn_agg_constructor():\n    agg = AttentionalAggregator(2, bias=False)\n    assert (agg.output_dim == 2)\n    assert (not agg.has_bias)\n    assert (agg.act.__name__ == '???')\n    config = agg.get_config()\n    assert (config['output_dim'] == 2)\n    assert (config['bias'] is False)\n    assert (config['act'] == 'relu')", "ground_truth": "'relu'", "quality_analysis": {"complexity_score": 3, "left_complexity": 2, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_613", "reponame": "stellargraph", "testpath": "tests/layer/test_graphsage.py", "testname": "test_graphsage.py", "classname": null, "funcname": "test_attn_agg_constructor", "imports": ["from tensorflow import keras", "from tensorflow.keras import initializers, regularizers", "import tensorflow as tf", "import numpy as np", "import pytest", "from stellargraph.mapper import GraphSAGENodeGenerator", "from stellargraph.layer.graphsage import GraphSAGE, MeanAggregator, MaxPoolingAggregator, MeanPoolingAggregator, AttentionalAggregator", "from ..test_utils.graphs import example_graph", "from .. import test_utils"], "code": "def test_attn_agg_constructor():\n    agg = AttentionalAggregator(2, bias=False)\n    assert (agg.output_dim == 2)\n    assert (not agg.has_bias)\n    assert (agg.act.__name__ == 'relu')\n    config = agg.get_config()\n    assert (config['output_dim'] == 2)\n    assert (config['bias'] is False)\n    assert (config['act'] == 'relu')", "masked_code": "def test_attn_agg_constructor():\n    agg = AttentionalAggregator(2, bias=False)\n    assert (agg.output_dim == 2)\n    assert (not agg.has_bias)\n    assert (agg.act.__name__ == 'relu')\n    config = agg.get_config()\n    assert (config['output_dim'] == 2)\n    assert (config['bias'] is False)\n    assert (config['act'] == '???')", "ground_truth": "'relu'", "quality_analysis": {"complexity_score": 6, "left_complexity": 5, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_614", "reponame": "stellargraph", "testpath": "tests/layer/test_graphsage.py", "testname": "test_graphsage.py", "classname": null, "funcname": "test_attn_agg_constructor_1", "imports": ["from tensorflow import keras", "from tensorflow.keras import initializers, regularizers", "import tensorflow as tf", "import numpy as np", "import pytest", "from stellargraph.mapper import GraphSAGENodeGenerator", "from stellargraph.layer.graphsage import GraphSAGE, MeanAggregator, MaxPoolingAggregator, MeanPoolingAggregator, AttentionalAggregator", "from ..test_utils.graphs import example_graph", "from .. import test_utils"], "code": "def test_attn_agg_constructor_1():\n    agg = AttentionalAggregator(output_dim=4, bias=True, act=(lambda x: (x + 1)))\n    assert (agg.output_dim == 4)\n    assert agg.has_bias\n    assert (agg.act(2) == 3)", "masked_code": "def test_attn_agg_constructor_1():\n    agg = AttentionalAggregator(output_dim=4, bias=True, act=(lambda x: (x + 1)))\n    assert (agg.output_dim == '???')\n    assert agg.has_bias\n    assert (agg.act(2) == 3)", "ground_truth": "4", "quality_analysis": {"complexity_score": 3, "left_complexity": 2, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_615", "reponame": "stellargraph", "testpath": "tests/layer/test_graphsage.py", "testname": "test_graphsage.py", "classname": null, "funcname": "test_attn_agg_constructor_1", "imports": ["from tensorflow import keras", "from tensorflow.keras import initializers, regularizers", "import tensorflow as tf", "import numpy as np", "import pytest", "from stellargraph.mapper import GraphSAGENodeGenerator", "from stellargraph.layer.graphsage import GraphSAGE, MeanAggregator, MaxPoolingAggregator, MeanPoolingAggregator, AttentionalAggregator", "from ..test_utils.graphs import example_graph", "from .. import test_utils"], "code": "def test_attn_agg_constructor_1():\n    agg = AttentionalAggregator(output_dim=4, bias=True, act=(lambda x: (x + 1)))\n    assert (agg.output_dim == 4)\n    assert agg.has_bias\n    assert (agg.act(2) == 3)", "masked_code": "def test_attn_agg_constructor_1():\n    agg = AttentionalAggregator(output_dim=4, bias=True, act=(lambda x: (x + 1)))\n    assert (agg.output_dim == 4)\n    assert agg.has_bias\n    assert (agg.act(2) == '???')", "ground_truth": "3", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_616", "reponame": "stellargraph", "testpath": "tests/layer/test_graphsage.py", "testname": "test_graphsage.py", "classname": null, "funcname": "test_attn_agg_apply", "imports": ["from tensorflow import keras", "from tensorflow.keras import initializers, regularizers", "import tensorflow as tf", "import numpy as np", "import pytest", "from stellargraph.mapper import GraphSAGENodeGenerator", "from stellargraph.layer.graphsage import GraphSAGE, MeanAggregator, MaxPoolingAggregator, MeanPoolingAggregator, AttentionalAggregator", "from ..test_utils.graphs import example_graph", "from .. import test_utils"], "code": "def test_attn_agg_apply():\n    agg = AttentionalAggregator(2, bias=False, act='linear', kernel_initializer='ones')\n    agg.attn_act = keras.activations.get('linear')\n    inp1 = keras.Input(shape=(1, 2))\n    inp2 = keras.Input(shape=(1, 2, 2))\n    out = agg([inp1, inp2])\n    assert (agg.weight_dims == [0, 2])\n    x1 = np.array([[[1, 1]]])\n    x2 = np.array([[[[2, 2], [3, 3]]]])\n    model = keras.Model(inputs=[inp1, inp2], outputs=out)\n    actual = model.predict([x1, x2])\n    expected = np.array([[[5.963, 5.963]]])\n    assert (expected == pytest.approx(actual, rel=0.0001))", "masked_code": "def test_attn_agg_apply():\n    agg = AttentionalAggregator(2, bias=False, act='linear', kernel_initializer='ones')\n    agg.attn_act = keras.activations.get('linear')\n    inp1 = keras.Input(shape=(1, 2))\n    inp2 = keras.Input(shape=(1, 2, 2))\n    out = agg([inp1, inp2])\n    assert (agg.weight_dims == '???')\n    x1 = np.array([[[1, 1]]])\n    x2 = np.array([[[[2, 2], [3, 3]]]])\n    model = keras.Model(inputs=[inp1, inp2], outputs=out)\n    actual = model.predict([x1, x2])\n    expected = np.array([[[5.963, 5.963]]])\n    assert (expected == pytest.approx(actual, rel=0.0001))", "ground_truth": "[0, 2]", "quality_analysis": {"complexity_score": 6, "left_complexity": 2, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_617", "reponame": "stellargraph", "testpath": "tests/layer/test_graphsage.py", "testname": "test_graphsage.py", "classname": null, "funcname": "test_graphsage_constructor", "imports": ["from tensorflow import keras", "from tensorflow.keras import initializers, regularizers", "import tensorflow as tf", "import numpy as np", "import pytest", "from stellargraph.mapper import GraphSAGENodeGenerator", "from stellargraph.layer.graphsage import GraphSAGE, MeanAggregator, MaxPoolingAggregator, MeanPoolingAggregator, AttentionalAggregator", "from ..test_utils.graphs import example_graph", "from .. import test_utils"], "code": "def test_graphsage_constructor():\n    gs = GraphSAGE(layer_sizes=[4], n_samples=[2], input_dim=2, normalize='l2', multiplicity=1)\n    assert (gs.dims == [2, 4])\n    assert (gs.n_samples == [2])\n    assert (gs.max_hops == 1)\n    assert gs.bias\n    assert (len(gs._aggs) == 1)\n    with pytest.raises(ValueError):\n        GraphSAGE(layer_sizes=[4], n_samples=[2], input_dim=2, normalize=(lambda x: x), multiplicity=1)\n    with pytest.raises(ValueError):\n        GraphSAGE(layer_sizes=[4], n_samples=[2], input_dim=2, normalize='unknown', multiplicity=1)\n    with pytest.raises(ValueError):\n        GraphSAGE(layer_sizes=[4])\n    G = example_graph(feature_size=3)\n    gen = GraphSAGENodeGenerator(G, batch_size=2, num_samples=[2, 2])\n    gs = GraphSAGE(layer_sizes=[4, 8], generator=gen, bias=True)\n    t_gen = gen.flow([1, 2])\n    with pytest.raises(TypeError):\n        gs = GraphSAGE(layer_sizes=[4, 8], generator=t_gen, bias=True)\n    assert (gs.dims == [3, 4, 8])\n    assert (gs.n_samples == [2, 2])\n    assert (gs.max_hops == 2)\n    assert gs.bias\n    assert (len(gs._aggs) == 2)", "masked_code": "def test_graphsage_constructor():\n    gs = GraphSAGE(layer_sizes=[4], n_samples=[2], input_dim=2, normalize='l2', multiplicity=1)\n    assert (gs.dims == '???')\n    assert (gs.n_samples == [2])\n    assert (gs.max_hops == 1)\n    assert gs.bias\n    assert (len(gs._aggs) == 1)\n    with pytest.raises(ValueError):\n        GraphSAGE(layer_sizes=[4], n_samples=[2], input_dim=2, normalize=(lambda x: x), multiplicity=1)\n    with pytest.raises(ValueError):\n        GraphSAGE(layer_sizes=[4], n_samples=[2], input_dim=2, normalize='unknown', multiplicity=1)\n    with pytest.raises(ValueError):\n        GraphSAGE(layer_sizes=[4])\n    G = example_graph(feature_size=3)\n    gen = GraphSAGENodeGenerator(G, batch_size=2, num_samples=[2, 2])\n    gs = GraphSAGE(layer_sizes=[4, 8], generator=gen, bias=True)\n    t_gen = gen.flow([1, 2])\n    with pytest.raises(TypeError):\n        gs = GraphSAGE(layer_sizes=[4, 8], generator=t_gen, bias=True)\n    assert (gs.dims == [3, 4, 8])\n    assert (gs.n_samples == [2, 2])\n    assert (gs.max_hops == 2)\n    assert gs.bias\n    assert (len(gs._aggs) == 2)", "ground_truth": "[2, 4]", "quality_analysis": {"complexity_score": 6, "left_complexity": 2, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_618", "reponame": "stellargraph", "testpath": "tests/layer/test_graphsage.py", "testname": "test_graphsage.py", "classname": null, "funcname": "test_graphsage_constructor", "imports": ["from tensorflow import keras", "from tensorflow.keras import initializers, regularizers", "import tensorflow as tf", "import numpy as np", "import pytest", "from stellargraph.mapper import GraphSAGENodeGenerator", "from stellargraph.layer.graphsage import GraphSAGE, MeanAggregator, MaxPoolingAggregator, MeanPoolingAggregator, AttentionalAggregator", "from ..test_utils.graphs import example_graph", "from .. import test_utils"], "code": "def test_graphsage_constructor():\n    gs = GraphSAGE(layer_sizes=[4], n_samples=[2], input_dim=2, normalize='l2', multiplicity=1)\n    assert (gs.dims == [2, 4])\n    assert (gs.n_samples == [2])\n    assert (gs.max_hops == 1)\n    assert gs.bias\n    assert (len(gs._aggs) == 1)\n    with pytest.raises(ValueError):\n        GraphSAGE(layer_sizes=[4], n_samples=[2], input_dim=2, normalize=(lambda x: x), multiplicity=1)\n    with pytest.raises(ValueError):\n        GraphSAGE(layer_sizes=[4], n_samples=[2], input_dim=2, normalize='unknown', multiplicity=1)\n    with pytest.raises(ValueError):\n        GraphSAGE(layer_sizes=[4])\n    G = example_graph(feature_size=3)\n    gen = GraphSAGENodeGenerator(G, batch_size=2, num_samples=[2, 2])\n    gs = GraphSAGE(layer_sizes=[4, 8], generator=gen, bias=True)\n    t_gen = gen.flow([1, 2])\n    with pytest.raises(TypeError):\n        gs = GraphSAGE(layer_sizes=[4, 8], generator=t_gen, bias=True)\n    assert (gs.dims == [3, 4, 8])\n    assert (gs.n_samples == [2, 2])\n    assert (gs.max_hops == 2)\n    assert gs.bias\n    assert (len(gs._aggs) == 2)", "masked_code": "def test_graphsage_constructor():\n    gs = GraphSAGE(layer_sizes=[4], n_samples=[2], input_dim=2, normalize='l2', multiplicity=1)\n    assert (gs.dims == [2, 4])\n    assert (gs.n_samples == '???')\n    assert (gs.max_hops == 1)\n    assert gs.bias\n    assert (len(gs._aggs) == 1)\n    with pytest.raises(ValueError):\n        GraphSAGE(layer_sizes=[4], n_samples=[2], input_dim=2, normalize=(lambda x: x), multiplicity=1)\n    with pytest.raises(ValueError):\n        GraphSAGE(layer_sizes=[4], n_samples=[2], input_dim=2, normalize='unknown', multiplicity=1)\n    with pytest.raises(ValueError):\n        GraphSAGE(layer_sizes=[4])\n    G = example_graph(feature_size=3)\n    gen = GraphSAGENodeGenerator(G, batch_size=2, num_samples=[2, 2])\n    gs = GraphSAGE(layer_sizes=[4, 8], generator=gen, bias=True)\n    t_gen = gen.flow([1, 2])\n    with pytest.raises(TypeError):\n        gs = GraphSAGE(layer_sizes=[4, 8], generator=t_gen, bias=True)\n    assert (gs.dims == [3, 4, 8])\n    assert (gs.n_samples == [2, 2])\n    assert (gs.max_hops == 2)\n    assert gs.bias\n    assert (len(gs._aggs) == 2)", "ground_truth": "[2]", "quality_analysis": {"complexity_score": 5, "left_complexity": 2, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_619", "reponame": "stellargraph", "testpath": "tests/layer/test_graphsage.py", "testname": "test_graphsage.py", "classname": null, "funcname": "test_graphsage_constructor", "imports": ["from tensorflow import keras", "from tensorflow.keras import initializers, regularizers", "import tensorflow as tf", "import numpy as np", "import pytest", "from stellargraph.mapper import GraphSAGENodeGenerator", "from stellargraph.layer.graphsage import GraphSAGE, MeanAggregator, MaxPoolingAggregator, MeanPoolingAggregator, AttentionalAggregator", "from ..test_utils.graphs import example_graph", "from .. import test_utils"], "code": "def test_graphsage_constructor():\n    gs = GraphSAGE(layer_sizes=[4], n_samples=[2], input_dim=2, normalize='l2', multiplicity=1)\n    assert (gs.dims == [2, 4])\n    assert (gs.n_samples == [2])\n    assert (gs.max_hops == 1)\n    assert gs.bias\n    assert (len(gs._aggs) == 1)\n    with pytest.raises(ValueError):\n        GraphSAGE(layer_sizes=[4], n_samples=[2], input_dim=2, normalize=(lambda x: x), multiplicity=1)\n    with pytest.raises(ValueError):\n        GraphSAGE(layer_sizes=[4], n_samples=[2], input_dim=2, normalize='unknown', multiplicity=1)\n    with pytest.raises(ValueError):\n        GraphSAGE(layer_sizes=[4])\n    G = example_graph(feature_size=3)\n    gen = GraphSAGENodeGenerator(G, batch_size=2, num_samples=[2, 2])\n    gs = GraphSAGE(layer_sizes=[4, 8], generator=gen, bias=True)\n    t_gen = gen.flow([1, 2])\n    with pytest.raises(TypeError):\n        gs = GraphSAGE(layer_sizes=[4, 8], generator=t_gen, bias=True)\n    assert (gs.dims == [3, 4, 8])\n    assert (gs.n_samples == [2, 2])\n    assert (gs.max_hops == 2)\n    assert gs.bias\n    assert (len(gs._aggs) == 2)", "masked_code": "def test_graphsage_constructor():\n    gs = GraphSAGE(layer_sizes=[4], n_samples=[2], input_dim=2, normalize='l2', multiplicity=1)\n    assert (gs.dims == [2, 4])\n    assert (gs.n_samples == [2])\n    assert (gs.max_hops == 1)\n    assert gs.bias\n    assert (len(gs._aggs) == 1)\n    with pytest.raises(ValueError):\n        GraphSAGE(layer_sizes=[4], n_samples=[2], input_dim=2, normalize=(lambda x: x), multiplicity=1)\n    with pytest.raises(ValueError):\n        GraphSAGE(layer_sizes=[4], n_samples=[2], input_dim=2, normalize='unknown', multiplicity=1)\n    with pytest.raises(ValueError):\n        GraphSAGE(layer_sizes=[4])\n    G = example_graph(feature_size=3)\n    gen = GraphSAGENodeGenerator(G, batch_size=2, num_samples=[2, 2])\n    gs = GraphSAGE(layer_sizes=[4, 8], generator=gen, bias=True)\n    t_gen = gen.flow([1, 2])\n    with pytest.raises(TypeError):\n        gs = GraphSAGE(layer_sizes=[4, 8], generator=t_gen, bias=True)\n    assert (gs.dims == '???')\n    assert (gs.n_samples == [2, 2])\n    assert (gs.max_hops == 2)\n    assert gs.bias\n    assert (len(gs._aggs) == 2)", "ground_truth": "[3, 4, 8]", "quality_analysis": {"complexity_score": 7, "left_complexity": 2, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_620", "reponame": "stellargraph", "testpath": "tests/layer/test_graphsage.py", "testname": "test_graphsage.py", "classname": null, "funcname": "test_graphsage_constructor", "imports": ["from tensorflow import keras", "from tensorflow.keras import initializers, regularizers", "import tensorflow as tf", "import numpy as np", "import pytest", "from stellargraph.mapper import GraphSAGENodeGenerator", "from stellargraph.layer.graphsage import GraphSAGE, MeanAggregator, MaxPoolingAggregator, MeanPoolingAggregator, AttentionalAggregator", "from ..test_utils.graphs import example_graph", "from .. import test_utils"], "code": "def test_graphsage_constructor():\n    gs = GraphSAGE(layer_sizes=[4], n_samples=[2], input_dim=2, normalize='l2', multiplicity=1)\n    assert (gs.dims == [2, 4])\n    assert (gs.n_samples == [2])\n    assert (gs.max_hops == 1)\n    assert gs.bias\n    assert (len(gs._aggs) == 1)\n    with pytest.raises(ValueError):\n        GraphSAGE(layer_sizes=[4], n_samples=[2], input_dim=2, normalize=(lambda x: x), multiplicity=1)\n    with pytest.raises(ValueError):\n        GraphSAGE(layer_sizes=[4], n_samples=[2], input_dim=2, normalize='unknown', multiplicity=1)\n    with pytest.raises(ValueError):\n        GraphSAGE(layer_sizes=[4])\n    G = example_graph(feature_size=3)\n    gen = GraphSAGENodeGenerator(G, batch_size=2, num_samples=[2, 2])\n    gs = GraphSAGE(layer_sizes=[4, 8], generator=gen, bias=True)\n    t_gen = gen.flow([1, 2])\n    with pytest.raises(TypeError):\n        gs = GraphSAGE(layer_sizes=[4, 8], generator=t_gen, bias=True)\n    assert (gs.dims == [3, 4, 8])\n    assert (gs.n_samples == [2, 2])\n    assert (gs.max_hops == 2)\n    assert gs.bias\n    assert (len(gs._aggs) == 2)", "masked_code": "def test_graphsage_constructor():\n    gs = GraphSAGE(layer_sizes=[4], n_samples=[2], input_dim=2, normalize='l2', multiplicity=1)\n    assert (gs.dims == [2, 4])\n    assert (gs.n_samples == [2])\n    assert (gs.max_hops == 1)\n    assert gs.bias\n    assert (len(gs._aggs) == 1)\n    with pytest.raises(ValueError):\n        GraphSAGE(layer_sizes=[4], n_samples=[2], input_dim=2, normalize=(lambda x: x), multiplicity=1)\n    with pytest.raises(ValueError):\n        GraphSAGE(layer_sizes=[4], n_samples=[2], input_dim=2, normalize='unknown', multiplicity=1)\n    with pytest.raises(ValueError):\n        GraphSAGE(layer_sizes=[4])\n    G = example_graph(feature_size=3)\n    gen = GraphSAGENodeGenerator(G, batch_size=2, num_samples=[2, 2])\n    gs = GraphSAGE(layer_sizes=[4, 8], generator=gen, bias=True)\n    t_gen = gen.flow([1, 2])\n    with pytest.raises(TypeError):\n        gs = GraphSAGE(layer_sizes=[4, 8], generator=t_gen, bias=True)\n    assert (gs.dims == [3, 4, 8])\n    assert (gs.n_samples == '???')\n    assert (gs.max_hops == 2)\n    assert gs.bias\n    assert (len(gs._aggs) == 2)", "ground_truth": "[2, 2]", "quality_analysis": {"complexity_score": 6, "left_complexity": 2, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_621", "reponame": "stellargraph", "testpath": "tests/layer/test_graphsage.py", "testname": "test_graphsage.py", "classname": null, "funcname": "test_graphsage_constructor_passing_aggregator", "imports": ["from tensorflow import keras", "from tensorflow.keras import initializers, regularizers", "import tensorflow as tf", "import numpy as np", "import pytest", "from stellargraph.mapper import GraphSAGENodeGenerator", "from stellargraph.layer.graphsage import GraphSAGE, MeanAggregator, MaxPoolingAggregator, MeanPoolingAggregator, AttentionalAggregator", "from ..test_utils.graphs import example_graph", "from .. import test_utils"], "code": "def test_graphsage_constructor_passing_aggregator():\n    gs = GraphSAGE(layer_sizes=[4], n_samples=[2], input_dim=2, multiplicity=1, aggregator=MeanAggregator)\n    assert (gs.dims == [2, 4])\n    assert (gs.n_samples == [2])\n    assert (gs.max_hops == 1)\n    assert gs.bias\n    assert (len(gs._aggs) == 1)\n    with pytest.raises(TypeError):\n        GraphSAGE(layer_sizes=[4], n_samples=[2], input_dim=2, multiplicity=1, aggregator=1)", "masked_code": "def test_graphsage_constructor_passing_aggregator():\n    gs = GraphSAGE(layer_sizes=[4], n_samples=[2], input_dim=2, multiplicity=1, aggregator=MeanAggregator)\n    assert (gs.dims == '???')\n    assert (gs.n_samples == [2])\n    assert (gs.max_hops == 1)\n    assert gs.bias\n    assert (len(gs._aggs) == 1)\n    with pytest.raises(TypeError):\n        GraphSAGE(layer_sizes=[4], n_samples=[2], input_dim=2, multiplicity=1, aggregator=1)", "ground_truth": "[2, 4]", "quality_analysis": {"complexity_score": 6, "left_complexity": 2, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_622", "reponame": "stellargraph", "testpath": "tests/layer/test_graphsage.py", "testname": "test_graphsage.py", "classname": null, "funcname": "test_graphsage_constructor_passing_aggregator", "imports": ["from tensorflow import keras", "from tensorflow.keras import initializers, regularizers", "import tensorflow as tf", "import numpy as np", "import pytest", "from stellargraph.mapper import GraphSAGENodeGenerator", "from stellargraph.layer.graphsage import GraphSAGE, MeanAggregator, MaxPoolingAggregator, MeanPoolingAggregator, AttentionalAggregator", "from ..test_utils.graphs import example_graph", "from .. import test_utils"], "code": "def test_graphsage_constructor_passing_aggregator():\n    gs = GraphSAGE(layer_sizes=[4], n_samples=[2], input_dim=2, multiplicity=1, aggregator=MeanAggregator)\n    assert (gs.dims == [2, 4])\n    assert (gs.n_samples == [2])\n    assert (gs.max_hops == 1)\n    assert gs.bias\n    assert (len(gs._aggs) == 1)\n    with pytest.raises(TypeError):\n        GraphSAGE(layer_sizes=[4], n_samples=[2], input_dim=2, multiplicity=1, aggregator=1)", "masked_code": "def test_graphsage_constructor_passing_aggregator():\n    gs = GraphSAGE(layer_sizes=[4], n_samples=[2], input_dim=2, multiplicity=1, aggregator=MeanAggregator)\n    assert (gs.dims == [2, 4])\n    assert (gs.n_samples == '???')\n    assert (gs.max_hops == 1)\n    assert gs.bias\n    assert (len(gs._aggs) == 1)\n    with pytest.raises(TypeError):\n        GraphSAGE(layer_sizes=[4], n_samples=[2], input_dim=2, multiplicity=1, aggregator=1)", "ground_truth": "[2]", "quality_analysis": {"complexity_score": 5, "left_complexity": 2, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_623", "reponame": "stellargraph", "testpath": "tests/layer/test_graphsage.py", "testname": "test_graphsage.py", "classname": null, "funcname": "test_graphsage_constructor_1", "imports": ["from tensorflow import keras", "from tensorflow.keras import initializers, regularizers", "import tensorflow as tf", "import numpy as np", "import pytest", "from stellargraph.mapper import GraphSAGENodeGenerator", "from stellargraph.layer.graphsage import GraphSAGE, MeanAggregator, MaxPoolingAggregator, MeanPoolingAggregator, AttentionalAggregator", "from ..test_utils.graphs import example_graph", "from .. import test_utils"], "code": "def test_graphsage_constructor_1():\n    gs = GraphSAGE(layer_sizes=[4, 6, 8], n_samples=[2, 4, 6], input_dim=2, multiplicity=1, bias=True, dropout=0.5)\n    assert (gs.dims == [2, 4, 6, 8])\n    assert (gs.n_samples == [2, 4, 6])\n    assert (gs.max_hops == 3)\n    assert gs.bias\n    assert (len(gs._aggs) == 3)", "masked_code": "def test_graphsage_constructor_1():\n    gs = GraphSAGE(layer_sizes=[4, 6, 8], n_samples=[2, 4, 6], input_dim=2, multiplicity=1, bias=True, dropout=0.5)\n    assert (gs.dims == '???')\n    assert (gs.n_samples == [2, 4, 6])\n    assert (gs.max_hops == 3)\n    assert gs.bias\n    assert (len(gs._aggs) == 3)", "ground_truth": "[2, 4, 6, 8]", "quality_analysis": {"complexity_score": 8, "left_complexity": 2, "right_complexity": 6, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_624", "reponame": "stellargraph", "testpath": "tests/layer/test_graphsage.py", "testname": "test_graphsage.py", "classname": null, "funcname": "test_graphsage_constructor_1", "imports": ["from tensorflow import keras", "from tensorflow.keras import initializers, regularizers", "import tensorflow as tf", "import numpy as np", "import pytest", "from stellargraph.mapper import GraphSAGENodeGenerator", "from stellargraph.layer.graphsage import GraphSAGE, MeanAggregator, MaxPoolingAggregator, MeanPoolingAggregator, AttentionalAggregator", "from ..test_utils.graphs import example_graph", "from .. import test_utils"], "code": "def test_graphsage_constructor_1():\n    gs = GraphSAGE(layer_sizes=[4, 6, 8], n_samples=[2, 4, 6], input_dim=2, multiplicity=1, bias=True, dropout=0.5)\n    assert (gs.dims == [2, 4, 6, 8])\n    assert (gs.n_samples == [2, 4, 6])\n    assert (gs.max_hops == 3)\n    assert gs.bias\n    assert (len(gs._aggs) == 3)", "masked_code": "def test_graphsage_constructor_1():\n    gs = GraphSAGE(layer_sizes=[4, 6, 8], n_samples=[2, 4, 6], input_dim=2, multiplicity=1, bias=True, dropout=0.5)\n    assert (gs.dims == [2, 4, 6, 8])\n    assert (gs.n_samples == '???')\n    assert (gs.max_hops == 3)\n    assert gs.bias\n    assert (len(gs._aggs) == 3)", "ground_truth": "[2, 4, 6]", "quality_analysis": {"complexity_score": 7, "left_complexity": 2, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_625", "reponame": "stellargraph", "testpath": "tests/layer/test_graphsage.py", "testname": "test_graphsage.py", "classname": null, "funcname": "test_graphsage_constructor_1", "imports": ["from tensorflow import keras", "from tensorflow.keras import initializers, regularizers", "import tensorflow as tf", "import numpy as np", "import pytest", "from stellargraph.mapper import GraphSAGENodeGenerator", "from stellargraph.layer.graphsage import GraphSAGE, MeanAggregator, MaxPoolingAggregator, MeanPoolingAggregator, AttentionalAggregator", "from ..test_utils.graphs import example_graph", "from .. import test_utils"], "code": "def test_graphsage_constructor_1():\n    gs = GraphSAGE(layer_sizes=[4, 6, 8], n_samples=[2, 4, 6], input_dim=2, multiplicity=1, bias=True, dropout=0.5)\n    assert (gs.dims == [2, 4, 6, 8])\n    assert (gs.n_samples == [2, 4, 6])\n    assert (gs.max_hops == 3)\n    assert gs.bias\n    assert (len(gs._aggs) == 3)", "masked_code": "def test_graphsage_constructor_1():\n    gs = GraphSAGE(layer_sizes=[4, 6, 8], n_samples=[2, 4, 6], input_dim=2, multiplicity=1, bias=True, dropout=0.5)\n    assert (gs.dims == [2, 4, 6, 8])\n    assert (gs.n_samples == [2, 4, 6])\n    assert (gs.max_hops == '???')\n    assert gs.bias\n    assert (len(gs._aggs) == 3)", "ground_truth": "3", "quality_analysis": {"complexity_score": 3, "left_complexity": 2, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_626", "reponame": "stellargraph", "testpath": "tests/layer/test_graphsage.py", "testname": "test_graphsage.py", "classname": null, "funcname": "test_graphsage_constructor_1", "imports": ["from tensorflow import keras", "from tensorflow.keras import initializers, regularizers", "import tensorflow as tf", "import numpy as np", "import pytest", "from stellargraph.mapper import GraphSAGENodeGenerator", "from stellargraph.layer.graphsage import GraphSAGE, MeanAggregator, MaxPoolingAggregator, MeanPoolingAggregator, AttentionalAggregator", "from ..test_utils.graphs import example_graph", "from .. import test_utils"], "code": "def test_graphsage_constructor_1():\n    gs = GraphSAGE(layer_sizes=[4, 6, 8], n_samples=[2, 4, 6], input_dim=2, multiplicity=1, bias=True, dropout=0.5)\n    assert (gs.dims == [2, 4, 6, 8])\n    assert (gs.n_samples == [2, 4, 6])\n    assert (gs.max_hops == 3)\n    assert gs.bias\n    assert (len(gs._aggs) == 3)", "masked_code": "def test_graphsage_constructor_1():\n    gs = GraphSAGE(layer_sizes=[4, 6, 8], n_samples=[2, 4, 6], input_dim=2, multiplicity=1, bias=True, dropout=0.5)\n    assert (gs.dims == [2, 4, 6, 8])\n    assert (gs.n_samples == [2, 4, 6])\n    assert (gs.max_hops == 3)\n    assert gs.bias\n    assert (len(gs._aggs) == '???')", "ground_truth": "3", "quality_analysis": {"complexity_score": 6, "left_complexity": 5, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_627", "reponame": "stellargraph", "testpath": "tests/layer/test_graphsage.py", "testname": "test_graphsage.py", "classname": null, "funcname": "test_graphsage_apply_1", "imports": ["from tensorflow import keras", "from tensorflow.keras import initializers, regularizers", "import tensorflow as tf", "import numpy as np", "import pytest", "from stellargraph.mapper import GraphSAGENodeGenerator", "from stellargraph.layer.graphsage import GraphSAGE, MeanAggregator, MaxPoolingAggregator, MeanPoolingAggregator, AttentionalAggregator", "from ..test_utils.graphs import example_graph", "from .. import test_utils"], "code": "def test_graphsage_apply_1():\n    gs = GraphSAGE(layer_sizes=[2, 2, 2], n_samples=[2, 2, 2], bias=False, input_dim=2, multiplicity=1, normalize=None, kernel_initializer='ones')\n    inp = [keras.Input(shape=(i, 2)) for i in [1, 2, 4, 8]]\n    out = gs(inp)\n    model = keras.Model(inputs=inp, outputs=out)\n    x = [np.array([[[1, 1]]]), np.array([[[2, 2], [2, 2]]]), np.array([[[3, 3], [3, 3], [3, 3], [3, 3]]]), np.array([[[4, 4], [4, 4], [4, 4], [4, 4], [5, 5], [5, 5], [5, 5], [5, 5]]])]\n    expected = np.array([[16, 25]])\n    actual = model.predict(x)\n    assert (expected == pytest.approx(actual))\n    (xinp, xout) = gs.in_out_tensors()\n    model2 = keras.Model(inputs=xinp, outputs=xout)\n    assert (pytest.approx(expected) == model2.predict(x))", "masked_code": "def test_graphsage_apply_1():\n    gs = GraphSAGE(layer_sizes=[2, 2, 2], n_samples=[2, 2, 2], bias=False, input_dim=2, multiplicity=1, normalize=None, kernel_initializer='ones')\n    inp = [keras.Input(shape=(i, 2)) for i in [1, 2, 4, 8]]\n    out = gs(inp)\n    model = keras.Model(inputs=inp, outputs=out)\n    x = [np.array([[[1, 1]]]), np.array([[[2, 2], [2, 2]]]), np.array([[[3, 3], [3, 3], [3, 3], [3, 3]]]), np.array([[[4, 4], [4, 4], [4, 4], [4, 4], [5, 5], [5, 5], [5, 5], [5, 5]]])]\n    expected = np.array([[16, 25]])\n    actual = model.predict(x)\n    assert (expected == pytest.approx(actual))\n    (xinp, xout) = gs.in_out_tensors()\n    model2 = keras.Model(inputs=xinp, outputs=xout)\n    assert (pytest.approx(expected) == '???')", "ground_truth": "model2.predict(x)", "quality_analysis": {"complexity_score": 8, "left_complexity": 4, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_628", "reponame": "stellargraph", "testpath": "tests/layer/test_graphsage.py", "testname": "test_graphsage.py", "classname": null, "funcname": "test_graphsage_passing_activations", "imports": ["from tensorflow import keras", "from tensorflow.keras import initializers, regularizers", "import tensorflow as tf", "import numpy as np", "import pytest", "from stellargraph.mapper import GraphSAGENodeGenerator", "from stellargraph.layer.graphsage import GraphSAGE, MeanAggregator, MaxPoolingAggregator, MeanPoolingAggregator, AttentionalAggregator", "from ..test_utils.graphs import example_graph", "from .. import test_utils"], "code": "def test_graphsage_passing_activations():\n    gs = GraphSAGE(layer_sizes=[4], n_samples=[2], input_dim=2, multiplicity=1)\n    assert (gs.activations == ['linear'])\n    gs = GraphSAGE(layer_sizes=[4, 4], n_samples=[2, 2], input_dim=2, multiplicity=1)\n    assert (gs.activations == ['relu', 'linear'])\n    gs = GraphSAGE(layer_sizes=[4, 4, 4], n_samples=[2, 2, 2], input_dim=2, multiplicity=1)\n    assert (gs.activations == ['relu', 'relu', 'linear'])\n    with pytest.raises(ValueError):\n        GraphSAGE(layer_sizes=[4, 4, 4], n_samples=[2, 2, 2], input_dim=2, multiplicity=1, activations=['relu'])\n    with pytest.raises(ValueError):\n        GraphSAGE(layer_sizes=[4, 4, 4], n_samples=[2, 2, 2], input_dim=2, multiplicity=1, activations=(['relu'] * 2))\n    with pytest.raises(ValueError):\n        GraphSAGE(layer_sizes=[4, 4, 4], n_samples=[2, 2, 2], input_dim=2, multiplicity=1, activations=['fred', 'wilma', 'barney'])\n    gs = GraphSAGE(layer_sizes=[4, 4, 4], n_samples=[2, 2, 2], input_dim=2, multiplicity=1, activations=(['linear'] * 3))\n    assert (gs.activations == (['linear'] * 3))", "masked_code": "def test_graphsage_passing_activations():\n    gs = GraphSAGE(layer_sizes=[4], n_samples=[2], input_dim=2, multiplicity=1)\n    assert (gs.activations == '???')\n    gs = GraphSAGE(layer_sizes=[4, 4], n_samples=[2, 2], input_dim=2, multiplicity=1)\n    assert (gs.activations == ['relu', 'linear'])\n    gs = GraphSAGE(layer_sizes=[4, 4, 4], n_samples=[2, 2, 2], input_dim=2, multiplicity=1)\n    assert (gs.activations == ['relu', 'relu', 'linear'])\n    with pytest.raises(ValueError):\n        GraphSAGE(layer_sizes=[4, 4, 4], n_samples=[2, 2, 2], input_dim=2, multiplicity=1, activations=['relu'])\n    with pytest.raises(ValueError):\n        GraphSAGE(layer_sizes=[4, 4, 4], n_samples=[2, 2, 2], input_dim=2, multiplicity=1, activations=(['relu'] * 2))\n    with pytest.raises(ValueError):\n        GraphSAGE(layer_sizes=[4, 4, 4], n_samples=[2, 2, 2], input_dim=2, multiplicity=1, activations=['fred', 'wilma', 'barney'])\n    gs = GraphSAGE(layer_sizes=[4, 4, 4], n_samples=[2, 2, 2], input_dim=2, multiplicity=1, activations=(['linear'] * 3))\n    assert (gs.activations == (['linear'] * 3))", "ground_truth": "['linear']", "quality_analysis": {"complexity_score": 5, "left_complexity": 2, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_629", "reponame": "stellargraph", "testpath": "tests/layer/test_graphsage.py", "testname": "test_graphsage.py", "classname": null, "funcname": "test_graphsage_passing_activations", "imports": ["from tensorflow import keras", "from tensorflow.keras import initializers, regularizers", "import tensorflow as tf", "import numpy as np", "import pytest", "from stellargraph.mapper import GraphSAGENodeGenerator", "from stellargraph.layer.graphsage import GraphSAGE, MeanAggregator, MaxPoolingAggregator, MeanPoolingAggregator, AttentionalAggregator", "from ..test_utils.graphs import example_graph", "from .. import test_utils"], "code": "def test_graphsage_passing_activations():\n    gs = GraphSAGE(layer_sizes=[4], n_samples=[2], input_dim=2, multiplicity=1)\n    assert (gs.activations == ['linear'])\n    gs = GraphSAGE(layer_sizes=[4, 4], n_samples=[2, 2], input_dim=2, multiplicity=1)\n    assert (gs.activations == ['relu', 'linear'])\n    gs = GraphSAGE(layer_sizes=[4, 4, 4], n_samples=[2, 2, 2], input_dim=2, multiplicity=1)\n    assert (gs.activations == ['relu', 'relu', 'linear'])\n    with pytest.raises(ValueError):\n        GraphSAGE(layer_sizes=[4, 4, 4], n_samples=[2, 2, 2], input_dim=2, multiplicity=1, activations=['relu'])\n    with pytest.raises(ValueError):\n        GraphSAGE(layer_sizes=[4, 4, 4], n_samples=[2, 2, 2], input_dim=2, multiplicity=1, activations=(['relu'] * 2))\n    with pytest.raises(ValueError):\n        GraphSAGE(layer_sizes=[4, 4, 4], n_samples=[2, 2, 2], input_dim=2, multiplicity=1, activations=['fred', 'wilma', 'barney'])\n    gs = GraphSAGE(layer_sizes=[4, 4, 4], n_samples=[2, 2, 2], input_dim=2, multiplicity=1, activations=(['linear'] * 3))\n    assert (gs.activations == (['linear'] * 3))", "masked_code": "def test_graphsage_passing_activations():\n    gs = GraphSAGE(layer_sizes=[4], n_samples=[2], input_dim=2, multiplicity=1)\n    assert (gs.activations == ['linear'])\n    gs = GraphSAGE(layer_sizes=[4, 4], n_samples=[2, 2], input_dim=2, multiplicity=1)\n    assert (gs.activations == '???')\n    gs = GraphSAGE(layer_sizes=[4, 4, 4], n_samples=[2, 2, 2], input_dim=2, multiplicity=1)\n    assert (gs.activations == ['relu', 'relu', 'linear'])\n    with pytest.raises(ValueError):\n        GraphSAGE(layer_sizes=[4, 4, 4], n_samples=[2, 2, 2], input_dim=2, multiplicity=1, activations=['relu'])\n    with pytest.raises(ValueError):\n        GraphSAGE(layer_sizes=[4, 4, 4], n_samples=[2, 2, 2], input_dim=2, multiplicity=1, activations=(['relu'] * 2))\n    with pytest.raises(ValueError):\n        GraphSAGE(layer_sizes=[4, 4, 4], n_samples=[2, 2, 2], input_dim=2, multiplicity=1, activations=['fred', 'wilma', 'barney'])\n    gs = GraphSAGE(layer_sizes=[4, 4, 4], n_samples=[2, 2, 2], input_dim=2, multiplicity=1, activations=(['linear'] * 3))\n    assert (gs.activations == (['linear'] * 3))", "ground_truth": "['relu', 'linear']", "quality_analysis": {"complexity_score": 6, "left_complexity": 2, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_630", "reponame": "stellargraph", "testpath": "tests/layer/test_graphsage.py", "testname": "test_graphsage.py", "classname": null, "funcname": "test_graphsage_passing_activations", "imports": ["from tensorflow import keras", "from tensorflow.keras import initializers, regularizers", "import tensorflow as tf", "import numpy as np", "import pytest", "from stellargraph.mapper import GraphSAGENodeGenerator", "from stellargraph.layer.graphsage import GraphSAGE, MeanAggregator, MaxPoolingAggregator, MeanPoolingAggregator, AttentionalAggregator", "from ..test_utils.graphs import example_graph", "from .. import test_utils"], "code": "def test_graphsage_passing_activations():\n    gs = GraphSAGE(layer_sizes=[4], n_samples=[2], input_dim=2, multiplicity=1)\n    assert (gs.activations == ['linear'])\n    gs = GraphSAGE(layer_sizes=[4, 4], n_samples=[2, 2], input_dim=2, multiplicity=1)\n    assert (gs.activations == ['relu', 'linear'])\n    gs = GraphSAGE(layer_sizes=[4, 4, 4], n_samples=[2, 2, 2], input_dim=2, multiplicity=1)\n    assert (gs.activations == ['relu', 'relu', 'linear'])\n    with pytest.raises(ValueError):\n        GraphSAGE(layer_sizes=[4, 4, 4], n_samples=[2, 2, 2], input_dim=2, multiplicity=1, activations=['relu'])\n    with pytest.raises(ValueError):\n        GraphSAGE(layer_sizes=[4, 4, 4], n_samples=[2, 2, 2], input_dim=2, multiplicity=1, activations=(['relu'] * 2))\n    with pytest.raises(ValueError):\n        GraphSAGE(layer_sizes=[4, 4, 4], n_samples=[2, 2, 2], input_dim=2, multiplicity=1, activations=['fred', 'wilma', 'barney'])\n    gs = GraphSAGE(layer_sizes=[4, 4, 4], n_samples=[2, 2, 2], input_dim=2, multiplicity=1, activations=(['linear'] * 3))\n    assert (gs.activations == (['linear'] * 3))", "masked_code": "def test_graphsage_passing_activations():\n    gs = GraphSAGE(layer_sizes=[4], n_samples=[2], input_dim=2, multiplicity=1)\n    assert (gs.activations == ['linear'])\n    gs = GraphSAGE(layer_sizes=[4, 4], n_samples=[2, 2], input_dim=2, multiplicity=1)\n    assert (gs.activations == ['relu', 'linear'])\n    gs = GraphSAGE(layer_sizes=[4, 4, 4], n_samples=[2, 2, 2], input_dim=2, multiplicity=1)\n    assert (gs.activations == '???')\n    with pytest.raises(ValueError):\n        GraphSAGE(layer_sizes=[4, 4, 4], n_samples=[2, 2, 2], input_dim=2, multiplicity=1, activations=['relu'])\n    with pytest.raises(ValueError):\n        GraphSAGE(layer_sizes=[4, 4, 4], n_samples=[2, 2, 2], input_dim=2, multiplicity=1, activations=(['relu'] * 2))\n    with pytest.raises(ValueError):\n        GraphSAGE(layer_sizes=[4, 4, 4], n_samples=[2, 2, 2], input_dim=2, multiplicity=1, activations=['fred', 'wilma', 'barney'])\n    gs = GraphSAGE(layer_sizes=[4, 4, 4], n_samples=[2, 2, 2], input_dim=2, multiplicity=1, activations=(['linear'] * 3))\n    assert (gs.activations == (['linear'] * 3))", "ground_truth": "['relu', 'relu', 'linear']", "quality_analysis": {"complexity_score": 7, "left_complexity": 2, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_631", "reponame": "stellargraph", "testpath": "tests/layer/test_graphsage.py", "testname": "test_graphsage.py", "classname": null, "funcname": "test_graphsage_passing_activations", "imports": ["from tensorflow import keras", "from tensorflow.keras import initializers, regularizers", "import tensorflow as tf", "import numpy as np", "import pytest", "from stellargraph.mapper import GraphSAGENodeGenerator", "from stellargraph.layer.graphsage import GraphSAGE, MeanAggregator, MaxPoolingAggregator, MeanPoolingAggregator, AttentionalAggregator", "from ..test_utils.graphs import example_graph", "from .. import test_utils"], "code": "def test_graphsage_passing_activations():\n    gs = GraphSAGE(layer_sizes=[4], n_samples=[2], input_dim=2, multiplicity=1)\n    assert (gs.activations == ['linear'])\n    gs = GraphSAGE(layer_sizes=[4, 4], n_samples=[2, 2], input_dim=2, multiplicity=1)\n    assert (gs.activations == ['relu', 'linear'])\n    gs = GraphSAGE(layer_sizes=[4, 4, 4], n_samples=[2, 2, 2], input_dim=2, multiplicity=1)\n    assert (gs.activations == ['relu', 'relu', 'linear'])\n    with pytest.raises(ValueError):\n        GraphSAGE(layer_sizes=[4, 4, 4], n_samples=[2, 2, 2], input_dim=2, multiplicity=1, activations=['relu'])\n    with pytest.raises(ValueError):\n        GraphSAGE(layer_sizes=[4, 4, 4], n_samples=[2, 2, 2], input_dim=2, multiplicity=1, activations=(['relu'] * 2))\n    with pytest.raises(ValueError):\n        GraphSAGE(layer_sizes=[4, 4, 4], n_samples=[2, 2, 2], input_dim=2, multiplicity=1, activations=['fred', 'wilma', 'barney'])\n    gs = GraphSAGE(layer_sizes=[4, 4, 4], n_samples=[2, 2, 2], input_dim=2, multiplicity=1, activations=(['linear'] * 3))\n    assert (gs.activations == (['linear'] * 3))", "masked_code": "def test_graphsage_passing_activations():\n    gs = GraphSAGE(layer_sizes=[4], n_samples=[2], input_dim=2, multiplicity=1)\n    assert (gs.activations == ['linear'])\n    gs = GraphSAGE(layer_sizes=[4, 4], n_samples=[2, 2], input_dim=2, multiplicity=1)\n    assert (gs.activations == ['relu', 'linear'])\n    gs = GraphSAGE(layer_sizes=[4, 4, 4], n_samples=[2, 2, 2], input_dim=2, multiplicity=1)\n    assert (gs.activations == ['relu', 'relu', 'linear'])\n    with pytest.raises(ValueError):\n        GraphSAGE(layer_sizes=[4, 4, 4], n_samples=[2, 2, 2], input_dim=2, multiplicity=1, activations=['relu'])\n    with pytest.raises(ValueError):\n        GraphSAGE(layer_sizes=[4, 4, 4], n_samples=[2, 2, 2], input_dim=2, multiplicity=1, activations=(['relu'] * 2))\n    with pytest.raises(ValueError):\n        GraphSAGE(layer_sizes=[4, 4, 4], n_samples=[2, 2, 2], input_dim=2, multiplicity=1, activations=['fred', 'wilma', 'barney'])\n    gs = GraphSAGE(layer_sizes=[4, 4, 4], n_samples=[2, 2, 2], input_dim=2, multiplicity=1, activations=(['linear'] * 3))\n    assert (gs.activations == '???')", "ground_truth": "(['linear'] * 3)", "quality_analysis": {"complexity_score": 8, "left_complexity": 2, "right_complexity": 6, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_632", "reponame": "stellargraph", "testpath": "tests/layer/test_graph_attention.py", "testname": "test_graph_attention.py", "classname": "Test_GraphAttention", "funcname": "test_constructor", "imports": ["import pytest", "import scipy.sparse as sps", "import tensorflow as tf", "from tensorflow import keras", "from tensorflow.keras import backend as K", "from tensorflow.keras.layers import Input", "from stellargraph.mapper import FullBatchNodeGenerator, FullBatchLinkGenerator, GraphSAGENodeGenerator", "from stellargraph.layer import *", "from ..test_utils.graphs import example_graph", "from .. import test_utils"], "code": "def test_constructor(self):\n    layer = self.layer(units=self.F_out, attn_heads=self.attn_heads, attn_heads_reduction='concat', activation=self.activation)\n    assert (layer.units == self.F_out)\n    assert (layer.attn_heads == self.attn_heads)\n    assert (layer.output_dim == (self.F_out * self.attn_heads))\n    assert (layer.activation == keras.activations.get(self.activation))\n    layer = self.layer(units=self.F_out, attn_heads=self.attn_heads, attn_heads_reduction='average', activation=self.activation)\n    assert (layer.output_dim == self.F_out)\n    with pytest.raises(ValueError):\n        self.layer(units=self.F_out, attn_heads=self.attn_heads, attn_heads_reduction='ave', activation=self.activation)", "masked_code": "def test_constructor(self):\n    layer = self.layer(units=self.F_out, attn_heads=self.attn_heads, attn_heads_reduction='concat', activation=self.activation)\n    assert (layer.units == '???')\n    assert (layer.attn_heads == self.attn_heads)\n    assert (layer.output_dim == (self.F_out * self.attn_heads))\n    assert (layer.activation == keras.activations.get(self.activation))\n    layer = self.layer(units=self.F_out, attn_heads=self.attn_heads, attn_heads_reduction='average', activation=self.activation)\n    assert (layer.output_dim == self.F_out)\n    with pytest.raises(ValueError):\n        self.layer(units=self.F_out, attn_heads=self.attn_heads, attn_heads_reduction='ave', activation=self.activation)", "ground_truth": "self.F_out", "quality_analysis": {"complexity_score": 4, "left_complexity": 2, "right_complexity": 2, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_633", "reponame": "stellargraph", "testpath": "tests/layer/test_graph_attention.py", "testname": "test_graph_attention.py", "classname": "Test_GraphAttention", "funcname": "test_constructor", "imports": ["import pytest", "import scipy.sparse as sps", "import tensorflow as tf", "from tensorflow import keras", "from tensorflow.keras import backend as K", "from tensorflow.keras.layers import Input", "from stellargraph.mapper import FullBatchNodeGenerator, FullBatchLinkGenerator, GraphSAGENodeGenerator", "from stellargraph.layer import *", "from ..test_utils.graphs import example_graph", "from .. import test_utils"], "code": "def test_constructor(self):\n    layer = self.layer(units=self.F_out, attn_heads=self.attn_heads, attn_heads_reduction='concat', activation=self.activation)\n    assert (layer.units == self.F_out)\n    assert (layer.attn_heads == self.attn_heads)\n    assert (layer.output_dim == (self.F_out * self.attn_heads))\n    assert (layer.activation == keras.activations.get(self.activation))\n    layer = self.layer(units=self.F_out, attn_heads=self.attn_heads, attn_heads_reduction='average', activation=self.activation)\n    assert (layer.output_dim == self.F_out)\n    with pytest.raises(ValueError):\n        self.layer(units=self.F_out, attn_heads=self.attn_heads, attn_heads_reduction='ave', activation=self.activation)", "masked_code": "def test_constructor(self):\n    layer = self.layer(units=self.F_out, attn_heads=self.attn_heads, attn_heads_reduction='concat', activation=self.activation)\n    assert (layer.units == self.F_out)\n    assert (layer.attn_heads == '???')\n    assert (layer.output_dim == (self.F_out * self.attn_heads))\n    assert (layer.activation == keras.activations.get(self.activation))\n    layer = self.layer(units=self.F_out, attn_heads=self.attn_heads, attn_heads_reduction='average', activation=self.activation)\n    assert (layer.output_dim == self.F_out)\n    with pytest.raises(ValueError):\n        self.layer(units=self.F_out, attn_heads=self.attn_heads, attn_heads_reduction='ave', activation=self.activation)", "ground_truth": "self.attn_heads", "quality_analysis": {"complexity_score": 4, "left_complexity": 2, "right_complexity": 2, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_634", "reponame": "stellargraph", "testpath": "tests/layer/test_graph_attention.py", "testname": "test_graph_attention.py", "classname": "Test_GraphAttention", "funcname": "test_constructor", "imports": ["import pytest", "import scipy.sparse as sps", "import tensorflow as tf", "from tensorflow import keras", "from tensorflow.keras import backend as K", "from tensorflow.keras.layers import Input", "from stellargraph.mapper import FullBatchNodeGenerator, FullBatchLinkGenerator, GraphSAGENodeGenerator", "from stellargraph.layer import *", "from ..test_utils.graphs import example_graph", "from .. import test_utils"], "code": "def test_constructor(self):\n    layer = self.layer(units=self.F_out, attn_heads=self.attn_heads, attn_heads_reduction='concat', activation=self.activation)\n    assert (layer.units == self.F_out)\n    assert (layer.attn_heads == self.attn_heads)\n    assert (layer.output_dim == (self.F_out * self.attn_heads))\n    assert (layer.activation == keras.activations.get(self.activation))\n    layer = self.layer(units=self.F_out, attn_heads=self.attn_heads, attn_heads_reduction='average', activation=self.activation)\n    assert (layer.output_dim == self.F_out)\n    with pytest.raises(ValueError):\n        self.layer(units=self.F_out, attn_heads=self.attn_heads, attn_heads_reduction='ave', activation=self.activation)", "masked_code": "def test_constructor(self):\n    layer = self.layer(units=self.F_out, attn_heads=self.attn_heads, attn_heads_reduction='concat', activation=self.activation)\n    assert (layer.units == self.F_out)\n    assert (layer.attn_heads == self.attn_heads)\n    assert (layer.output_dim == '???')\n    assert (layer.activation == keras.activations.get(self.activation))\n    layer = self.layer(units=self.F_out, attn_heads=self.attn_heads, attn_heads_reduction='average', activation=self.activation)\n    assert (layer.output_dim == self.F_out)\n    with pytest.raises(ValueError):\n        self.layer(units=self.F_out, attn_heads=self.attn_heads, attn_heads_reduction='ave', activation=self.activation)", "ground_truth": "(self.F_out * self.attn_heads)", "quality_analysis": {"complexity_score": 8, "left_complexity": 2, "right_complexity": 6, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_635", "reponame": "stellargraph", "testpath": "tests/layer/test_graph_attention.py", "testname": "test_graph_attention.py", "classname": "Test_GraphAttention", "funcname": "test_constructor", "imports": ["import pytest", "import scipy.sparse as sps", "import tensorflow as tf", "from tensorflow import keras", "from tensorflow.keras import backend as K", "from tensorflow.keras.layers import Input", "from stellargraph.mapper import FullBatchNodeGenerator, FullBatchLinkGenerator, GraphSAGENodeGenerator", "from stellargraph.layer import *", "from ..test_utils.graphs import example_graph", "from .. import test_utils"], "code": "def test_constructor(self):\n    layer = self.layer(units=self.F_out, attn_heads=self.attn_heads, attn_heads_reduction='concat', activation=self.activation)\n    assert (layer.units == self.F_out)\n    assert (layer.attn_heads == self.attn_heads)\n    assert (layer.output_dim == (self.F_out * self.attn_heads))\n    assert (layer.activation == keras.activations.get(self.activation))\n    layer = self.layer(units=self.F_out, attn_heads=self.attn_heads, attn_heads_reduction='average', activation=self.activation)\n    assert (layer.output_dim == self.F_out)\n    with pytest.raises(ValueError):\n        self.layer(units=self.F_out, attn_heads=self.attn_heads, attn_heads_reduction='ave', activation=self.activation)", "masked_code": "def test_constructor(self):\n    layer = self.layer(units=self.F_out, attn_heads=self.attn_heads, attn_heads_reduction='concat', activation=self.activation)\n    assert (layer.units == self.F_out)\n    assert (layer.attn_heads == self.attn_heads)\n    assert (layer.output_dim == (self.F_out * self.attn_heads))\n    assert (layer.activation == '???')\n    layer = self.layer(units=self.F_out, attn_heads=self.attn_heads, attn_heads_reduction='average', activation=self.activation)\n    assert (layer.output_dim == self.F_out)\n    with pytest.raises(ValueError):\n        self.layer(units=self.F_out, attn_heads=self.attn_heads, attn_heads_reduction='ave', activation=self.activation)", "ground_truth": "keras.activations.get(self.activation)", "quality_analysis": {"complexity_score": 7, "left_complexity": 2, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_636", "reponame": "stellargraph", "testpath": "tests/layer/test_graph_attention.py", "testname": "test_graph_attention.py", "classname": "Test_GraphAttention", "funcname": "test_constructor", "imports": ["import pytest", "import scipy.sparse as sps", "import tensorflow as tf", "from tensorflow import keras", "from tensorflow.keras import backend as K", "from tensorflow.keras.layers import Input", "from stellargraph.mapper import FullBatchNodeGenerator, FullBatchLinkGenerator, GraphSAGENodeGenerator", "from stellargraph.layer import *", "from ..test_utils.graphs import example_graph", "from .. import test_utils"], "code": "def test_constructor(self):\n    layer = self.layer(units=self.F_out, attn_heads=self.attn_heads, attn_heads_reduction='concat', activation=self.activation)\n    assert (layer.units == self.F_out)\n    assert (layer.attn_heads == self.attn_heads)\n    assert (layer.output_dim == (self.F_out * self.attn_heads))\n    assert (layer.activation == keras.activations.get(self.activation))\n    layer = self.layer(units=self.F_out, attn_heads=self.attn_heads, attn_heads_reduction='average', activation=self.activation)\n    assert (layer.output_dim == self.F_out)\n    with pytest.raises(ValueError):\n        self.layer(units=self.F_out, attn_heads=self.attn_heads, attn_heads_reduction='ave', activation=self.activation)", "masked_code": "def test_constructor(self):\n    layer = self.layer(units=self.F_out, attn_heads=self.attn_heads, attn_heads_reduction='concat', activation=self.activation)\n    assert (layer.units == self.F_out)\n    assert (layer.attn_heads == self.attn_heads)\n    assert (layer.output_dim == (self.F_out * self.attn_heads))\n    assert (layer.activation == keras.activations.get(self.activation))\n    layer = self.layer(units=self.F_out, attn_heads=self.attn_heads, attn_heads_reduction='average', activation=self.activation)\n    assert (layer.output_dim == '???')\n    with pytest.raises(ValueError):\n        self.layer(units=self.F_out, attn_heads=self.attn_heads, attn_heads_reduction='ave', activation=self.activation)", "ground_truth": "self.F_out", "quality_analysis": {"complexity_score": 4, "left_complexity": 2, "right_complexity": 2, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_637", "reponame": "stellargraph", "testpath": "tests/layer/test_graph_attention.py", "testname": "test_graph_attention.py", "classname": "Test_GraphAttention", "funcname": "test_apply_concat", "imports": ["import pytest", "import scipy.sparse as sps", "import tensorflow as tf", "from tensorflow import keras", "from tensorflow.keras import backend as K", "from tensorflow.keras.layers import Input", "from stellargraph.mapper import FullBatchNodeGenerator, FullBatchLinkGenerator, GraphSAGENodeGenerator", "from stellargraph.layer import *", "from ..test_utils.graphs import example_graph", "from .. import test_utils"], "code": "def test_apply_concat(self):\n    gat = self.layer(units=self.F_out, attn_heads=self.attn_heads, attn_heads_reduction='concat', activation=self.activation, kernel_initializer='ones')\n    (x_inp, layer_inp) = self.get_inputs()\n    x_out = gat(layer_inp)\n    model = keras.Model(inputs=x_inp, outputs=x_out)\n    assert (model.output_shape[(- 1)] == (self.F_out * self.attn_heads))\n    As = self.get_matrix()\n    X = np.ones((1, self.N, self.F_in))\n    expected = (np.ones((self.N, (self.F_out * self.attn_heads))) * self.F_in)\n    actual = model.predict(([X] + As))\n    np.testing.assert_allclose(actual.squeeze(), expected)", "masked_code": "def test_apply_concat(self):\n    gat = self.layer(units=self.F_out, attn_heads=self.attn_heads, attn_heads_reduction='concat', activation=self.activation, kernel_initializer='ones')\n    (x_inp, layer_inp) = self.get_inputs()\n    x_out = gat(layer_inp)\n    model = keras.Model(inputs=x_inp, outputs=x_out)\n    assert (model.output_shape[(- 1)] == '???')\n    As = self.get_matrix()\n    X = np.ones((1, self.N, self.F_in))\n    expected = (np.ones((self.N, (self.F_out * self.attn_heads))) * self.F_in)\n    actual = model.predict(([X] + As))\n    np.testing.assert_allclose(actual.squeeze(), expected)", "ground_truth": "(self.F_out * self.attn_heads)", "quality_analysis": {"complexity_score": 14, "left_complexity": 8, "right_complexity": 6, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_638", "reponame": "stellargraph", "testpath": "tests/layer/test_graph_attention.py", "testname": "test_graph_attention.py", "classname": "Test_GraphAttention", "funcname": "test_apply_average", "imports": ["import pytest", "import scipy.sparse as sps", "import tensorflow as tf", "from tensorflow import keras", "from tensorflow.keras import backend as K", "from tensorflow.keras.layers import Input", "from stellargraph.mapper import FullBatchNodeGenerator, FullBatchLinkGenerator, GraphSAGENodeGenerator", "from stellargraph.layer import *", "from ..test_utils.graphs import example_graph", "from .. import test_utils"], "code": "def test_apply_average(self):\n    gat = self.layer(units=self.F_out, attn_heads=self.attn_heads, attn_heads_reduction='average', activation=self.activation, kernel_initializer='ones', attn_kernel_initializer='zeros', bias_initializer='zeros')\n    (x_inp, layer_inp) = self.get_inputs()\n    x_out = gat(layer_inp)\n    model = keras.Model(inputs=x_inp, outputs=x_out)\n    assert (model.output_shape[(- 1)] == self.F_out)\n    X = np.ones((1, self.N, self.F_in))\n    for i in range(self.N):\n        X[(:, i, :)] = (i + 1)\n    As = self.get_matrix()\n    expected = (X * self.F_in)[(..., :self.F_out)]\n    actual = model.predict(([X] + As))\n    np.testing.assert_allclose(actual.squeeze(), expected.squeeze())", "masked_code": "def test_apply_average(self):\n    gat = self.layer(units=self.F_out, attn_heads=self.attn_heads, attn_heads_reduction='average', activation=self.activation, kernel_initializer='ones', attn_kernel_initializer='zeros', bias_initializer='zeros')\n    (x_inp, layer_inp) = self.get_inputs()\n    x_out = gat(layer_inp)\n    model = keras.Model(inputs=x_inp, outputs=x_out)\n    assert (model.output_shape[(- 1)] == '???')\n    X = np.ones((1, self.N, self.F_in))\n    for i in range(self.N):\n        X[(:, i, :)] = (i + 1)\n    As = self.get_matrix()\n    expected = (X * self.F_in)[(..., :self.F_out)]\n    actual = model.predict(([X] + As))\n    np.testing.assert_allclose(actual.squeeze(), expected.squeeze())", "ground_truth": "self.F_out", "quality_analysis": {"complexity_score": 10, "left_complexity": 8, "right_complexity": 2, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_639", "reponame": "stellargraph", "testpath": "tests/layer/test_graph_attention.py", "testname": "test_graph_attention.py", "classname": "Test_GraphAttention", "funcname": "test_apply_average_with_neighbours", "imports": ["import pytest", "import scipy.sparse as sps", "import tensorflow as tf", "from tensorflow import keras", "from tensorflow.keras import backend as K", "from tensorflow.keras.layers import Input", "from stellargraph.mapper import FullBatchNodeGenerator, FullBatchLinkGenerator, GraphSAGENodeGenerator", "from stellargraph.layer import *", "from ..test_utils.graphs import example_graph", "from .. import test_utils"], "code": "def test_apply_average_with_neighbours(self):\n    gat_saliency = self.layer(units=self.F_out, attn_heads=self.attn_heads, attn_heads_reduction='average', activation=self.activation, kernel_initializer='ones', attn_kernel_initializer='zeros', bias_initializer='zeros', saliency_map_support=True)\n    gat_origin = self.layer(units=self.F_out, attn_heads=self.attn_heads, attn_heads_reduction='average', activation=self.activation, kernel_initializer='ones', attn_kernel_initializer='zeros', bias_initializer='zeros', saliency_map_support=False)\n    (x_inp, layer_inp) = self.get_inputs()\n    x_out_saliency = gat_saliency(layer_inp)\n    x_out_origin = gat_origin(layer_inp)\n    model_origin = keras.Model(inputs=x_inp, outputs=x_out_origin)\n    model_saliency = keras.Model(inputs=x_inp, outputs=x_out_saliency)\n    assert (model_origin.output_shape[(- 1)] == self.F_out)\n    assert (model_saliency.output_shape[(- 1)] == self.F_out)\n    X = np.zeros((1, self.N, self.F_in))\n    for i in range(self.N):\n        X[(:, i, :)] = i\n    As = self.get_matrix([((0, 1), 1), ((1, 0), 1)])\n    expected = (X * self.F_in)[(..., :self.F_out)]\n    expected[(:, :2)] = (self.F_in / 2)\n    actual_origin = model_origin.predict(([X] + As))\n    actual_saliency = model_saliency.predict(([X] + As))\n    np.testing.assert_allclose(expected, actual_origin)\n    np.testing.assert_allclose(expected, actual_saliency)", "masked_code": "def test_apply_average_with_neighbours(self):\n    gat_saliency = self.layer(units=self.F_out, attn_heads=self.attn_heads, attn_heads_reduction='average', activation=self.activation, kernel_initializer='ones', attn_kernel_initializer='zeros', bias_initializer='zeros', saliency_map_support=True)\n    gat_origin = self.layer(units=self.F_out, attn_heads=self.attn_heads, attn_heads_reduction='average', activation=self.activation, kernel_initializer='ones', attn_kernel_initializer='zeros', bias_initializer='zeros', saliency_map_support=False)\n    (x_inp, layer_inp) = self.get_inputs()\n    x_out_saliency = gat_saliency(layer_inp)\n    x_out_origin = gat_origin(layer_inp)\n    model_origin = keras.Model(inputs=x_inp, outputs=x_out_origin)\n    model_saliency = keras.Model(inputs=x_inp, outputs=x_out_saliency)\n    assert (model_origin.output_shape[(- 1)] == '???')\n    assert (model_saliency.output_shape[(- 1)] == self.F_out)\n    X = np.zeros((1, self.N, self.F_in))\n    for i in range(self.N):\n        X[(:, i, :)] = i\n    As = self.get_matrix([((0, 1), 1), ((1, 0), 1)])\n    expected = (X * self.F_in)[(..., :self.F_out)]\n    expected[(:, :2)] = (self.F_in / 2)\n    actual_origin = model_origin.predict(([X] + As))\n    actual_saliency = model_saliency.predict(([X] + As))\n    np.testing.assert_allclose(expected, actual_origin)\n    np.testing.assert_allclose(expected, actual_saliency)", "ground_truth": "self.F_out", "quality_analysis": {"complexity_score": 10, "left_complexity": 8, "right_complexity": 2, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_640", "reponame": "stellargraph", "testpath": "tests/layer/test_graph_attention.py", "testname": "test_graph_attention.py", "classname": "Test_GraphAttention", "funcname": "test_apply_average_with_neighbours", "imports": ["import pytest", "import scipy.sparse as sps", "import tensorflow as tf", "from tensorflow import keras", "from tensorflow.keras import backend as K", "from tensorflow.keras.layers import Input", "from stellargraph.mapper import FullBatchNodeGenerator, FullBatchLinkGenerator, GraphSAGENodeGenerator", "from stellargraph.layer import *", "from ..test_utils.graphs import example_graph", "from .. import test_utils"], "code": "def test_apply_average_with_neighbours(self):\n    gat_saliency = self.layer(units=self.F_out, attn_heads=self.attn_heads, attn_heads_reduction='average', activation=self.activation, kernel_initializer='ones', attn_kernel_initializer='zeros', bias_initializer='zeros', saliency_map_support=True)\n    gat_origin = self.layer(units=self.F_out, attn_heads=self.attn_heads, attn_heads_reduction='average', activation=self.activation, kernel_initializer='ones', attn_kernel_initializer='zeros', bias_initializer='zeros', saliency_map_support=False)\n    (x_inp, layer_inp) = self.get_inputs()\n    x_out_saliency = gat_saliency(layer_inp)\n    x_out_origin = gat_origin(layer_inp)\n    model_origin = keras.Model(inputs=x_inp, outputs=x_out_origin)\n    model_saliency = keras.Model(inputs=x_inp, outputs=x_out_saliency)\n    assert (model_origin.output_shape[(- 1)] == self.F_out)\n    assert (model_saliency.output_shape[(- 1)] == self.F_out)\n    X = np.zeros((1, self.N, self.F_in))\n    for i in range(self.N):\n        X[(:, i, :)] = i\n    As = self.get_matrix([((0, 1), 1), ((1, 0), 1)])\n    expected = (X * self.F_in)[(..., :self.F_out)]\n    expected[(:, :2)] = (self.F_in / 2)\n    actual_origin = model_origin.predict(([X] + As))\n    actual_saliency = model_saliency.predict(([X] + As))\n    np.testing.assert_allclose(expected, actual_origin)\n    np.testing.assert_allclose(expected, actual_saliency)", "masked_code": "def test_apply_average_with_neighbours(self):\n    gat_saliency = self.layer(units=self.F_out, attn_heads=self.attn_heads, attn_heads_reduction='average', activation=self.activation, kernel_initializer='ones', attn_kernel_initializer='zeros', bias_initializer='zeros', saliency_map_support=True)\n    gat_origin = self.layer(units=self.F_out, attn_heads=self.attn_heads, attn_heads_reduction='average', activation=self.activation, kernel_initializer='ones', attn_kernel_initializer='zeros', bias_initializer='zeros', saliency_map_support=False)\n    (x_inp, layer_inp) = self.get_inputs()\n    x_out_saliency = gat_saliency(layer_inp)\n    x_out_origin = gat_origin(layer_inp)\n    model_origin = keras.Model(inputs=x_inp, outputs=x_out_origin)\n    model_saliency = keras.Model(inputs=x_inp, outputs=x_out_saliency)\n    assert (model_origin.output_shape[(- 1)] == self.F_out)\n    assert (model_saliency.output_shape[(- 1)] == '???')\n    X = np.zeros((1, self.N, self.F_in))\n    for i in range(self.N):\n        X[(:, i, :)] = i\n    As = self.get_matrix([((0, 1), 1), ((1, 0), 1)])\n    expected = (X * self.F_in)[(..., :self.F_out)]\n    expected[(:, :2)] = (self.F_in / 2)\n    actual_origin = model_origin.predict(([X] + As))\n    actual_saliency = model_saliency.predict(([X] + As))\n    np.testing.assert_allclose(expected, actual_origin)\n    np.testing.assert_allclose(expected, actual_saliency)", "ground_truth": "self.F_out", "quality_analysis": {"complexity_score": 10, "left_complexity": 8, "right_complexity": 2, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_641", "reponame": "stellargraph", "testpath": "tests/layer/test_graph_attention.py", "testname": "test_graph_attention.py", "classname": "Test_GraphAttention", "funcname": "test_layer_config", "imports": ["import pytest", "import scipy.sparse as sps", "import tensorflow as tf", "from tensorflow import keras", "from tensorflow.keras import backend as K", "from tensorflow.keras.layers import Input", "from stellargraph.mapper import FullBatchNodeGenerator, FullBatchLinkGenerator, GraphSAGENodeGenerator", "from stellargraph.layer import *", "from ..test_utils.graphs import example_graph", "from .. import test_utils"], "code": "def test_layer_config(self):\n    layer = self.layer(units=self.F_out, attn_heads=self.attn_heads, attn_heads_reduction='concat', activation=self.activation)\n    conf = layer.get_config()\n    assert (conf['units'] == self.F_out)\n    assert (conf['attn_heads'] == self.attn_heads)\n    assert (conf['attn_heads_reduction'] == 'concat')\n    assert (conf['activation'] == self.activation)\n    assert (conf['use_bias'] == True)\n    assert (conf['kernel_initializer']['class_name'] == 'GlorotUniform')\n    assert (conf['bias_initializer']['class_name'] == 'Zeros')\n    assert (conf['kernel_regularizer'] == None)\n    assert (conf['bias_regularizer'] == None)\n    assert (conf['kernel_constraint'] == None)\n    assert (conf['bias_constraint'] == None)", "masked_code": "def test_layer_config(self):\n    layer = self.layer(units=self.F_out, attn_heads=self.attn_heads, attn_heads_reduction='concat', activation=self.activation)\n    conf = layer.get_config()\n    assert (conf['units'] == '???')\n    assert (conf['attn_heads'] == self.attn_heads)\n    assert (conf['attn_heads_reduction'] == 'concat')\n    assert (conf['activation'] == self.activation)\n    assert (conf['use_bias'] == True)\n    assert (conf['kernel_initializer']['class_name'] == 'GlorotUniform')\n    assert (conf['bias_initializer']['class_name'] == 'Zeros')\n    assert (conf['kernel_regularizer'] == None)\n    assert (conf['bias_regularizer'] == None)\n    assert (conf['kernel_constraint'] == None)\n    assert (conf['bias_constraint'] == None)", "ground_truth": "self.F_out", "quality_analysis": {"complexity_score": 7, "left_complexity": 5, "right_complexity": 2, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_642", "reponame": "stellargraph", "testpath": "tests/layer/test_graph_attention.py", "testname": "test_graph_attention.py", "classname": "Test_GraphAttention", "funcname": "test_layer_config", "imports": ["import pytest", "import scipy.sparse as sps", "import tensorflow as tf", "from tensorflow import keras", "from tensorflow.keras import backend as K", "from tensorflow.keras.layers import Input", "from stellargraph.mapper import FullBatchNodeGenerator, FullBatchLinkGenerator, GraphSAGENodeGenerator", "from stellargraph.layer import *", "from ..test_utils.graphs import example_graph", "from .. import test_utils"], "code": "def test_layer_config(self):\n    layer = self.layer(units=self.F_out, attn_heads=self.attn_heads, attn_heads_reduction='concat', activation=self.activation)\n    conf = layer.get_config()\n    assert (conf['units'] == self.F_out)\n    assert (conf['attn_heads'] == self.attn_heads)\n    assert (conf['attn_heads_reduction'] == 'concat')\n    assert (conf['activation'] == self.activation)\n    assert (conf['use_bias'] == True)\n    assert (conf['kernel_initializer']['class_name'] == 'GlorotUniform')\n    assert (conf['bias_initializer']['class_name'] == 'Zeros')\n    assert (conf['kernel_regularizer'] == None)\n    assert (conf['bias_regularizer'] == None)\n    assert (conf['kernel_constraint'] == None)\n    assert (conf['bias_constraint'] == None)", "masked_code": "def test_layer_config(self):\n    layer = self.layer(units=self.F_out, attn_heads=self.attn_heads, attn_heads_reduction='concat', activation=self.activation)\n    conf = layer.get_config()\n    assert (conf['units'] == self.F_out)\n    assert (conf['attn_heads'] == '???')\n    assert (conf['attn_heads_reduction'] == 'concat')\n    assert (conf['activation'] == self.activation)\n    assert (conf['use_bias'] == True)\n    assert (conf['kernel_initializer']['class_name'] == 'GlorotUniform')\n    assert (conf['bias_initializer']['class_name'] == 'Zeros')\n    assert (conf['kernel_regularizer'] == None)\n    assert (conf['bias_regularizer'] == None)\n    assert (conf['kernel_constraint'] == None)\n    assert (conf['bias_constraint'] == None)", "ground_truth": "self.attn_heads", "quality_analysis": {"complexity_score": 7, "left_complexity": 5, "right_complexity": 2, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_643", "reponame": "stellargraph", "testpath": "tests/layer/test_graph_attention.py", "testname": "test_graph_attention.py", "classname": "Test_GraphAttention", "funcname": "test_layer_config", "imports": ["import pytest", "import scipy.sparse as sps", "import tensorflow as tf", "from tensorflow import keras", "from tensorflow.keras import backend as K", "from tensorflow.keras.layers import Input", "from stellargraph.mapper import FullBatchNodeGenerator, FullBatchLinkGenerator, GraphSAGENodeGenerator", "from stellargraph.layer import *", "from ..test_utils.graphs import example_graph", "from .. import test_utils"], "code": "def test_layer_config(self):\n    layer = self.layer(units=self.F_out, attn_heads=self.attn_heads, attn_heads_reduction='concat', activation=self.activation)\n    conf = layer.get_config()\n    assert (conf['units'] == self.F_out)\n    assert (conf['attn_heads'] == self.attn_heads)\n    assert (conf['attn_heads_reduction'] == 'concat')\n    assert (conf['activation'] == self.activation)\n    assert (conf['use_bias'] == True)\n    assert (conf['kernel_initializer']['class_name'] == 'GlorotUniform')\n    assert (conf['bias_initializer']['class_name'] == 'Zeros')\n    assert (conf['kernel_regularizer'] == None)\n    assert (conf['bias_regularizer'] == None)\n    assert (conf['kernel_constraint'] == None)\n    assert (conf['bias_constraint'] == None)", "masked_code": "def test_layer_config(self):\n    layer = self.layer(units=self.F_out, attn_heads=self.attn_heads, attn_heads_reduction='concat', activation=self.activation)\n    conf = layer.get_config()\n    assert (conf['units'] == self.F_out)\n    assert (conf['attn_heads'] == self.attn_heads)\n    assert (conf['attn_heads_reduction'] == '???')\n    assert (conf['activation'] == self.activation)\n    assert (conf['use_bias'] == True)\n    assert (conf['kernel_initializer']['class_name'] == 'GlorotUniform')\n    assert (conf['bias_initializer']['class_name'] == 'Zeros')\n    assert (conf['kernel_regularizer'] == None)\n    assert (conf['bias_regularizer'] == None)\n    assert (conf['kernel_constraint'] == None)\n    assert (conf['bias_constraint'] == None)", "ground_truth": "'concat'", "quality_analysis": {"complexity_score": 6, "left_complexity": 5, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_644", "reponame": "stellargraph", "testpath": "tests/layer/test_graph_attention.py", "testname": "test_graph_attention.py", "classname": "Test_GraphAttention", "funcname": "test_layer_config", "imports": ["import pytest", "import scipy.sparse as sps", "import tensorflow as tf", "from tensorflow import keras", "from tensorflow.keras import backend as K", "from tensorflow.keras.layers import Input", "from stellargraph.mapper import FullBatchNodeGenerator, FullBatchLinkGenerator, GraphSAGENodeGenerator", "from stellargraph.layer import *", "from ..test_utils.graphs import example_graph", "from .. import test_utils"], "code": "def test_layer_config(self):\n    layer = self.layer(units=self.F_out, attn_heads=self.attn_heads, attn_heads_reduction='concat', activation=self.activation)\n    conf = layer.get_config()\n    assert (conf['units'] == self.F_out)\n    assert (conf['attn_heads'] == self.attn_heads)\n    assert (conf['attn_heads_reduction'] == 'concat')\n    assert (conf['activation'] == self.activation)\n    assert (conf['use_bias'] == True)\n    assert (conf['kernel_initializer']['class_name'] == 'GlorotUniform')\n    assert (conf['bias_initializer']['class_name'] == 'Zeros')\n    assert (conf['kernel_regularizer'] == None)\n    assert (conf['bias_regularizer'] == None)\n    assert (conf['kernel_constraint'] == None)\n    assert (conf['bias_constraint'] == None)", "masked_code": "def test_layer_config(self):\n    layer = self.layer(units=self.F_out, attn_heads=self.attn_heads, attn_heads_reduction='concat', activation=self.activation)\n    conf = layer.get_config()\n    assert (conf['units'] == self.F_out)\n    assert (conf['attn_heads'] == self.attn_heads)\n    assert (conf['attn_heads_reduction'] == 'concat')\n    assert (conf['activation'] == '???')\n    assert (conf['use_bias'] == True)\n    assert (conf['kernel_initializer']['class_name'] == 'GlorotUniform')\n    assert (conf['bias_initializer']['class_name'] == 'Zeros')\n    assert (conf['kernel_regularizer'] == None)\n    assert (conf['bias_regularizer'] == None)\n    assert (conf['kernel_constraint'] == None)\n    assert (conf['bias_constraint'] == None)", "ground_truth": "self.activation", "quality_analysis": {"complexity_score": 7, "left_complexity": 5, "right_complexity": 2, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_645", "reponame": "stellargraph", "testpath": "tests/layer/test_graph_attention.py", "testname": "test_graph_attention.py", "classname": "Test_GraphAttention", "funcname": "test_layer_config", "imports": ["import pytest", "import scipy.sparse as sps", "import tensorflow as tf", "from tensorflow import keras", "from tensorflow.keras import backend as K", "from tensorflow.keras.layers import Input", "from stellargraph.mapper import FullBatchNodeGenerator, FullBatchLinkGenerator, GraphSAGENodeGenerator", "from stellargraph.layer import *", "from ..test_utils.graphs import example_graph", "from .. import test_utils"], "code": "def test_layer_config(self):\n    layer = self.layer(units=self.F_out, attn_heads=self.attn_heads, attn_heads_reduction='concat', activation=self.activation)\n    conf = layer.get_config()\n    assert (conf['units'] == self.F_out)\n    assert (conf['attn_heads'] == self.attn_heads)\n    assert (conf['attn_heads_reduction'] == 'concat')\n    assert (conf['activation'] == self.activation)\n    assert (conf['use_bias'] == True)\n    assert (conf['kernel_initializer']['class_name'] == 'GlorotUniform')\n    assert (conf['bias_initializer']['class_name'] == 'Zeros')\n    assert (conf['kernel_regularizer'] == None)\n    assert (conf['bias_regularizer'] == None)\n    assert (conf['kernel_constraint'] == None)\n    assert (conf['bias_constraint'] == None)", "masked_code": "def test_layer_config(self):\n    layer = self.layer(units=self.F_out, attn_heads=self.attn_heads, attn_heads_reduction='concat', activation=self.activation)\n    conf = layer.get_config()\n    assert (conf['units'] == self.F_out)\n    assert (conf['attn_heads'] == self.attn_heads)\n    assert (conf['attn_heads_reduction'] == 'concat')\n    assert (conf['activation'] == self.activation)\n    assert (conf['use_bias'] == True)\n    assert (conf['kernel_initializer']['class_name'] == '???')\n    assert (conf['bias_initializer']['class_name'] == 'Zeros')\n    assert (conf['kernel_regularizer'] == None)\n    assert (conf['bias_regularizer'] == None)\n    assert (conf['kernel_constraint'] == None)\n    assert (conf['bias_constraint'] == None)", "ground_truth": "'GlorotUniform'", "quality_analysis": {"complexity_score": 10, "left_complexity": 9, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_646", "reponame": "stellargraph", "testpath": "tests/layer/test_graph_attention.py", "testname": "test_graph_attention.py", "classname": "Test_GraphAttention", "funcname": "test_layer_config", "imports": ["import pytest", "import scipy.sparse as sps", "import tensorflow as tf", "from tensorflow import keras", "from tensorflow.keras import backend as K", "from tensorflow.keras.layers import Input", "from stellargraph.mapper import FullBatchNodeGenerator, FullBatchLinkGenerator, GraphSAGENodeGenerator", "from stellargraph.layer import *", "from ..test_utils.graphs import example_graph", "from .. import test_utils"], "code": "def test_layer_config(self):\n    layer = self.layer(units=self.F_out, attn_heads=self.attn_heads, attn_heads_reduction='concat', activation=self.activation)\n    conf = layer.get_config()\n    assert (conf['units'] == self.F_out)\n    assert (conf['attn_heads'] == self.attn_heads)\n    assert (conf['attn_heads_reduction'] == 'concat')\n    assert (conf['activation'] == self.activation)\n    assert (conf['use_bias'] == True)\n    assert (conf['kernel_initializer']['class_name'] == 'GlorotUniform')\n    assert (conf['bias_initializer']['class_name'] == 'Zeros')\n    assert (conf['kernel_regularizer'] == None)\n    assert (conf['bias_regularizer'] == None)\n    assert (conf['kernel_constraint'] == None)\n    assert (conf['bias_constraint'] == None)", "masked_code": "def test_layer_config(self):\n    layer = self.layer(units=self.F_out, attn_heads=self.attn_heads, attn_heads_reduction='concat', activation=self.activation)\n    conf = layer.get_config()\n    assert (conf['units'] == self.F_out)\n    assert (conf['attn_heads'] == self.attn_heads)\n    assert (conf['attn_heads_reduction'] == 'concat')\n    assert (conf['activation'] == self.activation)\n    assert (conf['use_bias'] == True)\n    assert (conf['kernel_initializer']['class_name'] == 'GlorotUniform')\n    assert (conf['bias_initializer']['class_name'] == '???')\n    assert (conf['kernel_regularizer'] == None)\n    assert (conf['bias_regularizer'] == None)\n    assert (conf['kernel_constraint'] == None)\n    assert (conf['bias_constraint'] == None)", "ground_truth": "'Zeros'", "quality_analysis": {"complexity_score": 10, "left_complexity": 9, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_647", "reponame": "stellargraph", "testpath": "tests/layer/test_graph_attention.py", "testname": "test_graph_attention.py", "classname": "Test_GraphAttention", "funcname": "test_layer_config", "imports": ["import pytest", "import scipy.sparse as sps", "import tensorflow as tf", "from tensorflow import keras", "from tensorflow.keras import backend as K", "from tensorflow.keras.layers import Input", "from stellargraph.mapper import FullBatchNodeGenerator, FullBatchLinkGenerator, GraphSAGENodeGenerator", "from stellargraph.layer import *", "from ..test_utils.graphs import example_graph", "from .. import test_utils"], "code": "def test_layer_config(self):\n    layer = self.layer(units=self.F_out, attn_heads=self.attn_heads, attn_heads_reduction='concat', activation=self.activation)\n    conf = layer.get_config()\n    assert (conf['units'] == self.F_out)\n    assert (conf['attn_heads'] == self.attn_heads)\n    assert (conf['attn_heads_reduction'] == 'concat')\n    assert (conf['activation'] == self.activation)\n    assert (conf['use_bias'] == True)\n    assert (conf['kernel_initializer']['class_name'] == 'GlorotUniform')\n    assert (conf['bias_initializer']['class_name'] == 'Zeros')\n    assert (conf['kernel_regularizer'] == None)\n    assert (conf['bias_regularizer'] == None)\n    assert (conf['kernel_constraint'] == None)\n    assert (conf['bias_constraint'] == None)", "masked_code": "def test_layer_config(self):\n    layer = self.layer(units=self.F_out, attn_heads=self.attn_heads, attn_heads_reduction='concat', activation=self.activation)\n    conf = layer.get_config()\n    assert (conf['units'] == self.F_out)\n    assert (conf['attn_heads'] == self.attn_heads)\n    assert (conf['attn_heads_reduction'] == 'concat')\n    assert (conf['activation'] == self.activation)\n    assert (conf['use_bias'] == True)\n    assert (conf['kernel_initializer']['class_name'] == 'GlorotUniform')\n    assert (conf['bias_initializer']['class_name'] == 'Zeros')\n    assert (conf['kernel_regularizer'] == '???')\n    assert (conf['bias_regularizer'] == None)\n    assert (conf['kernel_constraint'] == None)\n    assert (conf['bias_constraint'] == None)", "ground_truth": "None", "quality_analysis": {"complexity_score": 6, "left_complexity": 5, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_648", "reponame": "stellargraph", "testpath": "tests/layer/test_graph_attention.py", "testname": "test_graph_attention.py", "classname": "Test_GraphAttention", "funcname": "test_layer_config", "imports": ["import pytest", "import scipy.sparse as sps", "import tensorflow as tf", "from tensorflow import keras", "from tensorflow.keras import backend as K", "from tensorflow.keras.layers import Input", "from stellargraph.mapper import FullBatchNodeGenerator, FullBatchLinkGenerator, GraphSAGENodeGenerator", "from stellargraph.layer import *", "from ..test_utils.graphs import example_graph", "from .. import test_utils"], "code": "def test_layer_config(self):\n    layer = self.layer(units=self.F_out, attn_heads=self.attn_heads, attn_heads_reduction='concat', activation=self.activation)\n    conf = layer.get_config()\n    assert (conf['units'] == self.F_out)\n    assert (conf['attn_heads'] == self.attn_heads)\n    assert (conf['attn_heads_reduction'] == 'concat')\n    assert (conf['activation'] == self.activation)\n    assert (conf['use_bias'] == True)\n    assert (conf['kernel_initializer']['class_name'] == 'GlorotUniform')\n    assert (conf['bias_initializer']['class_name'] == 'Zeros')\n    assert (conf['kernel_regularizer'] == None)\n    assert (conf['bias_regularizer'] == None)\n    assert (conf['kernel_constraint'] == None)\n    assert (conf['bias_constraint'] == None)", "masked_code": "def test_layer_config(self):\n    layer = self.layer(units=self.F_out, attn_heads=self.attn_heads, attn_heads_reduction='concat', activation=self.activation)\n    conf = layer.get_config()\n    assert (conf['units'] == self.F_out)\n    assert (conf['attn_heads'] == self.attn_heads)\n    assert (conf['attn_heads_reduction'] == 'concat')\n    assert (conf['activation'] == self.activation)\n    assert (conf['use_bias'] == True)\n    assert (conf['kernel_initializer']['class_name'] == 'GlorotUniform')\n    assert (conf['bias_initializer']['class_name'] == 'Zeros')\n    assert (conf['kernel_regularizer'] == None)\n    assert (conf['bias_regularizer'] == '???')\n    assert (conf['kernel_constraint'] == None)\n    assert (conf['bias_constraint'] == None)", "ground_truth": "None", "quality_analysis": {"complexity_score": 6, "left_complexity": 5, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_649", "reponame": "stellargraph", "testpath": "tests/layer/test_graph_attention.py", "testname": "test_graph_attention.py", "classname": "Test_GraphAttention", "funcname": "test_layer_config", "imports": ["import pytest", "import scipy.sparse as sps", "import tensorflow as tf", "from tensorflow import keras", "from tensorflow.keras import backend as K", "from tensorflow.keras.layers import Input", "from stellargraph.mapper import FullBatchNodeGenerator, FullBatchLinkGenerator, GraphSAGENodeGenerator", "from stellargraph.layer import *", "from ..test_utils.graphs import example_graph", "from .. import test_utils"], "code": "def test_layer_config(self):\n    layer = self.layer(units=self.F_out, attn_heads=self.attn_heads, attn_heads_reduction='concat', activation=self.activation)\n    conf = layer.get_config()\n    assert (conf['units'] == self.F_out)\n    assert (conf['attn_heads'] == self.attn_heads)\n    assert (conf['attn_heads_reduction'] == 'concat')\n    assert (conf['activation'] == self.activation)\n    assert (conf['use_bias'] == True)\n    assert (conf['kernel_initializer']['class_name'] == 'GlorotUniform')\n    assert (conf['bias_initializer']['class_name'] == 'Zeros')\n    assert (conf['kernel_regularizer'] == None)\n    assert (conf['bias_regularizer'] == None)\n    assert (conf['kernel_constraint'] == None)\n    assert (conf['bias_constraint'] == None)", "masked_code": "def test_layer_config(self):\n    layer = self.layer(units=self.F_out, attn_heads=self.attn_heads, attn_heads_reduction='concat', activation=self.activation)\n    conf = layer.get_config()\n    assert (conf['units'] == self.F_out)\n    assert (conf['attn_heads'] == self.attn_heads)\n    assert (conf['attn_heads_reduction'] == 'concat')\n    assert (conf['activation'] == self.activation)\n    assert (conf['use_bias'] == True)\n    assert (conf['kernel_initializer']['class_name'] == 'GlorotUniform')\n    assert (conf['bias_initializer']['class_name'] == 'Zeros')\n    assert (conf['kernel_regularizer'] == None)\n    assert (conf['bias_regularizer'] == None)\n    assert (conf['kernel_constraint'] == '???')\n    assert (conf['bias_constraint'] == None)", "ground_truth": "None", "quality_analysis": {"complexity_score": 6, "left_complexity": 5, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_650", "reponame": "stellargraph", "testpath": "tests/layer/test_graph_attention.py", "testname": "test_graph_attention.py", "classname": "Test_GraphAttention", "funcname": "test_layer_config", "imports": ["import pytest", "import scipy.sparse as sps", "import tensorflow as tf", "from tensorflow import keras", "from tensorflow.keras import backend as K", "from tensorflow.keras.layers import Input", "from stellargraph.mapper import FullBatchNodeGenerator, FullBatchLinkGenerator, GraphSAGENodeGenerator", "from stellargraph.layer import *", "from ..test_utils.graphs import example_graph", "from .. import test_utils"], "code": "def test_layer_config(self):\n    layer = self.layer(units=self.F_out, attn_heads=self.attn_heads, attn_heads_reduction='concat', activation=self.activation)\n    conf = layer.get_config()\n    assert (conf['units'] == self.F_out)\n    assert (conf['attn_heads'] == self.attn_heads)\n    assert (conf['attn_heads_reduction'] == 'concat')\n    assert (conf['activation'] == self.activation)\n    assert (conf['use_bias'] == True)\n    assert (conf['kernel_initializer']['class_name'] == 'GlorotUniform')\n    assert (conf['bias_initializer']['class_name'] == 'Zeros')\n    assert (conf['kernel_regularizer'] == None)\n    assert (conf['bias_regularizer'] == None)\n    assert (conf['kernel_constraint'] == None)\n    assert (conf['bias_constraint'] == None)", "masked_code": "def test_layer_config(self):\n    layer = self.layer(units=self.F_out, attn_heads=self.attn_heads, attn_heads_reduction='concat', activation=self.activation)\n    conf = layer.get_config()\n    assert (conf['units'] == self.F_out)\n    assert (conf['attn_heads'] == self.attn_heads)\n    assert (conf['attn_heads_reduction'] == 'concat')\n    assert (conf['activation'] == self.activation)\n    assert (conf['use_bias'] == True)\n    assert (conf['kernel_initializer']['class_name'] == 'GlorotUniform')\n    assert (conf['bias_initializer']['class_name'] == 'Zeros')\n    assert (conf['kernel_regularizer'] == None)\n    assert (conf['bias_regularizer'] == None)\n    assert (conf['kernel_constraint'] == None)\n    assert (conf['bias_constraint'] == '???')", "ground_truth": "None", "quality_analysis": {"complexity_score": 6, "left_complexity": 5, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_651", "reponame": "stellargraph", "testpath": "tests/layer/test_graph_attention.py", "testname": "test_graph_attention.py", "classname": "Test_GAT", "funcname": "test_constructor", "imports": ["import pytest", "import scipy.sparse as sps", "import tensorflow as tf", "from tensorflow import keras", "from tensorflow.keras import backend as K", "from tensorflow.keras.layers import Input", "from stellargraph.mapper import FullBatchNodeGenerator, FullBatchLinkGenerator, GraphSAGENodeGenerator", "from stellargraph.layer import *", "from ..test_utils.graphs import example_graph", "from .. import test_utils"], "code": "def test_constructor(self):\n    G = example_graph(feature_size=self.F_in)\n    gen = FullBatchNodeGenerator(G, sparse=self.sparse, method=self.method)\n    gat = GAT(layer_sizes=self.layer_sizes, generator=gen, bias=True)\n    assert (gat.activations == ['elu', 'elu'])\n    with pytest.raises(ValueError):\n        gat = GAT(layer_sizes=[10], activations=self.activations, generator=gen)\n    with pytest.raises(ValueError):\n        gat = GAT(layer_sizes=[10, 10], activations=['relu'], generator=gen)\n    with pytest.raises(TypeError):\n        gat = GAT(layer_sizes=10, activations=self.activations, attn_heads=self.attn_heads, generator=gen, bias=True)\n    with pytest.raises(ValueError):\n        gat = GAT(layer_sizes=[4, 0], activations=self.activations, attn_heads=self.attn_heads, generator=gen, bias=True)\n    with pytest.raises(ValueError):\n        gat = GAT(layer_sizes=self.layer_sizes, activations=self.activations, attn_heads=[8, 8, 1], generator=gen, bias=True)\n    with pytest.raises(ValueError):\n        gat = GAT(layer_sizes=self.layer_sizes, activations=self.activations, attn_heads=[8, 0], generator=gen, bias=True)\n    with pytest.raises(TypeError):\n        gat = GAT(layer_sizes=self.layer_sizes, activations=self.activations, attn_heads=8.0, generator=gen, bias=True)\n    with pytest.raises(TypeError):\n        gat = GAT(layer_sizes=self.layer_sizes, activations='relu', generator=gen, bias=True)\n    with pytest.raises(TypeError):\n        gat = GAT(layer_sizes=self.layer_sizes, activations=self.activations, attn_heads=self.attn_heads, attn_heads_reduction='concat', generator=gen, bias=True)\n    with pytest.raises(ValueError):\n        gat = GAT(layer_sizes=self.layer_sizes, activations=self.activations, attn_heads=self.attn_heads, attn_heads_reduction=['concat', 'concat', 'average'], generator=gen, bias=True)\n    with pytest.raises(ValueError):\n        gat = GAT(layer_sizes=self.layer_sizes, activations=self.activations, attn_heads=self.attn_heads, attn_heads_reduction=['concat', 'sum'], generator=gen, bias=True)\n    with pytest.raises(ValueError):\n        gat = GAT(layer_sizes=self.layer_sizes, activations=['relu'], generator=gen, bias=True)\n    gat = GAT(layer_sizes=self.layer_sizes, activations=self.activations, attn_heads=self.attn_heads, generator=gen, bias=True)\n    assert (gat.activations == self.activations)\n    assert (gat.attn_heads_reduction == ['concat', 'average'])\n    assert (gat.generator == gen)\n    gat = GAT(layer_sizes=self.layer_sizes, activations=self.activations, attn_heads=self.attn_heads, attn_heads_reduction=['concat', 'concat'], generator=gen, bias=True)\n    assert (gat.attn_heads_reduction == ['concat', 'concat'])", "masked_code": "def test_constructor(self):\n    G = example_graph(feature_size=self.F_in)\n    gen = FullBatchNodeGenerator(G, sparse=self.sparse, method=self.method)\n    gat = GAT(layer_sizes=self.layer_sizes, generator=gen, bias=True)\n    assert (gat.activations == '???')\n    with pytest.raises(ValueError):\n        gat = GAT(layer_sizes=[10], activations=self.activations, generator=gen)\n    with pytest.raises(ValueError):\n        gat = GAT(layer_sizes=[10, 10], activations=['relu'], generator=gen)\n    with pytest.raises(TypeError):\n        gat = GAT(layer_sizes=10, activations=self.activations, attn_heads=self.attn_heads, generator=gen, bias=True)\n    with pytest.raises(ValueError):\n        gat = GAT(layer_sizes=[4, 0], activations=self.activations, attn_heads=self.attn_heads, generator=gen, bias=True)\n    with pytest.raises(ValueError):\n        gat = GAT(layer_sizes=self.layer_sizes, activations=self.activations, attn_heads=[8, 8, 1], generator=gen, bias=True)\n    with pytest.raises(ValueError):\n        gat = GAT(layer_sizes=self.layer_sizes, activations=self.activations, attn_heads=[8, 0], generator=gen, bias=True)\n    with pytest.raises(TypeError):\n        gat = GAT(layer_sizes=self.layer_sizes, activations=self.activations, attn_heads=8.0, generator=gen, bias=True)\n    with pytest.raises(TypeError):\n        gat = GAT(layer_sizes=self.layer_sizes, activations='relu', generator=gen, bias=True)\n    with pytest.raises(TypeError):\n        gat = GAT(layer_sizes=self.layer_sizes, activations=self.activations, attn_heads=self.attn_heads, attn_heads_reduction='concat', generator=gen, bias=True)\n    with pytest.raises(ValueError):\n        gat = GAT(layer_sizes=self.layer_sizes, activations=self.activations, attn_heads=self.attn_heads, attn_heads_reduction=['concat', 'concat', 'average'], generator=gen, bias=True)\n    with pytest.raises(ValueError):\n        gat = GAT(layer_sizes=self.layer_sizes, activations=self.activations, attn_heads=self.attn_heads, attn_heads_reduction=['concat', 'sum'], generator=gen, bias=True)\n    with pytest.raises(ValueError):\n        gat = GAT(layer_sizes=self.layer_sizes, activations=['relu'], generator=gen, bias=True)\n    gat = GAT(layer_sizes=self.layer_sizes, activations=self.activations, attn_heads=self.attn_heads, generator=gen, bias=True)\n    assert (gat.activations == self.activations)\n    assert (gat.attn_heads_reduction == ['concat', 'average'])\n    assert (gat.generator == gen)\n    gat = GAT(layer_sizes=self.layer_sizes, activations=self.activations, attn_heads=self.attn_heads, attn_heads_reduction=['concat', 'concat'], generator=gen, bias=True)\n    assert (gat.attn_heads_reduction == ['concat', 'concat'])", "ground_truth": "['elu', 'elu']", "quality_analysis": {"complexity_score": 6, "left_complexity": 2, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_652", "reponame": "stellargraph", "testpath": "tests/layer/test_graph_attention.py", "testname": "test_graph_attention.py", "classname": "Test_GAT", "funcname": "test_constructor", "imports": ["import pytest", "import scipy.sparse as sps", "import tensorflow as tf", "from tensorflow import keras", "from tensorflow.keras import backend as K", "from tensorflow.keras.layers import Input", "from stellargraph.mapper import FullBatchNodeGenerator, FullBatchLinkGenerator, GraphSAGENodeGenerator", "from stellargraph.layer import *", "from ..test_utils.graphs import example_graph", "from .. import test_utils"], "code": "def test_constructor(self):\n    G = example_graph(feature_size=self.F_in)\n    gen = FullBatchNodeGenerator(G, sparse=self.sparse, method=self.method)\n    gat = GAT(layer_sizes=self.layer_sizes, generator=gen, bias=True)\n    assert (gat.activations == ['elu', 'elu'])\n    with pytest.raises(ValueError):\n        gat = GAT(layer_sizes=[10], activations=self.activations, generator=gen)\n    with pytest.raises(ValueError):\n        gat = GAT(layer_sizes=[10, 10], activations=['relu'], generator=gen)\n    with pytest.raises(TypeError):\n        gat = GAT(layer_sizes=10, activations=self.activations, attn_heads=self.attn_heads, generator=gen, bias=True)\n    with pytest.raises(ValueError):\n        gat = GAT(layer_sizes=[4, 0], activations=self.activations, attn_heads=self.attn_heads, generator=gen, bias=True)\n    with pytest.raises(ValueError):\n        gat = GAT(layer_sizes=self.layer_sizes, activations=self.activations, attn_heads=[8, 8, 1], generator=gen, bias=True)\n    with pytest.raises(ValueError):\n        gat = GAT(layer_sizes=self.layer_sizes, activations=self.activations, attn_heads=[8, 0], generator=gen, bias=True)\n    with pytest.raises(TypeError):\n        gat = GAT(layer_sizes=self.layer_sizes, activations=self.activations, attn_heads=8.0, generator=gen, bias=True)\n    with pytest.raises(TypeError):\n        gat = GAT(layer_sizes=self.layer_sizes, activations='relu', generator=gen, bias=True)\n    with pytest.raises(TypeError):\n        gat = GAT(layer_sizes=self.layer_sizes, activations=self.activations, attn_heads=self.attn_heads, attn_heads_reduction='concat', generator=gen, bias=True)\n    with pytest.raises(ValueError):\n        gat = GAT(layer_sizes=self.layer_sizes, activations=self.activations, attn_heads=self.attn_heads, attn_heads_reduction=['concat', 'concat', 'average'], generator=gen, bias=True)\n    with pytest.raises(ValueError):\n        gat = GAT(layer_sizes=self.layer_sizes, activations=self.activations, attn_heads=self.attn_heads, attn_heads_reduction=['concat', 'sum'], generator=gen, bias=True)\n    with pytest.raises(ValueError):\n        gat = GAT(layer_sizes=self.layer_sizes, activations=['relu'], generator=gen, bias=True)\n    gat = GAT(layer_sizes=self.layer_sizes, activations=self.activations, attn_heads=self.attn_heads, generator=gen, bias=True)\n    assert (gat.activations == self.activations)\n    assert (gat.attn_heads_reduction == ['concat', 'average'])\n    assert (gat.generator == gen)\n    gat = GAT(layer_sizes=self.layer_sizes, activations=self.activations, attn_heads=self.attn_heads, attn_heads_reduction=['concat', 'concat'], generator=gen, bias=True)\n    assert (gat.attn_heads_reduction == ['concat', 'concat'])", "masked_code": "def test_constructor(self):\n    G = example_graph(feature_size=self.F_in)\n    gen = FullBatchNodeGenerator(G, sparse=self.sparse, method=self.method)\n    gat = GAT(layer_sizes=self.layer_sizes, generator=gen, bias=True)\n    assert (gat.activations == ['elu', 'elu'])\n    with pytest.raises(ValueError):\n        gat = GAT(layer_sizes=[10], activations=self.activations, generator=gen)\n    with pytest.raises(ValueError):\n        gat = GAT(layer_sizes=[10, 10], activations=['relu'], generator=gen)\n    with pytest.raises(TypeError):\n        gat = GAT(layer_sizes=10, activations=self.activations, attn_heads=self.attn_heads, generator=gen, bias=True)\n    with pytest.raises(ValueError):\n        gat = GAT(layer_sizes=[4, 0], activations=self.activations, attn_heads=self.attn_heads, generator=gen, bias=True)\n    with pytest.raises(ValueError):\n        gat = GAT(layer_sizes=self.layer_sizes, activations=self.activations, attn_heads=[8, 8, 1], generator=gen, bias=True)\n    with pytest.raises(ValueError):\n        gat = GAT(layer_sizes=self.layer_sizes, activations=self.activations, attn_heads=[8, 0], generator=gen, bias=True)\n    with pytest.raises(TypeError):\n        gat = GAT(layer_sizes=self.layer_sizes, activations=self.activations, attn_heads=8.0, generator=gen, bias=True)\n    with pytest.raises(TypeError):\n        gat = GAT(layer_sizes=self.layer_sizes, activations='relu', generator=gen, bias=True)\n    with pytest.raises(TypeError):\n        gat = GAT(layer_sizes=self.layer_sizes, activations=self.activations, attn_heads=self.attn_heads, attn_heads_reduction='concat', generator=gen, bias=True)\n    with pytest.raises(ValueError):\n        gat = GAT(layer_sizes=self.layer_sizes, activations=self.activations, attn_heads=self.attn_heads, attn_heads_reduction=['concat', 'concat', 'average'], generator=gen, bias=True)\n    with pytest.raises(ValueError):\n        gat = GAT(layer_sizes=self.layer_sizes, activations=self.activations, attn_heads=self.attn_heads, attn_heads_reduction=['concat', 'sum'], generator=gen, bias=True)\n    with pytest.raises(ValueError):\n        gat = GAT(layer_sizes=self.layer_sizes, activations=['relu'], generator=gen, bias=True)\n    gat = GAT(layer_sizes=self.layer_sizes, activations=self.activations, attn_heads=self.attn_heads, generator=gen, bias=True)\n    assert (gat.activations == '???')\n    assert (gat.attn_heads_reduction == ['concat', 'average'])\n    assert (gat.generator == gen)\n    gat = GAT(layer_sizes=self.layer_sizes, activations=self.activations, attn_heads=self.attn_heads, attn_heads_reduction=['concat', 'concat'], generator=gen, bias=True)\n    assert (gat.attn_heads_reduction == ['concat', 'concat'])", "ground_truth": "self.activations", "quality_analysis": {"complexity_score": 4, "left_complexity": 2, "right_complexity": 2, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_653", "reponame": "stellargraph", "testpath": "tests/layer/test_graph_attention.py", "testname": "test_graph_attention.py", "classname": "Test_GAT", "funcname": "test_constructor", "imports": ["import pytest", "import scipy.sparse as sps", "import tensorflow as tf", "from tensorflow import keras", "from tensorflow.keras import backend as K", "from tensorflow.keras.layers import Input", "from stellargraph.mapper import FullBatchNodeGenerator, FullBatchLinkGenerator, GraphSAGENodeGenerator", "from stellargraph.layer import *", "from ..test_utils.graphs import example_graph", "from .. import test_utils"], "code": "def test_constructor(self):\n    G = example_graph(feature_size=self.F_in)\n    gen = FullBatchNodeGenerator(G, sparse=self.sparse, method=self.method)\n    gat = GAT(layer_sizes=self.layer_sizes, generator=gen, bias=True)\n    assert (gat.activations == ['elu', 'elu'])\n    with pytest.raises(ValueError):\n        gat = GAT(layer_sizes=[10], activations=self.activations, generator=gen)\n    with pytest.raises(ValueError):\n        gat = GAT(layer_sizes=[10, 10], activations=['relu'], generator=gen)\n    with pytest.raises(TypeError):\n        gat = GAT(layer_sizes=10, activations=self.activations, attn_heads=self.attn_heads, generator=gen, bias=True)\n    with pytest.raises(ValueError):\n        gat = GAT(layer_sizes=[4, 0], activations=self.activations, attn_heads=self.attn_heads, generator=gen, bias=True)\n    with pytest.raises(ValueError):\n        gat = GAT(layer_sizes=self.layer_sizes, activations=self.activations, attn_heads=[8, 8, 1], generator=gen, bias=True)\n    with pytest.raises(ValueError):\n        gat = GAT(layer_sizes=self.layer_sizes, activations=self.activations, attn_heads=[8, 0], generator=gen, bias=True)\n    with pytest.raises(TypeError):\n        gat = GAT(layer_sizes=self.layer_sizes, activations=self.activations, attn_heads=8.0, generator=gen, bias=True)\n    with pytest.raises(TypeError):\n        gat = GAT(layer_sizes=self.layer_sizes, activations='relu', generator=gen, bias=True)\n    with pytest.raises(TypeError):\n        gat = GAT(layer_sizes=self.layer_sizes, activations=self.activations, attn_heads=self.attn_heads, attn_heads_reduction='concat', generator=gen, bias=True)\n    with pytest.raises(ValueError):\n        gat = GAT(layer_sizes=self.layer_sizes, activations=self.activations, attn_heads=self.attn_heads, attn_heads_reduction=['concat', 'concat', 'average'], generator=gen, bias=True)\n    with pytest.raises(ValueError):\n        gat = GAT(layer_sizes=self.layer_sizes, activations=self.activations, attn_heads=self.attn_heads, attn_heads_reduction=['concat', 'sum'], generator=gen, bias=True)\n    with pytest.raises(ValueError):\n        gat = GAT(layer_sizes=self.layer_sizes, activations=['relu'], generator=gen, bias=True)\n    gat = GAT(layer_sizes=self.layer_sizes, activations=self.activations, attn_heads=self.attn_heads, generator=gen, bias=True)\n    assert (gat.activations == self.activations)\n    assert (gat.attn_heads_reduction == ['concat', 'average'])\n    assert (gat.generator == gen)\n    gat = GAT(layer_sizes=self.layer_sizes, activations=self.activations, attn_heads=self.attn_heads, attn_heads_reduction=['concat', 'concat'], generator=gen, bias=True)\n    assert (gat.attn_heads_reduction == ['concat', 'concat'])", "masked_code": "def test_constructor(self):\n    G = example_graph(feature_size=self.F_in)\n    gen = FullBatchNodeGenerator(G, sparse=self.sparse, method=self.method)\n    gat = GAT(layer_sizes=self.layer_sizes, generator=gen, bias=True)\n    assert (gat.activations == ['elu', 'elu'])\n    with pytest.raises(ValueError):\n        gat = GAT(layer_sizes=[10], activations=self.activations, generator=gen)\n    with pytest.raises(ValueError):\n        gat = GAT(layer_sizes=[10, 10], activations=['relu'], generator=gen)\n    with pytest.raises(TypeError):\n        gat = GAT(layer_sizes=10, activations=self.activations, attn_heads=self.attn_heads, generator=gen, bias=True)\n    with pytest.raises(ValueError):\n        gat = GAT(layer_sizes=[4, 0], activations=self.activations, attn_heads=self.attn_heads, generator=gen, bias=True)\n    with pytest.raises(ValueError):\n        gat = GAT(layer_sizes=self.layer_sizes, activations=self.activations, attn_heads=[8, 8, 1], generator=gen, bias=True)\n    with pytest.raises(ValueError):\n        gat = GAT(layer_sizes=self.layer_sizes, activations=self.activations, attn_heads=[8, 0], generator=gen, bias=True)\n    with pytest.raises(TypeError):\n        gat = GAT(layer_sizes=self.layer_sizes, activations=self.activations, attn_heads=8.0, generator=gen, bias=True)\n    with pytest.raises(TypeError):\n        gat = GAT(layer_sizes=self.layer_sizes, activations='relu', generator=gen, bias=True)\n    with pytest.raises(TypeError):\n        gat = GAT(layer_sizes=self.layer_sizes, activations=self.activations, attn_heads=self.attn_heads, attn_heads_reduction='concat', generator=gen, bias=True)\n    with pytest.raises(ValueError):\n        gat = GAT(layer_sizes=self.layer_sizes, activations=self.activations, attn_heads=self.attn_heads, attn_heads_reduction=['concat', 'concat', 'average'], generator=gen, bias=True)\n    with pytest.raises(ValueError):\n        gat = GAT(layer_sizes=self.layer_sizes, activations=self.activations, attn_heads=self.attn_heads, attn_heads_reduction=['concat', 'sum'], generator=gen, bias=True)\n    with pytest.raises(ValueError):\n        gat = GAT(layer_sizes=self.layer_sizes, activations=['relu'], generator=gen, bias=True)\n    gat = GAT(layer_sizes=self.layer_sizes, activations=self.activations, attn_heads=self.attn_heads, generator=gen, bias=True)\n    assert (gat.activations == self.activations)\n    assert (gat.attn_heads_reduction == '???')\n    assert (gat.generator == gen)\n    gat = GAT(layer_sizes=self.layer_sizes, activations=self.activations, attn_heads=self.attn_heads, attn_heads_reduction=['concat', 'concat'], generator=gen, bias=True)\n    assert (gat.attn_heads_reduction == ['concat', 'concat'])", "ground_truth": "['concat', 'average']", "quality_analysis": {"complexity_score": 6, "left_complexity": 2, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_654", "reponame": "stellargraph", "testpath": "tests/layer/test_graph_attention.py", "testname": "test_graph_attention.py", "classname": "Test_GAT", "funcname": "test_constructor", "imports": ["import pytest", "import scipy.sparse as sps", "import tensorflow as tf", "from tensorflow import keras", "from tensorflow.keras import backend as K", "from tensorflow.keras.layers import Input", "from stellargraph.mapper import FullBatchNodeGenerator, FullBatchLinkGenerator, GraphSAGENodeGenerator", "from stellargraph.layer import *", "from ..test_utils.graphs import example_graph", "from .. import test_utils"], "code": "def test_constructor(self):\n    G = example_graph(feature_size=self.F_in)\n    gen = FullBatchNodeGenerator(G, sparse=self.sparse, method=self.method)\n    gat = GAT(layer_sizes=self.layer_sizes, generator=gen, bias=True)\n    assert (gat.activations == ['elu', 'elu'])\n    with pytest.raises(ValueError):\n        gat = GAT(layer_sizes=[10], activations=self.activations, generator=gen)\n    with pytest.raises(ValueError):\n        gat = GAT(layer_sizes=[10, 10], activations=['relu'], generator=gen)\n    with pytest.raises(TypeError):\n        gat = GAT(layer_sizes=10, activations=self.activations, attn_heads=self.attn_heads, generator=gen, bias=True)\n    with pytest.raises(ValueError):\n        gat = GAT(layer_sizes=[4, 0], activations=self.activations, attn_heads=self.attn_heads, generator=gen, bias=True)\n    with pytest.raises(ValueError):\n        gat = GAT(layer_sizes=self.layer_sizes, activations=self.activations, attn_heads=[8, 8, 1], generator=gen, bias=True)\n    with pytest.raises(ValueError):\n        gat = GAT(layer_sizes=self.layer_sizes, activations=self.activations, attn_heads=[8, 0], generator=gen, bias=True)\n    with pytest.raises(TypeError):\n        gat = GAT(layer_sizes=self.layer_sizes, activations=self.activations, attn_heads=8.0, generator=gen, bias=True)\n    with pytest.raises(TypeError):\n        gat = GAT(layer_sizes=self.layer_sizes, activations='relu', generator=gen, bias=True)\n    with pytest.raises(TypeError):\n        gat = GAT(layer_sizes=self.layer_sizes, activations=self.activations, attn_heads=self.attn_heads, attn_heads_reduction='concat', generator=gen, bias=True)\n    with pytest.raises(ValueError):\n        gat = GAT(layer_sizes=self.layer_sizes, activations=self.activations, attn_heads=self.attn_heads, attn_heads_reduction=['concat', 'concat', 'average'], generator=gen, bias=True)\n    with pytest.raises(ValueError):\n        gat = GAT(layer_sizes=self.layer_sizes, activations=self.activations, attn_heads=self.attn_heads, attn_heads_reduction=['concat', 'sum'], generator=gen, bias=True)\n    with pytest.raises(ValueError):\n        gat = GAT(layer_sizes=self.layer_sizes, activations=['relu'], generator=gen, bias=True)\n    gat = GAT(layer_sizes=self.layer_sizes, activations=self.activations, attn_heads=self.attn_heads, generator=gen, bias=True)\n    assert (gat.activations == self.activations)\n    assert (gat.attn_heads_reduction == ['concat', 'average'])\n    assert (gat.generator == gen)\n    gat = GAT(layer_sizes=self.layer_sizes, activations=self.activations, attn_heads=self.attn_heads, attn_heads_reduction=['concat', 'concat'], generator=gen, bias=True)\n    assert (gat.attn_heads_reduction == ['concat', 'concat'])", "masked_code": "def test_constructor(self):\n    G = example_graph(feature_size=self.F_in)\n    gen = FullBatchNodeGenerator(G, sparse=self.sparse, method=self.method)\n    gat = GAT(layer_sizes=self.layer_sizes, generator=gen, bias=True)\n    assert (gat.activations == ['elu', 'elu'])\n    with pytest.raises(ValueError):\n        gat = GAT(layer_sizes=[10], activations=self.activations, generator=gen)\n    with pytest.raises(ValueError):\n        gat = GAT(layer_sizes=[10, 10], activations=['relu'], generator=gen)\n    with pytest.raises(TypeError):\n        gat = GAT(layer_sizes=10, activations=self.activations, attn_heads=self.attn_heads, generator=gen, bias=True)\n    with pytest.raises(ValueError):\n        gat = GAT(layer_sizes=[4, 0], activations=self.activations, attn_heads=self.attn_heads, generator=gen, bias=True)\n    with pytest.raises(ValueError):\n        gat = GAT(layer_sizes=self.layer_sizes, activations=self.activations, attn_heads=[8, 8, 1], generator=gen, bias=True)\n    with pytest.raises(ValueError):\n        gat = GAT(layer_sizes=self.layer_sizes, activations=self.activations, attn_heads=[8, 0], generator=gen, bias=True)\n    with pytest.raises(TypeError):\n        gat = GAT(layer_sizes=self.layer_sizes, activations=self.activations, attn_heads=8.0, generator=gen, bias=True)\n    with pytest.raises(TypeError):\n        gat = GAT(layer_sizes=self.layer_sizes, activations='relu', generator=gen, bias=True)\n    with pytest.raises(TypeError):\n        gat = GAT(layer_sizes=self.layer_sizes, activations=self.activations, attn_heads=self.attn_heads, attn_heads_reduction='concat', generator=gen, bias=True)\n    with pytest.raises(ValueError):\n        gat = GAT(layer_sizes=self.layer_sizes, activations=self.activations, attn_heads=self.attn_heads, attn_heads_reduction=['concat', 'concat', 'average'], generator=gen, bias=True)\n    with pytest.raises(ValueError):\n        gat = GAT(layer_sizes=self.layer_sizes, activations=self.activations, attn_heads=self.attn_heads, attn_heads_reduction=['concat', 'sum'], generator=gen, bias=True)\n    with pytest.raises(ValueError):\n        gat = GAT(layer_sizes=self.layer_sizes, activations=['relu'], generator=gen, bias=True)\n    gat = GAT(layer_sizes=self.layer_sizes, activations=self.activations, attn_heads=self.attn_heads, generator=gen, bias=True)\n    assert (gat.activations == self.activations)\n    assert (gat.attn_heads_reduction == ['concat', 'average'])\n    assert (gat.generator == '???')\n    gat = GAT(layer_sizes=self.layer_sizes, activations=self.activations, attn_heads=self.attn_heads, attn_heads_reduction=['concat', 'concat'], generator=gen, bias=True)\n    assert (gat.attn_heads_reduction == ['concat', 'concat'])", "ground_truth": "gen", "quality_analysis": {"complexity_score": 3, "left_complexity": 2, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_655", "reponame": "stellargraph", "testpath": "tests/layer/test_graph_attention.py", "testname": "test_graph_attention.py", "classname": "Test_GAT", "funcname": "test_constructor", "imports": ["import pytest", "import scipy.sparse as sps", "import tensorflow as tf", "from tensorflow import keras", "from tensorflow.keras import backend as K", "from tensorflow.keras.layers import Input", "from stellargraph.mapper import FullBatchNodeGenerator, FullBatchLinkGenerator, GraphSAGENodeGenerator", "from stellargraph.layer import *", "from ..test_utils.graphs import example_graph", "from .. import test_utils"], "code": "def test_constructor(self):\n    G = example_graph(feature_size=self.F_in)\n    gen = FullBatchNodeGenerator(G, sparse=self.sparse, method=self.method)\n    gat = GAT(layer_sizes=self.layer_sizes, generator=gen, bias=True)\n    assert (gat.activations == ['elu', 'elu'])\n    with pytest.raises(ValueError):\n        gat = GAT(layer_sizes=[10], activations=self.activations, generator=gen)\n    with pytest.raises(ValueError):\n        gat = GAT(layer_sizes=[10, 10], activations=['relu'], generator=gen)\n    with pytest.raises(TypeError):\n        gat = GAT(layer_sizes=10, activations=self.activations, attn_heads=self.attn_heads, generator=gen, bias=True)\n    with pytest.raises(ValueError):\n        gat = GAT(layer_sizes=[4, 0], activations=self.activations, attn_heads=self.attn_heads, generator=gen, bias=True)\n    with pytest.raises(ValueError):\n        gat = GAT(layer_sizes=self.layer_sizes, activations=self.activations, attn_heads=[8, 8, 1], generator=gen, bias=True)\n    with pytest.raises(ValueError):\n        gat = GAT(layer_sizes=self.layer_sizes, activations=self.activations, attn_heads=[8, 0], generator=gen, bias=True)\n    with pytest.raises(TypeError):\n        gat = GAT(layer_sizes=self.layer_sizes, activations=self.activations, attn_heads=8.0, generator=gen, bias=True)\n    with pytest.raises(TypeError):\n        gat = GAT(layer_sizes=self.layer_sizes, activations='relu', generator=gen, bias=True)\n    with pytest.raises(TypeError):\n        gat = GAT(layer_sizes=self.layer_sizes, activations=self.activations, attn_heads=self.attn_heads, attn_heads_reduction='concat', generator=gen, bias=True)\n    with pytest.raises(ValueError):\n        gat = GAT(layer_sizes=self.layer_sizes, activations=self.activations, attn_heads=self.attn_heads, attn_heads_reduction=['concat', 'concat', 'average'], generator=gen, bias=True)\n    with pytest.raises(ValueError):\n        gat = GAT(layer_sizes=self.layer_sizes, activations=self.activations, attn_heads=self.attn_heads, attn_heads_reduction=['concat', 'sum'], generator=gen, bias=True)\n    with pytest.raises(ValueError):\n        gat = GAT(layer_sizes=self.layer_sizes, activations=['relu'], generator=gen, bias=True)\n    gat = GAT(layer_sizes=self.layer_sizes, activations=self.activations, attn_heads=self.attn_heads, generator=gen, bias=True)\n    assert (gat.activations == self.activations)\n    assert (gat.attn_heads_reduction == ['concat', 'average'])\n    assert (gat.generator == gen)\n    gat = GAT(layer_sizes=self.layer_sizes, activations=self.activations, attn_heads=self.attn_heads, attn_heads_reduction=['concat', 'concat'], generator=gen, bias=True)\n    assert (gat.attn_heads_reduction == ['concat', 'concat'])", "masked_code": "def test_constructor(self):\n    G = example_graph(feature_size=self.F_in)\n    gen = FullBatchNodeGenerator(G, sparse=self.sparse, method=self.method)\n    gat = GAT(layer_sizes=self.layer_sizes, generator=gen, bias=True)\n    assert (gat.activations == ['elu', 'elu'])\n    with pytest.raises(ValueError):\n        gat = GAT(layer_sizes=[10], activations=self.activations, generator=gen)\n    with pytest.raises(ValueError):\n        gat = GAT(layer_sizes=[10, 10], activations=['relu'], generator=gen)\n    with pytest.raises(TypeError):\n        gat = GAT(layer_sizes=10, activations=self.activations, attn_heads=self.attn_heads, generator=gen, bias=True)\n    with pytest.raises(ValueError):\n        gat = GAT(layer_sizes=[4, 0], activations=self.activations, attn_heads=self.attn_heads, generator=gen, bias=True)\n    with pytest.raises(ValueError):\n        gat = GAT(layer_sizes=self.layer_sizes, activations=self.activations, attn_heads=[8, 8, 1], generator=gen, bias=True)\n    with pytest.raises(ValueError):\n        gat = GAT(layer_sizes=self.layer_sizes, activations=self.activations, attn_heads=[8, 0], generator=gen, bias=True)\n    with pytest.raises(TypeError):\n        gat = GAT(layer_sizes=self.layer_sizes, activations=self.activations, attn_heads=8.0, generator=gen, bias=True)\n    with pytest.raises(TypeError):\n        gat = GAT(layer_sizes=self.layer_sizes, activations='relu', generator=gen, bias=True)\n    with pytest.raises(TypeError):\n        gat = GAT(layer_sizes=self.layer_sizes, activations=self.activations, attn_heads=self.attn_heads, attn_heads_reduction='concat', generator=gen, bias=True)\n    with pytest.raises(ValueError):\n        gat = GAT(layer_sizes=self.layer_sizes, activations=self.activations, attn_heads=self.attn_heads, attn_heads_reduction=['concat', 'concat', 'average'], generator=gen, bias=True)\n    with pytest.raises(ValueError):\n        gat = GAT(layer_sizes=self.layer_sizes, activations=self.activations, attn_heads=self.attn_heads, attn_heads_reduction=['concat', 'sum'], generator=gen, bias=True)\n    with pytest.raises(ValueError):\n        gat = GAT(layer_sizes=self.layer_sizes, activations=['relu'], generator=gen, bias=True)\n    gat = GAT(layer_sizes=self.layer_sizes, activations=self.activations, attn_heads=self.attn_heads, generator=gen, bias=True)\n    assert (gat.activations == self.activations)\n    assert (gat.attn_heads_reduction == ['concat', 'average'])\n    assert (gat.generator == gen)\n    gat = GAT(layer_sizes=self.layer_sizes, activations=self.activations, attn_heads=self.attn_heads, attn_heads_reduction=['concat', 'concat'], generator=gen, bias=True)\n    assert (gat.attn_heads_reduction == '???')", "ground_truth": "['concat', 'concat']", "quality_analysis": {"complexity_score": 6, "left_complexity": 2, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_656", "reponame": "stellargraph", "testpath": "tests/layer/test_graph_attention.py", "testname": "test_graph_attention.py", "classname": "Test_GAT", "funcname": "test_gat_build_constructor", "imports": ["import pytest", "import scipy.sparse as sps", "import tensorflow as tf", "from tensorflow import keras", "from tensorflow.keras import backend as K", "from tensorflow.keras.layers import Input", "from stellargraph.mapper import FullBatchNodeGenerator, FullBatchLinkGenerator, GraphSAGENodeGenerator", "from stellargraph.layer import *", "from ..test_utils.graphs import example_graph", "from .. import test_utils"], "code": "def test_gat_build_constructor(self):\n    G = example_graph(feature_size=self.F_in)\n    gen = FullBatchNodeGenerator(G, sparse=self.sparse, method=self.method)\n    gat = GAT(layer_sizes=self.layer_sizes, activations=self.activations, attn_heads=self.attn_heads, generator=gen, bias=True)\n    assert (len(gat.in_out_tensors()) == 2)\n    (x_in, x_out) = gat.in_out_tensors()\n    assert ((len(x_in) == 4) if self.sparse else 3)\n    assert (int(x_in[0].shape[(- 1)]) == self.F_in)\n    assert (K.int_shape(x_in[(- 1)]) == (1, G.number_of_nodes(), G.number_of_nodes()))\n    assert (int(x_out.shape[(- 1)]) == self.layer_sizes[(- 1)])", "masked_code": "def test_gat_build_constructor(self):\n    G = example_graph(feature_size=self.F_in)\n    gen = FullBatchNodeGenerator(G, sparse=self.sparse, method=self.method)\n    gat = GAT(layer_sizes=self.layer_sizes, activations=self.activations, attn_heads=self.attn_heads, generator=gen, bias=True)\n    assert (len(gat.in_out_tensors()) == 2)\n    (x_in, x_out) = gat.in_out_tensors()\n    assert ((len(x_in) == 4) if self.sparse else 3)\n    assert (int(x_in[0].shape[(- 1)]) == '???')\n    assert (K.int_shape(x_in[(- 1)]) == (1, G.number_of_nodes(), G.number_of_nodes()))\n    assert (int(x_out.shape[(- 1)]) == self.layer_sizes[(- 1)])", "ground_truth": "self.F_in", "quality_analysis": {"complexity_score": 13, "left_complexity": 11, "right_complexity": 2, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_657", "reponame": "stellargraph", "testpath": "tests/layer/test_graph_attention.py", "testname": "test_graph_attention.py", "classname": "Test_GAT", "funcname": "test_gat_build_constructor", "imports": ["import pytest", "import scipy.sparse as sps", "import tensorflow as tf", "from tensorflow import keras", "from tensorflow.keras import backend as K", "from tensorflow.keras.layers import Input", "from stellargraph.mapper import FullBatchNodeGenerator, FullBatchLinkGenerator, GraphSAGENodeGenerator", "from stellargraph.layer import *", "from ..test_utils.graphs import example_graph", "from .. import test_utils"], "code": "def test_gat_build_constructor(self):\n    G = example_graph(feature_size=self.F_in)\n    gen = FullBatchNodeGenerator(G, sparse=self.sparse, method=self.method)\n    gat = GAT(layer_sizes=self.layer_sizes, activations=self.activations, attn_heads=self.attn_heads, generator=gen, bias=True)\n    assert (len(gat.in_out_tensors()) == 2)\n    (x_in, x_out) = gat.in_out_tensors()\n    assert ((len(x_in) == 4) if self.sparse else 3)\n    assert (int(x_in[0].shape[(- 1)]) == self.F_in)\n    assert (K.int_shape(x_in[(- 1)]) == (1, G.number_of_nodes(), G.number_of_nodes()))\n    assert (int(x_out.shape[(- 1)]) == self.layer_sizes[(- 1)])", "masked_code": "def test_gat_build_constructor(self):\n    G = example_graph(feature_size=self.F_in)\n    gen = FullBatchNodeGenerator(G, sparse=self.sparse, method=self.method)\n    gat = GAT(layer_sizes=self.layer_sizes, activations=self.activations, attn_heads=self.attn_heads, generator=gen, bias=True)\n    assert (len(gat.in_out_tensors()) == 2)\n    (x_in, x_out) = gat.in_out_tensors()\n    assert ((len(x_in) == 4) if self.sparse else 3)\n    assert (int(x_in[0].shape[(- 1)]) == self.F_in)\n    assert (K.int_shape(x_in[(- 1)]) == '???')\n    assert (int(x_out.shape[(- 1)]) == self.layer_sizes[(- 1)])", "ground_truth": "(1, G.number_of_nodes(), G.number_of_nodes())", "quality_analysis": {"complexity_score": 19, "left_complexity": 10, "right_complexity": 9, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_658", "reponame": "stellargraph", "testpath": "tests/layer/test_graph_attention.py", "testname": "test_graph_attention.py", "classname": "Test_GAT", "funcname": "test_gat_build_constructor", "imports": ["import pytest", "import scipy.sparse as sps", "import tensorflow as tf", "from tensorflow import keras", "from tensorflow.keras import backend as K", "from tensorflow.keras.layers import Input", "from stellargraph.mapper import FullBatchNodeGenerator, FullBatchLinkGenerator, GraphSAGENodeGenerator", "from stellargraph.layer import *", "from ..test_utils.graphs import example_graph", "from .. import test_utils"], "code": "def test_gat_build_constructor(self):\n    G = example_graph(feature_size=self.F_in)\n    gen = FullBatchNodeGenerator(G, sparse=self.sparse, method=self.method)\n    gat = GAT(layer_sizes=self.layer_sizes, activations=self.activations, attn_heads=self.attn_heads, generator=gen, bias=True)\n    assert (len(gat.in_out_tensors()) == 2)\n    (x_in, x_out) = gat.in_out_tensors()\n    assert ((len(x_in) == 4) if self.sparse else 3)\n    assert (int(x_in[0].shape[(- 1)]) == self.F_in)\n    assert (K.int_shape(x_in[(- 1)]) == (1, G.number_of_nodes(), G.number_of_nodes()))\n    assert (int(x_out.shape[(- 1)]) == self.layer_sizes[(- 1)])", "masked_code": "def test_gat_build_constructor(self):\n    G = example_graph(feature_size=self.F_in)\n    gen = FullBatchNodeGenerator(G, sparse=self.sparse, method=self.method)\n    gat = GAT(layer_sizes=self.layer_sizes, activations=self.activations, attn_heads=self.attn_heads, generator=gen, bias=True)\n    assert (len(gat.in_out_tensors()) == 2)\n    (x_in, x_out) = gat.in_out_tensors()\n    assert ((len(x_in) == 4) if self.sparse else 3)\n    assert (int(x_in[0].shape[(- 1)]) == self.F_in)\n    assert (K.int_shape(x_in[(- 1)]) == (1, G.number_of_nodes(), G.number_of_nodes()))\n    assert (int(x_out.shape[(- 1)]) == '???')", "ground_truth": "self.layer_sizes[(- 1)]", "quality_analysis": {"complexity_score": 19, "left_complexity": 11, "right_complexity": 8, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_659", "reponame": "stellargraph", "testpath": "tests/layer/test_graph_attention.py", "testname": "test_graph_attention.py", "classname": "Test_GAT", "funcname": "test_gat_build_linkmodel_constructor", "imports": ["import pytest", "import scipy.sparse as sps", "import tensorflow as tf", "from tensorflow import keras", "from tensorflow.keras import backend as K", "from tensorflow.keras.layers import Input", "from stellargraph.mapper import FullBatchNodeGenerator, FullBatchLinkGenerator, GraphSAGENodeGenerator", "from stellargraph.layer import *", "from ..test_utils.graphs import example_graph", "from .. import test_utils"], "code": "def test_gat_build_linkmodel_constructor(self):\n    G = example_graph(feature_size=self.F_in)\n    gen = FullBatchLinkGenerator(G, sparse=self.sparse, method=self.method)\n    gat = GAT(layer_sizes=self.layer_sizes, activations=self.activations, attn_heads=self.attn_heads, generator=gen, bias=True)\n    assert (len(gat.in_out_tensors()) == 2)\n    (x_in, x_out) = gat.in_out_tensors()\n    assert ((len(x_in) == 4) if self.sparse else 3)\n    assert (int(x_in[0].shape[(- 1)]) == self.F_in)\n    assert (int(x_out.shape[(- 1)]) == self.layer_sizes[(- 1)])", "masked_code": "def test_gat_build_linkmodel_constructor(self):\n    G = example_graph(feature_size=self.F_in)\n    gen = FullBatchLinkGenerator(G, sparse=self.sparse, method=self.method)\n    gat = GAT(layer_sizes=self.layer_sizes, activations=self.activations, attn_heads=self.attn_heads, generator=gen, bias=True)\n    assert (len(gat.in_out_tensors()) == 2)\n    (x_in, x_out) = gat.in_out_tensors()\n    assert ((len(x_in) == 4) if self.sparse else 3)\n    assert (int(x_in[0].shape[(- 1)]) == '???')\n    assert (int(x_out.shape[(- 1)]) == self.layer_sizes[(- 1)])", "ground_truth": "self.F_in", "quality_analysis": {"complexity_score": 13, "left_complexity": 11, "right_complexity": 2, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_660", "reponame": "stellargraph", "testpath": "tests/layer/test_graph_attention.py", "testname": "test_graph_attention.py", "classname": "Test_GAT", "funcname": "test_gat_build_linkmodel_constructor", "imports": ["import pytest", "import scipy.sparse as sps", "import tensorflow as tf", "from tensorflow import keras", "from tensorflow.keras import backend as K", "from tensorflow.keras.layers import Input", "from stellargraph.mapper import FullBatchNodeGenerator, FullBatchLinkGenerator, GraphSAGENodeGenerator", "from stellargraph.layer import *", "from ..test_utils.graphs import example_graph", "from .. import test_utils"], "code": "def test_gat_build_linkmodel_constructor(self):\n    G = example_graph(feature_size=self.F_in)\n    gen = FullBatchLinkGenerator(G, sparse=self.sparse, method=self.method)\n    gat = GAT(layer_sizes=self.layer_sizes, activations=self.activations, attn_heads=self.attn_heads, generator=gen, bias=True)\n    assert (len(gat.in_out_tensors()) == 2)\n    (x_in, x_out) = gat.in_out_tensors()\n    assert ((len(x_in) == 4) if self.sparse else 3)\n    assert (int(x_in[0].shape[(- 1)]) == self.F_in)\n    assert (int(x_out.shape[(- 1)]) == self.layer_sizes[(- 1)])", "masked_code": "def test_gat_build_linkmodel_constructor(self):\n    G = example_graph(feature_size=self.F_in)\n    gen = FullBatchLinkGenerator(G, sparse=self.sparse, method=self.method)\n    gat = GAT(layer_sizes=self.layer_sizes, activations=self.activations, attn_heads=self.attn_heads, generator=gen, bias=True)\n    assert (len(gat.in_out_tensors()) == 2)\n    (x_in, x_out) = gat.in_out_tensors()\n    assert ((len(x_in) == 4) if self.sparse else 3)\n    assert (int(x_in[0].shape[(- 1)]) == self.F_in)\n    assert (int(x_out.shape[(- 1)]) == '???')", "ground_truth": "self.layer_sizes[(- 1)]", "quality_analysis": {"complexity_score": 19, "left_complexity": 11, "right_complexity": 8, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_661", "reponame": "stellargraph", "testpath": "tests/layer/test_graph_attention.py", "testname": "test_graph_attention.py", "classname": "Test_GAT", "funcname": "test_gat_build_constructor_no_generator", "imports": ["import pytest", "import scipy.sparse as sps", "import tensorflow as tf", "from tensorflow import keras", "from tensorflow.keras import backend as K", "from tensorflow.keras.layers import Input", "from stellargraph.mapper import FullBatchNodeGenerator, FullBatchLinkGenerator, GraphSAGENodeGenerator", "from stellargraph.layer import *", "from ..test_utils.graphs import example_graph", "from .. import test_utils"], "code": "def test_gat_build_constructor_no_generator(self):\n    G = example_graph(feature_size=self.F_in)\n    gat = GAT(layer_sizes=self.layer_sizes, activations=self.activations, attn_heads=self.attn_heads, bias=True, num_nodes=1000, num_features=self.F_in, multiplicity=1)\n    assert (gat.use_sparse == False)\n    (x_in, x_out) = gat.in_out_tensors()\n    assert ((len(x_in) == 4) if self.sparse else 3)\n    assert (int(x_in[0].shape[(- 1)]) == self.F_in)\n    assert (int(x_out.shape[(- 1)]) == self.layer_sizes[(- 1)])", "masked_code": "def test_gat_build_constructor_no_generator(self):\n    G = example_graph(feature_size=self.F_in)\n    gat = GAT(layer_sizes=self.layer_sizes, activations=self.activations, attn_heads=self.attn_heads, bias=True, num_nodes=1000, num_features=self.F_in, multiplicity=1)\n    assert (gat.use_sparse == False)\n    (x_in, x_out) = gat.in_out_tensors()\n    assert ((len(x_in) == 4) if self.sparse else 3)\n    assert (int(x_in[0].shape[(- 1)]) == '???')\n    assert (int(x_out.shape[(- 1)]) == self.layer_sizes[(- 1)])", "ground_truth": "self.F_in", "quality_analysis": {"complexity_score": 13, "left_complexity": 11, "right_complexity": 2, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_662", "reponame": "stellargraph", "testpath": "tests/layer/test_graph_attention.py", "testname": "test_graph_attention.py", "classname": "Test_GAT", "funcname": "test_gat_build_constructor_no_generator", "imports": ["import pytest", "import scipy.sparse as sps", "import tensorflow as tf", "from tensorflow import keras", "from tensorflow.keras import backend as K", "from tensorflow.keras.layers import Input", "from stellargraph.mapper import FullBatchNodeGenerator, FullBatchLinkGenerator, GraphSAGENodeGenerator", "from stellargraph.layer import *", "from ..test_utils.graphs import example_graph", "from .. import test_utils"], "code": "def test_gat_build_constructor_no_generator(self):\n    G = example_graph(feature_size=self.F_in)\n    gat = GAT(layer_sizes=self.layer_sizes, activations=self.activations, attn_heads=self.attn_heads, bias=True, num_nodes=1000, num_features=self.F_in, multiplicity=1)\n    assert (gat.use_sparse == False)\n    (x_in, x_out) = gat.in_out_tensors()\n    assert ((len(x_in) == 4) if self.sparse else 3)\n    assert (int(x_in[0].shape[(- 1)]) == self.F_in)\n    assert (int(x_out.shape[(- 1)]) == self.layer_sizes[(- 1)])", "masked_code": "def test_gat_build_constructor_no_generator(self):\n    G = example_graph(feature_size=self.F_in)\n    gat = GAT(layer_sizes=self.layer_sizes, activations=self.activations, attn_heads=self.attn_heads, bias=True, num_nodes=1000, num_features=self.F_in, multiplicity=1)\n    assert (gat.use_sparse == False)\n    (x_in, x_out) = gat.in_out_tensors()\n    assert ((len(x_in) == 4) if self.sparse else 3)\n    assert (int(x_in[0].shape[(- 1)]) == self.F_in)\n    assert (int(x_out.shape[(- 1)]) == '???')", "ground_truth": "self.layer_sizes[(- 1)]", "quality_analysis": {"complexity_score": 19, "left_complexity": 11, "right_complexity": 8, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_663", "reponame": "stellargraph", "testpath": "tests/layer/test_graph_classification.py", "testname": "test_graph_classification.py", "classname": null, "funcname": "test_init", "imports": ["import numpy as np", "import tensorflow as tf", "from stellargraph.layer.graph_classification import *", "from stellargraph.layer import SortPooling", "from stellargraph.mapper import PaddedGraphGenerator, FullBatchNodeGenerator", "import pytest", "from ..test_utils.graphs import example_graph_random", "from .. import test_utils"], "code": "def test_init():\n    model = GCNSupervisedGraphClassification(layer_sizes=[16], activations=['relu'], generator=generator)\n    assert (len(model.layer_sizes) == 1)\n    assert (len(model.activations) == 1)\n    assert (model.layer_sizes[0] == 16)\n    assert (model.activations[0] == 'relu')\n    with pytest.raises(TypeError, match='generator: expected.*PaddedGraphGenerator, found NoneType'):\n        GCNSupervisedGraphClassification(layer_sizes=[16], activations=['relu'], generator=None)\n    with pytest.raises(TypeError, match='generator: expected.*PaddedGraphGenerator, found FullBatchNodeGenerator'):\n        GCNSupervisedGraphClassification(layer_sizes=[16], activations=['relu'], generator=FullBatchNodeGenerator(graphs[0]))\n    with pytest.raises(ValueError, match='expected.*number of layers.*same as.*number of activations,found 2.*vs.*1'):\n        GCNSupervisedGraphClassification(layer_sizes=[16, 32], activations=['relu'], generator=generator)\n    with pytest.raises(ValueError, match='expected.*number of layers.*same as.*number of activations,found 1.*vs.*2'):\n        GCNSupervisedGraphClassification(layer_sizes=[32], activations=['relu', 'elu'], generator=generator)", "masked_code": "def test_init():\n    model = GCNSupervisedGraphClassification(layer_sizes=[16], activations=['relu'], generator=generator)\n    assert (len(model.layer_sizes) == 1)\n    assert (len(model.activations) == 1)\n    assert (model.layer_sizes[0] == '???')\n    assert (model.activations[0] == 'relu')\n    with pytest.raises(TypeError, match='generator: expected.*PaddedGraphGenerator, found NoneType'):\n        GCNSupervisedGraphClassification(layer_sizes=[16], activations=['relu'], generator=None)\n    with pytest.raises(TypeError, match='generator: expected.*PaddedGraphGenerator, found FullBatchNodeGenerator'):\n        GCNSupervisedGraphClassification(layer_sizes=[16], activations=['relu'], generator=FullBatchNodeGenerator(graphs[0]))\n    with pytest.raises(ValueError, match='expected.*number of layers.*same as.*number of activations,found 2.*vs.*1'):\n        GCNSupervisedGraphClassification(layer_sizes=[16, 32], activations=['relu'], generator=generator)\n    with pytest.raises(ValueError, match='expected.*number of layers.*same as.*number of activations,found 1.*vs.*2'):\n        GCNSupervisedGraphClassification(layer_sizes=[32], activations=['relu', 'elu'], generator=generator)", "ground_truth": "16", "quality_analysis": {"complexity_score": 7, "left_complexity": 6, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_664", "reponame": "stellargraph", "testpath": "tests/layer/test_graph_classification.py", "testname": "test_graph_classification.py", "classname": null, "funcname": "test_init", "imports": ["import numpy as np", "import tensorflow as tf", "from stellargraph.layer.graph_classification import *", "from stellargraph.layer import SortPooling", "from stellargraph.mapper import PaddedGraphGenerator, FullBatchNodeGenerator", "import pytest", "from ..test_utils.graphs import example_graph_random", "from .. import test_utils"], "code": "def test_init():\n    model = GCNSupervisedGraphClassification(layer_sizes=[16], activations=['relu'], generator=generator)\n    assert (len(model.layer_sizes) == 1)\n    assert (len(model.activations) == 1)\n    assert (model.layer_sizes[0] == 16)\n    assert (model.activations[0] == 'relu')\n    with pytest.raises(TypeError, match='generator: expected.*PaddedGraphGenerator, found NoneType'):\n        GCNSupervisedGraphClassification(layer_sizes=[16], activations=['relu'], generator=None)\n    with pytest.raises(TypeError, match='generator: expected.*PaddedGraphGenerator, found FullBatchNodeGenerator'):\n        GCNSupervisedGraphClassification(layer_sizes=[16], activations=['relu'], generator=FullBatchNodeGenerator(graphs[0]))\n    with pytest.raises(ValueError, match='expected.*number of layers.*same as.*number of activations,found 2.*vs.*1'):\n        GCNSupervisedGraphClassification(layer_sizes=[16, 32], activations=['relu'], generator=generator)\n    with pytest.raises(ValueError, match='expected.*number of layers.*same as.*number of activations,found 1.*vs.*2'):\n        GCNSupervisedGraphClassification(layer_sizes=[32], activations=['relu', 'elu'], generator=generator)", "masked_code": "def test_init():\n    model = GCNSupervisedGraphClassification(layer_sizes=[16], activations=['relu'], generator=generator)\n    assert (len(model.layer_sizes) == 1)\n    assert (len(model.activations) == 1)\n    assert (model.layer_sizes[0] == 16)\n    assert (model.activations[0] == '???')\n    with pytest.raises(TypeError, match='generator: expected.*PaddedGraphGenerator, found NoneType'):\n        GCNSupervisedGraphClassification(layer_sizes=[16], activations=['relu'], generator=None)\n    with pytest.raises(TypeError, match='generator: expected.*PaddedGraphGenerator, found FullBatchNodeGenerator'):\n        GCNSupervisedGraphClassification(layer_sizes=[16], activations=['relu'], generator=FullBatchNodeGenerator(graphs[0]))\n    with pytest.raises(ValueError, match='expected.*number of layers.*same as.*number of activations,found 2.*vs.*1'):\n        GCNSupervisedGraphClassification(layer_sizes=[16, 32], activations=['relu'], generator=generator)\n    with pytest.raises(ValueError, match='expected.*number of layers.*same as.*number of activations,found 1.*vs.*2'):\n        GCNSupervisedGraphClassification(layer_sizes=[32], activations=['relu', 'elu'], generator=generator)", "ground_truth": "'relu'", "quality_analysis": {"complexity_score": 7, "left_complexity": 6, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_665", "reponame": "stellargraph", "testpath": "tests/layer/test_graph_classification.py", "testname": "test_graph_classification.py", "classname": null, "funcname": "test_in_out_tensors", "imports": ["import numpy as np", "import tensorflow as tf", "from stellargraph.layer.graph_classification import *", "from stellargraph.layer import SortPooling", "from stellargraph.mapper import PaddedGraphGenerator, FullBatchNodeGenerator", "import pytest", "from ..test_utils.graphs import example_graph_random", "from .. import test_utils"], "code": "def test_in_out_tensors():\n    layer_sizes = [16, 8]\n    activations = ['relu', 'relu']\n    model = GCNSupervisedGraphClassification(layer_sizes=layer_sizes, activations=activations, generator=generator)\n    (x_in, x_out) = model.in_out_tensors()\n    assert (len(x_in) == 3)\n    assert (len(x_in[0].shape) == 3)\n    assert (x_in[0].shape[(- 1)] == 4)\n    assert (len(x_out.shape) == 2)\n    assert (x_out.shape[(- 1)] == layer_sizes[(- 1)])", "masked_code": "def test_in_out_tensors():\n    layer_sizes = [16, 8]\n    activations = ['relu', 'relu']\n    model = GCNSupervisedGraphClassification(layer_sizes=layer_sizes, activations=activations, generator=generator)\n    (x_in, x_out) = model.in_out_tensors()\n    assert (len(x_in) == '???')\n    assert (len(x_in[0].shape) == 3)\n    assert (x_in[0].shape[(- 1)] == 4)\n    assert (len(x_out.shape) == 2)\n    assert (x_out.shape[(- 1)] == layer_sizes[(- 1)])", "ground_truth": "3", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_666", "reponame": "stellargraph", "testpath": "tests/layer/test_graph_classification.py", "testname": "test_graph_classification.py", "classname": null, "funcname": "test_in_out_tensors", "imports": ["import numpy as np", "import tensorflow as tf", "from stellargraph.layer.graph_classification import *", "from stellargraph.layer import SortPooling", "from stellargraph.mapper import PaddedGraphGenerator, FullBatchNodeGenerator", "import pytest", "from ..test_utils.graphs import example_graph_random", "from .. import test_utils"], "code": "def test_in_out_tensors():\n    layer_sizes = [16, 8]\n    activations = ['relu', 'relu']\n    model = GCNSupervisedGraphClassification(layer_sizes=layer_sizes, activations=activations, generator=generator)\n    (x_in, x_out) = model.in_out_tensors()\n    assert (len(x_in) == 3)\n    assert (len(x_in[0].shape) == 3)\n    assert (x_in[0].shape[(- 1)] == 4)\n    assert (len(x_out.shape) == 2)\n    assert (x_out.shape[(- 1)] == layer_sizes[(- 1)])", "masked_code": "def test_in_out_tensors():\n    layer_sizes = [16, 8]\n    activations = ['relu', 'relu']\n    model = GCNSupervisedGraphClassification(layer_sizes=layer_sizes, activations=activations, generator=generator)\n    (x_in, x_out) = model.in_out_tensors()\n    assert (len(x_in) == 3)\n    assert (len(x_in[0].shape) == '???')\n    assert (x_in[0].shape[(- 1)] == 4)\n    assert (len(x_out.shape) == 2)\n    assert (x_out.shape[(- 1)] == layer_sizes[(- 1)])", "ground_truth": "3", "quality_analysis": {"complexity_score": 6, "left_complexity": 5, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_667", "reponame": "stellargraph", "testpath": "tests/layer/test_graph_classification.py", "testname": "test_graph_classification.py", "classname": null, "funcname": "test_in_out_tensors", "imports": ["import numpy as np", "import tensorflow as tf", "from stellargraph.layer.graph_classification import *", "from stellargraph.layer import SortPooling", "from stellargraph.mapper import PaddedGraphGenerator, FullBatchNodeGenerator", "import pytest", "from ..test_utils.graphs import example_graph_random", "from .. import test_utils"], "code": "def test_in_out_tensors():\n    layer_sizes = [16, 8]\n    activations = ['relu', 'relu']\n    model = GCNSupervisedGraphClassification(layer_sizes=layer_sizes, activations=activations, generator=generator)\n    (x_in, x_out) = model.in_out_tensors()\n    assert (len(x_in) == 3)\n    assert (len(x_in[0].shape) == 3)\n    assert (x_in[0].shape[(- 1)] == 4)\n    assert (len(x_out.shape) == 2)\n    assert (x_out.shape[(- 1)] == layer_sizes[(- 1)])", "masked_code": "def test_in_out_tensors():\n    layer_sizes = [16, 8]\n    activations = ['relu', 'relu']\n    model = GCNSupervisedGraphClassification(layer_sizes=layer_sizes, activations=activations, generator=generator)\n    (x_in, x_out) = model.in_out_tensors()\n    assert (len(x_in) == 3)\n    assert (len(x_in[0].shape) == 3)\n    assert (x_in[0].shape[(- 1)] == '???')\n    assert (len(x_out.shape) == 2)\n    assert (x_out.shape[(- 1)] == layer_sizes[(- 1)])", "ground_truth": "4", "quality_analysis": {"complexity_score": 9, "left_complexity": 8, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_668", "reponame": "stellargraph", "testpath": "tests/layer/test_graph_classification.py", "testname": "test_graph_classification.py", "classname": null, "funcname": "test_in_out_tensors", "imports": ["import numpy as np", "import tensorflow as tf", "from stellargraph.layer.graph_classification import *", "from stellargraph.layer import SortPooling", "from stellargraph.mapper import PaddedGraphGenerator, FullBatchNodeGenerator", "import pytest", "from ..test_utils.graphs import example_graph_random", "from .. import test_utils"], "code": "def test_in_out_tensors():\n    layer_sizes = [16, 8]\n    activations = ['relu', 'relu']\n    model = GCNSupervisedGraphClassification(layer_sizes=layer_sizes, activations=activations, generator=generator)\n    (x_in, x_out) = model.in_out_tensors()\n    assert (len(x_in) == 3)\n    assert (len(x_in[0].shape) == 3)\n    assert (x_in[0].shape[(- 1)] == 4)\n    assert (len(x_out.shape) == 2)\n    assert (x_out.shape[(- 1)] == layer_sizes[(- 1)])", "masked_code": "def test_in_out_tensors():\n    layer_sizes = [16, 8]\n    activations = ['relu', 'relu']\n    model = GCNSupervisedGraphClassification(layer_sizes=layer_sizes, activations=activations, generator=generator)\n    (x_in, x_out) = model.in_out_tensors()\n    assert (len(x_in) == 3)\n    assert (len(x_in[0].shape) == 3)\n    assert (x_in[0].shape[(- 1)] == 4)\n    assert (len(x_out.shape) == 2)\n    assert (x_out.shape[(- 1)] == '???')", "ground_truth": "layer_sizes[(- 1)]", "quality_analysis": {"complexity_score": 15, "left_complexity": 8, "right_complexity": 7, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_669", "reponame": "stellargraph", "testpath": "tests/layer/test_graph_classification.py", "testname": "test_graph_classification.py", "classname": null, "funcname": "test_pooling", "imports": ["import numpy as np", "import tensorflow as tf", "from stellargraph.layer.graph_classification import *", "from stellargraph.layer import SortPooling", "from stellargraph.mapper import PaddedGraphGenerator, FullBatchNodeGenerator", "import pytest", "from ..test_utils.graphs import example_graph_random", "from .. import test_utils"], "code": "@pytest.mark.parametrize('pooling', ['default', 'custom'])\ndef test_pooling(pooling):\n    if (pooling == 'default'):\n        gcn_graph_model = GCNSupervisedGraphClassification(layer_sizes=[], activations=[], generator=generator)\n\n        def expected_values(array):\n            return array.mean(axis=0)\n    else:\n        shift = 10\n\n        def shifted_sum_pooling(tensor, mask):\n            mask_floats = tf.expand_dims(tf.cast(mask, tf.float32), axis=(- 1))\n            return tf.math.reduce_sum(tf.multiply(mask_floats, (shift + tensor)), axis=1)\n        gcn_graph_model = GCNSupervisedGraphClassification(layer_sizes=[], activations=[], generator=generator, pooling=shifted_sum_pooling)\n\n        def expected_values(array):\n            return (shift + array).sum(axis=0)\n    train_graphs = [0, 1, 2]\n    train_gen = generator.flow(graphs=train_graphs, batch_size=2, shuffle=False)\n    model = tf.keras.Model(*gcn_graph_model.in_out_tensors())\n    predictions = model.predict(train_gen)\n    assert (predictions.shape == (3, 4))\n    expected = np.vstack([expected_values(graphs[iloc].node_features(node_type='n-0')) for iloc in train_graphs])\n    np.testing.assert_almost_equal(predictions, expected)", "masked_code": "@pytest.mark.parametrize('pooling', ['default', 'custom'])\ndef test_pooling(pooling):\n    if (pooling == 'default'):\n        gcn_graph_model = GCNSupervisedGraphClassification(layer_sizes=[], activations=[], generator=generator)\n\n        def expected_values(array):\n            return array.mean(axis=0)\n    else:\n        shift = 10\n\n        def shifted_sum_pooling(tensor, mask):\n            mask_floats = tf.expand_dims(tf.cast(mask, tf.float32), axis=(- 1))\n            return tf.math.reduce_sum(tf.multiply(mask_floats, (shift + tensor)), axis=1)\n        gcn_graph_model = GCNSupervisedGraphClassification(layer_sizes=[], activations=[], generator=generator, pooling=shifted_sum_pooling)\n\n        def expected_values(array):\n            return (shift + array).sum(axis=0)\n    train_graphs = [0, 1, 2]\n    train_gen = generator.flow(graphs=train_graphs, batch_size=2, shuffle=False)\n    model = tf.keras.Model(*gcn_graph_model.in_out_tensors())\n    predictions = model.predict(train_gen)\n    assert (predictions.shape == '???')\n    expected = np.vstack([expected_values(graphs[iloc].node_features(node_type='n-0')) for iloc in train_graphs])\n    np.testing.assert_almost_equal(predictions, expected)", "ground_truth": "(3, 4)", "quality_analysis": {"complexity_score": 6, "left_complexity": 2, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_670", "reponame": "stellargraph", "testpath": "tests/layer/test_graph_classification.py", "testname": "test_graph_classification.py", "classname": null, "funcname": "test_pool_all_layers", "imports": ["import numpy as np", "import tensorflow as tf", "from stellargraph.layer.graph_classification import *", "from stellargraph.layer import SortPooling", "from stellargraph.mapper import PaddedGraphGenerator, FullBatchNodeGenerator", "import pytest", "from ..test_utils.graphs import example_graph_random", "from .. import test_utils"], "code": "def test_pool_all_layers():\n    gcn_graph_model = GCNSupervisedGraphClassification(layer_sizes=[5, 7, 11, 1], activations=['relu', 'relu', 'relu', 'relu'], generator=generator, pool_all_layers=True)\n    train_graphs = [0, 1, 2]\n    train_gen = generator.flow(graphs=train_graphs, batch_size=2)\n    model = tf.keras.Model(*gcn_graph_model.in_out_tensors())\n    predictions = model.predict(train_gen)\n    assert (predictions.shape == (3, (((5 + 7) + 11) + 1)))", "masked_code": "def test_pool_all_layers():\n    gcn_graph_model = GCNSupervisedGraphClassification(layer_sizes=[5, 7, 11, 1], activations=['relu', 'relu', 'relu', 'relu'], generator=generator, pool_all_layers=True)\n    train_graphs = [0, 1, 2]\n    train_gen = generator.flow(graphs=train_graphs, batch_size=2)\n    model = tf.keras.Model(*gcn_graph_model.in_out_tensors())\n    predictions = model.predict(train_gen)\n    assert (predictions.shape == '???')", "ground_truth": "(3, (((5 + 7) + 11) + 1))", "quality_analysis": {"complexity_score": 15, "left_complexity": 2, "right_complexity": 13, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_671", "reponame": "stellargraph", "testpath": "tests/layer/test_graph_classification.py", "testname": "test_graph_classification.py", "classname": null, "funcname": "test_dgcnn_smoke", "imports": ["import numpy as np", "import tensorflow as tf", "from stellargraph.layer.graph_classification import *", "from stellargraph.layer import SortPooling", "from stellargraph.mapper import PaddedGraphGenerator, FullBatchNodeGenerator", "import pytest", "from ..test_utils.graphs import example_graph_random", "from .. import test_utils"], "code": "def test_dgcnn_smoke():\n    dgcnn = DeepGraphCNN(layer_sizes=[2, 3, 4], activations=['relu', 'relu', 'relu'], k=5, generator=generator)\n    assert isinstance(dgcnn, GCNSupervisedGraphClassification)\n    assert isinstance(dgcnn.pooling, SortPooling)\n    assert (dgcnn.pool_all_layers == True)\n    model = tf.keras.Model(*dgcnn.in_out_tensors())\n    preds = model.predict(generator.flow([0, 1, 2]))\n    assert (preds.shape == (3, (((2 + 3) + 4) * 5), 1))", "masked_code": "def test_dgcnn_smoke():\n    dgcnn = DeepGraphCNN(layer_sizes=[2, 3, 4], activations=['relu', 'relu', 'relu'], k=5, generator=generator)\n    assert isinstance(dgcnn, GCNSupervisedGraphClassification)\n    assert isinstance(dgcnn.pooling, SortPooling)\n    assert (dgcnn.pool_all_layers == True)\n    model = tf.keras.Model(*dgcnn.in_out_tensors())\n    preds = model.predict(generator.flow([0, 1, 2]))\n    assert (preds.shape == '???')", "ground_truth": "(3, (((2 + 3) + 4) * 5), 1)", "quality_analysis": {"complexity_score": 16, "left_complexity": 2, "right_complexity": 14, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_672", "reponame": "stellargraph", "testpath": "tests/layer/test_hinsage.py", "testname": "test_hinsage.py", "classname": null, "funcname": "test_mean_hin_agg_constructor", "imports": ["import pytest", "import numpy as np", "import networkx as nx", "from tensorflow import keras", "from tensorflow.keras import regularizers", "from stellargraph import StellarGraph", "from stellargraph.layer.hinsage import *", "from stellargraph.mapper import *", "from ..test_utils.graphs import example_hin_1", "from .. import test_utils"], "code": "def test_mean_hin_agg_constructor():\n    agg = MeanHinAggregator(output_dim=2)\n    assert (agg.output_dim == 2)\n    assert (agg.half_output_dim == 1)\n    assert (not agg.has_bias)\n    assert (agg.act.__name__ == 'relu')", "masked_code": "def test_mean_hin_agg_constructor():\n    agg = MeanHinAggregator(output_dim=2)\n    assert (agg.output_dim == 2)\n    assert (agg.half_output_dim == 1)\n    assert (not agg.has_bias)\n    assert (agg.act.__name__ == '???')", "ground_truth": "'relu'", "quality_analysis": {"complexity_score": 3, "left_complexity": 2, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_673", "reponame": "stellargraph", "testpath": "tests/layer/test_hinsage.py", "testname": "test_hinsage.py", "classname": null, "funcname": "test_mean_hin_agg_constructor_1", "imports": ["import pytest", "import numpy as np", "import networkx as nx", "from tensorflow import keras", "from tensorflow.keras import regularizers", "from stellargraph import StellarGraph", "from stellargraph.layer.hinsage import *", "from stellargraph.mapper import *", "from ..test_utils.graphs import example_hin_1", "from .. import test_utils"], "code": "def test_mean_hin_agg_constructor_1():\n    agg = MeanHinAggregator(output_dim=2, bias=True, act=(lambda x: (x + 1)))\n    assert (agg.output_dim == 2)\n    assert (agg.half_output_dim == 1)\n    assert agg.has_bias\n    assert (agg.act(2) == 3)\n    config = agg.get_config()\n    assert (config['output_dim'] == 2)\n    assert (config['bias'] == True)\n    assert (config['act'] == '<lambda>')\n    agg = MeanHinAggregator(output_dim=2, bias=True, act='relu')\n    assert (agg.output_dim == 2)\n    assert (agg.half_output_dim == 1)\n    assert agg.has_bias\n    config = agg.get_config()\n    assert (config['output_dim'] == 2)\n    assert (config['bias'] == True)\n    assert (config['act'] == 'relu')", "masked_code": "def test_mean_hin_agg_constructor_1():\n    agg = MeanHinAggregator(output_dim=2, bias=True, act=(lambda x: (x + 1)))\n    assert (agg.output_dim == 2)\n    assert (agg.half_output_dim == 1)\n    assert agg.has_bias\n    assert (agg.act(2) == '???')\n    config = agg.get_config()\n    assert (config['output_dim'] == 2)\n    assert (config['bias'] == True)\n    assert (config['act'] == '<lambda>')\n    agg = MeanHinAggregator(output_dim=2, bias=True, act='relu')\n    assert (agg.output_dim == 2)\n    assert (agg.half_output_dim == 1)\n    assert agg.has_bias\n    config = agg.get_config()\n    assert (config['output_dim'] == 2)\n    assert (config['bias'] == True)\n    assert (config['act'] == 'relu')", "ground_truth": "3", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_674", "reponame": "stellargraph", "testpath": "tests/layer/test_hinsage.py", "testname": "test_hinsage.py", "classname": null, "funcname": "test_mean_hin_agg_constructor_1", "imports": ["import pytest", "import numpy as np", "import networkx as nx", "from tensorflow import keras", "from tensorflow.keras import regularizers", "from stellargraph import StellarGraph", "from stellargraph.layer.hinsage import *", "from stellargraph.mapper import *", "from ..test_utils.graphs import example_hin_1", "from .. import test_utils"], "code": "def test_mean_hin_agg_constructor_1():\n    agg = MeanHinAggregator(output_dim=2, bias=True, act=(lambda x: (x + 1)))\n    assert (agg.output_dim == 2)\n    assert (agg.half_output_dim == 1)\n    assert agg.has_bias\n    assert (agg.act(2) == 3)\n    config = agg.get_config()\n    assert (config['output_dim'] == 2)\n    assert (config['bias'] == True)\n    assert (config['act'] == '<lambda>')\n    agg = MeanHinAggregator(output_dim=2, bias=True, act='relu')\n    assert (agg.output_dim == 2)\n    assert (agg.half_output_dim == 1)\n    assert agg.has_bias\n    config = agg.get_config()\n    assert (config['output_dim'] == 2)\n    assert (config['bias'] == True)\n    assert (config['act'] == 'relu')", "masked_code": "def test_mean_hin_agg_constructor_1():\n    agg = MeanHinAggregator(output_dim=2, bias=True, act=(lambda x: (x + 1)))\n    assert (agg.output_dim == 2)\n    assert (agg.half_output_dim == 1)\n    assert agg.has_bias\n    assert (agg.act(2) == 3)\n    config = agg.get_config()\n    assert (config['output_dim'] == 2)\n    assert (config['bias'] == True)\n    assert (config['act'] == '???')\n    agg = MeanHinAggregator(output_dim=2, bias=True, act='relu')\n    assert (agg.output_dim == 2)\n    assert (agg.half_output_dim == 1)\n    assert agg.has_bias\n    config = agg.get_config()\n    assert (config['output_dim'] == 2)\n    assert (config['bias'] == True)\n    assert (config['act'] == 'relu')", "ground_truth": "'<lambda>'", "quality_analysis": {"complexity_score": 6, "left_complexity": 5, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_675", "reponame": "stellargraph", "testpath": "tests/layer/test_hinsage.py", "testname": "test_hinsage.py", "classname": null, "funcname": "test_mean_hin_agg_constructor_1", "imports": ["import pytest", "import numpy as np", "import networkx as nx", "from tensorflow import keras", "from tensorflow.keras import regularizers", "from stellargraph import StellarGraph", "from stellargraph.layer.hinsage import *", "from stellargraph.mapper import *", "from ..test_utils.graphs import example_hin_1", "from .. import test_utils"], "code": "def test_mean_hin_agg_constructor_1():\n    agg = MeanHinAggregator(output_dim=2, bias=True, act=(lambda x: (x + 1)))\n    assert (agg.output_dim == 2)\n    assert (agg.half_output_dim == 1)\n    assert agg.has_bias\n    assert (agg.act(2) == 3)\n    config = agg.get_config()\n    assert (config['output_dim'] == 2)\n    assert (config['bias'] == True)\n    assert (config['act'] == '<lambda>')\n    agg = MeanHinAggregator(output_dim=2, bias=True, act='relu')\n    assert (agg.output_dim == 2)\n    assert (agg.half_output_dim == 1)\n    assert agg.has_bias\n    config = agg.get_config()\n    assert (config['output_dim'] == 2)\n    assert (config['bias'] == True)\n    assert (config['act'] == 'relu')", "masked_code": "def test_mean_hin_agg_constructor_1():\n    agg = MeanHinAggregator(output_dim=2, bias=True, act=(lambda x: (x + 1)))\n    assert (agg.output_dim == 2)\n    assert (agg.half_output_dim == 1)\n    assert agg.has_bias\n    assert (agg.act(2) == 3)\n    config = agg.get_config()\n    assert (config['output_dim'] == 2)\n    assert (config['bias'] == True)\n    assert (config['act'] == '<lambda>')\n    agg = MeanHinAggregator(output_dim=2, bias=True, act='relu')\n    assert (agg.output_dim == 2)\n    assert (agg.half_output_dim == 1)\n    assert agg.has_bias\n    config = agg.get_config()\n    assert (config['output_dim'] == 2)\n    assert (config['bias'] == True)\n    assert (config['act'] == '???')", "ground_truth": "'relu'", "quality_analysis": {"complexity_score": 6, "left_complexity": 5, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_676", "reponame": "stellargraph", "testpath": "tests/layer/test_hinsage.py", "testname": "test_hinsage.py", "classname": null, "funcname": "test_hinsage_constructor", "imports": ["import pytest", "import numpy as np", "import networkx as nx", "from tensorflow import keras", "from tensorflow.keras import regularizers", "from stellargraph import StellarGraph", "from stellargraph.layer.hinsage import *", "from stellargraph.mapper import *", "from ..test_utils.graphs import example_hin_1", "from .. import test_utils"], "code": "def test_hinsage_constructor():\n    hs = HinSAGE(layer_sizes=[{'1': 2, '2': 2}, {'1': 2}], n_samples=[2, 2], input_neighbor_tree=[('1', [1, 2]), ('1', [3, 4]), ('2', [5]), ('1', []), ('2', []), ('2', [])], multiplicity=1, input_dim={'1': 2, '2': 2})\n    assert (hs.n_layers == 2)\n    assert (hs.n_samples == [2, 2])\n    assert hs.bias\n    hs = HinSAGE(layer_sizes=[2, 2], n_samples=[2, 2], input_neighbor_tree=[('1', [1, 2]), ('1', [3, 4]), ('2', [5]), ('1', []), ('2', []), ('2', [])], multiplicity=1, input_dim={'1': 2, '2': 2})\n    assert (hs.n_layers == 2)\n    assert (hs.n_samples == [2, 2])\n    assert hs.bias", "masked_code": "def test_hinsage_constructor():\n    hs = HinSAGE(layer_sizes=[{'1': 2, '2': 2}, {'1': 2}], n_samples=[2, 2], input_neighbor_tree=[('1', [1, 2]), ('1', [3, 4]), ('2', [5]), ('1', []), ('2', []), ('2', [])], multiplicity=1, input_dim={'1': 2, '2': 2})\n    assert (hs.n_layers == 2)\n    assert (hs.n_samples == '???')\n    assert hs.bias\n    hs = HinSAGE(layer_sizes=[2, 2], n_samples=[2, 2], input_neighbor_tree=[('1', [1, 2]), ('1', [3, 4]), ('2', [5]), ('1', []), ('2', []), ('2', [])], multiplicity=1, input_dim={'1': 2, '2': 2})\n    assert (hs.n_layers == 2)\n    assert (hs.n_samples == [2, 2])\n    assert hs.bias", "ground_truth": "[2, 2]", "quality_analysis": {"complexity_score": 6, "left_complexity": 2, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_677", "reponame": "stellargraph", "testpath": "tests/layer/test_hinsage.py", "testname": "test_hinsage.py", "classname": null, "funcname": "test_hinsage_constructor", "imports": ["import pytest", "import numpy as np", "import networkx as nx", "from tensorflow import keras", "from tensorflow.keras import regularizers", "from stellargraph import StellarGraph", "from stellargraph.layer.hinsage import *", "from stellargraph.mapper import *", "from ..test_utils.graphs import example_hin_1", "from .. import test_utils"], "code": "def test_hinsage_constructor():\n    hs = HinSAGE(layer_sizes=[{'1': 2, '2': 2}, {'1': 2}], n_samples=[2, 2], input_neighbor_tree=[('1', [1, 2]), ('1', [3, 4]), ('2', [5]), ('1', []), ('2', []), ('2', [])], multiplicity=1, input_dim={'1': 2, '2': 2})\n    assert (hs.n_layers == 2)\n    assert (hs.n_samples == [2, 2])\n    assert hs.bias\n    hs = HinSAGE(layer_sizes=[2, 2], n_samples=[2, 2], input_neighbor_tree=[('1', [1, 2]), ('1', [3, 4]), ('2', [5]), ('1', []), ('2', []), ('2', [])], multiplicity=1, input_dim={'1': 2, '2': 2})\n    assert (hs.n_layers == 2)\n    assert (hs.n_samples == [2, 2])\n    assert hs.bias", "masked_code": "def test_hinsage_constructor():\n    hs = HinSAGE(layer_sizes=[{'1': 2, '2': 2}, {'1': 2}], n_samples=[2, 2], input_neighbor_tree=[('1', [1, 2]), ('1', [3, 4]), ('2', [5]), ('1', []), ('2', []), ('2', [])], multiplicity=1, input_dim={'1': 2, '2': 2})\n    assert (hs.n_layers == 2)\n    assert (hs.n_samples == [2, 2])\n    assert hs.bias\n    hs = HinSAGE(layer_sizes=[2, 2], n_samples=[2, 2], input_neighbor_tree=[('1', [1, 2]), ('1', [3, 4]), ('2', [5]), ('1', []), ('2', []), ('2', [])], multiplicity=1, input_dim={'1': 2, '2': 2})\n    assert (hs.n_layers == 2)\n    assert (hs.n_samples == '???')\n    assert hs.bias", "ground_truth": "[2, 2]", "quality_analysis": {"complexity_score": 6, "left_complexity": 2, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_678", "reponame": "stellargraph", "testpath": "tests/layer/test_hinsage.py", "testname": "test_hinsage.py", "classname": null, "funcname": "test_hinsage_constructor_with_agg", "imports": ["import pytest", "import numpy as np", "import networkx as nx", "from tensorflow import keras", "from tensorflow.keras import regularizers", "from stellargraph import StellarGraph", "from stellargraph.layer.hinsage import *", "from stellargraph.mapper import *", "from ..test_utils.graphs import example_hin_1", "from .. import test_utils"], "code": "def test_hinsage_constructor_with_agg():\n    hs = HinSAGE(layer_sizes=[{'1': 2, '2': 2}, {'1': 2}], n_samples=[2, 2], input_neighbor_tree=[('1', [1, 2]), ('1', [3, 4]), ('2', [5]), ('1', []), ('2', []), ('2', [])], multiplicity=1, input_dim={'1': 2, '2': 2}, aggregator=MeanHinAggregator)\n    assert (hs.n_layers == 2)\n    assert (hs.n_samples == [2, 2])\n    assert hs.bias", "masked_code": "def test_hinsage_constructor_with_agg():\n    hs = HinSAGE(layer_sizes=[{'1': 2, '2': 2}, {'1': 2}], n_samples=[2, 2], input_neighbor_tree=[('1', [1, 2]), ('1', [3, 4]), ('2', [5]), ('1', []), ('2', []), ('2', [])], multiplicity=1, input_dim={'1': 2, '2': 2}, aggregator=MeanHinAggregator)\n    assert (hs.n_layers == 2)\n    assert (hs.n_samples == '???')\n    assert hs.bias", "ground_truth": "[2, 2]", "quality_analysis": {"complexity_score": 6, "left_complexity": 2, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_679", "reponame": "stellargraph", "testpath": "tests/layer/test_hinsage.py", "testname": "test_hinsage.py", "classname": null, "funcname": "test_hinsage_input_shapes", "imports": ["import pytest", "import numpy as np", "import networkx as nx", "from tensorflow import keras", "from tensorflow.keras import regularizers", "from stellargraph import StellarGraph", "from stellargraph.layer.hinsage import *", "from stellargraph.mapper import *", "from ..test_utils.graphs import example_hin_1", "from .. import test_utils"], "code": "def test_hinsage_input_shapes():\n    hs = HinSAGE(layer_sizes=[{'1': 2, '2': 2}, 2], n_samples=[2, 2], input_neighbor_tree=[('1', [1, 2]), ('1', [3, 4]), ('2', [5]), ('1', []), ('2', []), ('2', [])], multiplicity=1, input_dim={'1': 2, '2': 4})\n    assert (hs._input_shapes() == [(1, 2), (2, 2), (2, 4), (4, 2), (4, 4), (4, 4)])", "masked_code": "def test_hinsage_input_shapes():\n    hs = HinSAGE(layer_sizes=[{'1': 2, '2': 2}, 2], n_samples=[2, 2], input_neighbor_tree=[('1', [1, 2]), ('1', [3, 4]), ('2', [5]), ('1', []), ('2', []), ('2', [])], multiplicity=1, input_dim={'1': 2, '2': 4})\n    assert (hs._input_shapes() == '???')", "ground_truth": "[(1, 2), (2, 2), (2, 4), (4, 2), (4, 4), (4, 4)]", "quality_analysis": {"complexity_score": 29, "left_complexity": 3, "right_complexity": 26, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_680", "reponame": "stellargraph", "testpath": "tests/layer/test_hinsage.py", "testname": "test_hinsage.py", "classname": null, "funcname": "test_hinsage_passing_activations", "imports": ["import pytest", "import numpy as np", "import networkx as nx", "from tensorflow import keras", "from tensorflow.keras import regularizers", "from stellargraph import StellarGraph", "from stellargraph.layer.hinsage import *", "from stellargraph.mapper import *", "from ..test_utils.graphs import example_hin_1", "from .. import test_utils"], "code": "def test_hinsage_passing_activations():\n    hs = HinSAGE(layer_sizes=[2, 2], n_samples=[2, 2], input_neighbor_tree=[('1', [1, 2]), ('1', [3, 4]), ('2', [5]), ('1', []), ('2', []), ('2', [])], multiplicity=1, input_dim={'1': 2, '2': 2})\n    assert (hs.activations == ['relu', 'linear'])\n    with pytest.raises(ValueError):\n        hs = HinSAGE(layer_sizes=[2, 2], n_samples=[2, 2], input_neighbor_tree=[('1', [1, 2]), ('1', [3, 4]), ('2', [5]), ('1', []), ('2', []), ('2', [])], multiplicity=1, input_dim={'1': 2, '2': 2}, activations=['fred', 'wilma'])\n    with pytest.raises(ValueError):\n        hs = HinSAGE(layer_sizes=[2, 2], n_samples=[2, 2], input_neighbor_tree=[('1', [1, 2]), ('1', [3, 4]), ('2', [5]), ('1', []), ('2', []), ('2', [])], input_dim={'1': 2, '2': 2}, multiplicity=1, activations=['relu'])\n    hs = HinSAGE(layer_sizes=[2, 2], n_samples=[2, 2], input_neighbor_tree=[('1', [1, 2]), ('1', [3, 4]), ('2', [5]), ('1', []), ('2', []), ('2', [])], input_dim={'1': 2, '2': 2}, multiplicity=1, activations=(['linear'] * 2))\n    assert (hs.activations == (['linear'] * 2))", "masked_code": "def test_hinsage_passing_activations():\n    hs = HinSAGE(layer_sizes=[2, 2], n_samples=[2, 2], input_neighbor_tree=[('1', [1, 2]), ('1', [3, 4]), ('2', [5]), ('1', []), ('2', []), ('2', [])], multiplicity=1, input_dim={'1': 2, '2': 2})\n    assert (hs.activations == '???')\n    with pytest.raises(ValueError):\n        hs = HinSAGE(layer_sizes=[2, 2], n_samples=[2, 2], input_neighbor_tree=[('1', [1, 2]), ('1', [3, 4]), ('2', [5]), ('1', []), ('2', []), ('2', [])], multiplicity=1, input_dim={'1': 2, '2': 2}, activations=['fred', 'wilma'])\n    with pytest.raises(ValueError):\n        hs = HinSAGE(layer_sizes=[2, 2], n_samples=[2, 2], input_neighbor_tree=[('1', [1, 2]), ('1', [3, 4]), ('2', [5]), ('1', []), ('2', []), ('2', [])], input_dim={'1': 2, '2': 2}, multiplicity=1, activations=['relu'])\n    hs = HinSAGE(layer_sizes=[2, 2], n_samples=[2, 2], input_neighbor_tree=[('1', [1, 2]), ('1', [3, 4]), ('2', [5]), ('1', []), ('2', []), ('2', [])], input_dim={'1': 2, '2': 2}, multiplicity=1, activations=(['linear'] * 2))\n    assert (hs.activations == (['linear'] * 2))", "ground_truth": "['relu', 'linear']", "quality_analysis": {"complexity_score": 6, "left_complexity": 2, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_681", "reponame": "stellargraph", "testpath": "tests/layer/test_hinsage.py", "testname": "test_hinsage.py", "classname": null, "funcname": "test_hinsage_passing_activations", "imports": ["import pytest", "import numpy as np", "import networkx as nx", "from tensorflow import keras", "from tensorflow.keras import regularizers", "from stellargraph import StellarGraph", "from stellargraph.layer.hinsage import *", "from stellargraph.mapper import *", "from ..test_utils.graphs import example_hin_1", "from .. import test_utils"], "code": "def test_hinsage_passing_activations():\n    hs = HinSAGE(layer_sizes=[2, 2], n_samples=[2, 2], input_neighbor_tree=[('1', [1, 2]), ('1', [3, 4]), ('2', [5]), ('1', []), ('2', []), ('2', [])], multiplicity=1, input_dim={'1': 2, '2': 2})\n    assert (hs.activations == ['relu', 'linear'])\n    with pytest.raises(ValueError):\n        hs = HinSAGE(layer_sizes=[2, 2], n_samples=[2, 2], input_neighbor_tree=[('1', [1, 2]), ('1', [3, 4]), ('2', [5]), ('1', []), ('2', []), ('2', [])], multiplicity=1, input_dim={'1': 2, '2': 2}, activations=['fred', 'wilma'])\n    with pytest.raises(ValueError):\n        hs = HinSAGE(layer_sizes=[2, 2], n_samples=[2, 2], input_neighbor_tree=[('1', [1, 2]), ('1', [3, 4]), ('2', [5]), ('1', []), ('2', []), ('2', [])], input_dim={'1': 2, '2': 2}, multiplicity=1, activations=['relu'])\n    hs = HinSAGE(layer_sizes=[2, 2], n_samples=[2, 2], input_neighbor_tree=[('1', [1, 2]), ('1', [3, 4]), ('2', [5]), ('1', []), ('2', []), ('2', [])], input_dim={'1': 2, '2': 2}, multiplicity=1, activations=(['linear'] * 2))\n    assert (hs.activations == (['linear'] * 2))", "masked_code": "def test_hinsage_passing_activations():\n    hs = HinSAGE(layer_sizes=[2, 2], n_samples=[2, 2], input_neighbor_tree=[('1', [1, 2]), ('1', [3, 4]), ('2', [5]), ('1', []), ('2', []), ('2', [])], multiplicity=1, input_dim={'1': 2, '2': 2})\n    assert (hs.activations == ['relu', 'linear'])\n    with pytest.raises(ValueError):\n        hs = HinSAGE(layer_sizes=[2, 2], n_samples=[2, 2], input_neighbor_tree=[('1', [1, 2]), ('1', [3, 4]), ('2', [5]), ('1', []), ('2', []), ('2', [])], multiplicity=1, input_dim={'1': 2, '2': 2}, activations=['fred', 'wilma'])\n    with pytest.raises(ValueError):\n        hs = HinSAGE(layer_sizes=[2, 2], n_samples=[2, 2], input_neighbor_tree=[('1', [1, 2]), ('1', [3, 4]), ('2', [5]), ('1', []), ('2', []), ('2', [])], input_dim={'1': 2, '2': 2}, multiplicity=1, activations=['relu'])\n    hs = HinSAGE(layer_sizes=[2, 2], n_samples=[2, 2], input_neighbor_tree=[('1', [1, 2]), ('1', [3, 4]), ('2', [5]), ('1', []), ('2', []), ('2', [])], input_dim={'1': 2, '2': 2}, multiplicity=1, activations=(['linear'] * 2))\n    assert (hs.activations == '???')", "ground_truth": "(['linear'] * 2)", "quality_analysis": {"complexity_score": 8, "left_complexity": 2, "right_complexity": 6, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_682", "reponame": "stellargraph", "testpath": "tests/layer/test_knowledge_graph.py", "testname": "test_knowledge_graph.py", "classname": null, "funcname": "test_rote_roth", "imports": ["import itertools", "import pytest", "import pandas as pd", "import numpy as np", "import tensorflow as tf", "from tensorflow.keras import Model, initializers, losses as tf_losses, layers", "from stellargraph import StellarGraph, StellarDiGraph, losses as sg_losses", "from stellargraph.mapper.knowledge_graph import KGTripleGenerator", "from stellargraph.layer.knowledge_graph import KGModel, KGScore, ComplEx, DistMult, RotatE, RotE, RotH, _ranks_from_score_columns", "from .. import test_utils", "from ..test_utils.graphs import knowledge_graph"], "code": "@pytest.mark.parametrize('model_class', [RotE, RotH])\ndef test_rote_roth(knowledge_graph, model_class):\n    gen = KGTripleGenerator(knowledge_graph, 3)\n    init = initializers.RandomUniform((- 1), 1)\n    rot_model = model_class(gen, 6, embeddings_initializer=init)\n    (x_inp, x_out) = rot_model.in_out_tensors()\n    model = Model(x_inp, x_out)\n    model.summary()\n    model.compile(loss=tf_losses.BinaryCrossentropy(from_logits=True))\n    every_edge = itertools.product(knowledge_graph.nodes(), knowledge_graph._edges.types.pandas_index, knowledge_graph.nodes())\n    df = triple_df(*every_edge)\n    model.fit(gen.flow(df.iloc[:7], negative_samples=2), validation_data=gen.flow(df.iloc[7:14], negative_samples=3))\n    prediction = model.predict(gen.flow(df))\n    ((node_emb, node_bias), (et_emb, et_theta)) = rot_model.embedding_arrays()\n    if (model_class is RotE):\n        s_idx = knowledge_graph.node_ids_to_ilocs(df.source)\n        r_idx = knowledge_graph.edge_type_names_to_ilocs(df.label)\n        o_idx = knowledge_graph.node_ids_to_ilocs(df.target)\n        e_s = node_emb[(s_idx, :)]\n        b_s = node_bias[(s_idx, 0)]\n        r_r = et_emb[(r_idx, :)]\n        theta_r = et_theta[(r_idx, :)]\n        e_o = node_emb[(o_idx, :)]\n        b_o = node_bias[(o_idx, 0)]\n        rot_r = (np.cos(theta_r) + (1j * np.sin(theta_r)))\n        assert (e_s.dtype == np.float32)\n        rotated = (e_s.view(np.complex64) * rot_r).view(np.float32)\n        actual = (((- (np.linalg.norm(((rotated + r_r) - e_o), axis=(- 1)) ** 2)) + b_s) + b_o)\n        np.testing.assert_allclose(prediction[(:, 0)], actual, rtol=0.001, atol=1e-14)\n    model2 = Model(*rot_model.in_out_tensors())\n    prediction2 = model2.predict(gen.flow(df))\n    np.testing.assert_array_equal(prediction, prediction2)", "masked_code": "@pytest.mark.parametrize('model_class', [RotE, RotH])\ndef test_rote_roth(knowledge_graph, model_class):\n    gen = KGTripleGenerator(knowledge_graph, 3)\n    init = initializers.RandomUniform((- 1), 1)\n    rot_model = model_class(gen, 6, embeddings_initializer=init)\n    (x_inp, x_out) = rot_model.in_out_tensors()\n    model = Model(x_inp, x_out)\n    model.summary()\n    model.compile(loss=tf_losses.BinaryCrossentropy(from_logits=True))\n    every_edge = itertools.product(knowledge_graph.nodes(), knowledge_graph._edges.types.pandas_index, knowledge_graph.nodes())\n    df = triple_df(*every_edge)\n    model.fit(gen.flow(df.iloc[:7], negative_samples=2), validation_data=gen.flow(df.iloc[7:14], negative_samples=3))\n    prediction = model.predict(gen.flow(df))\n    ((node_emb, node_bias), (et_emb, et_theta)) = rot_model.embedding_arrays()\n    if (model_class is RotE):\n        s_idx = knowledge_graph.node_ids_to_ilocs(df.source)\n        r_idx = knowledge_graph.edge_type_names_to_ilocs(df.label)\n        o_idx = knowledge_graph.node_ids_to_ilocs(df.target)\n        e_s = node_emb[(s_idx, :)]\n        b_s = node_bias[(s_idx, 0)]\n        r_r = et_emb[(r_idx, :)]\n        theta_r = et_theta[(r_idx, :)]\n        e_o = node_emb[(o_idx, :)]\n        b_o = node_bias[(o_idx, 0)]\n        rot_r = (np.cos(theta_r) + (1j * np.sin(theta_r)))\n        assert (e_s.dtype == '???')\n        rotated = (e_s.view(np.complex64) * rot_r).view(np.float32)\n        actual = (((- (np.linalg.norm(((rotated + r_r) - e_o), axis=(- 1)) ** 2)) + b_s) + b_o)\n        np.testing.assert_allclose(prediction[(:, 0)], actual, rtol=0.001, atol=1e-14)\n    model2 = Model(*rot_model.in_out_tensors())\n    prediction2 = model2.predict(gen.flow(df))\n    np.testing.assert_array_equal(prediction, prediction2)", "ground_truth": "np.float32", "quality_analysis": {"complexity_score": 4, "left_complexity": 2, "right_complexity": 2, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_683", "reponame": "stellargraph", "testpath": "tests/layer/test_knowledge_graph.py", "testname": "test_knowledge_graph.py", "classname": null, "funcname": "test_model_rankings", "imports": ["import itertools", "import pytest", "import pandas as pd", "import numpy as np", "import tensorflow as tf", "from tensorflow.keras import Model, initializers, losses as tf_losses, layers", "from stellargraph import StellarGraph, StellarDiGraph, losses as sg_losses", "from stellargraph.mapper.knowledge_graph import KGTripleGenerator", "from stellargraph.layer.knowledge_graph import KGModel, KGScore, ComplEx, DistMult, RotatE, RotE, RotH, _ranks_from_score_columns", "from .. import test_utils", "from ..test_utils.graphs import knowledge_graph"], "code": "@pytest.mark.parametrize('model_maker', [ComplEx, DistMult, pytest.param(RotatE, marks=test_utils.flaky_xfail_mark(AssertionError, 1623)), pytest.param(RotH, marks=test_utils.flaky_xfail_mark(AssertionError, 1675)), RotE])\ndef test_model_rankings(model_maker):\n    nodes = pd.DataFrame(index=['a', 'b', 'c', 'd'])\n    rels = ['W', 'X', 'Y', 'Z']\n    empty = pd.DataFrame(columns=['source', 'target'])\n    every_edge = itertools.product(nodes.index, rels, nodes.index)\n    every_edge_df = triple_df(*every_edge)\n    no_edges = StellarDiGraph(nodes, {name: empty for name in rels})\n    one_per_label_df = every_edge_df.groupby('label').apply((lambda df: df.sample(n=1))).droplevel(0)\n    others_df = every_edge_df.sample(frac=0.25)\n    some_edges_df = pd.concat([one_per_label_df, others_df], ignore_index=True)\n    some_edges = StellarDiGraph(nodes, {name: df.drop(columns='label') for (name, df) in some_edges_df.groupby('label')})\n    all_edges = StellarDiGraph(nodes=nodes, edges={name: df.drop(columns='label') for (name, df) in every_edge_df.groupby('label')})\n    gen = KGTripleGenerator(all_edges, 3)\n    sg_model = model_maker(gen, embedding_dimension=6)\n    (x_inp, x_out) = sg_model.in_out_tensors()\n    model = Model(x_inp, x_out)\n    (raw_some, filtered_some) = sg_model.rank_edges_against_all_nodes(gen.flow(every_edge_df), some_edges)\n    assert (raw_some.dtype == int)\n    assert np.all((raw_some >= 1))\n    assert np.all((filtered_some <= raw_some))\n    assert np.any((filtered_some < raw_some))\n    (raw_no, filtered_no) = sg_model.rank_edges_against_all_nodes(gen.flow(every_edge_df), no_edges)\n    np.testing.assert_array_equal(raw_no, raw_some)\n    np.testing.assert_array_equal(raw_no, filtered_no)\n    (raw_all, filtered_all) = sg_model.rank_edges_against_all_nodes(gen.flow(every_edge_df), all_edges)\n    np.testing.assert_array_equal(raw_all, raw_some)\n    assert np.all((filtered_all == 1))\n    predictions = model.predict(gen.flow(every_edge_df))\n    for ((source, rel, target), score, raw, filtered) in zip(every_edge_df.itertuples(index=False), predictions, raw_some, filtered_some):\n\n        def rank(compare_selector):\n            return (1 + (predictions[compare_selector] > score).sum())\n        same_r = (every_edge_df.label == rel)\n        same_s_r = ((every_edge_df.source == source) & same_r)\n        expected_raw_mod_o_rank = rank(same_s_r)\n        assert (raw[0] == expected_raw_mod_o_rank)\n        known_objects = some_edges_df[((some_edges_df.source == source) & (some_edges_df.label == rel))]\n        object_is_unknown = (~ every_edge_df.target.isin(known_objects.target))\n        expected_filt_mod_o_rank = rank((same_s_r & object_is_unknown))\n        assert (filtered[0] == expected_filt_mod_o_rank)\n        same_r_o = (same_r & (every_edge_df.target == target))\n        expected_raw_mod_s_rank = rank(same_r_o)\n        assert (raw[1] == expected_raw_mod_s_rank)\n        known_subjects = some_edges_df[((some_edges_df.label == rel) & (some_edges_df.target == target))]\n        subject_is_unknown = (~ every_edge_df.source.isin(known_subjects.source))\n        expected_filt_mod_s_rank = rank((subject_is_unknown & same_r_o))\n        assert (filtered[1] == expected_filt_mod_s_rank)", "masked_code": "@pytest.mark.parametrize('model_maker', [ComplEx, DistMult, pytest.param(RotatE, marks=test_utils.flaky_xfail_mark(AssertionError, 1623)), pytest.param(RotH, marks=test_utils.flaky_xfail_mark(AssertionError, 1675)), RotE])\ndef test_model_rankings(model_maker):\n    nodes = pd.DataFrame(index=['a', 'b', 'c', 'd'])\n    rels = ['W', 'X', 'Y', 'Z']\n    empty = pd.DataFrame(columns=['source', 'target'])\n    every_edge = itertools.product(nodes.index, rels, nodes.index)\n    every_edge_df = triple_df(*every_edge)\n    no_edges = StellarDiGraph(nodes, {name: empty for name in rels})\n    one_per_label_df = every_edge_df.groupby('label').apply((lambda df: df.sample(n=1))).droplevel(0)\n    others_df = every_edge_df.sample(frac=0.25)\n    some_edges_df = pd.concat([one_per_label_df, others_df], ignore_index=True)\n    some_edges = StellarDiGraph(nodes, {name: df.drop(columns='label') for (name, df) in some_edges_df.groupby('label')})\n    all_edges = StellarDiGraph(nodes=nodes, edges={name: df.drop(columns='label') for (name, df) in every_edge_df.groupby('label')})\n    gen = KGTripleGenerator(all_edges, 3)\n    sg_model = model_maker(gen, embedding_dimension=6)\n    (x_inp, x_out) = sg_model.in_out_tensors()\n    model = Model(x_inp, x_out)\n    (raw_some, filtered_some) = sg_model.rank_edges_against_all_nodes(gen.flow(every_edge_df), some_edges)\n    assert (raw_some.dtype == '???')\n    assert np.all((raw_some >= 1))\n    assert np.all((filtered_some <= raw_some))\n    assert np.any((filtered_some < raw_some))\n    (raw_no, filtered_no) = sg_model.rank_edges_against_all_nodes(gen.flow(every_edge_df), no_edges)\n    np.testing.assert_array_equal(raw_no, raw_some)\n    np.testing.assert_array_equal(raw_no, filtered_no)\n    (raw_all, filtered_all) = sg_model.rank_edges_against_all_nodes(gen.flow(every_edge_df), all_edges)\n    np.testing.assert_array_equal(raw_all, raw_some)\n    assert np.all((filtered_all == 1))\n    predictions = model.predict(gen.flow(every_edge_df))\n    for ((source, rel, target), score, raw, filtered) in zip(every_edge_df.itertuples(index=False), predictions, raw_some, filtered_some):\n\n        def rank(compare_selector):\n            return (1 + (predictions[compare_selector] > score).sum())\n        same_r = (every_edge_df.label == rel)\n        same_s_r = ((every_edge_df.source == source) & same_r)\n        expected_raw_mod_o_rank = rank(same_s_r)\n        assert (raw[0] == expected_raw_mod_o_rank)\n        known_objects = some_edges_df[((some_edges_df.source == source) & (some_edges_df.label == rel))]\n        object_is_unknown = (~ every_edge_df.target.isin(known_objects.target))\n        expected_filt_mod_o_rank = rank((same_s_r & object_is_unknown))\n        assert (filtered[0] == expected_filt_mod_o_rank)\n        same_r_o = (same_r & (every_edge_df.target == target))\n        expected_raw_mod_s_rank = rank(same_r_o)\n        assert (raw[1] == expected_raw_mod_s_rank)\n        known_subjects = some_edges_df[((some_edges_df.label == rel) & (some_edges_df.target == target))]\n        subject_is_unknown = (~ every_edge_df.source.isin(known_subjects.source))\n        expected_filt_mod_s_rank = rank((subject_is_unknown & same_r_o))\n        assert (filtered[1] == expected_filt_mod_s_rank)", "ground_truth": "int", "quality_analysis": {"complexity_score": 3, "left_complexity": 2, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_684", "reponame": "stellargraph", "testpath": "tests/layer/test_knowledge_graph.py", "testname": "test_knowledge_graph.py", "classname": null, "funcname": "test_model_rankings", "imports": ["import itertools", "import pytest", "import pandas as pd", "import numpy as np", "import tensorflow as tf", "from tensorflow.keras import Model, initializers, losses as tf_losses, layers", "from stellargraph import StellarGraph, StellarDiGraph, losses as sg_losses", "from stellargraph.mapper.knowledge_graph import KGTripleGenerator", "from stellargraph.layer.knowledge_graph import KGModel, KGScore, ComplEx, DistMult, RotatE, RotE, RotH, _ranks_from_score_columns", "from .. import test_utils", "from ..test_utils.graphs import knowledge_graph"], "code": "@pytest.mark.parametrize('model_maker', [ComplEx, DistMult, pytest.param(RotatE, marks=test_utils.flaky_xfail_mark(AssertionError, 1623)), pytest.param(RotH, marks=test_utils.flaky_xfail_mark(AssertionError, 1675)), RotE])\ndef test_model_rankings(model_maker):\n    nodes = pd.DataFrame(index=['a', 'b', 'c', 'd'])\n    rels = ['W', 'X', 'Y', 'Z']\n    empty = pd.DataFrame(columns=['source', 'target'])\n    every_edge = itertools.product(nodes.index, rels, nodes.index)\n    every_edge_df = triple_df(*every_edge)\n    no_edges = StellarDiGraph(nodes, {name: empty for name in rels})\n    one_per_label_df = every_edge_df.groupby('label').apply((lambda df: df.sample(n=1))).droplevel(0)\n    others_df = every_edge_df.sample(frac=0.25)\n    some_edges_df = pd.concat([one_per_label_df, others_df], ignore_index=True)\n    some_edges = StellarDiGraph(nodes, {name: df.drop(columns='label') for (name, df) in some_edges_df.groupby('label')})\n    all_edges = StellarDiGraph(nodes=nodes, edges={name: df.drop(columns='label') for (name, df) in every_edge_df.groupby('label')})\n    gen = KGTripleGenerator(all_edges, 3)\n    sg_model = model_maker(gen, embedding_dimension=6)\n    (x_inp, x_out) = sg_model.in_out_tensors()\n    model = Model(x_inp, x_out)\n    (raw_some, filtered_some) = sg_model.rank_edges_against_all_nodes(gen.flow(every_edge_df), some_edges)\n    assert (raw_some.dtype == int)\n    assert np.all((raw_some >= 1))\n    assert np.all((filtered_some <= raw_some))\n    assert np.any((filtered_some < raw_some))\n    (raw_no, filtered_no) = sg_model.rank_edges_against_all_nodes(gen.flow(every_edge_df), no_edges)\n    np.testing.assert_array_equal(raw_no, raw_some)\n    np.testing.assert_array_equal(raw_no, filtered_no)\n    (raw_all, filtered_all) = sg_model.rank_edges_against_all_nodes(gen.flow(every_edge_df), all_edges)\n    np.testing.assert_array_equal(raw_all, raw_some)\n    assert np.all((filtered_all == 1))\n    predictions = model.predict(gen.flow(every_edge_df))\n    for ((source, rel, target), score, raw, filtered) in zip(every_edge_df.itertuples(index=False), predictions, raw_some, filtered_some):\n\n        def rank(compare_selector):\n            return (1 + (predictions[compare_selector] > score).sum())\n        same_r = (every_edge_df.label == rel)\n        same_s_r = ((every_edge_df.source == source) & same_r)\n        expected_raw_mod_o_rank = rank(same_s_r)\n        assert (raw[0] == expected_raw_mod_o_rank)\n        known_objects = some_edges_df[((some_edges_df.source == source) & (some_edges_df.label == rel))]\n        object_is_unknown = (~ every_edge_df.target.isin(known_objects.target))\n        expected_filt_mod_o_rank = rank((same_s_r & object_is_unknown))\n        assert (filtered[0] == expected_filt_mod_o_rank)\n        same_r_o = (same_r & (every_edge_df.target == target))\n        expected_raw_mod_s_rank = rank(same_r_o)\n        assert (raw[1] == expected_raw_mod_s_rank)\n        known_subjects = some_edges_df[((some_edges_df.label == rel) & (some_edges_df.target == target))]\n        subject_is_unknown = (~ every_edge_df.source.isin(known_subjects.source))\n        expected_filt_mod_s_rank = rank((subject_is_unknown & same_r_o))\n        assert (filtered[1] == expected_filt_mod_s_rank)", "masked_code": "@pytest.mark.parametrize('model_maker', [ComplEx, DistMult, pytest.param(RotatE, marks=test_utils.flaky_xfail_mark(AssertionError, 1623)), pytest.param(RotH, marks=test_utils.flaky_xfail_mark(AssertionError, 1675)), RotE])\ndef test_model_rankings(model_maker):\n    nodes = pd.DataFrame(index=['a', 'b', 'c', 'd'])\n    rels = ['W', 'X', 'Y', 'Z']\n    empty = pd.DataFrame(columns=['source', 'target'])\n    every_edge = itertools.product(nodes.index, rels, nodes.index)\n    every_edge_df = triple_df(*every_edge)\n    no_edges = StellarDiGraph(nodes, {name: empty for name in rels})\n    one_per_label_df = every_edge_df.groupby('label').apply((lambda df: df.sample(n=1))).droplevel(0)\n    others_df = every_edge_df.sample(frac=0.25)\n    some_edges_df = pd.concat([one_per_label_df, others_df], ignore_index=True)\n    some_edges = StellarDiGraph(nodes, {name: df.drop(columns='label') for (name, df) in some_edges_df.groupby('label')})\n    all_edges = StellarDiGraph(nodes=nodes, edges={name: df.drop(columns='label') for (name, df) in every_edge_df.groupby('label')})\n    gen = KGTripleGenerator(all_edges, 3)\n    sg_model = model_maker(gen, embedding_dimension=6)\n    (x_inp, x_out) = sg_model.in_out_tensors()\n    model = Model(x_inp, x_out)\n    (raw_some, filtered_some) = sg_model.rank_edges_against_all_nodes(gen.flow(every_edge_df), some_edges)\n    assert (raw_some.dtype == int)\n    assert np.all((raw_some >= 1))\n    assert np.all((filtered_some <= raw_some))\n    assert np.any((filtered_some < raw_some))\n    (raw_no, filtered_no) = sg_model.rank_edges_against_all_nodes(gen.flow(every_edge_df), no_edges)\n    np.testing.assert_array_equal(raw_no, raw_some)\n    np.testing.assert_array_equal(raw_no, filtered_no)\n    (raw_all, filtered_all) = sg_model.rank_edges_against_all_nodes(gen.flow(every_edge_df), all_edges)\n    np.testing.assert_array_equal(raw_all, raw_some)\n    assert np.all((filtered_all == 1))\n    predictions = model.predict(gen.flow(every_edge_df))\n    for ((source, rel, target), score, raw, filtered) in zip(every_edge_df.itertuples(index=False), predictions, raw_some, filtered_some):\n\n        def rank(compare_selector):\n            return (1 + (predictions[compare_selector] > score).sum())\n        same_r = (every_edge_df.label == rel)\n        same_s_r = ((every_edge_df.source == source) & same_r)\n        expected_raw_mod_o_rank = rank(same_s_r)\n        assert (raw[0] == '???')\n        known_objects = some_edges_df[((some_edges_df.source == source) & (some_edges_df.label == rel))]\n        object_is_unknown = (~ every_edge_df.target.isin(known_objects.target))\n        expected_filt_mod_o_rank = rank((same_s_r & object_is_unknown))\n        assert (filtered[0] == expected_filt_mod_o_rank)\n        same_r_o = (same_r & (every_edge_df.target == target))\n        expected_raw_mod_s_rank = rank(same_r_o)\n        assert (raw[1] == expected_raw_mod_s_rank)\n        known_subjects = some_edges_df[((some_edges_df.label == rel) & (some_edges_df.target == target))]\n        subject_is_unknown = (~ every_edge_df.source.isin(known_subjects.source))\n        expected_filt_mod_s_rank = rank((subject_is_unknown & same_r_o))\n        assert (filtered[1] == expected_filt_mod_s_rank)", "ground_truth": "expected_raw_mod_o_rank", "quality_analysis": {"complexity_score": 6, "left_complexity": 5, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_685", "reponame": "stellargraph", "testpath": "tests/layer/test_knowledge_graph.py", "testname": "test_knowledge_graph.py", "classname": null, "funcname": "test_model_rankings", "imports": ["import itertools", "import pytest", "import pandas as pd", "import numpy as np", "import tensorflow as tf", "from tensorflow.keras import Model, initializers, losses as tf_losses, layers", "from stellargraph import StellarGraph, StellarDiGraph, losses as sg_losses", "from stellargraph.mapper.knowledge_graph import KGTripleGenerator", "from stellargraph.layer.knowledge_graph import KGModel, KGScore, ComplEx, DistMult, RotatE, RotE, RotH, _ranks_from_score_columns", "from .. import test_utils", "from ..test_utils.graphs import knowledge_graph"], "code": "@pytest.mark.parametrize('model_maker', [ComplEx, DistMult, pytest.param(RotatE, marks=test_utils.flaky_xfail_mark(AssertionError, 1623)), pytest.param(RotH, marks=test_utils.flaky_xfail_mark(AssertionError, 1675)), RotE])\ndef test_model_rankings(model_maker):\n    nodes = pd.DataFrame(index=['a', 'b', 'c', 'd'])\n    rels = ['W', 'X', 'Y', 'Z']\n    empty = pd.DataFrame(columns=['source', 'target'])\n    every_edge = itertools.product(nodes.index, rels, nodes.index)\n    every_edge_df = triple_df(*every_edge)\n    no_edges = StellarDiGraph(nodes, {name: empty for name in rels})\n    one_per_label_df = every_edge_df.groupby('label').apply((lambda df: df.sample(n=1))).droplevel(0)\n    others_df = every_edge_df.sample(frac=0.25)\n    some_edges_df = pd.concat([one_per_label_df, others_df], ignore_index=True)\n    some_edges = StellarDiGraph(nodes, {name: df.drop(columns='label') for (name, df) in some_edges_df.groupby('label')})\n    all_edges = StellarDiGraph(nodes=nodes, edges={name: df.drop(columns='label') for (name, df) in every_edge_df.groupby('label')})\n    gen = KGTripleGenerator(all_edges, 3)\n    sg_model = model_maker(gen, embedding_dimension=6)\n    (x_inp, x_out) = sg_model.in_out_tensors()\n    model = Model(x_inp, x_out)\n    (raw_some, filtered_some) = sg_model.rank_edges_against_all_nodes(gen.flow(every_edge_df), some_edges)\n    assert (raw_some.dtype == int)\n    assert np.all((raw_some >= 1))\n    assert np.all((filtered_some <= raw_some))\n    assert np.any((filtered_some < raw_some))\n    (raw_no, filtered_no) = sg_model.rank_edges_against_all_nodes(gen.flow(every_edge_df), no_edges)\n    np.testing.assert_array_equal(raw_no, raw_some)\n    np.testing.assert_array_equal(raw_no, filtered_no)\n    (raw_all, filtered_all) = sg_model.rank_edges_against_all_nodes(gen.flow(every_edge_df), all_edges)\n    np.testing.assert_array_equal(raw_all, raw_some)\n    assert np.all((filtered_all == 1))\n    predictions = model.predict(gen.flow(every_edge_df))\n    for ((source, rel, target), score, raw, filtered) in zip(every_edge_df.itertuples(index=False), predictions, raw_some, filtered_some):\n\n        def rank(compare_selector):\n            return (1 + (predictions[compare_selector] > score).sum())\n        same_r = (every_edge_df.label == rel)\n        same_s_r = ((every_edge_df.source == source) & same_r)\n        expected_raw_mod_o_rank = rank(same_s_r)\n        assert (raw[0] == expected_raw_mod_o_rank)\n        known_objects = some_edges_df[((some_edges_df.source == source) & (some_edges_df.label == rel))]\n        object_is_unknown = (~ every_edge_df.target.isin(known_objects.target))\n        expected_filt_mod_o_rank = rank((same_s_r & object_is_unknown))\n        assert (filtered[0] == expected_filt_mod_o_rank)\n        same_r_o = (same_r & (every_edge_df.target == target))\n        expected_raw_mod_s_rank = rank(same_r_o)\n        assert (raw[1] == expected_raw_mod_s_rank)\n        known_subjects = some_edges_df[((some_edges_df.label == rel) & (some_edges_df.target == target))]\n        subject_is_unknown = (~ every_edge_df.source.isin(known_subjects.source))\n        expected_filt_mod_s_rank = rank((subject_is_unknown & same_r_o))\n        assert (filtered[1] == expected_filt_mod_s_rank)", "masked_code": "@pytest.mark.parametrize('model_maker', [ComplEx, DistMult, pytest.param(RotatE, marks=test_utils.flaky_xfail_mark(AssertionError, 1623)), pytest.param(RotH, marks=test_utils.flaky_xfail_mark(AssertionError, 1675)), RotE])\ndef test_model_rankings(model_maker):\n    nodes = pd.DataFrame(index=['a', 'b', 'c', 'd'])\n    rels = ['W', 'X', 'Y', 'Z']\n    empty = pd.DataFrame(columns=['source', 'target'])\n    every_edge = itertools.product(nodes.index, rels, nodes.index)\n    every_edge_df = triple_df(*every_edge)\n    no_edges = StellarDiGraph(nodes, {name: empty for name in rels})\n    one_per_label_df = every_edge_df.groupby('label').apply((lambda df: df.sample(n=1))).droplevel(0)\n    others_df = every_edge_df.sample(frac=0.25)\n    some_edges_df = pd.concat([one_per_label_df, others_df], ignore_index=True)\n    some_edges = StellarDiGraph(nodes, {name: df.drop(columns='label') for (name, df) in some_edges_df.groupby('label')})\n    all_edges = StellarDiGraph(nodes=nodes, edges={name: df.drop(columns='label') for (name, df) in every_edge_df.groupby('label')})\n    gen = KGTripleGenerator(all_edges, 3)\n    sg_model = model_maker(gen, embedding_dimension=6)\n    (x_inp, x_out) = sg_model.in_out_tensors()\n    model = Model(x_inp, x_out)\n    (raw_some, filtered_some) = sg_model.rank_edges_against_all_nodes(gen.flow(every_edge_df), some_edges)\n    assert (raw_some.dtype == int)\n    assert np.all((raw_some >= 1))\n    assert np.all((filtered_some <= raw_some))\n    assert np.any((filtered_some < raw_some))\n    (raw_no, filtered_no) = sg_model.rank_edges_against_all_nodes(gen.flow(every_edge_df), no_edges)\n    np.testing.assert_array_equal(raw_no, raw_some)\n    np.testing.assert_array_equal(raw_no, filtered_no)\n    (raw_all, filtered_all) = sg_model.rank_edges_against_all_nodes(gen.flow(every_edge_df), all_edges)\n    np.testing.assert_array_equal(raw_all, raw_some)\n    assert np.all((filtered_all == 1))\n    predictions = model.predict(gen.flow(every_edge_df))\n    for ((source, rel, target), score, raw, filtered) in zip(every_edge_df.itertuples(index=False), predictions, raw_some, filtered_some):\n\n        def rank(compare_selector):\n            return (1 + (predictions[compare_selector] > score).sum())\n        same_r = (every_edge_df.label == rel)\n        same_s_r = ((every_edge_df.source == source) & same_r)\n        expected_raw_mod_o_rank = rank(same_s_r)\n        assert (raw[0] == expected_raw_mod_o_rank)\n        known_objects = some_edges_df[((some_edges_df.source == source) & (some_edges_df.label == rel))]\n        object_is_unknown = (~ every_edge_df.target.isin(known_objects.target))\n        expected_filt_mod_o_rank = rank((same_s_r & object_is_unknown))\n        assert (filtered[0] == '???')\n        same_r_o = (same_r & (every_edge_df.target == target))\n        expected_raw_mod_s_rank = rank(same_r_o)\n        assert (raw[1] == expected_raw_mod_s_rank)\n        known_subjects = some_edges_df[((some_edges_df.label == rel) & (some_edges_df.target == target))]\n        subject_is_unknown = (~ every_edge_df.source.isin(known_subjects.source))\n        expected_filt_mod_s_rank = rank((subject_is_unknown & same_r_o))\n        assert (filtered[1] == expected_filt_mod_s_rank)", "ground_truth": "expected_filt_mod_o_rank", "quality_analysis": {"complexity_score": 6, "left_complexity": 5, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_686", "reponame": "stellargraph", "testpath": "tests/layer/test_knowledge_graph.py", "testname": "test_knowledge_graph.py", "classname": null, "funcname": "test_model_rankings", "imports": ["import itertools", "import pytest", "import pandas as pd", "import numpy as np", "import tensorflow as tf", "from tensorflow.keras import Model, initializers, losses as tf_losses, layers", "from stellargraph import StellarGraph, StellarDiGraph, losses as sg_losses", "from stellargraph.mapper.knowledge_graph import KGTripleGenerator", "from stellargraph.layer.knowledge_graph import KGModel, KGScore, ComplEx, DistMult, RotatE, RotE, RotH, _ranks_from_score_columns", "from .. import test_utils", "from ..test_utils.graphs import knowledge_graph"], "code": "@pytest.mark.parametrize('model_maker', [ComplEx, DistMult, pytest.param(RotatE, marks=test_utils.flaky_xfail_mark(AssertionError, 1623)), pytest.param(RotH, marks=test_utils.flaky_xfail_mark(AssertionError, 1675)), RotE])\ndef test_model_rankings(model_maker):\n    nodes = pd.DataFrame(index=['a', 'b', 'c', 'd'])\n    rels = ['W', 'X', 'Y', 'Z']\n    empty = pd.DataFrame(columns=['source', 'target'])\n    every_edge = itertools.product(nodes.index, rels, nodes.index)\n    every_edge_df = triple_df(*every_edge)\n    no_edges = StellarDiGraph(nodes, {name: empty for name in rels})\n    one_per_label_df = every_edge_df.groupby('label').apply((lambda df: df.sample(n=1))).droplevel(0)\n    others_df = every_edge_df.sample(frac=0.25)\n    some_edges_df = pd.concat([one_per_label_df, others_df], ignore_index=True)\n    some_edges = StellarDiGraph(nodes, {name: df.drop(columns='label') for (name, df) in some_edges_df.groupby('label')})\n    all_edges = StellarDiGraph(nodes=nodes, edges={name: df.drop(columns='label') for (name, df) in every_edge_df.groupby('label')})\n    gen = KGTripleGenerator(all_edges, 3)\n    sg_model = model_maker(gen, embedding_dimension=6)\n    (x_inp, x_out) = sg_model.in_out_tensors()\n    model = Model(x_inp, x_out)\n    (raw_some, filtered_some) = sg_model.rank_edges_against_all_nodes(gen.flow(every_edge_df), some_edges)\n    assert (raw_some.dtype == int)\n    assert np.all((raw_some >= 1))\n    assert np.all((filtered_some <= raw_some))\n    assert np.any((filtered_some < raw_some))\n    (raw_no, filtered_no) = sg_model.rank_edges_against_all_nodes(gen.flow(every_edge_df), no_edges)\n    np.testing.assert_array_equal(raw_no, raw_some)\n    np.testing.assert_array_equal(raw_no, filtered_no)\n    (raw_all, filtered_all) = sg_model.rank_edges_against_all_nodes(gen.flow(every_edge_df), all_edges)\n    np.testing.assert_array_equal(raw_all, raw_some)\n    assert np.all((filtered_all == 1))\n    predictions = model.predict(gen.flow(every_edge_df))\n    for ((source, rel, target), score, raw, filtered) in zip(every_edge_df.itertuples(index=False), predictions, raw_some, filtered_some):\n\n        def rank(compare_selector):\n            return (1 + (predictions[compare_selector] > score).sum())\n        same_r = (every_edge_df.label == rel)\n        same_s_r = ((every_edge_df.source == source) & same_r)\n        expected_raw_mod_o_rank = rank(same_s_r)\n        assert (raw[0] == expected_raw_mod_o_rank)\n        known_objects = some_edges_df[((some_edges_df.source == source) & (some_edges_df.label == rel))]\n        object_is_unknown = (~ every_edge_df.target.isin(known_objects.target))\n        expected_filt_mod_o_rank = rank((same_s_r & object_is_unknown))\n        assert (filtered[0] == expected_filt_mod_o_rank)\n        same_r_o = (same_r & (every_edge_df.target == target))\n        expected_raw_mod_s_rank = rank(same_r_o)\n        assert (raw[1] == expected_raw_mod_s_rank)\n        known_subjects = some_edges_df[((some_edges_df.label == rel) & (some_edges_df.target == target))]\n        subject_is_unknown = (~ every_edge_df.source.isin(known_subjects.source))\n        expected_filt_mod_s_rank = rank((subject_is_unknown & same_r_o))\n        assert (filtered[1] == expected_filt_mod_s_rank)", "masked_code": "@pytest.mark.parametrize('model_maker', [ComplEx, DistMult, pytest.param(RotatE, marks=test_utils.flaky_xfail_mark(AssertionError, 1623)), pytest.param(RotH, marks=test_utils.flaky_xfail_mark(AssertionError, 1675)), RotE])\ndef test_model_rankings(model_maker):\n    nodes = pd.DataFrame(index=['a', 'b', 'c', 'd'])\n    rels = ['W', 'X', 'Y', 'Z']\n    empty = pd.DataFrame(columns=['source', 'target'])\n    every_edge = itertools.product(nodes.index, rels, nodes.index)\n    every_edge_df = triple_df(*every_edge)\n    no_edges = StellarDiGraph(nodes, {name: empty for name in rels})\n    one_per_label_df = every_edge_df.groupby('label').apply((lambda df: df.sample(n=1))).droplevel(0)\n    others_df = every_edge_df.sample(frac=0.25)\n    some_edges_df = pd.concat([one_per_label_df, others_df], ignore_index=True)\n    some_edges = StellarDiGraph(nodes, {name: df.drop(columns='label') for (name, df) in some_edges_df.groupby('label')})\n    all_edges = StellarDiGraph(nodes=nodes, edges={name: df.drop(columns='label') for (name, df) in every_edge_df.groupby('label')})\n    gen = KGTripleGenerator(all_edges, 3)\n    sg_model = model_maker(gen, embedding_dimension=6)\n    (x_inp, x_out) = sg_model.in_out_tensors()\n    model = Model(x_inp, x_out)\n    (raw_some, filtered_some) = sg_model.rank_edges_against_all_nodes(gen.flow(every_edge_df), some_edges)\n    assert (raw_some.dtype == int)\n    assert np.all((raw_some >= 1))\n    assert np.all((filtered_some <= raw_some))\n    assert np.any((filtered_some < raw_some))\n    (raw_no, filtered_no) = sg_model.rank_edges_against_all_nodes(gen.flow(every_edge_df), no_edges)\n    np.testing.assert_array_equal(raw_no, raw_some)\n    np.testing.assert_array_equal(raw_no, filtered_no)\n    (raw_all, filtered_all) = sg_model.rank_edges_against_all_nodes(gen.flow(every_edge_df), all_edges)\n    np.testing.assert_array_equal(raw_all, raw_some)\n    assert np.all((filtered_all == 1))\n    predictions = model.predict(gen.flow(every_edge_df))\n    for ((source, rel, target), score, raw, filtered) in zip(every_edge_df.itertuples(index=False), predictions, raw_some, filtered_some):\n\n        def rank(compare_selector):\n            return (1 + (predictions[compare_selector] > score).sum())\n        same_r = (every_edge_df.label == rel)\n        same_s_r = ((every_edge_df.source == source) & same_r)\n        expected_raw_mod_o_rank = rank(same_s_r)\n        assert (raw[0] == expected_raw_mod_o_rank)\n        known_objects = some_edges_df[((some_edges_df.source == source) & (some_edges_df.label == rel))]\n        object_is_unknown = (~ every_edge_df.target.isin(known_objects.target))\n        expected_filt_mod_o_rank = rank((same_s_r & object_is_unknown))\n        assert (filtered[0] == expected_filt_mod_o_rank)\n        same_r_o = (same_r & (every_edge_df.target == target))\n        expected_raw_mod_s_rank = rank(same_r_o)\n        assert (raw[1] == '???')\n        known_subjects = some_edges_df[((some_edges_df.label == rel) & (some_edges_df.target == target))]\n        subject_is_unknown = (~ every_edge_df.source.isin(known_subjects.source))\n        expected_filt_mod_s_rank = rank((subject_is_unknown & same_r_o))\n        assert (filtered[1] == expected_filt_mod_s_rank)", "ground_truth": "expected_raw_mod_s_rank", "quality_analysis": {"complexity_score": 6, "left_complexity": 5, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_687", "reponame": "stellargraph", "testpath": "tests/layer/test_knowledge_graph.py", "testname": "test_knowledge_graph.py", "classname": null, "funcname": "test_model_rankings", "imports": ["import itertools", "import pytest", "import pandas as pd", "import numpy as np", "import tensorflow as tf", "from tensorflow.keras import Model, initializers, losses as tf_losses, layers", "from stellargraph import StellarGraph, StellarDiGraph, losses as sg_losses", "from stellargraph.mapper.knowledge_graph import KGTripleGenerator", "from stellargraph.layer.knowledge_graph import KGModel, KGScore, ComplEx, DistMult, RotatE, RotE, RotH, _ranks_from_score_columns", "from .. import test_utils", "from ..test_utils.graphs import knowledge_graph"], "code": "@pytest.mark.parametrize('model_maker', [ComplEx, DistMult, pytest.param(RotatE, marks=test_utils.flaky_xfail_mark(AssertionError, 1623)), pytest.param(RotH, marks=test_utils.flaky_xfail_mark(AssertionError, 1675)), RotE])\ndef test_model_rankings(model_maker):\n    nodes = pd.DataFrame(index=['a', 'b', 'c', 'd'])\n    rels = ['W', 'X', 'Y', 'Z']\n    empty = pd.DataFrame(columns=['source', 'target'])\n    every_edge = itertools.product(nodes.index, rels, nodes.index)\n    every_edge_df = triple_df(*every_edge)\n    no_edges = StellarDiGraph(nodes, {name: empty for name in rels})\n    one_per_label_df = every_edge_df.groupby('label').apply((lambda df: df.sample(n=1))).droplevel(0)\n    others_df = every_edge_df.sample(frac=0.25)\n    some_edges_df = pd.concat([one_per_label_df, others_df], ignore_index=True)\n    some_edges = StellarDiGraph(nodes, {name: df.drop(columns='label') for (name, df) in some_edges_df.groupby('label')})\n    all_edges = StellarDiGraph(nodes=nodes, edges={name: df.drop(columns='label') for (name, df) in every_edge_df.groupby('label')})\n    gen = KGTripleGenerator(all_edges, 3)\n    sg_model = model_maker(gen, embedding_dimension=6)\n    (x_inp, x_out) = sg_model.in_out_tensors()\n    model = Model(x_inp, x_out)\n    (raw_some, filtered_some) = sg_model.rank_edges_against_all_nodes(gen.flow(every_edge_df), some_edges)\n    assert (raw_some.dtype == int)\n    assert np.all((raw_some >= 1))\n    assert np.all((filtered_some <= raw_some))\n    assert np.any((filtered_some < raw_some))\n    (raw_no, filtered_no) = sg_model.rank_edges_against_all_nodes(gen.flow(every_edge_df), no_edges)\n    np.testing.assert_array_equal(raw_no, raw_some)\n    np.testing.assert_array_equal(raw_no, filtered_no)\n    (raw_all, filtered_all) = sg_model.rank_edges_against_all_nodes(gen.flow(every_edge_df), all_edges)\n    np.testing.assert_array_equal(raw_all, raw_some)\n    assert np.all((filtered_all == 1))\n    predictions = model.predict(gen.flow(every_edge_df))\n    for ((source, rel, target), score, raw, filtered) in zip(every_edge_df.itertuples(index=False), predictions, raw_some, filtered_some):\n\n        def rank(compare_selector):\n            return (1 + (predictions[compare_selector] > score).sum())\n        same_r = (every_edge_df.label == rel)\n        same_s_r = ((every_edge_df.source == source) & same_r)\n        expected_raw_mod_o_rank = rank(same_s_r)\n        assert (raw[0] == expected_raw_mod_o_rank)\n        known_objects = some_edges_df[((some_edges_df.source == source) & (some_edges_df.label == rel))]\n        object_is_unknown = (~ every_edge_df.target.isin(known_objects.target))\n        expected_filt_mod_o_rank = rank((same_s_r & object_is_unknown))\n        assert (filtered[0] == expected_filt_mod_o_rank)\n        same_r_o = (same_r & (every_edge_df.target == target))\n        expected_raw_mod_s_rank = rank(same_r_o)\n        assert (raw[1] == expected_raw_mod_s_rank)\n        known_subjects = some_edges_df[((some_edges_df.label == rel) & (some_edges_df.target == target))]\n        subject_is_unknown = (~ every_edge_df.source.isin(known_subjects.source))\n        expected_filt_mod_s_rank = rank((subject_is_unknown & same_r_o))\n        assert (filtered[1] == expected_filt_mod_s_rank)", "masked_code": "@pytest.mark.parametrize('model_maker', [ComplEx, DistMult, pytest.param(RotatE, marks=test_utils.flaky_xfail_mark(AssertionError, 1623)), pytest.param(RotH, marks=test_utils.flaky_xfail_mark(AssertionError, 1675)), RotE])\ndef test_model_rankings(model_maker):\n    nodes = pd.DataFrame(index=['a', 'b', 'c', 'd'])\n    rels = ['W', 'X', 'Y', 'Z']\n    empty = pd.DataFrame(columns=['source', 'target'])\n    every_edge = itertools.product(nodes.index, rels, nodes.index)\n    every_edge_df = triple_df(*every_edge)\n    no_edges = StellarDiGraph(nodes, {name: empty for name in rels})\n    one_per_label_df = every_edge_df.groupby('label').apply((lambda df: df.sample(n=1))).droplevel(0)\n    others_df = every_edge_df.sample(frac=0.25)\n    some_edges_df = pd.concat([one_per_label_df, others_df], ignore_index=True)\n    some_edges = StellarDiGraph(nodes, {name: df.drop(columns='label') for (name, df) in some_edges_df.groupby('label')})\n    all_edges = StellarDiGraph(nodes=nodes, edges={name: df.drop(columns='label') for (name, df) in every_edge_df.groupby('label')})\n    gen = KGTripleGenerator(all_edges, 3)\n    sg_model = model_maker(gen, embedding_dimension=6)\n    (x_inp, x_out) = sg_model.in_out_tensors()\n    model = Model(x_inp, x_out)\n    (raw_some, filtered_some) = sg_model.rank_edges_against_all_nodes(gen.flow(every_edge_df), some_edges)\n    assert (raw_some.dtype == int)\n    assert np.all((raw_some >= 1))\n    assert np.all((filtered_some <= raw_some))\n    assert np.any((filtered_some < raw_some))\n    (raw_no, filtered_no) = sg_model.rank_edges_against_all_nodes(gen.flow(every_edge_df), no_edges)\n    np.testing.assert_array_equal(raw_no, raw_some)\n    np.testing.assert_array_equal(raw_no, filtered_no)\n    (raw_all, filtered_all) = sg_model.rank_edges_against_all_nodes(gen.flow(every_edge_df), all_edges)\n    np.testing.assert_array_equal(raw_all, raw_some)\n    assert np.all((filtered_all == 1))\n    predictions = model.predict(gen.flow(every_edge_df))\n    for ((source, rel, target), score, raw, filtered) in zip(every_edge_df.itertuples(index=False), predictions, raw_some, filtered_some):\n\n        def rank(compare_selector):\n            return (1 + (predictions[compare_selector] > score).sum())\n        same_r = (every_edge_df.label == rel)\n        same_s_r = ((every_edge_df.source == source) & same_r)\n        expected_raw_mod_o_rank = rank(same_s_r)\n        assert (raw[0] == expected_raw_mod_o_rank)\n        known_objects = some_edges_df[((some_edges_df.source == source) & (some_edges_df.label == rel))]\n        object_is_unknown = (~ every_edge_df.target.isin(known_objects.target))\n        expected_filt_mod_o_rank = rank((same_s_r & object_is_unknown))\n        assert (filtered[0] == expected_filt_mod_o_rank)\n        same_r_o = (same_r & (every_edge_df.target == target))\n        expected_raw_mod_s_rank = rank(same_r_o)\n        assert (raw[1] == expected_raw_mod_s_rank)\n        known_subjects = some_edges_df[((some_edges_df.label == rel) & (some_edges_df.target == target))]\n        subject_is_unknown = (~ every_edge_df.source.isin(known_subjects.source))\n        expected_filt_mod_s_rank = rank((subject_is_unknown & same_r_o))\n        assert (filtered[1] == '???')", "ground_truth": "expected_filt_mod_s_rank", "quality_analysis": {"complexity_score": 6, "left_complexity": 5, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_688", "reponame": "stellargraph", "testpath": "tests/layer/test_knowledge_graph.py", "testname": "test_knowledge_graph.py", "classname": null, "funcname": "test_tie_breaking", "imports": ["import itertools", "import pytest", "import pandas as pd", "import numpy as np", "import tensorflow as tf", "from tensorflow.keras import Model, initializers, losses as tf_losses, layers", "from stellargraph import StellarGraph, StellarDiGraph, losses as sg_losses", "from stellargraph.mapper.knowledge_graph import KGTripleGenerator", "from stellargraph.layer.knowledge_graph import KGModel, KGScore, ComplEx, DistMult, RotatE, RotE, RotH, _ranks_from_score_columns", "from .. import test_utils", "from ..test_utils.graphs import knowledge_graph"], "code": "@pytest.mark.parametrize('tie_breaking', ['top', 'bottom', 'random'])\ndef test_tie_breaking(tie_breaking):\n    pred_scores = np.array([[1, 5, 8], [1, 3, 8], [1, 2, 7], [1, 2, 6]])\n    known_edges_graph = StellarDiGraph(nodes=pd.DataFrame(index=['a', 'b', 'c', 'd']), edges=pd.DataFrame([('a', 'b'), ('b', 'd')], columns=['source', 'target']))\n    copies = 100\n    rankings = [_ranks_from_score_columns(pred_scores, true_modified_node_ilocs=np.array([1, 2, 3]), unmodified_node_ilocs=np.array([0, 1, 2]), true_rel_ilocs=np.array([0, 0, 0]), modified_object=True, known_edges_graph=known_edges_graph, tie_breaking=tie_breaking) for _ in range(copies)]\n    all_rankings = np.array(rankings)\n    assert (all_rankings.shape == (copies, 2, 3))\n    top_expected = np.repeat([[[1, 3, 4], [1, 3, 4]]], copies, axis=0)\n    bottom_expected = np.repeat([[[4, 4, 4], [4, 3, 4]]], copies, axis=0)\n    if (tie_breaking == 'top'):\n        np.testing.assert_array_equal(all_rankings, top_expected)\n    elif (tie_breaking == 'bottom'):\n        np.testing.assert_array_equal(all_rankings, bottom_expected)\n    elif (tie_breaking == 'random'):\n        assert (all_rankings >= top_expected).all()\n        assert (all_rankings <= bottom_expected).all()\n        for i in range(all_rankings.shape[1]):\n            raw_or_filtered = all_rankings[(:, i, :)]\n            assert (raw_or_filtered != top_expected[(:, i, :)]).any()\n            assert (raw_or_filtered != bottom_expected[(:, i, :)]).any()", "masked_code": "@pytest.mark.parametrize('tie_breaking', ['top', 'bottom', 'random'])\ndef test_tie_breaking(tie_breaking):\n    pred_scores = np.array([[1, 5, 8], [1, 3, 8], [1, 2, 7], [1, 2, 6]])\n    known_edges_graph = StellarDiGraph(nodes=pd.DataFrame(index=['a', 'b', 'c', 'd']), edges=pd.DataFrame([('a', 'b'), ('b', 'd')], columns=['source', 'target']))\n    copies = 100\n    rankings = [_ranks_from_score_columns(pred_scores, true_modified_node_ilocs=np.array([1, 2, 3]), unmodified_node_ilocs=np.array([0, 1, 2]), true_rel_ilocs=np.array([0, 0, 0]), modified_object=True, known_edges_graph=known_edges_graph, tie_breaking=tie_breaking) for _ in range(copies)]\n    all_rankings = np.array(rankings)\n    assert (all_rankings.shape == '???')\n    top_expected = np.repeat([[[1, 3, 4], [1, 3, 4]]], copies, axis=0)\n    bottom_expected = np.repeat([[[4, 4, 4], [4, 3, 4]]], copies, axis=0)\n    if (tie_breaking == 'top'):\n        np.testing.assert_array_equal(all_rankings, top_expected)\n    elif (tie_breaking == 'bottom'):\n        np.testing.assert_array_equal(all_rankings, bottom_expected)\n    elif (tie_breaking == 'random'):\n        assert (all_rankings >= top_expected).all()\n        assert (all_rankings <= bottom_expected).all()\n        for i in range(all_rankings.shape[1]):\n            raw_or_filtered = all_rankings[(:, i, :)]\n            assert (raw_or_filtered != top_expected[(:, i, :)]).any()\n            assert (raw_or_filtered != bottom_expected[(:, i, :)]).any()", "ground_truth": "(copies, 2, 3)", "quality_analysis": {"complexity_score": 7, "left_complexity": 2, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_689", "reponame": "stellargraph", "testpath": "tests/layer/test_link_inference.py", "testname": "test_link_inference.py", "classname": "Test_LinkEmbedding", "funcname": "test_ip", "imports": ["from stellargraph.layer.link_inference import *", "import tensorflow as tf", "from tensorflow import keras", "import numpy as np", "import pytest"], "code": "def test_ip(self):\n    \" Test the 'ip' binary operator on orthogonal vectors\"\n    (x_src, x_dst) = make_orthonormal_vectors(self.d)\n    x_src = tf.constant(x_src, shape=(1, self.d), dtype='float64')\n    x_dst = tf.constant(x_dst, shape=(1, self.d), dtype='float64')\n    li = LinkEmbedding(method='ip', activation='linear')([x_src, x_dst])\n    print(\"link inference with 'ip' operator on orthonormal vectors: {}\".format(li.numpy()))\n    assert (li.numpy() == pytest.approx(0, abs=1.5e-07))\n    li = LinkEmbedding(method='ip', activation='linear')([x_src, x_src])\n    print(\"link inference with 'ip' operator on unit vector: \", li.numpy())\n    assert (li.numpy() == pytest.approx(1, abs=1.5e-07))\n    li = LinkEmbedding(method='ip', activation='sigmoid')([x_src, x_dst])\n    assert (li.numpy() == pytest.approx(0.5, abs=1.5e-07))\n    li = LinkEmbedding(method='ip', activation='sigmoid')([x_src, x_src])\n    assert (li.numpy() == pytest.approx(0.7310586, abs=1.5e-07))", "masked_code": "def test_ip(self):\n    \" Test the 'ip' binary operator on orthogonal vectors\"\n    (x_src, x_dst) = make_orthonormal_vectors(self.d)\n    x_src = tf.constant(x_src, shape=(1, self.d), dtype='float64')\n    x_dst = tf.constant(x_dst, shape=(1, self.d), dtype='float64')\n    li = LinkEmbedding(method='ip', activation='linear')([x_src, x_dst])\n    print(\"link inference with 'ip' operator on orthonormal vectors: {}\".format(li.numpy()))\n    assert (li.numpy() == '???')\n    li = LinkEmbedding(method='ip', activation='linear')([x_src, x_src])\n    print(\"link inference with 'ip' operator on unit vector: \", li.numpy())\n    assert (li.numpy() == pytest.approx(1, abs=1.5e-07))\n    li = LinkEmbedding(method='ip', activation='sigmoid')([x_src, x_dst])\n    assert (li.numpy() == pytest.approx(0.5, abs=1.5e-07))\n    li = LinkEmbedding(method='ip', activation='sigmoid')([x_src, x_src])\n    assert (li.numpy() == pytest.approx(0.7310586, abs=1.5e-07))", "ground_truth": "pytest.approx(0, abs=1.5e-07)", "quality_analysis": {"complexity_score": 7, "left_complexity": 3, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_690", "reponame": "stellargraph", "testpath": "tests/layer/test_link_inference.py", "testname": "test_link_inference.py", "classname": "Test_LinkEmbedding", "funcname": "test_ip", "imports": ["from stellargraph.layer.link_inference import *", "import tensorflow as tf", "from tensorflow import keras", "import numpy as np", "import pytest"], "code": "def test_ip(self):\n    \" Test the 'ip' binary operator on orthogonal vectors\"\n    (x_src, x_dst) = make_orthonormal_vectors(self.d)\n    x_src = tf.constant(x_src, shape=(1, self.d), dtype='float64')\n    x_dst = tf.constant(x_dst, shape=(1, self.d), dtype='float64')\n    li = LinkEmbedding(method='ip', activation='linear')([x_src, x_dst])\n    print(\"link inference with 'ip' operator on orthonormal vectors: {}\".format(li.numpy()))\n    assert (li.numpy() == pytest.approx(0, abs=1.5e-07))\n    li = LinkEmbedding(method='ip', activation='linear')([x_src, x_src])\n    print(\"link inference with 'ip' operator on unit vector: \", li.numpy())\n    assert (li.numpy() == pytest.approx(1, abs=1.5e-07))\n    li = LinkEmbedding(method='ip', activation='sigmoid')([x_src, x_dst])\n    assert (li.numpy() == pytest.approx(0.5, abs=1.5e-07))\n    li = LinkEmbedding(method='ip', activation='sigmoid')([x_src, x_src])\n    assert (li.numpy() == pytest.approx(0.7310586, abs=1.5e-07))", "masked_code": "def test_ip(self):\n    \" Test the 'ip' binary operator on orthogonal vectors\"\n    (x_src, x_dst) = make_orthonormal_vectors(self.d)\n    x_src = tf.constant(x_src, shape=(1, self.d), dtype='float64')\n    x_dst = tf.constant(x_dst, shape=(1, self.d), dtype='float64')\n    li = LinkEmbedding(method='ip', activation='linear')([x_src, x_dst])\n    print(\"link inference with 'ip' operator on orthonormal vectors: {}\".format(li.numpy()))\n    assert (li.numpy() == pytest.approx(0, abs=1.5e-07))\n    li = LinkEmbedding(method='ip', activation='linear')([x_src, x_src])\n    print(\"link inference with 'ip' operator on unit vector: \", li.numpy())\n    assert (li.numpy() == '???')\n    li = LinkEmbedding(method='ip', activation='sigmoid')([x_src, x_dst])\n    assert (li.numpy() == pytest.approx(0.5, abs=1.5e-07))\n    li = LinkEmbedding(method='ip', activation='sigmoid')([x_src, x_src])\n    assert (li.numpy() == pytest.approx(0.7310586, abs=1.5e-07))", "ground_truth": "pytest.approx(1, abs=1.5e-07)", "quality_analysis": {"complexity_score": 7, "left_complexity": 3, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_691", "reponame": "stellargraph", "testpath": "tests/layer/test_link_inference.py", "testname": "test_link_inference.py", "classname": "Test_LinkEmbedding", "funcname": "test_ip", "imports": ["from stellargraph.layer.link_inference import *", "import tensorflow as tf", "from tensorflow import keras", "import numpy as np", "import pytest"], "code": "def test_ip(self):\n    \" Test the 'ip' binary operator on orthogonal vectors\"\n    (x_src, x_dst) = make_orthonormal_vectors(self.d)\n    x_src = tf.constant(x_src, shape=(1, self.d), dtype='float64')\n    x_dst = tf.constant(x_dst, shape=(1, self.d), dtype='float64')\n    li = LinkEmbedding(method='ip', activation='linear')([x_src, x_dst])\n    print(\"link inference with 'ip' operator on orthonormal vectors: {}\".format(li.numpy()))\n    assert (li.numpy() == pytest.approx(0, abs=1.5e-07))\n    li = LinkEmbedding(method='ip', activation='linear')([x_src, x_src])\n    print(\"link inference with 'ip' operator on unit vector: \", li.numpy())\n    assert (li.numpy() == pytest.approx(1, abs=1.5e-07))\n    li = LinkEmbedding(method='ip', activation='sigmoid')([x_src, x_dst])\n    assert (li.numpy() == pytest.approx(0.5, abs=1.5e-07))\n    li = LinkEmbedding(method='ip', activation='sigmoid')([x_src, x_src])\n    assert (li.numpy() == pytest.approx(0.7310586, abs=1.5e-07))", "masked_code": "def test_ip(self):\n    \" Test the 'ip' binary operator on orthogonal vectors\"\n    (x_src, x_dst) = make_orthonormal_vectors(self.d)\n    x_src = tf.constant(x_src, shape=(1, self.d), dtype='float64')\n    x_dst = tf.constant(x_dst, shape=(1, self.d), dtype='float64')\n    li = LinkEmbedding(method='ip', activation='linear')([x_src, x_dst])\n    print(\"link inference with 'ip' operator on orthonormal vectors: {}\".format(li.numpy()))\n    assert (li.numpy() == pytest.approx(0, abs=1.5e-07))\n    li = LinkEmbedding(method='ip', activation='linear')([x_src, x_src])\n    print(\"link inference with 'ip' operator on unit vector: \", li.numpy())\n    assert (li.numpy() == pytest.approx(1, abs=1.5e-07))\n    li = LinkEmbedding(method='ip', activation='sigmoid')([x_src, x_dst])\n    assert (li.numpy() == '???')\n    li = LinkEmbedding(method='ip', activation='sigmoid')([x_src, x_src])\n    assert (li.numpy() == pytest.approx(0.7310586, abs=1.5e-07))", "ground_truth": "pytest.approx(0.5, abs=1.5e-07)", "quality_analysis": {"complexity_score": 7, "left_complexity": 3, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_692", "reponame": "stellargraph", "testpath": "tests/layer/test_link_inference.py", "testname": "test_link_inference.py", "classname": "Test_LinkEmbedding", "funcname": "test_ip", "imports": ["from stellargraph.layer.link_inference import *", "import tensorflow as tf", "from tensorflow import keras", "import numpy as np", "import pytest"], "code": "def test_ip(self):\n    \" Test the 'ip' binary operator on orthogonal vectors\"\n    (x_src, x_dst) = make_orthonormal_vectors(self.d)\n    x_src = tf.constant(x_src, shape=(1, self.d), dtype='float64')\n    x_dst = tf.constant(x_dst, shape=(1, self.d), dtype='float64')\n    li = LinkEmbedding(method='ip', activation='linear')([x_src, x_dst])\n    print(\"link inference with 'ip' operator on orthonormal vectors: {}\".format(li.numpy()))\n    assert (li.numpy() == pytest.approx(0, abs=1.5e-07))\n    li = LinkEmbedding(method='ip', activation='linear')([x_src, x_src])\n    print(\"link inference with 'ip' operator on unit vector: \", li.numpy())\n    assert (li.numpy() == pytest.approx(1, abs=1.5e-07))\n    li = LinkEmbedding(method='ip', activation='sigmoid')([x_src, x_dst])\n    assert (li.numpy() == pytest.approx(0.5, abs=1.5e-07))\n    li = LinkEmbedding(method='ip', activation='sigmoid')([x_src, x_src])\n    assert (li.numpy() == pytest.approx(0.7310586, abs=1.5e-07))", "masked_code": "def test_ip(self):\n    \" Test the 'ip' binary operator on orthogonal vectors\"\n    (x_src, x_dst) = make_orthonormal_vectors(self.d)\n    x_src = tf.constant(x_src, shape=(1, self.d), dtype='float64')\n    x_dst = tf.constant(x_dst, shape=(1, self.d), dtype='float64')\n    li = LinkEmbedding(method='ip', activation='linear')([x_src, x_dst])\n    print(\"link inference with 'ip' operator on orthonormal vectors: {}\".format(li.numpy()))\n    assert (li.numpy() == pytest.approx(0, abs=1.5e-07))\n    li = LinkEmbedding(method='ip', activation='linear')([x_src, x_src])\n    print(\"link inference with 'ip' operator on unit vector: \", li.numpy())\n    assert (li.numpy() == pytest.approx(1, abs=1.5e-07))\n    li = LinkEmbedding(method='ip', activation='sigmoid')([x_src, x_dst])\n    assert (li.numpy() == pytest.approx(0.5, abs=1.5e-07))\n    li = LinkEmbedding(method='ip', activation='sigmoid')([x_src, x_src])\n    assert (li.numpy() == '???')", "ground_truth": "pytest.approx(0.7310586, abs=1.5e-07)", "quality_analysis": {"complexity_score": 7, "left_complexity": 3, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_693", "reponame": "stellargraph", "testpath": "tests/layer/test_link_inference.py", "testname": "test_link_inference.py", "classname": "Test_LinkEmbedding", "funcname": "test_ip_single_tensor", "imports": ["from stellargraph.layer.link_inference import *", "import tensorflow as tf", "from tensorflow import keras", "import numpy as np", "import pytest"], "code": "def test_ip_single_tensor(self):\n    \" Test the 'ip' binary operator on orthogonal vectors\"\n    (x_src, x_dst) = make_orthonormal_vectors(self.d)\n    x_src = tf.constant(x_src, shape=(1, self.d), dtype='float64')\n    x_dst = tf.constant(x_dst, shape=(1, self.d), dtype='float64')\n    x_link_sd = tf.stack([x_src, x_dst], axis=1)\n    x_link_ss = tf.stack([x_src, x_src], axis=1)\n    li = LinkEmbedding(method='ip', activation='linear')(x_link_sd)\n    print(\"link inference with 'ip' operator on orthonormal vectors: {}\".format(li.numpy()))\n    assert (li.numpy() == pytest.approx(0, abs=1.5e-07))\n    li = LinkEmbedding(method='ip', activation='linear')(x_link_ss)\n    print(\"link inference with 'ip' operator on unit vector: \", li.numpy())\n    assert (li.numpy() == pytest.approx(1, abs=1.5e-07))\n    li = LinkEmbedding(method='ip', activation='sigmoid')(x_link_sd)\n    assert (li.numpy() == pytest.approx(0.5, abs=1.5e-07))\n    li = LinkEmbedding(method='ip', activation='sigmoid')(x_link_ss)\n    assert (li.numpy() == pytest.approx(0.7310586, abs=1.5e-07))", "masked_code": "def test_ip_single_tensor(self):\n    \" Test the 'ip' binary operator on orthogonal vectors\"\n    (x_src, x_dst) = make_orthonormal_vectors(self.d)\n    x_src = tf.constant(x_src, shape=(1, self.d), dtype='float64')\n    x_dst = tf.constant(x_dst, shape=(1, self.d), dtype='float64')\n    x_link_sd = tf.stack([x_src, x_dst], axis=1)\n    x_link_ss = tf.stack([x_src, x_src], axis=1)\n    li = LinkEmbedding(method='ip', activation='linear')(x_link_sd)\n    print(\"link inference with 'ip' operator on orthonormal vectors: {}\".format(li.numpy()))\n    assert (li.numpy() == '???')\n    li = LinkEmbedding(method='ip', activation='linear')(x_link_ss)\n    print(\"link inference with 'ip' operator on unit vector: \", li.numpy())\n    assert (li.numpy() == pytest.approx(1, abs=1.5e-07))\n    li = LinkEmbedding(method='ip', activation='sigmoid')(x_link_sd)\n    assert (li.numpy() == pytest.approx(0.5, abs=1.5e-07))\n    li = LinkEmbedding(method='ip', activation='sigmoid')(x_link_ss)\n    assert (li.numpy() == pytest.approx(0.7310586, abs=1.5e-07))", "ground_truth": "pytest.approx(0, abs=1.5e-07)", "quality_analysis": {"complexity_score": 7, "left_complexity": 3, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_694", "reponame": "stellargraph", "testpath": "tests/layer/test_link_inference.py", "testname": "test_link_inference.py", "classname": "Test_LinkEmbedding", "funcname": "test_ip_single_tensor", "imports": ["from stellargraph.layer.link_inference import *", "import tensorflow as tf", "from tensorflow import keras", "import numpy as np", "import pytest"], "code": "def test_ip_single_tensor(self):\n    \" Test the 'ip' binary operator on orthogonal vectors\"\n    (x_src, x_dst) = make_orthonormal_vectors(self.d)\n    x_src = tf.constant(x_src, shape=(1, self.d), dtype='float64')\n    x_dst = tf.constant(x_dst, shape=(1, self.d), dtype='float64')\n    x_link_sd = tf.stack([x_src, x_dst], axis=1)\n    x_link_ss = tf.stack([x_src, x_src], axis=1)\n    li = LinkEmbedding(method='ip', activation='linear')(x_link_sd)\n    print(\"link inference with 'ip' operator on orthonormal vectors: {}\".format(li.numpy()))\n    assert (li.numpy() == pytest.approx(0, abs=1.5e-07))\n    li = LinkEmbedding(method='ip', activation='linear')(x_link_ss)\n    print(\"link inference with 'ip' operator on unit vector: \", li.numpy())\n    assert (li.numpy() == pytest.approx(1, abs=1.5e-07))\n    li = LinkEmbedding(method='ip', activation='sigmoid')(x_link_sd)\n    assert (li.numpy() == pytest.approx(0.5, abs=1.5e-07))\n    li = LinkEmbedding(method='ip', activation='sigmoid')(x_link_ss)\n    assert (li.numpy() == pytest.approx(0.7310586, abs=1.5e-07))", "masked_code": "def test_ip_single_tensor(self):\n    \" Test the 'ip' binary operator on orthogonal vectors\"\n    (x_src, x_dst) = make_orthonormal_vectors(self.d)\n    x_src = tf.constant(x_src, shape=(1, self.d), dtype='float64')\n    x_dst = tf.constant(x_dst, shape=(1, self.d), dtype='float64')\n    x_link_sd = tf.stack([x_src, x_dst], axis=1)\n    x_link_ss = tf.stack([x_src, x_src], axis=1)\n    li = LinkEmbedding(method='ip', activation='linear')(x_link_sd)\n    print(\"link inference with 'ip' operator on orthonormal vectors: {}\".format(li.numpy()))\n    assert (li.numpy() == pytest.approx(0, abs=1.5e-07))\n    li = LinkEmbedding(method='ip', activation='linear')(x_link_ss)\n    print(\"link inference with 'ip' operator on unit vector: \", li.numpy())\n    assert (li.numpy() == '???')\n    li = LinkEmbedding(method='ip', activation='sigmoid')(x_link_sd)\n    assert (li.numpy() == pytest.approx(0.5, abs=1.5e-07))\n    li = LinkEmbedding(method='ip', activation='sigmoid')(x_link_ss)\n    assert (li.numpy() == pytest.approx(0.7310586, abs=1.5e-07))", "ground_truth": "pytest.approx(1, abs=1.5e-07)", "quality_analysis": {"complexity_score": 7, "left_complexity": 3, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_695", "reponame": "stellargraph", "testpath": "tests/layer/test_link_inference.py", "testname": "test_link_inference.py", "classname": "Test_LinkEmbedding", "funcname": "test_ip_single_tensor", "imports": ["from stellargraph.layer.link_inference import *", "import tensorflow as tf", "from tensorflow import keras", "import numpy as np", "import pytest"], "code": "def test_ip_single_tensor(self):\n    \" Test the 'ip' binary operator on orthogonal vectors\"\n    (x_src, x_dst) = make_orthonormal_vectors(self.d)\n    x_src = tf.constant(x_src, shape=(1, self.d), dtype='float64')\n    x_dst = tf.constant(x_dst, shape=(1, self.d), dtype='float64')\n    x_link_sd = tf.stack([x_src, x_dst], axis=1)\n    x_link_ss = tf.stack([x_src, x_src], axis=1)\n    li = LinkEmbedding(method='ip', activation='linear')(x_link_sd)\n    print(\"link inference with 'ip' operator on orthonormal vectors: {}\".format(li.numpy()))\n    assert (li.numpy() == pytest.approx(0, abs=1.5e-07))\n    li = LinkEmbedding(method='ip', activation='linear')(x_link_ss)\n    print(\"link inference with 'ip' operator on unit vector: \", li.numpy())\n    assert (li.numpy() == pytest.approx(1, abs=1.5e-07))\n    li = LinkEmbedding(method='ip', activation='sigmoid')(x_link_sd)\n    assert (li.numpy() == pytest.approx(0.5, abs=1.5e-07))\n    li = LinkEmbedding(method='ip', activation='sigmoid')(x_link_ss)\n    assert (li.numpy() == pytest.approx(0.7310586, abs=1.5e-07))", "masked_code": "def test_ip_single_tensor(self):\n    \" Test the 'ip' binary operator on orthogonal vectors\"\n    (x_src, x_dst) = make_orthonormal_vectors(self.d)\n    x_src = tf.constant(x_src, shape=(1, self.d), dtype='float64')\n    x_dst = tf.constant(x_dst, shape=(1, self.d), dtype='float64')\n    x_link_sd = tf.stack([x_src, x_dst], axis=1)\n    x_link_ss = tf.stack([x_src, x_src], axis=1)\n    li = LinkEmbedding(method='ip', activation='linear')(x_link_sd)\n    print(\"link inference with 'ip' operator on orthonormal vectors: {}\".format(li.numpy()))\n    assert (li.numpy() == pytest.approx(0, abs=1.5e-07))\n    li = LinkEmbedding(method='ip', activation='linear')(x_link_ss)\n    print(\"link inference with 'ip' operator on unit vector: \", li.numpy())\n    assert (li.numpy() == pytest.approx(1, abs=1.5e-07))\n    li = LinkEmbedding(method='ip', activation='sigmoid')(x_link_sd)\n    assert (li.numpy() == '???')\n    li = LinkEmbedding(method='ip', activation='sigmoid')(x_link_ss)\n    assert (li.numpy() == pytest.approx(0.7310586, abs=1.5e-07))", "ground_truth": "pytest.approx(0.5, abs=1.5e-07)", "quality_analysis": {"complexity_score": 7, "left_complexity": 3, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_696", "reponame": "stellargraph", "testpath": "tests/layer/test_link_inference.py", "testname": "test_link_inference.py", "classname": "Test_LinkEmbedding", "funcname": "test_ip_single_tensor", "imports": ["from stellargraph.layer.link_inference import *", "import tensorflow as tf", "from tensorflow import keras", "import numpy as np", "import pytest"], "code": "def test_ip_single_tensor(self):\n    \" Test the 'ip' binary operator on orthogonal vectors\"\n    (x_src, x_dst) = make_orthonormal_vectors(self.d)\n    x_src = tf.constant(x_src, shape=(1, self.d), dtype='float64')\n    x_dst = tf.constant(x_dst, shape=(1, self.d), dtype='float64')\n    x_link_sd = tf.stack([x_src, x_dst], axis=1)\n    x_link_ss = tf.stack([x_src, x_src], axis=1)\n    li = LinkEmbedding(method='ip', activation='linear')(x_link_sd)\n    print(\"link inference with 'ip' operator on orthonormal vectors: {}\".format(li.numpy()))\n    assert (li.numpy() == pytest.approx(0, abs=1.5e-07))\n    li = LinkEmbedding(method='ip', activation='linear')(x_link_ss)\n    print(\"link inference with 'ip' operator on unit vector: \", li.numpy())\n    assert (li.numpy() == pytest.approx(1, abs=1.5e-07))\n    li = LinkEmbedding(method='ip', activation='sigmoid')(x_link_sd)\n    assert (li.numpy() == pytest.approx(0.5, abs=1.5e-07))\n    li = LinkEmbedding(method='ip', activation='sigmoid')(x_link_ss)\n    assert (li.numpy() == pytest.approx(0.7310586, abs=1.5e-07))", "masked_code": "def test_ip_single_tensor(self):\n    \" Test the 'ip' binary operator on orthogonal vectors\"\n    (x_src, x_dst) = make_orthonormal_vectors(self.d)\n    x_src = tf.constant(x_src, shape=(1, self.d), dtype='float64')\n    x_dst = tf.constant(x_dst, shape=(1, self.d), dtype='float64')\n    x_link_sd = tf.stack([x_src, x_dst], axis=1)\n    x_link_ss = tf.stack([x_src, x_src], axis=1)\n    li = LinkEmbedding(method='ip', activation='linear')(x_link_sd)\n    print(\"link inference with 'ip' operator on orthonormal vectors: {}\".format(li.numpy()))\n    assert (li.numpy() == pytest.approx(0, abs=1.5e-07))\n    li = LinkEmbedding(method='ip', activation='linear')(x_link_ss)\n    print(\"link inference with 'ip' operator on unit vector: \", li.numpy())\n    assert (li.numpy() == pytest.approx(1, abs=1.5e-07))\n    li = LinkEmbedding(method='ip', activation='sigmoid')(x_link_sd)\n    assert (li.numpy() == pytest.approx(0.5, abs=1.5e-07))\n    li = LinkEmbedding(method='ip', activation='sigmoid')(x_link_ss)\n    assert (li.numpy() == '???')", "ground_truth": "pytest.approx(0.7310586, abs=1.5e-07)", "quality_analysis": {"complexity_score": 7, "left_complexity": 3, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_697", "reponame": "stellargraph", "testpath": "tests/layer/test_link_inference.py", "testname": "test_link_inference.py", "classname": "Test_LinkEmbedding", "funcname": "test_mul_l1_l2_avg", "imports": ["from stellargraph.layer.link_inference import *", "import tensorflow as tf", "from tensorflow import keras", "import numpy as np", "import pytest"], "code": "def test_mul_l1_l2_avg(self):\n    \" Test the binary operators: 'mul'/'Hadamard', 'l1', 'l2', 'avg'\"\n    (x_src, x_dst) = make_orthonormal_vectors(self.d)\n    x_src = x_src.reshape(1, 1, self.d)\n    x_dst = x_dst.reshape(1, 1, self.d)\n    inp_src = keras.Input(shape=(1, self.d))\n    inp_dst = keras.Input(shape=(1, self.d))\n    for op in ['mul', 'l1', 'l2', 'avg']:\n        out = LinkEmbedding(method=op)([inp_src, inp_dst])\n        li = keras.Model(inputs=[inp_src, inp_dst], outputs=out)\n        res = li.predict(x=[x_src, x_dst])\n        print(\"link inference with '{}' operator: {}\".format(op, res.flatten()))\n        assert (res.shape == (1, 1, self.d))\n        assert isinstance(res.flatten()[0], np.float32)\n    for op in ['concat']:\n        out = LinkEmbedding(method=op)([inp_src, inp_dst])\n        li = keras.Model(inputs=[inp_src, inp_dst], outputs=out)\n        res = li.predict(x=[x_src, x_dst])\n        print(\"link inference with '{}' operator: {}\".format(op, res.flatten()))\n        assert (res.shape == (1, 1, (2 * self.d)))\n        assert isinstance(res.flatten()[0], np.float32)", "masked_code": "def test_mul_l1_l2_avg(self):\n    \" Test the binary operators: 'mul'/'Hadamard', 'l1', 'l2', 'avg'\"\n    (x_src, x_dst) = make_orthonormal_vectors(self.d)\n    x_src = x_src.reshape(1, 1, self.d)\n    x_dst = x_dst.reshape(1, 1, self.d)\n    inp_src = keras.Input(shape=(1, self.d))\n    inp_dst = keras.Input(shape=(1, self.d))\n    for op in ['mul', 'l1', 'l2', 'avg']:\n        out = LinkEmbedding(method=op)([inp_src, inp_dst])\n        li = keras.Model(inputs=[inp_src, inp_dst], outputs=out)\n        res = li.predict(x=[x_src, x_dst])\n        print(\"link inference with '{}' operator: {}\".format(op, res.flatten()))\n        assert (res.shape == '???')\n        assert isinstance(res.flatten()[0], np.float32)\n    for op in ['concat']:\n        out = LinkEmbedding(method=op)([inp_src, inp_dst])\n        li = keras.Model(inputs=[inp_src, inp_dst], outputs=out)\n        res = li.predict(x=[x_src, x_dst])\n        print(\"link inference with '{}' operator: {}\".format(op, res.flatten()))\n        assert (res.shape == (1, 1, (2 * self.d)))\n        assert isinstance(res.flatten()[0], np.float32)", "ground_truth": "(1, 1, self.d)", "quality_analysis": {"complexity_score": 8, "left_complexity": 2, "right_complexity": 6, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_698", "reponame": "stellargraph", "testpath": "tests/layer/test_link_inference.py", "testname": "test_link_inference.py", "classname": "Test_LinkEmbedding", "funcname": "test_mul_l1_l2_avg", "imports": ["from stellargraph.layer.link_inference import *", "import tensorflow as tf", "from tensorflow import keras", "import numpy as np", "import pytest"], "code": "def test_mul_l1_l2_avg(self):\n    \" Test the binary operators: 'mul'/'Hadamard', 'l1', 'l2', 'avg'\"\n    (x_src, x_dst) = make_orthonormal_vectors(self.d)\n    x_src = x_src.reshape(1, 1, self.d)\n    x_dst = x_dst.reshape(1, 1, self.d)\n    inp_src = keras.Input(shape=(1, self.d))\n    inp_dst = keras.Input(shape=(1, self.d))\n    for op in ['mul', 'l1', 'l2', 'avg']:\n        out = LinkEmbedding(method=op)([inp_src, inp_dst])\n        li = keras.Model(inputs=[inp_src, inp_dst], outputs=out)\n        res = li.predict(x=[x_src, x_dst])\n        print(\"link inference with '{}' operator: {}\".format(op, res.flatten()))\n        assert (res.shape == (1, 1, self.d))\n        assert isinstance(res.flatten()[0], np.float32)\n    for op in ['concat']:\n        out = LinkEmbedding(method=op)([inp_src, inp_dst])\n        li = keras.Model(inputs=[inp_src, inp_dst], outputs=out)\n        res = li.predict(x=[x_src, x_dst])\n        print(\"link inference with '{}' operator: {}\".format(op, res.flatten()))\n        assert (res.shape == (1, 1, (2 * self.d)))\n        assert isinstance(res.flatten()[0], np.float32)", "masked_code": "def test_mul_l1_l2_avg(self):\n    \" Test the binary operators: 'mul'/'Hadamard', 'l1', 'l2', 'avg'\"\n    (x_src, x_dst) = make_orthonormal_vectors(self.d)\n    x_src = x_src.reshape(1, 1, self.d)\n    x_dst = x_dst.reshape(1, 1, self.d)\n    inp_src = keras.Input(shape=(1, self.d))\n    inp_dst = keras.Input(shape=(1, self.d))\n    for op in ['mul', 'l1', 'l2', 'avg']:\n        out = LinkEmbedding(method=op)([inp_src, inp_dst])\n        li = keras.Model(inputs=[inp_src, inp_dst], outputs=out)\n        res = li.predict(x=[x_src, x_dst])\n        print(\"link inference with '{}' operator: {}\".format(op, res.flatten()))\n        assert (res.shape == (1, 1, self.d))\n        assert isinstance(res.flatten()[0], np.float32)\n    for op in ['concat']:\n        out = LinkEmbedding(method=op)([inp_src, inp_dst])\n        li = keras.Model(inputs=[inp_src, inp_dst], outputs=out)\n        res = li.predict(x=[x_src, x_dst])\n        print(\"link inference with '{}' operator: {}\".format(op, res.flatten()))\n        assert (res.shape == '???')\n        assert isinstance(res.flatten()[0], np.float32)", "ground_truth": "(1, 1, (2 * self.d))", "quality_analysis": {"complexity_score": 11, "left_complexity": 2, "right_complexity": 9, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_699", "reponame": "stellargraph", "testpath": "tests/layer/test_link_inference.py", "testname": "test_link_inference.py", "classname": "Test_LinkEmbedding", "funcname": "test_mul_l1_l2_avg_single_tensor", "imports": ["from stellargraph.layer.link_inference import *", "import tensorflow as tf", "from tensorflow import keras", "import numpy as np", "import pytest"], "code": "def test_mul_l1_l2_avg_single_tensor(self):\n    \" Test the binary operators: 'mul'/'Hadamard', 'l1', 'l2', 'avg'\"\n    (x_src, x_dst) = make_orthonormal_vectors(self.d)\n    x_src = x_src.reshape(1, self.d)\n    x_dst = x_dst.reshape(1, self.d)\n    x_link_np = np.stack([x_src, x_dst], axis=1)\n    x_link = keras.Input(shape=(2, self.d))\n    for op in ['mul', 'l1', 'l2', 'avg']:\n        out = LinkEmbedding(method=op)(x_link)\n        li = keras.Model(inputs=x_link, outputs=out)\n        res = li.predict(x=x_link_np)\n        print(\"link inference with '{}' operator: {}\".format(op, res.flatten()))\n        assert (res.shape == (1, self.d))\n        assert isinstance(res.flatten()[0], np.float32)\n    for op in ['concat']:\n        out = LinkEmbedding(method=op)(x_link)\n        li = keras.Model(inputs=x_link, outputs=out)\n        res = li.predict(x=x_link_np)\n        print(\"link inference with '{}' operator: {}\".format(op, res.flatten()))\n        assert (res.shape == (1, (2 * self.d)))\n        assert isinstance(res.flatten()[0], np.float32)", "masked_code": "def test_mul_l1_l2_avg_single_tensor(self):\n    \" Test the binary operators: 'mul'/'Hadamard', 'l1', 'l2', 'avg'\"\n    (x_src, x_dst) = make_orthonormal_vectors(self.d)\n    x_src = x_src.reshape(1, self.d)\n    x_dst = x_dst.reshape(1, self.d)\n    x_link_np = np.stack([x_src, x_dst], axis=1)\n    x_link = keras.Input(shape=(2, self.d))\n    for op in ['mul', 'l1', 'l2', 'avg']:\n        out = LinkEmbedding(method=op)(x_link)\n        li = keras.Model(inputs=x_link, outputs=out)\n        res = li.predict(x=x_link_np)\n        print(\"link inference with '{}' operator: {}\".format(op, res.flatten()))\n        assert (res.shape == '???')\n        assert isinstance(res.flatten()[0], np.float32)\n    for op in ['concat']:\n        out = LinkEmbedding(method=op)(x_link)\n        li = keras.Model(inputs=x_link, outputs=out)\n        res = li.predict(x=x_link_np)\n        print(\"link inference with '{}' operator: {}\".format(op, res.flatten()))\n        assert (res.shape == (1, (2 * self.d)))\n        assert isinstance(res.flatten()[0], np.float32)", "ground_truth": "(1, self.d)", "quality_analysis": {"complexity_score": 7, "left_complexity": 2, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_700", "reponame": "stellargraph", "testpath": "tests/layer/test_link_inference.py", "testname": "test_link_inference.py", "classname": "Test_LinkEmbedding", "funcname": "test_mul_l1_l2_avg_single_tensor", "imports": ["from stellargraph.layer.link_inference import *", "import tensorflow as tf", "from tensorflow import keras", "import numpy as np", "import pytest"], "code": "def test_mul_l1_l2_avg_single_tensor(self):\n    \" Test the binary operators: 'mul'/'Hadamard', 'l1', 'l2', 'avg'\"\n    (x_src, x_dst) = make_orthonormal_vectors(self.d)\n    x_src = x_src.reshape(1, self.d)\n    x_dst = x_dst.reshape(1, self.d)\n    x_link_np = np.stack([x_src, x_dst], axis=1)\n    x_link = keras.Input(shape=(2, self.d))\n    for op in ['mul', 'l1', 'l2', 'avg']:\n        out = LinkEmbedding(method=op)(x_link)\n        li = keras.Model(inputs=x_link, outputs=out)\n        res = li.predict(x=x_link_np)\n        print(\"link inference with '{}' operator: {}\".format(op, res.flatten()))\n        assert (res.shape == (1, self.d))\n        assert isinstance(res.flatten()[0], np.float32)\n    for op in ['concat']:\n        out = LinkEmbedding(method=op)(x_link)\n        li = keras.Model(inputs=x_link, outputs=out)\n        res = li.predict(x=x_link_np)\n        print(\"link inference with '{}' operator: {}\".format(op, res.flatten()))\n        assert (res.shape == (1, (2 * self.d)))\n        assert isinstance(res.flatten()[0], np.float32)", "masked_code": "def test_mul_l1_l2_avg_single_tensor(self):\n    \" Test the binary operators: 'mul'/'Hadamard', 'l1', 'l2', 'avg'\"\n    (x_src, x_dst) = make_orthonormal_vectors(self.d)\n    x_src = x_src.reshape(1, self.d)\n    x_dst = x_dst.reshape(1, self.d)\n    x_link_np = np.stack([x_src, x_dst], axis=1)\n    x_link = keras.Input(shape=(2, self.d))\n    for op in ['mul', 'l1', 'l2', 'avg']:\n        out = LinkEmbedding(method=op)(x_link)\n        li = keras.Model(inputs=x_link, outputs=out)\n        res = li.predict(x=x_link_np)\n        print(\"link inference with '{}' operator: {}\".format(op, res.flatten()))\n        assert (res.shape == (1, self.d))\n        assert isinstance(res.flatten()[0], np.float32)\n    for op in ['concat']:\n        out = LinkEmbedding(method=op)(x_link)\n        li = keras.Model(inputs=x_link, outputs=out)\n        res = li.predict(x=x_link_np)\n        print(\"link inference with '{}' operator: {}\".format(op, res.flatten()))\n        assert (res.shape == '???')\n        assert isinstance(res.flatten()[0], np.float32)", "ground_truth": "(1, (2 * self.d))", "quality_analysis": {"complexity_score": 10, "left_complexity": 2, "right_complexity": 8, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_701", "reponame": "stellargraph", "testpath": "tests/layer/test_link_inference.py", "testname": "test_link_inference.py", "classname": "Test_Link_Inference", "funcname": "test_ip", "imports": ["from stellargraph.layer.link_inference import *", "import tensorflow as tf", "from tensorflow import keras", "import numpy as np", "import pytest"], "code": "def test_ip(self):\n    \" Test the 'ip' binary operator on orthogonal vectors\"\n    (x_src, x_dst) = make_orthonormal_vectors(self.d)\n    x_src = tf.constant(x_src, shape=(1, self.d), dtype='float64')\n    x_dst = tf.constant(x_dst, shape=(1, self.d), dtype='float64')\n    li = link_inference(edge_embedding_method='ip', output_act='linear')([x_src, x_dst])\n    print(\"link inference with 'ip' operator on orthonormal vectors: {}\".format(li))\n    assert (li.numpy() == pytest.approx(0, abs=1.5e-07))\n    li = link_inference(edge_embedding_method='ip', output_act='linear')([x_src, x_src])\n    print(\"link inference with 'ip' operator on unit vector: \", li)\n    assert (li.numpy() == pytest.approx(1, abs=1.5e-07))\n    li = link_classification(edge_embedding_method='ip', output_act='sigmoid')([x_src, x_dst])\n    assert (li.numpy() == pytest.approx(0.5, abs=1.5e-07))\n    li = link_classification(edge_embedding_method='ip', output_act='sigmoid')([x_src, x_src])\n    assert (li.numpy() == pytest.approx(0.7310586, abs=1.5e-07))", "masked_code": "def test_ip(self):\n    \" Test the 'ip' binary operator on orthogonal vectors\"\n    (x_src, x_dst) = make_orthonormal_vectors(self.d)\n    x_src = tf.constant(x_src, shape=(1, self.d), dtype='float64')\n    x_dst = tf.constant(x_dst, shape=(1, self.d), dtype='float64')\n    li = link_inference(edge_embedding_method='ip', output_act='linear')([x_src, x_dst])\n    print(\"link inference with 'ip' operator on orthonormal vectors: {}\".format(li))\n    assert (li.numpy() == '???')\n    li = link_inference(edge_embedding_method='ip', output_act='linear')([x_src, x_src])\n    print(\"link inference with 'ip' operator on unit vector: \", li)\n    assert (li.numpy() == pytest.approx(1, abs=1.5e-07))\n    li = link_classification(edge_embedding_method='ip', output_act='sigmoid')([x_src, x_dst])\n    assert (li.numpy() == pytest.approx(0.5, abs=1.5e-07))\n    li = link_classification(edge_embedding_method='ip', output_act='sigmoid')([x_src, x_src])\n    assert (li.numpy() == pytest.approx(0.7310586, abs=1.5e-07))", "ground_truth": "pytest.approx(0, abs=1.5e-07)", "quality_analysis": {"complexity_score": 7, "left_complexity": 3, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_702", "reponame": "stellargraph", "testpath": "tests/layer/test_link_inference.py", "testname": "test_link_inference.py", "classname": "Test_Link_Inference", "funcname": "test_ip", "imports": ["from stellargraph.layer.link_inference import *", "import tensorflow as tf", "from tensorflow import keras", "import numpy as np", "import pytest"], "code": "def test_ip(self):\n    \" Test the 'ip' binary operator on orthogonal vectors\"\n    (x_src, x_dst) = make_orthonormal_vectors(self.d)\n    x_src = tf.constant(x_src, shape=(1, self.d), dtype='float64')\n    x_dst = tf.constant(x_dst, shape=(1, self.d), dtype='float64')\n    li = link_inference(edge_embedding_method='ip', output_act='linear')([x_src, x_dst])\n    print(\"link inference with 'ip' operator on orthonormal vectors: {}\".format(li))\n    assert (li.numpy() == pytest.approx(0, abs=1.5e-07))\n    li = link_inference(edge_embedding_method='ip', output_act='linear')([x_src, x_src])\n    print(\"link inference with 'ip' operator on unit vector: \", li)\n    assert (li.numpy() == pytest.approx(1, abs=1.5e-07))\n    li = link_classification(edge_embedding_method='ip', output_act='sigmoid')([x_src, x_dst])\n    assert (li.numpy() == pytest.approx(0.5, abs=1.5e-07))\n    li = link_classification(edge_embedding_method='ip', output_act='sigmoid')([x_src, x_src])\n    assert (li.numpy() == pytest.approx(0.7310586, abs=1.5e-07))", "masked_code": "def test_ip(self):\n    \" Test the 'ip' binary operator on orthogonal vectors\"\n    (x_src, x_dst) = make_orthonormal_vectors(self.d)\n    x_src = tf.constant(x_src, shape=(1, self.d), dtype='float64')\n    x_dst = tf.constant(x_dst, shape=(1, self.d), dtype='float64')\n    li = link_inference(edge_embedding_method='ip', output_act='linear')([x_src, x_dst])\n    print(\"link inference with 'ip' operator on orthonormal vectors: {}\".format(li))\n    assert (li.numpy() == pytest.approx(0, abs=1.5e-07))\n    li = link_inference(edge_embedding_method='ip', output_act='linear')([x_src, x_src])\n    print(\"link inference with 'ip' operator on unit vector: \", li)\n    assert (li.numpy() == '???')\n    li = link_classification(edge_embedding_method='ip', output_act='sigmoid')([x_src, x_dst])\n    assert (li.numpy() == pytest.approx(0.5, abs=1.5e-07))\n    li = link_classification(edge_embedding_method='ip', output_act='sigmoid')([x_src, x_src])\n    assert (li.numpy() == pytest.approx(0.7310586, abs=1.5e-07))", "ground_truth": "pytest.approx(1, abs=1.5e-07)", "quality_analysis": {"complexity_score": 7, "left_complexity": 3, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_703", "reponame": "stellargraph", "testpath": "tests/layer/test_link_inference.py", "testname": "test_link_inference.py", "classname": "Test_Link_Inference", "funcname": "test_ip", "imports": ["from stellargraph.layer.link_inference import *", "import tensorflow as tf", "from tensorflow import keras", "import numpy as np", "import pytest"], "code": "def test_ip(self):\n    \" Test the 'ip' binary operator on orthogonal vectors\"\n    (x_src, x_dst) = make_orthonormal_vectors(self.d)\n    x_src = tf.constant(x_src, shape=(1, self.d), dtype='float64')\n    x_dst = tf.constant(x_dst, shape=(1, self.d), dtype='float64')\n    li = link_inference(edge_embedding_method='ip', output_act='linear')([x_src, x_dst])\n    print(\"link inference with 'ip' operator on orthonormal vectors: {}\".format(li))\n    assert (li.numpy() == pytest.approx(0, abs=1.5e-07))\n    li = link_inference(edge_embedding_method='ip', output_act='linear')([x_src, x_src])\n    print(\"link inference with 'ip' operator on unit vector: \", li)\n    assert (li.numpy() == pytest.approx(1, abs=1.5e-07))\n    li = link_classification(edge_embedding_method='ip', output_act='sigmoid')([x_src, x_dst])\n    assert (li.numpy() == pytest.approx(0.5, abs=1.5e-07))\n    li = link_classification(edge_embedding_method='ip', output_act='sigmoid')([x_src, x_src])\n    assert (li.numpy() == pytest.approx(0.7310586, abs=1.5e-07))", "masked_code": "def test_ip(self):\n    \" Test the 'ip' binary operator on orthogonal vectors\"\n    (x_src, x_dst) = make_orthonormal_vectors(self.d)\n    x_src = tf.constant(x_src, shape=(1, self.d), dtype='float64')\n    x_dst = tf.constant(x_dst, shape=(1, self.d), dtype='float64')\n    li = link_inference(edge_embedding_method='ip', output_act='linear')([x_src, x_dst])\n    print(\"link inference with 'ip' operator on orthonormal vectors: {}\".format(li))\n    assert (li.numpy() == pytest.approx(0, abs=1.5e-07))\n    li = link_inference(edge_embedding_method='ip', output_act='linear')([x_src, x_src])\n    print(\"link inference with 'ip' operator on unit vector: \", li)\n    assert (li.numpy() == pytest.approx(1, abs=1.5e-07))\n    li = link_classification(edge_embedding_method='ip', output_act='sigmoid')([x_src, x_dst])\n    assert (li.numpy() == '???')\n    li = link_classification(edge_embedding_method='ip', output_act='sigmoid')([x_src, x_src])\n    assert (li.numpy() == pytest.approx(0.7310586, abs=1.5e-07))", "ground_truth": "pytest.approx(0.5, abs=1.5e-07)", "quality_analysis": {"complexity_score": 7, "left_complexity": 3, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_704", "reponame": "stellargraph", "testpath": "tests/layer/test_link_inference.py", "testname": "test_link_inference.py", "classname": "Test_Link_Inference", "funcname": "test_ip", "imports": ["from stellargraph.layer.link_inference import *", "import tensorflow as tf", "from tensorflow import keras", "import numpy as np", "import pytest"], "code": "def test_ip(self):\n    \" Test the 'ip' binary operator on orthogonal vectors\"\n    (x_src, x_dst) = make_orthonormal_vectors(self.d)\n    x_src = tf.constant(x_src, shape=(1, self.d), dtype='float64')\n    x_dst = tf.constant(x_dst, shape=(1, self.d), dtype='float64')\n    li = link_inference(edge_embedding_method='ip', output_act='linear')([x_src, x_dst])\n    print(\"link inference with 'ip' operator on orthonormal vectors: {}\".format(li))\n    assert (li.numpy() == pytest.approx(0, abs=1.5e-07))\n    li = link_inference(edge_embedding_method='ip', output_act='linear')([x_src, x_src])\n    print(\"link inference with 'ip' operator on unit vector: \", li)\n    assert (li.numpy() == pytest.approx(1, abs=1.5e-07))\n    li = link_classification(edge_embedding_method='ip', output_act='sigmoid')([x_src, x_dst])\n    assert (li.numpy() == pytest.approx(0.5, abs=1.5e-07))\n    li = link_classification(edge_embedding_method='ip', output_act='sigmoid')([x_src, x_src])\n    assert (li.numpy() == pytest.approx(0.7310586, abs=1.5e-07))", "masked_code": "def test_ip(self):\n    \" Test the 'ip' binary operator on orthogonal vectors\"\n    (x_src, x_dst) = make_orthonormal_vectors(self.d)\n    x_src = tf.constant(x_src, shape=(1, self.d), dtype='float64')\n    x_dst = tf.constant(x_dst, shape=(1, self.d), dtype='float64')\n    li = link_inference(edge_embedding_method='ip', output_act='linear')([x_src, x_dst])\n    print(\"link inference with 'ip' operator on orthonormal vectors: {}\".format(li))\n    assert (li.numpy() == pytest.approx(0, abs=1.5e-07))\n    li = link_inference(edge_embedding_method='ip', output_act='linear')([x_src, x_src])\n    print(\"link inference with 'ip' operator on unit vector: \", li)\n    assert (li.numpy() == pytest.approx(1, abs=1.5e-07))\n    li = link_classification(edge_embedding_method='ip', output_act='sigmoid')([x_src, x_dst])\n    assert (li.numpy() == pytest.approx(0.5, abs=1.5e-07))\n    li = link_classification(edge_embedding_method='ip', output_act='sigmoid')([x_src, x_src])\n    assert (li.numpy() == '???')", "ground_truth": "pytest.approx(0.7310586, abs=1.5e-07)", "quality_analysis": {"complexity_score": 7, "left_complexity": 3, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_705", "reponame": "stellargraph", "testpath": "tests/layer/test_link_inference.py", "testname": "test_link_inference.py", "classname": "Test_Link_Inference", "funcname": "test_mul_l1_l2_avg", "imports": ["from stellargraph.layer.link_inference import *", "import tensorflow as tf", "from tensorflow import keras", "import numpy as np", "import pytest"], "code": "def test_mul_l1_l2_avg(self):\n    \" Test the binary operators: 'mul'/'Hadamard', 'l1', 'l2', 'avg'\"\n    (x_src, x_dst) = make_orthonormal_vectors(self.d)\n    x_src = x_src.reshape(1, 1, self.d)\n    x_dst = x_dst.reshape(1, 1, self.d)\n    inp_src = keras.Input(shape=(1, self.d))\n    inp_dst = keras.Input(shape=(1, self.d))\n    for op in ['mul', 'l1', 'l2', 'avg', 'concat']:\n        out = link_inference(output_dim=self.d_out, edge_embedding_method=op)([inp_src, inp_dst])\n        li = keras.Model(inputs=[inp_src, inp_dst], outputs=out)\n        print(x_src.shape)\n        res = li.predict(x=[x_src, x_dst])\n        print(\"link inference with '{}' operator: {}\".format(op, res.flatten()))\n        assert (res.shape == (1, self.d_out))\n        assert isinstance(res.flatten()[0], np.float32)", "masked_code": "def test_mul_l1_l2_avg(self):\n    \" Test the binary operators: 'mul'/'Hadamard', 'l1', 'l2', 'avg'\"\n    (x_src, x_dst) = make_orthonormal_vectors(self.d)\n    x_src = x_src.reshape(1, 1, self.d)\n    x_dst = x_dst.reshape(1, 1, self.d)\n    inp_src = keras.Input(shape=(1, self.d))\n    inp_dst = keras.Input(shape=(1, self.d))\n    for op in ['mul', 'l1', 'l2', 'avg', 'concat']:\n        out = link_inference(output_dim=self.d_out, edge_embedding_method=op)([inp_src, inp_dst])\n        li = keras.Model(inputs=[inp_src, inp_dst], outputs=out)\n        print(x_src.shape)\n        res = li.predict(x=[x_src, x_dst])\n        print(\"link inference with '{}' operator: {}\".format(op, res.flatten()))\n        assert (res.shape == '???')\n        assert isinstance(res.flatten()[0], np.float32)", "ground_truth": "(1, self.d_out)", "quality_analysis": {"complexity_score": 7, "left_complexity": 2, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_706", "reponame": "stellargraph", "testpath": "tests/layer/test_link_inference.py", "testname": "test_link_inference.py", "classname": "Test_Link_Classification", "funcname": "test_ip", "imports": ["from stellargraph.layer.link_inference import *", "import tensorflow as tf", "from tensorflow import keras", "import numpy as np", "import pytest"], "code": "def test_ip(self):\n    \" Test the 'ip' binary operator on orthogonal vectors\"\n    (x_src, x_dst) = make_orthonormal_vectors(self.d)\n    x_src = tf.constant(x_src, shape=(1, self.d), dtype='float64')\n    x_dst = tf.constant(x_dst, shape=(1, self.d), dtype='float64')\n    li = link_classification(edge_embedding_method='ip', output_act='linear')([x_src, x_dst])\n    assert (li.numpy() == pytest.approx(0, abs=1.5e-07))\n    li = link_classification(edge_embedding_method='ip', output_act='linear')([x_src, x_src])\n    assert (li.numpy()[(0, 0)] == pytest.approx(1, abs=1.5e-07))\n    li = link_classification(edge_embedding_method='ip', output_act='sigmoid')([x_src, x_dst])\n    assert (li.numpy() == pytest.approx(0.5, abs=1.5e-07))\n    li = link_classification(edge_embedding_method='ip', output_act='sigmoid')([x_src, x_src])\n    assert (li.numpy() == pytest.approx(0.7310586, abs=1.5e-07))", "masked_code": "def test_ip(self):\n    \" Test the 'ip' binary operator on orthogonal vectors\"\n    (x_src, x_dst) = make_orthonormal_vectors(self.d)\n    x_src = tf.constant(x_src, shape=(1, self.d), dtype='float64')\n    x_dst = tf.constant(x_dst, shape=(1, self.d), dtype='float64')\n    li = link_classification(edge_embedding_method='ip', output_act='linear')([x_src, x_dst])\n    assert (li.numpy() == '???')\n    li = link_classification(edge_embedding_method='ip', output_act='linear')([x_src, x_src])\n    assert (li.numpy()[(0, 0)] == pytest.approx(1, abs=1.5e-07))\n    li = link_classification(edge_embedding_method='ip', output_act='sigmoid')([x_src, x_dst])\n    assert (li.numpy() == pytest.approx(0.5, abs=1.5e-07))\n    li = link_classification(edge_embedding_method='ip', output_act='sigmoid')([x_src, x_src])\n    assert (li.numpy() == pytest.approx(0.7310586, abs=1.5e-07))", "ground_truth": "pytest.approx(0, abs=1.5e-07)", "quality_analysis": {"complexity_score": 7, "left_complexity": 3, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_707", "reponame": "stellargraph", "testpath": "tests/layer/test_link_inference.py", "testname": "test_link_inference.py", "classname": "Test_Link_Classification", "funcname": "test_ip", "imports": ["from stellargraph.layer.link_inference import *", "import tensorflow as tf", "from tensorflow import keras", "import numpy as np", "import pytest"], "code": "def test_ip(self):\n    \" Test the 'ip' binary operator on orthogonal vectors\"\n    (x_src, x_dst) = make_orthonormal_vectors(self.d)\n    x_src = tf.constant(x_src, shape=(1, self.d), dtype='float64')\n    x_dst = tf.constant(x_dst, shape=(1, self.d), dtype='float64')\n    li = link_classification(edge_embedding_method='ip', output_act='linear')([x_src, x_dst])\n    assert (li.numpy() == pytest.approx(0, abs=1.5e-07))\n    li = link_classification(edge_embedding_method='ip', output_act='linear')([x_src, x_src])\n    assert (li.numpy()[(0, 0)] == pytest.approx(1, abs=1.5e-07))\n    li = link_classification(edge_embedding_method='ip', output_act='sigmoid')([x_src, x_dst])\n    assert (li.numpy() == pytest.approx(0.5, abs=1.5e-07))\n    li = link_classification(edge_embedding_method='ip', output_act='sigmoid')([x_src, x_src])\n    assert (li.numpy() == pytest.approx(0.7310586, abs=1.5e-07))", "masked_code": "def test_ip(self):\n    \" Test the 'ip' binary operator on orthogonal vectors\"\n    (x_src, x_dst) = make_orthonormal_vectors(self.d)\n    x_src = tf.constant(x_src, shape=(1, self.d), dtype='float64')\n    x_dst = tf.constant(x_dst, shape=(1, self.d), dtype='float64')\n    li = link_classification(edge_embedding_method='ip', output_act='linear')([x_src, x_dst])\n    assert (li.numpy() == pytest.approx(0, abs=1.5e-07))\n    li = link_classification(edge_embedding_method='ip', output_act='linear')([x_src, x_src])\n    assert (li.numpy()[(0, 0)] == '???')\n    li = link_classification(edge_embedding_method='ip', output_act='sigmoid')([x_src, x_dst])\n    assert (li.numpy() == pytest.approx(0.5, abs=1.5e-07))\n    li = link_classification(edge_embedding_method='ip', output_act='sigmoid')([x_src, x_src])\n    assert (li.numpy() == pytest.approx(0.7310586, abs=1.5e-07))", "ground_truth": "pytest.approx(1, abs=1.5e-07)", "quality_analysis": {"complexity_score": 14, "left_complexity": 10, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_708", "reponame": "stellargraph", "testpath": "tests/layer/test_link_inference.py", "testname": "test_link_inference.py", "classname": "Test_Link_Classification", "funcname": "test_ip", "imports": ["from stellargraph.layer.link_inference import *", "import tensorflow as tf", "from tensorflow import keras", "import numpy as np", "import pytest"], "code": "def test_ip(self):\n    \" Test the 'ip' binary operator on orthogonal vectors\"\n    (x_src, x_dst) = make_orthonormal_vectors(self.d)\n    x_src = tf.constant(x_src, shape=(1, self.d), dtype='float64')\n    x_dst = tf.constant(x_dst, shape=(1, self.d), dtype='float64')\n    li = link_classification(edge_embedding_method='ip', output_act='linear')([x_src, x_dst])\n    assert (li.numpy() == pytest.approx(0, abs=1.5e-07))\n    li = link_classification(edge_embedding_method='ip', output_act='linear')([x_src, x_src])\n    assert (li.numpy()[(0, 0)] == pytest.approx(1, abs=1.5e-07))\n    li = link_classification(edge_embedding_method='ip', output_act='sigmoid')([x_src, x_dst])\n    assert (li.numpy() == pytest.approx(0.5, abs=1.5e-07))\n    li = link_classification(edge_embedding_method='ip', output_act='sigmoid')([x_src, x_src])\n    assert (li.numpy() == pytest.approx(0.7310586, abs=1.5e-07))", "masked_code": "def test_ip(self):\n    \" Test the 'ip' binary operator on orthogonal vectors\"\n    (x_src, x_dst) = make_orthonormal_vectors(self.d)\n    x_src = tf.constant(x_src, shape=(1, self.d), dtype='float64')\n    x_dst = tf.constant(x_dst, shape=(1, self.d), dtype='float64')\n    li = link_classification(edge_embedding_method='ip', output_act='linear')([x_src, x_dst])\n    assert (li.numpy() == pytest.approx(0, abs=1.5e-07))\n    li = link_classification(edge_embedding_method='ip', output_act='linear')([x_src, x_src])\n    assert (li.numpy()[(0, 0)] == pytest.approx(1, abs=1.5e-07))\n    li = link_classification(edge_embedding_method='ip', output_act='sigmoid')([x_src, x_dst])\n    assert (li.numpy() == '???')\n    li = link_classification(edge_embedding_method='ip', output_act='sigmoid')([x_src, x_src])\n    assert (li.numpy() == pytest.approx(0.7310586, abs=1.5e-07))", "ground_truth": "pytest.approx(0.5, abs=1.5e-07)", "quality_analysis": {"complexity_score": 7, "left_complexity": 3, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_709", "reponame": "stellargraph", "testpath": "tests/layer/test_link_inference.py", "testname": "test_link_inference.py", "classname": "Test_Link_Classification", "funcname": "test_ip", "imports": ["from stellargraph.layer.link_inference import *", "import tensorflow as tf", "from tensorflow import keras", "import numpy as np", "import pytest"], "code": "def test_ip(self):\n    \" Test the 'ip' binary operator on orthogonal vectors\"\n    (x_src, x_dst) = make_orthonormal_vectors(self.d)\n    x_src = tf.constant(x_src, shape=(1, self.d), dtype='float64')\n    x_dst = tf.constant(x_dst, shape=(1, self.d), dtype='float64')\n    li = link_classification(edge_embedding_method='ip', output_act='linear')([x_src, x_dst])\n    assert (li.numpy() == pytest.approx(0, abs=1.5e-07))\n    li = link_classification(edge_embedding_method='ip', output_act='linear')([x_src, x_src])\n    assert (li.numpy()[(0, 0)] == pytest.approx(1, abs=1.5e-07))\n    li = link_classification(edge_embedding_method='ip', output_act='sigmoid')([x_src, x_dst])\n    assert (li.numpy() == pytest.approx(0.5, abs=1.5e-07))\n    li = link_classification(edge_embedding_method='ip', output_act='sigmoid')([x_src, x_src])\n    assert (li.numpy() == pytest.approx(0.7310586, abs=1.5e-07))", "masked_code": "def test_ip(self):\n    \" Test the 'ip' binary operator on orthogonal vectors\"\n    (x_src, x_dst) = make_orthonormal_vectors(self.d)\n    x_src = tf.constant(x_src, shape=(1, self.d), dtype='float64')\n    x_dst = tf.constant(x_dst, shape=(1, self.d), dtype='float64')\n    li = link_classification(edge_embedding_method='ip', output_act='linear')([x_src, x_dst])\n    assert (li.numpy() == pytest.approx(0, abs=1.5e-07))\n    li = link_classification(edge_embedding_method='ip', output_act='linear')([x_src, x_src])\n    assert (li.numpy()[(0, 0)] == pytest.approx(1, abs=1.5e-07))\n    li = link_classification(edge_embedding_method='ip', output_act='sigmoid')([x_src, x_dst])\n    assert (li.numpy() == pytest.approx(0.5, abs=1.5e-07))\n    li = link_classification(edge_embedding_method='ip', output_act='sigmoid')([x_src, x_src])\n    assert (li.numpy() == '???')", "ground_truth": "pytest.approx(0.7310586, abs=1.5e-07)", "quality_analysis": {"complexity_score": 7, "left_complexity": 3, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_710", "reponame": "stellargraph", "testpath": "tests/layer/test_link_inference.py", "testname": "test_link_inference.py", "classname": "Test_Link_Classification", "funcname": "test_mul_l1_l2_avg", "imports": ["from stellargraph.layer.link_inference import *", "import tensorflow as tf", "from tensorflow import keras", "import numpy as np", "import pytest"], "code": "def test_mul_l1_l2_avg(self):\n    \" Test the binary operators: 'mul'/'Hadamard', 'l1', 'l2', 'avg'\"\n    (x_src, x_dst) = make_orthonormal_vectors(self.d)\n    x_src = x_src.reshape(1, 1, self.d)\n    x_dst = x_dst.reshape(1, 1, self.d)\n    inp_src = keras.Input(shape=(1, self.d))\n    inp_dst = keras.Input(shape=(1, self.d))\n    for op in ['mul', 'l1', 'l2', 'avg', 'concat']:\n        out = link_classification(output_dim=self.d_out, edge_embedding_method=op)([inp_src, inp_dst])\n        li = keras.Model(inputs=[inp_src, inp_dst], outputs=out)\n        res = li.predict(x=[x_src, x_dst])\n        print(\"link classification with '{}' operator: {}\".format(op, res.flatten()))\n        assert (res.shape == (1, self.d_out))\n        assert isinstance(res.flatten()[0], np.float32)\n        assert all((res.flatten() >= 0))\n        assert all((res.flatten() <= 1))", "masked_code": "def test_mul_l1_l2_avg(self):\n    \" Test the binary operators: 'mul'/'Hadamard', 'l1', 'l2', 'avg'\"\n    (x_src, x_dst) = make_orthonormal_vectors(self.d)\n    x_src = x_src.reshape(1, 1, self.d)\n    x_dst = x_dst.reshape(1, 1, self.d)\n    inp_src = keras.Input(shape=(1, self.d))\n    inp_dst = keras.Input(shape=(1, self.d))\n    for op in ['mul', 'l1', 'l2', 'avg', 'concat']:\n        out = link_classification(output_dim=self.d_out, edge_embedding_method=op)([inp_src, inp_dst])\n        li = keras.Model(inputs=[inp_src, inp_dst], outputs=out)\n        res = li.predict(x=[x_src, x_dst])\n        print(\"link classification with '{}' operator: {}\".format(op, res.flatten()))\n        assert (res.shape == '???')\n        assert isinstance(res.flatten()[0], np.float32)\n        assert all((res.flatten() >= 0))\n        assert all((res.flatten() <= 1))", "ground_truth": "(1, self.d_out)", "quality_analysis": {"complexity_score": 7, "left_complexity": 2, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_711", "reponame": "stellargraph", "testpath": "tests/layer/test_link_inference.py", "testname": "test_link_inference.py", "classname": "Test_Link_Regression", "funcname": "test_ip", "imports": ["from stellargraph.layer.link_inference import *", "import tensorflow as tf", "from tensorflow import keras", "import numpy as np", "import pytest"], "code": "def test_ip(self):\n    \" Test the 'ip' binary operator on orthogonal vectors\"\n    (x_src, x_dst) = make_orthonormal_vectors(self.d)\n    expected = np.dot(x_src, x_dst)\n    x_src = tf.constant(x_src, shape=(1, self.d), dtype='float64')\n    x_dst = tf.constant(x_dst, shape=(1, self.d), dtype='float64')\n    li = link_regression(edge_embedding_method='ip')([x_src, x_dst])\n    print(\"link regression with 'ip' operator on orthonormal vectors: {}, expected: {}\".format(li, expected))\n    assert (li.numpy() == pytest.approx(0, abs=1.5e-07))\n    li = link_regression(edge_embedding_method='ip')([x_src, x_src])\n    print(\"link regression with 'ip' operator on unit vector: \", li)\n    assert (li.numpy() == pytest.approx(1, abs=1.5e-07))", "masked_code": "def test_ip(self):\n    \" Test the 'ip' binary operator on orthogonal vectors\"\n    (x_src, x_dst) = make_orthonormal_vectors(self.d)\n    expected = np.dot(x_src, x_dst)\n    x_src = tf.constant(x_src, shape=(1, self.d), dtype='float64')\n    x_dst = tf.constant(x_dst, shape=(1, self.d), dtype='float64')\n    li = link_regression(edge_embedding_method='ip')([x_src, x_dst])\n    print(\"link regression with 'ip' operator on orthonormal vectors: {}, expected: {}\".format(li, expected))\n    assert (li.numpy() == '???')\n    li = link_regression(edge_embedding_method='ip')([x_src, x_src])\n    print(\"link regression with 'ip' operator on unit vector: \", li)\n    assert (li.numpy() == pytest.approx(1, abs=1.5e-07))", "ground_truth": "pytest.approx(0, abs=1.5e-07)", "quality_analysis": {"complexity_score": 7, "left_complexity": 3, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_712", "reponame": "stellargraph", "testpath": "tests/layer/test_link_inference.py", "testname": "test_link_inference.py", "classname": "Test_Link_Regression", "funcname": "test_ip", "imports": ["from stellargraph.layer.link_inference import *", "import tensorflow as tf", "from tensorflow import keras", "import numpy as np", "import pytest"], "code": "def test_ip(self):\n    \" Test the 'ip' binary operator on orthogonal vectors\"\n    (x_src, x_dst) = make_orthonormal_vectors(self.d)\n    expected = np.dot(x_src, x_dst)\n    x_src = tf.constant(x_src, shape=(1, self.d), dtype='float64')\n    x_dst = tf.constant(x_dst, shape=(1, self.d), dtype='float64')\n    li = link_regression(edge_embedding_method='ip')([x_src, x_dst])\n    print(\"link regression with 'ip' operator on orthonormal vectors: {}, expected: {}\".format(li, expected))\n    assert (li.numpy() == pytest.approx(0, abs=1.5e-07))\n    li = link_regression(edge_embedding_method='ip')([x_src, x_src])\n    print(\"link regression with 'ip' operator on unit vector: \", li)\n    assert (li.numpy() == pytest.approx(1, abs=1.5e-07))", "masked_code": "def test_ip(self):\n    \" Test the 'ip' binary operator on orthogonal vectors\"\n    (x_src, x_dst) = make_orthonormal_vectors(self.d)\n    expected = np.dot(x_src, x_dst)\n    x_src = tf.constant(x_src, shape=(1, self.d), dtype='float64')\n    x_dst = tf.constant(x_dst, shape=(1, self.d), dtype='float64')\n    li = link_regression(edge_embedding_method='ip')([x_src, x_dst])\n    print(\"link regression with 'ip' operator on orthonormal vectors: {}, expected: {}\".format(li, expected))\n    assert (li.numpy() == pytest.approx(0, abs=1.5e-07))\n    li = link_regression(edge_embedding_method='ip')([x_src, x_src])\n    print(\"link regression with 'ip' operator on unit vector: \", li)\n    assert (li.numpy() == '???')", "ground_truth": "pytest.approx(1, abs=1.5e-07)", "quality_analysis": {"complexity_score": 7, "left_complexity": 3, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_713", "reponame": "stellargraph", "testpath": "tests/layer/test_link_inference.py", "testname": "test_link_inference.py", "classname": "Test_Link_Regression", "funcname": "test_mul_l1_l2_avg", "imports": ["from stellargraph.layer.link_inference import *", "import tensorflow as tf", "from tensorflow import keras", "import numpy as np", "import pytest"], "code": "def test_mul_l1_l2_avg(self):\n    \" Test the binary operators: 'mul'/'Hadamard', 'l1', 'l2', 'avg'\"\n    (x_src, x_dst) = make_orthonormal_vectors(self.d)\n    x_src = x_src.reshape(1, 1, self.d)\n    x_dst = x_dst.reshape(1, 1, self.d)\n    inp_src = keras.Input(shape=(1, self.d))\n    inp_dst = keras.Input(shape=(1, self.d))\n    for op in ['mul', 'l1', 'l2', 'avg', 'concat']:\n        out = link_regression(output_dim=self.d_out, edge_embedding_method=op)([inp_src, inp_dst])\n        li = keras.Model(inputs=[inp_src, inp_dst], outputs=out)\n        res = li.predict(x=[x_src, x_dst])\n        print(\"link regression with '{}' operator: {}\".format(op, res.flatten()))\n        assert (res.shape == (1, self.d_out))\n        assert isinstance(res.flatten()[0], np.float32)", "masked_code": "def test_mul_l1_l2_avg(self):\n    \" Test the binary operators: 'mul'/'Hadamard', 'l1', 'l2', 'avg'\"\n    (x_src, x_dst) = make_orthonormal_vectors(self.d)\n    x_src = x_src.reshape(1, 1, self.d)\n    x_dst = x_dst.reshape(1, 1, self.d)\n    inp_src = keras.Input(shape=(1, self.d))\n    inp_dst = keras.Input(shape=(1, self.d))\n    for op in ['mul', 'l1', 'l2', 'avg', 'concat']:\n        out = link_regression(output_dim=self.d_out, edge_embedding_method=op)([inp_src, inp_dst])\n        li = keras.Model(inputs=[inp_src, inp_dst], outputs=out)\n        res = li.predict(x=[x_src, x_dst])\n        print(\"link regression with '{}' operator: {}\".format(op, res.flatten()))\n        assert (res.shape == '???')\n        assert isinstance(res.flatten()[0], np.float32)", "ground_truth": "(1, self.d_out)", "quality_analysis": {"complexity_score": 7, "left_complexity": 2, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_714", "reponame": "stellargraph", "testpath": "tests/layer/test_link_inference.py", "testname": "test_link_inference.py", "classname": "Test_Link_Regression", "funcname": "test_clip_limits", "imports": ["from stellargraph.layer.link_inference import *", "import tensorflow as tf", "from tensorflow import keras", "import numpy as np", "import pytest"], "code": "def test_clip_limits(self):\n    \"\\n        Test calling with the leaky clip thresholds\\n        Not sure what a meaningful test should do (as the LeakyClippedLinear layer provides some advantages at model training),\\n        so just making sure applying the clip limits doesn't break anything.\\n        \"\n    print('\\n Testing clip limits...')\n    (x_src, x_dst) = make_orthonormal_vectors(self.d)\n    x_src = x_src.reshape(1, 1, self.d)\n    x_dst = x_dst.reshape(1, 1, self.d)\n    inp_src = keras.Input(shape=(1, self.d))\n    inp_dst = keras.Input(shape=(1, self.d))\n    for op in ['mul', 'l1', 'l2', 'avg', 'concat']:\n        out = link_regression(output_dim=self.d_out, edge_embedding_method=op, clip_limits=self.clip_limits)([inp_src, inp_dst])\n        li = keras.Model(inputs=[inp_src, inp_dst], outputs=out)\n        res = li.predict(x=[x_src, x_dst])\n        print(\"link regression with '{}' operator: {}\".format(op, res.flatten()))\n        assert (res.shape == (1, self.d_out))\n        assert isinstance(res.flatten()[0], np.float32)", "masked_code": "def test_clip_limits(self):\n    \"\\n        Test calling with the leaky clip thresholds\\n        Not sure what a meaningful test should do (as the LeakyClippedLinear layer provides some advantages at model training),\\n        so just making sure applying the clip limits doesn't break anything.\\n        \"\n    print('\\n Testing clip limits...')\n    (x_src, x_dst) = make_orthonormal_vectors(self.d)\n    x_src = x_src.reshape(1, 1, self.d)\n    x_dst = x_dst.reshape(1, 1, self.d)\n    inp_src = keras.Input(shape=(1, self.d))\n    inp_dst = keras.Input(shape=(1, self.d))\n    for op in ['mul', 'l1', 'l2', 'avg', 'concat']:\n        out = link_regression(output_dim=self.d_out, edge_embedding_method=op, clip_limits=self.clip_limits)([inp_src, inp_dst])\n        li = keras.Model(inputs=[inp_src, inp_dst], outputs=out)\n        res = li.predict(x=[x_src, x_dst])\n        print(\"link regression with '{}' operator: {}\".format(op, res.flatten()))\n        assert (res.shape == '???')\n        assert isinstance(res.flatten()[0], np.float32)", "ground_truth": "(1, self.d_out)", "quality_analysis": {"complexity_score": 7, "left_complexity": 2, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_715", "reponame": "stellargraph", "testpath": "tests/layer/test_misc.py", "testname": "test_misc.py", "classname": null, "funcname": "test_squeezedsparseconversion_dtype", "imports": ["import tensorflow as tf", "from tensorflow import keras", "import numpy as np", "import scipy.sparse as sps", "import pytest", "from stellargraph.layer.misc import *", "from ..test_utils.graphs import create_graph_features, example_graph", "from stellargraph.mapper import *", "from stellargraph.layer import *"], "code": "def test_squeezedsparseconversion_dtype():\n    N = 10\n    x_t = keras.Input(batch_shape=(1, N, 1), dtype='float64')\n    A_ind = keras.Input(batch_shape=(1, None, 2), dtype='int64')\n    A_val = keras.Input(batch_shape=(1, None), dtype='float32')\n    A_mat = SqueezedSparseConversion(shape=(N, N), dtype='float64')([A_ind, A_val])\n    x_out = keras.layers.Lambda((lambda xin: K.expand_dims(K.dot(xin[0], K.squeeze(xin[1], 0)), 0)))([A_mat, x_t])\n    model = keras.Model(inputs=[x_t, A_ind, A_val], outputs=x_out)\n    x = np.random.randn(1, N, 1)\n    (A_indices, A_values, A) = sparse_matrix_example(N)\n    z = model.predict([x, np.expand_dims(A_indices, 0), np.expand_dims(A_values, 0)])\n    assert (A_mat.dtype == tf.dtypes.float64)\n    np.testing.assert_allclose(z.squeeze(), A.dot(x.squeeze()), atol=1e-07, rtol=1e-05)", "masked_code": "def test_squeezedsparseconversion_dtype():\n    N = 10\n    x_t = keras.Input(batch_shape=(1, N, 1), dtype='float64')\n    A_ind = keras.Input(batch_shape=(1, None, 2), dtype='int64')\n    A_val = keras.Input(batch_shape=(1, None), dtype='float32')\n    A_mat = SqueezedSparseConversion(shape=(N, N), dtype='float64')([A_ind, A_val])\n    x_out = keras.layers.Lambda((lambda xin: K.expand_dims(K.dot(xin[0], K.squeeze(xin[1], 0)), 0)))([A_mat, x_t])\n    model = keras.Model(inputs=[x_t, A_ind, A_val], outputs=x_out)\n    x = np.random.randn(1, N, 1)\n    (A_indices, A_values, A) = sparse_matrix_example(N)\n    z = model.predict([x, np.expand_dims(A_indices, 0), np.expand_dims(A_values, 0)])\n    assert (A_mat.dtype == '???')\n    np.testing.assert_allclose(z.squeeze(), A.dot(x.squeeze()), atol=1e-07, rtol=1e-05)", "ground_truth": "tf.dtypes.float64", "quality_analysis": {"complexity_score": 4, "left_complexity": 2, "right_complexity": 2, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_716", "reponame": "stellargraph", "testpath": "tests/layer/test_node2vec.py", "testname": "test_node2vec.py", "classname": null, "funcname": "test_node2vec_constructor", "imports": ["from stellargraph.core.graph import StellarGraph", "from stellargraph.mapper import Node2VecNodeGenerator", "from stellargraph.layer.node2vec import *", "from tensorflow import keras", "import numpy as np", "import pytest", "from ..test_utils.graphs import example_graph", "from .. import test_utils"], "code": "def test_node2vec_constructor():\n    node2vec = Node2Vec(emb_size=4, node_num=4, multiplicity=2)\n    assert (node2vec.emb_size == 4)\n    assert (node2vec.input_node_num == 4)\n    assert (node2vec.multiplicity == 2)\n    with pytest.raises(ValueError):\n        Node2Vec(emb_size=4)\n    with pytest.raises(ValueError):\n        Node2Vec(emb_size=4, node_num=4)\n    with pytest.raises(ValueError):\n        Node2Vec(emb_size=4, multiplicity=2)\n    G = example_graph()\n    gen = Node2VecNodeGenerator(G, batch_size=2)\n    node2vec = Node2Vec(emb_size=4, generator=gen)\n    assert (node2vec.emb_size == 4)\n    assert (node2vec.input_node_num == 4)\n    assert (node2vec.multiplicity == 1)", "masked_code": "def test_node2vec_constructor():\n    node2vec = Node2Vec(emb_size=4, node_num=4, multiplicity=2)\n    assert (node2vec.emb_size == '???')\n    assert (node2vec.input_node_num == 4)\n    assert (node2vec.multiplicity == 2)\n    with pytest.raises(ValueError):\n        Node2Vec(emb_size=4)\n    with pytest.raises(ValueError):\n        Node2Vec(emb_size=4, node_num=4)\n    with pytest.raises(ValueError):\n        Node2Vec(emb_size=4, multiplicity=2)\n    G = example_graph()\n    gen = Node2VecNodeGenerator(G, batch_size=2)\n    node2vec = Node2Vec(emb_size=4, generator=gen)\n    assert (node2vec.emb_size == 4)\n    assert (node2vec.input_node_num == 4)\n    assert (node2vec.multiplicity == 1)", "ground_truth": "4", "quality_analysis": {"complexity_score": 3, "left_complexity": 2, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_717", "reponame": "stellargraph", "testpath": "tests/layer/test_node2vec.py", "testname": "test_node2vec.py", "classname": null, "funcname": "test_node2vec_constructor", "imports": ["from stellargraph.core.graph import StellarGraph", "from stellargraph.mapper import Node2VecNodeGenerator", "from stellargraph.layer.node2vec import *", "from tensorflow import keras", "import numpy as np", "import pytest", "from ..test_utils.graphs import example_graph", "from .. import test_utils"], "code": "def test_node2vec_constructor():\n    node2vec = Node2Vec(emb_size=4, node_num=4, multiplicity=2)\n    assert (node2vec.emb_size == 4)\n    assert (node2vec.input_node_num == 4)\n    assert (node2vec.multiplicity == 2)\n    with pytest.raises(ValueError):\n        Node2Vec(emb_size=4)\n    with pytest.raises(ValueError):\n        Node2Vec(emb_size=4, node_num=4)\n    with pytest.raises(ValueError):\n        Node2Vec(emb_size=4, multiplicity=2)\n    G = example_graph()\n    gen = Node2VecNodeGenerator(G, batch_size=2)\n    node2vec = Node2Vec(emb_size=4, generator=gen)\n    assert (node2vec.emb_size == 4)\n    assert (node2vec.input_node_num == 4)\n    assert (node2vec.multiplicity == 1)", "masked_code": "def test_node2vec_constructor():\n    node2vec = Node2Vec(emb_size=4, node_num=4, multiplicity=2)\n    assert (node2vec.emb_size == 4)\n    assert (node2vec.input_node_num == '???')\n    assert (node2vec.multiplicity == 2)\n    with pytest.raises(ValueError):\n        Node2Vec(emb_size=4)\n    with pytest.raises(ValueError):\n        Node2Vec(emb_size=4, node_num=4)\n    with pytest.raises(ValueError):\n        Node2Vec(emb_size=4, multiplicity=2)\n    G = example_graph()\n    gen = Node2VecNodeGenerator(G, batch_size=2)\n    node2vec = Node2Vec(emb_size=4, generator=gen)\n    assert (node2vec.emb_size == 4)\n    assert (node2vec.input_node_num == 4)\n    assert (node2vec.multiplicity == 1)", "ground_truth": "4", "quality_analysis": {"complexity_score": 3, "left_complexity": 2, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_718", "reponame": "stellargraph", "testpath": "tests/layer/test_node2vec.py", "testname": "test_node2vec.py", "classname": null, "funcname": "test_node2vec_constructor", "imports": ["from stellargraph.core.graph import StellarGraph", "from stellargraph.mapper import Node2VecNodeGenerator", "from stellargraph.layer.node2vec import *", "from tensorflow import keras", "import numpy as np", "import pytest", "from ..test_utils.graphs import example_graph", "from .. import test_utils"], "code": "def test_node2vec_constructor():\n    node2vec = Node2Vec(emb_size=4, node_num=4, multiplicity=2)\n    assert (node2vec.emb_size == 4)\n    assert (node2vec.input_node_num == 4)\n    assert (node2vec.multiplicity == 2)\n    with pytest.raises(ValueError):\n        Node2Vec(emb_size=4)\n    with pytest.raises(ValueError):\n        Node2Vec(emb_size=4, node_num=4)\n    with pytest.raises(ValueError):\n        Node2Vec(emb_size=4, multiplicity=2)\n    G = example_graph()\n    gen = Node2VecNodeGenerator(G, batch_size=2)\n    node2vec = Node2Vec(emb_size=4, generator=gen)\n    assert (node2vec.emb_size == 4)\n    assert (node2vec.input_node_num == 4)\n    assert (node2vec.multiplicity == 1)", "masked_code": "def test_node2vec_constructor():\n    node2vec = Node2Vec(emb_size=4, node_num=4, multiplicity=2)\n    assert (node2vec.emb_size == 4)\n    assert (node2vec.input_node_num == 4)\n    assert (node2vec.multiplicity == 2)\n    with pytest.raises(ValueError):\n        Node2Vec(emb_size=4)\n    with pytest.raises(ValueError):\n        Node2Vec(emb_size=4, node_num=4)\n    with pytest.raises(ValueError):\n        Node2Vec(emb_size=4, multiplicity=2)\n    G = example_graph()\n    gen = Node2VecNodeGenerator(G, batch_size=2)\n    node2vec = Node2Vec(emb_size=4, generator=gen)\n    assert (node2vec.emb_size == '???')\n    assert (node2vec.input_node_num == 4)\n    assert (node2vec.multiplicity == 1)", "ground_truth": "4", "quality_analysis": {"complexity_score": 3, "left_complexity": 2, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_719", "reponame": "stellargraph", "testpath": "tests/layer/test_node2vec.py", "testname": "test_node2vec.py", "classname": null, "funcname": "test_node2vec_constructor", "imports": ["from stellargraph.core.graph import StellarGraph", "from stellargraph.mapper import Node2VecNodeGenerator", "from stellargraph.layer.node2vec import *", "from tensorflow import keras", "import numpy as np", "import pytest", "from ..test_utils.graphs import example_graph", "from .. import test_utils"], "code": "def test_node2vec_constructor():\n    node2vec = Node2Vec(emb_size=4, node_num=4, multiplicity=2)\n    assert (node2vec.emb_size == 4)\n    assert (node2vec.input_node_num == 4)\n    assert (node2vec.multiplicity == 2)\n    with pytest.raises(ValueError):\n        Node2Vec(emb_size=4)\n    with pytest.raises(ValueError):\n        Node2Vec(emb_size=4, node_num=4)\n    with pytest.raises(ValueError):\n        Node2Vec(emb_size=4, multiplicity=2)\n    G = example_graph()\n    gen = Node2VecNodeGenerator(G, batch_size=2)\n    node2vec = Node2Vec(emb_size=4, generator=gen)\n    assert (node2vec.emb_size == 4)\n    assert (node2vec.input_node_num == 4)\n    assert (node2vec.multiplicity == 1)", "masked_code": "def test_node2vec_constructor():\n    node2vec = Node2Vec(emb_size=4, node_num=4, multiplicity=2)\n    assert (node2vec.emb_size == 4)\n    assert (node2vec.input_node_num == 4)\n    assert (node2vec.multiplicity == 2)\n    with pytest.raises(ValueError):\n        Node2Vec(emb_size=4)\n    with pytest.raises(ValueError):\n        Node2Vec(emb_size=4, node_num=4)\n    with pytest.raises(ValueError):\n        Node2Vec(emb_size=4, multiplicity=2)\n    G = example_graph()\n    gen = Node2VecNodeGenerator(G, batch_size=2)\n    node2vec = Node2Vec(emb_size=4, generator=gen)\n    assert (node2vec.emb_size == 4)\n    assert (node2vec.input_node_num == '???')\n    assert (node2vec.multiplicity == 1)", "ground_truth": "4", "quality_analysis": {"complexity_score": 3, "left_complexity": 2, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_720", "reponame": "stellargraph", "testpath": "tests/layer/test_node2vec.py", "testname": "test_node2vec.py", "classname": null, "funcname": "test_node2vec_apply", "imports": ["from stellargraph.core.graph import StellarGraph", "from stellargraph.mapper import Node2VecNodeGenerator", "from stellargraph.layer.node2vec import *", "from tensorflow import keras", "import numpy as np", "import pytest", "from ..test_utils.graphs import example_graph", "from .. import test_utils"], "code": "def test_node2vec_apply():\n    node2vec = Node2Vec(emb_size=4, node_num=4, multiplicity=2)\n    x = np.array([[1]])\n    expected = np.array([[1, 1, 1, 1]])\n    inp = keras.Input(shape=(1,))\n    out = node2vec(inp, 'target')\n    model1 = keras.Model(inputs=inp, outputs=out)\n    model_weights1 = [np.ones_like(w) for w in model1.get_weights()]\n    model1.set_weights(model_weights1)\n    actual = model1.predict(x)\n    assert (expected == pytest.approx(actual))\n    x1 = np.array([[0]])\n    x2 = np.array([[2]])\n    y1 = np.array([[1, 1, 1, 1]])\n    y2 = np.array([[1, 1, 1, 1]])\n    (xinp, xout) = node2vec.in_out_tensors()\n    model2 = keras.Model(inputs=xinp, outputs=xout)\n    model_weights2 = [np.ones_like(w) for w in model2.get_weights()]\n    model2.set_weights(model_weights2)\n    actual = model2.predict([x1, x2])\n    assert (pytest.approx(y1) == actual[0])\n    assert (pytest.approx(y2) == actual[1])", "masked_code": "def test_node2vec_apply():\n    node2vec = Node2Vec(emb_size=4, node_num=4, multiplicity=2)\n    x = np.array([[1]])\n    expected = np.array([[1, 1, 1, 1]])\n    inp = keras.Input(shape=(1,))\n    out = node2vec(inp, 'target')\n    model1 = keras.Model(inputs=inp, outputs=out)\n    model_weights1 = [np.ones_like(w) for w in model1.get_weights()]\n    model1.set_weights(model_weights1)\n    actual = model1.predict(x)\n    assert (expected == pytest.approx(actual))\n    x1 = np.array([[0]])\n    x2 = np.array([[2]])\n    y1 = np.array([[1, 1, 1, 1]])\n    y2 = np.array([[1, 1, 1, 1]])\n    (xinp, xout) = node2vec.in_out_tensors()\n    model2 = keras.Model(inputs=xinp, outputs=xout)\n    model_weights2 = [np.ones_like(w) for w in model2.get_weights()]\n    model2.set_weights(model_weights2)\n    actual = model2.predict([x1, x2])\n    assert (pytest.approx(y1) == '???')\n    assert (pytest.approx(y2) == actual[1])", "ground_truth": "actual[0]", "quality_analysis": {"complexity_score": 9, "left_complexity": 4, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_721", "reponame": "stellargraph", "testpath": "tests/layer/test_node2vec.py", "testname": "test_node2vec.py", "classname": null, "funcname": "test_node2vec_apply", "imports": ["from stellargraph.core.graph import StellarGraph", "from stellargraph.mapper import Node2VecNodeGenerator", "from stellargraph.layer.node2vec import *", "from tensorflow import keras", "import numpy as np", "import pytest", "from ..test_utils.graphs import example_graph", "from .. import test_utils"], "code": "def test_node2vec_apply():\n    node2vec = Node2Vec(emb_size=4, node_num=4, multiplicity=2)\n    x = np.array([[1]])\n    expected = np.array([[1, 1, 1, 1]])\n    inp = keras.Input(shape=(1,))\n    out = node2vec(inp, 'target')\n    model1 = keras.Model(inputs=inp, outputs=out)\n    model_weights1 = [np.ones_like(w) for w in model1.get_weights()]\n    model1.set_weights(model_weights1)\n    actual = model1.predict(x)\n    assert (expected == pytest.approx(actual))\n    x1 = np.array([[0]])\n    x2 = np.array([[2]])\n    y1 = np.array([[1, 1, 1, 1]])\n    y2 = np.array([[1, 1, 1, 1]])\n    (xinp, xout) = node2vec.in_out_tensors()\n    model2 = keras.Model(inputs=xinp, outputs=xout)\n    model_weights2 = [np.ones_like(w) for w in model2.get_weights()]\n    model2.set_weights(model_weights2)\n    actual = model2.predict([x1, x2])\n    assert (pytest.approx(y1) == actual[0])\n    assert (pytest.approx(y2) == actual[1])", "masked_code": "def test_node2vec_apply():\n    node2vec = Node2Vec(emb_size=4, node_num=4, multiplicity=2)\n    x = np.array([[1]])\n    expected = np.array([[1, 1, 1, 1]])\n    inp = keras.Input(shape=(1,))\n    out = node2vec(inp, 'target')\n    model1 = keras.Model(inputs=inp, outputs=out)\n    model_weights1 = [np.ones_like(w) for w in model1.get_weights()]\n    model1.set_weights(model_weights1)\n    actual = model1.predict(x)\n    assert (expected == pytest.approx(actual))\n    x1 = np.array([[0]])\n    x2 = np.array([[2]])\n    y1 = np.array([[1, 1, 1, 1]])\n    y2 = np.array([[1, 1, 1, 1]])\n    (xinp, xout) = node2vec.in_out_tensors()\n    model2 = keras.Model(inputs=xinp, outputs=xout)\n    model_weights2 = [np.ones_like(w) for w in model2.get_weights()]\n    model2.set_weights(model_weights2)\n    actual = model2.predict([x1, x2])\n    assert (pytest.approx(y1) == actual[0])\n    assert (pytest.approx(y2) == '???')", "ground_truth": "actual[1]", "quality_analysis": {"complexity_score": 9, "left_complexity": 4, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_722", "reponame": "stellargraph", "testpath": "tests/layer/test_ppnp.py", "testname": "test_ppnp.py", "classname": null, "funcname": "test_PPNP_edge_cases", "imports": ["from stellargraph.layer import PPNP", "from stellargraph.mapper import FullBatchNodeGenerator, FullBatchLinkGenerator", "from stellargraph import StellarGraph", "from stellargraph.core.utils import PPNP_Aadj_feats_op", "import networkx as nx", "import pandas as pd", "import numpy as np", "from tensorflow import keras", "import pytest", "from ..test_utils.graphs import create_graph_features", "from .. import test_utils"], "code": "def test_PPNP_edge_cases():\n    (G, features) = create_graph_features()\n    adj = G.to_adjacency_matrix()\n    (features, adj) = PPNP_Aadj_feats_op(features, adj)\n    ppnp_sparse_failed = False\n    try:\n        generator = FullBatchNodeGenerator(G, sparse=True, method='ppnp')\n    except ValueError as e:\n        ppnp_sparse_failed = True\n    assert ppnp_sparse_failed\n    generator = FullBatchNodeGenerator(G, sparse=False, method='ppnp')\n    try:\n        ppnpModel = PPNP([2, 2], generator=generator, activations=['relu'], dropout=0.5)\n    except ValueError as e:\n        error = e\n    assert (str(error) == 'The number of layers should equal the number of activations')\n    try:\n        ppnpModel = PPNP([2], generator=[0, 1], activations=['relu'], dropout=0.5)\n    except TypeError as e:\n        error = e\n    assert (str(error) == 'Generator should be a instance of FullBatchNodeGenerator')", "masked_code": "def test_PPNP_edge_cases():\n    (G, features) = create_graph_features()\n    adj = G.to_adjacency_matrix()\n    (features, adj) = PPNP_Aadj_feats_op(features, adj)\n    ppnp_sparse_failed = False\n    try:\n        generator = FullBatchNodeGenerator(G, sparse=True, method='ppnp')\n    except ValueError as e:\n        ppnp_sparse_failed = True\n    assert ppnp_sparse_failed\n    generator = FullBatchNodeGenerator(G, sparse=False, method='ppnp')\n    try:\n        ppnpModel = PPNP([2, 2], generator=generator, activations=['relu'], dropout=0.5)\n    except ValueError as e:\n        error = e\n    assert (str(error) == '???')\n    try:\n        ppnpModel = PPNP([2], generator=[0, 1], activations=['relu'], dropout=0.5)\n    except TypeError as e:\n        error = e\n    assert (str(error) == 'Generator should be a instance of FullBatchNodeGenerator')", "ground_truth": "'The number of layers should equal the number of activations'", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_723", "reponame": "stellargraph", "testpath": "tests/layer/test_ppnp.py", "testname": "test_ppnp.py", "classname": null, "funcname": "test_PPNP_edge_cases", "imports": ["from stellargraph.layer import PPNP", "from stellargraph.mapper import FullBatchNodeGenerator, FullBatchLinkGenerator", "from stellargraph import StellarGraph", "from stellargraph.core.utils import PPNP_Aadj_feats_op", "import networkx as nx", "import pandas as pd", "import numpy as np", "from tensorflow import keras", "import pytest", "from ..test_utils.graphs import create_graph_features", "from .. import test_utils"], "code": "def test_PPNP_edge_cases():\n    (G, features) = create_graph_features()\n    adj = G.to_adjacency_matrix()\n    (features, adj) = PPNP_Aadj_feats_op(features, adj)\n    ppnp_sparse_failed = False\n    try:\n        generator = FullBatchNodeGenerator(G, sparse=True, method='ppnp')\n    except ValueError as e:\n        ppnp_sparse_failed = True\n    assert ppnp_sparse_failed\n    generator = FullBatchNodeGenerator(G, sparse=False, method='ppnp')\n    try:\n        ppnpModel = PPNP([2, 2], generator=generator, activations=['relu'], dropout=0.5)\n    except ValueError as e:\n        error = e\n    assert (str(error) == 'The number of layers should equal the number of activations')\n    try:\n        ppnpModel = PPNP([2], generator=[0, 1], activations=['relu'], dropout=0.5)\n    except TypeError as e:\n        error = e\n    assert (str(error) == 'Generator should be a instance of FullBatchNodeGenerator')", "masked_code": "def test_PPNP_edge_cases():\n    (G, features) = create_graph_features()\n    adj = G.to_adjacency_matrix()\n    (features, adj) = PPNP_Aadj_feats_op(features, adj)\n    ppnp_sparse_failed = False\n    try:\n        generator = FullBatchNodeGenerator(G, sparse=True, method='ppnp')\n    except ValueError as e:\n        ppnp_sparse_failed = True\n    assert ppnp_sparse_failed\n    generator = FullBatchNodeGenerator(G, sparse=False, method='ppnp')\n    try:\n        ppnpModel = PPNP([2, 2], generator=generator, activations=['relu'], dropout=0.5)\n    except ValueError as e:\n        error = e\n    assert (str(error) == 'The number of layers should equal the number of activations')\n    try:\n        ppnpModel = PPNP([2], generator=[0, 1], activations=['relu'], dropout=0.5)\n    except TypeError as e:\n        error = e\n    assert (str(error) == '???')", "ground_truth": "'Generator should be a instance of FullBatchNodeGenerator'", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_724", "reponame": "stellargraph", "testpath": "tests/layer/test_ppnp.py", "testname": "test_ppnp.py", "classname": null, "funcname": "test_PPNP_apply_dense", "imports": ["from stellargraph.layer import PPNP", "from stellargraph.mapper import FullBatchNodeGenerator, FullBatchLinkGenerator", "from stellargraph import StellarGraph", "from stellargraph.core.utils import PPNP_Aadj_feats_op", "import networkx as nx", "import pandas as pd", "import numpy as np", "from tensorflow import keras", "import pytest", "from ..test_utils.graphs import create_graph_features", "from .. import test_utils"], "code": "def test_PPNP_apply_dense():\n    (G, features) = create_graph_features()\n    adj = G.to_adjacency_matrix()\n    (features, adj) = PPNP_Aadj_feats_op(features, adj)\n    adj = adj[(None, :, :)]\n    generator = FullBatchNodeGenerator(G, sparse=False, method='ppnp')\n    ppnpModel = PPNP([2], generator=generator, activations=['relu'], dropout=0.5)\n    (x_in, x_out) = ppnpModel.in_out_tensors()\n    model = keras.Model(inputs=x_in, outputs=x_out)\n    out_indices = np.array([[0, 1]], dtype='int32')\n    preds_1 = model.predict([features[(None, :, :)], out_indices, adj])\n    assert (preds_1.shape == (1, 2, 2))\n    preds_2 = model.predict(generator.flow(['a', 'b']))\n    assert (preds_2.shape == (1, 2, 2))\n    assert (preds_1 == pytest.approx(preds_2))", "masked_code": "def test_PPNP_apply_dense():\n    (G, features) = create_graph_features()\n    adj = G.to_adjacency_matrix()\n    (features, adj) = PPNP_Aadj_feats_op(features, adj)\n    adj = adj[(None, :, :)]\n    generator = FullBatchNodeGenerator(G, sparse=False, method='ppnp')\n    ppnpModel = PPNP([2], generator=generator, activations=['relu'], dropout=0.5)\n    (x_in, x_out) = ppnpModel.in_out_tensors()\n    model = keras.Model(inputs=x_in, outputs=x_out)\n    out_indices = np.array([[0, 1]], dtype='int32')\n    preds_1 = model.predict([features[(None, :, :)], out_indices, adj])\n    assert (preds_1.shape == '???')\n    preds_2 = model.predict(generator.flow(['a', 'b']))\n    assert (preds_2.shape == (1, 2, 2))\n    assert (preds_1 == pytest.approx(preds_2))", "ground_truth": "(1, 2, 2)", "quality_analysis": {"complexity_score": 7, "left_complexity": 2, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_725", "reponame": "stellargraph", "testpath": "tests/layer/test_ppnp.py", "testname": "test_ppnp.py", "classname": null, "funcname": "test_PPNP_apply_dense", "imports": ["from stellargraph.layer import PPNP", "from stellargraph.mapper import FullBatchNodeGenerator, FullBatchLinkGenerator", "from stellargraph import StellarGraph", "from stellargraph.core.utils import PPNP_Aadj_feats_op", "import networkx as nx", "import pandas as pd", "import numpy as np", "from tensorflow import keras", "import pytest", "from ..test_utils.graphs import create_graph_features", "from .. import test_utils"], "code": "def test_PPNP_apply_dense():\n    (G, features) = create_graph_features()\n    adj = G.to_adjacency_matrix()\n    (features, adj) = PPNP_Aadj_feats_op(features, adj)\n    adj = adj[(None, :, :)]\n    generator = FullBatchNodeGenerator(G, sparse=False, method='ppnp')\n    ppnpModel = PPNP([2], generator=generator, activations=['relu'], dropout=0.5)\n    (x_in, x_out) = ppnpModel.in_out_tensors()\n    model = keras.Model(inputs=x_in, outputs=x_out)\n    out_indices = np.array([[0, 1]], dtype='int32')\n    preds_1 = model.predict([features[(None, :, :)], out_indices, adj])\n    assert (preds_1.shape == (1, 2, 2))\n    preds_2 = model.predict(generator.flow(['a', 'b']))\n    assert (preds_2.shape == (1, 2, 2))\n    assert (preds_1 == pytest.approx(preds_2))", "masked_code": "def test_PPNP_apply_dense():\n    (G, features) = create_graph_features()\n    adj = G.to_adjacency_matrix()\n    (features, adj) = PPNP_Aadj_feats_op(features, adj)\n    adj = adj[(None, :, :)]\n    generator = FullBatchNodeGenerator(G, sparse=False, method='ppnp')\n    ppnpModel = PPNP([2], generator=generator, activations=['relu'], dropout=0.5)\n    (x_in, x_out) = ppnpModel.in_out_tensors()\n    model = keras.Model(inputs=x_in, outputs=x_out)\n    out_indices = np.array([[0, 1]], dtype='int32')\n    preds_1 = model.predict([features[(None, :, :)], out_indices, adj])\n    assert (preds_1.shape == (1, 2, 2))\n    preds_2 = model.predict(generator.flow(['a', 'b']))\n    assert (preds_2.shape == '???')\n    assert (preds_1 == pytest.approx(preds_2))", "ground_truth": "(1, 2, 2)", "quality_analysis": {"complexity_score": 7, "left_complexity": 2, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_726", "reponame": "stellargraph", "testpath": "tests/layer/test_rgcn.py", "testname": "test_rgcn.py", "classname": null, "funcname": "test_RelationalGraphConvolution_config", "imports": ["import numpy as np", "from stellargraph.layer.rgcn import RelationalGraphConvolution, RGCN", "from stellargraph.mapper.full_batch_generators import RelationalFullBatchNodeGenerator", "import pytest", "from scipy import sparse as sps", "from stellargraph.core.utils import normalize_adj", "import tensorflow as tf", "from tensorflow import keras", "from tensorflow.keras import backend as K", "from tensorflow.keras.layers import Input, Lambda", "from stellargraph import StellarDiGraph, StellarGraph", "from stellargraph.layer.misc import SqueezedSparseConversion", "import pandas as pd", "from ..test_utils.graphs import relational_create_graph_features as create_graph_features", "from .. import test_utils"], "code": "def test_RelationalGraphConvolution_config():\n    rgcn_layer = RelationalGraphConvolution(units=16, num_relationships=5)\n    conf = rgcn_layer.get_config()\n    assert (conf['units'] == 16)\n    assert (conf['activation'] == 'linear')\n    assert (conf['num_bases'] == 0)\n    assert (conf['num_relationships'] == 5)\n    assert (conf['use_bias'] == True)\n    assert (conf['kernel_initializer']['class_name'] == 'GlorotUniform')\n    assert (conf['bias_initializer']['class_name'] == 'Zeros')\n    assert (conf['basis_initializer']['class_name'] == 'GlorotUniform')\n    assert (conf['coefficient_initializer']['class_name'] == 'GlorotUniform')\n    assert (conf['kernel_regularizer'] is None)\n    assert (conf['bias_regularizer'] is None)\n    assert (conf['basis_regularizer'] is None)\n    assert (conf['coefficient_regularizer'] is None)\n    assert (conf['kernel_constraint'] is None)\n    assert (conf['bias_constraint'] is None)\n    assert (conf['basis_constraint'] is None)\n    assert (conf['coefficient_constraint'] is None)", "masked_code": "def test_RelationalGraphConvolution_config():\n    rgcn_layer = RelationalGraphConvolution(units=16, num_relationships=5)\n    conf = rgcn_layer.get_config()\n    assert (conf['units'] == '???')\n    assert (conf['activation'] == 'linear')\n    assert (conf['num_bases'] == 0)\n    assert (conf['num_relationships'] == 5)\n    assert (conf['use_bias'] == True)\n    assert (conf['kernel_initializer']['class_name'] == 'GlorotUniform')\n    assert (conf['bias_initializer']['class_name'] == 'Zeros')\n    assert (conf['basis_initializer']['class_name'] == 'GlorotUniform')\n    assert (conf['coefficient_initializer']['class_name'] == 'GlorotUniform')\n    assert (conf['kernel_regularizer'] is None)\n    assert (conf['bias_regularizer'] is None)\n    assert (conf['basis_regularizer'] is None)\n    assert (conf['coefficient_regularizer'] is None)\n    assert (conf['kernel_constraint'] is None)\n    assert (conf['bias_constraint'] is None)\n    assert (conf['basis_constraint'] is None)\n    assert (conf['coefficient_constraint'] is None)", "ground_truth": "16", "quality_analysis": {"complexity_score": 6, "left_complexity": 5, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_727", "reponame": "stellargraph", "testpath": "tests/layer/test_rgcn.py", "testname": "test_rgcn.py", "classname": null, "funcname": "test_RelationalGraphConvolution_config", "imports": ["import numpy as np", "from stellargraph.layer.rgcn import RelationalGraphConvolution, RGCN", "from stellargraph.mapper.full_batch_generators import RelationalFullBatchNodeGenerator", "import pytest", "from scipy import sparse as sps", "from stellargraph.core.utils import normalize_adj", "import tensorflow as tf", "from tensorflow import keras", "from tensorflow.keras import backend as K", "from tensorflow.keras.layers import Input, Lambda", "from stellargraph import StellarDiGraph, StellarGraph", "from stellargraph.layer.misc import SqueezedSparseConversion", "import pandas as pd", "from ..test_utils.graphs import relational_create_graph_features as create_graph_features", "from .. import test_utils"], "code": "def test_RelationalGraphConvolution_config():\n    rgcn_layer = RelationalGraphConvolution(units=16, num_relationships=5)\n    conf = rgcn_layer.get_config()\n    assert (conf['units'] == 16)\n    assert (conf['activation'] == 'linear')\n    assert (conf['num_bases'] == 0)\n    assert (conf['num_relationships'] == 5)\n    assert (conf['use_bias'] == True)\n    assert (conf['kernel_initializer']['class_name'] == 'GlorotUniform')\n    assert (conf['bias_initializer']['class_name'] == 'Zeros')\n    assert (conf['basis_initializer']['class_name'] == 'GlorotUniform')\n    assert (conf['coefficient_initializer']['class_name'] == 'GlorotUniform')\n    assert (conf['kernel_regularizer'] is None)\n    assert (conf['bias_regularizer'] is None)\n    assert (conf['basis_regularizer'] is None)\n    assert (conf['coefficient_regularizer'] is None)\n    assert (conf['kernel_constraint'] is None)\n    assert (conf['bias_constraint'] is None)\n    assert (conf['basis_constraint'] is None)\n    assert (conf['coefficient_constraint'] is None)", "masked_code": "def test_RelationalGraphConvolution_config():\n    rgcn_layer = RelationalGraphConvolution(units=16, num_relationships=5)\n    conf = rgcn_layer.get_config()\n    assert (conf['units'] == 16)\n    assert (conf['activation'] == '???')\n    assert (conf['num_bases'] == 0)\n    assert (conf['num_relationships'] == 5)\n    assert (conf['use_bias'] == True)\n    assert (conf['kernel_initializer']['class_name'] == 'GlorotUniform')\n    assert (conf['bias_initializer']['class_name'] == 'Zeros')\n    assert (conf['basis_initializer']['class_name'] == 'GlorotUniform')\n    assert (conf['coefficient_initializer']['class_name'] == 'GlorotUniform')\n    assert (conf['kernel_regularizer'] is None)\n    assert (conf['bias_regularizer'] is None)\n    assert (conf['basis_regularizer'] is None)\n    assert (conf['coefficient_regularizer'] is None)\n    assert (conf['kernel_constraint'] is None)\n    assert (conf['bias_constraint'] is None)\n    assert (conf['basis_constraint'] is None)\n    assert (conf['coefficient_constraint'] is None)", "ground_truth": "'linear'", "quality_analysis": {"complexity_score": 6, "left_complexity": 5, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_728", "reponame": "stellargraph", "testpath": "tests/layer/test_rgcn.py", "testname": "test_rgcn.py", "classname": null, "funcname": "test_RelationalGraphConvolution_config", "imports": ["import numpy as np", "from stellargraph.layer.rgcn import RelationalGraphConvolution, RGCN", "from stellargraph.mapper.full_batch_generators import RelationalFullBatchNodeGenerator", "import pytest", "from scipy import sparse as sps", "from stellargraph.core.utils import normalize_adj", "import tensorflow as tf", "from tensorflow import keras", "from tensorflow.keras import backend as K", "from tensorflow.keras.layers import Input, Lambda", "from stellargraph import StellarDiGraph, StellarGraph", "from stellargraph.layer.misc import SqueezedSparseConversion", "import pandas as pd", "from ..test_utils.graphs import relational_create_graph_features as create_graph_features", "from .. import test_utils"], "code": "def test_RelationalGraphConvolution_config():\n    rgcn_layer = RelationalGraphConvolution(units=16, num_relationships=5)\n    conf = rgcn_layer.get_config()\n    assert (conf['units'] == 16)\n    assert (conf['activation'] == 'linear')\n    assert (conf['num_bases'] == 0)\n    assert (conf['num_relationships'] == 5)\n    assert (conf['use_bias'] == True)\n    assert (conf['kernel_initializer']['class_name'] == 'GlorotUniform')\n    assert (conf['bias_initializer']['class_name'] == 'Zeros')\n    assert (conf['basis_initializer']['class_name'] == 'GlorotUniform')\n    assert (conf['coefficient_initializer']['class_name'] == 'GlorotUniform')\n    assert (conf['kernel_regularizer'] is None)\n    assert (conf['bias_regularizer'] is None)\n    assert (conf['basis_regularizer'] is None)\n    assert (conf['coefficient_regularizer'] is None)\n    assert (conf['kernel_constraint'] is None)\n    assert (conf['bias_constraint'] is None)\n    assert (conf['basis_constraint'] is None)\n    assert (conf['coefficient_constraint'] is None)", "masked_code": "def test_RelationalGraphConvolution_config():\n    rgcn_layer = RelationalGraphConvolution(units=16, num_relationships=5)\n    conf = rgcn_layer.get_config()\n    assert (conf['units'] == 16)\n    assert (conf['activation'] == 'linear')\n    assert (conf['num_bases'] == 0)\n    assert (conf['num_relationships'] == '???')\n    assert (conf['use_bias'] == True)\n    assert (conf['kernel_initializer']['class_name'] == 'GlorotUniform')\n    assert (conf['bias_initializer']['class_name'] == 'Zeros')\n    assert (conf['basis_initializer']['class_name'] == 'GlorotUniform')\n    assert (conf['coefficient_initializer']['class_name'] == 'GlorotUniform')\n    assert (conf['kernel_regularizer'] is None)\n    assert (conf['bias_regularizer'] is None)\n    assert (conf['basis_regularizer'] is None)\n    assert (conf['coefficient_regularizer'] is None)\n    assert (conf['kernel_constraint'] is None)\n    assert (conf['bias_constraint'] is None)\n    assert (conf['basis_constraint'] is None)\n    assert (conf['coefficient_constraint'] is None)", "ground_truth": "5", "quality_analysis": {"complexity_score": 6, "left_complexity": 5, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_729", "reponame": "stellargraph", "testpath": "tests/layer/test_rgcn.py", "testname": "test_rgcn.py", "classname": null, "funcname": "test_RelationalGraphConvolution_config", "imports": ["import numpy as np", "from stellargraph.layer.rgcn import RelationalGraphConvolution, RGCN", "from stellargraph.mapper.full_batch_generators import RelationalFullBatchNodeGenerator", "import pytest", "from scipy import sparse as sps", "from stellargraph.core.utils import normalize_adj", "import tensorflow as tf", "from tensorflow import keras", "from tensorflow.keras import backend as K", "from tensorflow.keras.layers import Input, Lambda", "from stellargraph import StellarDiGraph, StellarGraph", "from stellargraph.layer.misc import SqueezedSparseConversion", "import pandas as pd", "from ..test_utils.graphs import relational_create_graph_features as create_graph_features", "from .. import test_utils"], "code": "def test_RelationalGraphConvolution_config():\n    rgcn_layer = RelationalGraphConvolution(units=16, num_relationships=5)\n    conf = rgcn_layer.get_config()\n    assert (conf['units'] == 16)\n    assert (conf['activation'] == 'linear')\n    assert (conf['num_bases'] == 0)\n    assert (conf['num_relationships'] == 5)\n    assert (conf['use_bias'] == True)\n    assert (conf['kernel_initializer']['class_name'] == 'GlorotUniform')\n    assert (conf['bias_initializer']['class_name'] == 'Zeros')\n    assert (conf['basis_initializer']['class_name'] == 'GlorotUniform')\n    assert (conf['coefficient_initializer']['class_name'] == 'GlorotUniform')\n    assert (conf['kernel_regularizer'] is None)\n    assert (conf['bias_regularizer'] is None)\n    assert (conf['basis_regularizer'] is None)\n    assert (conf['coefficient_regularizer'] is None)\n    assert (conf['kernel_constraint'] is None)\n    assert (conf['bias_constraint'] is None)\n    assert (conf['basis_constraint'] is None)\n    assert (conf['coefficient_constraint'] is None)", "masked_code": "def test_RelationalGraphConvolution_config():\n    rgcn_layer = RelationalGraphConvolution(units=16, num_relationships=5)\n    conf = rgcn_layer.get_config()\n    assert (conf['units'] == 16)\n    assert (conf['activation'] == 'linear')\n    assert (conf['num_bases'] == 0)\n    assert (conf['num_relationships'] == 5)\n    assert (conf['use_bias'] == True)\n    assert (conf['kernel_initializer']['class_name'] == '???')\n    assert (conf['bias_initializer']['class_name'] == 'Zeros')\n    assert (conf['basis_initializer']['class_name'] == 'GlorotUniform')\n    assert (conf['coefficient_initializer']['class_name'] == 'GlorotUniform')\n    assert (conf['kernel_regularizer'] is None)\n    assert (conf['bias_regularizer'] is None)\n    assert (conf['basis_regularizer'] is None)\n    assert (conf['coefficient_regularizer'] is None)\n    assert (conf['kernel_constraint'] is None)\n    assert (conf['bias_constraint'] is None)\n    assert (conf['basis_constraint'] is None)\n    assert (conf['coefficient_constraint'] is None)", "ground_truth": "'GlorotUniform'", "quality_analysis": {"complexity_score": 10, "left_complexity": 9, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_730", "reponame": "stellargraph", "testpath": "tests/layer/test_rgcn.py", "testname": "test_rgcn.py", "classname": null, "funcname": "test_RelationalGraphConvolution_config", "imports": ["import numpy as np", "from stellargraph.layer.rgcn import RelationalGraphConvolution, RGCN", "from stellargraph.mapper.full_batch_generators import RelationalFullBatchNodeGenerator", "import pytest", "from scipy import sparse as sps", "from stellargraph.core.utils import normalize_adj", "import tensorflow as tf", "from tensorflow import keras", "from tensorflow.keras import backend as K", "from tensorflow.keras.layers import Input, Lambda", "from stellargraph import StellarDiGraph, StellarGraph", "from stellargraph.layer.misc import SqueezedSparseConversion", "import pandas as pd", "from ..test_utils.graphs import relational_create_graph_features as create_graph_features", "from .. import test_utils"], "code": "def test_RelationalGraphConvolution_config():\n    rgcn_layer = RelationalGraphConvolution(units=16, num_relationships=5)\n    conf = rgcn_layer.get_config()\n    assert (conf['units'] == 16)\n    assert (conf['activation'] == 'linear')\n    assert (conf['num_bases'] == 0)\n    assert (conf['num_relationships'] == 5)\n    assert (conf['use_bias'] == True)\n    assert (conf['kernel_initializer']['class_name'] == 'GlorotUniform')\n    assert (conf['bias_initializer']['class_name'] == 'Zeros')\n    assert (conf['basis_initializer']['class_name'] == 'GlorotUniform')\n    assert (conf['coefficient_initializer']['class_name'] == 'GlorotUniform')\n    assert (conf['kernel_regularizer'] is None)\n    assert (conf['bias_regularizer'] is None)\n    assert (conf['basis_regularizer'] is None)\n    assert (conf['coefficient_regularizer'] is None)\n    assert (conf['kernel_constraint'] is None)\n    assert (conf['bias_constraint'] is None)\n    assert (conf['basis_constraint'] is None)\n    assert (conf['coefficient_constraint'] is None)", "masked_code": "def test_RelationalGraphConvolution_config():\n    rgcn_layer = RelationalGraphConvolution(units=16, num_relationships=5)\n    conf = rgcn_layer.get_config()\n    assert (conf['units'] == 16)\n    assert (conf['activation'] == 'linear')\n    assert (conf['num_bases'] == 0)\n    assert (conf['num_relationships'] == 5)\n    assert (conf['use_bias'] == True)\n    assert (conf['kernel_initializer']['class_name'] == 'GlorotUniform')\n    assert (conf['bias_initializer']['class_name'] == '???')\n    assert (conf['basis_initializer']['class_name'] == 'GlorotUniform')\n    assert (conf['coefficient_initializer']['class_name'] == 'GlorotUniform')\n    assert (conf['kernel_regularizer'] is None)\n    assert (conf['bias_regularizer'] is None)\n    assert (conf['basis_regularizer'] is None)\n    assert (conf['coefficient_regularizer'] is None)\n    assert (conf['kernel_constraint'] is None)\n    assert (conf['bias_constraint'] is None)\n    assert (conf['basis_constraint'] is None)\n    assert (conf['coefficient_constraint'] is None)", "ground_truth": "'Zeros'", "quality_analysis": {"complexity_score": 10, "left_complexity": 9, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_731", "reponame": "stellargraph", "testpath": "tests/layer/test_rgcn.py", "testname": "test_rgcn.py", "classname": null, "funcname": "test_RelationalGraphConvolution_config", "imports": ["import numpy as np", "from stellargraph.layer.rgcn import RelationalGraphConvolution, RGCN", "from stellargraph.mapper.full_batch_generators import RelationalFullBatchNodeGenerator", "import pytest", "from scipy import sparse as sps", "from stellargraph.core.utils import normalize_adj", "import tensorflow as tf", "from tensorflow import keras", "from tensorflow.keras import backend as K", "from tensorflow.keras.layers import Input, Lambda", "from stellargraph import StellarDiGraph, StellarGraph", "from stellargraph.layer.misc import SqueezedSparseConversion", "import pandas as pd", "from ..test_utils.graphs import relational_create_graph_features as create_graph_features", "from .. import test_utils"], "code": "def test_RelationalGraphConvolution_config():\n    rgcn_layer = RelationalGraphConvolution(units=16, num_relationships=5)\n    conf = rgcn_layer.get_config()\n    assert (conf['units'] == 16)\n    assert (conf['activation'] == 'linear')\n    assert (conf['num_bases'] == 0)\n    assert (conf['num_relationships'] == 5)\n    assert (conf['use_bias'] == True)\n    assert (conf['kernel_initializer']['class_name'] == 'GlorotUniform')\n    assert (conf['bias_initializer']['class_name'] == 'Zeros')\n    assert (conf['basis_initializer']['class_name'] == 'GlorotUniform')\n    assert (conf['coefficient_initializer']['class_name'] == 'GlorotUniform')\n    assert (conf['kernel_regularizer'] is None)\n    assert (conf['bias_regularizer'] is None)\n    assert (conf['basis_regularizer'] is None)\n    assert (conf['coefficient_regularizer'] is None)\n    assert (conf['kernel_constraint'] is None)\n    assert (conf['bias_constraint'] is None)\n    assert (conf['basis_constraint'] is None)\n    assert (conf['coefficient_constraint'] is None)", "masked_code": "def test_RelationalGraphConvolution_config():\n    rgcn_layer = RelationalGraphConvolution(units=16, num_relationships=5)\n    conf = rgcn_layer.get_config()\n    assert (conf['units'] == 16)\n    assert (conf['activation'] == 'linear')\n    assert (conf['num_bases'] == 0)\n    assert (conf['num_relationships'] == 5)\n    assert (conf['use_bias'] == True)\n    assert (conf['kernel_initializer']['class_name'] == 'GlorotUniform')\n    assert (conf['bias_initializer']['class_name'] == 'Zeros')\n    assert (conf['basis_initializer']['class_name'] == '???')\n    assert (conf['coefficient_initializer']['class_name'] == 'GlorotUniform')\n    assert (conf['kernel_regularizer'] is None)\n    assert (conf['bias_regularizer'] is None)\n    assert (conf['basis_regularizer'] is None)\n    assert (conf['coefficient_regularizer'] is None)\n    assert (conf['kernel_constraint'] is None)\n    assert (conf['bias_constraint'] is None)\n    assert (conf['basis_constraint'] is None)\n    assert (conf['coefficient_constraint'] is None)", "ground_truth": "'GlorotUniform'", "quality_analysis": {"complexity_score": 10, "left_complexity": 9, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_732", "reponame": "stellargraph", "testpath": "tests/layer/test_rgcn.py", "testname": "test_rgcn.py", "classname": null, "funcname": "test_RelationalGraphConvolution_config", "imports": ["import numpy as np", "from stellargraph.layer.rgcn import RelationalGraphConvolution, RGCN", "from stellargraph.mapper.full_batch_generators import RelationalFullBatchNodeGenerator", "import pytest", "from scipy import sparse as sps", "from stellargraph.core.utils import normalize_adj", "import tensorflow as tf", "from tensorflow import keras", "from tensorflow.keras import backend as K", "from tensorflow.keras.layers import Input, Lambda", "from stellargraph import StellarDiGraph, StellarGraph", "from stellargraph.layer.misc import SqueezedSparseConversion", "import pandas as pd", "from ..test_utils.graphs import relational_create_graph_features as create_graph_features", "from .. import test_utils"], "code": "def test_RelationalGraphConvolution_config():\n    rgcn_layer = RelationalGraphConvolution(units=16, num_relationships=5)\n    conf = rgcn_layer.get_config()\n    assert (conf['units'] == 16)\n    assert (conf['activation'] == 'linear')\n    assert (conf['num_bases'] == 0)\n    assert (conf['num_relationships'] == 5)\n    assert (conf['use_bias'] == True)\n    assert (conf['kernel_initializer']['class_name'] == 'GlorotUniform')\n    assert (conf['bias_initializer']['class_name'] == 'Zeros')\n    assert (conf['basis_initializer']['class_name'] == 'GlorotUniform')\n    assert (conf['coefficient_initializer']['class_name'] == 'GlorotUniform')\n    assert (conf['kernel_regularizer'] is None)\n    assert (conf['bias_regularizer'] is None)\n    assert (conf['basis_regularizer'] is None)\n    assert (conf['coefficient_regularizer'] is None)\n    assert (conf['kernel_constraint'] is None)\n    assert (conf['bias_constraint'] is None)\n    assert (conf['basis_constraint'] is None)\n    assert (conf['coefficient_constraint'] is None)", "masked_code": "def test_RelationalGraphConvolution_config():\n    rgcn_layer = RelationalGraphConvolution(units=16, num_relationships=5)\n    conf = rgcn_layer.get_config()\n    assert (conf['units'] == 16)\n    assert (conf['activation'] == 'linear')\n    assert (conf['num_bases'] == 0)\n    assert (conf['num_relationships'] == 5)\n    assert (conf['use_bias'] == True)\n    assert (conf['kernel_initializer']['class_name'] == 'GlorotUniform')\n    assert (conf['bias_initializer']['class_name'] == 'Zeros')\n    assert (conf['basis_initializer']['class_name'] == 'GlorotUniform')\n    assert (conf['coefficient_initializer']['class_name'] == '???')\n    assert (conf['kernel_regularizer'] is None)\n    assert (conf['bias_regularizer'] is None)\n    assert (conf['basis_regularizer'] is None)\n    assert (conf['coefficient_regularizer'] is None)\n    assert (conf['kernel_constraint'] is None)\n    assert (conf['bias_constraint'] is None)\n    assert (conf['basis_constraint'] is None)\n    assert (conf['coefficient_constraint'] is None)", "ground_truth": "'GlorotUniform'", "quality_analysis": {"complexity_score": 10, "left_complexity": 9, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_733", "reponame": "stellargraph", "testpath": "tests/layer/test_rgcn.py", "testname": "test_rgcn.py", "classname": null, "funcname": "test_RelationalGraphConvolution_init", "imports": ["import numpy as np", "from stellargraph.layer.rgcn import RelationalGraphConvolution, RGCN", "from stellargraph.mapper.full_batch_generators import RelationalFullBatchNodeGenerator", "import pytest", "from scipy import sparse as sps", "from stellargraph.core.utils import normalize_adj", "import tensorflow as tf", "from tensorflow import keras", "from tensorflow.keras import backend as K", "from tensorflow.keras.layers import Input, Lambda", "from stellargraph import StellarDiGraph, StellarGraph", "from stellargraph.layer.misc import SqueezedSparseConversion", "import pandas as pd", "from ..test_utils.graphs import relational_create_graph_features as create_graph_features", "from .. import test_utils"], "code": "def test_RelationalGraphConvolution_init():\n    rgcn_layer = RelationalGraphConvolution(units=16, num_relationships=5, num_bases=0, activation='relu')\n    assert (rgcn_layer.units == 16)\n    assert (rgcn_layer.use_bias is True)\n    assert (rgcn_layer.num_bases == 0)\n    assert (rgcn_layer.get_config()['activation'] == 'relu')\n    rgcn_layer = RelationalGraphConvolution(units=16, num_relationships=5, num_bases=10, activation='relu')\n    assert (rgcn_layer.units == 16)\n    assert (rgcn_layer.use_bias is True)\n    assert (rgcn_layer.num_bases == 10)\n    assert (rgcn_layer.get_config()['activation'] == 'relu')", "masked_code": "def test_RelationalGraphConvolution_init():\n    rgcn_layer = RelationalGraphConvolution(units=16, num_relationships=5, num_bases=0, activation='relu')\n    assert (rgcn_layer.units == '???')\n    assert (rgcn_layer.use_bias is True)\n    assert (rgcn_layer.num_bases == 0)\n    assert (rgcn_layer.get_config()['activation'] == 'relu')\n    rgcn_layer = RelationalGraphConvolution(units=16, num_relationships=5, num_bases=10, activation='relu')\n    assert (rgcn_layer.units == 16)\n    assert (rgcn_layer.use_bias is True)\n    assert (rgcn_layer.num_bases == 10)\n    assert (rgcn_layer.get_config()['activation'] == 'relu')", "ground_truth": "16", "quality_analysis": {"complexity_score": 3, "left_complexity": 2, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_734", "reponame": "stellargraph", "testpath": "tests/layer/test_rgcn.py", "testname": "test_rgcn.py", "classname": null, "funcname": "test_RelationalGraphConvolution_init", "imports": ["import numpy as np", "from stellargraph.layer.rgcn import RelationalGraphConvolution, RGCN", "from stellargraph.mapper.full_batch_generators import RelationalFullBatchNodeGenerator", "import pytest", "from scipy import sparse as sps", "from stellargraph.core.utils import normalize_adj", "import tensorflow as tf", "from tensorflow import keras", "from tensorflow.keras import backend as K", "from tensorflow.keras.layers import Input, Lambda", "from stellargraph import StellarDiGraph, StellarGraph", "from stellargraph.layer.misc import SqueezedSparseConversion", "import pandas as pd", "from ..test_utils.graphs import relational_create_graph_features as create_graph_features", "from .. import test_utils"], "code": "def test_RelationalGraphConvolution_init():\n    rgcn_layer = RelationalGraphConvolution(units=16, num_relationships=5, num_bases=0, activation='relu')\n    assert (rgcn_layer.units == 16)\n    assert (rgcn_layer.use_bias is True)\n    assert (rgcn_layer.num_bases == 0)\n    assert (rgcn_layer.get_config()['activation'] == 'relu')\n    rgcn_layer = RelationalGraphConvolution(units=16, num_relationships=5, num_bases=10, activation='relu')\n    assert (rgcn_layer.units == 16)\n    assert (rgcn_layer.use_bias is True)\n    assert (rgcn_layer.num_bases == 10)\n    assert (rgcn_layer.get_config()['activation'] == 'relu')", "masked_code": "def test_RelationalGraphConvolution_init():\n    rgcn_layer = RelationalGraphConvolution(units=16, num_relationships=5, num_bases=0, activation='relu')\n    assert (rgcn_layer.units == 16)\n    assert (rgcn_layer.use_bias is True)\n    assert (rgcn_layer.num_bases == 0)\n    assert (rgcn_layer.get_config()['activation'] == '???')\n    rgcn_layer = RelationalGraphConvolution(units=16, num_relationships=5, num_bases=10, activation='relu')\n    assert (rgcn_layer.units == 16)\n    assert (rgcn_layer.use_bias is True)\n    assert (rgcn_layer.num_bases == 10)\n    assert (rgcn_layer.get_config()['activation'] == 'relu')", "ground_truth": "'relu'", "quality_analysis": {"complexity_score": 8, "left_complexity": 7, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_735", "reponame": "stellargraph", "testpath": "tests/layer/test_rgcn.py", "testname": "test_rgcn.py", "classname": null, "funcname": "test_RelationalGraphConvolution_init", "imports": ["import numpy as np", "from stellargraph.layer.rgcn import RelationalGraphConvolution, RGCN", "from stellargraph.mapper.full_batch_generators import RelationalFullBatchNodeGenerator", "import pytest", "from scipy import sparse as sps", "from stellargraph.core.utils import normalize_adj", "import tensorflow as tf", "from tensorflow import keras", "from tensorflow.keras import backend as K", "from tensorflow.keras.layers import Input, Lambda", "from stellargraph import StellarDiGraph, StellarGraph", "from stellargraph.layer.misc import SqueezedSparseConversion", "import pandas as pd", "from ..test_utils.graphs import relational_create_graph_features as create_graph_features", "from .. import test_utils"], "code": "def test_RelationalGraphConvolution_init():\n    rgcn_layer = RelationalGraphConvolution(units=16, num_relationships=5, num_bases=0, activation='relu')\n    assert (rgcn_layer.units == 16)\n    assert (rgcn_layer.use_bias is True)\n    assert (rgcn_layer.num_bases == 0)\n    assert (rgcn_layer.get_config()['activation'] == 'relu')\n    rgcn_layer = RelationalGraphConvolution(units=16, num_relationships=5, num_bases=10, activation='relu')\n    assert (rgcn_layer.units == 16)\n    assert (rgcn_layer.use_bias is True)\n    assert (rgcn_layer.num_bases == 10)\n    assert (rgcn_layer.get_config()['activation'] == 'relu')", "masked_code": "def test_RelationalGraphConvolution_init():\n    rgcn_layer = RelationalGraphConvolution(units=16, num_relationships=5, num_bases=0, activation='relu')\n    assert (rgcn_layer.units == 16)\n    assert (rgcn_layer.use_bias is True)\n    assert (rgcn_layer.num_bases == 0)\n    assert (rgcn_layer.get_config()['activation'] == 'relu')\n    rgcn_layer = RelationalGraphConvolution(units=16, num_relationships=5, num_bases=10, activation='relu')\n    assert (rgcn_layer.units == '???')\n    assert (rgcn_layer.use_bias is True)\n    assert (rgcn_layer.num_bases == 10)\n    assert (rgcn_layer.get_config()['activation'] == 'relu')", "ground_truth": "16", "quality_analysis": {"complexity_score": 3, "left_complexity": 2, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_736", "reponame": "stellargraph", "testpath": "tests/layer/test_rgcn.py", "testname": "test_rgcn.py", "classname": null, "funcname": "test_RelationalGraphConvolution_init", "imports": ["import numpy as np", "from stellargraph.layer.rgcn import RelationalGraphConvolution, RGCN", "from stellargraph.mapper.full_batch_generators import RelationalFullBatchNodeGenerator", "import pytest", "from scipy import sparse as sps", "from stellargraph.core.utils import normalize_adj", "import tensorflow as tf", "from tensorflow import keras", "from tensorflow.keras import backend as K", "from tensorflow.keras.layers import Input, Lambda", "from stellargraph import StellarDiGraph, StellarGraph", "from stellargraph.layer.misc import SqueezedSparseConversion", "import pandas as pd", "from ..test_utils.graphs import relational_create_graph_features as create_graph_features", "from .. import test_utils"], "code": "def test_RelationalGraphConvolution_init():\n    rgcn_layer = RelationalGraphConvolution(units=16, num_relationships=5, num_bases=0, activation='relu')\n    assert (rgcn_layer.units == 16)\n    assert (rgcn_layer.use_bias is True)\n    assert (rgcn_layer.num_bases == 0)\n    assert (rgcn_layer.get_config()['activation'] == 'relu')\n    rgcn_layer = RelationalGraphConvolution(units=16, num_relationships=5, num_bases=10, activation='relu')\n    assert (rgcn_layer.units == 16)\n    assert (rgcn_layer.use_bias is True)\n    assert (rgcn_layer.num_bases == 10)\n    assert (rgcn_layer.get_config()['activation'] == 'relu')", "masked_code": "def test_RelationalGraphConvolution_init():\n    rgcn_layer = RelationalGraphConvolution(units=16, num_relationships=5, num_bases=0, activation='relu')\n    assert (rgcn_layer.units == 16)\n    assert (rgcn_layer.use_bias is True)\n    assert (rgcn_layer.num_bases == 0)\n    assert (rgcn_layer.get_config()['activation'] == 'relu')\n    rgcn_layer = RelationalGraphConvolution(units=16, num_relationships=5, num_bases=10, activation='relu')\n    assert (rgcn_layer.units == 16)\n    assert (rgcn_layer.use_bias is True)\n    assert (rgcn_layer.num_bases == '???')\n    assert (rgcn_layer.get_config()['activation'] == 'relu')", "ground_truth": "10", "quality_analysis": {"complexity_score": 3, "left_complexity": 2, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_737", "reponame": "stellargraph", "testpath": "tests/layer/test_rgcn.py", "testname": "test_rgcn.py", "classname": null, "funcname": "test_RelationalGraphConvolution_init", "imports": ["import numpy as np", "from stellargraph.layer.rgcn import RelationalGraphConvolution, RGCN", "from stellargraph.mapper.full_batch_generators import RelationalFullBatchNodeGenerator", "import pytest", "from scipy import sparse as sps", "from stellargraph.core.utils import normalize_adj", "import tensorflow as tf", "from tensorflow import keras", "from tensorflow.keras import backend as K", "from tensorflow.keras.layers import Input, Lambda", "from stellargraph import StellarDiGraph, StellarGraph", "from stellargraph.layer.misc import SqueezedSparseConversion", "import pandas as pd", "from ..test_utils.graphs import relational_create_graph_features as create_graph_features", "from .. import test_utils"], "code": "def test_RelationalGraphConvolution_init():\n    rgcn_layer = RelationalGraphConvolution(units=16, num_relationships=5, num_bases=0, activation='relu')\n    assert (rgcn_layer.units == 16)\n    assert (rgcn_layer.use_bias is True)\n    assert (rgcn_layer.num_bases == 0)\n    assert (rgcn_layer.get_config()['activation'] == 'relu')\n    rgcn_layer = RelationalGraphConvolution(units=16, num_relationships=5, num_bases=10, activation='relu')\n    assert (rgcn_layer.units == 16)\n    assert (rgcn_layer.use_bias is True)\n    assert (rgcn_layer.num_bases == 10)\n    assert (rgcn_layer.get_config()['activation'] == 'relu')", "masked_code": "def test_RelationalGraphConvolution_init():\n    rgcn_layer = RelationalGraphConvolution(units=16, num_relationships=5, num_bases=0, activation='relu')\n    assert (rgcn_layer.units == 16)\n    assert (rgcn_layer.use_bias is True)\n    assert (rgcn_layer.num_bases == 0)\n    assert (rgcn_layer.get_config()['activation'] == 'relu')\n    rgcn_layer = RelationalGraphConvolution(units=16, num_relationships=5, num_bases=10, activation='relu')\n    assert (rgcn_layer.units == 16)\n    assert (rgcn_layer.use_bias is True)\n    assert (rgcn_layer.num_bases == 10)\n    assert (rgcn_layer.get_config()['activation'] == '???')", "ground_truth": "'relu'", "quality_analysis": {"complexity_score": 8, "left_complexity": 7, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_738", "reponame": "stellargraph", "testpath": "tests/layer/test_rgcn.py", "testname": "test_rgcn.py", "classname": null, "funcname": "test_RelationalGraphConvolution_sparse", "imports": ["import numpy as np", "from stellargraph.layer.rgcn import RelationalGraphConvolution, RGCN", "from stellargraph.mapper.full_batch_generators import RelationalFullBatchNodeGenerator", "import pytest", "from scipy import sparse as sps", "from stellargraph.core.utils import normalize_adj", "import tensorflow as tf", "from tensorflow import keras", "from tensorflow.keras import backend as K", "from tensorflow.keras.layers import Input, Lambda", "from stellargraph import StellarDiGraph, StellarGraph", "from stellargraph.layer.misc import SqueezedSparseConversion", "import pandas as pd", "from ..test_utils.graphs import relational_create_graph_features as create_graph_features", "from .. import test_utils"], "code": "def test_RelationalGraphConvolution_sparse():\n    (G, features) = create_graph_features()\n    n_edge_types = len(G.edge_types)\n    n_nodes = features.shape[0]\n    n_feat = features.shape[1]\n    x_t = Input(batch_shape=(1, n_nodes, n_feat))\n    As_indices = [Input(batch_shape=(1, None, 2), dtype='int64') for i in range(n_edge_types)]\n    As_values = [Input(batch_shape=(1, None)) for i in range(n_edge_types)]\n    A_placeholders = (As_indices + As_values)\n    Ainput = [SqueezedSparseConversion(shape=(n_nodes, n_nodes), dtype=As_values[i].dtype)([As_indices[i], As_values[i]]) for i in range(n_edge_types)]\n    x_inp_model = ([x_t] + A_placeholders)\n    x_inp_conv = ([x_t] + Ainput)\n    out = RelationalGraphConvolution(2, num_relationships=n_edge_types)(x_inp_conv)\n    As = [A.tocoo() for A in get_As(G)]\n    A_indices = [np.expand_dims(np.hstack((A.row[(:, None)], A.col[(:, None)])).astype(np.int64), 0) for A in As]\n    A_values = [np.expand_dims(A.data, 0) for A in As]\n    out_indices = np.array([[0, 1]], dtype='int32')\n    x = features[(None, :, :)]\n    model = keras.Model(inputs=x_inp_model, outputs=out)\n    preds = model.predict((([x] + A_indices) + A_values), batch_size=1)\n    assert (preds.shape == (1, 3, 2))", "masked_code": "def test_RelationalGraphConvolution_sparse():\n    (G, features) = create_graph_features()\n    n_edge_types = len(G.edge_types)\n    n_nodes = features.shape[0]\n    n_feat = features.shape[1]\n    x_t = Input(batch_shape=(1, n_nodes, n_feat))\n    As_indices = [Input(batch_shape=(1, None, 2), dtype='int64') for i in range(n_edge_types)]\n    As_values = [Input(batch_shape=(1, None)) for i in range(n_edge_types)]\n    A_placeholders = (As_indices + As_values)\n    Ainput = [SqueezedSparseConversion(shape=(n_nodes, n_nodes), dtype=As_values[i].dtype)([As_indices[i], As_values[i]]) for i in range(n_edge_types)]\n    x_inp_model = ([x_t] + A_placeholders)\n    x_inp_conv = ([x_t] + Ainput)\n    out = RelationalGraphConvolution(2, num_relationships=n_edge_types)(x_inp_conv)\n    As = [A.tocoo() for A in get_As(G)]\n    A_indices = [np.expand_dims(np.hstack((A.row[(:, None)], A.col[(:, None)])).astype(np.int64), 0) for A in As]\n    A_values = [np.expand_dims(A.data, 0) for A in As]\n    out_indices = np.array([[0, 1]], dtype='int32')\n    x = features[(None, :, :)]\n    model = keras.Model(inputs=x_inp_model, outputs=out)\n    preds = model.predict((([x] + A_indices) + A_values), batch_size=1)\n    assert (preds.shape == '???')", "ground_truth": "(1, 3, 2)", "quality_analysis": {"complexity_score": 7, "left_complexity": 2, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_739", "reponame": "stellargraph", "testpath": "tests/layer/test_rgcn.py", "testname": "test_rgcn.py", "classname": null, "funcname": "test_RelationalGraphConvolution_dense", "imports": ["import numpy as np", "from stellargraph.layer.rgcn import RelationalGraphConvolution, RGCN", "from stellargraph.mapper.full_batch_generators import RelationalFullBatchNodeGenerator", "import pytest", "from scipy import sparse as sps", "from stellargraph.core.utils import normalize_adj", "import tensorflow as tf", "from tensorflow import keras", "from tensorflow.keras import backend as K", "from tensorflow.keras.layers import Input, Lambda", "from stellargraph import StellarDiGraph, StellarGraph", "from stellargraph.layer.misc import SqueezedSparseConversion", "import pandas as pd", "from ..test_utils.graphs import relational_create_graph_features as create_graph_features", "from .. import test_utils"], "code": "def test_RelationalGraphConvolution_dense():\n    (G, features) = create_graph_features()\n    n_edge_types = len(G.edge_types)\n    n_nodes = features.shape[0]\n    n_feat = features.shape[1]\n    x_t = Input(batch_shape=(1, n_nodes, n_feat))\n    out_indices_t = Input(batch_shape=(1, None), dtype='int32')\n    A_placeholders = [Input(batch_shape=(1, n_nodes, n_nodes)) for _ in range(n_edge_types)]\n    A_in = [Lambda((lambda A: K.squeeze(A, 0)))(A_p) for A_p in A_placeholders]\n    x_inp_model = ([x_t] + A_placeholders)\n    x_inp_conv = ([x_t] + A_in)\n    out = RelationalGraphConvolution(2, num_relationships=n_edge_types)(x_inp_conv)\n    As = [np.expand_dims(A.todense(), 0) for A in get_As(G)]\n    out_indices = np.array([[0, 1]], dtype='int32')\n    x = features[(None, :, :)]\n    model = keras.Model(inputs=x_inp_model, outputs=out)\n    preds = model.predict(([x] + As), batch_size=1)\n    assert (preds.shape == (1, 3, 2))", "masked_code": "def test_RelationalGraphConvolution_dense():\n    (G, features) = create_graph_features()\n    n_edge_types = len(G.edge_types)\n    n_nodes = features.shape[0]\n    n_feat = features.shape[1]\n    x_t = Input(batch_shape=(1, n_nodes, n_feat))\n    out_indices_t = Input(batch_shape=(1, None), dtype='int32')\n    A_placeholders = [Input(batch_shape=(1, n_nodes, n_nodes)) for _ in range(n_edge_types)]\n    A_in = [Lambda((lambda A: K.squeeze(A, 0)))(A_p) for A_p in A_placeholders]\n    x_inp_model = ([x_t] + A_placeholders)\n    x_inp_conv = ([x_t] + A_in)\n    out = RelationalGraphConvolution(2, num_relationships=n_edge_types)(x_inp_conv)\n    As = [np.expand_dims(A.todense(), 0) for A in get_As(G)]\n    out_indices = np.array([[0, 1]], dtype='int32')\n    x = features[(None, :, :)]\n    model = keras.Model(inputs=x_inp_model, outputs=out)\n    preds = model.predict(([x] + As), batch_size=1)\n    assert (preds.shape == '???')", "ground_truth": "(1, 3, 2)", "quality_analysis": {"complexity_score": 7, "left_complexity": 2, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_740", "reponame": "stellargraph", "testpath": "tests/layer/test_rgcn.py", "testname": "test_rgcn.py", "classname": null, "funcname": "test_RGCN_init", "imports": ["import numpy as np", "from stellargraph.layer.rgcn import RelationalGraphConvolution, RGCN", "from stellargraph.mapper.full_batch_generators import RelationalFullBatchNodeGenerator", "import pytest", "from scipy import sparse as sps", "from stellargraph.core.utils import normalize_adj", "import tensorflow as tf", "from tensorflow import keras", "from tensorflow.keras import backend as K", "from tensorflow.keras.layers import Input, Lambda", "from stellargraph import StellarDiGraph, StellarGraph", "from stellargraph.layer.misc import SqueezedSparseConversion", "import pandas as pd", "from ..test_utils.graphs import relational_create_graph_features as create_graph_features", "from .. import test_utils"], "code": "def test_RGCN_init():\n    (G, features) = create_graph_features()\n    generator = RelationalFullBatchNodeGenerator(G)\n    rgcnModel = RGCN([2], generator, num_bases=10, activations=['relu'], dropout=0.5)\n    assert (rgcnModel.layer_sizes == [2])\n    assert (rgcnModel.activations == ['relu'])\n    assert (rgcnModel.dropout == 0.5)\n    assert (rgcnModel.num_bases == 10)", "masked_code": "def test_RGCN_init():\n    (G, features) = create_graph_features()\n    generator = RelationalFullBatchNodeGenerator(G)\n    rgcnModel = RGCN([2], generator, num_bases=10, activations=['relu'], dropout=0.5)\n    assert (rgcnModel.layer_sizes == '???')\n    assert (rgcnModel.activations == ['relu'])\n    assert (rgcnModel.dropout == 0.5)\n    assert (rgcnModel.num_bases == 10)", "ground_truth": "[2]", "quality_analysis": {"complexity_score": 5, "left_complexity": 2, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_741", "reponame": "stellargraph", "testpath": "tests/layer/test_rgcn.py", "testname": "test_rgcn.py", "classname": null, "funcname": "test_RGCN_init", "imports": ["import numpy as np", "from stellargraph.layer.rgcn import RelationalGraphConvolution, RGCN", "from stellargraph.mapper.full_batch_generators import RelationalFullBatchNodeGenerator", "import pytest", "from scipy import sparse as sps", "from stellargraph.core.utils import normalize_adj", "import tensorflow as tf", "from tensorflow import keras", "from tensorflow.keras import backend as K", "from tensorflow.keras.layers import Input, Lambda", "from stellargraph import StellarDiGraph, StellarGraph", "from stellargraph.layer.misc import SqueezedSparseConversion", "import pandas as pd", "from ..test_utils.graphs import relational_create_graph_features as create_graph_features", "from .. import test_utils"], "code": "def test_RGCN_init():\n    (G, features) = create_graph_features()\n    generator = RelationalFullBatchNodeGenerator(G)\n    rgcnModel = RGCN([2], generator, num_bases=10, activations=['relu'], dropout=0.5)\n    assert (rgcnModel.layer_sizes == [2])\n    assert (rgcnModel.activations == ['relu'])\n    assert (rgcnModel.dropout == 0.5)\n    assert (rgcnModel.num_bases == 10)", "masked_code": "def test_RGCN_init():\n    (G, features) = create_graph_features()\n    generator = RelationalFullBatchNodeGenerator(G)\n    rgcnModel = RGCN([2], generator, num_bases=10, activations=['relu'], dropout=0.5)\n    assert (rgcnModel.layer_sizes == [2])\n    assert (rgcnModel.activations == '???')\n    assert (rgcnModel.dropout == 0.5)\n    assert (rgcnModel.num_bases == 10)", "ground_truth": "['relu']", "quality_analysis": {"complexity_score": 5, "left_complexity": 2, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_742", "reponame": "stellargraph", "testpath": "tests/layer/test_rgcn.py", "testname": "test_rgcn.py", "classname": null, "funcname": "test_RGCN_init", "imports": ["import numpy as np", "from stellargraph.layer.rgcn import RelationalGraphConvolution, RGCN", "from stellargraph.mapper.full_batch_generators import RelationalFullBatchNodeGenerator", "import pytest", "from scipy import sparse as sps", "from stellargraph.core.utils import normalize_adj", "import tensorflow as tf", "from tensorflow import keras", "from tensorflow.keras import backend as K", "from tensorflow.keras.layers import Input, Lambda", "from stellargraph import StellarDiGraph, StellarGraph", "from stellargraph.layer.misc import SqueezedSparseConversion", "import pandas as pd", "from ..test_utils.graphs import relational_create_graph_features as create_graph_features", "from .. import test_utils"], "code": "def test_RGCN_init():\n    (G, features) = create_graph_features()\n    generator = RelationalFullBatchNodeGenerator(G)\n    rgcnModel = RGCN([2], generator, num_bases=10, activations=['relu'], dropout=0.5)\n    assert (rgcnModel.layer_sizes == [2])\n    assert (rgcnModel.activations == ['relu'])\n    assert (rgcnModel.dropout == 0.5)\n    assert (rgcnModel.num_bases == 10)", "masked_code": "def test_RGCN_init():\n    (G, features) = create_graph_features()\n    generator = RelationalFullBatchNodeGenerator(G)\n    rgcnModel = RGCN([2], generator, num_bases=10, activations=['relu'], dropout=0.5)\n    assert (rgcnModel.layer_sizes == [2])\n    assert (rgcnModel.activations == ['relu'])\n    assert (rgcnModel.dropout == '???')\n    assert (rgcnModel.num_bases == 10)", "ground_truth": "0.5", "quality_analysis": {"complexity_score": 3, "left_complexity": 2, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_743", "reponame": "stellargraph", "testpath": "tests/layer/test_rgcn.py", "testname": "test_rgcn.py", "classname": null, "funcname": "test_RGCN_init", "imports": ["import numpy as np", "from stellargraph.layer.rgcn import RelationalGraphConvolution, RGCN", "from stellargraph.mapper.full_batch_generators import RelationalFullBatchNodeGenerator", "import pytest", "from scipy import sparse as sps", "from stellargraph.core.utils import normalize_adj", "import tensorflow as tf", "from tensorflow import keras", "from tensorflow.keras import backend as K", "from tensorflow.keras.layers import Input, Lambda", "from stellargraph import StellarDiGraph, StellarGraph", "from stellargraph.layer.misc import SqueezedSparseConversion", "import pandas as pd", "from ..test_utils.graphs import relational_create_graph_features as create_graph_features", "from .. import test_utils"], "code": "def test_RGCN_init():\n    (G, features) = create_graph_features()\n    generator = RelationalFullBatchNodeGenerator(G)\n    rgcnModel = RGCN([2], generator, num_bases=10, activations=['relu'], dropout=0.5)\n    assert (rgcnModel.layer_sizes == [2])\n    assert (rgcnModel.activations == ['relu'])\n    assert (rgcnModel.dropout == 0.5)\n    assert (rgcnModel.num_bases == 10)", "masked_code": "def test_RGCN_init():\n    (G, features) = create_graph_features()\n    generator = RelationalFullBatchNodeGenerator(G)\n    rgcnModel = RGCN([2], generator, num_bases=10, activations=['relu'], dropout=0.5)\n    assert (rgcnModel.layer_sizes == [2])\n    assert (rgcnModel.activations == ['relu'])\n    assert (rgcnModel.dropout == 0.5)\n    assert (rgcnModel.num_bases == '???')", "ground_truth": "10", "quality_analysis": {"complexity_score": 3, "left_complexity": 2, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_744", "reponame": "stellargraph", "testpath": "tests/layer/test_rgcn.py", "testname": "test_rgcn.py", "classname": null, "funcname": "test_RGCN_apply_sparse", "imports": ["import numpy as np", "from stellargraph.layer.rgcn import RelationalGraphConvolution, RGCN", "from stellargraph.mapper.full_batch_generators import RelationalFullBatchNodeGenerator", "import pytest", "from scipy import sparse as sps", "from stellargraph.core.utils import normalize_adj", "import tensorflow as tf", "from tensorflow import keras", "from tensorflow.keras import backend as K", "from tensorflow.keras.layers import Input, Lambda", "from stellargraph import StellarDiGraph, StellarGraph", "from stellargraph.layer.misc import SqueezedSparseConversion", "import pandas as pd", "from ..test_utils.graphs import relational_create_graph_features as create_graph_features", "from .. import test_utils"], "code": "def test_RGCN_apply_sparse():\n    (G, features) = create_graph_features(is_directed=True)\n    As = get_As(G)\n    As = [A.tocoo() for A in As]\n    A_indices = [np.expand_dims(np.hstack((A.row[(:, None)], A.col[(:, None)])).astype(np.int64), 0) for A in As]\n    A_values = [np.expand_dims(A.data, 0) for A in As]\n    generator = RelationalFullBatchNodeGenerator(G, sparse=True)\n    rgcnModel = RGCN([2], generator, num_bases=10, activations=['relu'], dropout=0.5)\n    (x_in, x_out) = rgcnModel.in_out_tensors()\n    model = keras.Model(inputs=x_in, outputs=x_out)\n    out_indices = np.array([[0, 1]], dtype='int32')\n    preds_1 = model.predict((([features[(None, :, :)], out_indices] + A_indices) + A_values))\n    assert (preds_1.shape == (1, 2, 2))\n    preds_2 = model.predict(generator.flow(['a', 'b']))\n    assert (preds_2.shape == (1, 2, 2))\n    assert (preds_1 == pytest.approx(preds_2))", "masked_code": "def test_RGCN_apply_sparse():\n    (G, features) = create_graph_features(is_directed=True)\n    As = get_As(G)\n    As = [A.tocoo() for A in As]\n    A_indices = [np.expand_dims(np.hstack((A.row[(:, None)], A.col[(:, None)])).astype(np.int64), 0) for A in As]\n    A_values = [np.expand_dims(A.data, 0) for A in As]\n    generator = RelationalFullBatchNodeGenerator(G, sparse=True)\n    rgcnModel = RGCN([2], generator, num_bases=10, activations=['relu'], dropout=0.5)\n    (x_in, x_out) = rgcnModel.in_out_tensors()\n    model = keras.Model(inputs=x_in, outputs=x_out)\n    out_indices = np.array([[0, 1]], dtype='int32')\n    preds_1 = model.predict((([features[(None, :, :)], out_indices] + A_indices) + A_values))\n    assert (preds_1.shape == '???')\n    preds_2 = model.predict(generator.flow(['a', 'b']))\n    assert (preds_2.shape == (1, 2, 2))\n    assert (preds_1 == pytest.approx(preds_2))", "ground_truth": "(1, 2, 2)", "quality_analysis": {"complexity_score": 7, "left_complexity": 2, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_745", "reponame": "stellargraph", "testpath": "tests/layer/test_rgcn.py", "testname": "test_rgcn.py", "classname": null, "funcname": "test_RGCN_apply_sparse", "imports": ["import numpy as np", "from stellargraph.layer.rgcn import RelationalGraphConvolution, RGCN", "from stellargraph.mapper.full_batch_generators import RelationalFullBatchNodeGenerator", "import pytest", "from scipy import sparse as sps", "from stellargraph.core.utils import normalize_adj", "import tensorflow as tf", "from tensorflow import keras", "from tensorflow.keras import backend as K", "from tensorflow.keras.layers import Input, Lambda", "from stellargraph import StellarDiGraph, StellarGraph", "from stellargraph.layer.misc import SqueezedSparseConversion", "import pandas as pd", "from ..test_utils.graphs import relational_create_graph_features as create_graph_features", "from .. import test_utils"], "code": "def test_RGCN_apply_sparse():\n    (G, features) = create_graph_features(is_directed=True)\n    As = get_As(G)\n    As = [A.tocoo() for A in As]\n    A_indices = [np.expand_dims(np.hstack((A.row[(:, None)], A.col[(:, None)])).astype(np.int64), 0) for A in As]\n    A_values = [np.expand_dims(A.data, 0) for A in As]\n    generator = RelationalFullBatchNodeGenerator(G, sparse=True)\n    rgcnModel = RGCN([2], generator, num_bases=10, activations=['relu'], dropout=0.5)\n    (x_in, x_out) = rgcnModel.in_out_tensors()\n    model = keras.Model(inputs=x_in, outputs=x_out)\n    out_indices = np.array([[0, 1]], dtype='int32')\n    preds_1 = model.predict((([features[(None, :, :)], out_indices] + A_indices) + A_values))\n    assert (preds_1.shape == (1, 2, 2))\n    preds_2 = model.predict(generator.flow(['a', 'b']))\n    assert (preds_2.shape == (1, 2, 2))\n    assert (preds_1 == pytest.approx(preds_2))", "masked_code": "def test_RGCN_apply_sparse():\n    (G, features) = create_graph_features(is_directed=True)\n    As = get_As(G)\n    As = [A.tocoo() for A in As]\n    A_indices = [np.expand_dims(np.hstack((A.row[(:, None)], A.col[(:, None)])).astype(np.int64), 0) for A in As]\n    A_values = [np.expand_dims(A.data, 0) for A in As]\n    generator = RelationalFullBatchNodeGenerator(G, sparse=True)\n    rgcnModel = RGCN([2], generator, num_bases=10, activations=['relu'], dropout=0.5)\n    (x_in, x_out) = rgcnModel.in_out_tensors()\n    model = keras.Model(inputs=x_in, outputs=x_out)\n    out_indices = np.array([[0, 1]], dtype='int32')\n    preds_1 = model.predict((([features[(None, :, :)], out_indices] + A_indices) + A_values))\n    assert (preds_1.shape == (1, 2, 2))\n    preds_2 = model.predict(generator.flow(['a', 'b']))\n    assert (preds_2.shape == '???')\n    assert (preds_1 == pytest.approx(preds_2))", "ground_truth": "(1, 2, 2)", "quality_analysis": {"complexity_score": 7, "left_complexity": 2, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_746", "reponame": "stellargraph", "testpath": "tests/layer/test_rgcn.py", "testname": "test_rgcn.py", "classname": null, "funcname": "test_RGCN_apply_dense", "imports": ["import numpy as np", "from stellargraph.layer.rgcn import RelationalGraphConvolution, RGCN", "from stellargraph.mapper.full_batch_generators import RelationalFullBatchNodeGenerator", "import pytest", "from scipy import sparse as sps", "from stellargraph.core.utils import normalize_adj", "import tensorflow as tf", "from tensorflow import keras", "from tensorflow.keras import backend as K", "from tensorflow.keras.layers import Input, Lambda", "from stellargraph import StellarDiGraph, StellarGraph", "from stellargraph.layer.misc import SqueezedSparseConversion", "import pandas as pd", "from ..test_utils.graphs import relational_create_graph_features as create_graph_features", "from .. import test_utils"], "code": "def test_RGCN_apply_dense():\n    (G, features) = create_graph_features(is_directed=True)\n    As = get_As(G)\n    As = [np.expand_dims(A.todense(), 0) for A in As]\n    generator = RelationalFullBatchNodeGenerator(G, sparse=False)\n    rgcnModel = RGCN([2], generator, num_bases=10, activations=['relu'], dropout=0.5)\n    (x_in, x_out) = rgcnModel.in_out_tensors()\n    model = keras.Model(inputs=x_in, outputs=x_out)\n    out_indices = np.array([[0, 1]], dtype='int32')\n    preds_1 = model.predict(([features[(None, :, :)], out_indices] + As))\n    assert (preds_1.shape == (1, 2, 2))\n    preds_2 = model.predict(generator.flow(['a', 'b']))\n    assert (preds_2.shape == (1, 2, 2))\n    assert (preds_1 == pytest.approx(preds_2))", "masked_code": "def test_RGCN_apply_dense():\n    (G, features) = create_graph_features(is_directed=True)\n    As = get_As(G)\n    As = [np.expand_dims(A.todense(), 0) for A in As]\n    generator = RelationalFullBatchNodeGenerator(G, sparse=False)\n    rgcnModel = RGCN([2], generator, num_bases=10, activations=['relu'], dropout=0.5)\n    (x_in, x_out) = rgcnModel.in_out_tensors()\n    model = keras.Model(inputs=x_in, outputs=x_out)\n    out_indices = np.array([[0, 1]], dtype='int32')\n    preds_1 = model.predict(([features[(None, :, :)], out_indices] + As))\n    assert (preds_1.shape == '???')\n    preds_2 = model.predict(generator.flow(['a', 'b']))\n    assert (preds_2.shape == (1, 2, 2))\n    assert (preds_1 == pytest.approx(preds_2))", "ground_truth": "(1, 2, 2)", "quality_analysis": {"complexity_score": 7, "left_complexity": 2, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_747", "reponame": "stellargraph", "testpath": "tests/layer/test_rgcn.py", "testname": "test_rgcn.py", "classname": null, "funcname": "test_RGCN_apply_dense", "imports": ["import numpy as np", "from stellargraph.layer.rgcn import RelationalGraphConvolution, RGCN", "from stellargraph.mapper.full_batch_generators import RelationalFullBatchNodeGenerator", "import pytest", "from scipy import sparse as sps", "from stellargraph.core.utils import normalize_adj", "import tensorflow as tf", "from tensorflow import keras", "from tensorflow.keras import backend as K", "from tensorflow.keras.layers import Input, Lambda", "from stellargraph import StellarDiGraph, StellarGraph", "from stellargraph.layer.misc import SqueezedSparseConversion", "import pandas as pd", "from ..test_utils.graphs import relational_create_graph_features as create_graph_features", "from .. import test_utils"], "code": "def test_RGCN_apply_dense():\n    (G, features) = create_graph_features(is_directed=True)\n    As = get_As(G)\n    As = [np.expand_dims(A.todense(), 0) for A in As]\n    generator = RelationalFullBatchNodeGenerator(G, sparse=False)\n    rgcnModel = RGCN([2], generator, num_bases=10, activations=['relu'], dropout=0.5)\n    (x_in, x_out) = rgcnModel.in_out_tensors()\n    model = keras.Model(inputs=x_in, outputs=x_out)\n    out_indices = np.array([[0, 1]], dtype='int32')\n    preds_1 = model.predict(([features[(None, :, :)], out_indices] + As))\n    assert (preds_1.shape == (1, 2, 2))\n    preds_2 = model.predict(generator.flow(['a', 'b']))\n    assert (preds_2.shape == (1, 2, 2))\n    assert (preds_1 == pytest.approx(preds_2))", "masked_code": "def test_RGCN_apply_dense():\n    (G, features) = create_graph_features(is_directed=True)\n    As = get_As(G)\n    As = [np.expand_dims(A.todense(), 0) for A in As]\n    generator = RelationalFullBatchNodeGenerator(G, sparse=False)\n    rgcnModel = RGCN([2], generator, num_bases=10, activations=['relu'], dropout=0.5)\n    (x_in, x_out) = rgcnModel.in_out_tensors()\n    model = keras.Model(inputs=x_in, outputs=x_out)\n    out_indices = np.array([[0, 1]], dtype='int32')\n    preds_1 = model.predict(([features[(None, :, :)], out_indices] + As))\n    assert (preds_1.shape == (1, 2, 2))\n    preds_2 = model.predict(generator.flow(['a', 'b']))\n    assert (preds_2.shape == '???')\n    assert (preds_1 == pytest.approx(preds_2))", "ground_truth": "(1, 2, 2)", "quality_analysis": {"complexity_score": 7, "left_complexity": 2, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_748", "reponame": "stellargraph", "testpath": "tests/layer/test_rgcn.py", "testname": "test_rgcn.py", "classname": null, "funcname": "test_RGCN_apply_sparse_directed", "imports": ["import numpy as np", "from stellargraph.layer.rgcn import RelationalGraphConvolution, RGCN", "from stellargraph.mapper.full_batch_generators import RelationalFullBatchNodeGenerator", "import pytest", "from scipy import sparse as sps", "from stellargraph.core.utils import normalize_adj", "import tensorflow as tf", "from tensorflow import keras", "from tensorflow.keras import backend as K", "from tensorflow.keras.layers import Input, Lambda", "from stellargraph import StellarDiGraph, StellarGraph", "from stellargraph.layer.misc import SqueezedSparseConversion", "import pandas as pd", "from ..test_utils.graphs import relational_create_graph_features as create_graph_features", "from .. import test_utils"], "code": "def test_RGCN_apply_sparse_directed():\n    (G, features) = create_graph_features(is_directed=True)\n    As = get_As(G)\n    As = [A.tocoo() for A in As]\n    A_indices = [np.expand_dims(np.hstack((A.row[(:, None)], A.col[(:, None)])).astype(np.int64), 0) for A in As]\n    A_values = [np.expand_dims(A.data, 0) for A in As]\n    generator = RelationalFullBatchNodeGenerator(G, sparse=True)\n    rgcnModel = RGCN([2], generator, num_bases=10, activations=['relu'], dropout=0.5)\n    (x_in, x_out) = rgcnModel.in_out_tensors()\n    model = keras.Model(inputs=x_in, outputs=x_out)\n    out_indices = np.array([[0, 1]], dtype='int32')\n    preds_1 = model.predict((([features[(None, :, :)], out_indices] + A_indices) + A_values))\n    assert (preds_1.shape == (1, 2, 2))\n    preds_2 = model.predict(generator.flow(['a', 'b']))\n    assert (preds_2.shape == (1, 2, 2))\n    assert (preds_1 == pytest.approx(preds_2))", "masked_code": "def test_RGCN_apply_sparse_directed():\n    (G, features) = create_graph_features(is_directed=True)\n    As = get_As(G)\n    As = [A.tocoo() for A in As]\n    A_indices = [np.expand_dims(np.hstack((A.row[(:, None)], A.col[(:, None)])).astype(np.int64), 0) for A in As]\n    A_values = [np.expand_dims(A.data, 0) for A in As]\n    generator = RelationalFullBatchNodeGenerator(G, sparse=True)\n    rgcnModel = RGCN([2], generator, num_bases=10, activations=['relu'], dropout=0.5)\n    (x_in, x_out) = rgcnModel.in_out_tensors()\n    model = keras.Model(inputs=x_in, outputs=x_out)\n    out_indices = np.array([[0, 1]], dtype='int32')\n    preds_1 = model.predict((([features[(None, :, :)], out_indices] + A_indices) + A_values))\n    assert (preds_1.shape == '???')\n    preds_2 = model.predict(generator.flow(['a', 'b']))\n    assert (preds_2.shape == (1, 2, 2))\n    assert (preds_1 == pytest.approx(preds_2))", "ground_truth": "(1, 2, 2)", "quality_analysis": {"complexity_score": 7, "left_complexity": 2, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_749", "reponame": "stellargraph", "testpath": "tests/layer/test_rgcn.py", "testname": "test_rgcn.py", "classname": null, "funcname": "test_RGCN_apply_sparse_directed", "imports": ["import numpy as np", "from stellargraph.layer.rgcn import RelationalGraphConvolution, RGCN", "from stellargraph.mapper.full_batch_generators import RelationalFullBatchNodeGenerator", "import pytest", "from scipy import sparse as sps", "from stellargraph.core.utils import normalize_adj", "import tensorflow as tf", "from tensorflow import keras", "from tensorflow.keras import backend as K", "from tensorflow.keras.layers import Input, Lambda", "from stellargraph import StellarDiGraph, StellarGraph", "from stellargraph.layer.misc import SqueezedSparseConversion", "import pandas as pd", "from ..test_utils.graphs import relational_create_graph_features as create_graph_features", "from .. import test_utils"], "code": "def test_RGCN_apply_sparse_directed():\n    (G, features) = create_graph_features(is_directed=True)\n    As = get_As(G)\n    As = [A.tocoo() for A in As]\n    A_indices = [np.expand_dims(np.hstack((A.row[(:, None)], A.col[(:, None)])).astype(np.int64), 0) for A in As]\n    A_values = [np.expand_dims(A.data, 0) for A in As]\n    generator = RelationalFullBatchNodeGenerator(G, sparse=True)\n    rgcnModel = RGCN([2], generator, num_bases=10, activations=['relu'], dropout=0.5)\n    (x_in, x_out) = rgcnModel.in_out_tensors()\n    model = keras.Model(inputs=x_in, outputs=x_out)\n    out_indices = np.array([[0, 1]], dtype='int32')\n    preds_1 = model.predict((([features[(None, :, :)], out_indices] + A_indices) + A_values))\n    assert (preds_1.shape == (1, 2, 2))\n    preds_2 = model.predict(generator.flow(['a', 'b']))\n    assert (preds_2.shape == (1, 2, 2))\n    assert (preds_1 == pytest.approx(preds_2))", "masked_code": "def test_RGCN_apply_sparse_directed():\n    (G, features) = create_graph_features(is_directed=True)\n    As = get_As(G)\n    As = [A.tocoo() for A in As]\n    A_indices = [np.expand_dims(np.hstack((A.row[(:, None)], A.col[(:, None)])).astype(np.int64), 0) for A in As]\n    A_values = [np.expand_dims(A.data, 0) for A in As]\n    generator = RelationalFullBatchNodeGenerator(G, sparse=True)\n    rgcnModel = RGCN([2], generator, num_bases=10, activations=['relu'], dropout=0.5)\n    (x_in, x_out) = rgcnModel.in_out_tensors()\n    model = keras.Model(inputs=x_in, outputs=x_out)\n    out_indices = np.array([[0, 1]], dtype='int32')\n    preds_1 = model.predict((([features[(None, :, :)], out_indices] + A_indices) + A_values))\n    assert (preds_1.shape == (1, 2, 2))\n    preds_2 = model.predict(generator.flow(['a', 'b']))\n    assert (preds_2.shape == '???')\n    assert (preds_1 == pytest.approx(preds_2))", "ground_truth": "(1, 2, 2)", "quality_analysis": {"complexity_score": 7, "left_complexity": 2, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_750", "reponame": "stellargraph", "testpath": "tests/layer/test_rgcn.py", "testname": "test_rgcn.py", "classname": null, "funcname": "test_RGCN_apply_dense_directed", "imports": ["import numpy as np", "from stellargraph.layer.rgcn import RelationalGraphConvolution, RGCN", "from stellargraph.mapper.full_batch_generators import RelationalFullBatchNodeGenerator", "import pytest", "from scipy import sparse as sps", "from stellargraph.core.utils import normalize_adj", "import tensorflow as tf", "from tensorflow import keras", "from tensorflow.keras import backend as K", "from tensorflow.keras.layers import Input, Lambda", "from stellargraph import StellarDiGraph, StellarGraph", "from stellargraph.layer.misc import SqueezedSparseConversion", "import pandas as pd", "from ..test_utils.graphs import relational_create_graph_features as create_graph_features", "from .. import test_utils"], "code": "def test_RGCN_apply_dense_directed():\n    (G, features) = create_graph_features(is_directed=True)\n    As = get_As(G)\n    As = [np.expand_dims(A.todense(), 0) for A in As]\n    generator = RelationalFullBatchNodeGenerator(G, sparse=False)\n    rgcnModel = RGCN([2], generator, num_bases=10, activations=['relu'], dropout=0.5)\n    (x_in, x_out) = rgcnModel.in_out_tensors()\n    model = keras.Model(inputs=x_in, outputs=x_out)\n    out_indices = np.array([[0, 1]], dtype='int32')\n    preds_1 = model.predict(([features[(None, :, :)], out_indices] + As))\n    assert (preds_1.shape == (1, 2, 2))\n    preds_2 = model.predict(generator.flow(['a', 'b']))\n    assert (preds_2.shape == (1, 2, 2))\n    assert (preds_1 == pytest.approx(preds_2))", "masked_code": "def test_RGCN_apply_dense_directed():\n    (G, features) = create_graph_features(is_directed=True)\n    As = get_As(G)\n    As = [np.expand_dims(A.todense(), 0) for A in As]\n    generator = RelationalFullBatchNodeGenerator(G, sparse=False)\n    rgcnModel = RGCN([2], generator, num_bases=10, activations=['relu'], dropout=0.5)\n    (x_in, x_out) = rgcnModel.in_out_tensors()\n    model = keras.Model(inputs=x_in, outputs=x_out)\n    out_indices = np.array([[0, 1]], dtype='int32')\n    preds_1 = model.predict(([features[(None, :, :)], out_indices] + As))\n    assert (preds_1.shape == '???')\n    preds_2 = model.predict(generator.flow(['a', 'b']))\n    assert (preds_2.shape == (1, 2, 2))\n    assert (preds_1 == pytest.approx(preds_2))", "ground_truth": "(1, 2, 2)", "quality_analysis": {"complexity_score": 7, "left_complexity": 2, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_751", "reponame": "stellargraph", "testpath": "tests/layer/test_rgcn.py", "testname": "test_rgcn.py", "classname": null, "funcname": "test_RGCN_apply_dense_directed", "imports": ["import numpy as np", "from stellargraph.layer.rgcn import RelationalGraphConvolution, RGCN", "from stellargraph.mapper.full_batch_generators import RelationalFullBatchNodeGenerator", "import pytest", "from scipy import sparse as sps", "from stellargraph.core.utils import normalize_adj", "import tensorflow as tf", "from tensorflow import keras", "from tensorflow.keras import backend as K", "from tensorflow.keras.layers import Input, Lambda", "from stellargraph import StellarDiGraph, StellarGraph", "from stellargraph.layer.misc import SqueezedSparseConversion", "import pandas as pd", "from ..test_utils.graphs import relational_create_graph_features as create_graph_features", "from .. import test_utils"], "code": "def test_RGCN_apply_dense_directed():\n    (G, features) = create_graph_features(is_directed=True)\n    As = get_As(G)\n    As = [np.expand_dims(A.todense(), 0) for A in As]\n    generator = RelationalFullBatchNodeGenerator(G, sparse=False)\n    rgcnModel = RGCN([2], generator, num_bases=10, activations=['relu'], dropout=0.5)\n    (x_in, x_out) = rgcnModel.in_out_tensors()\n    model = keras.Model(inputs=x_in, outputs=x_out)\n    out_indices = np.array([[0, 1]], dtype='int32')\n    preds_1 = model.predict(([features[(None, :, :)], out_indices] + As))\n    assert (preds_1.shape == (1, 2, 2))\n    preds_2 = model.predict(generator.flow(['a', 'b']))\n    assert (preds_2.shape == (1, 2, 2))\n    assert (preds_1 == pytest.approx(preds_2))", "masked_code": "def test_RGCN_apply_dense_directed():\n    (G, features) = create_graph_features(is_directed=True)\n    As = get_As(G)\n    As = [np.expand_dims(A.todense(), 0) for A in As]\n    generator = RelationalFullBatchNodeGenerator(G, sparse=False)\n    rgcnModel = RGCN([2], generator, num_bases=10, activations=['relu'], dropout=0.5)\n    (x_in, x_out) = rgcnModel.in_out_tensors()\n    model = keras.Model(inputs=x_in, outputs=x_out)\n    out_indices = np.array([[0, 1]], dtype='int32')\n    preds_1 = model.predict(([features[(None, :, :)], out_indices] + As))\n    assert (preds_1.shape == (1, 2, 2))\n    preds_2 = model.predict(generator.flow(['a', 'b']))\n    assert (preds_2.shape == '???')\n    assert (preds_1 == pytest.approx(preds_2))", "ground_truth": "(1, 2, 2)", "quality_analysis": {"complexity_score": 7, "left_complexity": 2, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_752", "reponame": "stellargraph", "testpath": "tests/layer/test_rgcn.py", "testname": "test_rgcn.py", "classname": null, "funcname": "test_RelationalGraphConvolution_edge_cases", "imports": ["import numpy as np", "from stellargraph.layer.rgcn import RelationalGraphConvolution, RGCN", "from stellargraph.mapper.full_batch_generators import RelationalFullBatchNodeGenerator", "import pytest", "from scipy import sparse as sps", "from stellargraph.core.utils import normalize_adj", "import tensorflow as tf", "from tensorflow import keras", "from tensorflow.keras import backend as K", "from tensorflow.keras.layers import Input, Lambda", "from stellargraph import StellarDiGraph, StellarGraph", "from stellargraph.layer.misc import SqueezedSparseConversion", "import pandas as pd", "from ..test_utils.graphs import relational_create_graph_features as create_graph_features", "from .. import test_utils"], "code": "def test_RelationalGraphConvolution_edge_cases():\n    try:\n        rgcn_layer = RelationalGraphConvolution(units=16, num_relationships=5, num_bases=0.5, activation='relu')\n    except TypeError as e:\n        error = e\n    assert (str(error) == 'num_bases should be an int')\n    rgcn_layer = RelationalGraphConvolution(units=16, num_relationships=5, num_bases=(- 1), activation='relu')\n    rgcn_layer.build(input_shapes=[(1,)])\n    assert (rgcn_layer.bases is None)\n    try:\n        rgcn_layer = RelationalGraphConvolution(units=16, num_relationships=0.5, num_bases=2, activation='relu')\n    except TypeError as e:\n        error = e\n    assert (str(error) == 'num_relationships should be an int')\n    try:\n        rgcn_layer = RelationalGraphConvolution(units=16, num_relationships=(- 1), num_bases=2, activation='relu')\n    except ValueError as e:\n        error = e\n    assert (str(error) == 'num_relationships should be positive')\n    try:\n        rgcn_layer = RelationalGraphConvolution(units=0.5, num_relationships=1, num_bases=2, activation='relu')\n    except TypeError as e:\n        error = e\n    assert (str(error) == 'units should be an int')\n    try:\n        rgcn_layer = RelationalGraphConvolution(units=(- 16), num_relationships=1, num_bases=2, activation='relu')\n    except ValueError as e:\n        error = e\n    assert (str(error) == 'units should be positive')", "masked_code": "def test_RelationalGraphConvolution_edge_cases():\n    try:\n        rgcn_layer = RelationalGraphConvolution(units=16, num_relationships=5, num_bases=0.5, activation='relu')\n    except TypeError as e:\n        error = e\n    assert (str(error) == '???')\n    rgcn_layer = RelationalGraphConvolution(units=16, num_relationships=5, num_bases=(- 1), activation='relu')\n    rgcn_layer.build(input_shapes=[(1,)])\n    assert (rgcn_layer.bases is None)\n    try:\n        rgcn_layer = RelationalGraphConvolution(units=16, num_relationships=0.5, num_bases=2, activation='relu')\n    except TypeError as e:\n        error = e\n    assert (str(error) == 'num_relationships should be an int')\n    try:\n        rgcn_layer = RelationalGraphConvolution(units=16, num_relationships=(- 1), num_bases=2, activation='relu')\n    except ValueError as e:\n        error = e\n    assert (str(error) == 'num_relationships should be positive')\n    try:\n        rgcn_layer = RelationalGraphConvolution(units=0.5, num_relationships=1, num_bases=2, activation='relu')\n    except TypeError as e:\n        error = e\n    assert (str(error) == 'units should be an int')\n    try:\n        rgcn_layer = RelationalGraphConvolution(units=(- 16), num_relationships=1, num_bases=2, activation='relu')\n    except ValueError as e:\n        error = e\n    assert (str(error) == 'units should be positive')", "ground_truth": "'num_bases should be an int'", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_753", "reponame": "stellargraph", "testpath": "tests/layer/test_rgcn.py", "testname": "test_rgcn.py", "classname": null, "funcname": "test_RelationalGraphConvolution_edge_cases", "imports": ["import numpy as np", "from stellargraph.layer.rgcn import RelationalGraphConvolution, RGCN", "from stellargraph.mapper.full_batch_generators import RelationalFullBatchNodeGenerator", "import pytest", "from scipy import sparse as sps", "from stellargraph.core.utils import normalize_adj", "import tensorflow as tf", "from tensorflow import keras", "from tensorflow.keras import backend as K", "from tensorflow.keras.layers import Input, Lambda", "from stellargraph import StellarDiGraph, StellarGraph", "from stellargraph.layer.misc import SqueezedSparseConversion", "import pandas as pd", "from ..test_utils.graphs import relational_create_graph_features as create_graph_features", "from .. import test_utils"], "code": "def test_RelationalGraphConvolution_edge_cases():\n    try:\n        rgcn_layer = RelationalGraphConvolution(units=16, num_relationships=5, num_bases=0.5, activation='relu')\n    except TypeError as e:\n        error = e\n    assert (str(error) == 'num_bases should be an int')\n    rgcn_layer = RelationalGraphConvolution(units=16, num_relationships=5, num_bases=(- 1), activation='relu')\n    rgcn_layer.build(input_shapes=[(1,)])\n    assert (rgcn_layer.bases is None)\n    try:\n        rgcn_layer = RelationalGraphConvolution(units=16, num_relationships=0.5, num_bases=2, activation='relu')\n    except TypeError as e:\n        error = e\n    assert (str(error) == 'num_relationships should be an int')\n    try:\n        rgcn_layer = RelationalGraphConvolution(units=16, num_relationships=(- 1), num_bases=2, activation='relu')\n    except ValueError as e:\n        error = e\n    assert (str(error) == 'num_relationships should be positive')\n    try:\n        rgcn_layer = RelationalGraphConvolution(units=0.5, num_relationships=1, num_bases=2, activation='relu')\n    except TypeError as e:\n        error = e\n    assert (str(error) == 'units should be an int')\n    try:\n        rgcn_layer = RelationalGraphConvolution(units=(- 16), num_relationships=1, num_bases=2, activation='relu')\n    except ValueError as e:\n        error = e\n    assert (str(error) == 'units should be positive')", "masked_code": "def test_RelationalGraphConvolution_edge_cases():\n    try:\n        rgcn_layer = RelationalGraphConvolution(units=16, num_relationships=5, num_bases=0.5, activation='relu')\n    except TypeError as e:\n        error = e\n    assert (str(error) == 'num_bases should be an int')\n    rgcn_layer = RelationalGraphConvolution(units=16, num_relationships=5, num_bases=(- 1), activation='relu')\n    rgcn_layer.build(input_shapes=[(1,)])\n    assert (rgcn_layer.bases is None)\n    try:\n        rgcn_layer = RelationalGraphConvolution(units=16, num_relationships=0.5, num_bases=2, activation='relu')\n    except TypeError as e:\n        error = e\n    assert (str(error) == '???')\n    try:\n        rgcn_layer = RelationalGraphConvolution(units=16, num_relationships=(- 1), num_bases=2, activation='relu')\n    except ValueError as e:\n        error = e\n    assert (str(error) == 'num_relationships should be positive')\n    try:\n        rgcn_layer = RelationalGraphConvolution(units=0.5, num_relationships=1, num_bases=2, activation='relu')\n    except TypeError as e:\n        error = e\n    assert (str(error) == 'units should be an int')\n    try:\n        rgcn_layer = RelationalGraphConvolution(units=(- 16), num_relationships=1, num_bases=2, activation='relu')\n    except ValueError as e:\n        error = e\n    assert (str(error) == 'units should be positive')", "ground_truth": "'num_relationships should be an int'", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_754", "reponame": "stellargraph", "testpath": "tests/layer/test_rgcn.py", "testname": "test_rgcn.py", "classname": null, "funcname": "test_RelationalGraphConvolution_edge_cases", "imports": ["import numpy as np", "from stellargraph.layer.rgcn import RelationalGraphConvolution, RGCN", "from stellargraph.mapper.full_batch_generators import RelationalFullBatchNodeGenerator", "import pytest", "from scipy import sparse as sps", "from stellargraph.core.utils import normalize_adj", "import tensorflow as tf", "from tensorflow import keras", "from tensorflow.keras import backend as K", "from tensorflow.keras.layers import Input, Lambda", "from stellargraph import StellarDiGraph, StellarGraph", "from stellargraph.layer.misc import SqueezedSparseConversion", "import pandas as pd", "from ..test_utils.graphs import relational_create_graph_features as create_graph_features", "from .. import test_utils"], "code": "def test_RelationalGraphConvolution_edge_cases():\n    try:\n        rgcn_layer = RelationalGraphConvolution(units=16, num_relationships=5, num_bases=0.5, activation='relu')\n    except TypeError as e:\n        error = e\n    assert (str(error) == 'num_bases should be an int')\n    rgcn_layer = RelationalGraphConvolution(units=16, num_relationships=5, num_bases=(- 1), activation='relu')\n    rgcn_layer.build(input_shapes=[(1,)])\n    assert (rgcn_layer.bases is None)\n    try:\n        rgcn_layer = RelationalGraphConvolution(units=16, num_relationships=0.5, num_bases=2, activation='relu')\n    except TypeError as e:\n        error = e\n    assert (str(error) == 'num_relationships should be an int')\n    try:\n        rgcn_layer = RelationalGraphConvolution(units=16, num_relationships=(- 1), num_bases=2, activation='relu')\n    except ValueError as e:\n        error = e\n    assert (str(error) == 'num_relationships should be positive')\n    try:\n        rgcn_layer = RelationalGraphConvolution(units=0.5, num_relationships=1, num_bases=2, activation='relu')\n    except TypeError as e:\n        error = e\n    assert (str(error) == 'units should be an int')\n    try:\n        rgcn_layer = RelationalGraphConvolution(units=(- 16), num_relationships=1, num_bases=2, activation='relu')\n    except ValueError as e:\n        error = e\n    assert (str(error) == 'units should be positive')", "masked_code": "def test_RelationalGraphConvolution_edge_cases():\n    try:\n        rgcn_layer = RelationalGraphConvolution(units=16, num_relationships=5, num_bases=0.5, activation='relu')\n    except TypeError as e:\n        error = e\n    assert (str(error) == 'num_bases should be an int')\n    rgcn_layer = RelationalGraphConvolution(units=16, num_relationships=5, num_bases=(- 1), activation='relu')\n    rgcn_layer.build(input_shapes=[(1,)])\n    assert (rgcn_layer.bases is None)\n    try:\n        rgcn_layer = RelationalGraphConvolution(units=16, num_relationships=0.5, num_bases=2, activation='relu')\n    except TypeError as e:\n        error = e\n    assert (str(error) == 'num_relationships should be an int')\n    try:\n        rgcn_layer = RelationalGraphConvolution(units=16, num_relationships=(- 1), num_bases=2, activation='relu')\n    except ValueError as e:\n        error = e\n    assert (str(error) == '???')\n    try:\n        rgcn_layer = RelationalGraphConvolution(units=0.5, num_relationships=1, num_bases=2, activation='relu')\n    except TypeError as e:\n        error = e\n    assert (str(error) == 'units should be an int')\n    try:\n        rgcn_layer = RelationalGraphConvolution(units=(- 16), num_relationships=1, num_bases=2, activation='relu')\n    except ValueError as e:\n        error = e\n    assert (str(error) == 'units should be positive')", "ground_truth": "'num_relationships should be positive'", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_755", "reponame": "stellargraph", "testpath": "tests/layer/test_rgcn.py", "testname": "test_rgcn.py", "classname": null, "funcname": "test_RelationalGraphConvolution_edge_cases", "imports": ["import numpy as np", "from stellargraph.layer.rgcn import RelationalGraphConvolution, RGCN", "from stellargraph.mapper.full_batch_generators import RelationalFullBatchNodeGenerator", "import pytest", "from scipy import sparse as sps", "from stellargraph.core.utils import normalize_adj", "import tensorflow as tf", "from tensorflow import keras", "from tensorflow.keras import backend as K", "from tensorflow.keras.layers import Input, Lambda", "from stellargraph import StellarDiGraph, StellarGraph", "from stellargraph.layer.misc import SqueezedSparseConversion", "import pandas as pd", "from ..test_utils.graphs import relational_create_graph_features as create_graph_features", "from .. import test_utils"], "code": "def test_RelationalGraphConvolution_edge_cases():\n    try:\n        rgcn_layer = RelationalGraphConvolution(units=16, num_relationships=5, num_bases=0.5, activation='relu')\n    except TypeError as e:\n        error = e\n    assert (str(error) == 'num_bases should be an int')\n    rgcn_layer = RelationalGraphConvolution(units=16, num_relationships=5, num_bases=(- 1), activation='relu')\n    rgcn_layer.build(input_shapes=[(1,)])\n    assert (rgcn_layer.bases is None)\n    try:\n        rgcn_layer = RelationalGraphConvolution(units=16, num_relationships=0.5, num_bases=2, activation='relu')\n    except TypeError as e:\n        error = e\n    assert (str(error) == 'num_relationships should be an int')\n    try:\n        rgcn_layer = RelationalGraphConvolution(units=16, num_relationships=(- 1), num_bases=2, activation='relu')\n    except ValueError as e:\n        error = e\n    assert (str(error) == 'num_relationships should be positive')\n    try:\n        rgcn_layer = RelationalGraphConvolution(units=0.5, num_relationships=1, num_bases=2, activation='relu')\n    except TypeError as e:\n        error = e\n    assert (str(error) == 'units should be an int')\n    try:\n        rgcn_layer = RelationalGraphConvolution(units=(- 16), num_relationships=1, num_bases=2, activation='relu')\n    except ValueError as e:\n        error = e\n    assert (str(error) == 'units should be positive')", "masked_code": "def test_RelationalGraphConvolution_edge_cases():\n    try:\n        rgcn_layer = RelationalGraphConvolution(units=16, num_relationships=5, num_bases=0.5, activation='relu')\n    except TypeError as e:\n        error = e\n    assert (str(error) == 'num_bases should be an int')\n    rgcn_layer = RelationalGraphConvolution(units=16, num_relationships=5, num_bases=(- 1), activation='relu')\n    rgcn_layer.build(input_shapes=[(1,)])\n    assert (rgcn_layer.bases is None)\n    try:\n        rgcn_layer = RelationalGraphConvolution(units=16, num_relationships=0.5, num_bases=2, activation='relu')\n    except TypeError as e:\n        error = e\n    assert (str(error) == 'num_relationships should be an int')\n    try:\n        rgcn_layer = RelationalGraphConvolution(units=16, num_relationships=(- 1), num_bases=2, activation='relu')\n    except ValueError as e:\n        error = e\n    assert (str(error) == 'num_relationships should be positive')\n    try:\n        rgcn_layer = RelationalGraphConvolution(units=0.5, num_relationships=1, num_bases=2, activation='relu')\n    except TypeError as e:\n        error = e\n    assert (str(error) == '???')\n    try:\n        rgcn_layer = RelationalGraphConvolution(units=(- 16), num_relationships=1, num_bases=2, activation='relu')\n    except ValueError as e:\n        error = e\n    assert (str(error) == 'units should be positive')", "ground_truth": "'units should be an int'", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_756", "reponame": "stellargraph", "testpath": "tests/layer/test_rgcn.py", "testname": "test_rgcn.py", "classname": null, "funcname": "test_RelationalGraphConvolution_edge_cases", "imports": ["import numpy as np", "from stellargraph.layer.rgcn import RelationalGraphConvolution, RGCN", "from stellargraph.mapper.full_batch_generators import RelationalFullBatchNodeGenerator", "import pytest", "from scipy import sparse as sps", "from stellargraph.core.utils import normalize_adj", "import tensorflow as tf", "from tensorflow import keras", "from tensorflow.keras import backend as K", "from tensorflow.keras.layers import Input, Lambda", "from stellargraph import StellarDiGraph, StellarGraph", "from stellargraph.layer.misc import SqueezedSparseConversion", "import pandas as pd", "from ..test_utils.graphs import relational_create_graph_features as create_graph_features", "from .. import test_utils"], "code": "def test_RelationalGraphConvolution_edge_cases():\n    try:\n        rgcn_layer = RelationalGraphConvolution(units=16, num_relationships=5, num_bases=0.5, activation='relu')\n    except TypeError as e:\n        error = e\n    assert (str(error) == 'num_bases should be an int')\n    rgcn_layer = RelationalGraphConvolution(units=16, num_relationships=5, num_bases=(- 1), activation='relu')\n    rgcn_layer.build(input_shapes=[(1,)])\n    assert (rgcn_layer.bases is None)\n    try:\n        rgcn_layer = RelationalGraphConvolution(units=16, num_relationships=0.5, num_bases=2, activation='relu')\n    except TypeError as e:\n        error = e\n    assert (str(error) == 'num_relationships should be an int')\n    try:\n        rgcn_layer = RelationalGraphConvolution(units=16, num_relationships=(- 1), num_bases=2, activation='relu')\n    except ValueError as e:\n        error = e\n    assert (str(error) == 'num_relationships should be positive')\n    try:\n        rgcn_layer = RelationalGraphConvolution(units=0.5, num_relationships=1, num_bases=2, activation='relu')\n    except TypeError as e:\n        error = e\n    assert (str(error) == 'units should be an int')\n    try:\n        rgcn_layer = RelationalGraphConvolution(units=(- 16), num_relationships=1, num_bases=2, activation='relu')\n    except ValueError as e:\n        error = e\n    assert (str(error) == 'units should be positive')", "masked_code": "def test_RelationalGraphConvolution_edge_cases():\n    try:\n        rgcn_layer = RelationalGraphConvolution(units=16, num_relationships=5, num_bases=0.5, activation='relu')\n    except TypeError as e:\n        error = e\n    assert (str(error) == 'num_bases should be an int')\n    rgcn_layer = RelationalGraphConvolution(units=16, num_relationships=5, num_bases=(- 1), activation='relu')\n    rgcn_layer.build(input_shapes=[(1,)])\n    assert (rgcn_layer.bases is None)\n    try:\n        rgcn_layer = RelationalGraphConvolution(units=16, num_relationships=0.5, num_bases=2, activation='relu')\n    except TypeError as e:\n        error = e\n    assert (str(error) == 'num_relationships should be an int')\n    try:\n        rgcn_layer = RelationalGraphConvolution(units=16, num_relationships=(- 1), num_bases=2, activation='relu')\n    except ValueError as e:\n        error = e\n    assert (str(error) == 'num_relationships should be positive')\n    try:\n        rgcn_layer = RelationalGraphConvolution(units=0.5, num_relationships=1, num_bases=2, activation='relu')\n    except TypeError as e:\n        error = e\n    assert (str(error) == 'units should be an int')\n    try:\n        rgcn_layer = RelationalGraphConvolution(units=(- 16), num_relationships=1, num_bases=2, activation='relu')\n    except ValueError as e:\n        error = e\n    assert (str(error) == '???')", "ground_truth": "'units should be positive'", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_757", "reponame": "stellargraph", "testpath": "tests/layer/test_watch_your_step.py", "testname": "test_watch_your_step.py", "classname": null, "funcname": "test_AttentiveWalk_config", "imports": ["from stellargraph.layer import AttentiveWalk, WatchYourStep", "import numpy as np", "from ..test_utils.graphs import barbell", "from stellargraph.mapper import AdjacencyPowerGenerator", "from stellargraph.losses import graph_log_likelihood", "import pytest", "from tensorflow.keras import Model", "from .. import test_utils"], "code": "def test_AttentiveWalk_config():\n    att_wlk = AttentiveWalk(walk_length=10)\n    conf = att_wlk.get_config()\n    assert (conf['walk_length'] == 10)\n    assert (conf['attention_initializer']['class_name'] == 'GlorotUniform')\n    assert (conf['attention_regularizer'] is None)\n    assert (conf['attention_constraint'] is None)", "masked_code": "def test_AttentiveWalk_config():\n    att_wlk = AttentiveWalk(walk_length=10)\n    conf = att_wlk.get_config()\n    assert (conf['walk_length'] == '???')\n    assert (conf['attention_initializer']['class_name'] == 'GlorotUniform')\n    assert (conf['attention_regularizer'] is None)\n    assert (conf['attention_constraint'] is None)", "ground_truth": "10", "quality_analysis": {"complexity_score": 6, "left_complexity": 5, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_758", "reponame": "stellargraph", "testpath": "tests/layer/test_watch_your_step.py", "testname": "test_watch_your_step.py", "classname": null, "funcname": "test_AttentiveWalk_config", "imports": ["from stellargraph.layer import AttentiveWalk, WatchYourStep", "import numpy as np", "from ..test_utils.graphs import barbell", "from stellargraph.mapper import AdjacencyPowerGenerator", "from stellargraph.losses import graph_log_likelihood", "import pytest", "from tensorflow.keras import Model", "from .. import test_utils"], "code": "def test_AttentiveWalk_config():\n    att_wlk = AttentiveWalk(walk_length=10)\n    conf = att_wlk.get_config()\n    assert (conf['walk_length'] == 10)\n    assert (conf['attention_initializer']['class_name'] == 'GlorotUniform')\n    assert (conf['attention_regularizer'] is None)\n    assert (conf['attention_constraint'] is None)", "masked_code": "def test_AttentiveWalk_config():\n    att_wlk = AttentiveWalk(walk_length=10)\n    conf = att_wlk.get_config()\n    assert (conf['walk_length'] == 10)\n    assert (conf['attention_initializer']['class_name'] == '???')\n    assert (conf['attention_regularizer'] is None)\n    assert (conf['attention_constraint'] is None)", "ground_truth": "'GlorotUniform'", "quality_analysis": {"complexity_score": 10, "left_complexity": 9, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_759", "reponame": "stellargraph", "testpath": "tests/layer/test_watch_your_step.py", "testname": "test_watch_your_step.py", "classname": null, "funcname": "test_WatchYourStep_init", "imports": ["from stellargraph.layer import AttentiveWalk, WatchYourStep", "import numpy as np", "from ..test_utils.graphs import barbell", "from stellargraph.mapper import AdjacencyPowerGenerator", "from stellargraph.losses import graph_log_likelihood", "import pytest", "from tensorflow.keras import Model", "from .. import test_utils"], "code": "def test_WatchYourStep_init(barbell):\n    generator = AdjacencyPowerGenerator(barbell, num_powers=5)\n    wys = WatchYourStep(generator)\n    assert (wys.num_powers == 5)\n    assert (wys.n_nodes == len(barbell.nodes()))\n    assert (wys.num_walks == 80)\n    assert (wys.embedding_dimension == 64)", "masked_code": "def test_WatchYourStep_init(barbell):\n    generator = AdjacencyPowerGenerator(barbell, num_powers=5)\n    wys = WatchYourStep(generator)\n    assert (wys.num_powers == '???')\n    assert (wys.n_nodes == len(barbell.nodes()))\n    assert (wys.num_walks == 80)\n    assert (wys.embedding_dimension == 64)", "ground_truth": "5", "quality_analysis": {"complexity_score": 3, "left_complexity": 2, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_760", "reponame": "stellargraph", "testpath": "tests/layer/test_watch_your_step.py", "testname": "test_watch_your_step.py", "classname": null, "funcname": "test_WatchYourStep_init", "imports": ["from stellargraph.layer import AttentiveWalk, WatchYourStep", "import numpy as np", "from ..test_utils.graphs import barbell", "from stellargraph.mapper import AdjacencyPowerGenerator", "from stellargraph.losses import graph_log_likelihood", "import pytest", "from tensorflow.keras import Model", "from .. import test_utils"], "code": "def test_WatchYourStep_init(barbell):\n    generator = AdjacencyPowerGenerator(barbell, num_powers=5)\n    wys = WatchYourStep(generator)\n    assert (wys.num_powers == 5)\n    assert (wys.n_nodes == len(barbell.nodes()))\n    assert (wys.num_walks == 80)\n    assert (wys.embedding_dimension == 64)", "masked_code": "def test_WatchYourStep_init(barbell):\n    generator = AdjacencyPowerGenerator(barbell, num_powers=5)\n    wys = WatchYourStep(generator)\n    assert (wys.num_powers == 5)\n    assert (wys.n_nodes == '???')\n    assert (wys.num_walks == 80)\n    assert (wys.embedding_dimension == 64)", "ground_truth": "len(barbell.nodes())", "quality_analysis": {"complexity_score": 8, "left_complexity": 2, "right_complexity": 6, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_761", "reponame": "stellargraph", "testpath": "tests/layer/test_watch_your_step.py", "testname": "test_watch_your_step.py", "classname": null, "funcname": "test_WatchYourStep_init", "imports": ["from stellargraph.layer import AttentiveWalk, WatchYourStep", "import numpy as np", "from ..test_utils.graphs import barbell", "from stellargraph.mapper import AdjacencyPowerGenerator", "from stellargraph.losses import graph_log_likelihood", "import pytest", "from tensorflow.keras import Model", "from .. import test_utils"], "code": "def test_WatchYourStep_init(barbell):\n    generator = AdjacencyPowerGenerator(barbell, num_powers=5)\n    wys = WatchYourStep(generator)\n    assert (wys.num_powers == 5)\n    assert (wys.n_nodes == len(barbell.nodes()))\n    assert (wys.num_walks == 80)\n    assert (wys.embedding_dimension == 64)", "masked_code": "def test_WatchYourStep_init(barbell):\n    generator = AdjacencyPowerGenerator(barbell, num_powers=5)\n    wys = WatchYourStep(generator)\n    assert (wys.num_powers == 5)\n    assert (wys.n_nodes == len(barbell.nodes()))\n    assert (wys.num_walks == '???')\n    assert (wys.embedding_dimension == 64)", "ground_truth": "80", "quality_analysis": {"complexity_score": 3, "left_complexity": 2, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_762", "reponame": "stellargraph", "testpath": "tests/layer/test_watch_your_step.py", "testname": "test_watch_your_step.py", "classname": null, "funcname": "test_WatchYourStep_init", "imports": ["from stellargraph.layer import AttentiveWalk, WatchYourStep", "import numpy as np", "from ..test_utils.graphs import barbell", "from stellargraph.mapper import AdjacencyPowerGenerator", "from stellargraph.losses import graph_log_likelihood", "import pytest", "from tensorflow.keras import Model", "from .. import test_utils"], "code": "def test_WatchYourStep_init(barbell):\n    generator = AdjacencyPowerGenerator(barbell, num_powers=5)\n    wys = WatchYourStep(generator)\n    assert (wys.num_powers == 5)\n    assert (wys.n_nodes == len(barbell.nodes()))\n    assert (wys.num_walks == 80)\n    assert (wys.embedding_dimension == 64)", "masked_code": "def test_WatchYourStep_init(barbell):\n    generator = AdjacencyPowerGenerator(barbell, num_powers=5)\n    wys = WatchYourStep(generator)\n    assert (wys.num_powers == 5)\n    assert (wys.n_nodes == len(barbell.nodes()))\n    assert (wys.num_walks == 80)\n    assert (wys.embedding_dimension == '???')", "ground_truth": "64", "quality_analysis": {"complexity_score": 3, "left_complexity": 2, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_763", "reponame": "stellargraph", "testpath": "tests/layer/test_watch_your_step.py", "testname": "test_watch_your_step.py", "classname": null, "funcname": "test_WatchYourStep", "imports": ["from stellargraph.layer import AttentiveWalk, WatchYourStep", "import numpy as np", "from ..test_utils.graphs import barbell", "from stellargraph.mapper import AdjacencyPowerGenerator", "from stellargraph.losses import graph_log_likelihood", "import pytest", "from tensorflow.keras import Model", "from .. import test_utils"], "code": "@pytest.mark.parametrize('weighted', [False, True])\ndef test_WatchYourStep(barbell, weighted):\n    generator = AdjacencyPowerGenerator(barbell, num_powers=5, weighted=weighted)\n    gen = generator.flow(batch_size=4)\n    wys = WatchYourStep(generator)\n    (x_in, x_out) = wys.in_out_tensors()\n    model = Model(inputs=x_in, outputs=x_out)\n    model.compile(optimizer='adam', loss=graph_log_likelihood)\n    model.fit(gen, epochs=1, steps_per_epoch=int((len(barbell.nodes()) // 4)))\n    embs = wys.embeddings()\n    assert (embs.shape == (len(barbell.nodes()), wys.embedding_dimension))\n    preds1 = model.predict(gen, steps=8)\n    preds2 = Model(*wys.in_out_tensors()).predict(gen, steps=8)\n    np.testing.assert_array_equal(preds1, preds2)", "masked_code": "@pytest.mark.parametrize('weighted', [False, True])\ndef test_WatchYourStep(barbell, weighted):\n    generator = AdjacencyPowerGenerator(barbell, num_powers=5, weighted=weighted)\n    gen = generator.flow(batch_size=4)\n    wys = WatchYourStep(generator)\n    (x_in, x_out) = wys.in_out_tensors()\n    model = Model(inputs=x_in, outputs=x_out)\n    model.compile(optimizer='adam', loss=graph_log_likelihood)\n    model.fit(gen, epochs=1, steps_per_epoch=int((len(barbell.nodes()) // 4)))\n    embs = wys.embeddings()\n    assert (embs.shape == '???')\n    preds1 = model.predict(gen, steps=8)\n    preds2 = Model(*wys.in_out_tensors()).predict(gen, steps=8)\n    np.testing.assert_array_equal(preds1, preds2)", "ground_truth": "(len(barbell.nodes()), wys.embedding_dimension)", "quality_analysis": {"complexity_score": 12, "left_complexity": 2, "right_complexity": 10, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_764", "reponame": "stellargraph", "testpath": "tests/mapper/test_adjacency_generators.py", "testname": "test_adjacency_generators.py", "classname": null, "funcname": "test_init", "imports": ["from stellargraph.core.utils import normalize_adj", "from stellargraph.mapper.adjacency_generators import AdjacencyPowerGenerator", "from ..test_utils.graphs import barbell", "import tensorflow as tf", "import numpy as np", "import pytest"], "code": "def test_init(barbell):\n    generator = AdjacencyPowerGenerator(barbell, num_powers=5)\n    num_nodes = len(barbell.nodes())\n    assert (generator.num_powers == 5)\n    assert (generator.Aadj_T.shape == (num_nodes, num_nodes))\n    assert (generator.transition_matrix_T.shape == (num_nodes, num_nodes))", "masked_code": "def test_init(barbell):\n    generator = AdjacencyPowerGenerator(barbell, num_powers=5)\n    num_nodes = len(barbell.nodes())\n    assert (generator.num_powers == '???')\n    assert (generator.Aadj_T.shape == (num_nodes, num_nodes))\n    assert (generator.transition_matrix_T.shape == (num_nodes, num_nodes))", "ground_truth": "5", "quality_analysis": {"complexity_score": 3, "left_complexity": 2, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_765", "reponame": "stellargraph", "testpath": "tests/mapper/test_adjacency_generators.py", "testname": "test_adjacency_generators.py", "classname": null, "funcname": "test_init", "imports": ["from stellargraph.core.utils import normalize_adj", "from stellargraph.mapper.adjacency_generators import AdjacencyPowerGenerator", "from ..test_utils.graphs import barbell", "import tensorflow as tf", "import numpy as np", "import pytest"], "code": "def test_init(barbell):\n    generator = AdjacencyPowerGenerator(barbell, num_powers=5)\n    num_nodes = len(barbell.nodes())\n    assert (generator.num_powers == 5)\n    assert (generator.Aadj_T.shape == (num_nodes, num_nodes))\n    assert (generator.transition_matrix_T.shape == (num_nodes, num_nodes))", "masked_code": "def test_init(barbell):\n    generator = AdjacencyPowerGenerator(barbell, num_powers=5)\n    num_nodes = len(barbell.nodes())\n    assert (generator.num_powers == 5)\n    assert (generator.Aadj_T.shape == '???')\n    assert (generator.transition_matrix_T.shape == (num_nodes, num_nodes))", "ground_truth": "(num_nodes, num_nodes)", "quality_analysis": {"complexity_score": 6, "left_complexity": 2, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_766", "reponame": "stellargraph", "testpath": "tests/mapper/test_adjacency_generators.py", "testname": "test_adjacency_generators.py", "classname": null, "funcname": "test_init", "imports": ["from stellargraph.core.utils import normalize_adj", "from stellargraph.mapper.adjacency_generators import AdjacencyPowerGenerator", "from ..test_utils.graphs import barbell", "import tensorflow as tf", "import numpy as np", "import pytest"], "code": "def test_init(barbell):\n    generator = AdjacencyPowerGenerator(barbell, num_powers=5)\n    num_nodes = len(barbell.nodes())\n    assert (generator.num_powers == 5)\n    assert (generator.Aadj_T.shape == (num_nodes, num_nodes))\n    assert (generator.transition_matrix_T.shape == (num_nodes, num_nodes))", "masked_code": "def test_init(barbell):\n    generator = AdjacencyPowerGenerator(barbell, num_powers=5)\n    num_nodes = len(barbell.nodes())\n    assert (generator.num_powers == 5)\n    assert (generator.Aadj_T.shape == (num_nodes, num_nodes))\n    assert (generator.transition_matrix_T.shape == '???')", "ground_truth": "(num_nodes, num_nodes)", "quality_analysis": {"complexity_score": 6, "left_complexity": 2, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_767", "reponame": "stellargraph", "testpath": "tests/mapper/test_adjacency_generators.py", "testname": "test_adjacency_generators.py", "classname": null, "funcname": "test_flow", "imports": ["from stellargraph.core.utils import normalize_adj", "from stellargraph.mapper.adjacency_generators import AdjacencyPowerGenerator", "from ..test_utils.graphs import barbell", "import tensorflow as tf", "import numpy as np", "import pytest"], "code": "def test_flow(barbell):\n    generator = AdjacencyPowerGenerator(barbell, num_powers=5)\n    dataset = generator.flow(batch_size=1)\n    assert (tf.data.experimental.cardinality(dataset).numpy() == (- 1))", "masked_code": "def test_flow(barbell):\n    generator = AdjacencyPowerGenerator(barbell, num_powers=5)\n    dataset = generator.flow(batch_size=1)\n    assert (tf.data.experimental.cardinality(dataset).numpy() == '???')", "ground_truth": "(- 1)", "quality_analysis": {"complexity_score": 6, "left_complexity": 3, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_768", "reponame": "stellargraph", "testpath": "tests/mapper/test_adjacency_generators.py", "testname": "test_adjacency_generators.py", "classname": null, "funcname": "test_flow_batch_size", "imports": ["from stellargraph.core.utils import normalize_adj", "from stellargraph.mapper.adjacency_generators import AdjacencyPowerGenerator", "from ..test_utils.graphs import barbell", "import tensorflow as tf", "import numpy as np", "import pytest"], "code": "@pytest.mark.parametrize('batch_size', [1, 5, 10])\ndef test_flow_batch_size(barbell, batch_size):\n    num_powers = 5\n    generator = AdjacencyPowerGenerator(barbell, num_powers=num_powers)\n    for (x, y) in generator.flow(batch_size=batch_size).take(1):\n        assert (x[0].shape == (batch_size,))\n        assert (y.shape == (batch_size, 1, len(barbell.nodes())))\n        assert (x[1].shape == (batch_size, num_powers, len(barbell.nodes())))", "masked_code": "@pytest.mark.parametrize('batch_size', [1, 5, 10])\ndef test_flow_batch_size(barbell, batch_size):\n    num_powers = 5\n    generator = AdjacencyPowerGenerator(barbell, num_powers=num_powers)\n    for (x, y) in generator.flow(batch_size=batch_size).take(1):\n        assert (x[0].shape == '???')\n        assert (y.shape == (batch_size, 1, len(barbell.nodes())))\n        assert (x[1].shape == (batch_size, num_powers, len(barbell.nodes())))", "ground_truth": "(batch_size,)", "quality_analysis": {"complexity_score": 5, "left_complexity": 2, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_769", "reponame": "stellargraph", "testpath": "tests/mapper/test_adjacency_generators.py", "testname": "test_adjacency_generators.py", "classname": null, "funcname": "test_flow_batch_size", "imports": ["from stellargraph.core.utils import normalize_adj", "from stellargraph.mapper.adjacency_generators import AdjacencyPowerGenerator", "from ..test_utils.graphs import barbell", "import tensorflow as tf", "import numpy as np", "import pytest"], "code": "@pytest.mark.parametrize('batch_size', [1, 5, 10])\ndef test_flow_batch_size(barbell, batch_size):\n    num_powers = 5\n    generator = AdjacencyPowerGenerator(barbell, num_powers=num_powers)\n    for (x, y) in generator.flow(batch_size=batch_size).take(1):\n        assert (x[0].shape == (batch_size,))\n        assert (y.shape == (batch_size, 1, len(barbell.nodes())))\n        assert (x[1].shape == (batch_size, num_powers, len(barbell.nodes())))", "masked_code": "@pytest.mark.parametrize('batch_size', [1, 5, 10])\ndef test_flow_batch_size(barbell, batch_size):\n    num_powers = 5\n    generator = AdjacencyPowerGenerator(barbell, num_powers=num_powers)\n    for (x, y) in generator.flow(batch_size=batch_size).take(1):\n        assert (x[0].shape == (batch_size,))\n        assert (y.shape == '???')\n        assert (x[1].shape == (batch_size, num_powers, len(barbell.nodes())))", "ground_truth": "(batch_size, 1, len(barbell.nodes()))", "quality_analysis": {"complexity_score": 12, "left_complexity": 2, "right_complexity": 10, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_770", "reponame": "stellargraph", "testpath": "tests/mapper/test_adjacency_generators.py", "testname": "test_adjacency_generators.py", "classname": null, "funcname": "test_flow_batch_size", "imports": ["from stellargraph.core.utils import normalize_adj", "from stellargraph.mapper.adjacency_generators import AdjacencyPowerGenerator", "from ..test_utils.graphs import barbell", "import tensorflow as tf", "import numpy as np", "import pytest"], "code": "@pytest.mark.parametrize('batch_size', [1, 5, 10])\ndef test_flow_batch_size(barbell, batch_size):\n    num_powers = 5\n    generator = AdjacencyPowerGenerator(barbell, num_powers=num_powers)\n    for (x, y) in generator.flow(batch_size=batch_size).take(1):\n        assert (x[0].shape == (batch_size,))\n        assert (y.shape == (batch_size, 1, len(barbell.nodes())))\n        assert (x[1].shape == (batch_size, num_powers, len(barbell.nodes())))", "masked_code": "@pytest.mark.parametrize('batch_size', [1, 5, 10])\ndef test_flow_batch_size(barbell, batch_size):\n    num_powers = 5\n    generator = AdjacencyPowerGenerator(barbell, num_powers=num_powers)\n    for (x, y) in generator.flow(batch_size=batch_size).take(1):\n        assert (x[0].shape == (batch_size,))\n        assert (y.shape == (batch_size, 1, len(barbell.nodes())))\n        assert (x[1].shape == '???')", "ground_truth": "(batch_size, num_powers, len(barbell.nodes()))", "quality_analysis": {"complexity_score": 12, "left_complexity": 2, "right_complexity": 10, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_771", "reponame": "stellargraph", "testpath": "tests/mapper/test_adjacency_generators.py", "testname": "test_adjacency_generators.py", "classname": null, "funcname": "test_flow_batch_size", "imports": ["from stellargraph.core.utils import normalize_adj", "from stellargraph.mapper.adjacency_generators import AdjacencyPowerGenerator", "from ..test_utils.graphs import barbell", "import tensorflow as tf", "import numpy as np", "import pytest"], "code": "@pytest.mark.parametrize('num_powers', [2, 4, 8])\ndef test_flow_batch_size(barbell, num_powers):\n    batch_size = 2\n    generator = AdjacencyPowerGenerator(barbell, num_powers=num_powers)\n    for (x, y) in generator.flow(batch_size=batch_size).take(1):\n        assert (x[0].shape == (batch_size,))\n        assert (y.shape == (batch_size, 1, len(barbell.nodes())))\n        assert (x[1].shape == (batch_size, num_powers, len(barbell.nodes())))", "masked_code": "@pytest.mark.parametrize('num_powers', [2, 4, 8])\ndef test_flow_batch_size(barbell, num_powers):\n    batch_size = 2\n    generator = AdjacencyPowerGenerator(barbell, num_powers=num_powers)\n    for (x, y) in generator.flow(batch_size=batch_size).take(1):\n        assert (x[0].shape == '???')\n        assert (y.shape == (batch_size, 1, len(barbell.nodes())))\n        assert (x[1].shape == (batch_size, num_powers, len(barbell.nodes())))", "ground_truth": "(batch_size,)", "quality_analysis": {"complexity_score": 5, "left_complexity": 2, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_772", "reponame": "stellargraph", "testpath": "tests/mapper/test_adjacency_generators.py", "testname": "test_adjacency_generators.py", "classname": null, "funcname": "test_flow_batch_size", "imports": ["from stellargraph.core.utils import normalize_adj", "from stellargraph.mapper.adjacency_generators import AdjacencyPowerGenerator", "from ..test_utils.graphs import barbell", "import tensorflow as tf", "import numpy as np", "import pytest"], "code": "@pytest.mark.parametrize('num_powers', [2, 4, 8])\ndef test_flow_batch_size(barbell, num_powers):\n    batch_size = 2\n    generator = AdjacencyPowerGenerator(barbell, num_powers=num_powers)\n    for (x, y) in generator.flow(batch_size=batch_size).take(1):\n        assert (x[0].shape == (batch_size,))\n        assert (y.shape == (batch_size, 1, len(barbell.nodes())))\n        assert (x[1].shape == (batch_size, num_powers, len(barbell.nodes())))", "masked_code": "@pytest.mark.parametrize('num_powers', [2, 4, 8])\ndef test_flow_batch_size(barbell, num_powers):\n    batch_size = 2\n    generator = AdjacencyPowerGenerator(barbell, num_powers=num_powers)\n    for (x, y) in generator.flow(batch_size=batch_size).take(1):\n        assert (x[0].shape == (batch_size,))\n        assert (y.shape == '???')\n        assert (x[1].shape == (batch_size, num_powers, len(barbell.nodes())))", "ground_truth": "(batch_size, 1, len(barbell.nodes()))", "quality_analysis": {"complexity_score": 12, "left_complexity": 2, "right_complexity": 10, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_773", "reponame": "stellargraph", "testpath": "tests/mapper/test_adjacency_generators.py", "testname": "test_adjacency_generators.py", "classname": null, "funcname": "test_flow_batch_size", "imports": ["from stellargraph.core.utils import normalize_adj", "from stellargraph.mapper.adjacency_generators import AdjacencyPowerGenerator", "from ..test_utils.graphs import barbell", "import tensorflow as tf", "import numpy as np", "import pytest"], "code": "@pytest.mark.parametrize('num_powers', [2, 4, 8])\ndef test_flow_batch_size(barbell, num_powers):\n    batch_size = 2\n    generator = AdjacencyPowerGenerator(barbell, num_powers=num_powers)\n    for (x, y) in generator.flow(batch_size=batch_size).take(1):\n        assert (x[0].shape == (batch_size,))\n        assert (y.shape == (batch_size, 1, len(barbell.nodes())))\n        assert (x[1].shape == (batch_size, num_powers, len(barbell.nodes())))", "masked_code": "@pytest.mark.parametrize('num_powers', [2, 4, 8])\ndef test_flow_batch_size(barbell, num_powers):\n    batch_size = 2\n    generator = AdjacencyPowerGenerator(barbell, num_powers=num_powers)\n    for (x, y) in generator.flow(batch_size=batch_size).take(1):\n        assert (x[0].shape == (batch_size,))\n        assert (y.shape == (batch_size, 1, len(barbell.nodes())))\n        assert (x[1].shape == '???')", "ground_truth": "(batch_size, num_powers, len(barbell.nodes()))", "quality_analysis": {"complexity_score": 12, "left_complexity": 2, "right_complexity": 10, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_774", "reponame": "stellargraph", "testpath": "tests/mapper/test_cluster_gcn_node_mapper.py", "testname": "test_cluster_gcn_node_mapper.py", "classname": null, "funcname": "test_ClusterNodeSequence_init", "imports": ["from stellargraph.mapper import ClusterNodeGenerator, ClusterNodeSequence", "from stellargraph.core.graph import StellarGraph", "import pandas as pd", "import numpy as np", "import pytest", "from ..test_utils.graphs import example_graph_random"], "code": "def test_ClusterNodeSequence_init():\n    G = create_stellargraph()\n    nsg = ClusterNodeSequence(graph=G, clusters=[list(G.nodes())])\n    assert (len(nsg) == 1)\n    nsg = ClusterNodeSequence(graph=G, clusters=[['a'], ['b', 'd'], ['c']])\n    assert (len(nsg) == 3)\n    with pytest.raises(ValueError):\n        ClusterNodeSequence(graph=G, clusters=[list(G.nodes())], q=1, targets=np.array([[0, 1]]))\n    with pytest.raises(ValueError):\n        ClusterNodeSequence(graph=G, clusters=[list(G.nodes())], q=1, targets=np.array([[0, 1], [1, 0]]), node_ids=['a'])\n    with pytest.raises(ValueError):\n        ClusterNodeSequence(graph=G, clusters=[list(G.nodes())], q=2)", "masked_code": "def test_ClusterNodeSequence_init():\n    G = create_stellargraph()\n    nsg = ClusterNodeSequence(graph=G, clusters=[list(G.nodes())])\n    assert (len(nsg) == 1)\n    nsg = ClusterNodeSequence(graph=G, clusters=[['a'], ['b', 'd'], ['c']])\n    assert (len(nsg) == '???')\n    with pytest.raises(ValueError):\n        ClusterNodeSequence(graph=G, clusters=[list(G.nodes())], q=1, targets=np.array([[0, 1]]))\n    with pytest.raises(ValueError):\n        ClusterNodeSequence(graph=G, clusters=[list(G.nodes())], q=1, targets=np.array([[0, 1], [1, 0]]), node_ids=['a'])\n    with pytest.raises(ValueError):\n        ClusterNodeSequence(graph=G, clusters=[list(G.nodes())], q=2)", "ground_truth": "3", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_775", "reponame": "stellargraph", "testpath": "tests/mapper/test_cluster_gcn_node_mapper.py", "testname": "test_cluster_gcn_node_mapper.py", "classname": null, "funcname": "test_ClusterNodeSequence_getitem", "imports": ["from stellargraph.mapper import ClusterNodeGenerator, ClusterNodeSequence", "from stellargraph.core.graph import StellarGraph", "import pandas as pd", "import numpy as np", "import pytest", "from ..test_utils.graphs import example_graph_random"], "code": "def test_ClusterNodeSequence_getitem():\n    G = create_stellargraph()\n    nsg = ClusterNodeSequence(graph=G, clusters=[['a'], ['b'], ['c'], ['d']], node_ids=['a', 'b', 'd'])\n    assert (len(nsg) == 4)\n    for cluster in list(nsg):\n        print(cluster)\n        assert (len(cluster) == 2)\n        assert (len(cluster[0][0]) == 1)\n        assert (len(cluster[0][1]) == 1)\n        assert (cluster[0][2].shape == (1, 1, 1))\n        assert (cluster[1] is None)\n    assert (len(nsg.node_order) == 3)\n    nodes = set()\n    for node in nsg.node_order:\n        nodes.add(node)\n    assert (len(nodes.intersection(['a', 'b', 'd'])) == 3)", "masked_code": "def test_ClusterNodeSequence_getitem():\n    G = create_stellargraph()\n    nsg = ClusterNodeSequence(graph=G, clusters=[['a'], ['b'], ['c'], ['d']], node_ids=['a', 'b', 'd'])\n    assert (len(nsg) == '???')\n    for cluster in list(nsg):\n        print(cluster)\n        assert (len(cluster) == 2)\n        assert (len(cluster[0][0]) == 1)\n        assert (len(cluster[0][1]) == 1)\n        assert (cluster[0][2].shape == (1, 1, 1))\n        assert (cluster[1] is None)\n    assert (len(nsg.node_order) == 3)\n    nodes = set()\n    for node in nsg.node_order:\n        nodes.add(node)\n    assert (len(nodes.intersection(['a', 'b', 'd'])) == 3)", "ground_truth": "4", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_776", "reponame": "stellargraph", "testpath": "tests/mapper/test_cluster_gcn_node_mapper.py", "testname": "test_cluster_gcn_node_mapper.py", "classname": null, "funcname": "test_ClusterNodeSequence_getitem", "imports": ["from stellargraph.mapper import ClusterNodeGenerator, ClusterNodeSequence", "from stellargraph.core.graph import StellarGraph", "import pandas as pd", "import numpy as np", "import pytest", "from ..test_utils.graphs import example_graph_random"], "code": "def test_ClusterNodeSequence_getitem():\n    G = create_stellargraph()\n    nsg = ClusterNodeSequence(graph=G, clusters=[['a'], ['b'], ['c'], ['d']], node_ids=['a', 'b', 'd'])\n    assert (len(nsg) == 4)\n    for cluster in list(nsg):\n        print(cluster)\n        assert (len(cluster) == 2)\n        assert (len(cluster[0][0]) == 1)\n        assert (len(cluster[0][1]) == 1)\n        assert (cluster[0][2].shape == (1, 1, 1))\n        assert (cluster[1] is None)\n    assert (len(nsg.node_order) == 3)\n    nodes = set()\n    for node in nsg.node_order:\n        nodes.add(node)\n    assert (len(nodes.intersection(['a', 'b', 'd'])) == 3)", "masked_code": "def test_ClusterNodeSequence_getitem():\n    G = create_stellargraph()\n    nsg = ClusterNodeSequence(graph=G, clusters=[['a'], ['b'], ['c'], ['d']], node_ids=['a', 'b', 'd'])\n    assert (len(nsg) == 4)\n    for cluster in list(nsg):\n        print(cluster)\n        assert (len(cluster) == 2)\n        assert (len(cluster[0][0]) == 1)\n        assert (len(cluster[0][1]) == 1)\n        assert (cluster[0][2].shape == (1, 1, 1))\n        assert (cluster[1] is None)\n    assert (len(nsg.node_order) == '???')\n    nodes = set()\n    for node in nsg.node_order:\n        nodes.add(node)\n    assert (len(nodes.intersection(['a', 'b', 'd'])) == 3)", "ground_truth": "3", "quality_analysis": {"complexity_score": 6, "left_complexity": 5, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_777", "reponame": "stellargraph", "testpath": "tests/mapper/test_cluster_gcn_node_mapper.py", "testname": "test_cluster_gcn_node_mapper.py", "classname": null, "funcname": "test_ClusterNodeSequence_getitem", "imports": ["from stellargraph.mapper import ClusterNodeGenerator, ClusterNodeSequence", "from stellargraph.core.graph import StellarGraph", "import pandas as pd", "import numpy as np", "import pytest", "from ..test_utils.graphs import example_graph_random"], "code": "def test_ClusterNodeSequence_getitem():\n    G = create_stellargraph()\n    nsg = ClusterNodeSequence(graph=G, clusters=[['a'], ['b'], ['c'], ['d']], node_ids=['a', 'b', 'd'])\n    assert (len(nsg) == 4)\n    for cluster in list(nsg):\n        print(cluster)\n        assert (len(cluster) == 2)\n        assert (len(cluster[0][0]) == 1)\n        assert (len(cluster[0][1]) == 1)\n        assert (cluster[0][2].shape == (1, 1, 1))\n        assert (cluster[1] is None)\n    assert (len(nsg.node_order) == 3)\n    nodes = set()\n    for node in nsg.node_order:\n        nodes.add(node)\n    assert (len(nodes.intersection(['a', 'b', 'd'])) == 3)", "masked_code": "def test_ClusterNodeSequence_getitem():\n    G = create_stellargraph()\n    nsg = ClusterNodeSequence(graph=G, clusters=[['a'], ['b'], ['c'], ['d']], node_ids=['a', 'b', 'd'])\n    assert (len(nsg) == 4)\n    for cluster in list(nsg):\n        print(cluster)\n        assert (len(cluster) == 2)\n        assert (len(cluster[0][0]) == 1)\n        assert (len(cluster[0][1]) == 1)\n        assert (cluster[0][2].shape == (1, 1, 1))\n        assert (cluster[1] is None)\n    assert (len(nsg.node_order) == 3)\n    nodes = set()\n    for node in nsg.node_order:\n        nodes.add(node)\n    assert (len(nodes.intersection(['a', 'b', 'd'])) == '???')", "ground_truth": "3", "quality_analysis": {"complexity_score": 12, "left_complexity": 11, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_778", "reponame": "stellargraph", "testpath": "tests/mapper/test_cluster_gcn_node_mapper.py", "testname": "test_cluster_gcn_node_mapper.py", "classname": null, "funcname": "test_ClusterNodeSequence_getitem", "imports": ["from stellargraph.mapper import ClusterNodeGenerator, ClusterNodeSequence", "from stellargraph.core.graph import StellarGraph", "import pandas as pd", "import numpy as np", "import pytest", "from ..test_utils.graphs import example_graph_random"], "code": "def test_ClusterNodeSequence_getitem():\n    G = create_stellargraph()\n    nsg = ClusterNodeSequence(graph=G, clusters=[['a'], ['b'], ['c'], ['d']], node_ids=['a', 'b', 'd'])\n    assert (len(nsg) == 4)\n    for cluster in list(nsg):\n        print(cluster)\n        assert (len(cluster) == 2)\n        assert (len(cluster[0][0]) == 1)\n        assert (len(cluster[0][1]) == 1)\n        assert (cluster[0][2].shape == (1, 1, 1))\n        assert (cluster[1] is None)\n    assert (len(nsg.node_order) == 3)\n    nodes = set()\n    for node in nsg.node_order:\n        nodes.add(node)\n    assert (len(nodes.intersection(['a', 'b', 'd'])) == 3)", "masked_code": "def test_ClusterNodeSequence_getitem():\n    G = create_stellargraph()\n    nsg = ClusterNodeSequence(graph=G, clusters=[['a'], ['b'], ['c'], ['d']], node_ids=['a', 'b', 'd'])\n    assert (len(nsg) == 4)\n    for cluster in list(nsg):\n        print(cluster)\n        assert (len(cluster) == 2)\n        assert (len(cluster[0][0]) == 1)\n        assert (len(cluster[0][1]) == 1)\n        assert (cluster[0][2].shape == '???')\n        assert (cluster[1] is None)\n    assert (len(nsg.node_order) == 3)\n    nodes = set()\n    for node in nsg.node_order:\n        nodes.add(node)\n    assert (len(nodes.intersection(['a', 'b', 'd'])) == 3)", "ground_truth": "(1, 1, 1)", "quality_analysis": {"complexity_score": 7, "left_complexity": 2, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_779", "reponame": "stellargraph", "testpath": "tests/mapper/test_cluster_gcn_node_mapper.py", "testname": "test_cluster_gcn_node_mapper.py", "classname": null, "funcname": "test_ClusterNodeSquence", "imports": ["from stellargraph.mapper import ClusterNodeGenerator, ClusterNodeSequence", "from stellargraph.core.graph import StellarGraph", "import pandas as pd", "import numpy as np", "import pytest", "from ..test_utils.graphs import example_graph_random"], "code": "def test_ClusterNodeSquence():\n    G = create_stellargraph()\n    generator = ClusterNodeGenerator(G, clusters=1, q=1).flow(node_ids=['a', 'b', 'c', 'd'])\n    assert (len(generator) == 1)\n    generator = ClusterNodeGenerator(G, clusters=4, q=1).flow(node_ids=['a', 'b', 'c', 'd'])\n    assert (len(generator) == 4)\n    generator = ClusterNodeGenerator(G, clusters=4, q=1).flow(node_ids=['a', 'b', 'c', 'd'])\n    for batch in generator:\n        assert (len(batch) == 2)\n        assert (batch[0][0].shape == (1, 1, 2))\n        assert (batch[0][1].shape == (1, 1))\n        assert (batch[0][2].shape == (1, 1, 1))\n        assert (batch[1] is None)\n    generator = ClusterNodeGenerator(G, clusters=2, q=1).flow(node_ids=['a', 'b', 'c', 'd'])\n    assert (len(generator) == 2)\n    for batch in generator:\n        assert (len(batch) == 2)\n        assert (batch[0][0].shape == (1, 2, 2))\n        assert (batch[0][1].shape == (1, 2))\n        assert (batch[0][2].shape == (1, 2, 2))\n        assert (batch[1] is None)", "masked_code": "def test_ClusterNodeSquence():\n    G = create_stellargraph()\n    generator = ClusterNodeGenerator(G, clusters=1, q=1).flow(node_ids=['a', 'b', 'c', 'd'])\n    assert (len(generator) == 1)\n    generator = ClusterNodeGenerator(G, clusters=4, q=1).flow(node_ids=['a', 'b', 'c', 'd'])\n    assert (len(generator) == '???')\n    generator = ClusterNodeGenerator(G, clusters=4, q=1).flow(node_ids=['a', 'b', 'c', 'd'])\n    for batch in generator:\n        assert (len(batch) == 2)\n        assert (batch[0][0].shape == (1, 1, 2))\n        assert (batch[0][1].shape == (1, 1))\n        assert (batch[0][2].shape == (1, 1, 1))\n        assert (batch[1] is None)\n    generator = ClusterNodeGenerator(G, clusters=2, q=1).flow(node_ids=['a', 'b', 'c', 'd'])\n    assert (len(generator) == 2)\n    for batch in generator:\n        assert (len(batch) == 2)\n        assert (batch[0][0].shape == (1, 2, 2))\n        assert (batch[0][1].shape == (1, 2))\n        assert (batch[0][2].shape == (1, 2, 2))\n        assert (batch[1] is None)", "ground_truth": "4", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_780", "reponame": "stellargraph", "testpath": "tests/mapper/test_cluster_gcn_node_mapper.py", "testname": "test_cluster_gcn_node_mapper.py", "classname": null, "funcname": "test_ClusterNodeSquence", "imports": ["from stellargraph.mapper import ClusterNodeGenerator, ClusterNodeSequence", "from stellargraph.core.graph import StellarGraph", "import pandas as pd", "import numpy as np", "import pytest", "from ..test_utils.graphs import example_graph_random"], "code": "def test_ClusterNodeSquence():\n    G = create_stellargraph()\n    generator = ClusterNodeGenerator(G, clusters=1, q=1).flow(node_ids=['a', 'b', 'c', 'd'])\n    assert (len(generator) == 1)\n    generator = ClusterNodeGenerator(G, clusters=4, q=1).flow(node_ids=['a', 'b', 'c', 'd'])\n    assert (len(generator) == 4)\n    generator = ClusterNodeGenerator(G, clusters=4, q=1).flow(node_ids=['a', 'b', 'c', 'd'])\n    for batch in generator:\n        assert (len(batch) == 2)\n        assert (batch[0][0].shape == (1, 1, 2))\n        assert (batch[0][1].shape == (1, 1))\n        assert (batch[0][2].shape == (1, 1, 1))\n        assert (batch[1] is None)\n    generator = ClusterNodeGenerator(G, clusters=2, q=1).flow(node_ids=['a', 'b', 'c', 'd'])\n    assert (len(generator) == 2)\n    for batch in generator:\n        assert (len(batch) == 2)\n        assert (batch[0][0].shape == (1, 2, 2))\n        assert (batch[0][1].shape == (1, 2))\n        assert (batch[0][2].shape == (1, 2, 2))\n        assert (batch[1] is None)", "masked_code": "def test_ClusterNodeSquence():\n    G = create_stellargraph()\n    generator = ClusterNodeGenerator(G, clusters=1, q=1).flow(node_ids=['a', 'b', 'c', 'd'])\n    assert (len(generator) == 1)\n    generator = ClusterNodeGenerator(G, clusters=4, q=1).flow(node_ids=['a', 'b', 'c', 'd'])\n    assert (len(generator) == 4)\n    generator = ClusterNodeGenerator(G, clusters=4, q=1).flow(node_ids=['a', 'b', 'c', 'd'])\n    for batch in generator:\n        assert (len(batch) == 2)\n        assert (batch[0][0].shape == '???')\n        assert (batch[0][1].shape == (1, 1))\n        assert (batch[0][2].shape == (1, 1, 1))\n        assert (batch[1] is None)\n    generator = ClusterNodeGenerator(G, clusters=2, q=1).flow(node_ids=['a', 'b', 'c', 'd'])\n    assert (len(generator) == 2)\n    for batch in generator:\n        assert (len(batch) == 2)\n        assert (batch[0][0].shape == (1, 2, 2))\n        assert (batch[0][1].shape == (1, 2))\n        assert (batch[0][2].shape == (1, 2, 2))\n        assert (batch[1] is None)", "ground_truth": "(1, 1, 2)", "quality_analysis": {"complexity_score": 7, "left_complexity": 2, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_781", "reponame": "stellargraph", "testpath": "tests/mapper/test_cluster_gcn_node_mapper.py", "testname": "test_cluster_gcn_node_mapper.py", "classname": null, "funcname": "test_ClusterNodeSquence", "imports": ["from stellargraph.mapper import ClusterNodeGenerator, ClusterNodeSequence", "from stellargraph.core.graph import StellarGraph", "import pandas as pd", "import numpy as np", "import pytest", "from ..test_utils.graphs import example_graph_random"], "code": "def test_ClusterNodeSquence():\n    G = create_stellargraph()\n    generator = ClusterNodeGenerator(G, clusters=1, q=1).flow(node_ids=['a', 'b', 'c', 'd'])\n    assert (len(generator) == 1)\n    generator = ClusterNodeGenerator(G, clusters=4, q=1).flow(node_ids=['a', 'b', 'c', 'd'])\n    assert (len(generator) == 4)\n    generator = ClusterNodeGenerator(G, clusters=4, q=1).flow(node_ids=['a', 'b', 'c', 'd'])\n    for batch in generator:\n        assert (len(batch) == 2)\n        assert (batch[0][0].shape == (1, 1, 2))\n        assert (batch[0][1].shape == (1, 1))\n        assert (batch[0][2].shape == (1, 1, 1))\n        assert (batch[1] is None)\n    generator = ClusterNodeGenerator(G, clusters=2, q=1).flow(node_ids=['a', 'b', 'c', 'd'])\n    assert (len(generator) == 2)\n    for batch in generator:\n        assert (len(batch) == 2)\n        assert (batch[0][0].shape == (1, 2, 2))\n        assert (batch[0][1].shape == (1, 2))\n        assert (batch[0][2].shape == (1, 2, 2))\n        assert (batch[1] is None)", "masked_code": "def test_ClusterNodeSquence():\n    G = create_stellargraph()\n    generator = ClusterNodeGenerator(G, clusters=1, q=1).flow(node_ids=['a', 'b', 'c', 'd'])\n    assert (len(generator) == 1)\n    generator = ClusterNodeGenerator(G, clusters=4, q=1).flow(node_ids=['a', 'b', 'c', 'd'])\n    assert (len(generator) == 4)\n    generator = ClusterNodeGenerator(G, clusters=4, q=1).flow(node_ids=['a', 'b', 'c', 'd'])\n    for batch in generator:\n        assert (len(batch) == 2)\n        assert (batch[0][0].shape == (1, 1, 2))\n        assert (batch[0][1].shape == '???')\n        assert (batch[0][2].shape == (1, 1, 1))\n        assert (batch[1] is None)\n    generator = ClusterNodeGenerator(G, clusters=2, q=1).flow(node_ids=['a', 'b', 'c', 'd'])\n    assert (len(generator) == 2)\n    for batch in generator:\n        assert (len(batch) == 2)\n        assert (batch[0][0].shape == (1, 2, 2))\n        assert (batch[0][1].shape == (1, 2))\n        assert (batch[0][2].shape == (1, 2, 2))\n        assert (batch[1] is None)", "ground_truth": "(1, 1)", "quality_analysis": {"complexity_score": 6, "left_complexity": 2, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_782", "reponame": "stellargraph", "testpath": "tests/mapper/test_cluster_gcn_node_mapper.py", "testname": "test_cluster_gcn_node_mapper.py", "classname": null, "funcname": "test_ClusterNodeSquence", "imports": ["from stellargraph.mapper import ClusterNodeGenerator, ClusterNodeSequence", "from stellargraph.core.graph import StellarGraph", "import pandas as pd", "import numpy as np", "import pytest", "from ..test_utils.graphs import example_graph_random"], "code": "def test_ClusterNodeSquence():\n    G = create_stellargraph()\n    generator = ClusterNodeGenerator(G, clusters=1, q=1).flow(node_ids=['a', 'b', 'c', 'd'])\n    assert (len(generator) == 1)\n    generator = ClusterNodeGenerator(G, clusters=4, q=1).flow(node_ids=['a', 'b', 'c', 'd'])\n    assert (len(generator) == 4)\n    generator = ClusterNodeGenerator(G, clusters=4, q=1).flow(node_ids=['a', 'b', 'c', 'd'])\n    for batch in generator:\n        assert (len(batch) == 2)\n        assert (batch[0][0].shape == (1, 1, 2))\n        assert (batch[0][1].shape == (1, 1))\n        assert (batch[0][2].shape == (1, 1, 1))\n        assert (batch[1] is None)\n    generator = ClusterNodeGenerator(G, clusters=2, q=1).flow(node_ids=['a', 'b', 'c', 'd'])\n    assert (len(generator) == 2)\n    for batch in generator:\n        assert (len(batch) == 2)\n        assert (batch[0][0].shape == (1, 2, 2))\n        assert (batch[0][1].shape == (1, 2))\n        assert (batch[0][2].shape == (1, 2, 2))\n        assert (batch[1] is None)", "masked_code": "def test_ClusterNodeSquence():\n    G = create_stellargraph()\n    generator = ClusterNodeGenerator(G, clusters=1, q=1).flow(node_ids=['a', 'b', 'c', 'd'])\n    assert (len(generator) == 1)\n    generator = ClusterNodeGenerator(G, clusters=4, q=1).flow(node_ids=['a', 'b', 'c', 'd'])\n    assert (len(generator) == 4)\n    generator = ClusterNodeGenerator(G, clusters=4, q=1).flow(node_ids=['a', 'b', 'c', 'd'])\n    for batch in generator:\n        assert (len(batch) == 2)\n        assert (batch[0][0].shape == (1, 1, 2))\n        assert (batch[0][1].shape == (1, 1))\n        assert (batch[0][2].shape == '???')\n        assert (batch[1] is None)\n    generator = ClusterNodeGenerator(G, clusters=2, q=1).flow(node_ids=['a', 'b', 'c', 'd'])\n    assert (len(generator) == 2)\n    for batch in generator:\n        assert (len(batch) == 2)\n        assert (batch[0][0].shape == (1, 2, 2))\n        assert (batch[0][1].shape == (1, 2))\n        assert (batch[0][2].shape == (1, 2, 2))\n        assert (batch[1] is None)", "ground_truth": "(1, 1, 1)", "quality_analysis": {"complexity_score": 7, "left_complexity": 2, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_783", "reponame": "stellargraph", "testpath": "tests/mapper/test_cluster_gcn_node_mapper.py", "testname": "test_cluster_gcn_node_mapper.py", "classname": null, "funcname": "test_ClusterNodeSquence", "imports": ["from stellargraph.mapper import ClusterNodeGenerator, ClusterNodeSequence", "from stellargraph.core.graph import StellarGraph", "import pandas as pd", "import numpy as np", "import pytest", "from ..test_utils.graphs import example_graph_random"], "code": "def test_ClusterNodeSquence():\n    G = create_stellargraph()\n    generator = ClusterNodeGenerator(G, clusters=1, q=1).flow(node_ids=['a', 'b', 'c', 'd'])\n    assert (len(generator) == 1)\n    generator = ClusterNodeGenerator(G, clusters=4, q=1).flow(node_ids=['a', 'b', 'c', 'd'])\n    assert (len(generator) == 4)\n    generator = ClusterNodeGenerator(G, clusters=4, q=1).flow(node_ids=['a', 'b', 'c', 'd'])\n    for batch in generator:\n        assert (len(batch) == 2)\n        assert (batch[0][0].shape == (1, 1, 2))\n        assert (batch[0][1].shape == (1, 1))\n        assert (batch[0][2].shape == (1, 1, 1))\n        assert (batch[1] is None)\n    generator = ClusterNodeGenerator(G, clusters=2, q=1).flow(node_ids=['a', 'b', 'c', 'd'])\n    assert (len(generator) == 2)\n    for batch in generator:\n        assert (len(batch) == 2)\n        assert (batch[0][0].shape == (1, 2, 2))\n        assert (batch[0][1].shape == (1, 2))\n        assert (batch[0][2].shape == (1, 2, 2))\n        assert (batch[1] is None)", "masked_code": "def test_ClusterNodeSquence():\n    G = create_stellargraph()\n    generator = ClusterNodeGenerator(G, clusters=1, q=1).flow(node_ids=['a', 'b', 'c', 'd'])\n    assert (len(generator) == 1)\n    generator = ClusterNodeGenerator(G, clusters=4, q=1).flow(node_ids=['a', 'b', 'c', 'd'])\n    assert (len(generator) == 4)\n    generator = ClusterNodeGenerator(G, clusters=4, q=1).flow(node_ids=['a', 'b', 'c', 'd'])\n    for batch in generator:\n        assert (len(batch) == 2)\n        assert (batch[0][0].shape == (1, 1, 2))\n        assert (batch[0][1].shape == (1, 1))\n        assert (batch[0][2].shape == (1, 1, 1))\n        assert (batch[1] is None)\n    generator = ClusterNodeGenerator(G, clusters=2, q=1).flow(node_ids=['a', 'b', 'c', 'd'])\n    assert (len(generator) == 2)\n    for batch in generator:\n        assert (len(batch) == 2)\n        assert (batch[0][0].shape == '???')\n        assert (batch[0][1].shape == (1, 2))\n        assert (batch[0][2].shape == (1, 2, 2))\n        assert (batch[1] is None)", "ground_truth": "(1, 2, 2)", "quality_analysis": {"complexity_score": 7, "left_complexity": 2, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_784", "reponame": "stellargraph", "testpath": "tests/mapper/test_cluster_gcn_node_mapper.py", "testname": "test_cluster_gcn_node_mapper.py", "classname": null, "funcname": "test_ClusterNodeSquence", "imports": ["from stellargraph.mapper import ClusterNodeGenerator, ClusterNodeSequence", "from stellargraph.core.graph import StellarGraph", "import pandas as pd", "import numpy as np", "import pytest", "from ..test_utils.graphs import example_graph_random"], "code": "def test_ClusterNodeSquence():\n    G = create_stellargraph()\n    generator = ClusterNodeGenerator(G, clusters=1, q=1).flow(node_ids=['a', 'b', 'c', 'd'])\n    assert (len(generator) == 1)\n    generator = ClusterNodeGenerator(G, clusters=4, q=1).flow(node_ids=['a', 'b', 'c', 'd'])\n    assert (len(generator) == 4)\n    generator = ClusterNodeGenerator(G, clusters=4, q=1).flow(node_ids=['a', 'b', 'c', 'd'])\n    for batch in generator:\n        assert (len(batch) == 2)\n        assert (batch[0][0].shape == (1, 1, 2))\n        assert (batch[0][1].shape == (1, 1))\n        assert (batch[0][2].shape == (1, 1, 1))\n        assert (batch[1] is None)\n    generator = ClusterNodeGenerator(G, clusters=2, q=1).flow(node_ids=['a', 'b', 'c', 'd'])\n    assert (len(generator) == 2)\n    for batch in generator:\n        assert (len(batch) == 2)\n        assert (batch[0][0].shape == (1, 2, 2))\n        assert (batch[0][1].shape == (1, 2))\n        assert (batch[0][2].shape == (1, 2, 2))\n        assert (batch[1] is None)", "masked_code": "def test_ClusterNodeSquence():\n    G = create_stellargraph()\n    generator = ClusterNodeGenerator(G, clusters=1, q=1).flow(node_ids=['a', 'b', 'c', 'd'])\n    assert (len(generator) == 1)\n    generator = ClusterNodeGenerator(G, clusters=4, q=1).flow(node_ids=['a', 'b', 'c', 'd'])\n    assert (len(generator) == 4)\n    generator = ClusterNodeGenerator(G, clusters=4, q=1).flow(node_ids=['a', 'b', 'c', 'd'])\n    for batch in generator:\n        assert (len(batch) == 2)\n        assert (batch[0][0].shape == (1, 1, 2))\n        assert (batch[0][1].shape == (1, 1))\n        assert (batch[0][2].shape == (1, 1, 1))\n        assert (batch[1] is None)\n    generator = ClusterNodeGenerator(G, clusters=2, q=1).flow(node_ids=['a', 'b', 'c', 'd'])\n    assert (len(generator) == 2)\n    for batch in generator:\n        assert (len(batch) == 2)\n        assert (batch[0][0].shape == (1, 2, 2))\n        assert (batch[0][1].shape == '???')\n        assert (batch[0][2].shape == (1, 2, 2))\n        assert (batch[1] is None)", "ground_truth": "(1, 2)", "quality_analysis": {"complexity_score": 6, "left_complexity": 2, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_785", "reponame": "stellargraph", "testpath": "tests/mapper/test_cluster_gcn_node_mapper.py", "testname": "test_cluster_gcn_node_mapper.py", "classname": null, "funcname": "test_ClusterNodeSquence", "imports": ["from stellargraph.mapper import ClusterNodeGenerator, ClusterNodeSequence", "from stellargraph.core.graph import StellarGraph", "import pandas as pd", "import numpy as np", "import pytest", "from ..test_utils.graphs import example_graph_random"], "code": "def test_ClusterNodeSquence():\n    G = create_stellargraph()\n    generator = ClusterNodeGenerator(G, clusters=1, q=1).flow(node_ids=['a', 'b', 'c', 'd'])\n    assert (len(generator) == 1)\n    generator = ClusterNodeGenerator(G, clusters=4, q=1).flow(node_ids=['a', 'b', 'c', 'd'])\n    assert (len(generator) == 4)\n    generator = ClusterNodeGenerator(G, clusters=4, q=1).flow(node_ids=['a', 'b', 'c', 'd'])\n    for batch in generator:\n        assert (len(batch) == 2)\n        assert (batch[0][0].shape == (1, 1, 2))\n        assert (batch[0][1].shape == (1, 1))\n        assert (batch[0][2].shape == (1, 1, 1))\n        assert (batch[1] is None)\n    generator = ClusterNodeGenerator(G, clusters=2, q=1).flow(node_ids=['a', 'b', 'c', 'd'])\n    assert (len(generator) == 2)\n    for batch in generator:\n        assert (len(batch) == 2)\n        assert (batch[0][0].shape == (1, 2, 2))\n        assert (batch[0][1].shape == (1, 2))\n        assert (batch[0][2].shape == (1, 2, 2))\n        assert (batch[1] is None)", "masked_code": "def test_ClusterNodeSquence():\n    G = create_stellargraph()\n    generator = ClusterNodeGenerator(G, clusters=1, q=1).flow(node_ids=['a', 'b', 'c', 'd'])\n    assert (len(generator) == 1)\n    generator = ClusterNodeGenerator(G, clusters=4, q=1).flow(node_ids=['a', 'b', 'c', 'd'])\n    assert (len(generator) == 4)\n    generator = ClusterNodeGenerator(G, clusters=4, q=1).flow(node_ids=['a', 'b', 'c', 'd'])\n    for batch in generator:\n        assert (len(batch) == 2)\n        assert (batch[0][0].shape == (1, 1, 2))\n        assert (batch[0][1].shape == (1, 1))\n        assert (batch[0][2].shape == (1, 1, 1))\n        assert (batch[1] is None)\n    generator = ClusterNodeGenerator(G, clusters=2, q=1).flow(node_ids=['a', 'b', 'c', 'd'])\n    assert (len(generator) == 2)\n    for batch in generator:\n        assert (len(batch) == 2)\n        assert (batch[0][0].shape == (1, 2, 2))\n        assert (batch[0][1].shape == (1, 2))\n        assert (batch[0][2].shape == '???')\n        assert (batch[1] is None)", "ground_truth": "(1, 2, 2)", "quality_analysis": {"complexity_score": 7, "left_complexity": 2, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_786", "reponame": "stellargraph", "testpath": "tests/mapper/test_cluster_gcn_node_mapper.py", "testname": "test_cluster_gcn_node_mapper.py", "classname": null, "funcname": "test_cluster_weighted", "imports": ["from stellargraph.mapper import ClusterNodeGenerator, ClusterNodeSequence", "from stellargraph.core.graph import StellarGraph", "import pandas as pd", "import numpy as np", "import pytest", "from ..test_utils.graphs import example_graph_random"], "code": "def test_cluster_weighted():\n    G = create_stellargraph()\n    unweighted = ClusterNodeGenerator(G, clusters=1, q=1, weighted=False).flow(node_ids=['a', 'b', 'c', 'd'])\n    weighted = ClusterNodeGenerator(G, clusters=1, q=1, weighted=True).flow(node_ids=['a', 'b', 'c', 'd'])\n    assert (len(unweighted) == len(weighted) == 1)\n    (unweighted_features, _) = unweighted[0]\n    (weighted_features, _) = weighted[0]\n\n    def canonical(adj):\n        return np.sort(adj.ravel())\n    assert (not np.allclose(canonical(weighted_features[2]), canonical(unweighted_features[2])))", "masked_code": "def test_cluster_weighted():\n    G = create_stellargraph()\n    unweighted = ClusterNodeGenerator(G, clusters=1, q=1, weighted=False).flow(node_ids=['a', 'b', 'c', 'd'])\n    weighted = ClusterNodeGenerator(G, clusters=1, q=1, weighted=True).flow(node_ids=['a', 'b', 'c', 'd'])\n    assert (len(unweighted) == '???' == 1)\n    (unweighted_features, _) = unweighted[0]\n    (weighted_features, _) = weighted[0]\n\n    def canonical(adj):\n        return np.sort(adj.ravel())\n    assert (not np.allclose(canonical(weighted_features[2]), canonical(unweighted_features[2])))", "ground_truth": "len(weighted)", "quality_analysis": {"complexity_score": 8, "left_complexity": 4, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_787", "reponame": "stellargraph", "testpath": "tests/mapper/test_corrupted.py", "testname": "test_corrupted.py", "classname": null, "funcname": "test_corrupted_groups", "imports": ["import pytest", "import numpy as np", "from stellargraph.mapper import *", "from ..test_utils.graphs import example_graph_random"], "code": "@pytest.mark.parametrize('group_param', ['default', 'override'])\ndef test_corrupted_groups(group_param):\n    batch = [_data(0), _data(1), _data(2), _data(3, shape=(3, 10, 10, 6))]\n    groups = [[0], [2, 3]]\n    if (group_param == 'default'):\n        base_gen = DummyGenerator(groups, batch_dims=1, data=[batch])\n        corr_gen = CorruptedGenerator(base_gen)\n    else:\n        base_gen = DummyGenerator(None, batch_dims=1, data=[batch])\n        corr_gen = CorruptedGenerator(base_gen, corrupt_index_groups=groups)\n    corr_seq = corr_gen.flow()\n    assert (len(corr_seq) == 1)\n    ((corr0, corr2, corr3, *orig), targets) = corr_seq[0]\n    assert (len(orig) == len(batch))\n    for (o, b) in zip(orig, batch):\n        np.testing.assert_array_equal(o, b)\n    np.testing.assert_array_equal(_sorted_feats([corr0]), _sorted_feats([orig[0]]))\n    np.testing.assert_array_equal(_sorted_feats([corr2, corr3]), _sorted_feats([orig[2], orig[3]]))\n    assert np.any((_sorted_feats([corr2]) != _sorted_feats([orig[2]])))\n    assert np.any((_sorted_feats([corr3]) != _sorted_feats([orig[3]])))\n    np.testing.assert_array_equal(targets, [[1, 0], [1, 0], [1, 0]])", "masked_code": "@pytest.mark.parametrize('group_param', ['default', 'override'])\ndef test_corrupted_groups(group_param):\n    batch = [_data(0), _data(1), _data(2), _data(3, shape=(3, 10, 10, 6))]\n    groups = [[0], [2, 3]]\n    if (group_param == 'default'):\n        base_gen = DummyGenerator(groups, batch_dims=1, data=[batch])\n        corr_gen = CorruptedGenerator(base_gen)\n    else:\n        base_gen = DummyGenerator(None, batch_dims=1, data=[batch])\n        corr_gen = CorruptedGenerator(base_gen, corrupt_index_groups=groups)\n    corr_seq = corr_gen.flow()\n    assert (len(corr_seq) == 1)\n    ((corr0, corr2, corr3, *orig), targets) = corr_seq[0]\n    assert (len(orig) == '???')\n    for (o, b) in zip(orig, batch):\n        np.testing.assert_array_equal(o, b)\n    np.testing.assert_array_equal(_sorted_feats([corr0]), _sorted_feats([orig[0]]))\n    np.testing.assert_array_equal(_sorted_feats([corr2, corr3]), _sorted_feats([orig[2], orig[3]]))\n    assert np.any((_sorted_feats([corr2]) != _sorted_feats([orig[2]])))\n    assert np.any((_sorted_feats([corr3]) != _sorted_feats([orig[3]])))\n    np.testing.assert_array_equal(targets, [[1, 0], [1, 0], [1, 0]])", "ground_truth": "len(batch)", "quality_analysis": {"complexity_score": 8, "left_complexity": 4, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_788", "reponame": "stellargraph", "testpath": "tests/mapper/test_corrupted.py", "testname": "test_corrupted.py", "classname": null, "funcname": "test_corrupted_batching", "imports": ["import pytest", "import numpy as np", "from stellargraph.mapper import *", "from ..test_utils.graphs import example_graph_random"], "code": "@pytest.mark.parametrize('batch_dims', [1, 2, 3])\ndef test_corrupted_batching(batch_dims):\n    batch0_shape = (10, 4, 5, 6)\n    batch0 = [_data(0, shape=batch0_shape)]\n    batch1_shape = (5, 4, 5, 6)\n    batch1 = [_data(1, shape=batch1_shape)]\n    base_gen = DummyGenerator([[0]], batch_dims=batch_dims, data=[batch0, batch1])\n    corr_gen = CorruptedGenerator(base_gen)\n    corr_seq = corr_gen.flow()\n    assert (len(corr_seq) == 2)\n\n    def check(index, shape):\n        ((corr, orig), targets) = corr_seq[index]\n        assert (targets.shape == (*shape[:batch_dims], 2))\n        np.testing.assert_array_equal(targets[(..., 0)], 1)\n        np.testing.assert_array_equal(targets[(..., 1)], 0)\n    check(0, batch0_shape)\n    check(1, batch1_shape)", "masked_code": "@pytest.mark.parametrize('batch_dims', [1, 2, 3])\ndef test_corrupted_batching(batch_dims):\n    batch0_shape = (10, 4, 5, 6)\n    batch0 = [_data(0, shape=batch0_shape)]\n    batch1_shape = (5, 4, 5, 6)\n    batch1 = [_data(1, shape=batch1_shape)]\n    base_gen = DummyGenerator([[0]], batch_dims=batch_dims, data=[batch0, batch1])\n    corr_gen = CorruptedGenerator(base_gen)\n    corr_seq = corr_gen.flow()\n    assert (len(corr_seq) == 2)\n\n    def check(index, shape):\n        ((corr, orig), targets) = corr_seq[index]\n        assert (targets.shape == '???')\n        np.testing.assert_array_equal(targets[(..., 0)], 1)\n        np.testing.assert_array_equal(targets[(..., 1)], 0)\n    check(0, batch0_shape)\n    check(1, batch1_shape)", "ground_truth": "(*shape[:batch_dims], 2)", "quality_analysis": {"complexity_score": 5, "left_complexity": 2, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_789", "reponame": "stellargraph", "testpath": "tests/mapper/test_corrupted.py", "testname": "test_corrupted.py", "classname": null, "funcname": "test_corrupt_full_batch_generator", "imports": ["import pytest", "import numpy as np", "from stellargraph.mapper import *", "from ..test_utils.graphs import example_graph_random"], "code": "@pytest.mark.parametrize('num_nodes', [10, 20])\n@pytest.mark.parametrize('sparse', [True, False])\ndef test_corrupt_full_batch_generator(sparse, num_nodes):\n    G = example_graph_random(n_nodes=20)\n    generator = FullBatchNodeGenerator(G, sparse=sparse)\n    nodes = G.nodes()[:num_nodes]\n    gen = CorruptedGenerator(generator).flow(nodes)\n    ([shuffled_feats, features, *_], targets) = gen[0]\n    assert (features.shape == shuffled_feats.shape)\n    assert (not np.array_equal(features, shuffled_feats))\n    np.testing.assert_array_equal(_sorted_feats([shuffled_feats]), _sorted_feats([features]))\n    assert (targets.shape == (1, num_nodes, 2))", "masked_code": "@pytest.mark.parametrize('num_nodes', [10, 20])\n@pytest.mark.parametrize('sparse', [True, False])\ndef test_corrupt_full_batch_generator(sparse, num_nodes):\n    G = example_graph_random(n_nodes=20)\n    generator = FullBatchNodeGenerator(G, sparse=sparse)\n    nodes = G.nodes()[:num_nodes]\n    gen = CorruptedGenerator(generator).flow(nodes)\n    ([shuffled_feats, features, *_], targets) = gen[0]\n    assert (features.shape == '???')\n    assert (not np.array_equal(features, shuffled_feats))\n    np.testing.assert_array_equal(_sorted_feats([shuffled_feats]), _sorted_feats([features]))\n    assert (targets.shape == (1, num_nodes, 2))", "ground_truth": "shuffled_feats.shape", "quality_analysis": {"complexity_score": 4, "left_complexity": 2, "right_complexity": 2, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_790", "reponame": "stellargraph", "testpath": "tests/mapper/test_corrupted.py", "testname": "test_corrupted.py", "classname": null, "funcname": "test_corrupt_full_batch_generator", "imports": ["import pytest", "import numpy as np", "from stellargraph.mapper import *", "from ..test_utils.graphs import example_graph_random"], "code": "@pytest.mark.parametrize('num_nodes', [10, 20])\n@pytest.mark.parametrize('sparse', [True, False])\ndef test_corrupt_full_batch_generator(sparse, num_nodes):\n    G = example_graph_random(n_nodes=20)\n    generator = FullBatchNodeGenerator(G, sparse=sparse)\n    nodes = G.nodes()[:num_nodes]\n    gen = CorruptedGenerator(generator).flow(nodes)\n    ([shuffled_feats, features, *_], targets) = gen[0]\n    assert (features.shape == shuffled_feats.shape)\n    assert (not np.array_equal(features, shuffled_feats))\n    np.testing.assert_array_equal(_sorted_feats([shuffled_feats]), _sorted_feats([features]))\n    assert (targets.shape == (1, num_nodes, 2))", "masked_code": "@pytest.mark.parametrize('num_nodes', [10, 20])\n@pytest.mark.parametrize('sparse', [True, False])\ndef test_corrupt_full_batch_generator(sparse, num_nodes):\n    G = example_graph_random(n_nodes=20)\n    generator = FullBatchNodeGenerator(G, sparse=sparse)\n    nodes = G.nodes()[:num_nodes]\n    gen = CorruptedGenerator(generator).flow(nodes)\n    ([shuffled_feats, features, *_], targets) = gen[0]\n    assert (features.shape == shuffled_feats.shape)\n    assert (not np.array_equal(features, shuffled_feats))\n    np.testing.assert_array_equal(_sorted_feats([shuffled_feats]), _sorted_feats([features]))\n    assert (targets.shape == '???')", "ground_truth": "(1, num_nodes, 2)", "quality_analysis": {"complexity_score": 7, "left_complexity": 2, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_791", "reponame": "stellargraph", "testpath": "tests/mapper/test_corrupted.py", "testname": "test_corrupted.py", "classname": null, "funcname": "test_corrupt_graphsage_generator", "imports": ["import pytest", "import numpy as np", "from stellargraph.mapper import *", "from ..test_utils.graphs import example_graph_random"], "code": "@pytest.mark.parametrize('is_directed', [True, False])\ndef test_corrupt_graphsage_generator(is_directed):\n    G = example_graph_random(n_nodes=20, is_directed=is_directed)\n    if is_directed:\n        generator = DirectedGraphSAGENodeGenerator(G, batch_size=5, in_samples=[2, 3], out_samples=[4, 1])\n    else:\n        generator = GraphSAGENodeGenerator(G, batch_size=5, num_samples=[2, 3])\n    base_gen = generator.flow(G.nodes())\n    gen = CorruptedGenerator(generator).flow(G.nodes())\n    (x, targets) = gen[0]\n    (clean_feats, _) = base_gen[0]\n    shuffled_feats = x[:(len(x) // 2)]\n    features = x[(len(x) // 2):]\n    assert (len(clean_feats) == len(features))\n    assert (len(x) == (2 * len(clean_feats)))\n    assert (len(features) == len(shuffled_feats))\n    assert all(((f.shape == s.shape) for (f, s) in zip(features, shuffled_feats)))\n    assert (not all((np.array_equal(_sorted_feats([shuf]), _sorted_feats(feat)) for (shuf, feat) in zip(shuffled_feats, features))))\n    np.testing.assert_array_equal(_sorted_feats(shuffled_feats), _sorted_feats(features))", "masked_code": "@pytest.mark.parametrize('is_directed', [True, False])\ndef test_corrupt_graphsage_generator(is_directed):\n    G = example_graph_random(n_nodes=20, is_directed=is_directed)\n    if is_directed:\n        generator = DirectedGraphSAGENodeGenerator(G, batch_size=5, in_samples=[2, 3], out_samples=[4, 1])\n    else:\n        generator = GraphSAGENodeGenerator(G, batch_size=5, num_samples=[2, 3])\n    base_gen = generator.flow(G.nodes())\n    gen = CorruptedGenerator(generator).flow(G.nodes())\n    (x, targets) = gen[0]\n    (clean_feats, _) = base_gen[0]\n    shuffled_feats = x[:(len(x) // 2)]\n    features = x[(len(x) // 2):]\n    assert (len(clean_feats) == '???')\n    assert (len(x) == (2 * len(clean_feats)))\n    assert (len(features) == len(shuffled_feats))\n    assert all(((f.shape == s.shape) for (f, s) in zip(features, shuffled_feats)))\n    assert (not all((np.array_equal(_sorted_feats([shuf]), _sorted_feats(feat)) for (shuf, feat) in zip(shuffled_feats, features))))\n    np.testing.assert_array_equal(_sorted_feats(shuffled_feats), _sorted_feats(features))", "ground_truth": "len(features)", "quality_analysis": {"complexity_score": 8, "left_complexity": 4, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_792", "reponame": "stellargraph", "testpath": "tests/mapper/test_corrupted.py", "testname": "test_corrupted.py", "classname": null, "funcname": "test_corrupt_graphsage_generator", "imports": ["import pytest", "import numpy as np", "from stellargraph.mapper import *", "from ..test_utils.graphs import example_graph_random"], "code": "@pytest.mark.parametrize('is_directed', [True, False])\ndef test_corrupt_graphsage_generator(is_directed):\n    G = example_graph_random(n_nodes=20, is_directed=is_directed)\n    if is_directed:\n        generator = DirectedGraphSAGENodeGenerator(G, batch_size=5, in_samples=[2, 3], out_samples=[4, 1])\n    else:\n        generator = GraphSAGENodeGenerator(G, batch_size=5, num_samples=[2, 3])\n    base_gen = generator.flow(G.nodes())\n    gen = CorruptedGenerator(generator).flow(G.nodes())\n    (x, targets) = gen[0]\n    (clean_feats, _) = base_gen[0]\n    shuffled_feats = x[:(len(x) // 2)]\n    features = x[(len(x) // 2):]\n    assert (len(clean_feats) == len(features))\n    assert (len(x) == (2 * len(clean_feats)))\n    assert (len(features) == len(shuffled_feats))\n    assert all(((f.shape == s.shape) for (f, s) in zip(features, shuffled_feats)))\n    assert (not all((np.array_equal(_sorted_feats([shuf]), _sorted_feats(feat)) for (shuf, feat) in zip(shuffled_feats, features))))\n    np.testing.assert_array_equal(_sorted_feats(shuffled_feats), _sorted_feats(features))", "masked_code": "@pytest.mark.parametrize('is_directed', [True, False])\ndef test_corrupt_graphsage_generator(is_directed):\n    G = example_graph_random(n_nodes=20, is_directed=is_directed)\n    if is_directed:\n        generator = DirectedGraphSAGENodeGenerator(G, batch_size=5, in_samples=[2, 3], out_samples=[4, 1])\n    else:\n        generator = GraphSAGENodeGenerator(G, batch_size=5, num_samples=[2, 3])\n    base_gen = generator.flow(G.nodes())\n    gen = CorruptedGenerator(generator).flow(G.nodes())\n    (x, targets) = gen[0]\n    (clean_feats, _) = base_gen[0]\n    shuffled_feats = x[:(len(x) // 2)]\n    features = x[(len(x) // 2):]\n    assert (len(clean_feats) == len(features))\n    assert (len(x) == '???')\n    assert (len(features) == len(shuffled_feats))\n    assert all(((f.shape == s.shape) for (f, s) in zip(features, shuffled_feats)))\n    assert (not all((np.array_equal(_sorted_feats([shuf]), _sorted_feats(feat)) for (shuf, feat) in zip(shuffled_feats, features))))\n    np.testing.assert_array_equal(_sorted_feats(shuffled_feats), _sorted_feats(features))", "ground_truth": "(2 * len(clean_feats))", "quality_analysis": {"complexity_score": 11, "left_complexity": 4, "right_complexity": 7, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_793", "reponame": "stellargraph", "testpath": "tests/mapper/test_corrupted.py", "testname": "test_corrupted.py", "classname": null, "funcname": "test_corrupt_graphsage_generator", "imports": ["import pytest", "import numpy as np", "from stellargraph.mapper import *", "from ..test_utils.graphs import example_graph_random"], "code": "@pytest.mark.parametrize('is_directed', [True, False])\ndef test_corrupt_graphsage_generator(is_directed):\n    G = example_graph_random(n_nodes=20, is_directed=is_directed)\n    if is_directed:\n        generator = DirectedGraphSAGENodeGenerator(G, batch_size=5, in_samples=[2, 3], out_samples=[4, 1])\n    else:\n        generator = GraphSAGENodeGenerator(G, batch_size=5, num_samples=[2, 3])\n    base_gen = generator.flow(G.nodes())\n    gen = CorruptedGenerator(generator).flow(G.nodes())\n    (x, targets) = gen[0]\n    (clean_feats, _) = base_gen[0]\n    shuffled_feats = x[:(len(x) // 2)]\n    features = x[(len(x) // 2):]\n    assert (len(clean_feats) == len(features))\n    assert (len(x) == (2 * len(clean_feats)))\n    assert (len(features) == len(shuffled_feats))\n    assert all(((f.shape == s.shape) for (f, s) in zip(features, shuffled_feats)))\n    assert (not all((np.array_equal(_sorted_feats([shuf]), _sorted_feats(feat)) for (shuf, feat) in zip(shuffled_feats, features))))\n    np.testing.assert_array_equal(_sorted_feats(shuffled_feats), _sorted_feats(features))", "masked_code": "@pytest.mark.parametrize('is_directed', [True, False])\ndef test_corrupt_graphsage_generator(is_directed):\n    G = example_graph_random(n_nodes=20, is_directed=is_directed)\n    if is_directed:\n        generator = DirectedGraphSAGENodeGenerator(G, batch_size=5, in_samples=[2, 3], out_samples=[4, 1])\n    else:\n        generator = GraphSAGENodeGenerator(G, batch_size=5, num_samples=[2, 3])\n    base_gen = generator.flow(G.nodes())\n    gen = CorruptedGenerator(generator).flow(G.nodes())\n    (x, targets) = gen[0]\n    (clean_feats, _) = base_gen[0]\n    shuffled_feats = x[:(len(x) // 2)]\n    features = x[(len(x) // 2):]\n    assert (len(clean_feats) == len(features))\n    assert (len(x) == (2 * len(clean_feats)))\n    assert (len(features) == '???')\n    assert all(((f.shape == s.shape) for (f, s) in zip(features, shuffled_feats)))\n    assert (not all((np.array_equal(_sorted_feats([shuf]), _sorted_feats(feat)) for (shuf, feat) in zip(shuffled_feats, features))))\n    np.testing.assert_array_equal(_sorted_feats(shuffled_feats), _sorted_feats(features))", "ground_truth": "len(shuffled_feats)", "quality_analysis": {"complexity_score": 8, "left_complexity": 4, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_794", "reponame": "stellargraph", "testpath": "tests/mapper/test_directed_node_generator.py", "testname": "test_directed_node_generator.py", "classname": "TestDirectedNodeGenerator", "funcname": "test_two_hop", "imports": ["import networkx as nx", "import pandas as pd", "from stellargraph.mapper import DirectedGraphSAGENodeGenerator", "from stellargraph.core.graph import StellarDiGraph", "from ..test_utils.graphs import weighted_tree"], "code": "def test_two_hop(self):\n    g = create_simple_graph()\n    nodes = list(g.nodes())\n    gen = DirectedGraphSAGENodeGenerator(g, batch_size=g.number_of_nodes(), in_samples=[1, 1], out_samples=[1, 1])\n    flow = gen.flow(node_ids=nodes, shuffle=False)\n    node_ilocs = g.node_ids_to_ilocs(nodes)\n    features = gen.sample_features(node_ilocs, 0)\n    num_hops = 2\n    tree_len = ((2 ** (num_hops + 1)) - 1)\n    assert (len(features) == tree_len)\n    node_features = features[0]\n    assert (len(node_features) == len(nodes))\n    assert (node_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        assert (node_features[(idx, 0, 0)] == ((- 1.0) * node))\n    in_features = features[1]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == (- 1.0))\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 2.0))\n        else:\n            assert False\n    out_features = features[2]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == (- 3.0))\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False\n    in_features = features[3]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 1.0))\n        else:\n            assert False\n    in_features = features[4]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 3.0))\n        else:\n            assert False\n    out_features = features[5]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 1.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False\n    out_features = features[6]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 3.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False", "masked_code": "def test_two_hop(self):\n    g = create_simple_graph()\n    nodes = list(g.nodes())\n    gen = DirectedGraphSAGENodeGenerator(g, batch_size=g.number_of_nodes(), in_samples=[1, 1], out_samples=[1, 1])\n    flow = gen.flow(node_ids=nodes, shuffle=False)\n    node_ilocs = g.node_ids_to_ilocs(nodes)\n    features = gen.sample_features(node_ilocs, 0)\n    num_hops = 2\n    tree_len = ((2 ** (num_hops + 1)) - 1)\n    assert (len(features) == '???')\n    node_features = features[0]\n    assert (len(node_features) == len(nodes))\n    assert (node_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        assert (node_features[(idx, 0, 0)] == ((- 1.0) * node))\n    in_features = features[1]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == (- 1.0))\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 2.0))\n        else:\n            assert False\n    out_features = features[2]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == (- 3.0))\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False\n    in_features = features[3]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 1.0))\n        else:\n            assert False\n    in_features = features[4]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 3.0))\n        else:\n            assert False\n    out_features = features[5]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 1.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False\n    out_features = features[6]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 3.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False", "ground_truth": "tree_len", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_795", "reponame": "stellargraph", "testpath": "tests/mapper/test_directed_node_generator.py", "testname": "test_directed_node_generator.py", "classname": "TestDirectedNodeGenerator", "funcname": "test_two_hop", "imports": ["import networkx as nx", "import pandas as pd", "from stellargraph.mapper import DirectedGraphSAGENodeGenerator", "from stellargraph.core.graph import StellarDiGraph", "from ..test_utils.graphs import weighted_tree"], "code": "def test_two_hop(self):\n    g = create_simple_graph()\n    nodes = list(g.nodes())\n    gen = DirectedGraphSAGENodeGenerator(g, batch_size=g.number_of_nodes(), in_samples=[1, 1], out_samples=[1, 1])\n    flow = gen.flow(node_ids=nodes, shuffle=False)\n    node_ilocs = g.node_ids_to_ilocs(nodes)\n    features = gen.sample_features(node_ilocs, 0)\n    num_hops = 2\n    tree_len = ((2 ** (num_hops + 1)) - 1)\n    assert (len(features) == tree_len)\n    node_features = features[0]\n    assert (len(node_features) == len(nodes))\n    assert (node_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        assert (node_features[(idx, 0, 0)] == ((- 1.0) * node))\n    in_features = features[1]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == (- 1.0))\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 2.0))\n        else:\n            assert False\n    out_features = features[2]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == (- 3.0))\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False\n    in_features = features[3]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 1.0))\n        else:\n            assert False\n    in_features = features[4]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 3.0))\n        else:\n            assert False\n    out_features = features[5]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 1.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False\n    out_features = features[6]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 3.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False", "masked_code": "def test_two_hop(self):\n    g = create_simple_graph()\n    nodes = list(g.nodes())\n    gen = DirectedGraphSAGENodeGenerator(g, batch_size=g.number_of_nodes(), in_samples=[1, 1], out_samples=[1, 1])\n    flow = gen.flow(node_ids=nodes, shuffle=False)\n    node_ilocs = g.node_ids_to_ilocs(nodes)\n    features = gen.sample_features(node_ilocs, 0)\n    num_hops = 2\n    tree_len = ((2 ** (num_hops + 1)) - 1)\n    assert (len(features) == tree_len)\n    node_features = features[0]\n    assert (len(node_features) == '???')\n    assert (node_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        assert (node_features[(idx, 0, 0)] == ((- 1.0) * node))\n    in_features = features[1]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == (- 1.0))\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 2.0))\n        else:\n            assert False\n    out_features = features[2]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == (- 3.0))\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False\n    in_features = features[3]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 1.0))\n        else:\n            assert False\n    in_features = features[4]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 3.0))\n        else:\n            assert False\n    out_features = features[5]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 1.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False\n    out_features = features[6]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 3.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False", "ground_truth": "len(nodes)", "quality_analysis": {"complexity_score": 8, "left_complexity": 4, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_796", "reponame": "stellargraph", "testpath": "tests/mapper/test_directed_node_generator.py", "testname": "test_directed_node_generator.py", "classname": "TestDirectedNodeGenerator", "funcname": "test_two_hop", "imports": ["import networkx as nx", "import pandas as pd", "from stellargraph.mapper import DirectedGraphSAGENodeGenerator", "from stellargraph.core.graph import StellarDiGraph", "from ..test_utils.graphs import weighted_tree"], "code": "def test_two_hop(self):\n    g = create_simple_graph()\n    nodes = list(g.nodes())\n    gen = DirectedGraphSAGENodeGenerator(g, batch_size=g.number_of_nodes(), in_samples=[1, 1], out_samples=[1, 1])\n    flow = gen.flow(node_ids=nodes, shuffle=False)\n    node_ilocs = g.node_ids_to_ilocs(nodes)\n    features = gen.sample_features(node_ilocs, 0)\n    num_hops = 2\n    tree_len = ((2 ** (num_hops + 1)) - 1)\n    assert (len(features) == tree_len)\n    node_features = features[0]\n    assert (len(node_features) == len(nodes))\n    assert (node_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        assert (node_features[(idx, 0, 0)] == ((- 1.0) * node))\n    in_features = features[1]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == (- 1.0))\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 2.0))\n        else:\n            assert False\n    out_features = features[2]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == (- 3.0))\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False\n    in_features = features[3]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 1.0))\n        else:\n            assert False\n    in_features = features[4]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 3.0))\n        else:\n            assert False\n    out_features = features[5]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 1.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False\n    out_features = features[6]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 3.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False", "masked_code": "def test_two_hop(self):\n    g = create_simple_graph()\n    nodes = list(g.nodes())\n    gen = DirectedGraphSAGENodeGenerator(g, batch_size=g.number_of_nodes(), in_samples=[1, 1], out_samples=[1, 1])\n    flow = gen.flow(node_ids=nodes, shuffle=False)\n    node_ilocs = g.node_ids_to_ilocs(nodes)\n    features = gen.sample_features(node_ilocs, 0)\n    num_hops = 2\n    tree_len = ((2 ** (num_hops + 1)) - 1)\n    assert (len(features) == tree_len)\n    node_features = features[0]\n    assert (len(node_features) == len(nodes))\n    assert (node_features.shape == '???')\n    for (idx, node) in enumerate(nodes):\n        assert (node_features[(idx, 0, 0)] == ((- 1.0) * node))\n    in_features = features[1]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == (- 1.0))\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 2.0))\n        else:\n            assert False\n    out_features = features[2]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == (- 3.0))\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False\n    in_features = features[3]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 1.0))\n        else:\n            assert False\n    in_features = features[4]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 3.0))\n        else:\n            assert False\n    out_features = features[5]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 1.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False\n    out_features = features[6]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 3.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False", "ground_truth": "(len(nodes), 1, 1)", "quality_analysis": {"complexity_score": 10, "left_complexity": 2, "right_complexity": 8, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_797", "reponame": "stellargraph", "testpath": "tests/mapper/test_directed_node_generator.py", "testname": "test_directed_node_generator.py", "classname": "TestDirectedNodeGenerator", "funcname": "test_two_hop", "imports": ["import networkx as nx", "import pandas as pd", "from stellargraph.mapper import DirectedGraphSAGENodeGenerator", "from stellargraph.core.graph import StellarDiGraph", "from ..test_utils.graphs import weighted_tree"], "code": "def test_two_hop(self):\n    g = create_simple_graph()\n    nodes = list(g.nodes())\n    gen = DirectedGraphSAGENodeGenerator(g, batch_size=g.number_of_nodes(), in_samples=[1, 1], out_samples=[1, 1])\n    flow = gen.flow(node_ids=nodes, shuffle=False)\n    node_ilocs = g.node_ids_to_ilocs(nodes)\n    features = gen.sample_features(node_ilocs, 0)\n    num_hops = 2\n    tree_len = ((2 ** (num_hops + 1)) - 1)\n    assert (len(features) == tree_len)\n    node_features = features[0]\n    assert (len(node_features) == len(nodes))\n    assert (node_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        assert (node_features[(idx, 0, 0)] == ((- 1.0) * node))\n    in_features = features[1]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == (- 1.0))\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 2.0))\n        else:\n            assert False\n    out_features = features[2]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == (- 3.0))\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False\n    in_features = features[3]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 1.0))\n        else:\n            assert False\n    in_features = features[4]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 3.0))\n        else:\n            assert False\n    out_features = features[5]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 1.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False\n    out_features = features[6]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 3.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False", "masked_code": "def test_two_hop(self):\n    g = create_simple_graph()\n    nodes = list(g.nodes())\n    gen = DirectedGraphSAGENodeGenerator(g, batch_size=g.number_of_nodes(), in_samples=[1, 1], out_samples=[1, 1])\n    flow = gen.flow(node_ids=nodes, shuffle=False)\n    node_ilocs = g.node_ids_to_ilocs(nodes)\n    features = gen.sample_features(node_ilocs, 0)\n    num_hops = 2\n    tree_len = ((2 ** (num_hops + 1)) - 1)\n    assert (len(features) == tree_len)\n    node_features = features[0]\n    assert (len(node_features) == len(nodes))\n    assert (node_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        assert (node_features[(idx, 0, 0)] == ((- 1.0) * node))\n    in_features = features[1]\n    assert (in_features.shape == '???')\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == (- 1.0))\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 2.0))\n        else:\n            assert False\n    out_features = features[2]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == (- 3.0))\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False\n    in_features = features[3]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 1.0))\n        else:\n            assert False\n    in_features = features[4]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 3.0))\n        else:\n            assert False\n    out_features = features[5]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 1.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False\n    out_features = features[6]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 3.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False", "ground_truth": "(len(nodes), 1, 1)", "quality_analysis": {"complexity_score": 10, "left_complexity": 2, "right_complexity": 8, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_798", "reponame": "stellargraph", "testpath": "tests/mapper/test_directed_node_generator.py", "testname": "test_directed_node_generator.py", "classname": "TestDirectedNodeGenerator", "funcname": "test_two_hop", "imports": ["import networkx as nx", "import pandas as pd", "from stellargraph.mapper import DirectedGraphSAGENodeGenerator", "from stellargraph.core.graph import StellarDiGraph", "from ..test_utils.graphs import weighted_tree"], "code": "def test_two_hop(self):\n    g = create_simple_graph()\n    nodes = list(g.nodes())\n    gen = DirectedGraphSAGENodeGenerator(g, batch_size=g.number_of_nodes(), in_samples=[1, 1], out_samples=[1, 1])\n    flow = gen.flow(node_ids=nodes, shuffle=False)\n    node_ilocs = g.node_ids_to_ilocs(nodes)\n    features = gen.sample_features(node_ilocs, 0)\n    num_hops = 2\n    tree_len = ((2 ** (num_hops + 1)) - 1)\n    assert (len(features) == tree_len)\n    node_features = features[0]\n    assert (len(node_features) == len(nodes))\n    assert (node_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        assert (node_features[(idx, 0, 0)] == ((- 1.0) * node))\n    in_features = features[1]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == (- 1.0))\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 2.0))\n        else:\n            assert False\n    out_features = features[2]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == (- 3.0))\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False\n    in_features = features[3]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 1.0))\n        else:\n            assert False\n    in_features = features[4]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 3.0))\n        else:\n            assert False\n    out_features = features[5]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 1.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False\n    out_features = features[6]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 3.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False", "masked_code": "def test_two_hop(self):\n    g = create_simple_graph()\n    nodes = list(g.nodes())\n    gen = DirectedGraphSAGENodeGenerator(g, batch_size=g.number_of_nodes(), in_samples=[1, 1], out_samples=[1, 1])\n    flow = gen.flow(node_ids=nodes, shuffle=False)\n    node_ilocs = g.node_ids_to_ilocs(nodes)\n    features = gen.sample_features(node_ilocs, 0)\n    num_hops = 2\n    tree_len = ((2 ** (num_hops + 1)) - 1)\n    assert (len(features) == tree_len)\n    node_features = features[0]\n    assert (len(node_features) == len(nodes))\n    assert (node_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        assert (node_features[(idx, 0, 0)] == ((- 1.0) * node))\n    in_features = features[1]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == (- 1.0))\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 2.0))\n        else:\n            assert False\n    out_features = features[2]\n    assert (out_features.shape == '???')\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == (- 3.0))\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False\n    in_features = features[3]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 1.0))\n        else:\n            assert False\n    in_features = features[4]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 3.0))\n        else:\n            assert False\n    out_features = features[5]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 1.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False\n    out_features = features[6]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 3.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False", "ground_truth": "(len(nodes), 1, 1)", "quality_analysis": {"complexity_score": 10, "left_complexity": 2, "right_complexity": 8, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_799", "reponame": "stellargraph", "testpath": "tests/mapper/test_directed_node_generator.py", "testname": "test_directed_node_generator.py", "classname": "TestDirectedNodeGenerator", "funcname": "test_two_hop", "imports": ["import networkx as nx", "import pandas as pd", "from stellargraph.mapper import DirectedGraphSAGENodeGenerator", "from stellargraph.core.graph import StellarDiGraph", "from ..test_utils.graphs import weighted_tree"], "code": "def test_two_hop(self):\n    g = create_simple_graph()\n    nodes = list(g.nodes())\n    gen = DirectedGraphSAGENodeGenerator(g, batch_size=g.number_of_nodes(), in_samples=[1, 1], out_samples=[1, 1])\n    flow = gen.flow(node_ids=nodes, shuffle=False)\n    node_ilocs = g.node_ids_to_ilocs(nodes)\n    features = gen.sample_features(node_ilocs, 0)\n    num_hops = 2\n    tree_len = ((2 ** (num_hops + 1)) - 1)\n    assert (len(features) == tree_len)\n    node_features = features[0]\n    assert (len(node_features) == len(nodes))\n    assert (node_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        assert (node_features[(idx, 0, 0)] == ((- 1.0) * node))\n    in_features = features[1]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == (- 1.0))\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 2.0))\n        else:\n            assert False\n    out_features = features[2]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == (- 3.0))\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False\n    in_features = features[3]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 1.0))\n        else:\n            assert False\n    in_features = features[4]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 3.0))\n        else:\n            assert False\n    out_features = features[5]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 1.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False\n    out_features = features[6]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 3.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False", "masked_code": "def test_two_hop(self):\n    g = create_simple_graph()\n    nodes = list(g.nodes())\n    gen = DirectedGraphSAGENodeGenerator(g, batch_size=g.number_of_nodes(), in_samples=[1, 1], out_samples=[1, 1])\n    flow = gen.flow(node_ids=nodes, shuffle=False)\n    node_ilocs = g.node_ids_to_ilocs(nodes)\n    features = gen.sample_features(node_ilocs, 0)\n    num_hops = 2\n    tree_len = ((2 ** (num_hops + 1)) - 1)\n    assert (len(features) == tree_len)\n    node_features = features[0]\n    assert (len(node_features) == len(nodes))\n    assert (node_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        assert (node_features[(idx, 0, 0)] == ((- 1.0) * node))\n    in_features = features[1]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == (- 1.0))\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 2.0))\n        else:\n            assert False\n    out_features = features[2]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == (- 3.0))\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False\n    in_features = features[3]\n    assert (in_features.shape == '???')\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 1.0))\n        else:\n            assert False\n    in_features = features[4]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 3.0))\n        else:\n            assert False\n    out_features = features[5]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 1.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False\n    out_features = features[6]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 3.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False", "ground_truth": "(len(nodes), 1, 1)", "quality_analysis": {"complexity_score": 10, "left_complexity": 2, "right_complexity": 8, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_800", "reponame": "stellargraph", "testpath": "tests/mapper/test_directed_node_generator.py", "testname": "test_directed_node_generator.py", "classname": "TestDirectedNodeGenerator", "funcname": "test_two_hop", "imports": ["import networkx as nx", "import pandas as pd", "from stellargraph.mapper import DirectedGraphSAGENodeGenerator", "from stellargraph.core.graph import StellarDiGraph", "from ..test_utils.graphs import weighted_tree"], "code": "def test_two_hop(self):\n    g = create_simple_graph()\n    nodes = list(g.nodes())\n    gen = DirectedGraphSAGENodeGenerator(g, batch_size=g.number_of_nodes(), in_samples=[1, 1], out_samples=[1, 1])\n    flow = gen.flow(node_ids=nodes, shuffle=False)\n    node_ilocs = g.node_ids_to_ilocs(nodes)\n    features = gen.sample_features(node_ilocs, 0)\n    num_hops = 2\n    tree_len = ((2 ** (num_hops + 1)) - 1)\n    assert (len(features) == tree_len)\n    node_features = features[0]\n    assert (len(node_features) == len(nodes))\n    assert (node_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        assert (node_features[(idx, 0, 0)] == ((- 1.0) * node))\n    in_features = features[1]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == (- 1.0))\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 2.0))\n        else:\n            assert False\n    out_features = features[2]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == (- 3.0))\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False\n    in_features = features[3]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 1.0))\n        else:\n            assert False\n    in_features = features[4]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 3.0))\n        else:\n            assert False\n    out_features = features[5]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 1.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False\n    out_features = features[6]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 3.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False", "masked_code": "def test_two_hop(self):\n    g = create_simple_graph()\n    nodes = list(g.nodes())\n    gen = DirectedGraphSAGENodeGenerator(g, batch_size=g.number_of_nodes(), in_samples=[1, 1], out_samples=[1, 1])\n    flow = gen.flow(node_ids=nodes, shuffle=False)\n    node_ilocs = g.node_ids_to_ilocs(nodes)\n    features = gen.sample_features(node_ilocs, 0)\n    num_hops = 2\n    tree_len = ((2 ** (num_hops + 1)) - 1)\n    assert (len(features) == tree_len)\n    node_features = features[0]\n    assert (len(node_features) == len(nodes))\n    assert (node_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        assert (node_features[(idx, 0, 0)] == ((- 1.0) * node))\n    in_features = features[1]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == (- 1.0))\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 2.0))\n        else:\n            assert False\n    out_features = features[2]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == (- 3.0))\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False\n    in_features = features[3]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 1.0))\n        else:\n            assert False\n    in_features = features[4]\n    assert (in_features.shape == '???')\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 3.0))\n        else:\n            assert False\n    out_features = features[5]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 1.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False\n    out_features = features[6]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 3.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False", "ground_truth": "(len(nodes), 1, 1)", "quality_analysis": {"complexity_score": 10, "left_complexity": 2, "right_complexity": 8, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_801", "reponame": "stellargraph", "testpath": "tests/mapper/test_directed_node_generator.py", "testname": "test_directed_node_generator.py", "classname": "TestDirectedNodeGenerator", "funcname": "test_two_hop", "imports": ["import networkx as nx", "import pandas as pd", "from stellargraph.mapper import DirectedGraphSAGENodeGenerator", "from stellargraph.core.graph import StellarDiGraph", "from ..test_utils.graphs import weighted_tree"], "code": "def test_two_hop(self):\n    g = create_simple_graph()\n    nodes = list(g.nodes())\n    gen = DirectedGraphSAGENodeGenerator(g, batch_size=g.number_of_nodes(), in_samples=[1, 1], out_samples=[1, 1])\n    flow = gen.flow(node_ids=nodes, shuffle=False)\n    node_ilocs = g.node_ids_to_ilocs(nodes)\n    features = gen.sample_features(node_ilocs, 0)\n    num_hops = 2\n    tree_len = ((2 ** (num_hops + 1)) - 1)\n    assert (len(features) == tree_len)\n    node_features = features[0]\n    assert (len(node_features) == len(nodes))\n    assert (node_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        assert (node_features[(idx, 0, 0)] == ((- 1.0) * node))\n    in_features = features[1]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == (- 1.0))\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 2.0))\n        else:\n            assert False\n    out_features = features[2]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == (- 3.0))\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False\n    in_features = features[3]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 1.0))\n        else:\n            assert False\n    in_features = features[4]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 3.0))\n        else:\n            assert False\n    out_features = features[5]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 1.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False\n    out_features = features[6]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 3.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False", "masked_code": "def test_two_hop(self):\n    g = create_simple_graph()\n    nodes = list(g.nodes())\n    gen = DirectedGraphSAGENodeGenerator(g, batch_size=g.number_of_nodes(), in_samples=[1, 1], out_samples=[1, 1])\n    flow = gen.flow(node_ids=nodes, shuffle=False)\n    node_ilocs = g.node_ids_to_ilocs(nodes)\n    features = gen.sample_features(node_ilocs, 0)\n    num_hops = 2\n    tree_len = ((2 ** (num_hops + 1)) - 1)\n    assert (len(features) == tree_len)\n    node_features = features[0]\n    assert (len(node_features) == len(nodes))\n    assert (node_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        assert (node_features[(idx, 0, 0)] == ((- 1.0) * node))\n    in_features = features[1]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == (- 1.0))\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 2.0))\n        else:\n            assert False\n    out_features = features[2]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == (- 3.0))\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False\n    in_features = features[3]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 1.0))\n        else:\n            assert False\n    in_features = features[4]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 3.0))\n        else:\n            assert False\n    out_features = features[5]\n    assert (out_features.shape == '???')\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 1.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False\n    out_features = features[6]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 3.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False", "ground_truth": "(len(nodes), 1, 1)", "quality_analysis": {"complexity_score": 10, "left_complexity": 2, "right_complexity": 8, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_802", "reponame": "stellargraph", "testpath": "tests/mapper/test_directed_node_generator.py", "testname": "test_directed_node_generator.py", "classname": "TestDirectedNodeGenerator", "funcname": "test_two_hop", "imports": ["import networkx as nx", "import pandas as pd", "from stellargraph.mapper import DirectedGraphSAGENodeGenerator", "from stellargraph.core.graph import StellarDiGraph", "from ..test_utils.graphs import weighted_tree"], "code": "def test_two_hop(self):\n    g = create_simple_graph()\n    nodes = list(g.nodes())\n    gen = DirectedGraphSAGENodeGenerator(g, batch_size=g.number_of_nodes(), in_samples=[1, 1], out_samples=[1, 1])\n    flow = gen.flow(node_ids=nodes, shuffle=False)\n    node_ilocs = g.node_ids_to_ilocs(nodes)\n    features = gen.sample_features(node_ilocs, 0)\n    num_hops = 2\n    tree_len = ((2 ** (num_hops + 1)) - 1)\n    assert (len(features) == tree_len)\n    node_features = features[0]\n    assert (len(node_features) == len(nodes))\n    assert (node_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        assert (node_features[(idx, 0, 0)] == ((- 1.0) * node))\n    in_features = features[1]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == (- 1.0))\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 2.0))\n        else:\n            assert False\n    out_features = features[2]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == (- 3.0))\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False\n    in_features = features[3]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 1.0))\n        else:\n            assert False\n    in_features = features[4]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 3.0))\n        else:\n            assert False\n    out_features = features[5]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 1.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False\n    out_features = features[6]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 3.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False", "masked_code": "def test_two_hop(self):\n    g = create_simple_graph()\n    nodes = list(g.nodes())\n    gen = DirectedGraphSAGENodeGenerator(g, batch_size=g.number_of_nodes(), in_samples=[1, 1], out_samples=[1, 1])\n    flow = gen.flow(node_ids=nodes, shuffle=False)\n    node_ilocs = g.node_ids_to_ilocs(nodes)\n    features = gen.sample_features(node_ilocs, 0)\n    num_hops = 2\n    tree_len = ((2 ** (num_hops + 1)) - 1)\n    assert (len(features) == tree_len)\n    node_features = features[0]\n    assert (len(node_features) == len(nodes))\n    assert (node_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        assert (node_features[(idx, 0, 0)] == ((- 1.0) * node))\n    in_features = features[1]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == (- 1.0))\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 2.0))\n        else:\n            assert False\n    out_features = features[2]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == (- 3.0))\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False\n    in_features = features[3]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 1.0))\n        else:\n            assert False\n    in_features = features[4]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 3.0))\n        else:\n            assert False\n    out_features = features[5]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 1.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False\n    out_features = features[6]\n    assert (out_features.shape == '???')\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 3.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False", "ground_truth": "(len(nodes), 1, 1)", "quality_analysis": {"complexity_score": 10, "left_complexity": 2, "right_complexity": 8, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_803", "reponame": "stellargraph", "testpath": "tests/mapper/test_directed_node_generator.py", "testname": "test_directed_node_generator.py", "classname": "TestDirectedNodeGenerator", "funcname": "test_two_hop", "imports": ["import networkx as nx", "import pandas as pd", "from stellargraph.mapper import DirectedGraphSAGENodeGenerator", "from stellargraph.core.graph import StellarDiGraph", "from ..test_utils.graphs import weighted_tree"], "code": "def test_two_hop(self):\n    g = create_simple_graph()\n    nodes = list(g.nodes())\n    gen = DirectedGraphSAGENodeGenerator(g, batch_size=g.number_of_nodes(), in_samples=[1, 1], out_samples=[1, 1])\n    flow = gen.flow(node_ids=nodes, shuffle=False)\n    node_ilocs = g.node_ids_to_ilocs(nodes)\n    features = gen.sample_features(node_ilocs, 0)\n    num_hops = 2\n    tree_len = ((2 ** (num_hops + 1)) - 1)\n    assert (len(features) == tree_len)\n    node_features = features[0]\n    assert (len(node_features) == len(nodes))\n    assert (node_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        assert (node_features[(idx, 0, 0)] == ((- 1.0) * node))\n    in_features = features[1]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == (- 1.0))\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 2.0))\n        else:\n            assert False\n    out_features = features[2]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == (- 3.0))\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False\n    in_features = features[3]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 1.0))\n        else:\n            assert False\n    in_features = features[4]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 3.0))\n        else:\n            assert False\n    out_features = features[5]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 1.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False\n    out_features = features[6]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 3.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False", "masked_code": "def test_two_hop(self):\n    g = create_simple_graph()\n    nodes = list(g.nodes())\n    gen = DirectedGraphSAGENodeGenerator(g, batch_size=g.number_of_nodes(), in_samples=[1, 1], out_samples=[1, 1])\n    flow = gen.flow(node_ids=nodes, shuffle=False)\n    node_ilocs = g.node_ids_to_ilocs(nodes)\n    features = gen.sample_features(node_ilocs, 0)\n    num_hops = 2\n    tree_len = ((2 ** (num_hops + 1)) - 1)\n    assert (len(features) == tree_len)\n    node_features = features[0]\n    assert (len(node_features) == len(nodes))\n    assert (node_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        assert (node_features[(idx, 0, 0)] == '???')\n    in_features = features[1]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == (- 1.0))\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 2.0))\n        else:\n            assert False\n    out_features = features[2]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == (- 3.0))\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False\n    in_features = features[3]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 1.0))\n        else:\n            assert False\n    in_features = features[4]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 3.0))\n        else:\n            assert False\n    out_features = features[5]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 1.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False\n    out_features = features[6]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 3.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False", "ground_truth": "((- 1.0) * node)", "quality_analysis": {"complexity_score": 15, "left_complexity": 9, "right_complexity": 6, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_804", "reponame": "stellargraph", "testpath": "tests/mapper/test_directed_node_generator.py", "testname": "test_directed_node_generator.py", "classname": "TestDirectedNodeGenerator", "funcname": "test_two_hop", "imports": ["import networkx as nx", "import pandas as pd", "from stellargraph.mapper import DirectedGraphSAGENodeGenerator", "from stellargraph.core.graph import StellarDiGraph", "from ..test_utils.graphs import weighted_tree"], "code": "def test_two_hop(self):\n    g = create_simple_graph()\n    nodes = list(g.nodes())\n    gen = DirectedGraphSAGENodeGenerator(g, batch_size=g.number_of_nodes(), in_samples=[1, 1], out_samples=[1, 1])\n    flow = gen.flow(node_ids=nodes, shuffle=False)\n    node_ilocs = g.node_ids_to_ilocs(nodes)\n    features = gen.sample_features(node_ilocs, 0)\n    num_hops = 2\n    tree_len = ((2 ** (num_hops + 1)) - 1)\n    assert (len(features) == tree_len)\n    node_features = features[0]\n    assert (len(node_features) == len(nodes))\n    assert (node_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        assert (node_features[(idx, 0, 0)] == ((- 1.0) * node))\n    in_features = features[1]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == (- 1.0))\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 2.0))\n        else:\n            assert False\n    out_features = features[2]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == (- 3.0))\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False\n    in_features = features[3]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 1.0))\n        else:\n            assert False\n    in_features = features[4]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 3.0))\n        else:\n            assert False\n    out_features = features[5]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 1.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False\n    out_features = features[6]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 3.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False", "masked_code": "def test_two_hop(self):\n    g = create_simple_graph()\n    nodes = list(g.nodes())\n    gen = DirectedGraphSAGENodeGenerator(g, batch_size=g.number_of_nodes(), in_samples=[1, 1], out_samples=[1, 1])\n    flow = gen.flow(node_ids=nodes, shuffle=False)\n    node_ilocs = g.node_ids_to_ilocs(nodes)\n    features = gen.sample_features(node_ilocs, 0)\n    num_hops = 2\n    tree_len = ((2 ** (num_hops + 1)) - 1)\n    assert (len(features) == tree_len)\n    node_features = features[0]\n    assert (len(node_features) == len(nodes))\n    assert (node_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        assert (node_features[(idx, 0, 0)] == ((- 1.0) * node))\n    in_features = features[1]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == (- 1.0))\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 2.0))\n        else:\n            assert False\n    out_features = features[2]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == '???')\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == (- 3.0))\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False\n    in_features = features[3]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 1.0))\n        else:\n            assert False\n    in_features = features[4]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 3.0))\n        else:\n            assert False\n    out_features = features[5]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 1.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False\n    out_features = features[6]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 3.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False", "ground_truth": "(- 2.0)", "quality_analysis": {"complexity_score": 12, "left_complexity": 9, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_805", "reponame": "stellargraph", "testpath": "tests/mapper/test_directed_node_generator.py", "testname": "test_directed_node_generator.py", "classname": "TestDirectedNodeGenerator", "funcname": "test_two_hop", "imports": ["import networkx as nx", "import pandas as pd", "from stellargraph.mapper import DirectedGraphSAGENodeGenerator", "from stellargraph.core.graph import StellarDiGraph", "from ..test_utils.graphs import weighted_tree"], "code": "def test_two_hop(self):\n    g = create_simple_graph()\n    nodes = list(g.nodes())\n    gen = DirectedGraphSAGENodeGenerator(g, batch_size=g.number_of_nodes(), in_samples=[1, 1], out_samples=[1, 1])\n    flow = gen.flow(node_ids=nodes, shuffle=False)\n    node_ilocs = g.node_ids_to_ilocs(nodes)\n    features = gen.sample_features(node_ilocs, 0)\n    num_hops = 2\n    tree_len = ((2 ** (num_hops + 1)) - 1)\n    assert (len(features) == tree_len)\n    node_features = features[0]\n    assert (len(node_features) == len(nodes))\n    assert (node_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        assert (node_features[(idx, 0, 0)] == ((- 1.0) * node))\n    in_features = features[1]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == (- 1.0))\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 2.0))\n        else:\n            assert False\n    out_features = features[2]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == (- 3.0))\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False\n    in_features = features[3]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 1.0))\n        else:\n            assert False\n    in_features = features[4]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 3.0))\n        else:\n            assert False\n    out_features = features[5]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 1.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False\n    out_features = features[6]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 3.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False", "masked_code": "def test_two_hop(self):\n    g = create_simple_graph()\n    nodes = list(g.nodes())\n    gen = DirectedGraphSAGENodeGenerator(g, batch_size=g.number_of_nodes(), in_samples=[1, 1], out_samples=[1, 1])\n    flow = gen.flow(node_ids=nodes, shuffle=False)\n    node_ilocs = g.node_ids_to_ilocs(nodes)\n    features = gen.sample_features(node_ilocs, 0)\n    num_hops = 2\n    tree_len = ((2 ** (num_hops + 1)) - 1)\n    assert (len(features) == tree_len)\n    node_features = features[0]\n    assert (len(node_features) == len(nodes))\n    assert (node_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        assert (node_features[(idx, 0, 0)] == ((- 1.0) * node))\n    in_features = features[1]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == (- 1.0))\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 2.0))\n        else:\n            assert False\n    out_features = features[2]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == (- 3.0))\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False\n    in_features = features[3]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 1.0))\n        else:\n            assert False\n    in_features = features[4]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 3.0))\n        else:\n            assert False\n    out_features = features[5]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == '???')\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False\n    out_features = features[6]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 3.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False", "ground_truth": "(- 1.0)", "quality_analysis": {"complexity_score": 12, "left_complexity": 9, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_806", "reponame": "stellargraph", "testpath": "tests/mapper/test_directed_node_generator.py", "testname": "test_directed_node_generator.py", "classname": "TestDirectedNodeGenerator", "funcname": "test_two_hop", "imports": ["import networkx as nx", "import pandas as pd", "from stellargraph.mapper import DirectedGraphSAGENodeGenerator", "from stellargraph.core.graph import StellarDiGraph", "from ..test_utils.graphs import weighted_tree"], "code": "def test_two_hop(self):\n    g = create_simple_graph()\n    nodes = list(g.nodes())\n    gen = DirectedGraphSAGENodeGenerator(g, batch_size=g.number_of_nodes(), in_samples=[1, 1], out_samples=[1, 1])\n    flow = gen.flow(node_ids=nodes, shuffle=False)\n    node_ilocs = g.node_ids_to_ilocs(nodes)\n    features = gen.sample_features(node_ilocs, 0)\n    num_hops = 2\n    tree_len = ((2 ** (num_hops + 1)) - 1)\n    assert (len(features) == tree_len)\n    node_features = features[0]\n    assert (len(node_features) == len(nodes))\n    assert (node_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        assert (node_features[(idx, 0, 0)] == ((- 1.0) * node))\n    in_features = features[1]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == (- 1.0))\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 2.0))\n        else:\n            assert False\n    out_features = features[2]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == (- 3.0))\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False\n    in_features = features[3]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 1.0))\n        else:\n            assert False\n    in_features = features[4]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 3.0))\n        else:\n            assert False\n    out_features = features[5]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 1.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False\n    out_features = features[6]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 3.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False", "masked_code": "def test_two_hop(self):\n    g = create_simple_graph()\n    nodes = list(g.nodes())\n    gen = DirectedGraphSAGENodeGenerator(g, batch_size=g.number_of_nodes(), in_samples=[1, 1], out_samples=[1, 1])\n    flow = gen.flow(node_ids=nodes, shuffle=False)\n    node_ilocs = g.node_ids_to_ilocs(nodes)\n    features = gen.sample_features(node_ilocs, 0)\n    num_hops = 2\n    tree_len = ((2 ** (num_hops + 1)) - 1)\n    assert (len(features) == tree_len)\n    node_features = features[0]\n    assert (len(node_features) == len(nodes))\n    assert (node_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        assert (node_features[(idx, 0, 0)] == ((- 1.0) * node))\n    in_features = features[1]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == (- 1.0))\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 2.0))\n        else:\n            assert False\n    out_features = features[2]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == (- 3.0))\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False\n    in_features = features[3]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 1.0))\n        else:\n            assert False\n    in_features = features[4]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 3.0))\n        else:\n            assert False\n    out_features = features[5]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 1.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False\n    out_features = features[6]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == '???')\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False", "ground_truth": "(- 3.0)", "quality_analysis": {"complexity_score": 12, "left_complexity": 9, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_807", "reponame": "stellargraph", "testpath": "tests/mapper/test_directed_node_generator.py", "testname": "test_directed_node_generator.py", "classname": "TestDirectedNodeGenerator", "funcname": "test_two_hop", "imports": ["import networkx as nx", "import pandas as pd", "from stellargraph.mapper import DirectedGraphSAGENodeGenerator", "from stellargraph.core.graph import StellarDiGraph", "from ..test_utils.graphs import weighted_tree"], "code": "def test_two_hop(self):\n    g = create_simple_graph()\n    nodes = list(g.nodes())\n    gen = DirectedGraphSAGENodeGenerator(g, batch_size=g.number_of_nodes(), in_samples=[1, 1], out_samples=[1, 1])\n    flow = gen.flow(node_ids=nodes, shuffle=False)\n    node_ilocs = g.node_ids_to_ilocs(nodes)\n    features = gen.sample_features(node_ilocs, 0)\n    num_hops = 2\n    tree_len = ((2 ** (num_hops + 1)) - 1)\n    assert (len(features) == tree_len)\n    node_features = features[0]\n    assert (len(node_features) == len(nodes))\n    assert (node_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        assert (node_features[(idx, 0, 0)] == ((- 1.0) * node))\n    in_features = features[1]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == (- 1.0))\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 2.0))\n        else:\n            assert False\n    out_features = features[2]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == (- 3.0))\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False\n    in_features = features[3]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 1.0))\n        else:\n            assert False\n    in_features = features[4]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 3.0))\n        else:\n            assert False\n    out_features = features[5]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 1.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False\n    out_features = features[6]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 3.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False", "masked_code": "def test_two_hop(self):\n    g = create_simple_graph()\n    nodes = list(g.nodes())\n    gen = DirectedGraphSAGENodeGenerator(g, batch_size=g.number_of_nodes(), in_samples=[1, 1], out_samples=[1, 1])\n    flow = gen.flow(node_ids=nodes, shuffle=False)\n    node_ilocs = g.node_ids_to_ilocs(nodes)\n    features = gen.sample_features(node_ilocs, 0)\n    num_hops = 2\n    tree_len = ((2 ** (num_hops + 1)) - 1)\n    assert (len(features) == tree_len)\n    node_features = features[0]\n    assert (len(node_features) == len(nodes))\n    assert (node_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        assert (node_features[(idx, 0, 0)] == ((- 1.0) * node))\n    in_features = features[1]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == '???')\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 2.0))\n        else:\n            assert False\n    out_features = features[2]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == (- 3.0))\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False\n    in_features = features[3]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 1.0))\n        else:\n            assert False\n    in_features = features[4]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 3.0))\n        else:\n            assert False\n    out_features = features[5]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 1.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False\n    out_features = features[6]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 3.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False", "ground_truth": "(- 1.0)", "quality_analysis": {"complexity_score": 12, "left_complexity": 9, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_808", "reponame": "stellargraph", "testpath": "tests/mapper/test_directed_node_generator.py", "testname": "test_directed_node_generator.py", "classname": "TestDirectedNodeGenerator", "funcname": "test_two_hop", "imports": ["import networkx as nx", "import pandas as pd", "from stellargraph.mapper import DirectedGraphSAGENodeGenerator", "from stellargraph.core.graph import StellarDiGraph", "from ..test_utils.graphs import weighted_tree"], "code": "def test_two_hop(self):\n    g = create_simple_graph()\n    nodes = list(g.nodes())\n    gen = DirectedGraphSAGENodeGenerator(g, batch_size=g.number_of_nodes(), in_samples=[1, 1], out_samples=[1, 1])\n    flow = gen.flow(node_ids=nodes, shuffle=False)\n    node_ilocs = g.node_ids_to_ilocs(nodes)\n    features = gen.sample_features(node_ilocs, 0)\n    num_hops = 2\n    tree_len = ((2 ** (num_hops + 1)) - 1)\n    assert (len(features) == tree_len)\n    node_features = features[0]\n    assert (len(node_features) == len(nodes))\n    assert (node_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        assert (node_features[(idx, 0, 0)] == ((- 1.0) * node))\n    in_features = features[1]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == (- 1.0))\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 2.0))\n        else:\n            assert False\n    out_features = features[2]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == (- 3.0))\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False\n    in_features = features[3]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 1.0))\n        else:\n            assert False\n    in_features = features[4]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 3.0))\n        else:\n            assert False\n    out_features = features[5]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 1.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False\n    out_features = features[6]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 3.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False", "masked_code": "def test_two_hop(self):\n    g = create_simple_graph()\n    nodes = list(g.nodes())\n    gen = DirectedGraphSAGENodeGenerator(g, batch_size=g.number_of_nodes(), in_samples=[1, 1], out_samples=[1, 1])\n    flow = gen.flow(node_ids=nodes, shuffle=False)\n    node_ilocs = g.node_ids_to_ilocs(nodes)\n    features = gen.sample_features(node_ilocs, 0)\n    num_hops = 2\n    tree_len = ((2 ** (num_hops + 1)) - 1)\n    assert (len(features) == tree_len)\n    node_features = features[0]\n    assert (len(node_features) == len(nodes))\n    assert (node_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        assert (node_features[(idx, 0, 0)] == ((- 1.0) * node))\n    in_features = features[1]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == (- 1.0))\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 2.0))\n        else:\n            assert False\n    out_features = features[2]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == '???')\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False\n    in_features = features[3]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 1.0))\n        else:\n            assert False\n    in_features = features[4]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 3.0))\n        else:\n            assert False\n    out_features = features[5]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 1.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False\n    out_features = features[6]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 3.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False", "ground_truth": "(- 3.0)", "quality_analysis": {"complexity_score": 12, "left_complexity": 9, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_809", "reponame": "stellargraph", "testpath": "tests/mapper/test_directed_node_generator.py", "testname": "test_directed_node_generator.py", "classname": "TestDirectedNodeGenerator", "funcname": "test_two_hop", "imports": ["import networkx as nx", "import pandas as pd", "from stellargraph.mapper import DirectedGraphSAGENodeGenerator", "from stellargraph.core.graph import StellarDiGraph", "from ..test_utils.graphs import weighted_tree"], "code": "def test_two_hop(self):\n    g = create_simple_graph()\n    nodes = list(g.nodes())\n    gen = DirectedGraphSAGENodeGenerator(g, batch_size=g.number_of_nodes(), in_samples=[1, 1], out_samples=[1, 1])\n    flow = gen.flow(node_ids=nodes, shuffle=False)\n    node_ilocs = g.node_ids_to_ilocs(nodes)\n    features = gen.sample_features(node_ilocs, 0)\n    num_hops = 2\n    tree_len = ((2 ** (num_hops + 1)) - 1)\n    assert (len(features) == tree_len)\n    node_features = features[0]\n    assert (len(node_features) == len(nodes))\n    assert (node_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        assert (node_features[(idx, 0, 0)] == ((- 1.0) * node))\n    in_features = features[1]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == (- 1.0))\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 2.0))\n        else:\n            assert False\n    out_features = features[2]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == (- 3.0))\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False\n    in_features = features[3]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 1.0))\n        else:\n            assert False\n    in_features = features[4]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 3.0))\n        else:\n            assert False\n    out_features = features[5]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 1.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False\n    out_features = features[6]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 3.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False", "masked_code": "def test_two_hop(self):\n    g = create_simple_graph()\n    nodes = list(g.nodes())\n    gen = DirectedGraphSAGENodeGenerator(g, batch_size=g.number_of_nodes(), in_samples=[1, 1], out_samples=[1, 1])\n    flow = gen.flow(node_ids=nodes, shuffle=False)\n    node_ilocs = g.node_ids_to_ilocs(nodes)\n    features = gen.sample_features(node_ilocs, 0)\n    num_hops = 2\n    tree_len = ((2 ** (num_hops + 1)) - 1)\n    assert (len(features) == tree_len)\n    node_features = features[0]\n    assert (len(node_features) == len(nodes))\n    assert (node_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        assert (node_features[(idx, 0, 0)] == ((- 1.0) * node))\n    in_features = features[1]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == (- 1.0))\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 2.0))\n        else:\n            assert False\n    out_features = features[2]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == (- 3.0))\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False\n    in_features = features[3]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 1.0))\n        else:\n            assert False\n    in_features = features[4]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == '???')\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 3.0))\n        else:\n            assert False\n    out_features = features[5]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 1.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False\n    out_features = features[6]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 3.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False", "ground_truth": "(- 2.0)", "quality_analysis": {"complexity_score": 12, "left_complexity": 9, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_810", "reponame": "stellargraph", "testpath": "tests/mapper/test_directed_node_generator.py", "testname": "test_directed_node_generator.py", "classname": "TestDirectedNodeGenerator", "funcname": "test_two_hop", "imports": ["import networkx as nx", "import pandas as pd", "from stellargraph.mapper import DirectedGraphSAGENodeGenerator", "from stellargraph.core.graph import StellarDiGraph", "from ..test_utils.graphs import weighted_tree"], "code": "def test_two_hop(self):\n    g = create_simple_graph()\n    nodes = list(g.nodes())\n    gen = DirectedGraphSAGENodeGenerator(g, batch_size=g.number_of_nodes(), in_samples=[1, 1], out_samples=[1, 1])\n    flow = gen.flow(node_ids=nodes, shuffle=False)\n    node_ilocs = g.node_ids_to_ilocs(nodes)\n    features = gen.sample_features(node_ilocs, 0)\n    num_hops = 2\n    tree_len = ((2 ** (num_hops + 1)) - 1)\n    assert (len(features) == tree_len)\n    node_features = features[0]\n    assert (len(node_features) == len(nodes))\n    assert (node_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        assert (node_features[(idx, 0, 0)] == ((- 1.0) * node))\n    in_features = features[1]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == (- 1.0))\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 2.0))\n        else:\n            assert False\n    out_features = features[2]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == (- 3.0))\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False\n    in_features = features[3]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 1.0))\n        else:\n            assert False\n    in_features = features[4]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 3.0))\n        else:\n            assert False\n    out_features = features[5]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 1.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False\n    out_features = features[6]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 3.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False", "masked_code": "def test_two_hop(self):\n    g = create_simple_graph()\n    nodes = list(g.nodes())\n    gen = DirectedGraphSAGENodeGenerator(g, batch_size=g.number_of_nodes(), in_samples=[1, 1], out_samples=[1, 1])\n    flow = gen.flow(node_ids=nodes, shuffle=False)\n    node_ilocs = g.node_ids_to_ilocs(nodes)\n    features = gen.sample_features(node_ilocs, 0)\n    num_hops = 2\n    tree_len = ((2 ** (num_hops + 1)) - 1)\n    assert (len(features) == tree_len)\n    node_features = features[0]\n    assert (len(node_features) == len(nodes))\n    assert (node_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        assert (node_features[(idx, 0, 0)] == ((- 1.0) * node))\n    in_features = features[1]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == (- 1.0))\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 2.0))\n        else:\n            assert False\n    out_features = features[2]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == (- 3.0))\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False\n    in_features = features[3]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 1.0))\n        else:\n            assert False\n    in_features = features[4]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 3.0))\n        else:\n            assert False\n    out_features = features[5]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 1.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == '???')\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False\n    out_features = features[6]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 3.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False", "ground_truth": "(- 2.0)", "quality_analysis": {"complexity_score": 12, "left_complexity": 9, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_811", "reponame": "stellargraph", "testpath": "tests/mapper/test_directed_node_generator.py", "testname": "test_directed_node_generator.py", "classname": "TestDirectedNodeGenerator", "funcname": "test_two_hop", "imports": ["import networkx as nx", "import pandas as pd", "from stellargraph.mapper import DirectedGraphSAGENodeGenerator", "from stellargraph.core.graph import StellarDiGraph", "from ..test_utils.graphs import weighted_tree"], "code": "def test_two_hop(self):\n    g = create_simple_graph()\n    nodes = list(g.nodes())\n    gen = DirectedGraphSAGENodeGenerator(g, batch_size=g.number_of_nodes(), in_samples=[1, 1], out_samples=[1, 1])\n    flow = gen.flow(node_ids=nodes, shuffle=False)\n    node_ilocs = g.node_ids_to_ilocs(nodes)\n    features = gen.sample_features(node_ilocs, 0)\n    num_hops = 2\n    tree_len = ((2 ** (num_hops + 1)) - 1)\n    assert (len(features) == tree_len)\n    node_features = features[0]\n    assert (len(node_features) == len(nodes))\n    assert (node_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        assert (node_features[(idx, 0, 0)] == ((- 1.0) * node))\n    in_features = features[1]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == (- 1.0))\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 2.0))\n        else:\n            assert False\n    out_features = features[2]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == (- 3.0))\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False\n    in_features = features[3]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 1.0))\n        else:\n            assert False\n    in_features = features[4]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 3.0))\n        else:\n            assert False\n    out_features = features[5]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 1.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False\n    out_features = features[6]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 3.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False", "masked_code": "def test_two_hop(self):\n    g = create_simple_graph()\n    nodes = list(g.nodes())\n    gen = DirectedGraphSAGENodeGenerator(g, batch_size=g.number_of_nodes(), in_samples=[1, 1], out_samples=[1, 1])\n    flow = gen.flow(node_ids=nodes, shuffle=False)\n    node_ilocs = g.node_ids_to_ilocs(nodes)\n    features = gen.sample_features(node_ilocs, 0)\n    num_hops = 2\n    tree_len = ((2 ** (num_hops + 1)) - 1)\n    assert (len(features) == tree_len)\n    node_features = features[0]\n    assert (len(node_features) == len(nodes))\n    assert (node_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        assert (node_features[(idx, 0, 0)] == ((- 1.0) * node))\n    in_features = features[1]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == (- 1.0))\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == '???')\n        else:\n            assert False\n    out_features = features[2]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == (- 3.0))\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False\n    in_features = features[3]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 1.0))\n        else:\n            assert False\n    in_features = features[4]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 3.0))\n        else:\n            assert False\n    out_features = features[5]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 1.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False\n    out_features = features[6]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 3.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False", "ground_truth": "(- 2.0)", "quality_analysis": {"complexity_score": 12, "left_complexity": 9, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_812", "reponame": "stellargraph", "testpath": "tests/mapper/test_directed_node_generator.py", "testname": "test_directed_node_generator.py", "classname": "TestDirectedNodeGenerator", "funcname": "test_two_hop", "imports": ["import networkx as nx", "import pandas as pd", "from stellargraph.mapper import DirectedGraphSAGENodeGenerator", "from stellargraph.core.graph import StellarDiGraph", "from ..test_utils.graphs import weighted_tree"], "code": "def test_two_hop(self):\n    g = create_simple_graph()\n    nodes = list(g.nodes())\n    gen = DirectedGraphSAGENodeGenerator(g, batch_size=g.number_of_nodes(), in_samples=[1, 1], out_samples=[1, 1])\n    flow = gen.flow(node_ids=nodes, shuffle=False)\n    node_ilocs = g.node_ids_to_ilocs(nodes)\n    features = gen.sample_features(node_ilocs, 0)\n    num_hops = 2\n    tree_len = ((2 ** (num_hops + 1)) - 1)\n    assert (len(features) == tree_len)\n    node_features = features[0]\n    assert (len(node_features) == len(nodes))\n    assert (node_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        assert (node_features[(idx, 0, 0)] == ((- 1.0) * node))\n    in_features = features[1]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == (- 1.0))\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 2.0))\n        else:\n            assert False\n    out_features = features[2]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == (- 3.0))\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False\n    in_features = features[3]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 1.0))\n        else:\n            assert False\n    in_features = features[4]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 3.0))\n        else:\n            assert False\n    out_features = features[5]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 1.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False\n    out_features = features[6]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 3.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False", "masked_code": "def test_two_hop(self):\n    g = create_simple_graph()\n    nodes = list(g.nodes())\n    gen = DirectedGraphSAGENodeGenerator(g, batch_size=g.number_of_nodes(), in_samples=[1, 1], out_samples=[1, 1])\n    flow = gen.flow(node_ids=nodes, shuffle=False)\n    node_ilocs = g.node_ids_to_ilocs(nodes)\n    features = gen.sample_features(node_ilocs, 0)\n    num_hops = 2\n    tree_len = ((2 ** (num_hops + 1)) - 1)\n    assert (len(features) == tree_len)\n    node_features = features[0]\n    assert (len(node_features) == len(nodes))\n    assert (node_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        assert (node_features[(idx, 0, 0)] == ((- 1.0) * node))\n    in_features = features[1]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == (- 1.0))\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 2.0))\n        else:\n            assert False\n    out_features = features[2]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == (- 3.0))\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False\n    in_features = features[3]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == '???')\n        else:\n            assert False\n    in_features = features[4]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 3.0))\n        else:\n            assert False\n    out_features = features[5]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 1.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False\n    out_features = features[6]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 3.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False", "ground_truth": "(- 1.0)", "quality_analysis": {"complexity_score": 12, "left_complexity": 9, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_813", "reponame": "stellargraph", "testpath": "tests/mapper/test_directed_node_generator.py", "testname": "test_directed_node_generator.py", "classname": "TestDirectedNodeGenerator", "funcname": "test_two_hop", "imports": ["import networkx as nx", "import pandas as pd", "from stellargraph.mapper import DirectedGraphSAGENodeGenerator", "from stellargraph.core.graph import StellarDiGraph", "from ..test_utils.graphs import weighted_tree"], "code": "def test_two_hop(self):\n    g = create_simple_graph()\n    nodes = list(g.nodes())\n    gen = DirectedGraphSAGENodeGenerator(g, batch_size=g.number_of_nodes(), in_samples=[1, 1], out_samples=[1, 1])\n    flow = gen.flow(node_ids=nodes, shuffle=False)\n    node_ilocs = g.node_ids_to_ilocs(nodes)\n    features = gen.sample_features(node_ilocs, 0)\n    num_hops = 2\n    tree_len = ((2 ** (num_hops + 1)) - 1)\n    assert (len(features) == tree_len)\n    node_features = features[0]\n    assert (len(node_features) == len(nodes))\n    assert (node_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        assert (node_features[(idx, 0, 0)] == ((- 1.0) * node))\n    in_features = features[1]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == (- 1.0))\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 2.0))\n        else:\n            assert False\n    out_features = features[2]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == (- 3.0))\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False\n    in_features = features[3]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 1.0))\n        else:\n            assert False\n    in_features = features[4]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 3.0))\n        else:\n            assert False\n    out_features = features[5]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 1.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False\n    out_features = features[6]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 3.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False", "masked_code": "def test_two_hop(self):\n    g = create_simple_graph()\n    nodes = list(g.nodes())\n    gen = DirectedGraphSAGENodeGenerator(g, batch_size=g.number_of_nodes(), in_samples=[1, 1], out_samples=[1, 1])\n    flow = gen.flow(node_ids=nodes, shuffle=False)\n    node_ilocs = g.node_ids_to_ilocs(nodes)\n    features = gen.sample_features(node_ilocs, 0)\n    num_hops = 2\n    tree_len = ((2 ** (num_hops + 1)) - 1)\n    assert (len(features) == tree_len)\n    node_features = features[0]\n    assert (len(node_features) == len(nodes))\n    assert (node_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        assert (node_features[(idx, 0, 0)] == ((- 1.0) * node))\n    in_features = features[1]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == (- 1.0))\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 2.0))\n        else:\n            assert False\n    out_features = features[2]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == (- 3.0))\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False\n    in_features = features[3]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == (- 1.0))\n        else:\n            assert False\n    in_features = features[4]\n    assert (in_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (in_features[(idx, 0, 0)] == 0.0)\n        elif (node == 2):\n            assert (in_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 3):\n            assert (in_features[(idx, 0, 0)] == '???')\n        else:\n            assert False\n    out_features = features[5]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 1.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == (- 2.0))\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False\n    out_features = features[6]\n    assert (out_features.shape == (len(nodes), 1, 1))\n    for (idx, node) in enumerate(nodes):\n        if (node == 1):\n            assert (out_features[(idx, 0, 0)] == (- 3.0))\n        elif (node == 2):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        elif (node == 3):\n            assert (out_features[(idx, 0, 0)] == 0.0)\n        else:\n            assert False", "ground_truth": "(- 3.0)", "quality_analysis": {"complexity_score": 12, "left_complexity": 9, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_814", "reponame": "stellargraph", "testpath": "tests/mapper/test_full_batch_generators.py", "testname": "test_full_batch_generators.py", "classname": "Test_FullBatchNodeGenerator", "funcname": "test_generator_constructor", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper import FullBatchGenerator, FullBatchLinkGenerator, FullBatchNodeGenerator", "import networkx as nx", "import numpy as np", "import random", "import pytest", "import pandas as pd", "import scipy.sparse as sps", "from ..test_utils.graphs import create_graph_features, example_graph_random, example_hin_1, example_graph"], "code": "def test_generator_constructor(self):\n    generator = FullBatchNodeGenerator(self.G)\n    assert (generator.Aadj.shape == (self.N, self.N))\n    assert (generator.features.shape == (self.N, self.n_feat))", "masked_code": "def test_generator_constructor(self):\n    generator = FullBatchNodeGenerator(self.G)\n    assert (generator.Aadj.shape == '???')\n    assert (generator.features.shape == (self.N, self.n_feat))", "ground_truth": "(self.N, self.N)", "quality_analysis": {"complexity_score": 8, "left_complexity": 2, "right_complexity": 6, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_815", "reponame": "stellargraph", "testpath": "tests/mapper/test_full_batch_generators.py", "testname": "test_full_batch_generators.py", "classname": "Test_FullBatchNodeGenerator", "funcname": "test_generator_constructor", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper import FullBatchGenerator, FullBatchLinkGenerator, FullBatchNodeGenerator", "import networkx as nx", "import numpy as np", "import random", "import pytest", "import pandas as pd", "import scipy.sparse as sps", "from ..test_utils.graphs import create_graph_features, example_graph_random, example_hin_1, example_graph"], "code": "def test_generator_constructor(self):\n    generator = FullBatchNodeGenerator(self.G)\n    assert (generator.Aadj.shape == (self.N, self.N))\n    assert (generator.features.shape == (self.N, self.n_feat))", "masked_code": "def test_generator_constructor(self):\n    generator = FullBatchNodeGenerator(self.G)\n    assert (generator.Aadj.shape == (self.N, self.N))\n    assert (generator.features.shape == '???')", "ground_truth": "(self.N, self.n_feat)", "quality_analysis": {"complexity_score": 8, "left_complexity": 2, "right_complexity": 6, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_816", "reponame": "stellargraph", "testpath": "tests/mapper/test_full_batch_generators.py", "testname": "test_full_batch_generators.py", "classname": "Test_FullBatchNodeGenerator", "funcname": "test_generator_flow_targets_as_list", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper import FullBatchGenerator, FullBatchLinkGenerator, FullBatchNodeGenerator", "import networkx as nx", "import numpy as np", "import random", "import pytest", "import pandas as pd", "import scipy.sparse as sps", "from ..test_utils.graphs import create_graph_features, example_graph_random, example_hin_1, example_graph"], "code": "def test_generator_flow_targets_as_list(self):\n    generator = FullBatchNodeGenerator(self.G)\n    node_ids = list(self.G.nodes())[:3]\n    node_targets = ([1] * len(node_ids))\n    gen = generator.flow(node_ids, node_targets)\n    (inputs, y) = gen[0]\n    assert (y.shape == (1, 3))\n    assert (np.sum(y) == 3)", "masked_code": "def test_generator_flow_targets_as_list(self):\n    generator = FullBatchNodeGenerator(self.G)\n    node_ids = list(self.G.nodes())[:3]\n    node_targets = ([1] * len(node_ids))\n    gen = generator.flow(node_ids, node_targets)\n    (inputs, y) = gen[0]\n    assert (y.shape == '???')\n    assert (np.sum(y) == 3)", "ground_truth": "(1, 3)", "quality_analysis": {"complexity_score": 6, "left_complexity": 2, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_817", "reponame": "stellargraph", "testpath": "tests/mapper/test_full_batch_generators.py", "testname": "test_full_batch_generators.py", "classname": "Test_FullBatchNodeGenerator", "funcname": "test_generator_flow_targets_as_list", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper import FullBatchGenerator, FullBatchLinkGenerator, FullBatchNodeGenerator", "import networkx as nx", "import numpy as np", "import random", "import pytest", "import pandas as pd", "import scipy.sparse as sps", "from ..test_utils.graphs import create_graph_features, example_graph_random, example_hin_1, example_graph"], "code": "def test_generator_flow_targets_as_list(self):\n    generator = FullBatchNodeGenerator(self.G)\n    node_ids = list(self.G.nodes())[:3]\n    node_targets = ([1] * len(node_ids))\n    gen = generator.flow(node_ids, node_targets)\n    (inputs, y) = gen[0]\n    assert (y.shape == (1, 3))\n    assert (np.sum(y) == 3)", "masked_code": "def test_generator_flow_targets_as_list(self):\n    generator = FullBatchNodeGenerator(self.G)\n    node_ids = list(self.G.nodes())[:3]\n    node_targets = ([1] * len(node_ids))\n    gen = generator.flow(node_ids, node_targets)\n    (inputs, y) = gen[0]\n    assert (y.shape == (1, 3))\n    assert (np.sum(y) == '???')", "ground_truth": "3", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_818", "reponame": "stellargraph", "testpath": "tests/mapper/test_full_batch_generators.py", "testname": "test_full_batch_generators.py", "classname": "Test_FullBatchNodeGenerator", "funcname": "test_fullbatch_generator_transform", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper import FullBatchGenerator, FullBatchLinkGenerator, FullBatchNodeGenerator", "import networkx as nx", "import numpy as np", "import random", "import pytest", "import pandas as pd", "import scipy.sparse as sps", "from ..test_utils.graphs import create_graph_features, example_graph_random, example_hin_1, example_graph"], "code": "def test_fullbatch_generator_transform(self):\n    (G, feats) = create_graph_features()\n\n    def func(features, A, **kwargs):\n        return (features, A.dot(A))\n    generator = FullBatchNodeGenerator(G, 'test', transform=func)\n    assert (generator.name == 'test')\n    A = G.to_adjacency_matrix().toarray()\n    np.testing.assert_array_equal(A.dot(A), generator.Aadj.toarray())", "masked_code": "def test_fullbatch_generator_transform(self):\n    (G, feats) = create_graph_features()\n\n    def func(features, A, **kwargs):\n        return (features, A.dot(A))\n    generator = FullBatchNodeGenerator(G, 'test', transform=func)\n    assert (generator.name == '???')\n    A = G.to_adjacency_matrix().toarray()\n    np.testing.assert_array_equal(A.dot(A), generator.Aadj.toarray())", "ground_truth": "'test'", "quality_analysis": {"complexity_score": 3, "left_complexity": 2, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_819", "reponame": "stellargraph", "testpath": "tests/mapper/test_full_batch_generators.py", "testname": "test_full_batch_generators.py", "classname": "Test_FullBatchLinkGenerator", "funcname": "test_generator_constructor", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper import FullBatchGenerator, FullBatchLinkGenerator, FullBatchNodeGenerator", "import networkx as nx", "import numpy as np", "import random", "import pytest", "import pandas as pd", "import scipy.sparse as sps", "from ..test_utils.graphs import create_graph_features, example_graph_random, example_hin_1, example_graph"], "code": "def test_generator_constructor(self):\n    generator = FullBatchLinkGenerator(self.G)\n    assert (generator.Aadj.shape == (self.N, self.N))\n    assert (generator.features.shape == (self.N, self.n_feat))", "masked_code": "def test_generator_constructor(self):\n    generator = FullBatchLinkGenerator(self.G)\n    assert (generator.Aadj.shape == '???')\n    assert (generator.features.shape == (self.N, self.n_feat))", "ground_truth": "(self.N, self.N)", "quality_analysis": {"complexity_score": 8, "left_complexity": 2, "right_complexity": 6, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_820", "reponame": "stellargraph", "testpath": "tests/mapper/test_full_batch_generators.py", "testname": "test_full_batch_generators.py", "classname": "Test_FullBatchLinkGenerator", "funcname": "test_generator_constructor", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper import FullBatchGenerator, FullBatchLinkGenerator, FullBatchNodeGenerator", "import networkx as nx", "import numpy as np", "import random", "import pytest", "import pandas as pd", "import scipy.sparse as sps", "from ..test_utils.graphs import create_graph_features, example_graph_random, example_hin_1, example_graph"], "code": "def test_generator_constructor(self):\n    generator = FullBatchLinkGenerator(self.G)\n    assert (generator.Aadj.shape == (self.N, self.N))\n    assert (generator.features.shape == (self.N, self.n_feat))", "masked_code": "def test_generator_constructor(self):\n    generator = FullBatchLinkGenerator(self.G)\n    assert (generator.Aadj.shape == (self.N, self.N))\n    assert (generator.features.shape == '???')", "ground_truth": "(self.N, self.n_feat)", "quality_analysis": {"complexity_score": 8, "left_complexity": 2, "right_complexity": 6, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_821", "reponame": "stellargraph", "testpath": "tests/mapper/test_full_batch_generators.py", "testname": "test_full_batch_generators.py", "classname": "Test_FullBatchLinkGenerator", "funcname": "test_generator_flow_targets_as_list", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper import FullBatchGenerator, FullBatchLinkGenerator, FullBatchNodeGenerator", "import networkx as nx", "import numpy as np", "import random", "import pytest", "import pandas as pd", "import scipy.sparse as sps", "from ..test_utils.graphs import create_graph_features, example_graph_random, example_hin_1, example_graph"], "code": "def test_generator_flow_targets_as_list(self):\n    generator = FullBatchLinkGenerator(self.G)\n    link_ids = list(self.G.edges())[:3]\n    link_targets = ([1] * len(link_ids))\n    gen = generator.flow(link_ids, link_targets)\n    (inputs, y) = gen[0]\n    assert (y.shape == (1, 3))\n    assert (np.sum(y) == 3)", "masked_code": "def test_generator_flow_targets_as_list(self):\n    generator = FullBatchLinkGenerator(self.G)\n    link_ids = list(self.G.edges())[:3]\n    link_targets = ([1] * len(link_ids))\n    gen = generator.flow(link_ids, link_targets)\n    (inputs, y) = gen[0]\n    assert (y.shape == '???')\n    assert (np.sum(y) == 3)", "ground_truth": "(1, 3)", "quality_analysis": {"complexity_score": 6, "left_complexity": 2, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_822", "reponame": "stellargraph", "testpath": "tests/mapper/test_full_batch_generators.py", "testname": "test_full_batch_generators.py", "classname": "Test_FullBatchLinkGenerator", "funcname": "test_generator_flow_targets_as_list", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper import FullBatchGenerator, FullBatchLinkGenerator, FullBatchNodeGenerator", "import networkx as nx", "import numpy as np", "import random", "import pytest", "import pandas as pd", "import scipy.sparse as sps", "from ..test_utils.graphs import create_graph_features, example_graph_random, example_hin_1, example_graph"], "code": "def test_generator_flow_targets_as_list(self):\n    generator = FullBatchLinkGenerator(self.G)\n    link_ids = list(self.G.edges())[:3]\n    link_targets = ([1] * len(link_ids))\n    gen = generator.flow(link_ids, link_targets)\n    (inputs, y) = gen[0]\n    assert (y.shape == (1, 3))\n    assert (np.sum(y) == 3)", "masked_code": "def test_generator_flow_targets_as_list(self):\n    generator = FullBatchLinkGenerator(self.G)\n    link_ids = list(self.G.edges())[:3]\n    link_targets = ([1] * len(link_ids))\n    gen = generator.flow(link_ids, link_targets)\n    (inputs, y) = gen[0]\n    assert (y.shape == (1, 3))\n    assert (np.sum(y) == '???')", "ground_truth": "3", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_823", "reponame": "stellargraph", "testpath": "tests/mapper/test_full_batch_generators.py", "testname": "test_full_batch_generators.py", "classname": "Test_FullBatchLinkGenerator", "funcname": "test_fullbatch_generator_transform", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper import FullBatchGenerator, FullBatchLinkGenerator, FullBatchNodeGenerator", "import networkx as nx", "import numpy as np", "import random", "import pytest", "import pandas as pd", "import scipy.sparse as sps", "from ..test_utils.graphs import create_graph_features, example_graph_random, example_hin_1, example_graph"], "code": "def test_fullbatch_generator_transform(self):\n\n    def func(features, A, **kwargs):\n        return (features, A.dot(A))\n    generator = FullBatchNodeGenerator(self.G, 'test', transform=func)\n    assert (generator.name == 'test')\n    A = self.G.to_adjacency_matrix().toarray()\n    np.testing.assert_array_equal(A.dot(A), generator.Aadj.toarray())", "masked_code": "def test_fullbatch_generator_transform(self):\n\n    def func(features, A, **kwargs):\n        return (features, A.dot(A))\n    generator = FullBatchNodeGenerator(self.G, 'test', transform=func)\n    assert (generator.name == '???')\n    A = self.G.to_adjacency_matrix().toarray()\n    np.testing.assert_array_equal(A.dot(A), generator.Aadj.toarray())", "ground_truth": "'test'", "quality_analysis": {"complexity_score": 3, "left_complexity": 2, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_824", "reponame": "stellargraph", "testpath": "tests/mapper/test_graphwave_generator.py", "testname": "test_graphwave_generator.py", "classname": null, "funcname": "test_init", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper.graphwave_generator import GraphWaveGenerator, _empirical_characteristic_function", "from ..test_utils.graphs import barbell", "import numpy as np", "import pytest", "import scipy.sparse as sps", "import tensorflow as tf"], "code": "def test_init(barbell):\n    generator = GraphWaveGenerator(barbell, scales=(0.1, 2, 3, 4), degree=10)\n    np.testing.assert_array_equal(generator.scales, np.array((0.1, 2, 3, 4)).astype(np.float32))\n    assert (generator.coeffs.shape == (4, (10 + 1)))\n    assert (generator.laplacian.shape == (barbell.number_of_nodes(), barbell.number_of_nodes()))", "masked_code": "def test_init(barbell):\n    generator = GraphWaveGenerator(barbell, scales=(0.1, 2, 3, 4), degree=10)\n    np.testing.assert_array_equal(generator.scales, np.array((0.1, 2, 3, 4)).astype(np.float32))\n    assert (generator.coeffs.shape == '???')\n    assert (generator.laplacian.shape == (barbell.number_of_nodes(), barbell.number_of_nodes()))", "ground_truth": "(4, (10 + 1))", "quality_analysis": {"complexity_score": 9, "left_complexity": 2, "right_complexity": 7, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_825", "reponame": "stellargraph", "testpath": "tests/mapper/test_graphwave_generator.py", "testname": "test_graphwave_generator.py", "classname": null, "funcname": "test_init", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper.graphwave_generator import GraphWaveGenerator, _empirical_characteristic_function", "from ..test_utils.graphs import barbell", "import numpy as np", "import pytest", "import scipy.sparse as sps", "import tensorflow as tf"], "code": "def test_init(barbell):\n    generator = GraphWaveGenerator(barbell, scales=(0.1, 2, 3, 4), degree=10)\n    np.testing.assert_array_equal(generator.scales, np.array((0.1, 2, 3, 4)).astype(np.float32))\n    assert (generator.coeffs.shape == (4, (10 + 1)))\n    assert (generator.laplacian.shape == (barbell.number_of_nodes(), barbell.number_of_nodes()))", "masked_code": "def test_init(barbell):\n    generator = GraphWaveGenerator(barbell, scales=(0.1, 2, 3, 4), degree=10)\n    np.testing.assert_array_equal(generator.scales, np.array((0.1, 2, 3, 4)).astype(np.float32))\n    assert (generator.coeffs.shape == (4, (10 + 1)))\n    assert (generator.laplacian.shape == '???')", "ground_truth": "(barbell.number_of_nodes(), barbell.number_of_nodes())", "quality_analysis": {"complexity_score": 10, "left_complexity": 2, "right_complexity": 8, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_826", "reponame": "stellargraph", "testpath": "tests/mapper/test_graphwave_generator.py", "testname": "test_graphwave_generator.py", "classname": null, "funcname": "test_flow_repeat", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper.graphwave_generator import GraphWaveGenerator, _empirical_characteristic_function", "from ..test_utils.graphs import barbell", "import numpy as np", "import pytest", "import scipy.sparse as sps", "import tensorflow as tf"], "code": "@pytest.mark.parametrize('repeat', [False, True])\ndef test_flow_repeat(barbell, repeat):\n    generator = GraphWaveGenerator(barbell, scales=(0.1, 2, 3, 4), degree=10)\n    sample_points = np.linspace(0, 100, 25)\n    for (i, x) in enumerate(generator.flow(barbell.nodes(), sample_points=sample_points, batch_size=1, repeat=repeat)):\n        if (i > barbell.number_of_nodes()):\n            break\n    assert ((i > barbell.number_of_nodes()) == repeat)", "masked_code": "@pytest.mark.parametrize('repeat', [False, True])\ndef test_flow_repeat(barbell, repeat):\n    generator = GraphWaveGenerator(barbell, scales=(0.1, 2, 3, 4), degree=10)\n    sample_points = np.linspace(0, 100, 25)\n    for (i, x) in enumerate(generator.flow(barbell.nodes(), sample_points=sample_points, batch_size=1, repeat=repeat)):\n        if (i > barbell.number_of_nodes()):\n            break\n    assert ((i > barbell.number_of_nodes()) == '???')", "ground_truth": "repeat", "quality_analysis": {"complexity_score": 7, "left_complexity": 6, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_827", "reponame": "stellargraph", "testpath": "tests/mapper/test_graphwave_generator.py", "testname": "test_graphwave_generator.py", "classname": null, "funcname": "test_flow_batch_size", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper.graphwave_generator import GraphWaveGenerator, _empirical_characteristic_function", "from ..test_utils.graphs import barbell", "import numpy as np", "import pytest", "import scipy.sparse as sps", "import tensorflow as tf"], "code": "@pytest.mark.parametrize('batch_size', [1, 5, 10])\ndef test_flow_batch_size(barbell, batch_size):\n    scales = (0.1, 2, 3, 4)\n    generator = GraphWaveGenerator(barbell, scales=scales, degree=10)\n    sample_points = np.linspace(0, 100, 25)\n    expected_embed_dim = ((len(sample_points) * len(scales)) * 2)\n    for (i, x) in enumerate(generator.flow(barbell.nodes(), sample_points=sample_points, batch_size=batch_size, repeat=False)):\n        if (i < (barbell.number_of_nodes() // batch_size)):\n            assert (x.shape == (batch_size, expected_embed_dim))\n        else:\n            assert (x.shape == ((barbell.number_of_nodes() % batch_size), expected_embed_dim))", "masked_code": "@pytest.mark.parametrize('batch_size', [1, 5, 10])\ndef test_flow_batch_size(barbell, batch_size):\n    scales = (0.1, 2, 3, 4)\n    generator = GraphWaveGenerator(barbell, scales=scales, degree=10)\n    sample_points = np.linspace(0, 100, 25)\n    expected_embed_dim = ((len(sample_points) * len(scales)) * 2)\n    for (i, x) in enumerate(generator.flow(barbell.nodes(), sample_points=sample_points, batch_size=batch_size, repeat=False)):\n        if (i < (barbell.number_of_nodes() // batch_size)):\n            assert (x.shape == '???')\n        else:\n            assert (x.shape == ((barbell.number_of_nodes() % batch_size), expected_embed_dim))", "ground_truth": "(batch_size, expected_embed_dim)", "quality_analysis": {"complexity_score": 6, "left_complexity": 2, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_828", "reponame": "stellargraph", "testpath": "tests/mapper/test_graphwave_generator.py", "testname": "test_graphwave_generator.py", "classname": null, "funcname": "test_flow_batch_size", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper.graphwave_generator import GraphWaveGenerator, _empirical_characteristic_function", "from ..test_utils.graphs import barbell", "import numpy as np", "import pytest", "import scipy.sparse as sps", "import tensorflow as tf"], "code": "@pytest.mark.parametrize('batch_size', [1, 5, 10])\ndef test_flow_batch_size(barbell, batch_size):\n    scales = (0.1, 2, 3, 4)\n    generator = GraphWaveGenerator(barbell, scales=scales, degree=10)\n    sample_points = np.linspace(0, 100, 25)\n    expected_embed_dim = ((len(sample_points) * len(scales)) * 2)\n    for (i, x) in enumerate(generator.flow(barbell.nodes(), sample_points=sample_points, batch_size=batch_size, repeat=False)):\n        if (i < (barbell.number_of_nodes() // batch_size)):\n            assert (x.shape == (batch_size, expected_embed_dim))\n        else:\n            assert (x.shape == ((barbell.number_of_nodes() % batch_size), expected_embed_dim))", "masked_code": "@pytest.mark.parametrize('batch_size', [1, 5, 10])\ndef test_flow_batch_size(barbell, batch_size):\n    scales = (0.1, 2, 3, 4)\n    generator = GraphWaveGenerator(barbell, scales=scales, degree=10)\n    sample_points = np.linspace(0, 100, 25)\n    expected_embed_dim = ((len(sample_points) * len(scales)) * 2)\n    for (i, x) in enumerate(generator.flow(barbell.nodes(), sample_points=sample_points, batch_size=batch_size, repeat=False)):\n        if (i < (barbell.number_of_nodes() // batch_size)):\n            assert (x.shape == (batch_size, expected_embed_dim))\n        else:\n            assert (x.shape == '???')", "ground_truth": "((barbell.number_of_nodes() % batch_size), expected_embed_dim)", "quality_analysis": {"complexity_score": 11, "left_complexity": 2, "right_complexity": 9, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_829", "reponame": "stellargraph", "testpath": "tests/mapper/test_graphwave_generator.py", "testname": "test_graphwave_generator.py", "classname": null, "funcname": "test_embedding_dim", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper.graphwave_generator import GraphWaveGenerator, _empirical_characteristic_function", "from ..test_utils.graphs import barbell", "import numpy as np", "import pytest", "import scipy.sparse as sps", "import tensorflow as tf"], "code": "@pytest.mark.parametrize('num_samples', [1, 25, 50])\ndef test_embedding_dim(barbell, num_samples):\n    scales = (0.1, 2, 3, 4)\n    generator = GraphWaveGenerator(barbell, scales=scales, degree=10)\n    sample_points = np.linspace(0, 1, num_samples)\n    expected_embed_dim = ((len(sample_points) * len(scales)) * 2)\n    for x in generator.flow(barbell.nodes(), sample_points=sample_points, batch_size=4, repeat=False):\n        assert (x.shape[1] == expected_embed_dim)", "masked_code": "@pytest.mark.parametrize('num_samples', [1, 25, 50])\ndef test_embedding_dim(barbell, num_samples):\n    scales = (0.1, 2, 3, 4)\n    generator = GraphWaveGenerator(barbell, scales=scales, degree=10)\n    sample_points = np.linspace(0, 1, num_samples)\n    expected_embed_dim = ((len(sample_points) * len(scales)) * 2)\n    for x in generator.flow(barbell.nodes(), sample_points=sample_points, batch_size=4, repeat=False):\n        assert (x.shape[1] == '???')", "ground_truth": "expected_embed_dim", "quality_analysis": {"complexity_score": 7, "left_complexity": 6, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_830", "reponame": "stellargraph", "testpath": "tests/mapper/test_graphwave_generator.py", "testname": "test_graphwave_generator.py", "classname": null, "funcname": "test_flow_targets", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper.graphwave_generator import GraphWaveGenerator, _empirical_characteristic_function", "from ..test_utils.graphs import barbell", "import numpy as np", "import pytest", "import scipy.sparse as sps", "import tensorflow as tf"], "code": "def test_flow_targets(barbell):\n    generator = GraphWaveGenerator(barbell, scales=(0.1, 2, 3, 4), degree=10)\n    sample_points = np.linspace(0, 100, 25)\n    for (i, x) in enumerate(generator.flow(barbell.nodes(), sample_points=sample_points, batch_size=1, targets=np.arange(barbell.number_of_nodes()))):\n        assert (len(x) == 2)\n        assert (x[1].numpy() == i)", "masked_code": "def test_flow_targets(barbell):\n    generator = GraphWaveGenerator(barbell, scales=(0.1, 2, 3, 4), degree=10)\n    sample_points = np.linspace(0, 100, 25)\n    for (i, x) in enumerate(generator.flow(barbell.nodes(), sample_points=sample_points, batch_size=1, targets=np.arange(barbell.number_of_nodes()))):\n        assert (len(x) == 2)\n        assert (x[1].numpy() == '???')", "ground_truth": "i", "quality_analysis": {"complexity_score": 4, "left_complexity": 3, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_831", "reponame": "stellargraph", "testpath": "tests/mapper/test_knowledge_graph.py", "testname": "test_knowledge_graph.py", "classname": null, "funcname": "test_kg_triple_sequence_shuffle", "imports": ["import pytest", "import pandas as pd", "import numpy as np", "from stellargraph.mapper.knowledge_graph import KGTripleGenerator, KGTripleSequence", "from .. import test_utils", "from ..test_utils.graphs import knowledge_graph"], "code": "@pytest.mark.parametrize('shuffle', [False, True])\ndef test_kg_triple_sequence_shuffle(shuffle):\n    seq = KGTripleSequence(max_node_iloc=10, source_ilocs=[0, 1, 2, 3, 4], rel_ilocs=[0, 1, 0, 1, 0], target_ilocs=[4, 3, 2, 1, 0], batch_size=5, shuffle=shuffle, negative_samples=None, sample_strategy='uniform', seed=None)\n    assert (len(seq) == 1)\n\n    def sample():\n        ret = seq[0]\n        seq.on_epoch_end()\n        return ret\n    (first, *rest) = [sample() for _ in range(20)]\n    should_be_equal = (not shuffle)\n    assert (all((epoch_sample_equal(first, r) for r in rest)) == should_be_equal)", "masked_code": "@pytest.mark.parametrize('shuffle', [False, True])\ndef test_kg_triple_sequence_shuffle(shuffle):\n    seq = KGTripleSequence(max_node_iloc=10, source_ilocs=[0, 1, 2, 3, 4], rel_ilocs=[0, 1, 0, 1, 0], target_ilocs=[4, 3, 2, 1, 0], batch_size=5, shuffle=shuffle, negative_samples=None, sample_strategy='uniform', seed=None)\n    assert (len(seq) == 1)\n\n    def sample():\n        ret = seq[0]\n        seq.on_epoch_end()\n        return ret\n    (first, *rest) = [sample() for _ in range(20)]\n    should_be_equal = (not shuffle)\n    assert (all((epoch_sample_equal(first, r) for r in rest)) == '???')", "ground_truth": "should_be_equal", "quality_analysis": {"complexity_score": 4, "left_complexity": 3, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_832", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_GraphSAGELinkGenerator", "funcname": "test_LinkMapper_constructor", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_LinkMapper_constructor(self):\n    G = example_graph(feature_size=self.n_feat)\n    edge_labels = ([0] * G.number_of_edges())\n    generator = GraphSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=self.num_samples)\n    mapper = generator.flow(G.edges(), edge_labels)\n    assert (generator.batch_size == self.batch_size)\n    assert (mapper.data_size == G.number_of_edges())\n    assert (len(mapper.ids) == G.number_of_edges())\n    G = example_graph(feature_size=self.n_feat, is_directed=True)\n    edge_labels = ([0] * G.number_of_edges())\n    generator = GraphSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=self.num_samples)\n    mapper = generator.flow(G.edges(), edge_labels)\n    assert (generator.batch_size == self.batch_size)\n    assert (mapper.data_size == G.number_of_edges())\n    assert (len(mapper.ids) == G.number_of_edges())", "masked_code": "def test_LinkMapper_constructor(self):\n    G = example_graph(feature_size=self.n_feat)\n    edge_labels = ([0] * G.number_of_edges())\n    generator = GraphSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=self.num_samples)\n    mapper = generator.flow(G.edges(), edge_labels)\n    assert (generator.batch_size == '???')\n    assert (mapper.data_size == G.number_of_edges())\n    assert (len(mapper.ids) == G.number_of_edges())\n    G = example_graph(feature_size=self.n_feat, is_directed=True)\n    edge_labels = ([0] * G.number_of_edges())\n    generator = GraphSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=self.num_samples)\n    mapper = generator.flow(G.edges(), edge_labels)\n    assert (generator.batch_size == self.batch_size)\n    assert (mapper.data_size == G.number_of_edges())\n    assert (len(mapper.ids) == G.number_of_edges())", "ground_truth": "self.batch_size", "quality_analysis": {"complexity_score": 4, "left_complexity": 2, "right_complexity": 2, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_833", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_GraphSAGELinkGenerator", "funcname": "test_LinkMapper_constructor", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_LinkMapper_constructor(self):\n    G = example_graph(feature_size=self.n_feat)\n    edge_labels = ([0] * G.number_of_edges())\n    generator = GraphSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=self.num_samples)\n    mapper = generator.flow(G.edges(), edge_labels)\n    assert (generator.batch_size == self.batch_size)\n    assert (mapper.data_size == G.number_of_edges())\n    assert (len(mapper.ids) == G.number_of_edges())\n    G = example_graph(feature_size=self.n_feat, is_directed=True)\n    edge_labels = ([0] * G.number_of_edges())\n    generator = GraphSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=self.num_samples)\n    mapper = generator.flow(G.edges(), edge_labels)\n    assert (generator.batch_size == self.batch_size)\n    assert (mapper.data_size == G.number_of_edges())\n    assert (len(mapper.ids) == G.number_of_edges())", "masked_code": "def test_LinkMapper_constructor(self):\n    G = example_graph(feature_size=self.n_feat)\n    edge_labels = ([0] * G.number_of_edges())\n    generator = GraphSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=self.num_samples)\n    mapper = generator.flow(G.edges(), edge_labels)\n    assert (generator.batch_size == self.batch_size)\n    assert (mapper.data_size == '???')\n    assert (len(mapper.ids) == G.number_of_edges())\n    G = example_graph(feature_size=self.n_feat, is_directed=True)\n    edge_labels = ([0] * G.number_of_edges())\n    generator = GraphSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=self.num_samples)\n    mapper = generator.flow(G.edges(), edge_labels)\n    assert (generator.batch_size == self.batch_size)\n    assert (mapper.data_size == G.number_of_edges())\n    assert (len(mapper.ids) == G.number_of_edges())", "ground_truth": "G.number_of_edges()", "quality_analysis": {"complexity_score": 5, "left_complexity": 2, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_834", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_GraphSAGELinkGenerator", "funcname": "test_LinkMapper_constructor", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_LinkMapper_constructor(self):\n    G = example_graph(feature_size=self.n_feat)\n    edge_labels = ([0] * G.number_of_edges())\n    generator = GraphSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=self.num_samples)\n    mapper = generator.flow(G.edges(), edge_labels)\n    assert (generator.batch_size == self.batch_size)\n    assert (mapper.data_size == G.number_of_edges())\n    assert (len(mapper.ids) == G.number_of_edges())\n    G = example_graph(feature_size=self.n_feat, is_directed=True)\n    edge_labels = ([0] * G.number_of_edges())\n    generator = GraphSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=self.num_samples)\n    mapper = generator.flow(G.edges(), edge_labels)\n    assert (generator.batch_size == self.batch_size)\n    assert (mapper.data_size == G.number_of_edges())\n    assert (len(mapper.ids) == G.number_of_edges())", "masked_code": "def test_LinkMapper_constructor(self):\n    G = example_graph(feature_size=self.n_feat)\n    edge_labels = ([0] * G.number_of_edges())\n    generator = GraphSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=self.num_samples)\n    mapper = generator.flow(G.edges(), edge_labels)\n    assert (generator.batch_size == self.batch_size)\n    assert (mapper.data_size == G.number_of_edges())\n    assert (len(mapper.ids) == '???')\n    G = example_graph(feature_size=self.n_feat, is_directed=True)\n    edge_labels = ([0] * G.number_of_edges())\n    generator = GraphSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=self.num_samples)\n    mapper = generator.flow(G.edges(), edge_labels)\n    assert (generator.batch_size == self.batch_size)\n    assert (mapper.data_size == G.number_of_edges())\n    assert (len(mapper.ids) == G.number_of_edges())", "ground_truth": "G.number_of_edges()", "quality_analysis": {"complexity_score": 8, "left_complexity": 5, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_835", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_GraphSAGELinkGenerator", "funcname": "test_LinkMapper_constructor", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_LinkMapper_constructor(self):\n    G = example_graph(feature_size=self.n_feat)\n    edge_labels = ([0] * G.number_of_edges())\n    generator = GraphSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=self.num_samples)\n    mapper = generator.flow(G.edges(), edge_labels)\n    assert (generator.batch_size == self.batch_size)\n    assert (mapper.data_size == G.number_of_edges())\n    assert (len(mapper.ids) == G.number_of_edges())\n    G = example_graph(feature_size=self.n_feat, is_directed=True)\n    edge_labels = ([0] * G.number_of_edges())\n    generator = GraphSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=self.num_samples)\n    mapper = generator.flow(G.edges(), edge_labels)\n    assert (generator.batch_size == self.batch_size)\n    assert (mapper.data_size == G.number_of_edges())\n    assert (len(mapper.ids) == G.number_of_edges())", "masked_code": "def test_LinkMapper_constructor(self):\n    G = example_graph(feature_size=self.n_feat)\n    edge_labels = ([0] * G.number_of_edges())\n    generator = GraphSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=self.num_samples)\n    mapper = generator.flow(G.edges(), edge_labels)\n    assert (generator.batch_size == self.batch_size)\n    assert (mapper.data_size == G.number_of_edges())\n    assert (len(mapper.ids) == G.number_of_edges())\n    G = example_graph(feature_size=self.n_feat, is_directed=True)\n    edge_labels = ([0] * G.number_of_edges())\n    generator = GraphSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=self.num_samples)\n    mapper = generator.flow(G.edges(), edge_labels)\n    assert (generator.batch_size == '???')\n    assert (mapper.data_size == G.number_of_edges())\n    assert (len(mapper.ids) == G.number_of_edges())", "ground_truth": "self.batch_size", "quality_analysis": {"complexity_score": 4, "left_complexity": 2, "right_complexity": 2, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_836", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_GraphSAGELinkGenerator", "funcname": "test_LinkMapper_constructor", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_LinkMapper_constructor(self):\n    G = example_graph(feature_size=self.n_feat)\n    edge_labels = ([0] * G.number_of_edges())\n    generator = GraphSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=self.num_samples)\n    mapper = generator.flow(G.edges(), edge_labels)\n    assert (generator.batch_size == self.batch_size)\n    assert (mapper.data_size == G.number_of_edges())\n    assert (len(mapper.ids) == G.number_of_edges())\n    G = example_graph(feature_size=self.n_feat, is_directed=True)\n    edge_labels = ([0] * G.number_of_edges())\n    generator = GraphSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=self.num_samples)\n    mapper = generator.flow(G.edges(), edge_labels)\n    assert (generator.batch_size == self.batch_size)\n    assert (mapper.data_size == G.number_of_edges())\n    assert (len(mapper.ids) == G.number_of_edges())", "masked_code": "def test_LinkMapper_constructor(self):\n    G = example_graph(feature_size=self.n_feat)\n    edge_labels = ([0] * G.number_of_edges())\n    generator = GraphSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=self.num_samples)\n    mapper = generator.flow(G.edges(), edge_labels)\n    assert (generator.batch_size == self.batch_size)\n    assert (mapper.data_size == G.number_of_edges())\n    assert (len(mapper.ids) == G.number_of_edges())\n    G = example_graph(feature_size=self.n_feat, is_directed=True)\n    edge_labels = ([0] * G.number_of_edges())\n    generator = GraphSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=self.num_samples)\n    mapper = generator.flow(G.edges(), edge_labels)\n    assert (generator.batch_size == self.batch_size)\n    assert (mapper.data_size == '???')\n    assert (len(mapper.ids) == G.number_of_edges())", "ground_truth": "G.number_of_edges()", "quality_analysis": {"complexity_score": 5, "left_complexity": 2, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_837", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_GraphSAGELinkGenerator", "funcname": "test_LinkMapper_constructor", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_LinkMapper_constructor(self):\n    G = example_graph(feature_size=self.n_feat)\n    edge_labels = ([0] * G.number_of_edges())\n    generator = GraphSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=self.num_samples)\n    mapper = generator.flow(G.edges(), edge_labels)\n    assert (generator.batch_size == self.batch_size)\n    assert (mapper.data_size == G.number_of_edges())\n    assert (len(mapper.ids) == G.number_of_edges())\n    G = example_graph(feature_size=self.n_feat, is_directed=True)\n    edge_labels = ([0] * G.number_of_edges())\n    generator = GraphSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=self.num_samples)\n    mapper = generator.flow(G.edges(), edge_labels)\n    assert (generator.batch_size == self.batch_size)\n    assert (mapper.data_size == G.number_of_edges())\n    assert (len(mapper.ids) == G.number_of_edges())", "masked_code": "def test_LinkMapper_constructor(self):\n    G = example_graph(feature_size=self.n_feat)\n    edge_labels = ([0] * G.number_of_edges())\n    generator = GraphSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=self.num_samples)\n    mapper = generator.flow(G.edges(), edge_labels)\n    assert (generator.batch_size == self.batch_size)\n    assert (mapper.data_size == G.number_of_edges())\n    assert (len(mapper.ids) == G.number_of_edges())\n    G = example_graph(feature_size=self.n_feat, is_directed=True)\n    edge_labels = ([0] * G.number_of_edges())\n    generator = GraphSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=self.num_samples)\n    mapper = generator.flow(G.edges(), edge_labels)\n    assert (generator.batch_size == self.batch_size)\n    assert (mapper.data_size == G.number_of_edges())\n    assert (len(mapper.ids) == '???')", "ground_truth": "G.number_of_edges()", "quality_analysis": {"complexity_score": 8, "left_complexity": 5, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_838", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_GraphSAGELinkGenerator", "funcname": "test_GraphSAGELinkGenerator_1", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_GraphSAGELinkGenerator_1(self):\n    G = example_graph(feature_size=self.n_feat)\n    data_size = G.number_of_edges()\n    edge_labels = ([0] * data_size)\n    mapper = GraphSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=self.num_samples).flow(G.edges(), edge_labels)\n    assert (len(mapper) == 2)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        assert (len(nf) == (3 * 2))\n        for ii in range(2):\n            assert (nf[ii].shape == (min(self.batch_size, data_size), 1, self.n_feat))\n            assert (nf[(ii + 2)].shape == (min(self.batch_size, data_size), 2, self.n_feat))\n            assert (nf[(ii + (2 * 2))].shape == (min(self.batch_size, data_size), (2 * 2), self.n_feat))\n            assert (len(nl) == min(self.batch_size, data_size))\n            assert all((nl == 0))\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper[2]", "masked_code": "def test_GraphSAGELinkGenerator_1(self):\n    G = example_graph(feature_size=self.n_feat)\n    data_size = G.number_of_edges()\n    edge_labels = ([0] * data_size)\n    mapper = GraphSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=self.num_samples).flow(G.edges(), edge_labels)\n    assert (len(mapper) == 2)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        assert (len(nf) == '???')\n        for ii in range(2):\n            assert (nf[ii].shape == (min(self.batch_size, data_size), 1, self.n_feat))\n            assert (nf[(ii + 2)].shape == (min(self.batch_size, data_size), 2, self.n_feat))\n            assert (nf[(ii + (2 * 2))].shape == (min(self.batch_size, data_size), (2 * 2), self.n_feat))\n            assert (len(nl) == min(self.batch_size, data_size))\n            assert all((nl == 0))\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper[2]", "ground_truth": "(3 * 2)", "quality_analysis": {"complexity_score": 8, "left_complexity": 4, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_839", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_GraphSAGELinkGenerator", "funcname": "test_GraphSAGELinkGenerator_1", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_GraphSAGELinkGenerator_1(self):\n    G = example_graph(feature_size=self.n_feat)\n    data_size = G.number_of_edges()\n    edge_labels = ([0] * data_size)\n    mapper = GraphSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=self.num_samples).flow(G.edges(), edge_labels)\n    assert (len(mapper) == 2)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        assert (len(nf) == (3 * 2))\n        for ii in range(2):\n            assert (nf[ii].shape == (min(self.batch_size, data_size), 1, self.n_feat))\n            assert (nf[(ii + 2)].shape == (min(self.batch_size, data_size), 2, self.n_feat))\n            assert (nf[(ii + (2 * 2))].shape == (min(self.batch_size, data_size), (2 * 2), self.n_feat))\n            assert (len(nl) == min(self.batch_size, data_size))\n            assert all((nl == 0))\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper[2]", "masked_code": "def test_GraphSAGELinkGenerator_1(self):\n    G = example_graph(feature_size=self.n_feat)\n    data_size = G.number_of_edges()\n    edge_labels = ([0] * data_size)\n    mapper = GraphSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=self.num_samples).flow(G.edges(), edge_labels)\n    assert (len(mapper) == 2)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        assert (len(nf) == (3 * 2))\n        for ii in range(2):\n            assert (nf[ii].shape == '???')\n            assert (nf[(ii + 2)].shape == (min(self.batch_size, data_size), 2, self.n_feat))\n            assert (nf[(ii + (2 * 2))].shape == (min(self.batch_size, data_size), (2 * 2), self.n_feat))\n            assert (len(nl) == min(self.batch_size, data_size))\n            assert all((nl == 0))\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper[2]", "ground_truth": "(min(self.batch_size, data_size), 1, self.n_feat)", "quality_analysis": {"complexity_score": 13, "left_complexity": 2, "right_complexity": 11, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_840", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_GraphSAGELinkGenerator", "funcname": "test_GraphSAGELinkGenerator_1", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_GraphSAGELinkGenerator_1(self):\n    G = example_graph(feature_size=self.n_feat)\n    data_size = G.number_of_edges()\n    edge_labels = ([0] * data_size)\n    mapper = GraphSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=self.num_samples).flow(G.edges(), edge_labels)\n    assert (len(mapper) == 2)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        assert (len(nf) == (3 * 2))\n        for ii in range(2):\n            assert (nf[ii].shape == (min(self.batch_size, data_size), 1, self.n_feat))\n            assert (nf[(ii + 2)].shape == (min(self.batch_size, data_size), 2, self.n_feat))\n            assert (nf[(ii + (2 * 2))].shape == (min(self.batch_size, data_size), (2 * 2), self.n_feat))\n            assert (len(nl) == min(self.batch_size, data_size))\n            assert all((nl == 0))\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper[2]", "masked_code": "def test_GraphSAGELinkGenerator_1(self):\n    G = example_graph(feature_size=self.n_feat)\n    data_size = G.number_of_edges()\n    edge_labels = ([0] * data_size)\n    mapper = GraphSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=self.num_samples).flow(G.edges(), edge_labels)\n    assert (len(mapper) == 2)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        assert (len(nf) == (3 * 2))\n        for ii in range(2):\n            assert (nf[ii].shape == (min(self.batch_size, data_size), 1, self.n_feat))\n            assert (nf[(ii + 2)].shape == '???')\n            assert (nf[(ii + (2 * 2))].shape == (min(self.batch_size, data_size), (2 * 2), self.n_feat))\n            assert (len(nl) == min(self.batch_size, data_size))\n            assert all((nl == 0))\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper[2]", "ground_truth": "(min(self.batch_size, data_size), 2, self.n_feat)", "quality_analysis": {"complexity_score": 13, "left_complexity": 2, "right_complexity": 11, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_841", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_GraphSAGELinkGenerator", "funcname": "test_GraphSAGELinkGenerator_1", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_GraphSAGELinkGenerator_1(self):\n    G = example_graph(feature_size=self.n_feat)\n    data_size = G.number_of_edges()\n    edge_labels = ([0] * data_size)\n    mapper = GraphSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=self.num_samples).flow(G.edges(), edge_labels)\n    assert (len(mapper) == 2)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        assert (len(nf) == (3 * 2))\n        for ii in range(2):\n            assert (nf[ii].shape == (min(self.batch_size, data_size), 1, self.n_feat))\n            assert (nf[(ii + 2)].shape == (min(self.batch_size, data_size), 2, self.n_feat))\n            assert (nf[(ii + (2 * 2))].shape == (min(self.batch_size, data_size), (2 * 2), self.n_feat))\n            assert (len(nl) == min(self.batch_size, data_size))\n            assert all((nl == 0))\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper[2]", "masked_code": "def test_GraphSAGELinkGenerator_1(self):\n    G = example_graph(feature_size=self.n_feat)\n    data_size = G.number_of_edges()\n    edge_labels = ([0] * data_size)\n    mapper = GraphSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=self.num_samples).flow(G.edges(), edge_labels)\n    assert (len(mapper) == 2)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        assert (len(nf) == (3 * 2))\n        for ii in range(2):\n            assert (nf[ii].shape == (min(self.batch_size, data_size), 1, self.n_feat))\n            assert (nf[(ii + 2)].shape == (min(self.batch_size, data_size), 2, self.n_feat))\n            assert (nf[(ii + (2 * 2))].shape == '???')\n            assert (len(nl) == min(self.batch_size, data_size))\n            assert all((nl == 0))\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper[2]", "ground_truth": "(min(self.batch_size, data_size), (2 * 2), self.n_feat)", "quality_analysis": {"complexity_score": 16, "left_complexity": 2, "right_complexity": 14, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_842", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_GraphSAGELinkGenerator", "funcname": "test_GraphSAGELinkGenerator_1", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_GraphSAGELinkGenerator_1(self):\n    G = example_graph(feature_size=self.n_feat)\n    data_size = G.number_of_edges()\n    edge_labels = ([0] * data_size)\n    mapper = GraphSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=self.num_samples).flow(G.edges(), edge_labels)\n    assert (len(mapper) == 2)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        assert (len(nf) == (3 * 2))\n        for ii in range(2):\n            assert (nf[ii].shape == (min(self.batch_size, data_size), 1, self.n_feat))\n            assert (nf[(ii + 2)].shape == (min(self.batch_size, data_size), 2, self.n_feat))\n            assert (nf[(ii + (2 * 2))].shape == (min(self.batch_size, data_size), (2 * 2), self.n_feat))\n            assert (len(nl) == min(self.batch_size, data_size))\n            assert all((nl == 0))\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper[2]", "masked_code": "def test_GraphSAGELinkGenerator_1(self):\n    G = example_graph(feature_size=self.n_feat)\n    data_size = G.number_of_edges()\n    edge_labels = ([0] * data_size)\n    mapper = GraphSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=self.num_samples).flow(G.edges(), edge_labels)\n    assert (len(mapper) == 2)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        assert (len(nf) == (3 * 2))\n        for ii in range(2):\n            assert (nf[ii].shape == (min(self.batch_size, data_size), 1, self.n_feat))\n            assert (nf[(ii + 2)].shape == (min(self.batch_size, data_size), 2, self.n_feat))\n            assert (nf[(ii + (2 * 2))].shape == (min(self.batch_size, data_size), (2 * 2), self.n_feat))\n            assert (len(nl) == '???')\n            assert all((nl == 0))\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper[2]", "ground_truth": "min(self.batch_size, data_size)", "quality_analysis": {"complexity_score": 10, "left_complexity": 4, "right_complexity": 6, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_843", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_GraphSAGELinkGenerator", "funcname": "test_GraphSAGELinkGenerator_shuffle", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_GraphSAGELinkGenerator_shuffle(self):\n\n    def test_edge_consistency(shuffle):\n        G = example_graph(feature_size=1)\n        edges = list(G.edges())\n        edge_labels = list(range(len(edges)))\n        mapper = GraphSAGELinkGenerator(G, batch_size=2, num_samples=[0]).flow(edges, edge_labels, shuffle=shuffle)\n        assert (len(mapper) == 2)\n        for batch in range(len(mapper)):\n            (nf, nl) = mapper[batch]\n            e1 = edges[nl[0]]\n            e2 = edges[nl[1]]\n            assert (nf[0][(0, 0, 0)] == e1[0])\n            assert (nf[1][(0, 0, 0)] == e1[1])\n            assert (nf[0][(1, 0, 0)] == e2[0])\n            assert (nf[1][(1, 0, 0)] == e2[1])\n    test_edge_consistency(True)\n    test_edge_consistency(False)", "masked_code": "def test_GraphSAGELinkGenerator_shuffle(self):\n\n    def test_edge_consistency(shuffle):\n        G = example_graph(feature_size=1)\n        edges = list(G.edges())\n        edge_labels = list(range(len(edges)))\n        mapper = GraphSAGELinkGenerator(G, batch_size=2, num_samples=[0]).flow(edges, edge_labels, shuffle=shuffle)\n        assert (len(mapper) == 2)\n        for batch in range(len(mapper)):\n            (nf, nl) = mapper[batch]\n            e1 = edges[nl[0]]\n            e2 = edges[nl[1]]\n            assert (nf[0][(0, 0, 0)] == '???')\n            assert (nf[1][(0, 0, 0)] == e1[1])\n            assert (nf[0][(1, 0, 0)] == e2[0])\n            assert (nf[1][(1, 0, 0)] == e2[1])\n    test_edge_consistency(True)\n    test_edge_consistency(False)", "ground_truth": "e1[0]", "quality_analysis": {"complexity_score": 18, "left_complexity": 13, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_844", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_GraphSAGELinkGenerator", "funcname": "test_GraphSAGELinkGenerator_shuffle", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_GraphSAGELinkGenerator_shuffle(self):\n\n    def test_edge_consistency(shuffle):\n        G = example_graph(feature_size=1)\n        edges = list(G.edges())\n        edge_labels = list(range(len(edges)))\n        mapper = GraphSAGELinkGenerator(G, batch_size=2, num_samples=[0]).flow(edges, edge_labels, shuffle=shuffle)\n        assert (len(mapper) == 2)\n        for batch in range(len(mapper)):\n            (nf, nl) = mapper[batch]\n            e1 = edges[nl[0]]\n            e2 = edges[nl[1]]\n            assert (nf[0][(0, 0, 0)] == e1[0])\n            assert (nf[1][(0, 0, 0)] == e1[1])\n            assert (nf[0][(1, 0, 0)] == e2[0])\n            assert (nf[1][(1, 0, 0)] == e2[1])\n    test_edge_consistency(True)\n    test_edge_consistency(False)", "masked_code": "def test_GraphSAGELinkGenerator_shuffle(self):\n\n    def test_edge_consistency(shuffle):\n        G = example_graph(feature_size=1)\n        edges = list(G.edges())\n        edge_labels = list(range(len(edges)))\n        mapper = GraphSAGELinkGenerator(G, batch_size=2, num_samples=[0]).flow(edges, edge_labels, shuffle=shuffle)\n        assert (len(mapper) == 2)\n        for batch in range(len(mapper)):\n            (nf, nl) = mapper[batch]\n            e1 = edges[nl[0]]\n            e2 = edges[nl[1]]\n            assert (nf[0][(0, 0, 0)] == e1[0])\n            assert (nf[1][(0, 0, 0)] == '???')\n            assert (nf[0][(1, 0, 0)] == e2[0])\n            assert (nf[1][(1, 0, 0)] == e2[1])\n    test_edge_consistency(True)\n    test_edge_consistency(False)", "ground_truth": "e1[1]", "quality_analysis": {"complexity_score": 18, "left_complexity": 13, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_845", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_GraphSAGELinkGenerator", "funcname": "test_GraphSAGELinkGenerator_shuffle", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_GraphSAGELinkGenerator_shuffle(self):\n\n    def test_edge_consistency(shuffle):\n        G = example_graph(feature_size=1)\n        edges = list(G.edges())\n        edge_labels = list(range(len(edges)))\n        mapper = GraphSAGELinkGenerator(G, batch_size=2, num_samples=[0]).flow(edges, edge_labels, shuffle=shuffle)\n        assert (len(mapper) == 2)\n        for batch in range(len(mapper)):\n            (nf, nl) = mapper[batch]\n            e1 = edges[nl[0]]\n            e2 = edges[nl[1]]\n            assert (nf[0][(0, 0, 0)] == e1[0])\n            assert (nf[1][(0, 0, 0)] == e1[1])\n            assert (nf[0][(1, 0, 0)] == e2[0])\n            assert (nf[1][(1, 0, 0)] == e2[1])\n    test_edge_consistency(True)\n    test_edge_consistency(False)", "masked_code": "def test_GraphSAGELinkGenerator_shuffle(self):\n\n    def test_edge_consistency(shuffle):\n        G = example_graph(feature_size=1)\n        edges = list(G.edges())\n        edge_labels = list(range(len(edges)))\n        mapper = GraphSAGELinkGenerator(G, batch_size=2, num_samples=[0]).flow(edges, edge_labels, shuffle=shuffle)\n        assert (len(mapper) == 2)\n        for batch in range(len(mapper)):\n            (nf, nl) = mapper[batch]\n            e1 = edges[nl[0]]\n            e2 = edges[nl[1]]\n            assert (nf[0][(0, 0, 0)] == e1[0])\n            assert (nf[1][(0, 0, 0)] == e1[1])\n            assert (nf[0][(1, 0, 0)] == '???')\n            assert (nf[1][(1, 0, 0)] == e2[1])\n    test_edge_consistency(True)\n    test_edge_consistency(False)", "ground_truth": "e2[0]", "quality_analysis": {"complexity_score": 18, "left_complexity": 13, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_846", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_GraphSAGELinkGenerator", "funcname": "test_GraphSAGELinkGenerator_shuffle", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_GraphSAGELinkGenerator_shuffle(self):\n\n    def test_edge_consistency(shuffle):\n        G = example_graph(feature_size=1)\n        edges = list(G.edges())\n        edge_labels = list(range(len(edges)))\n        mapper = GraphSAGELinkGenerator(G, batch_size=2, num_samples=[0]).flow(edges, edge_labels, shuffle=shuffle)\n        assert (len(mapper) == 2)\n        for batch in range(len(mapper)):\n            (nf, nl) = mapper[batch]\n            e1 = edges[nl[0]]\n            e2 = edges[nl[1]]\n            assert (nf[0][(0, 0, 0)] == e1[0])\n            assert (nf[1][(0, 0, 0)] == e1[1])\n            assert (nf[0][(1, 0, 0)] == e2[0])\n            assert (nf[1][(1, 0, 0)] == e2[1])\n    test_edge_consistency(True)\n    test_edge_consistency(False)", "masked_code": "def test_GraphSAGELinkGenerator_shuffle(self):\n\n    def test_edge_consistency(shuffle):\n        G = example_graph(feature_size=1)\n        edges = list(G.edges())\n        edge_labels = list(range(len(edges)))\n        mapper = GraphSAGELinkGenerator(G, batch_size=2, num_samples=[0]).flow(edges, edge_labels, shuffle=shuffle)\n        assert (len(mapper) == 2)\n        for batch in range(len(mapper)):\n            (nf, nl) = mapper[batch]\n            e1 = edges[nl[0]]\n            e2 = edges[nl[1]]\n            assert (nf[0][(0, 0, 0)] == e1[0])\n            assert (nf[1][(0, 0, 0)] == e1[1])\n            assert (nf[0][(1, 0, 0)] == e2[0])\n            assert (nf[1][(1, 0, 0)] == '???')\n    test_edge_consistency(True)\n    test_edge_consistency(False)", "ground_truth": "e2[1]", "quality_analysis": {"complexity_score": 18, "left_complexity": 13, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_847", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_GraphSAGELinkGenerator", "funcname": "test_edge_consistency", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_edge_consistency(shuffle):\n    G = example_graph(feature_size=1)\n    edges = list(G.edges())\n    edge_labels = list(range(len(edges)))\n    mapper = GraphSAGELinkGenerator(G, batch_size=2, num_samples=[0]).flow(edges, edge_labels, shuffle=shuffle)\n    assert (len(mapper) == 2)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        e1 = edges[nl[0]]\n        e2 = edges[nl[1]]\n        assert (nf[0][(0, 0, 0)] == e1[0])\n        assert (nf[1][(0, 0, 0)] == e1[1])\n        assert (nf[0][(1, 0, 0)] == e2[0])\n        assert (nf[1][(1, 0, 0)] == e2[1])", "masked_code": "def test_edge_consistency(shuffle):\n    G = example_graph(feature_size=1)\n    edges = list(G.edges())\n    edge_labels = list(range(len(edges)))\n    mapper = GraphSAGELinkGenerator(G, batch_size=2, num_samples=[0]).flow(edges, edge_labels, shuffle=shuffle)\n    assert (len(mapper) == 2)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        e1 = edges[nl[0]]\n        e2 = edges[nl[1]]\n        assert (nf[0][(0, 0, 0)] == '???')\n        assert (nf[1][(0, 0, 0)] == e1[1])\n        assert (nf[0][(1, 0, 0)] == e2[0])\n        assert (nf[1][(1, 0, 0)] == e2[1])", "ground_truth": "e1[0]", "quality_analysis": {"complexity_score": 18, "left_complexity": 13, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_848", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_GraphSAGELinkGenerator", "funcname": "test_edge_consistency", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_edge_consistency(shuffle):\n    G = example_graph(feature_size=1)\n    edges = list(G.edges())\n    edge_labels = list(range(len(edges)))\n    mapper = GraphSAGELinkGenerator(G, batch_size=2, num_samples=[0]).flow(edges, edge_labels, shuffle=shuffle)\n    assert (len(mapper) == 2)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        e1 = edges[nl[0]]\n        e2 = edges[nl[1]]\n        assert (nf[0][(0, 0, 0)] == e1[0])\n        assert (nf[1][(0, 0, 0)] == e1[1])\n        assert (nf[0][(1, 0, 0)] == e2[0])\n        assert (nf[1][(1, 0, 0)] == e2[1])", "masked_code": "def test_edge_consistency(shuffle):\n    G = example_graph(feature_size=1)\n    edges = list(G.edges())\n    edge_labels = list(range(len(edges)))\n    mapper = GraphSAGELinkGenerator(G, batch_size=2, num_samples=[0]).flow(edges, edge_labels, shuffle=shuffle)\n    assert (len(mapper) == 2)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        e1 = edges[nl[0]]\n        e2 = edges[nl[1]]\n        assert (nf[0][(0, 0, 0)] == e1[0])\n        assert (nf[1][(0, 0, 0)] == '???')\n        assert (nf[0][(1, 0, 0)] == e2[0])\n        assert (nf[1][(1, 0, 0)] == e2[1])", "ground_truth": "e1[1]", "quality_analysis": {"complexity_score": 18, "left_complexity": 13, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_849", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_GraphSAGELinkGenerator", "funcname": "test_edge_consistency", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_edge_consistency(shuffle):\n    G = example_graph(feature_size=1)\n    edges = list(G.edges())\n    edge_labels = list(range(len(edges)))\n    mapper = GraphSAGELinkGenerator(G, batch_size=2, num_samples=[0]).flow(edges, edge_labels, shuffle=shuffle)\n    assert (len(mapper) == 2)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        e1 = edges[nl[0]]\n        e2 = edges[nl[1]]\n        assert (nf[0][(0, 0, 0)] == e1[0])\n        assert (nf[1][(0, 0, 0)] == e1[1])\n        assert (nf[0][(1, 0, 0)] == e2[0])\n        assert (nf[1][(1, 0, 0)] == e2[1])", "masked_code": "def test_edge_consistency(shuffle):\n    G = example_graph(feature_size=1)\n    edges = list(G.edges())\n    edge_labels = list(range(len(edges)))\n    mapper = GraphSAGELinkGenerator(G, batch_size=2, num_samples=[0]).flow(edges, edge_labels, shuffle=shuffle)\n    assert (len(mapper) == 2)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        e1 = edges[nl[0]]\n        e2 = edges[nl[1]]\n        assert (nf[0][(0, 0, 0)] == e1[0])\n        assert (nf[1][(0, 0, 0)] == e1[1])\n        assert (nf[0][(1, 0, 0)] == '???')\n        assert (nf[1][(1, 0, 0)] == e2[1])", "ground_truth": "e2[0]", "quality_analysis": {"complexity_score": 18, "left_complexity": 13, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_850", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_GraphSAGELinkGenerator", "funcname": "test_edge_consistency", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_edge_consistency(shuffle):\n    G = example_graph(feature_size=1)\n    edges = list(G.edges())\n    edge_labels = list(range(len(edges)))\n    mapper = GraphSAGELinkGenerator(G, batch_size=2, num_samples=[0]).flow(edges, edge_labels, shuffle=shuffle)\n    assert (len(mapper) == 2)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        e1 = edges[nl[0]]\n        e2 = edges[nl[1]]\n        assert (nf[0][(0, 0, 0)] == e1[0])\n        assert (nf[1][(0, 0, 0)] == e1[1])\n        assert (nf[0][(1, 0, 0)] == e2[0])\n        assert (nf[1][(1, 0, 0)] == e2[1])", "masked_code": "def test_edge_consistency(shuffle):\n    G = example_graph(feature_size=1)\n    edges = list(G.edges())\n    edge_labels = list(range(len(edges)))\n    mapper = GraphSAGELinkGenerator(G, batch_size=2, num_samples=[0]).flow(edges, edge_labels, shuffle=shuffle)\n    assert (len(mapper) == 2)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        e1 = edges[nl[0]]\n        e2 = edges[nl[1]]\n        assert (nf[0][(0, 0, 0)] == e1[0])\n        assert (nf[1][(0, 0, 0)] == e1[1])\n        assert (nf[0][(1, 0, 0)] == e2[0])\n        assert (nf[1][(1, 0, 0)] == '???')", "ground_truth": "e2[1]", "quality_analysis": {"complexity_score": 18, "left_complexity": 13, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_851", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_GraphSAGELinkGenerator", "funcname": "test_GraphSAGELinkGenerator_zero_samples", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_GraphSAGELinkGenerator_zero_samples(self):\n    G = example_graph(feature_size=self.n_feat)\n    data_size = G.number_of_edges()\n    edge_labels = ([0] * data_size)\n    mapper = GraphSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=[0]).flow(G.edges(), edge_labels)\n    assert (len(mapper) == 2)\n    for ii in range(len(mapper)):\n        (nf, nl) = mapper[ii]\n        assert (len(nf) == (2 * 2))\n        for j in range(len(nf)):\n            if (j < self.batch_size):\n                assert (nf[j].shape == (min(self.batch_size, data_size), 1, self.n_feat))\n            else:\n                assert (nf[j].shape == (min(self.batch_size, data_size), 0, self.n_feat))\n        assert (len(nl) == min(self.batch_size, data_size))\n        assert all((nl == 0))", "masked_code": "def test_GraphSAGELinkGenerator_zero_samples(self):\n    G = example_graph(feature_size=self.n_feat)\n    data_size = G.number_of_edges()\n    edge_labels = ([0] * data_size)\n    mapper = GraphSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=[0]).flow(G.edges(), edge_labels)\n    assert (len(mapper) == 2)\n    for ii in range(len(mapper)):\n        (nf, nl) = mapper[ii]\n        assert (len(nf) == '???')\n        for j in range(len(nf)):\n            if (j < self.batch_size):\n                assert (nf[j].shape == (min(self.batch_size, data_size), 1, self.n_feat))\n            else:\n                assert (nf[j].shape == (min(self.batch_size, data_size), 0, self.n_feat))\n        assert (len(nl) == min(self.batch_size, data_size))\n        assert all((nl == 0))", "ground_truth": "(2 * 2)", "quality_analysis": {"complexity_score": 8, "left_complexity": 4, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_852", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_GraphSAGELinkGenerator", "funcname": "test_GraphSAGELinkGenerator_zero_samples", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_GraphSAGELinkGenerator_zero_samples(self):\n    G = example_graph(feature_size=self.n_feat)\n    data_size = G.number_of_edges()\n    edge_labels = ([0] * data_size)\n    mapper = GraphSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=[0]).flow(G.edges(), edge_labels)\n    assert (len(mapper) == 2)\n    for ii in range(len(mapper)):\n        (nf, nl) = mapper[ii]\n        assert (len(nf) == (2 * 2))\n        for j in range(len(nf)):\n            if (j < self.batch_size):\n                assert (nf[j].shape == (min(self.batch_size, data_size), 1, self.n_feat))\n            else:\n                assert (nf[j].shape == (min(self.batch_size, data_size), 0, self.n_feat))\n        assert (len(nl) == min(self.batch_size, data_size))\n        assert all((nl == 0))", "masked_code": "def test_GraphSAGELinkGenerator_zero_samples(self):\n    G = example_graph(feature_size=self.n_feat)\n    data_size = G.number_of_edges()\n    edge_labels = ([0] * data_size)\n    mapper = GraphSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=[0]).flow(G.edges(), edge_labels)\n    assert (len(mapper) == 2)\n    for ii in range(len(mapper)):\n        (nf, nl) = mapper[ii]\n        assert (len(nf) == (2 * 2))\n        for j in range(len(nf)):\n            if (j < self.batch_size):\n                assert (nf[j].shape == (min(self.batch_size, data_size), 1, self.n_feat))\n            else:\n                assert (nf[j].shape == (min(self.batch_size, data_size), 0, self.n_feat))\n        assert (len(nl) == '???')\n        assert all((nl == 0))", "ground_truth": "min(self.batch_size, data_size)", "quality_analysis": {"complexity_score": 10, "left_complexity": 4, "right_complexity": 6, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_853", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_GraphSAGELinkGenerator", "funcname": "test_GraphSAGELinkGenerator_zero_samples", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_GraphSAGELinkGenerator_zero_samples(self):\n    G = example_graph(feature_size=self.n_feat)\n    data_size = G.number_of_edges()\n    edge_labels = ([0] * data_size)\n    mapper = GraphSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=[0]).flow(G.edges(), edge_labels)\n    assert (len(mapper) == 2)\n    for ii in range(len(mapper)):\n        (nf, nl) = mapper[ii]\n        assert (len(nf) == (2 * 2))\n        for j in range(len(nf)):\n            if (j < self.batch_size):\n                assert (nf[j].shape == (min(self.batch_size, data_size), 1, self.n_feat))\n            else:\n                assert (nf[j].shape == (min(self.batch_size, data_size), 0, self.n_feat))\n        assert (len(nl) == min(self.batch_size, data_size))\n        assert all((nl == 0))", "masked_code": "def test_GraphSAGELinkGenerator_zero_samples(self):\n    G = example_graph(feature_size=self.n_feat)\n    data_size = G.number_of_edges()\n    edge_labels = ([0] * data_size)\n    mapper = GraphSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=[0]).flow(G.edges(), edge_labels)\n    assert (len(mapper) == 2)\n    for ii in range(len(mapper)):\n        (nf, nl) = mapper[ii]\n        assert (len(nf) == (2 * 2))\n        for j in range(len(nf)):\n            if (j < self.batch_size):\n                assert (nf[j].shape == '???')\n            else:\n                assert (nf[j].shape == (min(self.batch_size, data_size), 0, self.n_feat))\n        assert (len(nl) == min(self.batch_size, data_size))\n        assert all((nl == 0))", "ground_truth": "(min(self.batch_size, data_size), 1, self.n_feat)", "quality_analysis": {"complexity_score": 13, "left_complexity": 2, "right_complexity": 11, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_854", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_GraphSAGELinkGenerator", "funcname": "test_GraphSAGELinkGenerator_zero_samples", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_GraphSAGELinkGenerator_zero_samples(self):\n    G = example_graph(feature_size=self.n_feat)\n    data_size = G.number_of_edges()\n    edge_labels = ([0] * data_size)\n    mapper = GraphSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=[0]).flow(G.edges(), edge_labels)\n    assert (len(mapper) == 2)\n    for ii in range(len(mapper)):\n        (nf, nl) = mapper[ii]\n        assert (len(nf) == (2 * 2))\n        for j in range(len(nf)):\n            if (j < self.batch_size):\n                assert (nf[j].shape == (min(self.batch_size, data_size), 1, self.n_feat))\n            else:\n                assert (nf[j].shape == (min(self.batch_size, data_size), 0, self.n_feat))\n        assert (len(nl) == min(self.batch_size, data_size))\n        assert all((nl == 0))", "masked_code": "def test_GraphSAGELinkGenerator_zero_samples(self):\n    G = example_graph(feature_size=self.n_feat)\n    data_size = G.number_of_edges()\n    edge_labels = ([0] * data_size)\n    mapper = GraphSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=[0]).flow(G.edges(), edge_labels)\n    assert (len(mapper) == 2)\n    for ii in range(len(mapper)):\n        (nf, nl) = mapper[ii]\n        assert (len(nf) == (2 * 2))\n        for j in range(len(nf)):\n            if (j < self.batch_size):\n                assert (nf[j].shape == (min(self.batch_size, data_size), 1, self.n_feat))\n            else:\n                assert (nf[j].shape == '???')\n        assert (len(nl) == min(self.batch_size, data_size))\n        assert all((nl == 0))", "ground_truth": "(min(self.batch_size, data_size), 0, self.n_feat)", "quality_analysis": {"complexity_score": 13, "left_complexity": 2, "right_complexity": 11, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_855", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_GraphSAGELinkGenerator", "funcname": "test_GraphSAGELinkGenerator_isolates", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_GraphSAGELinkGenerator_isolates(self):\n    '\\n        Test for handling of isolated nodes\\n        '\n    n_feat = 4\n    n_batch = 2\n    n_samples = [2, 2]\n    G = example_graph_random(feature_size=n_feat, n_nodes=6, n_isolates=2, n_edges=10)\n    head_links = [(1, 5)]\n    gen = GraphSAGELinkGenerator(G, batch_size=n_batch, num_samples=n_samples).flow(head_links)\n    (ne, nl) = gen[0]\n    assert (pytest.approx([1, 1, 2, 2, 4, 4]) == [x.shape[1] for x in ne])\n    head_links = [(4, 5)]\n    gen = GraphSAGELinkGenerator(G, batch_size=n_batch, num_samples=n_samples).flow(head_links)\n    (ne, nl) = gen[0]\n    assert (pytest.approx([1, 1, 2, 2, 4, 4]) == [x.shape[1] for x in ne])", "masked_code": "def test_GraphSAGELinkGenerator_isolates(self):\n    '\\n        Test for handling of isolated nodes\\n        '\n    n_feat = 4\n    n_batch = 2\n    n_samples = [2, 2]\n    G = example_graph_random(feature_size=n_feat, n_nodes=6, n_isolates=2, n_edges=10)\n    head_links = [(1, 5)]\n    gen = GraphSAGELinkGenerator(G, batch_size=n_batch, num_samples=n_samples).flow(head_links)\n    (ne, nl) = gen[0]\n    assert (pytest.approx([1, 1, 2, 2, 4, 4]) == '???')\n    head_links = [(4, 5)]\n    gen = GraphSAGELinkGenerator(G, batch_size=n_batch, num_samples=n_samples).flow(head_links)\n    (ne, nl) = gen[0]\n    assert (pytest.approx([1, 1, 2, 2, 4, 4]) == [x.shape[1] for x in ne])", "ground_truth": "[x.shape[1] for x in ne]", "quality_analysis": {"complexity_score": 11, "left_complexity": 11, "right_complexity": 0, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_856", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_GraphSAGELinkGenerator", "funcname": "test_GraphSAGELinkGenerator_isolates", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_GraphSAGELinkGenerator_isolates(self):\n    '\\n        Test for handling of isolated nodes\\n        '\n    n_feat = 4\n    n_batch = 2\n    n_samples = [2, 2]\n    G = example_graph_random(feature_size=n_feat, n_nodes=6, n_isolates=2, n_edges=10)\n    head_links = [(1, 5)]\n    gen = GraphSAGELinkGenerator(G, batch_size=n_batch, num_samples=n_samples).flow(head_links)\n    (ne, nl) = gen[0]\n    assert (pytest.approx([1, 1, 2, 2, 4, 4]) == [x.shape[1] for x in ne])\n    head_links = [(4, 5)]\n    gen = GraphSAGELinkGenerator(G, batch_size=n_batch, num_samples=n_samples).flow(head_links)\n    (ne, nl) = gen[0]\n    assert (pytest.approx([1, 1, 2, 2, 4, 4]) == [x.shape[1] for x in ne])", "masked_code": "def test_GraphSAGELinkGenerator_isolates(self):\n    '\\n        Test for handling of isolated nodes\\n        '\n    n_feat = 4\n    n_batch = 2\n    n_samples = [2, 2]\n    G = example_graph_random(feature_size=n_feat, n_nodes=6, n_isolates=2, n_edges=10)\n    head_links = [(1, 5)]\n    gen = GraphSAGELinkGenerator(G, batch_size=n_batch, num_samples=n_samples).flow(head_links)\n    (ne, nl) = gen[0]\n    assert (pytest.approx([1, 1, 2, 2, 4, 4]) == [x.shape[1] for x in ne])\n    head_links = [(4, 5)]\n    gen = GraphSAGELinkGenerator(G, batch_size=n_batch, num_samples=n_samples).flow(head_links)\n    (ne, nl) = gen[0]\n    assert (pytest.approx([1, 1, 2, 2, 4, 4]) == '???')", "ground_truth": "[x.shape[1] for x in ne]", "quality_analysis": {"complexity_score": 11, "left_complexity": 11, "right_complexity": 0, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_857", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_GraphSAGELinkGenerator", "funcname": "test_GraphSAGELinkGenerator_unsupervisedSampler_sample_generation", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_GraphSAGELinkGenerator_unsupervisedSampler_sample_generation(self):\n    G = example_graph(feature_size=self.n_feat)\n    unsupervisedSamples = UnsupervisedSampler(G)\n    gen = GraphSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=self.num_samples)\n    mapper = gen.flow(unsupervisedSamples)\n    assert (mapper.data_size == (len(list(G.nodes())) * 2))\n    assert (mapper.batch_size == self.batch_size)\n    assert (len(mapper) == np.ceil((mapper.data_size / mapper.batch_size)))\n    assert (len(set(gen.head_node_types)) == 1)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        assert (len(nf) == (3 * 2))\n        for ii in range(2):\n            assert (nf[ii].shape == (min(self.batch_size, mapper.data_size), 1, self.n_feat))\n            assert (nf[(ii + 2)].shape == (min(self.batch_size, mapper.data_size), 2, self.n_feat))\n            assert (nf[(ii + (2 * 2))].shape == (min(self.batch_size, mapper.data_size), (2 * 2), self.n_feat))\n            assert (len(nl) == min(self.batch_size, mapper.data_size))\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper[8]", "masked_code": "def test_GraphSAGELinkGenerator_unsupervisedSampler_sample_generation(self):\n    G = example_graph(feature_size=self.n_feat)\n    unsupervisedSamples = UnsupervisedSampler(G)\n    gen = GraphSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=self.num_samples)\n    mapper = gen.flow(unsupervisedSamples)\n    assert (mapper.data_size == '???')\n    assert (mapper.batch_size == self.batch_size)\n    assert (len(mapper) == np.ceil((mapper.data_size / mapper.batch_size)))\n    assert (len(set(gen.head_node_types)) == 1)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        assert (len(nf) == (3 * 2))\n        for ii in range(2):\n            assert (nf[ii].shape == (min(self.batch_size, mapper.data_size), 1, self.n_feat))\n            assert (nf[(ii + 2)].shape == (min(self.batch_size, mapper.data_size), 2, self.n_feat))\n            assert (nf[(ii + (2 * 2))].shape == (min(self.batch_size, mapper.data_size), (2 * 2), self.n_feat))\n            assert (len(nl) == min(self.batch_size, mapper.data_size))\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper[8]", "ground_truth": "(len(list(G.nodes())) * 2)", "quality_analysis": {"complexity_score": 14, "left_complexity": 2, "right_complexity": 12, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_858", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_GraphSAGELinkGenerator", "funcname": "test_GraphSAGELinkGenerator_unsupervisedSampler_sample_generation", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_GraphSAGELinkGenerator_unsupervisedSampler_sample_generation(self):\n    G = example_graph(feature_size=self.n_feat)\n    unsupervisedSamples = UnsupervisedSampler(G)\n    gen = GraphSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=self.num_samples)\n    mapper = gen.flow(unsupervisedSamples)\n    assert (mapper.data_size == (len(list(G.nodes())) * 2))\n    assert (mapper.batch_size == self.batch_size)\n    assert (len(mapper) == np.ceil((mapper.data_size / mapper.batch_size)))\n    assert (len(set(gen.head_node_types)) == 1)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        assert (len(nf) == (3 * 2))\n        for ii in range(2):\n            assert (nf[ii].shape == (min(self.batch_size, mapper.data_size), 1, self.n_feat))\n            assert (nf[(ii + 2)].shape == (min(self.batch_size, mapper.data_size), 2, self.n_feat))\n            assert (nf[(ii + (2 * 2))].shape == (min(self.batch_size, mapper.data_size), (2 * 2), self.n_feat))\n            assert (len(nl) == min(self.batch_size, mapper.data_size))\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper[8]", "masked_code": "def test_GraphSAGELinkGenerator_unsupervisedSampler_sample_generation(self):\n    G = example_graph(feature_size=self.n_feat)\n    unsupervisedSamples = UnsupervisedSampler(G)\n    gen = GraphSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=self.num_samples)\n    mapper = gen.flow(unsupervisedSamples)\n    assert (mapper.data_size == (len(list(G.nodes())) * 2))\n    assert (mapper.batch_size == '???')\n    assert (len(mapper) == np.ceil((mapper.data_size / mapper.batch_size)))\n    assert (len(set(gen.head_node_types)) == 1)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        assert (len(nf) == (3 * 2))\n        for ii in range(2):\n            assert (nf[ii].shape == (min(self.batch_size, mapper.data_size), 1, self.n_feat))\n            assert (nf[(ii + 2)].shape == (min(self.batch_size, mapper.data_size), 2, self.n_feat))\n            assert (nf[(ii + (2 * 2))].shape == (min(self.batch_size, mapper.data_size), (2 * 2), self.n_feat))\n            assert (len(nl) == min(self.batch_size, mapper.data_size))\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper[8]", "ground_truth": "self.batch_size", "quality_analysis": {"complexity_score": 4, "left_complexity": 2, "right_complexity": 2, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_859", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_GraphSAGELinkGenerator", "funcname": "test_GraphSAGELinkGenerator_unsupervisedSampler_sample_generation", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_GraphSAGELinkGenerator_unsupervisedSampler_sample_generation(self):\n    G = example_graph(feature_size=self.n_feat)\n    unsupervisedSamples = UnsupervisedSampler(G)\n    gen = GraphSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=self.num_samples)\n    mapper = gen.flow(unsupervisedSamples)\n    assert (mapper.data_size == (len(list(G.nodes())) * 2))\n    assert (mapper.batch_size == self.batch_size)\n    assert (len(mapper) == np.ceil((mapper.data_size / mapper.batch_size)))\n    assert (len(set(gen.head_node_types)) == 1)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        assert (len(nf) == (3 * 2))\n        for ii in range(2):\n            assert (nf[ii].shape == (min(self.batch_size, mapper.data_size), 1, self.n_feat))\n            assert (nf[(ii + 2)].shape == (min(self.batch_size, mapper.data_size), 2, self.n_feat))\n            assert (nf[(ii + (2 * 2))].shape == (min(self.batch_size, mapper.data_size), (2 * 2), self.n_feat))\n            assert (len(nl) == min(self.batch_size, mapper.data_size))\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper[8]", "masked_code": "def test_GraphSAGELinkGenerator_unsupervisedSampler_sample_generation(self):\n    G = example_graph(feature_size=self.n_feat)\n    unsupervisedSamples = UnsupervisedSampler(G)\n    gen = GraphSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=self.num_samples)\n    mapper = gen.flow(unsupervisedSamples)\n    assert (mapper.data_size == (len(list(G.nodes())) * 2))\n    assert (mapper.batch_size == self.batch_size)\n    assert (len(mapper) == '???')\n    assert (len(set(gen.head_node_types)) == 1)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        assert (len(nf) == (3 * 2))\n        for ii in range(2):\n            assert (nf[ii].shape == (min(self.batch_size, mapper.data_size), 1, self.n_feat))\n            assert (nf[(ii + 2)].shape == (min(self.batch_size, mapper.data_size), 2, self.n_feat))\n            assert (nf[(ii + (2 * 2))].shape == (min(self.batch_size, mapper.data_size), (2 * 2), self.n_feat))\n            assert (len(nl) == min(self.batch_size, mapper.data_size))\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper[8]", "ground_truth": "np.ceil((mapper.data_size / mapper.batch_size))", "quality_analysis": {"complexity_score": 13, "left_complexity": 4, "right_complexity": 9, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_860", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_GraphSAGELinkGenerator", "funcname": "test_GraphSAGELinkGenerator_unsupervisedSampler_sample_generation", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_GraphSAGELinkGenerator_unsupervisedSampler_sample_generation(self):\n    G = example_graph(feature_size=self.n_feat)\n    unsupervisedSamples = UnsupervisedSampler(G)\n    gen = GraphSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=self.num_samples)\n    mapper = gen.flow(unsupervisedSamples)\n    assert (mapper.data_size == (len(list(G.nodes())) * 2))\n    assert (mapper.batch_size == self.batch_size)\n    assert (len(mapper) == np.ceil((mapper.data_size / mapper.batch_size)))\n    assert (len(set(gen.head_node_types)) == 1)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        assert (len(nf) == (3 * 2))\n        for ii in range(2):\n            assert (nf[ii].shape == (min(self.batch_size, mapper.data_size), 1, self.n_feat))\n            assert (nf[(ii + 2)].shape == (min(self.batch_size, mapper.data_size), 2, self.n_feat))\n            assert (nf[(ii + (2 * 2))].shape == (min(self.batch_size, mapper.data_size), (2 * 2), self.n_feat))\n            assert (len(nl) == min(self.batch_size, mapper.data_size))\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper[8]", "masked_code": "def test_GraphSAGELinkGenerator_unsupervisedSampler_sample_generation(self):\n    G = example_graph(feature_size=self.n_feat)\n    unsupervisedSamples = UnsupervisedSampler(G)\n    gen = GraphSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=self.num_samples)\n    mapper = gen.flow(unsupervisedSamples)\n    assert (mapper.data_size == (len(list(G.nodes())) * 2))\n    assert (mapper.batch_size == self.batch_size)\n    assert (len(mapper) == np.ceil((mapper.data_size / mapper.batch_size)))\n    assert (len(set(gen.head_node_types)) == 1)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        assert (len(nf) == '???')\n        for ii in range(2):\n            assert (nf[ii].shape == (min(self.batch_size, mapper.data_size), 1, self.n_feat))\n            assert (nf[(ii + 2)].shape == (min(self.batch_size, mapper.data_size), 2, self.n_feat))\n            assert (nf[(ii + (2 * 2))].shape == (min(self.batch_size, mapper.data_size), (2 * 2), self.n_feat))\n            assert (len(nl) == min(self.batch_size, mapper.data_size))\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper[8]", "ground_truth": "(3 * 2)", "quality_analysis": {"complexity_score": 8, "left_complexity": 4, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_861", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_GraphSAGELinkGenerator", "funcname": "test_GraphSAGELinkGenerator_unsupervisedSampler_sample_generation", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_GraphSAGELinkGenerator_unsupervisedSampler_sample_generation(self):\n    G = example_graph(feature_size=self.n_feat)\n    unsupervisedSamples = UnsupervisedSampler(G)\n    gen = GraphSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=self.num_samples)\n    mapper = gen.flow(unsupervisedSamples)\n    assert (mapper.data_size == (len(list(G.nodes())) * 2))\n    assert (mapper.batch_size == self.batch_size)\n    assert (len(mapper) == np.ceil((mapper.data_size / mapper.batch_size)))\n    assert (len(set(gen.head_node_types)) == 1)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        assert (len(nf) == (3 * 2))\n        for ii in range(2):\n            assert (nf[ii].shape == (min(self.batch_size, mapper.data_size), 1, self.n_feat))\n            assert (nf[(ii + 2)].shape == (min(self.batch_size, mapper.data_size), 2, self.n_feat))\n            assert (nf[(ii + (2 * 2))].shape == (min(self.batch_size, mapper.data_size), (2 * 2), self.n_feat))\n            assert (len(nl) == min(self.batch_size, mapper.data_size))\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper[8]", "masked_code": "def test_GraphSAGELinkGenerator_unsupervisedSampler_sample_generation(self):\n    G = example_graph(feature_size=self.n_feat)\n    unsupervisedSamples = UnsupervisedSampler(G)\n    gen = GraphSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=self.num_samples)\n    mapper = gen.flow(unsupervisedSamples)\n    assert (mapper.data_size == (len(list(G.nodes())) * 2))\n    assert (mapper.batch_size == self.batch_size)\n    assert (len(mapper) == np.ceil((mapper.data_size / mapper.batch_size)))\n    assert (len(set(gen.head_node_types)) == 1)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        assert (len(nf) == (3 * 2))\n        for ii in range(2):\n            assert (nf[ii].shape == '???')\n            assert (nf[(ii + 2)].shape == (min(self.batch_size, mapper.data_size), 2, self.n_feat))\n            assert (nf[(ii + (2 * 2))].shape == (min(self.batch_size, mapper.data_size), (2 * 2), self.n_feat))\n            assert (len(nl) == min(self.batch_size, mapper.data_size))\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper[8]", "ground_truth": "(min(self.batch_size, mapper.data_size), 1, self.n_feat)", "quality_analysis": {"complexity_score": 14, "left_complexity": 2, "right_complexity": 12, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_862", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_GraphSAGELinkGenerator", "funcname": "test_GraphSAGELinkGenerator_unsupervisedSampler_sample_generation", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_GraphSAGELinkGenerator_unsupervisedSampler_sample_generation(self):\n    G = example_graph(feature_size=self.n_feat)\n    unsupervisedSamples = UnsupervisedSampler(G)\n    gen = GraphSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=self.num_samples)\n    mapper = gen.flow(unsupervisedSamples)\n    assert (mapper.data_size == (len(list(G.nodes())) * 2))\n    assert (mapper.batch_size == self.batch_size)\n    assert (len(mapper) == np.ceil((mapper.data_size / mapper.batch_size)))\n    assert (len(set(gen.head_node_types)) == 1)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        assert (len(nf) == (3 * 2))\n        for ii in range(2):\n            assert (nf[ii].shape == (min(self.batch_size, mapper.data_size), 1, self.n_feat))\n            assert (nf[(ii + 2)].shape == (min(self.batch_size, mapper.data_size), 2, self.n_feat))\n            assert (nf[(ii + (2 * 2))].shape == (min(self.batch_size, mapper.data_size), (2 * 2), self.n_feat))\n            assert (len(nl) == min(self.batch_size, mapper.data_size))\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper[8]", "masked_code": "def test_GraphSAGELinkGenerator_unsupervisedSampler_sample_generation(self):\n    G = example_graph(feature_size=self.n_feat)\n    unsupervisedSamples = UnsupervisedSampler(G)\n    gen = GraphSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=self.num_samples)\n    mapper = gen.flow(unsupervisedSamples)\n    assert (mapper.data_size == (len(list(G.nodes())) * 2))\n    assert (mapper.batch_size == self.batch_size)\n    assert (len(mapper) == np.ceil((mapper.data_size / mapper.batch_size)))\n    assert (len(set(gen.head_node_types)) == 1)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        assert (len(nf) == (3 * 2))\n        for ii in range(2):\n            assert (nf[ii].shape == (min(self.batch_size, mapper.data_size), 1, self.n_feat))\n            assert (nf[(ii + 2)].shape == '???')\n            assert (nf[(ii + (2 * 2))].shape == (min(self.batch_size, mapper.data_size), (2 * 2), self.n_feat))\n            assert (len(nl) == min(self.batch_size, mapper.data_size))\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper[8]", "ground_truth": "(min(self.batch_size, mapper.data_size), 2, self.n_feat)", "quality_analysis": {"complexity_score": 14, "left_complexity": 2, "right_complexity": 12, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_863", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_GraphSAGELinkGenerator", "funcname": "test_GraphSAGELinkGenerator_unsupervisedSampler_sample_generation", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_GraphSAGELinkGenerator_unsupervisedSampler_sample_generation(self):\n    G = example_graph(feature_size=self.n_feat)\n    unsupervisedSamples = UnsupervisedSampler(G)\n    gen = GraphSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=self.num_samples)\n    mapper = gen.flow(unsupervisedSamples)\n    assert (mapper.data_size == (len(list(G.nodes())) * 2))\n    assert (mapper.batch_size == self.batch_size)\n    assert (len(mapper) == np.ceil((mapper.data_size / mapper.batch_size)))\n    assert (len(set(gen.head_node_types)) == 1)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        assert (len(nf) == (3 * 2))\n        for ii in range(2):\n            assert (nf[ii].shape == (min(self.batch_size, mapper.data_size), 1, self.n_feat))\n            assert (nf[(ii + 2)].shape == (min(self.batch_size, mapper.data_size), 2, self.n_feat))\n            assert (nf[(ii + (2 * 2))].shape == (min(self.batch_size, mapper.data_size), (2 * 2), self.n_feat))\n            assert (len(nl) == min(self.batch_size, mapper.data_size))\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper[8]", "masked_code": "def test_GraphSAGELinkGenerator_unsupervisedSampler_sample_generation(self):\n    G = example_graph(feature_size=self.n_feat)\n    unsupervisedSamples = UnsupervisedSampler(G)\n    gen = GraphSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=self.num_samples)\n    mapper = gen.flow(unsupervisedSamples)\n    assert (mapper.data_size == (len(list(G.nodes())) * 2))\n    assert (mapper.batch_size == self.batch_size)\n    assert (len(mapper) == np.ceil((mapper.data_size / mapper.batch_size)))\n    assert (len(set(gen.head_node_types)) == 1)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        assert (len(nf) == (3 * 2))\n        for ii in range(2):\n            assert (nf[ii].shape == (min(self.batch_size, mapper.data_size), 1, self.n_feat))\n            assert (nf[(ii + 2)].shape == (min(self.batch_size, mapper.data_size), 2, self.n_feat))\n            assert (nf[(ii + (2 * 2))].shape == '???')\n            assert (len(nl) == min(self.batch_size, mapper.data_size))\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper[8]", "ground_truth": "(min(self.batch_size, mapper.data_size), (2 * 2), self.n_feat)", "quality_analysis": {"complexity_score": 17, "left_complexity": 2, "right_complexity": 15, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_864", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_GraphSAGELinkGenerator", "funcname": "test_GraphSAGELinkGenerator_unsupervisedSampler_sample_generation", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_GraphSAGELinkGenerator_unsupervisedSampler_sample_generation(self):\n    G = example_graph(feature_size=self.n_feat)\n    unsupervisedSamples = UnsupervisedSampler(G)\n    gen = GraphSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=self.num_samples)\n    mapper = gen.flow(unsupervisedSamples)\n    assert (mapper.data_size == (len(list(G.nodes())) * 2))\n    assert (mapper.batch_size == self.batch_size)\n    assert (len(mapper) == np.ceil((mapper.data_size / mapper.batch_size)))\n    assert (len(set(gen.head_node_types)) == 1)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        assert (len(nf) == (3 * 2))\n        for ii in range(2):\n            assert (nf[ii].shape == (min(self.batch_size, mapper.data_size), 1, self.n_feat))\n            assert (nf[(ii + 2)].shape == (min(self.batch_size, mapper.data_size), 2, self.n_feat))\n            assert (nf[(ii + (2 * 2))].shape == (min(self.batch_size, mapper.data_size), (2 * 2), self.n_feat))\n            assert (len(nl) == min(self.batch_size, mapper.data_size))\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper[8]", "masked_code": "def test_GraphSAGELinkGenerator_unsupervisedSampler_sample_generation(self):\n    G = example_graph(feature_size=self.n_feat)\n    unsupervisedSamples = UnsupervisedSampler(G)\n    gen = GraphSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=self.num_samples)\n    mapper = gen.flow(unsupervisedSamples)\n    assert (mapper.data_size == (len(list(G.nodes())) * 2))\n    assert (mapper.batch_size == self.batch_size)\n    assert (len(mapper) == np.ceil((mapper.data_size / mapper.batch_size)))\n    assert (len(set(gen.head_node_types)) == 1)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        assert (len(nf) == (3 * 2))\n        for ii in range(2):\n            assert (nf[ii].shape == (min(self.batch_size, mapper.data_size), 1, self.n_feat))\n            assert (nf[(ii + 2)].shape == (min(self.batch_size, mapper.data_size), 2, self.n_feat))\n            assert (nf[(ii + (2 * 2))].shape == (min(self.batch_size, mapper.data_size), (2 * 2), self.n_feat))\n            assert (len(nl) == '???')\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper[8]", "ground_truth": "min(self.batch_size, mapper.data_size)", "quality_analysis": {"complexity_score": 11, "left_complexity": 4, "right_complexity": 7, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_865", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_HinSAGELinkGenerator", "funcname": "test_HinSAGELinkGenerator_constructor", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_HinSAGELinkGenerator_constructor(self):\n    G = example_HIN_homo(self.n_feat)\n    links = [(1, 4), (1, 5), (0, 4), (5, 0)]\n    link_labels = ([0] * len(links))\n    gen = HinSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=self.num_samples, head_node_types=['B', 'B'])\n    mapper = gen.flow(links, link_labels)\n    assert (mapper.data_size == len(links))\n    assert (len(mapper.ids) == len(links))\n    assert (tuple(gen.head_node_types) == ('B', 'B'))\n    G = example_hin_1(self.n_feat)\n    links = [(1, 4), (1, 5), (0, 4), (0, 5)]\n    link_labels = ([0] * len(links))\n    gen = HinSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=self.num_samples, head_node_types=['A', 'B'])\n    mapper = gen.flow(links, link_labels)\n    assert (mapper.data_size == len(links))\n    assert (len(mapper.ids) == len(links))\n    assert (mapper.data_size == len(link_labels))\n    assert (tuple(gen.head_node_types) == ('A', 'B'))", "masked_code": "def test_HinSAGELinkGenerator_constructor(self):\n    G = example_HIN_homo(self.n_feat)\n    links = [(1, 4), (1, 5), (0, 4), (5, 0)]\n    link_labels = ([0] * len(links))\n    gen = HinSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=self.num_samples, head_node_types=['B', 'B'])\n    mapper = gen.flow(links, link_labels)\n    assert (mapper.data_size == '???')\n    assert (len(mapper.ids) == len(links))\n    assert (tuple(gen.head_node_types) == ('B', 'B'))\n    G = example_hin_1(self.n_feat)\n    links = [(1, 4), (1, 5), (0, 4), (0, 5)]\n    link_labels = ([0] * len(links))\n    gen = HinSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=self.num_samples, head_node_types=['A', 'B'])\n    mapper = gen.flow(links, link_labels)\n    assert (mapper.data_size == len(links))\n    assert (len(mapper.ids) == len(links))\n    assert (mapper.data_size == len(link_labels))\n    assert (tuple(gen.head_node_types) == ('A', 'B'))", "ground_truth": "len(links)", "quality_analysis": {"complexity_score": 6, "left_complexity": 2, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_866", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_HinSAGELinkGenerator", "funcname": "test_HinSAGELinkGenerator_constructor", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_HinSAGELinkGenerator_constructor(self):\n    G = example_HIN_homo(self.n_feat)\n    links = [(1, 4), (1, 5), (0, 4), (5, 0)]\n    link_labels = ([0] * len(links))\n    gen = HinSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=self.num_samples, head_node_types=['B', 'B'])\n    mapper = gen.flow(links, link_labels)\n    assert (mapper.data_size == len(links))\n    assert (len(mapper.ids) == len(links))\n    assert (tuple(gen.head_node_types) == ('B', 'B'))\n    G = example_hin_1(self.n_feat)\n    links = [(1, 4), (1, 5), (0, 4), (0, 5)]\n    link_labels = ([0] * len(links))\n    gen = HinSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=self.num_samples, head_node_types=['A', 'B'])\n    mapper = gen.flow(links, link_labels)\n    assert (mapper.data_size == len(links))\n    assert (len(mapper.ids) == len(links))\n    assert (mapper.data_size == len(link_labels))\n    assert (tuple(gen.head_node_types) == ('A', 'B'))", "masked_code": "def test_HinSAGELinkGenerator_constructor(self):\n    G = example_HIN_homo(self.n_feat)\n    links = [(1, 4), (1, 5), (0, 4), (5, 0)]\n    link_labels = ([0] * len(links))\n    gen = HinSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=self.num_samples, head_node_types=['B', 'B'])\n    mapper = gen.flow(links, link_labels)\n    assert (mapper.data_size == len(links))\n    assert (len(mapper.ids) == '???')\n    assert (tuple(gen.head_node_types) == ('B', 'B'))\n    G = example_hin_1(self.n_feat)\n    links = [(1, 4), (1, 5), (0, 4), (0, 5)]\n    link_labels = ([0] * len(links))\n    gen = HinSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=self.num_samples, head_node_types=['A', 'B'])\n    mapper = gen.flow(links, link_labels)\n    assert (mapper.data_size == len(links))\n    assert (len(mapper.ids) == len(links))\n    assert (mapper.data_size == len(link_labels))\n    assert (tuple(gen.head_node_types) == ('A', 'B'))", "ground_truth": "len(links)", "quality_analysis": {"complexity_score": 9, "left_complexity": 5, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_867", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_HinSAGELinkGenerator", "funcname": "test_HinSAGELinkGenerator_constructor", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_HinSAGELinkGenerator_constructor(self):\n    G = example_HIN_homo(self.n_feat)\n    links = [(1, 4), (1, 5), (0, 4), (5, 0)]\n    link_labels = ([0] * len(links))\n    gen = HinSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=self.num_samples, head_node_types=['B', 'B'])\n    mapper = gen.flow(links, link_labels)\n    assert (mapper.data_size == len(links))\n    assert (len(mapper.ids) == len(links))\n    assert (tuple(gen.head_node_types) == ('B', 'B'))\n    G = example_hin_1(self.n_feat)\n    links = [(1, 4), (1, 5), (0, 4), (0, 5)]\n    link_labels = ([0] * len(links))\n    gen = HinSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=self.num_samples, head_node_types=['A', 'B'])\n    mapper = gen.flow(links, link_labels)\n    assert (mapper.data_size == len(links))\n    assert (len(mapper.ids) == len(links))\n    assert (mapper.data_size == len(link_labels))\n    assert (tuple(gen.head_node_types) == ('A', 'B'))", "masked_code": "def test_HinSAGELinkGenerator_constructor(self):\n    G = example_HIN_homo(self.n_feat)\n    links = [(1, 4), (1, 5), (0, 4), (5, 0)]\n    link_labels = ([0] * len(links))\n    gen = HinSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=self.num_samples, head_node_types=['B', 'B'])\n    mapper = gen.flow(links, link_labels)\n    assert (mapper.data_size == len(links))\n    assert (len(mapper.ids) == len(links))\n    assert (tuple(gen.head_node_types) == '???')\n    G = example_hin_1(self.n_feat)\n    links = [(1, 4), (1, 5), (0, 4), (0, 5)]\n    link_labels = ([0] * len(links))\n    gen = HinSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=self.num_samples, head_node_types=['A', 'B'])\n    mapper = gen.flow(links, link_labels)\n    assert (mapper.data_size == len(links))\n    assert (len(mapper.ids) == len(links))\n    assert (mapper.data_size == len(link_labels))\n    assert (tuple(gen.head_node_types) == ('A', 'B'))", "ground_truth": "('B', 'B')", "quality_analysis": {"complexity_score": 9, "left_complexity": 5, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_868", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_HinSAGELinkGenerator", "funcname": "test_HinSAGELinkGenerator_constructor", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_HinSAGELinkGenerator_constructor(self):\n    G = example_HIN_homo(self.n_feat)\n    links = [(1, 4), (1, 5), (0, 4), (5, 0)]\n    link_labels = ([0] * len(links))\n    gen = HinSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=self.num_samples, head_node_types=['B', 'B'])\n    mapper = gen.flow(links, link_labels)\n    assert (mapper.data_size == len(links))\n    assert (len(mapper.ids) == len(links))\n    assert (tuple(gen.head_node_types) == ('B', 'B'))\n    G = example_hin_1(self.n_feat)\n    links = [(1, 4), (1, 5), (0, 4), (0, 5)]\n    link_labels = ([0] * len(links))\n    gen = HinSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=self.num_samples, head_node_types=['A', 'B'])\n    mapper = gen.flow(links, link_labels)\n    assert (mapper.data_size == len(links))\n    assert (len(mapper.ids) == len(links))\n    assert (mapper.data_size == len(link_labels))\n    assert (tuple(gen.head_node_types) == ('A', 'B'))", "masked_code": "def test_HinSAGELinkGenerator_constructor(self):\n    G = example_HIN_homo(self.n_feat)\n    links = [(1, 4), (1, 5), (0, 4), (5, 0)]\n    link_labels = ([0] * len(links))\n    gen = HinSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=self.num_samples, head_node_types=['B', 'B'])\n    mapper = gen.flow(links, link_labels)\n    assert (mapper.data_size == len(links))\n    assert (len(mapper.ids) == len(links))\n    assert (tuple(gen.head_node_types) == ('B', 'B'))\n    G = example_hin_1(self.n_feat)\n    links = [(1, 4), (1, 5), (0, 4), (0, 5)]\n    link_labels = ([0] * len(links))\n    gen = HinSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=self.num_samples, head_node_types=['A', 'B'])\n    mapper = gen.flow(links, link_labels)\n    assert (mapper.data_size == '???')\n    assert (len(mapper.ids) == len(links))\n    assert (mapper.data_size == len(link_labels))\n    assert (tuple(gen.head_node_types) == ('A', 'B'))", "ground_truth": "len(links)", "quality_analysis": {"complexity_score": 6, "left_complexity": 2, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_869", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_HinSAGELinkGenerator", "funcname": "test_HinSAGELinkGenerator_constructor", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_HinSAGELinkGenerator_constructor(self):\n    G = example_HIN_homo(self.n_feat)\n    links = [(1, 4), (1, 5), (0, 4), (5, 0)]\n    link_labels = ([0] * len(links))\n    gen = HinSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=self.num_samples, head_node_types=['B', 'B'])\n    mapper = gen.flow(links, link_labels)\n    assert (mapper.data_size == len(links))\n    assert (len(mapper.ids) == len(links))\n    assert (tuple(gen.head_node_types) == ('B', 'B'))\n    G = example_hin_1(self.n_feat)\n    links = [(1, 4), (1, 5), (0, 4), (0, 5)]\n    link_labels = ([0] * len(links))\n    gen = HinSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=self.num_samples, head_node_types=['A', 'B'])\n    mapper = gen.flow(links, link_labels)\n    assert (mapper.data_size == len(links))\n    assert (len(mapper.ids) == len(links))\n    assert (mapper.data_size == len(link_labels))\n    assert (tuple(gen.head_node_types) == ('A', 'B'))", "masked_code": "def test_HinSAGELinkGenerator_constructor(self):\n    G = example_HIN_homo(self.n_feat)\n    links = [(1, 4), (1, 5), (0, 4), (5, 0)]\n    link_labels = ([0] * len(links))\n    gen = HinSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=self.num_samples, head_node_types=['B', 'B'])\n    mapper = gen.flow(links, link_labels)\n    assert (mapper.data_size == len(links))\n    assert (len(mapper.ids) == len(links))\n    assert (tuple(gen.head_node_types) == ('B', 'B'))\n    G = example_hin_1(self.n_feat)\n    links = [(1, 4), (1, 5), (0, 4), (0, 5)]\n    link_labels = ([0] * len(links))\n    gen = HinSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=self.num_samples, head_node_types=['A', 'B'])\n    mapper = gen.flow(links, link_labels)\n    assert (mapper.data_size == len(links))\n    assert (len(mapper.ids) == '???')\n    assert (mapper.data_size == len(link_labels))\n    assert (tuple(gen.head_node_types) == ('A', 'B'))", "ground_truth": "len(links)", "quality_analysis": {"complexity_score": 9, "left_complexity": 5, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_870", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_HinSAGELinkGenerator", "funcname": "test_HinSAGELinkGenerator_constructor", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_HinSAGELinkGenerator_constructor(self):\n    G = example_HIN_homo(self.n_feat)\n    links = [(1, 4), (1, 5), (0, 4), (5, 0)]\n    link_labels = ([0] * len(links))\n    gen = HinSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=self.num_samples, head_node_types=['B', 'B'])\n    mapper = gen.flow(links, link_labels)\n    assert (mapper.data_size == len(links))\n    assert (len(mapper.ids) == len(links))\n    assert (tuple(gen.head_node_types) == ('B', 'B'))\n    G = example_hin_1(self.n_feat)\n    links = [(1, 4), (1, 5), (0, 4), (0, 5)]\n    link_labels = ([0] * len(links))\n    gen = HinSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=self.num_samples, head_node_types=['A', 'B'])\n    mapper = gen.flow(links, link_labels)\n    assert (mapper.data_size == len(links))\n    assert (len(mapper.ids) == len(links))\n    assert (mapper.data_size == len(link_labels))\n    assert (tuple(gen.head_node_types) == ('A', 'B'))", "masked_code": "def test_HinSAGELinkGenerator_constructor(self):\n    G = example_HIN_homo(self.n_feat)\n    links = [(1, 4), (1, 5), (0, 4), (5, 0)]\n    link_labels = ([0] * len(links))\n    gen = HinSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=self.num_samples, head_node_types=['B', 'B'])\n    mapper = gen.flow(links, link_labels)\n    assert (mapper.data_size == len(links))\n    assert (len(mapper.ids) == len(links))\n    assert (tuple(gen.head_node_types) == ('B', 'B'))\n    G = example_hin_1(self.n_feat)\n    links = [(1, 4), (1, 5), (0, 4), (0, 5)]\n    link_labels = ([0] * len(links))\n    gen = HinSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=self.num_samples, head_node_types=['A', 'B'])\n    mapper = gen.flow(links, link_labels)\n    assert (mapper.data_size == len(links))\n    assert (len(mapper.ids) == len(links))\n    assert (mapper.data_size == '???')\n    assert (tuple(gen.head_node_types) == ('A', 'B'))", "ground_truth": "len(link_labels)", "quality_analysis": {"complexity_score": 6, "left_complexity": 2, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_871", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_HinSAGELinkGenerator", "funcname": "test_HinSAGELinkGenerator_constructor", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_HinSAGELinkGenerator_constructor(self):\n    G = example_HIN_homo(self.n_feat)\n    links = [(1, 4), (1, 5), (0, 4), (5, 0)]\n    link_labels = ([0] * len(links))\n    gen = HinSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=self.num_samples, head_node_types=['B', 'B'])\n    mapper = gen.flow(links, link_labels)\n    assert (mapper.data_size == len(links))\n    assert (len(mapper.ids) == len(links))\n    assert (tuple(gen.head_node_types) == ('B', 'B'))\n    G = example_hin_1(self.n_feat)\n    links = [(1, 4), (1, 5), (0, 4), (0, 5)]\n    link_labels = ([0] * len(links))\n    gen = HinSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=self.num_samples, head_node_types=['A', 'B'])\n    mapper = gen.flow(links, link_labels)\n    assert (mapper.data_size == len(links))\n    assert (len(mapper.ids) == len(links))\n    assert (mapper.data_size == len(link_labels))\n    assert (tuple(gen.head_node_types) == ('A', 'B'))", "masked_code": "def test_HinSAGELinkGenerator_constructor(self):\n    G = example_HIN_homo(self.n_feat)\n    links = [(1, 4), (1, 5), (0, 4), (5, 0)]\n    link_labels = ([0] * len(links))\n    gen = HinSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=self.num_samples, head_node_types=['B', 'B'])\n    mapper = gen.flow(links, link_labels)\n    assert (mapper.data_size == len(links))\n    assert (len(mapper.ids) == len(links))\n    assert (tuple(gen.head_node_types) == ('B', 'B'))\n    G = example_hin_1(self.n_feat)\n    links = [(1, 4), (1, 5), (0, 4), (0, 5)]\n    link_labels = ([0] * len(links))\n    gen = HinSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=self.num_samples, head_node_types=['A', 'B'])\n    mapper = gen.flow(links, link_labels)\n    assert (mapper.data_size == len(links))\n    assert (len(mapper.ids) == len(links))\n    assert (mapper.data_size == len(link_labels))\n    assert (tuple(gen.head_node_types) == '???')", "ground_truth": "('A', 'B')", "quality_analysis": {"complexity_score": 9, "left_complexity": 5, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_872", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_HinSAGELinkGenerator", "funcname": "test_HinSAGELinkGenerator_homogeneous_inference", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_HinSAGELinkGenerator_homogeneous_inference(self):\n    feature_size = 4\n    edge_types = 3\n    batch_size = 2\n    num_samples = [5, 7]\n    G = example_graph_random(feature_size=feature_size, node_types=1, edge_types=edge_types)\n    mapper = HinSAGELinkGenerator(G, batch_size=batch_size, num_samples=num_samples)\n    assert (mapper.head_node_types == ['n-0', 'n-0'])\n    links = [(1, 4), (2, 3), (4, 1)]\n    seq = mapper.flow(links)\n    assert (len(seq) == 2)\n    samples_per_head = ((1 + edge_types) + (edge_types * edge_types))\n    for (batch_idx, (samples, labels)) in enumerate(seq):\n        this_batch_size = {0: batch_size, 1: 1}[batch_idx]\n        assert (len(samples) == (2 * samples_per_head))\n        for i in range(0, 2):\n            assert (samples[i].shape == (this_batch_size, 1, feature_size))\n        for i in range(2, (2 * (1 + edge_types))):\n            assert (samples[i].shape == (this_batch_size, num_samples[0], feature_size))\n        for i in range((2 * (1 + edge_types)), (2 * samples_per_head)):\n            assert (samples[i].shape == (this_batch_size, np.product(num_samples), feature_size))\n        assert (labels is None)", "masked_code": "def test_HinSAGELinkGenerator_homogeneous_inference(self):\n    feature_size = 4\n    edge_types = 3\n    batch_size = 2\n    num_samples = [5, 7]\n    G = example_graph_random(feature_size=feature_size, node_types=1, edge_types=edge_types)\n    mapper = HinSAGELinkGenerator(G, batch_size=batch_size, num_samples=num_samples)\n    assert (mapper.head_node_types == '???')\n    links = [(1, 4), (2, 3), (4, 1)]\n    seq = mapper.flow(links)\n    assert (len(seq) == 2)\n    samples_per_head = ((1 + edge_types) + (edge_types * edge_types))\n    for (batch_idx, (samples, labels)) in enumerate(seq):\n        this_batch_size = {0: batch_size, 1: 1}[batch_idx]\n        assert (len(samples) == (2 * samples_per_head))\n        for i in range(0, 2):\n            assert (samples[i].shape == (this_batch_size, 1, feature_size))\n        for i in range(2, (2 * (1 + edge_types))):\n            assert (samples[i].shape == (this_batch_size, num_samples[0], feature_size))\n        for i in range((2 * (1 + edge_types)), (2 * samples_per_head)):\n            assert (samples[i].shape == (this_batch_size, np.product(num_samples), feature_size))\n        assert (labels is None)", "ground_truth": "['n-0', 'n-0']", "quality_analysis": {"complexity_score": 6, "left_complexity": 2, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_873", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_HinSAGELinkGenerator", "funcname": "test_HinSAGELinkGenerator_homogeneous_inference", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_HinSAGELinkGenerator_homogeneous_inference(self):\n    feature_size = 4\n    edge_types = 3\n    batch_size = 2\n    num_samples = [5, 7]\n    G = example_graph_random(feature_size=feature_size, node_types=1, edge_types=edge_types)\n    mapper = HinSAGELinkGenerator(G, batch_size=batch_size, num_samples=num_samples)\n    assert (mapper.head_node_types == ['n-0', 'n-0'])\n    links = [(1, 4), (2, 3), (4, 1)]\n    seq = mapper.flow(links)\n    assert (len(seq) == 2)\n    samples_per_head = ((1 + edge_types) + (edge_types * edge_types))\n    for (batch_idx, (samples, labels)) in enumerate(seq):\n        this_batch_size = {0: batch_size, 1: 1}[batch_idx]\n        assert (len(samples) == (2 * samples_per_head))\n        for i in range(0, 2):\n            assert (samples[i].shape == (this_batch_size, 1, feature_size))\n        for i in range(2, (2 * (1 + edge_types))):\n            assert (samples[i].shape == (this_batch_size, num_samples[0], feature_size))\n        for i in range((2 * (1 + edge_types)), (2 * samples_per_head)):\n            assert (samples[i].shape == (this_batch_size, np.product(num_samples), feature_size))\n        assert (labels is None)", "masked_code": "def test_HinSAGELinkGenerator_homogeneous_inference(self):\n    feature_size = 4\n    edge_types = 3\n    batch_size = 2\n    num_samples = [5, 7]\n    G = example_graph_random(feature_size=feature_size, node_types=1, edge_types=edge_types)\n    mapper = HinSAGELinkGenerator(G, batch_size=batch_size, num_samples=num_samples)\n    assert (mapper.head_node_types == ['n-0', 'n-0'])\n    links = [(1, 4), (2, 3), (4, 1)]\n    seq = mapper.flow(links)\n    assert (len(seq) == 2)\n    samples_per_head = ((1 + edge_types) + (edge_types * edge_types))\n    for (batch_idx, (samples, labels)) in enumerate(seq):\n        this_batch_size = {0: batch_size, 1: 1}[batch_idx]\n        assert (len(samples) == '???')\n        for i in range(0, 2):\n            assert (samples[i].shape == (this_batch_size, 1, feature_size))\n        for i in range(2, (2 * (1 + edge_types))):\n            assert (samples[i].shape == (this_batch_size, num_samples[0], feature_size))\n        for i in range((2 * (1 + edge_types)), (2 * samples_per_head)):\n            assert (samples[i].shape == (this_batch_size, np.product(num_samples), feature_size))\n        assert (labels is None)", "ground_truth": "(2 * samples_per_head)", "quality_analysis": {"complexity_score": 8, "left_complexity": 4, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_874", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_HinSAGELinkGenerator", "funcname": "test_HinSAGELinkGenerator_homogeneous_inference", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_HinSAGELinkGenerator_homogeneous_inference(self):\n    feature_size = 4\n    edge_types = 3\n    batch_size = 2\n    num_samples = [5, 7]\n    G = example_graph_random(feature_size=feature_size, node_types=1, edge_types=edge_types)\n    mapper = HinSAGELinkGenerator(G, batch_size=batch_size, num_samples=num_samples)\n    assert (mapper.head_node_types == ['n-0', 'n-0'])\n    links = [(1, 4), (2, 3), (4, 1)]\n    seq = mapper.flow(links)\n    assert (len(seq) == 2)\n    samples_per_head = ((1 + edge_types) + (edge_types * edge_types))\n    for (batch_idx, (samples, labels)) in enumerate(seq):\n        this_batch_size = {0: batch_size, 1: 1}[batch_idx]\n        assert (len(samples) == (2 * samples_per_head))\n        for i in range(0, 2):\n            assert (samples[i].shape == (this_batch_size, 1, feature_size))\n        for i in range(2, (2 * (1 + edge_types))):\n            assert (samples[i].shape == (this_batch_size, num_samples[0], feature_size))\n        for i in range((2 * (1 + edge_types)), (2 * samples_per_head)):\n            assert (samples[i].shape == (this_batch_size, np.product(num_samples), feature_size))\n        assert (labels is None)", "masked_code": "def test_HinSAGELinkGenerator_homogeneous_inference(self):\n    feature_size = 4\n    edge_types = 3\n    batch_size = 2\n    num_samples = [5, 7]\n    G = example_graph_random(feature_size=feature_size, node_types=1, edge_types=edge_types)\n    mapper = HinSAGELinkGenerator(G, batch_size=batch_size, num_samples=num_samples)\n    assert (mapper.head_node_types == ['n-0', 'n-0'])\n    links = [(1, 4), (2, 3), (4, 1)]\n    seq = mapper.flow(links)\n    assert (len(seq) == 2)\n    samples_per_head = ((1 + edge_types) + (edge_types * edge_types))\n    for (batch_idx, (samples, labels)) in enumerate(seq):\n        this_batch_size = {0: batch_size, 1: 1}[batch_idx]\n        assert (len(samples) == (2 * samples_per_head))\n        for i in range(0, 2):\n            assert (samples[i].shape == '???')\n        for i in range(2, (2 * (1 + edge_types))):\n            assert (samples[i].shape == (this_batch_size, num_samples[0], feature_size))\n        for i in range((2 * (1 + edge_types)), (2 * samples_per_head)):\n            assert (samples[i].shape == (this_batch_size, np.product(num_samples), feature_size))\n        assert (labels is None)", "ground_truth": "(this_batch_size, 1, feature_size)", "quality_analysis": {"complexity_score": 7, "left_complexity": 2, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_875", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_HinSAGELinkGenerator", "funcname": "test_HinSAGELinkGenerator_homogeneous_inference", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_HinSAGELinkGenerator_homogeneous_inference(self):\n    feature_size = 4\n    edge_types = 3\n    batch_size = 2\n    num_samples = [5, 7]\n    G = example_graph_random(feature_size=feature_size, node_types=1, edge_types=edge_types)\n    mapper = HinSAGELinkGenerator(G, batch_size=batch_size, num_samples=num_samples)\n    assert (mapper.head_node_types == ['n-0', 'n-0'])\n    links = [(1, 4), (2, 3), (4, 1)]\n    seq = mapper.flow(links)\n    assert (len(seq) == 2)\n    samples_per_head = ((1 + edge_types) + (edge_types * edge_types))\n    for (batch_idx, (samples, labels)) in enumerate(seq):\n        this_batch_size = {0: batch_size, 1: 1}[batch_idx]\n        assert (len(samples) == (2 * samples_per_head))\n        for i in range(0, 2):\n            assert (samples[i].shape == (this_batch_size, 1, feature_size))\n        for i in range(2, (2 * (1 + edge_types))):\n            assert (samples[i].shape == (this_batch_size, num_samples[0], feature_size))\n        for i in range((2 * (1 + edge_types)), (2 * samples_per_head)):\n            assert (samples[i].shape == (this_batch_size, np.product(num_samples), feature_size))\n        assert (labels is None)", "masked_code": "def test_HinSAGELinkGenerator_homogeneous_inference(self):\n    feature_size = 4\n    edge_types = 3\n    batch_size = 2\n    num_samples = [5, 7]\n    G = example_graph_random(feature_size=feature_size, node_types=1, edge_types=edge_types)\n    mapper = HinSAGELinkGenerator(G, batch_size=batch_size, num_samples=num_samples)\n    assert (mapper.head_node_types == ['n-0', 'n-0'])\n    links = [(1, 4), (2, 3), (4, 1)]\n    seq = mapper.flow(links)\n    assert (len(seq) == 2)\n    samples_per_head = ((1 + edge_types) + (edge_types * edge_types))\n    for (batch_idx, (samples, labels)) in enumerate(seq):\n        this_batch_size = {0: batch_size, 1: 1}[batch_idx]\n        assert (len(samples) == (2 * samples_per_head))\n        for i in range(0, 2):\n            assert (samples[i].shape == (this_batch_size, 1, feature_size))\n        for i in range(2, (2 * (1 + edge_types))):\n            assert (samples[i].shape == '???')\n        for i in range((2 * (1 + edge_types)), (2 * samples_per_head)):\n            assert (samples[i].shape == (this_batch_size, np.product(num_samples), feature_size))\n        assert (labels is None)", "ground_truth": "(this_batch_size, num_samples[0], feature_size)", "quality_analysis": {"complexity_score": 11, "left_complexity": 2, "right_complexity": 9, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_876", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_HinSAGELinkGenerator", "funcname": "test_HinSAGELinkGenerator_homogeneous_inference", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_HinSAGELinkGenerator_homogeneous_inference(self):\n    feature_size = 4\n    edge_types = 3\n    batch_size = 2\n    num_samples = [5, 7]\n    G = example_graph_random(feature_size=feature_size, node_types=1, edge_types=edge_types)\n    mapper = HinSAGELinkGenerator(G, batch_size=batch_size, num_samples=num_samples)\n    assert (mapper.head_node_types == ['n-0', 'n-0'])\n    links = [(1, 4), (2, 3), (4, 1)]\n    seq = mapper.flow(links)\n    assert (len(seq) == 2)\n    samples_per_head = ((1 + edge_types) + (edge_types * edge_types))\n    for (batch_idx, (samples, labels)) in enumerate(seq):\n        this_batch_size = {0: batch_size, 1: 1}[batch_idx]\n        assert (len(samples) == (2 * samples_per_head))\n        for i in range(0, 2):\n            assert (samples[i].shape == (this_batch_size, 1, feature_size))\n        for i in range(2, (2 * (1 + edge_types))):\n            assert (samples[i].shape == (this_batch_size, num_samples[0], feature_size))\n        for i in range((2 * (1 + edge_types)), (2 * samples_per_head)):\n            assert (samples[i].shape == (this_batch_size, np.product(num_samples), feature_size))\n        assert (labels is None)", "masked_code": "def test_HinSAGELinkGenerator_homogeneous_inference(self):\n    feature_size = 4\n    edge_types = 3\n    batch_size = 2\n    num_samples = [5, 7]\n    G = example_graph_random(feature_size=feature_size, node_types=1, edge_types=edge_types)\n    mapper = HinSAGELinkGenerator(G, batch_size=batch_size, num_samples=num_samples)\n    assert (mapper.head_node_types == ['n-0', 'n-0'])\n    links = [(1, 4), (2, 3), (4, 1)]\n    seq = mapper.flow(links)\n    assert (len(seq) == 2)\n    samples_per_head = ((1 + edge_types) + (edge_types * edge_types))\n    for (batch_idx, (samples, labels)) in enumerate(seq):\n        this_batch_size = {0: batch_size, 1: 1}[batch_idx]\n        assert (len(samples) == (2 * samples_per_head))\n        for i in range(0, 2):\n            assert (samples[i].shape == (this_batch_size, 1, feature_size))\n        for i in range(2, (2 * (1 + edge_types))):\n            assert (samples[i].shape == (this_batch_size, num_samples[0], feature_size))\n        for i in range((2 * (1 + edge_types)), (2 * samples_per_head)):\n            assert (samples[i].shape == '???')\n        assert (labels is None)", "ground_truth": "(this_batch_size, np.product(num_samples), feature_size)", "quality_analysis": {"complexity_score": 10, "left_complexity": 2, "right_complexity": 8, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_877", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_HinSAGELinkGenerator", "funcname": "test_HinSAGELinkGenerator_1", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_HinSAGELinkGenerator_1(self):\n    G = example_hin_1(self.n_feat)\n    links = [(1, 4), (1, 5), (0, 4), (0, 5)]\n    data_size = len(links)\n    link_labels = ([0] * data_size)\n    mapper = HinSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=self.num_samples, head_node_types=['A', 'B']).flow(links, link_labels)\n    assert (len(mapper) == 2)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        assert (len(nf) == 10)\n        assert (nf[0].shape == (self.batch_size, 1, self.n_feat['A']))\n        assert (nf[1].shape == (self.batch_size, 1, self.n_feat['B']))\n        assert (nf[2].shape == (self.batch_size, self.num_samples[0], self.n_feat['B']))\n        assert (nf[3].shape == (self.batch_size, self.num_samples[0], self.n_feat['B']))\n        assert (nf[4].shape == (self.batch_size, self.num_samples[0], self.n_feat['A']))\n        assert (nf[5].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['B']))\n        assert (nf[6].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['A']))\n        assert (nf[7].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['B']))\n        assert (nf[8].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['A']))\n        assert (nf[9].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['B']))\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper[2]", "masked_code": "def test_HinSAGELinkGenerator_1(self):\n    G = example_hin_1(self.n_feat)\n    links = [(1, 4), (1, 5), (0, 4), (0, 5)]\n    data_size = len(links)\n    link_labels = ([0] * data_size)\n    mapper = HinSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=self.num_samples, head_node_types=['A', 'B']).flow(links, link_labels)\n    assert (len(mapper) == 2)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        assert (len(nf) == '???')\n        assert (nf[0].shape == (self.batch_size, 1, self.n_feat['A']))\n        assert (nf[1].shape == (self.batch_size, 1, self.n_feat['B']))\n        assert (nf[2].shape == (self.batch_size, self.num_samples[0], self.n_feat['B']))\n        assert (nf[3].shape == (self.batch_size, self.num_samples[0], self.n_feat['B']))\n        assert (nf[4].shape == (self.batch_size, self.num_samples[0], self.n_feat['A']))\n        assert (nf[5].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['B']))\n        assert (nf[6].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['A']))\n        assert (nf[7].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['B']))\n        assert (nf[8].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['A']))\n        assert (nf[9].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['B']))\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper[2]", "ground_truth": "10", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_878", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_HinSAGELinkGenerator", "funcname": "test_HinSAGELinkGenerator_1", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_HinSAGELinkGenerator_1(self):\n    G = example_hin_1(self.n_feat)\n    links = [(1, 4), (1, 5), (0, 4), (0, 5)]\n    data_size = len(links)\n    link_labels = ([0] * data_size)\n    mapper = HinSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=self.num_samples, head_node_types=['A', 'B']).flow(links, link_labels)\n    assert (len(mapper) == 2)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        assert (len(nf) == 10)\n        assert (nf[0].shape == (self.batch_size, 1, self.n_feat['A']))\n        assert (nf[1].shape == (self.batch_size, 1, self.n_feat['B']))\n        assert (nf[2].shape == (self.batch_size, self.num_samples[0], self.n_feat['B']))\n        assert (nf[3].shape == (self.batch_size, self.num_samples[0], self.n_feat['B']))\n        assert (nf[4].shape == (self.batch_size, self.num_samples[0], self.n_feat['A']))\n        assert (nf[5].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['B']))\n        assert (nf[6].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['A']))\n        assert (nf[7].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['B']))\n        assert (nf[8].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['A']))\n        assert (nf[9].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['B']))\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper[2]", "masked_code": "def test_HinSAGELinkGenerator_1(self):\n    G = example_hin_1(self.n_feat)\n    links = [(1, 4), (1, 5), (0, 4), (0, 5)]\n    data_size = len(links)\n    link_labels = ([0] * data_size)\n    mapper = HinSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=self.num_samples, head_node_types=['A', 'B']).flow(links, link_labels)\n    assert (len(mapper) == 2)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        assert (len(nf) == 10)\n        assert (nf[0].shape == '???')\n        assert (nf[1].shape == (self.batch_size, 1, self.n_feat['B']))\n        assert (nf[2].shape == (self.batch_size, self.num_samples[0], self.n_feat['B']))\n        assert (nf[3].shape == (self.batch_size, self.num_samples[0], self.n_feat['B']))\n        assert (nf[4].shape == (self.batch_size, self.num_samples[0], self.n_feat['A']))\n        assert (nf[5].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['B']))\n        assert (nf[6].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['A']))\n        assert (nf[7].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['B']))\n        assert (nf[8].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['A']))\n        assert (nf[9].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['B']))\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper[2]", "ground_truth": "(self.batch_size, 1, self.n_feat['A'])", "quality_analysis": {"complexity_score": 13, "left_complexity": 2, "right_complexity": 11, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_879", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_HinSAGELinkGenerator", "funcname": "test_HinSAGELinkGenerator_1", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_HinSAGELinkGenerator_1(self):\n    G = example_hin_1(self.n_feat)\n    links = [(1, 4), (1, 5), (0, 4), (0, 5)]\n    data_size = len(links)\n    link_labels = ([0] * data_size)\n    mapper = HinSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=self.num_samples, head_node_types=['A', 'B']).flow(links, link_labels)\n    assert (len(mapper) == 2)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        assert (len(nf) == 10)\n        assert (nf[0].shape == (self.batch_size, 1, self.n_feat['A']))\n        assert (nf[1].shape == (self.batch_size, 1, self.n_feat['B']))\n        assert (nf[2].shape == (self.batch_size, self.num_samples[0], self.n_feat['B']))\n        assert (nf[3].shape == (self.batch_size, self.num_samples[0], self.n_feat['B']))\n        assert (nf[4].shape == (self.batch_size, self.num_samples[0], self.n_feat['A']))\n        assert (nf[5].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['B']))\n        assert (nf[6].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['A']))\n        assert (nf[7].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['B']))\n        assert (nf[8].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['A']))\n        assert (nf[9].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['B']))\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper[2]", "masked_code": "def test_HinSAGELinkGenerator_1(self):\n    G = example_hin_1(self.n_feat)\n    links = [(1, 4), (1, 5), (0, 4), (0, 5)]\n    data_size = len(links)\n    link_labels = ([0] * data_size)\n    mapper = HinSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=self.num_samples, head_node_types=['A', 'B']).flow(links, link_labels)\n    assert (len(mapper) == 2)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        assert (len(nf) == 10)\n        assert (nf[0].shape == (self.batch_size, 1, self.n_feat['A']))\n        assert (nf[1].shape == '???')\n        assert (nf[2].shape == (self.batch_size, self.num_samples[0], self.n_feat['B']))\n        assert (nf[3].shape == (self.batch_size, self.num_samples[0], self.n_feat['B']))\n        assert (nf[4].shape == (self.batch_size, self.num_samples[0], self.n_feat['A']))\n        assert (nf[5].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['B']))\n        assert (nf[6].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['A']))\n        assert (nf[7].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['B']))\n        assert (nf[8].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['A']))\n        assert (nf[9].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['B']))\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper[2]", "ground_truth": "(self.batch_size, 1, self.n_feat['B'])", "quality_analysis": {"complexity_score": 13, "left_complexity": 2, "right_complexity": 11, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_880", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_HinSAGELinkGenerator", "funcname": "test_HinSAGELinkGenerator_1", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_HinSAGELinkGenerator_1(self):\n    G = example_hin_1(self.n_feat)\n    links = [(1, 4), (1, 5), (0, 4), (0, 5)]\n    data_size = len(links)\n    link_labels = ([0] * data_size)\n    mapper = HinSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=self.num_samples, head_node_types=['A', 'B']).flow(links, link_labels)\n    assert (len(mapper) == 2)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        assert (len(nf) == 10)\n        assert (nf[0].shape == (self.batch_size, 1, self.n_feat['A']))\n        assert (nf[1].shape == (self.batch_size, 1, self.n_feat['B']))\n        assert (nf[2].shape == (self.batch_size, self.num_samples[0], self.n_feat['B']))\n        assert (nf[3].shape == (self.batch_size, self.num_samples[0], self.n_feat['B']))\n        assert (nf[4].shape == (self.batch_size, self.num_samples[0], self.n_feat['A']))\n        assert (nf[5].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['B']))\n        assert (nf[6].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['A']))\n        assert (nf[7].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['B']))\n        assert (nf[8].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['A']))\n        assert (nf[9].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['B']))\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper[2]", "masked_code": "def test_HinSAGELinkGenerator_1(self):\n    G = example_hin_1(self.n_feat)\n    links = [(1, 4), (1, 5), (0, 4), (0, 5)]\n    data_size = len(links)\n    link_labels = ([0] * data_size)\n    mapper = HinSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=self.num_samples, head_node_types=['A', 'B']).flow(links, link_labels)\n    assert (len(mapper) == 2)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        assert (len(nf) == 10)\n        assert (nf[0].shape == (self.batch_size, 1, self.n_feat['A']))\n        assert (nf[1].shape == (self.batch_size, 1, self.n_feat['B']))\n        assert (nf[2].shape == '???')\n        assert (nf[3].shape == (self.batch_size, self.num_samples[0], self.n_feat['B']))\n        assert (nf[4].shape == (self.batch_size, self.num_samples[0], self.n_feat['A']))\n        assert (nf[5].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['B']))\n        assert (nf[6].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['A']))\n        assert (nf[7].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['B']))\n        assert (nf[8].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['A']))\n        assert (nf[9].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['B']))\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper[2]", "ground_truth": "(self.batch_size, self.num_samples[0], self.n_feat['B'])", "quality_analysis": {"complexity_score": 18, "left_complexity": 2, "right_complexity": 16, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_881", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_HinSAGELinkGenerator", "funcname": "test_HinSAGELinkGenerator_1", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_HinSAGELinkGenerator_1(self):\n    G = example_hin_1(self.n_feat)\n    links = [(1, 4), (1, 5), (0, 4), (0, 5)]\n    data_size = len(links)\n    link_labels = ([0] * data_size)\n    mapper = HinSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=self.num_samples, head_node_types=['A', 'B']).flow(links, link_labels)\n    assert (len(mapper) == 2)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        assert (len(nf) == 10)\n        assert (nf[0].shape == (self.batch_size, 1, self.n_feat['A']))\n        assert (nf[1].shape == (self.batch_size, 1, self.n_feat['B']))\n        assert (nf[2].shape == (self.batch_size, self.num_samples[0], self.n_feat['B']))\n        assert (nf[3].shape == (self.batch_size, self.num_samples[0], self.n_feat['B']))\n        assert (nf[4].shape == (self.batch_size, self.num_samples[0], self.n_feat['A']))\n        assert (nf[5].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['B']))\n        assert (nf[6].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['A']))\n        assert (nf[7].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['B']))\n        assert (nf[8].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['A']))\n        assert (nf[9].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['B']))\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper[2]", "masked_code": "def test_HinSAGELinkGenerator_1(self):\n    G = example_hin_1(self.n_feat)\n    links = [(1, 4), (1, 5), (0, 4), (0, 5)]\n    data_size = len(links)\n    link_labels = ([0] * data_size)\n    mapper = HinSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=self.num_samples, head_node_types=['A', 'B']).flow(links, link_labels)\n    assert (len(mapper) == 2)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        assert (len(nf) == 10)\n        assert (nf[0].shape == (self.batch_size, 1, self.n_feat['A']))\n        assert (nf[1].shape == (self.batch_size, 1, self.n_feat['B']))\n        assert (nf[2].shape == (self.batch_size, self.num_samples[0], self.n_feat['B']))\n        assert (nf[3].shape == '???')\n        assert (nf[4].shape == (self.batch_size, self.num_samples[0], self.n_feat['A']))\n        assert (nf[5].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['B']))\n        assert (nf[6].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['A']))\n        assert (nf[7].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['B']))\n        assert (nf[8].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['A']))\n        assert (nf[9].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['B']))\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper[2]", "ground_truth": "(self.batch_size, self.num_samples[0], self.n_feat['B'])", "quality_analysis": {"complexity_score": 18, "left_complexity": 2, "right_complexity": 16, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_882", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_HinSAGELinkGenerator", "funcname": "test_HinSAGELinkGenerator_1", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_HinSAGELinkGenerator_1(self):\n    G = example_hin_1(self.n_feat)\n    links = [(1, 4), (1, 5), (0, 4), (0, 5)]\n    data_size = len(links)\n    link_labels = ([0] * data_size)\n    mapper = HinSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=self.num_samples, head_node_types=['A', 'B']).flow(links, link_labels)\n    assert (len(mapper) == 2)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        assert (len(nf) == 10)\n        assert (nf[0].shape == (self.batch_size, 1, self.n_feat['A']))\n        assert (nf[1].shape == (self.batch_size, 1, self.n_feat['B']))\n        assert (nf[2].shape == (self.batch_size, self.num_samples[0], self.n_feat['B']))\n        assert (nf[3].shape == (self.batch_size, self.num_samples[0], self.n_feat['B']))\n        assert (nf[4].shape == (self.batch_size, self.num_samples[0], self.n_feat['A']))\n        assert (nf[5].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['B']))\n        assert (nf[6].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['A']))\n        assert (nf[7].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['B']))\n        assert (nf[8].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['A']))\n        assert (nf[9].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['B']))\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper[2]", "masked_code": "def test_HinSAGELinkGenerator_1(self):\n    G = example_hin_1(self.n_feat)\n    links = [(1, 4), (1, 5), (0, 4), (0, 5)]\n    data_size = len(links)\n    link_labels = ([0] * data_size)\n    mapper = HinSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=self.num_samples, head_node_types=['A', 'B']).flow(links, link_labels)\n    assert (len(mapper) == 2)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        assert (len(nf) == 10)\n        assert (nf[0].shape == (self.batch_size, 1, self.n_feat['A']))\n        assert (nf[1].shape == (self.batch_size, 1, self.n_feat['B']))\n        assert (nf[2].shape == (self.batch_size, self.num_samples[0], self.n_feat['B']))\n        assert (nf[3].shape == (self.batch_size, self.num_samples[0], self.n_feat['B']))\n        assert (nf[4].shape == '???')\n        assert (nf[5].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['B']))\n        assert (nf[6].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['A']))\n        assert (nf[7].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['B']))\n        assert (nf[8].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['A']))\n        assert (nf[9].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['B']))\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper[2]", "ground_truth": "(self.batch_size, self.num_samples[0], self.n_feat['A'])", "quality_analysis": {"complexity_score": 18, "left_complexity": 2, "right_complexity": 16, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_883", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_HinSAGELinkGenerator", "funcname": "test_HinSAGELinkGenerator_1", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_HinSAGELinkGenerator_1(self):\n    G = example_hin_1(self.n_feat)\n    links = [(1, 4), (1, 5), (0, 4), (0, 5)]\n    data_size = len(links)\n    link_labels = ([0] * data_size)\n    mapper = HinSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=self.num_samples, head_node_types=['A', 'B']).flow(links, link_labels)\n    assert (len(mapper) == 2)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        assert (len(nf) == 10)\n        assert (nf[0].shape == (self.batch_size, 1, self.n_feat['A']))\n        assert (nf[1].shape == (self.batch_size, 1, self.n_feat['B']))\n        assert (nf[2].shape == (self.batch_size, self.num_samples[0], self.n_feat['B']))\n        assert (nf[3].shape == (self.batch_size, self.num_samples[0], self.n_feat['B']))\n        assert (nf[4].shape == (self.batch_size, self.num_samples[0], self.n_feat['A']))\n        assert (nf[5].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['B']))\n        assert (nf[6].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['A']))\n        assert (nf[7].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['B']))\n        assert (nf[8].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['A']))\n        assert (nf[9].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['B']))\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper[2]", "masked_code": "def test_HinSAGELinkGenerator_1(self):\n    G = example_hin_1(self.n_feat)\n    links = [(1, 4), (1, 5), (0, 4), (0, 5)]\n    data_size = len(links)\n    link_labels = ([0] * data_size)\n    mapper = HinSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=self.num_samples, head_node_types=['A', 'B']).flow(links, link_labels)\n    assert (len(mapper) == 2)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        assert (len(nf) == 10)\n        assert (nf[0].shape == (self.batch_size, 1, self.n_feat['A']))\n        assert (nf[1].shape == (self.batch_size, 1, self.n_feat['B']))\n        assert (nf[2].shape == (self.batch_size, self.num_samples[0], self.n_feat['B']))\n        assert (nf[3].shape == (self.batch_size, self.num_samples[0], self.n_feat['B']))\n        assert (nf[4].shape == (self.batch_size, self.num_samples[0], self.n_feat['A']))\n        assert (nf[5].shape == '???')\n        assert (nf[6].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['A']))\n        assert (nf[7].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['B']))\n        assert (nf[8].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['A']))\n        assert (nf[9].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['B']))\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper[2]", "ground_truth": "(self.batch_size, np.multiply(*self.num_samples), self.n_feat['B'])", "quality_analysis": {"complexity_score": 15, "left_complexity": 2, "right_complexity": 13, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_884", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_HinSAGELinkGenerator", "funcname": "test_HinSAGELinkGenerator_1", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_HinSAGELinkGenerator_1(self):\n    G = example_hin_1(self.n_feat)\n    links = [(1, 4), (1, 5), (0, 4), (0, 5)]\n    data_size = len(links)\n    link_labels = ([0] * data_size)\n    mapper = HinSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=self.num_samples, head_node_types=['A', 'B']).flow(links, link_labels)\n    assert (len(mapper) == 2)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        assert (len(nf) == 10)\n        assert (nf[0].shape == (self.batch_size, 1, self.n_feat['A']))\n        assert (nf[1].shape == (self.batch_size, 1, self.n_feat['B']))\n        assert (nf[2].shape == (self.batch_size, self.num_samples[0], self.n_feat['B']))\n        assert (nf[3].shape == (self.batch_size, self.num_samples[0], self.n_feat['B']))\n        assert (nf[4].shape == (self.batch_size, self.num_samples[0], self.n_feat['A']))\n        assert (nf[5].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['B']))\n        assert (nf[6].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['A']))\n        assert (nf[7].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['B']))\n        assert (nf[8].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['A']))\n        assert (nf[9].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['B']))\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper[2]", "masked_code": "def test_HinSAGELinkGenerator_1(self):\n    G = example_hin_1(self.n_feat)\n    links = [(1, 4), (1, 5), (0, 4), (0, 5)]\n    data_size = len(links)\n    link_labels = ([0] * data_size)\n    mapper = HinSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=self.num_samples, head_node_types=['A', 'B']).flow(links, link_labels)\n    assert (len(mapper) == 2)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        assert (len(nf) == 10)\n        assert (nf[0].shape == (self.batch_size, 1, self.n_feat['A']))\n        assert (nf[1].shape == (self.batch_size, 1, self.n_feat['B']))\n        assert (nf[2].shape == (self.batch_size, self.num_samples[0], self.n_feat['B']))\n        assert (nf[3].shape == (self.batch_size, self.num_samples[0], self.n_feat['B']))\n        assert (nf[4].shape == (self.batch_size, self.num_samples[0], self.n_feat['A']))\n        assert (nf[5].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['B']))\n        assert (nf[6].shape == '???')\n        assert (nf[7].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['B']))\n        assert (nf[8].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['A']))\n        assert (nf[9].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['B']))\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper[2]", "ground_truth": "(self.batch_size, np.multiply(*self.num_samples), self.n_feat['A'])", "quality_analysis": {"complexity_score": 15, "left_complexity": 2, "right_complexity": 13, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_885", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_HinSAGELinkGenerator", "funcname": "test_HinSAGELinkGenerator_1", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_HinSAGELinkGenerator_1(self):\n    G = example_hin_1(self.n_feat)\n    links = [(1, 4), (1, 5), (0, 4), (0, 5)]\n    data_size = len(links)\n    link_labels = ([0] * data_size)\n    mapper = HinSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=self.num_samples, head_node_types=['A', 'B']).flow(links, link_labels)\n    assert (len(mapper) == 2)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        assert (len(nf) == 10)\n        assert (nf[0].shape == (self.batch_size, 1, self.n_feat['A']))\n        assert (nf[1].shape == (self.batch_size, 1, self.n_feat['B']))\n        assert (nf[2].shape == (self.batch_size, self.num_samples[0], self.n_feat['B']))\n        assert (nf[3].shape == (self.batch_size, self.num_samples[0], self.n_feat['B']))\n        assert (nf[4].shape == (self.batch_size, self.num_samples[0], self.n_feat['A']))\n        assert (nf[5].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['B']))\n        assert (nf[6].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['A']))\n        assert (nf[7].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['B']))\n        assert (nf[8].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['A']))\n        assert (nf[9].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['B']))\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper[2]", "masked_code": "def test_HinSAGELinkGenerator_1(self):\n    G = example_hin_1(self.n_feat)\n    links = [(1, 4), (1, 5), (0, 4), (0, 5)]\n    data_size = len(links)\n    link_labels = ([0] * data_size)\n    mapper = HinSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=self.num_samples, head_node_types=['A', 'B']).flow(links, link_labels)\n    assert (len(mapper) == 2)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        assert (len(nf) == 10)\n        assert (nf[0].shape == (self.batch_size, 1, self.n_feat['A']))\n        assert (nf[1].shape == (self.batch_size, 1, self.n_feat['B']))\n        assert (nf[2].shape == (self.batch_size, self.num_samples[0], self.n_feat['B']))\n        assert (nf[3].shape == (self.batch_size, self.num_samples[0], self.n_feat['B']))\n        assert (nf[4].shape == (self.batch_size, self.num_samples[0], self.n_feat['A']))\n        assert (nf[5].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['B']))\n        assert (nf[6].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['A']))\n        assert (nf[7].shape == '???')\n        assert (nf[8].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['A']))\n        assert (nf[9].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['B']))\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper[2]", "ground_truth": "(self.batch_size, np.multiply(*self.num_samples), self.n_feat['B'])", "quality_analysis": {"complexity_score": 15, "left_complexity": 2, "right_complexity": 13, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_886", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_HinSAGELinkGenerator", "funcname": "test_HinSAGELinkGenerator_1", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_HinSAGELinkGenerator_1(self):\n    G = example_hin_1(self.n_feat)\n    links = [(1, 4), (1, 5), (0, 4), (0, 5)]\n    data_size = len(links)\n    link_labels = ([0] * data_size)\n    mapper = HinSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=self.num_samples, head_node_types=['A', 'B']).flow(links, link_labels)\n    assert (len(mapper) == 2)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        assert (len(nf) == 10)\n        assert (nf[0].shape == (self.batch_size, 1, self.n_feat['A']))\n        assert (nf[1].shape == (self.batch_size, 1, self.n_feat['B']))\n        assert (nf[2].shape == (self.batch_size, self.num_samples[0], self.n_feat['B']))\n        assert (nf[3].shape == (self.batch_size, self.num_samples[0], self.n_feat['B']))\n        assert (nf[4].shape == (self.batch_size, self.num_samples[0], self.n_feat['A']))\n        assert (nf[5].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['B']))\n        assert (nf[6].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['A']))\n        assert (nf[7].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['B']))\n        assert (nf[8].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['A']))\n        assert (nf[9].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['B']))\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper[2]", "masked_code": "def test_HinSAGELinkGenerator_1(self):\n    G = example_hin_1(self.n_feat)\n    links = [(1, 4), (1, 5), (0, 4), (0, 5)]\n    data_size = len(links)\n    link_labels = ([0] * data_size)\n    mapper = HinSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=self.num_samples, head_node_types=['A', 'B']).flow(links, link_labels)\n    assert (len(mapper) == 2)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        assert (len(nf) == 10)\n        assert (nf[0].shape == (self.batch_size, 1, self.n_feat['A']))\n        assert (nf[1].shape == (self.batch_size, 1, self.n_feat['B']))\n        assert (nf[2].shape == (self.batch_size, self.num_samples[0], self.n_feat['B']))\n        assert (nf[3].shape == (self.batch_size, self.num_samples[0], self.n_feat['B']))\n        assert (nf[4].shape == (self.batch_size, self.num_samples[0], self.n_feat['A']))\n        assert (nf[5].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['B']))\n        assert (nf[6].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['A']))\n        assert (nf[7].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['B']))\n        assert (nf[8].shape == '???')\n        assert (nf[9].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['B']))\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper[2]", "ground_truth": "(self.batch_size, np.multiply(*self.num_samples), self.n_feat['A'])", "quality_analysis": {"complexity_score": 15, "left_complexity": 2, "right_complexity": 13, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_887", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_HinSAGELinkGenerator", "funcname": "test_HinSAGELinkGenerator_1", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_HinSAGELinkGenerator_1(self):\n    G = example_hin_1(self.n_feat)\n    links = [(1, 4), (1, 5), (0, 4), (0, 5)]\n    data_size = len(links)\n    link_labels = ([0] * data_size)\n    mapper = HinSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=self.num_samples, head_node_types=['A', 'B']).flow(links, link_labels)\n    assert (len(mapper) == 2)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        assert (len(nf) == 10)\n        assert (nf[0].shape == (self.batch_size, 1, self.n_feat['A']))\n        assert (nf[1].shape == (self.batch_size, 1, self.n_feat['B']))\n        assert (nf[2].shape == (self.batch_size, self.num_samples[0], self.n_feat['B']))\n        assert (nf[3].shape == (self.batch_size, self.num_samples[0], self.n_feat['B']))\n        assert (nf[4].shape == (self.batch_size, self.num_samples[0], self.n_feat['A']))\n        assert (nf[5].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['B']))\n        assert (nf[6].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['A']))\n        assert (nf[7].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['B']))\n        assert (nf[8].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['A']))\n        assert (nf[9].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['B']))\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper[2]", "masked_code": "def test_HinSAGELinkGenerator_1(self):\n    G = example_hin_1(self.n_feat)\n    links = [(1, 4), (1, 5), (0, 4), (0, 5)]\n    data_size = len(links)\n    link_labels = ([0] * data_size)\n    mapper = HinSAGELinkGenerator(G, batch_size=self.batch_size, num_samples=self.num_samples, head_node_types=['A', 'B']).flow(links, link_labels)\n    assert (len(mapper) == 2)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        assert (len(nf) == 10)\n        assert (nf[0].shape == (self.batch_size, 1, self.n_feat['A']))\n        assert (nf[1].shape == (self.batch_size, 1, self.n_feat['B']))\n        assert (nf[2].shape == (self.batch_size, self.num_samples[0], self.n_feat['B']))\n        assert (nf[3].shape == (self.batch_size, self.num_samples[0], self.n_feat['B']))\n        assert (nf[4].shape == (self.batch_size, self.num_samples[0], self.n_feat['A']))\n        assert (nf[5].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['B']))\n        assert (nf[6].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['A']))\n        assert (nf[7].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['B']))\n        assert (nf[8].shape == (self.batch_size, np.multiply(*self.num_samples), self.n_feat['A']))\n        assert (nf[9].shape == '???')\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper[2]", "ground_truth": "(self.batch_size, np.multiply(*self.num_samples), self.n_feat['B'])", "quality_analysis": {"complexity_score": 15, "left_complexity": 2, "right_complexity": 13, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_888", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_HinSAGELinkGenerator", "funcname": "test_HinSAGELinkGenerator_shuffle", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_HinSAGELinkGenerator_shuffle(self):\n\n    def test_edge_consistency(shuffle):\n        G = example_hin_1({'B': 1, 'A': 1})\n        edges = [(1, 4), (1, 5), (0, 4), (0, 5)]\n        data_size = len(edges)\n        edge_labels = np.arange(data_size)\n        mapper = HinSAGELinkGenerator(G, batch_size=2, num_samples=[0], head_node_types=['A', 'B']).flow(edges, edge_labels, shuffle=shuffle)\n        assert (len(mapper) == 2)\n        for batch in range(len(mapper)):\n            (nf, nl) = mapper[batch]\n            e1 = edges[nl[0]]\n            e2 = edges[nl[1]]\n            assert (nf[0][(0, 0, 0)] == e1[0])\n            assert (nf[1][(0, 0, 0)] == e1[1])\n            assert (nf[0][(1, 0, 0)] == e2[0])\n            assert (nf[1][(1, 0, 0)] == e2[1])\n    test_edge_consistency(True)\n    test_edge_consistency(False)", "masked_code": "def test_HinSAGELinkGenerator_shuffle(self):\n\n    def test_edge_consistency(shuffle):\n        G = example_hin_1({'B': 1, 'A': 1})\n        edges = [(1, 4), (1, 5), (0, 4), (0, 5)]\n        data_size = len(edges)\n        edge_labels = np.arange(data_size)\n        mapper = HinSAGELinkGenerator(G, batch_size=2, num_samples=[0], head_node_types=['A', 'B']).flow(edges, edge_labels, shuffle=shuffle)\n        assert (len(mapper) == 2)\n        for batch in range(len(mapper)):\n            (nf, nl) = mapper[batch]\n            e1 = edges[nl[0]]\n            e2 = edges[nl[1]]\n            assert (nf[0][(0, 0, 0)] == '???')\n            assert (nf[1][(0, 0, 0)] == e1[1])\n            assert (nf[0][(1, 0, 0)] == e2[0])\n            assert (nf[1][(1, 0, 0)] == e2[1])\n    test_edge_consistency(True)\n    test_edge_consistency(False)", "ground_truth": "e1[0]", "quality_analysis": {"complexity_score": 18, "left_complexity": 13, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_889", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_HinSAGELinkGenerator", "funcname": "test_HinSAGELinkGenerator_shuffle", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_HinSAGELinkGenerator_shuffle(self):\n\n    def test_edge_consistency(shuffle):\n        G = example_hin_1({'B': 1, 'A': 1})\n        edges = [(1, 4), (1, 5), (0, 4), (0, 5)]\n        data_size = len(edges)\n        edge_labels = np.arange(data_size)\n        mapper = HinSAGELinkGenerator(G, batch_size=2, num_samples=[0], head_node_types=['A', 'B']).flow(edges, edge_labels, shuffle=shuffle)\n        assert (len(mapper) == 2)\n        for batch in range(len(mapper)):\n            (nf, nl) = mapper[batch]\n            e1 = edges[nl[0]]\n            e2 = edges[nl[1]]\n            assert (nf[0][(0, 0, 0)] == e1[0])\n            assert (nf[1][(0, 0, 0)] == e1[1])\n            assert (nf[0][(1, 0, 0)] == e2[0])\n            assert (nf[1][(1, 0, 0)] == e2[1])\n    test_edge_consistency(True)\n    test_edge_consistency(False)", "masked_code": "def test_HinSAGELinkGenerator_shuffle(self):\n\n    def test_edge_consistency(shuffle):\n        G = example_hin_1({'B': 1, 'A': 1})\n        edges = [(1, 4), (1, 5), (0, 4), (0, 5)]\n        data_size = len(edges)\n        edge_labels = np.arange(data_size)\n        mapper = HinSAGELinkGenerator(G, batch_size=2, num_samples=[0], head_node_types=['A', 'B']).flow(edges, edge_labels, shuffle=shuffle)\n        assert (len(mapper) == 2)\n        for batch in range(len(mapper)):\n            (nf, nl) = mapper[batch]\n            e1 = edges[nl[0]]\n            e2 = edges[nl[1]]\n            assert (nf[0][(0, 0, 0)] == e1[0])\n            assert (nf[1][(0, 0, 0)] == '???')\n            assert (nf[0][(1, 0, 0)] == e2[0])\n            assert (nf[1][(1, 0, 0)] == e2[1])\n    test_edge_consistency(True)\n    test_edge_consistency(False)", "ground_truth": "e1[1]", "quality_analysis": {"complexity_score": 18, "left_complexity": 13, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_890", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_HinSAGELinkGenerator", "funcname": "test_HinSAGELinkGenerator_shuffle", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_HinSAGELinkGenerator_shuffle(self):\n\n    def test_edge_consistency(shuffle):\n        G = example_hin_1({'B': 1, 'A': 1})\n        edges = [(1, 4), (1, 5), (0, 4), (0, 5)]\n        data_size = len(edges)\n        edge_labels = np.arange(data_size)\n        mapper = HinSAGELinkGenerator(G, batch_size=2, num_samples=[0], head_node_types=['A', 'B']).flow(edges, edge_labels, shuffle=shuffle)\n        assert (len(mapper) == 2)\n        for batch in range(len(mapper)):\n            (nf, nl) = mapper[batch]\n            e1 = edges[nl[0]]\n            e2 = edges[nl[1]]\n            assert (nf[0][(0, 0, 0)] == e1[0])\n            assert (nf[1][(0, 0, 0)] == e1[1])\n            assert (nf[0][(1, 0, 0)] == e2[0])\n            assert (nf[1][(1, 0, 0)] == e2[1])\n    test_edge_consistency(True)\n    test_edge_consistency(False)", "masked_code": "def test_HinSAGELinkGenerator_shuffle(self):\n\n    def test_edge_consistency(shuffle):\n        G = example_hin_1({'B': 1, 'A': 1})\n        edges = [(1, 4), (1, 5), (0, 4), (0, 5)]\n        data_size = len(edges)\n        edge_labels = np.arange(data_size)\n        mapper = HinSAGELinkGenerator(G, batch_size=2, num_samples=[0], head_node_types=['A', 'B']).flow(edges, edge_labels, shuffle=shuffle)\n        assert (len(mapper) == 2)\n        for batch in range(len(mapper)):\n            (nf, nl) = mapper[batch]\n            e1 = edges[nl[0]]\n            e2 = edges[nl[1]]\n            assert (nf[0][(0, 0, 0)] == e1[0])\n            assert (nf[1][(0, 0, 0)] == e1[1])\n            assert (nf[0][(1, 0, 0)] == '???')\n            assert (nf[1][(1, 0, 0)] == e2[1])\n    test_edge_consistency(True)\n    test_edge_consistency(False)", "ground_truth": "e2[0]", "quality_analysis": {"complexity_score": 18, "left_complexity": 13, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_891", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_HinSAGELinkGenerator", "funcname": "test_HinSAGELinkGenerator_shuffle", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_HinSAGELinkGenerator_shuffle(self):\n\n    def test_edge_consistency(shuffle):\n        G = example_hin_1({'B': 1, 'A': 1})\n        edges = [(1, 4), (1, 5), (0, 4), (0, 5)]\n        data_size = len(edges)\n        edge_labels = np.arange(data_size)\n        mapper = HinSAGELinkGenerator(G, batch_size=2, num_samples=[0], head_node_types=['A', 'B']).flow(edges, edge_labels, shuffle=shuffle)\n        assert (len(mapper) == 2)\n        for batch in range(len(mapper)):\n            (nf, nl) = mapper[batch]\n            e1 = edges[nl[0]]\n            e2 = edges[nl[1]]\n            assert (nf[0][(0, 0, 0)] == e1[0])\n            assert (nf[1][(0, 0, 0)] == e1[1])\n            assert (nf[0][(1, 0, 0)] == e2[0])\n            assert (nf[1][(1, 0, 0)] == e2[1])\n    test_edge_consistency(True)\n    test_edge_consistency(False)", "masked_code": "def test_HinSAGELinkGenerator_shuffle(self):\n\n    def test_edge_consistency(shuffle):\n        G = example_hin_1({'B': 1, 'A': 1})\n        edges = [(1, 4), (1, 5), (0, 4), (0, 5)]\n        data_size = len(edges)\n        edge_labels = np.arange(data_size)\n        mapper = HinSAGELinkGenerator(G, batch_size=2, num_samples=[0], head_node_types=['A', 'B']).flow(edges, edge_labels, shuffle=shuffle)\n        assert (len(mapper) == 2)\n        for batch in range(len(mapper)):\n            (nf, nl) = mapper[batch]\n            e1 = edges[nl[0]]\n            e2 = edges[nl[1]]\n            assert (nf[0][(0, 0, 0)] == e1[0])\n            assert (nf[1][(0, 0, 0)] == e1[1])\n            assert (nf[0][(1, 0, 0)] == e2[0])\n            assert (nf[1][(1, 0, 0)] == '???')\n    test_edge_consistency(True)\n    test_edge_consistency(False)", "ground_truth": "e2[1]", "quality_analysis": {"complexity_score": 18, "left_complexity": 13, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_892", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_HinSAGELinkGenerator", "funcname": "test_edge_consistency", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_edge_consistency(shuffle):\n    G = example_hin_1({'B': 1, 'A': 1})\n    edges = [(1, 4), (1, 5), (0, 4), (0, 5)]\n    data_size = len(edges)\n    edge_labels = np.arange(data_size)\n    mapper = HinSAGELinkGenerator(G, batch_size=2, num_samples=[0], head_node_types=['A', 'B']).flow(edges, edge_labels, shuffle=shuffle)\n    assert (len(mapper) == 2)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        e1 = edges[nl[0]]\n        e2 = edges[nl[1]]\n        assert (nf[0][(0, 0, 0)] == e1[0])\n        assert (nf[1][(0, 0, 0)] == e1[1])\n        assert (nf[0][(1, 0, 0)] == e2[0])\n        assert (nf[1][(1, 0, 0)] == e2[1])", "masked_code": "def test_edge_consistency(shuffle):\n    G = example_hin_1({'B': 1, 'A': 1})\n    edges = [(1, 4), (1, 5), (0, 4), (0, 5)]\n    data_size = len(edges)\n    edge_labels = np.arange(data_size)\n    mapper = HinSAGELinkGenerator(G, batch_size=2, num_samples=[0], head_node_types=['A', 'B']).flow(edges, edge_labels, shuffle=shuffle)\n    assert (len(mapper) == 2)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        e1 = edges[nl[0]]\n        e2 = edges[nl[1]]\n        assert (nf[0][(0, 0, 0)] == '???')\n        assert (nf[1][(0, 0, 0)] == e1[1])\n        assert (nf[0][(1, 0, 0)] == e2[0])\n        assert (nf[1][(1, 0, 0)] == e2[1])", "ground_truth": "e1[0]", "quality_analysis": {"complexity_score": 18, "left_complexity": 13, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_893", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_HinSAGELinkGenerator", "funcname": "test_edge_consistency", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_edge_consistency(shuffle):\n    G = example_hin_1({'B': 1, 'A': 1})\n    edges = [(1, 4), (1, 5), (0, 4), (0, 5)]\n    data_size = len(edges)\n    edge_labels = np.arange(data_size)\n    mapper = HinSAGELinkGenerator(G, batch_size=2, num_samples=[0], head_node_types=['A', 'B']).flow(edges, edge_labels, shuffle=shuffle)\n    assert (len(mapper) == 2)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        e1 = edges[nl[0]]\n        e2 = edges[nl[1]]\n        assert (nf[0][(0, 0, 0)] == e1[0])\n        assert (nf[1][(0, 0, 0)] == e1[1])\n        assert (nf[0][(1, 0, 0)] == e2[0])\n        assert (nf[1][(1, 0, 0)] == e2[1])", "masked_code": "def test_edge_consistency(shuffle):\n    G = example_hin_1({'B': 1, 'A': 1})\n    edges = [(1, 4), (1, 5), (0, 4), (0, 5)]\n    data_size = len(edges)\n    edge_labels = np.arange(data_size)\n    mapper = HinSAGELinkGenerator(G, batch_size=2, num_samples=[0], head_node_types=['A', 'B']).flow(edges, edge_labels, shuffle=shuffle)\n    assert (len(mapper) == 2)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        e1 = edges[nl[0]]\n        e2 = edges[nl[1]]\n        assert (nf[0][(0, 0, 0)] == e1[0])\n        assert (nf[1][(0, 0, 0)] == '???')\n        assert (nf[0][(1, 0, 0)] == e2[0])\n        assert (nf[1][(1, 0, 0)] == e2[1])", "ground_truth": "e1[1]", "quality_analysis": {"complexity_score": 18, "left_complexity": 13, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_894", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_HinSAGELinkGenerator", "funcname": "test_edge_consistency", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_edge_consistency(shuffle):\n    G = example_hin_1({'B': 1, 'A': 1})\n    edges = [(1, 4), (1, 5), (0, 4), (0, 5)]\n    data_size = len(edges)\n    edge_labels = np.arange(data_size)\n    mapper = HinSAGELinkGenerator(G, batch_size=2, num_samples=[0], head_node_types=['A', 'B']).flow(edges, edge_labels, shuffle=shuffle)\n    assert (len(mapper) == 2)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        e1 = edges[nl[0]]\n        e2 = edges[nl[1]]\n        assert (nf[0][(0, 0, 0)] == e1[0])\n        assert (nf[1][(0, 0, 0)] == e1[1])\n        assert (nf[0][(1, 0, 0)] == e2[0])\n        assert (nf[1][(1, 0, 0)] == e2[1])", "masked_code": "def test_edge_consistency(shuffle):\n    G = example_hin_1({'B': 1, 'A': 1})\n    edges = [(1, 4), (1, 5), (0, 4), (0, 5)]\n    data_size = len(edges)\n    edge_labels = np.arange(data_size)\n    mapper = HinSAGELinkGenerator(G, batch_size=2, num_samples=[0], head_node_types=['A', 'B']).flow(edges, edge_labels, shuffle=shuffle)\n    assert (len(mapper) == 2)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        e1 = edges[nl[0]]\n        e2 = edges[nl[1]]\n        assert (nf[0][(0, 0, 0)] == e1[0])\n        assert (nf[1][(0, 0, 0)] == e1[1])\n        assert (nf[0][(1, 0, 0)] == '???')\n        assert (nf[1][(1, 0, 0)] == e2[1])", "ground_truth": "e2[0]", "quality_analysis": {"complexity_score": 18, "left_complexity": 13, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_895", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_HinSAGELinkGenerator", "funcname": "test_edge_consistency", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_edge_consistency(shuffle):\n    G = example_hin_1({'B': 1, 'A': 1})\n    edges = [(1, 4), (1, 5), (0, 4), (0, 5)]\n    data_size = len(edges)\n    edge_labels = np.arange(data_size)\n    mapper = HinSAGELinkGenerator(G, batch_size=2, num_samples=[0], head_node_types=['A', 'B']).flow(edges, edge_labels, shuffle=shuffle)\n    assert (len(mapper) == 2)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        e1 = edges[nl[0]]\n        e2 = edges[nl[1]]\n        assert (nf[0][(0, 0, 0)] == e1[0])\n        assert (nf[1][(0, 0, 0)] == e1[1])\n        assert (nf[0][(1, 0, 0)] == e2[0])\n        assert (nf[1][(1, 0, 0)] == e2[1])", "masked_code": "def test_edge_consistency(shuffle):\n    G = example_hin_1({'B': 1, 'A': 1})\n    edges = [(1, 4), (1, 5), (0, 4), (0, 5)]\n    data_size = len(edges)\n    edge_labels = np.arange(data_size)\n    mapper = HinSAGELinkGenerator(G, batch_size=2, num_samples=[0], head_node_types=['A', 'B']).flow(edges, edge_labels, shuffle=shuffle)\n    assert (len(mapper) == 2)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        e1 = edges[nl[0]]\n        e2 = edges[nl[1]]\n        assert (nf[0][(0, 0, 0)] == e1[0])\n        assert (nf[1][(0, 0, 0)] == e1[1])\n        assert (nf[0][(1, 0, 0)] == e2[0])\n        assert (nf[1][(1, 0, 0)] == '???')", "ground_truth": "e2[1]", "quality_analysis": {"complexity_score": 18, "left_complexity": 13, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_896", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_HinSAGELinkGenerator", "funcname": "test_HinSAGELinkGenerator_isolates", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_HinSAGELinkGenerator_isolates(self):\n    \"\\n        This tests link generator's iterator for prediction, i.e., without targets provided\\n        \"\n    n_batch = 2\n    n_samples = [2, 2]\n    feature_size_by_type = {'A': 4, 'B': 2}\n    nodes_by_type = {'A': 5, 'B': 5}\n    n_isolates_by_type = {'A': 0, 'B': 2}\n    edges_by_type = {('A', 'A'): 5, ('A', 'B'): 10}\n    (Gh, hnodes) = example_hin_random(feature_size_by_type, nodes_by_type, n_isolates_by_type, edges_by_type)\n    head_links = [(hnodes['A'][0], hnodes['B'][(- 1)])]\n    gen = HinSAGELinkGenerator(Gh, batch_size=n_batch, num_samples=n_samples, head_node_types=['A', 'B'])\n    flow = gen.flow(head_links)\n    (ne, nl) = flow[0]\n    assert (len(gen._sampling_schema[0]) == len(ne))\n    assert (pytest.approx([1, 1, 2, 2, 2, 4, 4, 4, 4, 4]) == [x.shape[1] for x in ne])\n    head_links = [(hnodes['B'][(- 2)], hnodes['B'][(- 1)])]\n    gen = HinSAGELinkGenerator(Gh, batch_size=n_batch, num_samples=n_samples, head_node_types=['B', 'B'])\n    flow = gen.flow(head_links)\n    (ne, nl) = flow[0]\n    assert (len(gen._sampling_schema[0]) == len(ne))\n    assert (pytest.approx([1, 1, 2, 2, 4, 4, 4, 4]) == [x.shape[1] for x in ne])\n    assert all(((pytest.approx(0) == x) for x in ne[2:]))", "masked_code": "def test_HinSAGELinkGenerator_isolates(self):\n    \"\\n        This tests link generator's iterator for prediction, i.e., without targets provided\\n        \"\n    n_batch = 2\n    n_samples = [2, 2]\n    feature_size_by_type = {'A': 4, 'B': 2}\n    nodes_by_type = {'A': 5, 'B': 5}\n    n_isolates_by_type = {'A': 0, 'B': 2}\n    edges_by_type = {('A', 'A'): 5, ('A', 'B'): 10}\n    (Gh, hnodes) = example_hin_random(feature_size_by_type, nodes_by_type, n_isolates_by_type, edges_by_type)\n    head_links = [(hnodes['A'][0], hnodes['B'][(- 1)])]\n    gen = HinSAGELinkGenerator(Gh, batch_size=n_batch, num_samples=n_samples, head_node_types=['A', 'B'])\n    flow = gen.flow(head_links)\n    (ne, nl) = flow[0]\n    assert (len(gen._sampling_schema[0]) == '???')\n    assert (pytest.approx([1, 1, 2, 2, 2, 4, 4, 4, 4, 4]) == [x.shape[1] for x in ne])\n    head_links = [(hnodes['B'][(- 2)], hnodes['B'][(- 1)])]\n    gen = HinSAGELinkGenerator(Gh, batch_size=n_batch, num_samples=n_samples, head_node_types=['B', 'B'])\n    flow = gen.flow(head_links)\n    (ne, nl) = flow[0]\n    assert (len(gen._sampling_schema[0]) == len(ne))\n    assert (pytest.approx([1, 1, 2, 2, 4, 4, 4, 4]) == [x.shape[1] for x in ne])\n    assert all(((pytest.approx(0) == x) for x in ne[2:]))", "ground_truth": "len(ne)", "quality_analysis": {"complexity_score": 13, "left_complexity": 9, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_897", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_HinSAGELinkGenerator", "funcname": "test_HinSAGELinkGenerator_isolates", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_HinSAGELinkGenerator_isolates(self):\n    \"\\n        This tests link generator's iterator for prediction, i.e., without targets provided\\n        \"\n    n_batch = 2\n    n_samples = [2, 2]\n    feature_size_by_type = {'A': 4, 'B': 2}\n    nodes_by_type = {'A': 5, 'B': 5}\n    n_isolates_by_type = {'A': 0, 'B': 2}\n    edges_by_type = {('A', 'A'): 5, ('A', 'B'): 10}\n    (Gh, hnodes) = example_hin_random(feature_size_by_type, nodes_by_type, n_isolates_by_type, edges_by_type)\n    head_links = [(hnodes['A'][0], hnodes['B'][(- 1)])]\n    gen = HinSAGELinkGenerator(Gh, batch_size=n_batch, num_samples=n_samples, head_node_types=['A', 'B'])\n    flow = gen.flow(head_links)\n    (ne, nl) = flow[0]\n    assert (len(gen._sampling_schema[0]) == len(ne))\n    assert (pytest.approx([1, 1, 2, 2, 2, 4, 4, 4, 4, 4]) == [x.shape[1] for x in ne])\n    head_links = [(hnodes['B'][(- 2)], hnodes['B'][(- 1)])]\n    gen = HinSAGELinkGenerator(Gh, batch_size=n_batch, num_samples=n_samples, head_node_types=['B', 'B'])\n    flow = gen.flow(head_links)\n    (ne, nl) = flow[0]\n    assert (len(gen._sampling_schema[0]) == len(ne))\n    assert (pytest.approx([1, 1, 2, 2, 4, 4, 4, 4]) == [x.shape[1] for x in ne])\n    assert all(((pytest.approx(0) == x) for x in ne[2:]))", "masked_code": "def test_HinSAGELinkGenerator_isolates(self):\n    \"\\n        This tests link generator's iterator for prediction, i.e., without targets provided\\n        \"\n    n_batch = 2\n    n_samples = [2, 2]\n    feature_size_by_type = {'A': 4, 'B': 2}\n    nodes_by_type = {'A': 5, 'B': 5}\n    n_isolates_by_type = {'A': 0, 'B': 2}\n    edges_by_type = {('A', 'A'): 5, ('A', 'B'): 10}\n    (Gh, hnodes) = example_hin_random(feature_size_by_type, nodes_by_type, n_isolates_by_type, edges_by_type)\n    head_links = [(hnodes['A'][0], hnodes['B'][(- 1)])]\n    gen = HinSAGELinkGenerator(Gh, batch_size=n_batch, num_samples=n_samples, head_node_types=['A', 'B'])\n    flow = gen.flow(head_links)\n    (ne, nl) = flow[0]\n    assert (len(gen._sampling_schema[0]) == len(ne))\n    assert (pytest.approx([1, 1, 2, 2, 2, 4, 4, 4, 4, 4]) == '???')\n    head_links = [(hnodes['B'][(- 2)], hnodes['B'][(- 1)])]\n    gen = HinSAGELinkGenerator(Gh, batch_size=n_batch, num_samples=n_samples, head_node_types=['B', 'B'])\n    flow = gen.flow(head_links)\n    (ne, nl) = flow[0]\n    assert (len(gen._sampling_schema[0]) == len(ne))\n    assert (pytest.approx([1, 1, 2, 2, 4, 4, 4, 4]) == [x.shape[1] for x in ne])\n    assert all(((pytest.approx(0) == x) for x in ne[2:]))", "ground_truth": "[x.shape[1] for x in ne]", "quality_analysis": {"complexity_score": 15, "left_complexity": 15, "right_complexity": 0, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_898", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_HinSAGELinkGenerator", "funcname": "test_HinSAGELinkGenerator_isolates", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_HinSAGELinkGenerator_isolates(self):\n    \"\\n        This tests link generator's iterator for prediction, i.e., without targets provided\\n        \"\n    n_batch = 2\n    n_samples = [2, 2]\n    feature_size_by_type = {'A': 4, 'B': 2}\n    nodes_by_type = {'A': 5, 'B': 5}\n    n_isolates_by_type = {'A': 0, 'B': 2}\n    edges_by_type = {('A', 'A'): 5, ('A', 'B'): 10}\n    (Gh, hnodes) = example_hin_random(feature_size_by_type, nodes_by_type, n_isolates_by_type, edges_by_type)\n    head_links = [(hnodes['A'][0], hnodes['B'][(- 1)])]\n    gen = HinSAGELinkGenerator(Gh, batch_size=n_batch, num_samples=n_samples, head_node_types=['A', 'B'])\n    flow = gen.flow(head_links)\n    (ne, nl) = flow[0]\n    assert (len(gen._sampling_schema[0]) == len(ne))\n    assert (pytest.approx([1, 1, 2, 2, 2, 4, 4, 4, 4, 4]) == [x.shape[1] for x in ne])\n    head_links = [(hnodes['B'][(- 2)], hnodes['B'][(- 1)])]\n    gen = HinSAGELinkGenerator(Gh, batch_size=n_batch, num_samples=n_samples, head_node_types=['B', 'B'])\n    flow = gen.flow(head_links)\n    (ne, nl) = flow[0]\n    assert (len(gen._sampling_schema[0]) == len(ne))\n    assert (pytest.approx([1, 1, 2, 2, 4, 4, 4, 4]) == [x.shape[1] for x in ne])\n    assert all(((pytest.approx(0) == x) for x in ne[2:]))", "masked_code": "def test_HinSAGELinkGenerator_isolates(self):\n    \"\\n        This tests link generator's iterator for prediction, i.e., without targets provided\\n        \"\n    n_batch = 2\n    n_samples = [2, 2]\n    feature_size_by_type = {'A': 4, 'B': 2}\n    nodes_by_type = {'A': 5, 'B': 5}\n    n_isolates_by_type = {'A': 0, 'B': 2}\n    edges_by_type = {('A', 'A'): 5, ('A', 'B'): 10}\n    (Gh, hnodes) = example_hin_random(feature_size_by_type, nodes_by_type, n_isolates_by_type, edges_by_type)\n    head_links = [(hnodes['A'][0], hnodes['B'][(- 1)])]\n    gen = HinSAGELinkGenerator(Gh, batch_size=n_batch, num_samples=n_samples, head_node_types=['A', 'B'])\n    flow = gen.flow(head_links)\n    (ne, nl) = flow[0]\n    assert (len(gen._sampling_schema[0]) == len(ne))\n    assert (pytest.approx([1, 1, 2, 2, 2, 4, 4, 4, 4, 4]) == [x.shape[1] for x in ne])\n    head_links = [(hnodes['B'][(- 2)], hnodes['B'][(- 1)])]\n    gen = HinSAGELinkGenerator(Gh, batch_size=n_batch, num_samples=n_samples, head_node_types=['B', 'B'])\n    flow = gen.flow(head_links)\n    (ne, nl) = flow[0]\n    assert (len(gen._sampling_schema[0]) == '???')\n    assert (pytest.approx([1, 1, 2, 2, 4, 4, 4, 4]) == [x.shape[1] for x in ne])\n    assert all(((pytest.approx(0) == x) for x in ne[2:]))", "ground_truth": "len(ne)", "quality_analysis": {"complexity_score": 13, "left_complexity": 9, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_899", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_HinSAGELinkGenerator", "funcname": "test_HinSAGELinkGenerator_isolates", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_HinSAGELinkGenerator_isolates(self):\n    \"\\n        This tests link generator's iterator for prediction, i.e., without targets provided\\n        \"\n    n_batch = 2\n    n_samples = [2, 2]\n    feature_size_by_type = {'A': 4, 'B': 2}\n    nodes_by_type = {'A': 5, 'B': 5}\n    n_isolates_by_type = {'A': 0, 'B': 2}\n    edges_by_type = {('A', 'A'): 5, ('A', 'B'): 10}\n    (Gh, hnodes) = example_hin_random(feature_size_by_type, nodes_by_type, n_isolates_by_type, edges_by_type)\n    head_links = [(hnodes['A'][0], hnodes['B'][(- 1)])]\n    gen = HinSAGELinkGenerator(Gh, batch_size=n_batch, num_samples=n_samples, head_node_types=['A', 'B'])\n    flow = gen.flow(head_links)\n    (ne, nl) = flow[0]\n    assert (len(gen._sampling_schema[0]) == len(ne))\n    assert (pytest.approx([1, 1, 2, 2, 2, 4, 4, 4, 4, 4]) == [x.shape[1] for x in ne])\n    head_links = [(hnodes['B'][(- 2)], hnodes['B'][(- 1)])]\n    gen = HinSAGELinkGenerator(Gh, batch_size=n_batch, num_samples=n_samples, head_node_types=['B', 'B'])\n    flow = gen.flow(head_links)\n    (ne, nl) = flow[0]\n    assert (len(gen._sampling_schema[0]) == len(ne))\n    assert (pytest.approx([1, 1, 2, 2, 4, 4, 4, 4]) == [x.shape[1] for x in ne])\n    assert all(((pytest.approx(0) == x) for x in ne[2:]))", "masked_code": "def test_HinSAGELinkGenerator_isolates(self):\n    \"\\n        This tests link generator's iterator for prediction, i.e., without targets provided\\n        \"\n    n_batch = 2\n    n_samples = [2, 2]\n    feature_size_by_type = {'A': 4, 'B': 2}\n    nodes_by_type = {'A': 5, 'B': 5}\n    n_isolates_by_type = {'A': 0, 'B': 2}\n    edges_by_type = {('A', 'A'): 5, ('A', 'B'): 10}\n    (Gh, hnodes) = example_hin_random(feature_size_by_type, nodes_by_type, n_isolates_by_type, edges_by_type)\n    head_links = [(hnodes['A'][0], hnodes['B'][(- 1)])]\n    gen = HinSAGELinkGenerator(Gh, batch_size=n_batch, num_samples=n_samples, head_node_types=['A', 'B'])\n    flow = gen.flow(head_links)\n    (ne, nl) = flow[0]\n    assert (len(gen._sampling_schema[0]) == len(ne))\n    assert (pytest.approx([1, 1, 2, 2, 2, 4, 4, 4, 4, 4]) == [x.shape[1] for x in ne])\n    head_links = [(hnodes['B'][(- 2)], hnodes['B'][(- 1)])]\n    gen = HinSAGELinkGenerator(Gh, batch_size=n_batch, num_samples=n_samples, head_node_types=['B', 'B'])\n    flow = gen.flow(head_links)\n    (ne, nl) = flow[0]\n    assert (len(gen._sampling_schema[0]) == len(ne))\n    assert (pytest.approx([1, 1, 2, 2, 4, 4, 4, 4]) == '???')\n    assert all(((pytest.approx(0) == x) for x in ne[2:]))", "ground_truth": "[x.shape[1] for x in ne]", "quality_analysis": {"complexity_score": 13, "left_complexity": 13, "right_complexity": 0, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_900", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_Attri2VecLinkGenerator", "funcname": "test_LinkMapper_constructor", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_LinkMapper_constructor(self):\n    G = example_graph(feature_size=self.n_feat)\n    edge_labels = ([0] * G.number_of_edges())\n    generator = Attri2VecLinkGenerator(G, batch_size=self.batch_size)\n    mapper = generator.flow(G.edges(), edge_labels)\n    assert (generator.batch_size == self.batch_size)\n    assert (mapper.data_size == G.number_of_edges())\n    assert (len(mapper.ids) == G.number_of_edges())\n    G = example_graph(feature_size=self.n_feat, is_directed=True)\n    edge_labels = ([0] * G.number_of_edges())\n    generator = Attri2VecLinkGenerator(G, batch_size=self.batch_size)\n    mapper = generator.flow(G.edges(), edge_labels)\n    assert (generator.batch_size == self.batch_size)\n    assert (mapper.data_size == G.number_of_edges())\n    assert (len(mapper.ids) == G.number_of_edges())", "masked_code": "def test_LinkMapper_constructor(self):\n    G = example_graph(feature_size=self.n_feat)\n    edge_labels = ([0] * G.number_of_edges())\n    generator = Attri2VecLinkGenerator(G, batch_size=self.batch_size)\n    mapper = generator.flow(G.edges(), edge_labels)\n    assert (generator.batch_size == '???')\n    assert (mapper.data_size == G.number_of_edges())\n    assert (len(mapper.ids) == G.number_of_edges())\n    G = example_graph(feature_size=self.n_feat, is_directed=True)\n    edge_labels = ([0] * G.number_of_edges())\n    generator = Attri2VecLinkGenerator(G, batch_size=self.batch_size)\n    mapper = generator.flow(G.edges(), edge_labels)\n    assert (generator.batch_size == self.batch_size)\n    assert (mapper.data_size == G.number_of_edges())\n    assert (len(mapper.ids) == G.number_of_edges())", "ground_truth": "self.batch_size", "quality_analysis": {"complexity_score": 4, "left_complexity": 2, "right_complexity": 2, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_901", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_Attri2VecLinkGenerator", "funcname": "test_LinkMapper_constructor", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_LinkMapper_constructor(self):\n    G = example_graph(feature_size=self.n_feat)\n    edge_labels = ([0] * G.number_of_edges())\n    generator = Attri2VecLinkGenerator(G, batch_size=self.batch_size)\n    mapper = generator.flow(G.edges(), edge_labels)\n    assert (generator.batch_size == self.batch_size)\n    assert (mapper.data_size == G.number_of_edges())\n    assert (len(mapper.ids) == G.number_of_edges())\n    G = example_graph(feature_size=self.n_feat, is_directed=True)\n    edge_labels = ([0] * G.number_of_edges())\n    generator = Attri2VecLinkGenerator(G, batch_size=self.batch_size)\n    mapper = generator.flow(G.edges(), edge_labels)\n    assert (generator.batch_size == self.batch_size)\n    assert (mapper.data_size == G.number_of_edges())\n    assert (len(mapper.ids) == G.number_of_edges())", "masked_code": "def test_LinkMapper_constructor(self):\n    G = example_graph(feature_size=self.n_feat)\n    edge_labels = ([0] * G.number_of_edges())\n    generator = Attri2VecLinkGenerator(G, batch_size=self.batch_size)\n    mapper = generator.flow(G.edges(), edge_labels)\n    assert (generator.batch_size == self.batch_size)\n    assert (mapper.data_size == '???')\n    assert (len(mapper.ids) == G.number_of_edges())\n    G = example_graph(feature_size=self.n_feat, is_directed=True)\n    edge_labels = ([0] * G.number_of_edges())\n    generator = Attri2VecLinkGenerator(G, batch_size=self.batch_size)\n    mapper = generator.flow(G.edges(), edge_labels)\n    assert (generator.batch_size == self.batch_size)\n    assert (mapper.data_size == G.number_of_edges())\n    assert (len(mapper.ids) == G.number_of_edges())", "ground_truth": "G.number_of_edges()", "quality_analysis": {"complexity_score": 5, "left_complexity": 2, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_902", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_Attri2VecLinkGenerator", "funcname": "test_LinkMapper_constructor", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_LinkMapper_constructor(self):\n    G = example_graph(feature_size=self.n_feat)\n    edge_labels = ([0] * G.number_of_edges())\n    generator = Attri2VecLinkGenerator(G, batch_size=self.batch_size)\n    mapper = generator.flow(G.edges(), edge_labels)\n    assert (generator.batch_size == self.batch_size)\n    assert (mapper.data_size == G.number_of_edges())\n    assert (len(mapper.ids) == G.number_of_edges())\n    G = example_graph(feature_size=self.n_feat, is_directed=True)\n    edge_labels = ([0] * G.number_of_edges())\n    generator = Attri2VecLinkGenerator(G, batch_size=self.batch_size)\n    mapper = generator.flow(G.edges(), edge_labels)\n    assert (generator.batch_size == self.batch_size)\n    assert (mapper.data_size == G.number_of_edges())\n    assert (len(mapper.ids) == G.number_of_edges())", "masked_code": "def test_LinkMapper_constructor(self):\n    G = example_graph(feature_size=self.n_feat)\n    edge_labels = ([0] * G.number_of_edges())\n    generator = Attri2VecLinkGenerator(G, batch_size=self.batch_size)\n    mapper = generator.flow(G.edges(), edge_labels)\n    assert (generator.batch_size == self.batch_size)\n    assert (mapper.data_size == G.number_of_edges())\n    assert (len(mapper.ids) == '???')\n    G = example_graph(feature_size=self.n_feat, is_directed=True)\n    edge_labels = ([0] * G.number_of_edges())\n    generator = Attri2VecLinkGenerator(G, batch_size=self.batch_size)\n    mapper = generator.flow(G.edges(), edge_labels)\n    assert (generator.batch_size == self.batch_size)\n    assert (mapper.data_size == G.number_of_edges())\n    assert (len(mapper.ids) == G.number_of_edges())", "ground_truth": "G.number_of_edges()", "quality_analysis": {"complexity_score": 8, "left_complexity": 5, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_903", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_Attri2VecLinkGenerator", "funcname": "test_LinkMapper_constructor", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_LinkMapper_constructor(self):\n    G = example_graph(feature_size=self.n_feat)\n    edge_labels = ([0] * G.number_of_edges())\n    generator = Attri2VecLinkGenerator(G, batch_size=self.batch_size)\n    mapper = generator.flow(G.edges(), edge_labels)\n    assert (generator.batch_size == self.batch_size)\n    assert (mapper.data_size == G.number_of_edges())\n    assert (len(mapper.ids) == G.number_of_edges())\n    G = example_graph(feature_size=self.n_feat, is_directed=True)\n    edge_labels = ([0] * G.number_of_edges())\n    generator = Attri2VecLinkGenerator(G, batch_size=self.batch_size)\n    mapper = generator.flow(G.edges(), edge_labels)\n    assert (generator.batch_size == self.batch_size)\n    assert (mapper.data_size == G.number_of_edges())\n    assert (len(mapper.ids) == G.number_of_edges())", "masked_code": "def test_LinkMapper_constructor(self):\n    G = example_graph(feature_size=self.n_feat)\n    edge_labels = ([0] * G.number_of_edges())\n    generator = Attri2VecLinkGenerator(G, batch_size=self.batch_size)\n    mapper = generator.flow(G.edges(), edge_labels)\n    assert (generator.batch_size == self.batch_size)\n    assert (mapper.data_size == G.number_of_edges())\n    assert (len(mapper.ids) == G.number_of_edges())\n    G = example_graph(feature_size=self.n_feat, is_directed=True)\n    edge_labels = ([0] * G.number_of_edges())\n    generator = Attri2VecLinkGenerator(G, batch_size=self.batch_size)\n    mapper = generator.flow(G.edges(), edge_labels)\n    assert (generator.batch_size == '???')\n    assert (mapper.data_size == G.number_of_edges())\n    assert (len(mapper.ids) == G.number_of_edges())", "ground_truth": "self.batch_size", "quality_analysis": {"complexity_score": 4, "left_complexity": 2, "right_complexity": 2, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_904", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_Attri2VecLinkGenerator", "funcname": "test_LinkMapper_constructor", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_LinkMapper_constructor(self):\n    G = example_graph(feature_size=self.n_feat)\n    edge_labels = ([0] * G.number_of_edges())\n    generator = Attri2VecLinkGenerator(G, batch_size=self.batch_size)\n    mapper = generator.flow(G.edges(), edge_labels)\n    assert (generator.batch_size == self.batch_size)\n    assert (mapper.data_size == G.number_of_edges())\n    assert (len(mapper.ids) == G.number_of_edges())\n    G = example_graph(feature_size=self.n_feat, is_directed=True)\n    edge_labels = ([0] * G.number_of_edges())\n    generator = Attri2VecLinkGenerator(G, batch_size=self.batch_size)\n    mapper = generator.flow(G.edges(), edge_labels)\n    assert (generator.batch_size == self.batch_size)\n    assert (mapper.data_size == G.number_of_edges())\n    assert (len(mapper.ids) == G.number_of_edges())", "masked_code": "def test_LinkMapper_constructor(self):\n    G = example_graph(feature_size=self.n_feat)\n    edge_labels = ([0] * G.number_of_edges())\n    generator = Attri2VecLinkGenerator(G, batch_size=self.batch_size)\n    mapper = generator.flow(G.edges(), edge_labels)\n    assert (generator.batch_size == self.batch_size)\n    assert (mapper.data_size == G.number_of_edges())\n    assert (len(mapper.ids) == G.number_of_edges())\n    G = example_graph(feature_size=self.n_feat, is_directed=True)\n    edge_labels = ([0] * G.number_of_edges())\n    generator = Attri2VecLinkGenerator(G, batch_size=self.batch_size)\n    mapper = generator.flow(G.edges(), edge_labels)\n    assert (generator.batch_size == self.batch_size)\n    assert (mapper.data_size == '???')\n    assert (len(mapper.ids) == G.number_of_edges())", "ground_truth": "G.number_of_edges()", "quality_analysis": {"complexity_score": 5, "left_complexity": 2, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_905", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_Attri2VecLinkGenerator", "funcname": "test_LinkMapper_constructor", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_LinkMapper_constructor(self):\n    G = example_graph(feature_size=self.n_feat)\n    edge_labels = ([0] * G.number_of_edges())\n    generator = Attri2VecLinkGenerator(G, batch_size=self.batch_size)\n    mapper = generator.flow(G.edges(), edge_labels)\n    assert (generator.batch_size == self.batch_size)\n    assert (mapper.data_size == G.number_of_edges())\n    assert (len(mapper.ids) == G.number_of_edges())\n    G = example_graph(feature_size=self.n_feat, is_directed=True)\n    edge_labels = ([0] * G.number_of_edges())\n    generator = Attri2VecLinkGenerator(G, batch_size=self.batch_size)\n    mapper = generator.flow(G.edges(), edge_labels)\n    assert (generator.batch_size == self.batch_size)\n    assert (mapper.data_size == G.number_of_edges())\n    assert (len(mapper.ids) == G.number_of_edges())", "masked_code": "def test_LinkMapper_constructor(self):\n    G = example_graph(feature_size=self.n_feat)\n    edge_labels = ([0] * G.number_of_edges())\n    generator = Attri2VecLinkGenerator(G, batch_size=self.batch_size)\n    mapper = generator.flow(G.edges(), edge_labels)\n    assert (generator.batch_size == self.batch_size)\n    assert (mapper.data_size == G.number_of_edges())\n    assert (len(mapper.ids) == G.number_of_edges())\n    G = example_graph(feature_size=self.n_feat, is_directed=True)\n    edge_labels = ([0] * G.number_of_edges())\n    generator = Attri2VecLinkGenerator(G, batch_size=self.batch_size)\n    mapper = generator.flow(G.edges(), edge_labels)\n    assert (generator.batch_size == self.batch_size)\n    assert (mapper.data_size == G.number_of_edges())\n    assert (len(mapper.ids) == '???')", "ground_truth": "G.number_of_edges()", "quality_analysis": {"complexity_score": 8, "left_complexity": 5, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_906", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_Attri2VecLinkGenerator", "funcname": "test_Attri2VecLinkGenerator_1", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_Attri2VecLinkGenerator_1(self):\n    G = example_graph(feature_size=self.n_feat)\n    data_size = G.number_of_edges()\n    edge_labels = ([0] * data_size)\n    mapper = Attri2VecLinkGenerator(G, batch_size=self.batch_size).flow(G.edges(), edge_labels)\n    assert (len(mapper) == 2)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        assert (len(nf) == 2)\n        assert (nf[0].shape == (min(self.batch_size, data_size), self.n_feat))\n        assert (nf[1].shape == (min(self.batch_size, data_size),))\n        assert (len(nl) == min(self.batch_size, data_size))\n        assert all((nl == 0))\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper[2]", "masked_code": "def test_Attri2VecLinkGenerator_1(self):\n    G = example_graph(feature_size=self.n_feat)\n    data_size = G.number_of_edges()\n    edge_labels = ([0] * data_size)\n    mapper = Attri2VecLinkGenerator(G, batch_size=self.batch_size).flow(G.edges(), edge_labels)\n    assert (len(mapper) == 2)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        assert (len(nf) == 2)\n        assert (nf[0].shape == '???')\n        assert (nf[1].shape == (min(self.batch_size, data_size),))\n        assert (len(nl) == min(self.batch_size, data_size))\n        assert all((nl == 0))\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper[2]", "ground_truth": "(min(self.batch_size, data_size), self.n_feat)", "quality_analysis": {"complexity_score": 12, "left_complexity": 2, "right_complexity": 10, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_907", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_Attri2VecLinkGenerator", "funcname": "test_Attri2VecLinkGenerator_1", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_Attri2VecLinkGenerator_1(self):\n    G = example_graph(feature_size=self.n_feat)\n    data_size = G.number_of_edges()\n    edge_labels = ([0] * data_size)\n    mapper = Attri2VecLinkGenerator(G, batch_size=self.batch_size).flow(G.edges(), edge_labels)\n    assert (len(mapper) == 2)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        assert (len(nf) == 2)\n        assert (nf[0].shape == (min(self.batch_size, data_size), self.n_feat))\n        assert (nf[1].shape == (min(self.batch_size, data_size),))\n        assert (len(nl) == min(self.batch_size, data_size))\n        assert all((nl == 0))\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper[2]", "masked_code": "def test_Attri2VecLinkGenerator_1(self):\n    G = example_graph(feature_size=self.n_feat)\n    data_size = G.number_of_edges()\n    edge_labels = ([0] * data_size)\n    mapper = Attri2VecLinkGenerator(G, batch_size=self.batch_size).flow(G.edges(), edge_labels)\n    assert (len(mapper) == 2)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        assert (len(nf) == 2)\n        assert (nf[0].shape == (min(self.batch_size, data_size), self.n_feat))\n        assert (nf[1].shape == '???')\n        assert (len(nl) == min(self.batch_size, data_size))\n        assert all((nl == 0))\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper[2]", "ground_truth": "(min(self.batch_size, data_size),)", "quality_analysis": {"complexity_score": 10, "left_complexity": 2, "right_complexity": 8, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_908", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_Attri2VecLinkGenerator", "funcname": "test_Attri2VecLinkGenerator_1", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_Attri2VecLinkGenerator_1(self):\n    G = example_graph(feature_size=self.n_feat)\n    data_size = G.number_of_edges()\n    edge_labels = ([0] * data_size)\n    mapper = Attri2VecLinkGenerator(G, batch_size=self.batch_size).flow(G.edges(), edge_labels)\n    assert (len(mapper) == 2)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        assert (len(nf) == 2)\n        assert (nf[0].shape == (min(self.batch_size, data_size), self.n_feat))\n        assert (nf[1].shape == (min(self.batch_size, data_size),))\n        assert (len(nl) == min(self.batch_size, data_size))\n        assert all((nl == 0))\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper[2]", "masked_code": "def test_Attri2VecLinkGenerator_1(self):\n    G = example_graph(feature_size=self.n_feat)\n    data_size = G.number_of_edges()\n    edge_labels = ([0] * data_size)\n    mapper = Attri2VecLinkGenerator(G, batch_size=self.batch_size).flow(G.edges(), edge_labels)\n    assert (len(mapper) == 2)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        assert (len(nf) == 2)\n        assert (nf[0].shape == (min(self.batch_size, data_size), self.n_feat))\n        assert (nf[1].shape == (min(self.batch_size, data_size),))\n        assert (len(nl) == '???')\n        assert all((nl == 0))\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper[2]", "ground_truth": "min(self.batch_size, data_size)", "quality_analysis": {"complexity_score": 10, "left_complexity": 4, "right_complexity": 6, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_909", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_Attri2VecLinkGenerator", "funcname": "test_edge_consistency", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_edge_consistency(self):\n    G = example_graph(feature_size=1)\n    edges = list(G.edges())\n    edge_labels = list(range(len(edges)))\n    mapper = Attri2VecLinkGenerator(G, batch_size=2).flow(edges, edge_labels)\n    assert (len(mapper) == 2)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        e1 = edges[nl[0]]\n        e2 = edges[nl[1]]\n        assert (nf[0][(0, 0)] == e1[0])\n        assert (nf[1][0] == G.node_ids_to_ilocs([e1[1]])[0])\n        assert (nf[0][(1, 0)] == e2[0])\n        assert (nf[1][1] == G.node_ids_to_ilocs([e2[1]])[0])", "masked_code": "def test_edge_consistency(self):\n    G = example_graph(feature_size=1)\n    edges = list(G.edges())\n    edge_labels = list(range(len(edges)))\n    mapper = Attri2VecLinkGenerator(G, batch_size=2).flow(edges, edge_labels)\n    assert (len(mapper) == 2)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        e1 = edges[nl[0]]\n        e2 = edges[nl[1]]\n        assert (nf[0][(0, 0)] == '???')\n        assert (nf[1][0] == G.node_ids_to_ilocs([e1[1]])[0])\n        assert (nf[0][(1, 0)] == e2[0])\n        assert (nf[1][1] == G.node_ids_to_ilocs([e2[1]])[0])", "ground_truth": "e1[0]", "quality_analysis": {"complexity_score": 17, "left_complexity": 12, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_910", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_Attri2VecLinkGenerator", "funcname": "test_edge_consistency", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_edge_consistency(self):\n    G = example_graph(feature_size=1)\n    edges = list(G.edges())\n    edge_labels = list(range(len(edges)))\n    mapper = Attri2VecLinkGenerator(G, batch_size=2).flow(edges, edge_labels)\n    assert (len(mapper) == 2)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        e1 = edges[nl[0]]\n        e2 = edges[nl[1]]\n        assert (nf[0][(0, 0)] == e1[0])\n        assert (nf[1][0] == G.node_ids_to_ilocs([e1[1]])[0])\n        assert (nf[0][(1, 0)] == e2[0])\n        assert (nf[1][1] == G.node_ids_to_ilocs([e2[1]])[0])", "masked_code": "def test_edge_consistency(self):\n    G = example_graph(feature_size=1)\n    edges = list(G.edges())\n    edge_labels = list(range(len(edges)))\n    mapper = Attri2VecLinkGenerator(G, batch_size=2).flow(edges, edge_labels)\n    assert (len(mapper) == 2)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        e1 = edges[nl[0]]\n        e2 = edges[nl[1]]\n        assert (nf[0][(0, 0)] == e1[0])\n        assert (nf[1][0] == '???')\n        assert (nf[0][(1, 0)] == e2[0])\n        assert (nf[1][1] == G.node_ids_to_ilocs([e2[1]])[0])", "ground_truth": "G.node_ids_to_ilocs([e1[1]])[0]", "quality_analysis": {"complexity_score": 23, "left_complexity": 9, "right_complexity": 14, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_911", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_Attri2VecLinkGenerator", "funcname": "test_edge_consistency", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_edge_consistency(self):\n    G = example_graph(feature_size=1)\n    edges = list(G.edges())\n    edge_labels = list(range(len(edges)))\n    mapper = Attri2VecLinkGenerator(G, batch_size=2).flow(edges, edge_labels)\n    assert (len(mapper) == 2)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        e1 = edges[nl[0]]\n        e2 = edges[nl[1]]\n        assert (nf[0][(0, 0)] == e1[0])\n        assert (nf[1][0] == G.node_ids_to_ilocs([e1[1]])[0])\n        assert (nf[0][(1, 0)] == e2[0])\n        assert (nf[1][1] == G.node_ids_to_ilocs([e2[1]])[0])", "masked_code": "def test_edge_consistency(self):\n    G = example_graph(feature_size=1)\n    edges = list(G.edges())\n    edge_labels = list(range(len(edges)))\n    mapper = Attri2VecLinkGenerator(G, batch_size=2).flow(edges, edge_labels)\n    assert (len(mapper) == 2)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        e1 = edges[nl[0]]\n        e2 = edges[nl[1]]\n        assert (nf[0][(0, 0)] == e1[0])\n        assert (nf[1][0] == G.node_ids_to_ilocs([e1[1]])[0])\n        assert (nf[0][(1, 0)] == '???')\n        assert (nf[1][1] == G.node_ids_to_ilocs([e2[1]])[0])", "ground_truth": "e2[0]", "quality_analysis": {"complexity_score": 17, "left_complexity": 12, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_912", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_Attri2VecLinkGenerator", "funcname": "test_edge_consistency", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_edge_consistency(self):\n    G = example_graph(feature_size=1)\n    edges = list(G.edges())\n    edge_labels = list(range(len(edges)))\n    mapper = Attri2VecLinkGenerator(G, batch_size=2).flow(edges, edge_labels)\n    assert (len(mapper) == 2)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        e1 = edges[nl[0]]\n        e2 = edges[nl[1]]\n        assert (nf[0][(0, 0)] == e1[0])\n        assert (nf[1][0] == G.node_ids_to_ilocs([e1[1]])[0])\n        assert (nf[0][(1, 0)] == e2[0])\n        assert (nf[1][1] == G.node_ids_to_ilocs([e2[1]])[0])", "masked_code": "def test_edge_consistency(self):\n    G = example_graph(feature_size=1)\n    edges = list(G.edges())\n    edge_labels = list(range(len(edges)))\n    mapper = Attri2VecLinkGenerator(G, batch_size=2).flow(edges, edge_labels)\n    assert (len(mapper) == 2)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        e1 = edges[nl[0]]\n        e2 = edges[nl[1]]\n        assert (nf[0][(0, 0)] == e1[0])\n        assert (nf[1][0] == G.node_ids_to_ilocs([e1[1]])[0])\n        assert (nf[0][(1, 0)] == e2[0])\n        assert (nf[1][1] == '???')", "ground_truth": "G.node_ids_to_ilocs([e2[1]])[0]", "quality_analysis": {"complexity_score": 23, "left_complexity": 9, "right_complexity": 14, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_913", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_Attri2VecLinkGenerator", "funcname": "test_Attri2VecLinkGenerator_unsupervisedSampler_sample_generation", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_Attri2VecLinkGenerator_unsupervisedSampler_sample_generation(self):\n    G = example_graph(feature_size=self.n_feat)\n    unsupervisedSamples = UnsupervisedSampler(G)\n    mapper = Attri2VecLinkGenerator(G, batch_size=self.batch_size).flow(unsupervisedSamples)\n    assert (mapper.data_size == (len(list(G.nodes())) * 2))\n    assert (mapper.batch_size == self.batch_size)\n    assert (len(mapper) == np.ceil((mapper.data_size / mapper.batch_size)))\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        assert (len(nf) == 2)\n        assert (nf[0].shape == (min(self.batch_size, mapper.data_size), self.n_feat))\n        assert (nf[1].shape == (min(self.batch_size, mapper.data_size),))\n        assert (len(nl) == min(self.batch_size, mapper.data_size))\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper[8]", "masked_code": "def test_Attri2VecLinkGenerator_unsupervisedSampler_sample_generation(self):\n    G = example_graph(feature_size=self.n_feat)\n    unsupervisedSamples = UnsupervisedSampler(G)\n    mapper = Attri2VecLinkGenerator(G, batch_size=self.batch_size).flow(unsupervisedSamples)\n    assert (mapper.data_size == '???')\n    assert (mapper.batch_size == self.batch_size)\n    assert (len(mapper) == np.ceil((mapper.data_size / mapper.batch_size)))\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        assert (len(nf) == 2)\n        assert (nf[0].shape == (min(self.batch_size, mapper.data_size), self.n_feat))\n        assert (nf[1].shape == (min(self.batch_size, mapper.data_size),))\n        assert (len(nl) == min(self.batch_size, mapper.data_size))\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper[8]", "ground_truth": "(len(list(G.nodes())) * 2)", "quality_analysis": {"complexity_score": 14, "left_complexity": 2, "right_complexity": 12, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_914", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_Attri2VecLinkGenerator", "funcname": "test_Attri2VecLinkGenerator_unsupervisedSampler_sample_generation", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_Attri2VecLinkGenerator_unsupervisedSampler_sample_generation(self):\n    G = example_graph(feature_size=self.n_feat)\n    unsupervisedSamples = UnsupervisedSampler(G)\n    mapper = Attri2VecLinkGenerator(G, batch_size=self.batch_size).flow(unsupervisedSamples)\n    assert (mapper.data_size == (len(list(G.nodes())) * 2))\n    assert (mapper.batch_size == self.batch_size)\n    assert (len(mapper) == np.ceil((mapper.data_size / mapper.batch_size)))\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        assert (len(nf) == 2)\n        assert (nf[0].shape == (min(self.batch_size, mapper.data_size), self.n_feat))\n        assert (nf[1].shape == (min(self.batch_size, mapper.data_size),))\n        assert (len(nl) == min(self.batch_size, mapper.data_size))\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper[8]", "masked_code": "def test_Attri2VecLinkGenerator_unsupervisedSampler_sample_generation(self):\n    G = example_graph(feature_size=self.n_feat)\n    unsupervisedSamples = UnsupervisedSampler(G)\n    mapper = Attri2VecLinkGenerator(G, batch_size=self.batch_size).flow(unsupervisedSamples)\n    assert (mapper.data_size == (len(list(G.nodes())) * 2))\n    assert (mapper.batch_size == '???')\n    assert (len(mapper) == np.ceil((mapper.data_size / mapper.batch_size)))\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        assert (len(nf) == 2)\n        assert (nf[0].shape == (min(self.batch_size, mapper.data_size), self.n_feat))\n        assert (nf[1].shape == (min(self.batch_size, mapper.data_size),))\n        assert (len(nl) == min(self.batch_size, mapper.data_size))\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper[8]", "ground_truth": "self.batch_size", "quality_analysis": {"complexity_score": 4, "left_complexity": 2, "right_complexity": 2, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_915", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_Attri2VecLinkGenerator", "funcname": "test_Attri2VecLinkGenerator_unsupervisedSampler_sample_generation", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_Attri2VecLinkGenerator_unsupervisedSampler_sample_generation(self):\n    G = example_graph(feature_size=self.n_feat)\n    unsupervisedSamples = UnsupervisedSampler(G)\n    mapper = Attri2VecLinkGenerator(G, batch_size=self.batch_size).flow(unsupervisedSamples)\n    assert (mapper.data_size == (len(list(G.nodes())) * 2))\n    assert (mapper.batch_size == self.batch_size)\n    assert (len(mapper) == np.ceil((mapper.data_size / mapper.batch_size)))\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        assert (len(nf) == 2)\n        assert (nf[0].shape == (min(self.batch_size, mapper.data_size), self.n_feat))\n        assert (nf[1].shape == (min(self.batch_size, mapper.data_size),))\n        assert (len(nl) == min(self.batch_size, mapper.data_size))\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper[8]", "masked_code": "def test_Attri2VecLinkGenerator_unsupervisedSampler_sample_generation(self):\n    G = example_graph(feature_size=self.n_feat)\n    unsupervisedSamples = UnsupervisedSampler(G)\n    mapper = Attri2VecLinkGenerator(G, batch_size=self.batch_size).flow(unsupervisedSamples)\n    assert (mapper.data_size == (len(list(G.nodes())) * 2))\n    assert (mapper.batch_size == self.batch_size)\n    assert (len(mapper) == '???')\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        assert (len(nf) == 2)\n        assert (nf[0].shape == (min(self.batch_size, mapper.data_size), self.n_feat))\n        assert (nf[1].shape == (min(self.batch_size, mapper.data_size),))\n        assert (len(nl) == min(self.batch_size, mapper.data_size))\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper[8]", "ground_truth": "np.ceil((mapper.data_size / mapper.batch_size))", "quality_analysis": {"complexity_score": 13, "left_complexity": 4, "right_complexity": 9, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_916", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_Attri2VecLinkGenerator", "funcname": "test_Attri2VecLinkGenerator_unsupervisedSampler_sample_generation", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_Attri2VecLinkGenerator_unsupervisedSampler_sample_generation(self):\n    G = example_graph(feature_size=self.n_feat)\n    unsupervisedSamples = UnsupervisedSampler(G)\n    mapper = Attri2VecLinkGenerator(G, batch_size=self.batch_size).flow(unsupervisedSamples)\n    assert (mapper.data_size == (len(list(G.nodes())) * 2))\n    assert (mapper.batch_size == self.batch_size)\n    assert (len(mapper) == np.ceil((mapper.data_size / mapper.batch_size)))\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        assert (len(nf) == 2)\n        assert (nf[0].shape == (min(self.batch_size, mapper.data_size), self.n_feat))\n        assert (nf[1].shape == (min(self.batch_size, mapper.data_size),))\n        assert (len(nl) == min(self.batch_size, mapper.data_size))\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper[8]", "masked_code": "def test_Attri2VecLinkGenerator_unsupervisedSampler_sample_generation(self):\n    G = example_graph(feature_size=self.n_feat)\n    unsupervisedSamples = UnsupervisedSampler(G)\n    mapper = Attri2VecLinkGenerator(G, batch_size=self.batch_size).flow(unsupervisedSamples)\n    assert (mapper.data_size == (len(list(G.nodes())) * 2))\n    assert (mapper.batch_size == self.batch_size)\n    assert (len(mapper) == np.ceil((mapper.data_size / mapper.batch_size)))\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        assert (len(nf) == 2)\n        assert (nf[0].shape == '???')\n        assert (nf[1].shape == (min(self.batch_size, mapper.data_size),))\n        assert (len(nl) == min(self.batch_size, mapper.data_size))\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper[8]", "ground_truth": "(min(self.batch_size, mapper.data_size), self.n_feat)", "quality_analysis": {"complexity_score": 13, "left_complexity": 2, "right_complexity": 11, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_917", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_Attri2VecLinkGenerator", "funcname": "test_Attri2VecLinkGenerator_unsupervisedSampler_sample_generation", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_Attri2VecLinkGenerator_unsupervisedSampler_sample_generation(self):\n    G = example_graph(feature_size=self.n_feat)\n    unsupervisedSamples = UnsupervisedSampler(G)\n    mapper = Attri2VecLinkGenerator(G, batch_size=self.batch_size).flow(unsupervisedSamples)\n    assert (mapper.data_size == (len(list(G.nodes())) * 2))\n    assert (mapper.batch_size == self.batch_size)\n    assert (len(mapper) == np.ceil((mapper.data_size / mapper.batch_size)))\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        assert (len(nf) == 2)\n        assert (nf[0].shape == (min(self.batch_size, mapper.data_size), self.n_feat))\n        assert (nf[1].shape == (min(self.batch_size, mapper.data_size),))\n        assert (len(nl) == min(self.batch_size, mapper.data_size))\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper[8]", "masked_code": "def test_Attri2VecLinkGenerator_unsupervisedSampler_sample_generation(self):\n    G = example_graph(feature_size=self.n_feat)\n    unsupervisedSamples = UnsupervisedSampler(G)\n    mapper = Attri2VecLinkGenerator(G, batch_size=self.batch_size).flow(unsupervisedSamples)\n    assert (mapper.data_size == (len(list(G.nodes())) * 2))\n    assert (mapper.batch_size == self.batch_size)\n    assert (len(mapper) == np.ceil((mapper.data_size / mapper.batch_size)))\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        assert (len(nf) == 2)\n        assert (nf[0].shape == (min(self.batch_size, mapper.data_size), self.n_feat))\n        assert (nf[1].shape == '???')\n        assert (len(nl) == min(self.batch_size, mapper.data_size))\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper[8]", "ground_truth": "(min(self.batch_size, mapper.data_size),)", "quality_analysis": {"complexity_score": 11, "left_complexity": 2, "right_complexity": 9, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_918", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_Attri2VecLinkGenerator", "funcname": "test_Attri2VecLinkGenerator_unsupervisedSampler_sample_generation", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_Attri2VecLinkGenerator_unsupervisedSampler_sample_generation(self):\n    G = example_graph(feature_size=self.n_feat)\n    unsupervisedSamples = UnsupervisedSampler(G)\n    mapper = Attri2VecLinkGenerator(G, batch_size=self.batch_size).flow(unsupervisedSamples)\n    assert (mapper.data_size == (len(list(G.nodes())) * 2))\n    assert (mapper.batch_size == self.batch_size)\n    assert (len(mapper) == np.ceil((mapper.data_size / mapper.batch_size)))\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        assert (len(nf) == 2)\n        assert (nf[0].shape == (min(self.batch_size, mapper.data_size), self.n_feat))\n        assert (nf[1].shape == (min(self.batch_size, mapper.data_size),))\n        assert (len(nl) == min(self.batch_size, mapper.data_size))\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper[8]", "masked_code": "def test_Attri2VecLinkGenerator_unsupervisedSampler_sample_generation(self):\n    G = example_graph(feature_size=self.n_feat)\n    unsupervisedSamples = UnsupervisedSampler(G)\n    mapper = Attri2VecLinkGenerator(G, batch_size=self.batch_size).flow(unsupervisedSamples)\n    assert (mapper.data_size == (len(list(G.nodes())) * 2))\n    assert (mapper.batch_size == self.batch_size)\n    assert (len(mapper) == np.ceil((mapper.data_size / mapper.batch_size)))\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        assert (len(nf) == 2)\n        assert (nf[0].shape == (min(self.batch_size, mapper.data_size), self.n_feat))\n        assert (nf[1].shape == (min(self.batch_size, mapper.data_size),))\n        assert (len(nl) == '???')\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper[8]", "ground_truth": "min(self.batch_size, mapper.data_size)", "quality_analysis": {"complexity_score": 11, "left_complexity": 4, "right_complexity": 7, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_919", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_Node2VecLinkGenerator", "funcname": "test_LinkMapper_constructor", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_LinkMapper_constructor(self):\n    G = example_graph(self.n_feat)\n    edge_labels = ([0] * G.number_of_edges())\n    generator = Node2VecLinkGenerator(G, batch_size=self.batch_size)\n    mapper = generator.flow(G.edges(), edge_labels)\n    assert (generator.batch_size == self.batch_size)\n    assert (mapper.data_size == G.number_of_edges())\n    assert (len(mapper.ids) == G.number_of_edges())\n    G = example_graph()\n    edge_labels = ([0] * G.number_of_edges())\n    generator = Node2VecLinkGenerator(G, batch_size=self.batch_size)\n    mapper = generator.flow(G.edges(), edge_labels)\n    assert (generator.batch_size == self.batch_size)\n    assert (mapper.data_size == G.number_of_edges())\n    assert (len(mapper.ids) == G.number_of_edges())", "masked_code": "def test_LinkMapper_constructor(self):\n    G = example_graph(self.n_feat)\n    edge_labels = ([0] * G.number_of_edges())\n    generator = Node2VecLinkGenerator(G, batch_size=self.batch_size)\n    mapper = generator.flow(G.edges(), edge_labels)\n    assert (generator.batch_size == '???')\n    assert (mapper.data_size == G.number_of_edges())\n    assert (len(mapper.ids) == G.number_of_edges())\n    G = example_graph()\n    edge_labels = ([0] * G.number_of_edges())\n    generator = Node2VecLinkGenerator(G, batch_size=self.batch_size)\n    mapper = generator.flow(G.edges(), edge_labels)\n    assert (generator.batch_size == self.batch_size)\n    assert (mapper.data_size == G.number_of_edges())\n    assert (len(mapper.ids) == G.number_of_edges())", "ground_truth": "self.batch_size", "quality_analysis": {"complexity_score": 4, "left_complexity": 2, "right_complexity": 2, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_920", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_Node2VecLinkGenerator", "funcname": "test_LinkMapper_constructor", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_LinkMapper_constructor(self):\n    G = example_graph(self.n_feat)\n    edge_labels = ([0] * G.number_of_edges())\n    generator = Node2VecLinkGenerator(G, batch_size=self.batch_size)\n    mapper = generator.flow(G.edges(), edge_labels)\n    assert (generator.batch_size == self.batch_size)\n    assert (mapper.data_size == G.number_of_edges())\n    assert (len(mapper.ids) == G.number_of_edges())\n    G = example_graph()\n    edge_labels = ([0] * G.number_of_edges())\n    generator = Node2VecLinkGenerator(G, batch_size=self.batch_size)\n    mapper = generator.flow(G.edges(), edge_labels)\n    assert (generator.batch_size == self.batch_size)\n    assert (mapper.data_size == G.number_of_edges())\n    assert (len(mapper.ids) == G.number_of_edges())", "masked_code": "def test_LinkMapper_constructor(self):\n    G = example_graph(self.n_feat)\n    edge_labels = ([0] * G.number_of_edges())\n    generator = Node2VecLinkGenerator(G, batch_size=self.batch_size)\n    mapper = generator.flow(G.edges(), edge_labels)\n    assert (generator.batch_size == self.batch_size)\n    assert (mapper.data_size == '???')\n    assert (len(mapper.ids) == G.number_of_edges())\n    G = example_graph()\n    edge_labels = ([0] * G.number_of_edges())\n    generator = Node2VecLinkGenerator(G, batch_size=self.batch_size)\n    mapper = generator.flow(G.edges(), edge_labels)\n    assert (generator.batch_size == self.batch_size)\n    assert (mapper.data_size == G.number_of_edges())\n    assert (len(mapper.ids) == G.number_of_edges())", "ground_truth": "G.number_of_edges()", "quality_analysis": {"complexity_score": 5, "left_complexity": 2, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_921", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_Node2VecLinkGenerator", "funcname": "test_LinkMapper_constructor", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_LinkMapper_constructor(self):\n    G = example_graph(self.n_feat)\n    edge_labels = ([0] * G.number_of_edges())\n    generator = Node2VecLinkGenerator(G, batch_size=self.batch_size)\n    mapper = generator.flow(G.edges(), edge_labels)\n    assert (generator.batch_size == self.batch_size)\n    assert (mapper.data_size == G.number_of_edges())\n    assert (len(mapper.ids) == G.number_of_edges())\n    G = example_graph()\n    edge_labels = ([0] * G.number_of_edges())\n    generator = Node2VecLinkGenerator(G, batch_size=self.batch_size)\n    mapper = generator.flow(G.edges(), edge_labels)\n    assert (generator.batch_size == self.batch_size)\n    assert (mapper.data_size == G.number_of_edges())\n    assert (len(mapper.ids) == G.number_of_edges())", "masked_code": "def test_LinkMapper_constructor(self):\n    G = example_graph(self.n_feat)\n    edge_labels = ([0] * G.number_of_edges())\n    generator = Node2VecLinkGenerator(G, batch_size=self.batch_size)\n    mapper = generator.flow(G.edges(), edge_labels)\n    assert (generator.batch_size == self.batch_size)\n    assert (mapper.data_size == G.number_of_edges())\n    assert (len(mapper.ids) == '???')\n    G = example_graph()\n    edge_labels = ([0] * G.number_of_edges())\n    generator = Node2VecLinkGenerator(G, batch_size=self.batch_size)\n    mapper = generator.flow(G.edges(), edge_labels)\n    assert (generator.batch_size == self.batch_size)\n    assert (mapper.data_size == G.number_of_edges())\n    assert (len(mapper.ids) == G.number_of_edges())", "ground_truth": "G.number_of_edges()", "quality_analysis": {"complexity_score": 8, "left_complexity": 5, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_922", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_Node2VecLinkGenerator", "funcname": "test_LinkMapper_constructor", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_LinkMapper_constructor(self):\n    G = example_graph(self.n_feat)\n    edge_labels = ([0] * G.number_of_edges())\n    generator = Node2VecLinkGenerator(G, batch_size=self.batch_size)\n    mapper = generator.flow(G.edges(), edge_labels)\n    assert (generator.batch_size == self.batch_size)\n    assert (mapper.data_size == G.number_of_edges())\n    assert (len(mapper.ids) == G.number_of_edges())\n    G = example_graph()\n    edge_labels = ([0] * G.number_of_edges())\n    generator = Node2VecLinkGenerator(G, batch_size=self.batch_size)\n    mapper = generator.flow(G.edges(), edge_labels)\n    assert (generator.batch_size == self.batch_size)\n    assert (mapper.data_size == G.number_of_edges())\n    assert (len(mapper.ids) == G.number_of_edges())", "masked_code": "def test_LinkMapper_constructor(self):\n    G = example_graph(self.n_feat)\n    edge_labels = ([0] * G.number_of_edges())\n    generator = Node2VecLinkGenerator(G, batch_size=self.batch_size)\n    mapper = generator.flow(G.edges(), edge_labels)\n    assert (generator.batch_size == self.batch_size)\n    assert (mapper.data_size == G.number_of_edges())\n    assert (len(mapper.ids) == G.number_of_edges())\n    G = example_graph()\n    edge_labels = ([0] * G.number_of_edges())\n    generator = Node2VecLinkGenerator(G, batch_size=self.batch_size)\n    mapper = generator.flow(G.edges(), edge_labels)\n    assert (generator.batch_size == '???')\n    assert (mapper.data_size == G.number_of_edges())\n    assert (len(mapper.ids) == G.number_of_edges())", "ground_truth": "self.batch_size", "quality_analysis": {"complexity_score": 4, "left_complexity": 2, "right_complexity": 2, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_923", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_Node2VecLinkGenerator", "funcname": "test_LinkMapper_constructor", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_LinkMapper_constructor(self):\n    G = example_graph(self.n_feat)\n    edge_labels = ([0] * G.number_of_edges())\n    generator = Node2VecLinkGenerator(G, batch_size=self.batch_size)\n    mapper = generator.flow(G.edges(), edge_labels)\n    assert (generator.batch_size == self.batch_size)\n    assert (mapper.data_size == G.number_of_edges())\n    assert (len(mapper.ids) == G.number_of_edges())\n    G = example_graph()\n    edge_labels = ([0] * G.number_of_edges())\n    generator = Node2VecLinkGenerator(G, batch_size=self.batch_size)\n    mapper = generator.flow(G.edges(), edge_labels)\n    assert (generator.batch_size == self.batch_size)\n    assert (mapper.data_size == G.number_of_edges())\n    assert (len(mapper.ids) == G.number_of_edges())", "masked_code": "def test_LinkMapper_constructor(self):\n    G = example_graph(self.n_feat)\n    edge_labels = ([0] * G.number_of_edges())\n    generator = Node2VecLinkGenerator(G, batch_size=self.batch_size)\n    mapper = generator.flow(G.edges(), edge_labels)\n    assert (generator.batch_size == self.batch_size)\n    assert (mapper.data_size == G.number_of_edges())\n    assert (len(mapper.ids) == G.number_of_edges())\n    G = example_graph()\n    edge_labels = ([0] * G.number_of_edges())\n    generator = Node2VecLinkGenerator(G, batch_size=self.batch_size)\n    mapper = generator.flow(G.edges(), edge_labels)\n    assert (generator.batch_size == self.batch_size)\n    assert (mapper.data_size == '???')\n    assert (len(mapper.ids) == G.number_of_edges())", "ground_truth": "G.number_of_edges()", "quality_analysis": {"complexity_score": 5, "left_complexity": 2, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_924", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_Node2VecLinkGenerator", "funcname": "test_LinkMapper_constructor", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_LinkMapper_constructor(self):\n    G = example_graph(self.n_feat)\n    edge_labels = ([0] * G.number_of_edges())\n    generator = Node2VecLinkGenerator(G, batch_size=self.batch_size)\n    mapper = generator.flow(G.edges(), edge_labels)\n    assert (generator.batch_size == self.batch_size)\n    assert (mapper.data_size == G.number_of_edges())\n    assert (len(mapper.ids) == G.number_of_edges())\n    G = example_graph()\n    edge_labels = ([0] * G.number_of_edges())\n    generator = Node2VecLinkGenerator(G, batch_size=self.batch_size)\n    mapper = generator.flow(G.edges(), edge_labels)\n    assert (generator.batch_size == self.batch_size)\n    assert (mapper.data_size == G.number_of_edges())\n    assert (len(mapper.ids) == G.number_of_edges())", "masked_code": "def test_LinkMapper_constructor(self):\n    G = example_graph(self.n_feat)\n    edge_labels = ([0] * G.number_of_edges())\n    generator = Node2VecLinkGenerator(G, batch_size=self.batch_size)\n    mapper = generator.flow(G.edges(), edge_labels)\n    assert (generator.batch_size == self.batch_size)\n    assert (mapper.data_size == G.number_of_edges())\n    assert (len(mapper.ids) == G.number_of_edges())\n    G = example_graph()\n    edge_labels = ([0] * G.number_of_edges())\n    generator = Node2VecLinkGenerator(G, batch_size=self.batch_size)\n    mapper = generator.flow(G.edges(), edge_labels)\n    assert (generator.batch_size == self.batch_size)\n    assert (mapper.data_size == G.number_of_edges())\n    assert (len(mapper.ids) == '???')", "ground_truth": "G.number_of_edges()", "quality_analysis": {"complexity_score": 8, "left_complexity": 5, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_925", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_Node2VecLinkGenerator", "funcname": "test_Node2VecLinkGenerator_1", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_Node2VecLinkGenerator_1(self):\n    G = example_graph()\n    data_size = G.number_of_edges()\n    edge_labels = ([0] * data_size)\n    mapper = Node2VecLinkGenerator(G, batch_size=self.batch_size).flow(G.edges(), edge_labels)\n    assert (len(mapper) == 2)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        assert (len(nf) == 2)\n        assert (nf[0].shape == (min(self.batch_size, data_size),))\n        assert (nf[1].shape == (min(self.batch_size, data_size),))\n        assert (len(nl) == min(self.batch_size, data_size))\n        assert all((nl == 0))\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper[2]", "masked_code": "def test_Node2VecLinkGenerator_1(self):\n    G = example_graph()\n    data_size = G.number_of_edges()\n    edge_labels = ([0] * data_size)\n    mapper = Node2VecLinkGenerator(G, batch_size=self.batch_size).flow(G.edges(), edge_labels)\n    assert (len(mapper) == 2)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        assert (len(nf) == 2)\n        assert (nf[0].shape == '???')\n        assert (nf[1].shape == (min(self.batch_size, data_size),))\n        assert (len(nl) == min(self.batch_size, data_size))\n        assert all((nl == 0))\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper[2]", "ground_truth": "(min(self.batch_size, data_size),)", "quality_analysis": {"complexity_score": 10, "left_complexity": 2, "right_complexity": 8, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_926", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_Node2VecLinkGenerator", "funcname": "test_Node2VecLinkGenerator_1", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_Node2VecLinkGenerator_1(self):\n    G = example_graph()\n    data_size = G.number_of_edges()\n    edge_labels = ([0] * data_size)\n    mapper = Node2VecLinkGenerator(G, batch_size=self.batch_size).flow(G.edges(), edge_labels)\n    assert (len(mapper) == 2)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        assert (len(nf) == 2)\n        assert (nf[0].shape == (min(self.batch_size, data_size),))\n        assert (nf[1].shape == (min(self.batch_size, data_size),))\n        assert (len(nl) == min(self.batch_size, data_size))\n        assert all((nl == 0))\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper[2]", "masked_code": "def test_Node2VecLinkGenerator_1(self):\n    G = example_graph()\n    data_size = G.number_of_edges()\n    edge_labels = ([0] * data_size)\n    mapper = Node2VecLinkGenerator(G, batch_size=self.batch_size).flow(G.edges(), edge_labels)\n    assert (len(mapper) == 2)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        assert (len(nf) == 2)\n        assert (nf[0].shape == (min(self.batch_size, data_size),))\n        assert (nf[1].shape == '???')\n        assert (len(nl) == min(self.batch_size, data_size))\n        assert all((nl == 0))\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper[2]", "ground_truth": "(min(self.batch_size, data_size),)", "quality_analysis": {"complexity_score": 10, "left_complexity": 2, "right_complexity": 8, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_927", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_Node2VecLinkGenerator", "funcname": "test_Node2VecLinkGenerator_1", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_Node2VecLinkGenerator_1(self):\n    G = example_graph()\n    data_size = G.number_of_edges()\n    edge_labels = ([0] * data_size)\n    mapper = Node2VecLinkGenerator(G, batch_size=self.batch_size).flow(G.edges(), edge_labels)\n    assert (len(mapper) == 2)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        assert (len(nf) == 2)\n        assert (nf[0].shape == (min(self.batch_size, data_size),))\n        assert (nf[1].shape == (min(self.batch_size, data_size),))\n        assert (len(nl) == min(self.batch_size, data_size))\n        assert all((nl == 0))\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper[2]", "masked_code": "def test_Node2VecLinkGenerator_1(self):\n    G = example_graph()\n    data_size = G.number_of_edges()\n    edge_labels = ([0] * data_size)\n    mapper = Node2VecLinkGenerator(G, batch_size=self.batch_size).flow(G.edges(), edge_labels)\n    assert (len(mapper) == 2)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        assert (len(nf) == 2)\n        assert (nf[0].shape == (min(self.batch_size, data_size),))\n        assert (nf[1].shape == (min(self.batch_size, data_size),))\n        assert (len(nl) == '???')\n        assert all((nl == 0))\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper[2]", "ground_truth": "min(self.batch_size, data_size)", "quality_analysis": {"complexity_score": 10, "left_complexity": 4, "right_complexity": 6, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_928", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_Node2VecLinkGenerator", "funcname": "test_edge_consistency", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_edge_consistency(self):\n    G = example_graph(1)\n    edges = list(G.edges())\n    edge_labels = list(range(len(edges)))\n    mapper = Node2VecLinkGenerator(G, batch_size=2).flow(edges, edge_labels)\n    assert (len(mapper) == 2)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        e1 = edges[nl[0]]\n        e2 = edges[nl[1]]\n        assert (nf[0][0] == G.node_ids_to_ilocs([e1[0]])[0])\n        assert (nf[1][0] == G.node_ids_to_ilocs([e1[1]])[0])\n        assert (nf[0][1] == G.node_ids_to_ilocs([e2[0]])[0])\n        assert (nf[1][1] == G.node_ids_to_ilocs([e2[1]])[0])", "masked_code": "def test_edge_consistency(self):\n    G = example_graph(1)\n    edges = list(G.edges())\n    edge_labels = list(range(len(edges)))\n    mapper = Node2VecLinkGenerator(G, batch_size=2).flow(edges, edge_labels)\n    assert (len(mapper) == 2)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        e1 = edges[nl[0]]\n        e2 = edges[nl[1]]\n        assert (nf[0][0] == '???')\n        assert (nf[1][0] == G.node_ids_to_ilocs([e1[1]])[0])\n        assert (nf[0][1] == G.node_ids_to_ilocs([e2[0]])[0])\n        assert (nf[1][1] == G.node_ids_to_ilocs([e2[1]])[0])", "ground_truth": "G.node_ids_to_ilocs([e1[0]])[0]", "quality_analysis": {"complexity_score": 23, "left_complexity": 9, "right_complexity": 14, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_929", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_Node2VecLinkGenerator", "funcname": "test_edge_consistency", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_edge_consistency(self):\n    G = example_graph(1)\n    edges = list(G.edges())\n    edge_labels = list(range(len(edges)))\n    mapper = Node2VecLinkGenerator(G, batch_size=2).flow(edges, edge_labels)\n    assert (len(mapper) == 2)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        e1 = edges[nl[0]]\n        e2 = edges[nl[1]]\n        assert (nf[0][0] == G.node_ids_to_ilocs([e1[0]])[0])\n        assert (nf[1][0] == G.node_ids_to_ilocs([e1[1]])[0])\n        assert (nf[0][1] == G.node_ids_to_ilocs([e2[0]])[0])\n        assert (nf[1][1] == G.node_ids_to_ilocs([e2[1]])[0])", "masked_code": "def test_edge_consistency(self):\n    G = example_graph(1)\n    edges = list(G.edges())\n    edge_labels = list(range(len(edges)))\n    mapper = Node2VecLinkGenerator(G, batch_size=2).flow(edges, edge_labels)\n    assert (len(mapper) == 2)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        e1 = edges[nl[0]]\n        e2 = edges[nl[1]]\n        assert (nf[0][0] == G.node_ids_to_ilocs([e1[0]])[0])\n        assert (nf[1][0] == '???')\n        assert (nf[0][1] == G.node_ids_to_ilocs([e2[0]])[0])\n        assert (nf[1][1] == G.node_ids_to_ilocs([e2[1]])[0])", "ground_truth": "G.node_ids_to_ilocs([e1[1]])[0]", "quality_analysis": {"complexity_score": 23, "left_complexity": 9, "right_complexity": 14, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_930", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_Node2VecLinkGenerator", "funcname": "test_edge_consistency", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_edge_consistency(self):\n    G = example_graph(1)\n    edges = list(G.edges())\n    edge_labels = list(range(len(edges)))\n    mapper = Node2VecLinkGenerator(G, batch_size=2).flow(edges, edge_labels)\n    assert (len(mapper) == 2)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        e1 = edges[nl[0]]\n        e2 = edges[nl[1]]\n        assert (nf[0][0] == G.node_ids_to_ilocs([e1[0]])[0])\n        assert (nf[1][0] == G.node_ids_to_ilocs([e1[1]])[0])\n        assert (nf[0][1] == G.node_ids_to_ilocs([e2[0]])[0])\n        assert (nf[1][1] == G.node_ids_to_ilocs([e2[1]])[0])", "masked_code": "def test_edge_consistency(self):\n    G = example_graph(1)\n    edges = list(G.edges())\n    edge_labels = list(range(len(edges)))\n    mapper = Node2VecLinkGenerator(G, batch_size=2).flow(edges, edge_labels)\n    assert (len(mapper) == 2)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        e1 = edges[nl[0]]\n        e2 = edges[nl[1]]\n        assert (nf[0][0] == G.node_ids_to_ilocs([e1[0]])[0])\n        assert (nf[1][0] == G.node_ids_to_ilocs([e1[1]])[0])\n        assert (nf[0][1] == '???')\n        assert (nf[1][1] == G.node_ids_to_ilocs([e2[1]])[0])", "ground_truth": "G.node_ids_to_ilocs([e2[0]])[0]", "quality_analysis": {"complexity_score": 23, "left_complexity": 9, "right_complexity": 14, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_931", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_Node2VecLinkGenerator", "funcname": "test_edge_consistency", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_edge_consistency(self):\n    G = example_graph(1)\n    edges = list(G.edges())\n    edge_labels = list(range(len(edges)))\n    mapper = Node2VecLinkGenerator(G, batch_size=2).flow(edges, edge_labels)\n    assert (len(mapper) == 2)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        e1 = edges[nl[0]]\n        e2 = edges[nl[1]]\n        assert (nf[0][0] == G.node_ids_to_ilocs([e1[0]])[0])\n        assert (nf[1][0] == G.node_ids_to_ilocs([e1[1]])[0])\n        assert (nf[0][1] == G.node_ids_to_ilocs([e2[0]])[0])\n        assert (nf[1][1] == G.node_ids_to_ilocs([e2[1]])[0])", "masked_code": "def test_edge_consistency(self):\n    G = example_graph(1)\n    edges = list(G.edges())\n    edge_labels = list(range(len(edges)))\n    mapper = Node2VecLinkGenerator(G, batch_size=2).flow(edges, edge_labels)\n    assert (len(mapper) == 2)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        e1 = edges[nl[0]]\n        e2 = edges[nl[1]]\n        assert (nf[0][0] == G.node_ids_to_ilocs([e1[0]])[0])\n        assert (nf[1][0] == G.node_ids_to_ilocs([e1[1]])[0])\n        assert (nf[0][1] == G.node_ids_to_ilocs([e2[0]])[0])\n        assert (nf[1][1] == '???')", "ground_truth": "G.node_ids_to_ilocs([e2[1]])[0]", "quality_analysis": {"complexity_score": 23, "left_complexity": 9, "right_complexity": 14, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_932", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_Node2VecLinkGenerator", "funcname": "test_Node2VecLinkGenerator_unsupervisedSampler_sample_generation", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_Node2VecLinkGenerator_unsupervisedSampler_sample_generation(self):\n    G = example_graph()\n    unsupervisedSamples = UnsupervisedSampler(G)\n    mapper = Node2VecLinkGenerator(G, batch_size=self.batch_size).flow(unsupervisedSamples)\n    assert (mapper.data_size == (len(list(G.nodes())) * 2))\n    assert (mapper.batch_size == self.batch_size)\n    assert (len(mapper) == np.ceil((mapper.data_size / mapper.batch_size)))\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        assert (len(nf) == 2)\n        assert (nf[0].shape == (min(self.batch_size, mapper.data_size),))\n        assert (nf[1].shape == (min(self.batch_size, mapper.data_size),))\n        assert (len(nl) == min(self.batch_size, mapper.data_size))\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper[len(mapper)]", "masked_code": "def test_Node2VecLinkGenerator_unsupervisedSampler_sample_generation(self):\n    G = example_graph()\n    unsupervisedSamples = UnsupervisedSampler(G)\n    mapper = Node2VecLinkGenerator(G, batch_size=self.batch_size).flow(unsupervisedSamples)\n    assert (mapper.data_size == '???')\n    assert (mapper.batch_size == self.batch_size)\n    assert (len(mapper) == np.ceil((mapper.data_size / mapper.batch_size)))\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        assert (len(nf) == 2)\n        assert (nf[0].shape == (min(self.batch_size, mapper.data_size),))\n        assert (nf[1].shape == (min(self.batch_size, mapper.data_size),))\n        assert (len(nl) == min(self.batch_size, mapper.data_size))\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper[len(mapper)]", "ground_truth": "(len(list(G.nodes())) * 2)", "quality_analysis": {"complexity_score": 14, "left_complexity": 2, "right_complexity": 12, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_933", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_Node2VecLinkGenerator", "funcname": "test_Node2VecLinkGenerator_unsupervisedSampler_sample_generation", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_Node2VecLinkGenerator_unsupervisedSampler_sample_generation(self):\n    G = example_graph()\n    unsupervisedSamples = UnsupervisedSampler(G)\n    mapper = Node2VecLinkGenerator(G, batch_size=self.batch_size).flow(unsupervisedSamples)\n    assert (mapper.data_size == (len(list(G.nodes())) * 2))\n    assert (mapper.batch_size == self.batch_size)\n    assert (len(mapper) == np.ceil((mapper.data_size / mapper.batch_size)))\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        assert (len(nf) == 2)\n        assert (nf[0].shape == (min(self.batch_size, mapper.data_size),))\n        assert (nf[1].shape == (min(self.batch_size, mapper.data_size),))\n        assert (len(nl) == min(self.batch_size, mapper.data_size))\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper[len(mapper)]", "masked_code": "def test_Node2VecLinkGenerator_unsupervisedSampler_sample_generation(self):\n    G = example_graph()\n    unsupervisedSamples = UnsupervisedSampler(G)\n    mapper = Node2VecLinkGenerator(G, batch_size=self.batch_size).flow(unsupervisedSamples)\n    assert (mapper.data_size == (len(list(G.nodes())) * 2))\n    assert (mapper.batch_size == '???')\n    assert (len(mapper) == np.ceil((mapper.data_size / mapper.batch_size)))\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        assert (len(nf) == 2)\n        assert (nf[0].shape == (min(self.batch_size, mapper.data_size),))\n        assert (nf[1].shape == (min(self.batch_size, mapper.data_size),))\n        assert (len(nl) == min(self.batch_size, mapper.data_size))\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper[len(mapper)]", "ground_truth": "self.batch_size", "quality_analysis": {"complexity_score": 4, "left_complexity": 2, "right_complexity": 2, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_934", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_Node2VecLinkGenerator", "funcname": "test_Node2VecLinkGenerator_unsupervisedSampler_sample_generation", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_Node2VecLinkGenerator_unsupervisedSampler_sample_generation(self):\n    G = example_graph()\n    unsupervisedSamples = UnsupervisedSampler(G)\n    mapper = Node2VecLinkGenerator(G, batch_size=self.batch_size).flow(unsupervisedSamples)\n    assert (mapper.data_size == (len(list(G.nodes())) * 2))\n    assert (mapper.batch_size == self.batch_size)\n    assert (len(mapper) == np.ceil((mapper.data_size / mapper.batch_size)))\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        assert (len(nf) == 2)\n        assert (nf[0].shape == (min(self.batch_size, mapper.data_size),))\n        assert (nf[1].shape == (min(self.batch_size, mapper.data_size),))\n        assert (len(nl) == min(self.batch_size, mapper.data_size))\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper[len(mapper)]", "masked_code": "def test_Node2VecLinkGenerator_unsupervisedSampler_sample_generation(self):\n    G = example_graph()\n    unsupervisedSamples = UnsupervisedSampler(G)\n    mapper = Node2VecLinkGenerator(G, batch_size=self.batch_size).flow(unsupervisedSamples)\n    assert (mapper.data_size == (len(list(G.nodes())) * 2))\n    assert (mapper.batch_size == self.batch_size)\n    assert (len(mapper) == '???')\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        assert (len(nf) == 2)\n        assert (nf[0].shape == (min(self.batch_size, mapper.data_size),))\n        assert (nf[1].shape == (min(self.batch_size, mapper.data_size),))\n        assert (len(nl) == min(self.batch_size, mapper.data_size))\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper[len(mapper)]", "ground_truth": "np.ceil((mapper.data_size / mapper.batch_size))", "quality_analysis": {"complexity_score": 13, "left_complexity": 4, "right_complexity": 9, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_935", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_Node2VecLinkGenerator", "funcname": "test_Node2VecLinkGenerator_unsupervisedSampler_sample_generation", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_Node2VecLinkGenerator_unsupervisedSampler_sample_generation(self):\n    G = example_graph()\n    unsupervisedSamples = UnsupervisedSampler(G)\n    mapper = Node2VecLinkGenerator(G, batch_size=self.batch_size).flow(unsupervisedSamples)\n    assert (mapper.data_size == (len(list(G.nodes())) * 2))\n    assert (mapper.batch_size == self.batch_size)\n    assert (len(mapper) == np.ceil((mapper.data_size / mapper.batch_size)))\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        assert (len(nf) == 2)\n        assert (nf[0].shape == (min(self.batch_size, mapper.data_size),))\n        assert (nf[1].shape == (min(self.batch_size, mapper.data_size),))\n        assert (len(nl) == min(self.batch_size, mapper.data_size))\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper[len(mapper)]", "masked_code": "def test_Node2VecLinkGenerator_unsupervisedSampler_sample_generation(self):\n    G = example_graph()\n    unsupervisedSamples = UnsupervisedSampler(G)\n    mapper = Node2VecLinkGenerator(G, batch_size=self.batch_size).flow(unsupervisedSamples)\n    assert (mapper.data_size == (len(list(G.nodes())) * 2))\n    assert (mapper.batch_size == self.batch_size)\n    assert (len(mapper) == np.ceil((mapper.data_size / mapper.batch_size)))\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        assert (len(nf) == 2)\n        assert (nf[0].shape == '???')\n        assert (nf[1].shape == (min(self.batch_size, mapper.data_size),))\n        assert (len(nl) == min(self.batch_size, mapper.data_size))\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper[len(mapper)]", "ground_truth": "(min(self.batch_size, mapper.data_size),)", "quality_analysis": {"complexity_score": 11, "left_complexity": 2, "right_complexity": 9, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_936", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_Node2VecLinkGenerator", "funcname": "test_Node2VecLinkGenerator_unsupervisedSampler_sample_generation", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_Node2VecLinkGenerator_unsupervisedSampler_sample_generation(self):\n    G = example_graph()\n    unsupervisedSamples = UnsupervisedSampler(G)\n    mapper = Node2VecLinkGenerator(G, batch_size=self.batch_size).flow(unsupervisedSamples)\n    assert (mapper.data_size == (len(list(G.nodes())) * 2))\n    assert (mapper.batch_size == self.batch_size)\n    assert (len(mapper) == np.ceil((mapper.data_size / mapper.batch_size)))\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        assert (len(nf) == 2)\n        assert (nf[0].shape == (min(self.batch_size, mapper.data_size),))\n        assert (nf[1].shape == (min(self.batch_size, mapper.data_size),))\n        assert (len(nl) == min(self.batch_size, mapper.data_size))\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper[len(mapper)]", "masked_code": "def test_Node2VecLinkGenerator_unsupervisedSampler_sample_generation(self):\n    G = example_graph()\n    unsupervisedSamples = UnsupervisedSampler(G)\n    mapper = Node2VecLinkGenerator(G, batch_size=self.batch_size).flow(unsupervisedSamples)\n    assert (mapper.data_size == (len(list(G.nodes())) * 2))\n    assert (mapper.batch_size == self.batch_size)\n    assert (len(mapper) == np.ceil((mapper.data_size / mapper.batch_size)))\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        assert (len(nf) == 2)\n        assert (nf[0].shape == (min(self.batch_size, mapper.data_size),))\n        assert (nf[1].shape == '???')\n        assert (len(nl) == min(self.batch_size, mapper.data_size))\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper[len(mapper)]", "ground_truth": "(min(self.batch_size, mapper.data_size),)", "quality_analysis": {"complexity_score": 11, "left_complexity": 2, "right_complexity": 9, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_937", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_Node2VecLinkGenerator", "funcname": "test_Node2VecLinkGenerator_unsupervisedSampler_sample_generation", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_Node2VecLinkGenerator_unsupervisedSampler_sample_generation(self):\n    G = example_graph()\n    unsupervisedSamples = UnsupervisedSampler(G)\n    mapper = Node2VecLinkGenerator(G, batch_size=self.batch_size).flow(unsupervisedSamples)\n    assert (mapper.data_size == (len(list(G.nodes())) * 2))\n    assert (mapper.batch_size == self.batch_size)\n    assert (len(mapper) == np.ceil((mapper.data_size / mapper.batch_size)))\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        assert (len(nf) == 2)\n        assert (nf[0].shape == (min(self.batch_size, mapper.data_size),))\n        assert (nf[1].shape == (min(self.batch_size, mapper.data_size),))\n        assert (len(nl) == min(self.batch_size, mapper.data_size))\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper[len(mapper)]", "masked_code": "def test_Node2VecLinkGenerator_unsupervisedSampler_sample_generation(self):\n    G = example_graph()\n    unsupervisedSamples = UnsupervisedSampler(G)\n    mapper = Node2VecLinkGenerator(G, batch_size=self.batch_size).flow(unsupervisedSamples)\n    assert (mapper.data_size == (len(list(G.nodes())) * 2))\n    assert (mapper.batch_size == self.batch_size)\n    assert (len(mapper) == np.ceil((mapper.data_size / mapper.batch_size)))\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        assert (len(nf) == 2)\n        assert (nf[0].shape == (min(self.batch_size, mapper.data_size),))\n        assert (nf[1].shape == (min(self.batch_size, mapper.data_size),))\n        assert (len(nl) == '???')\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper[len(mapper)]", "ground_truth": "min(self.batch_size, mapper.data_size)", "quality_analysis": {"complexity_score": 11, "left_complexity": 4, "right_complexity": 7, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_938", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_DirectedGraphSAGELinkGenerator", "funcname": "test_constructor", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_constructor(self):\n    G = example_graph(feature_size=self.n_feat, is_directed=True)\n    edge_labels = ([0] * G.number_of_edges())\n    generator = DirectedGraphSAGELinkGenerator(G, batch_size=self.batch_size, in_samples=self.in_samples, out_samples=self.out_samples)\n    mapper = generator.flow(G.edges(), edge_labels)\n    assert (generator.batch_size == self.batch_size)\n    assert (mapper.data_size == G.number_of_edges())\n    assert (len(mapper.ids) == G.number_of_edges())", "masked_code": "def test_constructor(self):\n    G = example_graph(feature_size=self.n_feat, is_directed=True)\n    edge_labels = ([0] * G.number_of_edges())\n    generator = DirectedGraphSAGELinkGenerator(G, batch_size=self.batch_size, in_samples=self.in_samples, out_samples=self.out_samples)\n    mapper = generator.flow(G.edges(), edge_labels)\n    assert (generator.batch_size == '???')\n    assert (mapper.data_size == G.number_of_edges())\n    assert (len(mapper.ids) == G.number_of_edges())", "ground_truth": "self.batch_size", "quality_analysis": {"complexity_score": 4, "left_complexity": 2, "right_complexity": 2, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_939", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_DirectedGraphSAGELinkGenerator", "funcname": "test_constructor", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_constructor(self):\n    G = example_graph(feature_size=self.n_feat, is_directed=True)\n    edge_labels = ([0] * G.number_of_edges())\n    generator = DirectedGraphSAGELinkGenerator(G, batch_size=self.batch_size, in_samples=self.in_samples, out_samples=self.out_samples)\n    mapper = generator.flow(G.edges(), edge_labels)\n    assert (generator.batch_size == self.batch_size)\n    assert (mapper.data_size == G.number_of_edges())\n    assert (len(mapper.ids) == G.number_of_edges())", "masked_code": "def test_constructor(self):\n    G = example_graph(feature_size=self.n_feat, is_directed=True)\n    edge_labels = ([0] * G.number_of_edges())\n    generator = DirectedGraphSAGELinkGenerator(G, batch_size=self.batch_size, in_samples=self.in_samples, out_samples=self.out_samples)\n    mapper = generator.flow(G.edges(), edge_labels)\n    assert (generator.batch_size == self.batch_size)\n    assert (mapper.data_size == '???')\n    assert (len(mapper.ids) == G.number_of_edges())", "ground_truth": "G.number_of_edges()", "quality_analysis": {"complexity_score": 5, "left_complexity": 2, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_940", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_DirectedGraphSAGELinkGenerator", "funcname": "test_constructor", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_constructor(self):\n    G = example_graph(feature_size=self.n_feat, is_directed=True)\n    edge_labels = ([0] * G.number_of_edges())\n    generator = DirectedGraphSAGELinkGenerator(G, batch_size=self.batch_size, in_samples=self.in_samples, out_samples=self.out_samples)\n    mapper = generator.flow(G.edges(), edge_labels)\n    assert (generator.batch_size == self.batch_size)\n    assert (mapper.data_size == G.number_of_edges())\n    assert (len(mapper.ids) == G.number_of_edges())", "masked_code": "def test_constructor(self):\n    G = example_graph(feature_size=self.n_feat, is_directed=True)\n    edge_labels = ([0] * G.number_of_edges())\n    generator = DirectedGraphSAGELinkGenerator(G, batch_size=self.batch_size, in_samples=self.in_samples, out_samples=self.out_samples)\n    mapper = generator.flow(G.edges(), edge_labels)\n    assert (generator.batch_size == self.batch_size)\n    assert (mapper.data_size == G.number_of_edges())\n    assert (len(mapper.ids) == '???')", "ground_truth": "G.number_of_edges()", "quality_analysis": {"complexity_score": 8, "left_complexity": 5, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_941", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_DirectedGraphSAGELinkGenerator", "funcname": "test_batch_feature_shapes", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_batch_feature_shapes(self):\n    G = example_graph(feature_size=self.n_feat, is_directed=True)\n    data_size = G.number_of_edges()\n    edge_labels = ([0] * data_size)\n    mapper = DirectedGraphSAGELinkGenerator(G, batch_size=self.batch_size, in_samples=self.in_samples, out_samples=self.out_samples).flow(G.edges(), edge_labels)\n    assert (len(mapper) == 2)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        assert (len(nf) == ((2 ** (len(self.in_samples) + 2)) - 2))\n        (ins, outs) = (self.in_samples, self.out_samples)\n        dims = [1, ins[0], outs[0], (ins[0] * ins[1]), (ins[0] * outs[1]), (outs[0] * ins[1]), (outs[0] * outs[1])]\n        for (ii, dim) in zip(range(7), dims):\n            assert (nf[(2 * ii)].shape == nf[((2 * ii) + 1)].shape == (min(self.batch_size, data_size), dim, self.n_feat))\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper[2]", "masked_code": "def test_batch_feature_shapes(self):\n    G = example_graph(feature_size=self.n_feat, is_directed=True)\n    data_size = G.number_of_edges()\n    edge_labels = ([0] * data_size)\n    mapper = DirectedGraphSAGELinkGenerator(G, batch_size=self.batch_size, in_samples=self.in_samples, out_samples=self.out_samples).flow(G.edges(), edge_labels)\n    assert (len(mapper) == 2)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        assert (len(nf) == '???')\n        (ins, outs) = (self.in_samples, self.out_samples)\n        dims = [1, ins[0], outs[0], (ins[0] * ins[1]), (ins[0] * outs[1]), (outs[0] * ins[1]), (outs[0] * outs[1])]\n        for (ii, dim) in zip(range(7), dims):\n            assert (nf[(2 * ii)].shape == nf[((2 * ii) + 1)].shape == (min(self.batch_size, data_size), dim, self.n_feat))\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper[2]", "ground_truth": "((2 ** (len(self.in_samples) + 2)) - 2)", "quality_analysis": {"complexity_score": 18, "left_complexity": 4, "right_complexity": 14, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_942", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_DirectedGraphSAGELinkGenerator", "funcname": "test_batch_feature_shapes", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_batch_feature_shapes(self):\n    G = example_graph(feature_size=self.n_feat, is_directed=True)\n    data_size = G.number_of_edges()\n    edge_labels = ([0] * data_size)\n    mapper = DirectedGraphSAGELinkGenerator(G, batch_size=self.batch_size, in_samples=self.in_samples, out_samples=self.out_samples).flow(G.edges(), edge_labels)\n    assert (len(mapper) == 2)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        assert (len(nf) == ((2 ** (len(self.in_samples) + 2)) - 2))\n        (ins, outs) = (self.in_samples, self.out_samples)\n        dims = [1, ins[0], outs[0], (ins[0] * ins[1]), (ins[0] * outs[1]), (outs[0] * ins[1]), (outs[0] * outs[1])]\n        for (ii, dim) in zip(range(7), dims):\n            assert (nf[(2 * ii)].shape == nf[((2 * ii) + 1)].shape == (min(self.batch_size, data_size), dim, self.n_feat))\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper[2]", "masked_code": "def test_batch_feature_shapes(self):\n    G = example_graph(feature_size=self.n_feat, is_directed=True)\n    data_size = G.number_of_edges()\n    edge_labels = ([0] * data_size)\n    mapper = DirectedGraphSAGELinkGenerator(G, batch_size=self.batch_size, in_samples=self.in_samples, out_samples=self.out_samples).flow(G.edges(), edge_labels)\n    assert (len(mapper) == 2)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        assert (len(nf) == ((2 ** (len(self.in_samples) + 2)) - 2))\n        (ins, outs) = (self.in_samples, self.out_samples)\n        dims = [1, ins[0], outs[0], (ins[0] * ins[1]), (ins[0] * outs[1]), (outs[0] * ins[1]), (outs[0] * outs[1])]\n        for (ii, dim) in zip(range(7), dims):\n            assert (nf[(2 * ii)].shape == '???' == (min(self.batch_size, data_size), dim, self.n_feat))\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper[2]", "ground_truth": "nf[((2 * ii) + 1)].shape", "quality_analysis": {"complexity_score": 4, "left_complexity": 2, "right_complexity": 2, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_943", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_DirectedGraphSAGELinkGenerator", "funcname": "test_shuffle", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "@pytest.mark.parametrize('shuffle', [True, False])\ndef test_shuffle(self, shuffle):\n    G = example_graph(feature_size=1, is_directed=True)\n    edges = list(G.edges())\n    edge_labels = list(range(len(edges)))\n    mapper = DirectedGraphSAGELinkGenerator(G, batch_size=2, in_samples=[0], out_samples=[0]).flow(edges, edge_labels, shuffle=shuffle)\n    assert (len(mapper) == 2)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        e1 = edges[nl[0]]\n        e2 = edges[nl[1]]\n        assert (nf[0][(0, 0, 0)] == e1[0])\n        assert (nf[1][(0, 0, 0)] == e1[1])\n        assert (nf[0][(1, 0, 0)] == e2[0])\n        assert (nf[1][(1, 0, 0)] == e2[1])", "masked_code": "@pytest.mark.parametrize('shuffle', [True, False])\ndef test_shuffle(self, shuffle):\n    G = example_graph(feature_size=1, is_directed=True)\n    edges = list(G.edges())\n    edge_labels = list(range(len(edges)))\n    mapper = DirectedGraphSAGELinkGenerator(G, batch_size=2, in_samples=[0], out_samples=[0]).flow(edges, edge_labels, shuffle=shuffle)\n    assert (len(mapper) == 2)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        e1 = edges[nl[0]]\n        e2 = edges[nl[1]]\n        assert (nf[0][(0, 0, 0)] == '???')\n        assert (nf[1][(0, 0, 0)] == e1[1])\n        assert (nf[0][(1, 0, 0)] == e2[0])\n        assert (nf[1][(1, 0, 0)] == e2[1])", "ground_truth": "e1[0]", "quality_analysis": {"complexity_score": 18, "left_complexity": 13, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_944", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_DirectedGraphSAGELinkGenerator", "funcname": "test_shuffle", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "@pytest.mark.parametrize('shuffle', [True, False])\ndef test_shuffle(self, shuffle):\n    G = example_graph(feature_size=1, is_directed=True)\n    edges = list(G.edges())\n    edge_labels = list(range(len(edges)))\n    mapper = DirectedGraphSAGELinkGenerator(G, batch_size=2, in_samples=[0], out_samples=[0]).flow(edges, edge_labels, shuffle=shuffle)\n    assert (len(mapper) == 2)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        e1 = edges[nl[0]]\n        e2 = edges[nl[1]]\n        assert (nf[0][(0, 0, 0)] == e1[0])\n        assert (nf[1][(0, 0, 0)] == e1[1])\n        assert (nf[0][(1, 0, 0)] == e2[0])\n        assert (nf[1][(1, 0, 0)] == e2[1])", "masked_code": "@pytest.mark.parametrize('shuffle', [True, False])\ndef test_shuffle(self, shuffle):\n    G = example_graph(feature_size=1, is_directed=True)\n    edges = list(G.edges())\n    edge_labels = list(range(len(edges)))\n    mapper = DirectedGraphSAGELinkGenerator(G, batch_size=2, in_samples=[0], out_samples=[0]).flow(edges, edge_labels, shuffle=shuffle)\n    assert (len(mapper) == 2)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        e1 = edges[nl[0]]\n        e2 = edges[nl[1]]\n        assert (nf[0][(0, 0, 0)] == e1[0])\n        assert (nf[1][(0, 0, 0)] == '???')\n        assert (nf[0][(1, 0, 0)] == e2[0])\n        assert (nf[1][(1, 0, 0)] == e2[1])", "ground_truth": "e1[1]", "quality_analysis": {"complexity_score": 18, "left_complexity": 13, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_945", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_DirectedGraphSAGELinkGenerator", "funcname": "test_shuffle", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "@pytest.mark.parametrize('shuffle', [True, False])\ndef test_shuffle(self, shuffle):\n    G = example_graph(feature_size=1, is_directed=True)\n    edges = list(G.edges())\n    edge_labels = list(range(len(edges)))\n    mapper = DirectedGraphSAGELinkGenerator(G, batch_size=2, in_samples=[0], out_samples=[0]).flow(edges, edge_labels, shuffle=shuffle)\n    assert (len(mapper) == 2)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        e1 = edges[nl[0]]\n        e2 = edges[nl[1]]\n        assert (nf[0][(0, 0, 0)] == e1[0])\n        assert (nf[1][(0, 0, 0)] == e1[1])\n        assert (nf[0][(1, 0, 0)] == e2[0])\n        assert (nf[1][(1, 0, 0)] == e2[1])", "masked_code": "@pytest.mark.parametrize('shuffle', [True, False])\ndef test_shuffle(self, shuffle):\n    G = example_graph(feature_size=1, is_directed=True)\n    edges = list(G.edges())\n    edge_labels = list(range(len(edges)))\n    mapper = DirectedGraphSAGELinkGenerator(G, batch_size=2, in_samples=[0], out_samples=[0]).flow(edges, edge_labels, shuffle=shuffle)\n    assert (len(mapper) == 2)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        e1 = edges[nl[0]]\n        e2 = edges[nl[1]]\n        assert (nf[0][(0, 0, 0)] == e1[0])\n        assert (nf[1][(0, 0, 0)] == e1[1])\n        assert (nf[0][(1, 0, 0)] == '???')\n        assert (nf[1][(1, 0, 0)] == e2[1])", "ground_truth": "e2[0]", "quality_analysis": {"complexity_score": 18, "left_complexity": 13, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_946", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_DirectedGraphSAGELinkGenerator", "funcname": "test_shuffle", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "@pytest.mark.parametrize('shuffle', [True, False])\ndef test_shuffle(self, shuffle):\n    G = example_graph(feature_size=1, is_directed=True)\n    edges = list(G.edges())\n    edge_labels = list(range(len(edges)))\n    mapper = DirectedGraphSAGELinkGenerator(G, batch_size=2, in_samples=[0], out_samples=[0]).flow(edges, edge_labels, shuffle=shuffle)\n    assert (len(mapper) == 2)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        e1 = edges[nl[0]]\n        e2 = edges[nl[1]]\n        assert (nf[0][(0, 0, 0)] == e1[0])\n        assert (nf[1][(0, 0, 0)] == e1[1])\n        assert (nf[0][(1, 0, 0)] == e2[0])\n        assert (nf[1][(1, 0, 0)] == e2[1])", "masked_code": "@pytest.mark.parametrize('shuffle', [True, False])\ndef test_shuffle(self, shuffle):\n    G = example_graph(feature_size=1, is_directed=True)\n    edges = list(G.edges())\n    edge_labels = list(range(len(edges)))\n    mapper = DirectedGraphSAGELinkGenerator(G, batch_size=2, in_samples=[0], out_samples=[0]).flow(edges, edge_labels, shuffle=shuffle)\n    assert (len(mapper) == 2)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        e1 = edges[nl[0]]\n        e2 = edges[nl[1]]\n        assert (nf[0][(0, 0, 0)] == e1[0])\n        assert (nf[1][(0, 0, 0)] == e1[1])\n        assert (nf[0][(1, 0, 0)] == e2[0])\n        assert (nf[1][(1, 0, 0)] == '???')", "ground_truth": "e2[1]", "quality_analysis": {"complexity_score": 18, "left_complexity": 13, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_947", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_DirectedGraphSAGELinkGenerator", "funcname": "test_zero_dim_samples", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_zero_dim_samples(self):\n    G = example_graph(feature_size=self.n_feat, is_directed=True)\n    data_size = G.number_of_edges()\n    edge_labels = ([0] * data_size)\n    mapper = DirectedGraphSAGELinkGenerator(G, batch_size=self.batch_size, in_samples=[0], out_samples=[0]).flow(G.edges(), edge_labels)\n    assert (len(mapper) == 2)\n    for ii in range(len(mapper)):\n        (nf, nl) = mapper[ii]\n        assert (len(nf) == ((2 ** (len([0]) + 2)) - 2))\n        for f in nf[:2]:\n            assert (f.shape == (self.batch_size, 1, self.n_feat))\n        for f in nf[2:]:\n            assert (f.shape == (self.batch_size, 0, self.n_feat))\n        assert (len(nl) == min(self.batch_size, data_size))\n        assert all((nl == 0))", "masked_code": "def test_zero_dim_samples(self):\n    G = example_graph(feature_size=self.n_feat, is_directed=True)\n    data_size = G.number_of_edges()\n    edge_labels = ([0] * data_size)\n    mapper = DirectedGraphSAGELinkGenerator(G, batch_size=self.batch_size, in_samples=[0], out_samples=[0]).flow(G.edges(), edge_labels)\n    assert (len(mapper) == 2)\n    for ii in range(len(mapper)):\n        (nf, nl) = mapper[ii]\n        assert (len(nf) == '???')\n        for f in nf[:2]:\n            assert (f.shape == (self.batch_size, 1, self.n_feat))\n        for f in nf[2:]:\n            assert (f.shape == (self.batch_size, 0, self.n_feat))\n        assert (len(nl) == min(self.batch_size, data_size))\n        assert all((nl == 0))", "ground_truth": "((2 ** (len([0]) + 2)) - 2)", "quality_analysis": {"complexity_score": 19, "left_complexity": 4, "right_complexity": 15, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_948", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_DirectedGraphSAGELinkGenerator", "funcname": "test_zero_dim_samples", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_zero_dim_samples(self):\n    G = example_graph(feature_size=self.n_feat, is_directed=True)\n    data_size = G.number_of_edges()\n    edge_labels = ([0] * data_size)\n    mapper = DirectedGraphSAGELinkGenerator(G, batch_size=self.batch_size, in_samples=[0], out_samples=[0]).flow(G.edges(), edge_labels)\n    assert (len(mapper) == 2)\n    for ii in range(len(mapper)):\n        (nf, nl) = mapper[ii]\n        assert (len(nf) == ((2 ** (len([0]) + 2)) - 2))\n        for f in nf[:2]:\n            assert (f.shape == (self.batch_size, 1, self.n_feat))\n        for f in nf[2:]:\n            assert (f.shape == (self.batch_size, 0, self.n_feat))\n        assert (len(nl) == min(self.batch_size, data_size))\n        assert all((nl == 0))", "masked_code": "def test_zero_dim_samples(self):\n    G = example_graph(feature_size=self.n_feat, is_directed=True)\n    data_size = G.number_of_edges()\n    edge_labels = ([0] * data_size)\n    mapper = DirectedGraphSAGELinkGenerator(G, batch_size=self.batch_size, in_samples=[0], out_samples=[0]).flow(G.edges(), edge_labels)\n    assert (len(mapper) == 2)\n    for ii in range(len(mapper)):\n        (nf, nl) = mapper[ii]\n        assert (len(nf) == ((2 ** (len([0]) + 2)) - 2))\n        for f in nf[:2]:\n            assert (f.shape == (self.batch_size, 1, self.n_feat))\n        for f in nf[2:]:\n            assert (f.shape == (self.batch_size, 0, self.n_feat))\n        assert (len(nl) == '???')\n        assert all((nl == 0))", "ground_truth": "min(self.batch_size, data_size)", "quality_analysis": {"complexity_score": 10, "left_complexity": 4, "right_complexity": 6, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_949", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_DirectedGraphSAGELinkGenerator", "funcname": "test_zero_dim_samples", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_zero_dim_samples(self):\n    G = example_graph(feature_size=self.n_feat, is_directed=True)\n    data_size = G.number_of_edges()\n    edge_labels = ([0] * data_size)\n    mapper = DirectedGraphSAGELinkGenerator(G, batch_size=self.batch_size, in_samples=[0], out_samples=[0]).flow(G.edges(), edge_labels)\n    assert (len(mapper) == 2)\n    for ii in range(len(mapper)):\n        (nf, nl) = mapper[ii]\n        assert (len(nf) == ((2 ** (len([0]) + 2)) - 2))\n        for f in nf[:2]:\n            assert (f.shape == (self.batch_size, 1, self.n_feat))\n        for f in nf[2:]:\n            assert (f.shape == (self.batch_size, 0, self.n_feat))\n        assert (len(nl) == min(self.batch_size, data_size))\n        assert all((nl == 0))", "masked_code": "def test_zero_dim_samples(self):\n    G = example_graph(feature_size=self.n_feat, is_directed=True)\n    data_size = G.number_of_edges()\n    edge_labels = ([0] * data_size)\n    mapper = DirectedGraphSAGELinkGenerator(G, batch_size=self.batch_size, in_samples=[0], out_samples=[0]).flow(G.edges(), edge_labels)\n    assert (len(mapper) == 2)\n    for ii in range(len(mapper)):\n        (nf, nl) = mapper[ii]\n        assert (len(nf) == ((2 ** (len([0]) + 2)) - 2))\n        for f in nf[:2]:\n            assert (f.shape == '???')\n        for f in nf[2:]:\n            assert (f.shape == (self.batch_size, 0, self.n_feat))\n        assert (len(nl) == min(self.batch_size, data_size))\n        assert all((nl == 0))", "ground_truth": "(self.batch_size, 1, self.n_feat)", "quality_analysis": {"complexity_score": 9, "left_complexity": 2, "right_complexity": 7, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_950", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_DirectedGraphSAGELinkGenerator", "funcname": "test_zero_dim_samples", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_zero_dim_samples(self):\n    G = example_graph(feature_size=self.n_feat, is_directed=True)\n    data_size = G.number_of_edges()\n    edge_labels = ([0] * data_size)\n    mapper = DirectedGraphSAGELinkGenerator(G, batch_size=self.batch_size, in_samples=[0], out_samples=[0]).flow(G.edges(), edge_labels)\n    assert (len(mapper) == 2)\n    for ii in range(len(mapper)):\n        (nf, nl) = mapper[ii]\n        assert (len(nf) == ((2 ** (len([0]) + 2)) - 2))\n        for f in nf[:2]:\n            assert (f.shape == (self.batch_size, 1, self.n_feat))\n        for f in nf[2:]:\n            assert (f.shape == (self.batch_size, 0, self.n_feat))\n        assert (len(nl) == min(self.batch_size, data_size))\n        assert all((nl == 0))", "masked_code": "def test_zero_dim_samples(self):\n    G = example_graph(feature_size=self.n_feat, is_directed=True)\n    data_size = G.number_of_edges()\n    edge_labels = ([0] * data_size)\n    mapper = DirectedGraphSAGELinkGenerator(G, batch_size=self.batch_size, in_samples=[0], out_samples=[0]).flow(G.edges(), edge_labels)\n    assert (len(mapper) == 2)\n    for ii in range(len(mapper)):\n        (nf, nl) = mapper[ii]\n        assert (len(nf) == ((2 ** (len([0]) + 2)) - 2))\n        for f in nf[:2]:\n            assert (f.shape == (self.batch_size, 1, self.n_feat))\n        for f in nf[2:]:\n            assert (f.shape == '???')\n        assert (len(nl) == min(self.batch_size, data_size))\n        assert all((nl == 0))", "ground_truth": "(self.batch_size, 0, self.n_feat)", "quality_analysis": {"complexity_score": 9, "left_complexity": 2, "right_complexity": 7, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_951", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_DirectedGraphSAGELinkGenerator", "funcname": "test_isolates", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_isolates(self):\n    '\\n        Test for handling of isolated nodes\\n        '\n    n_feat = 4\n    n_batch = 3\n    G = example_graph_random(feature_size=n_feat, n_nodes=6, n_isolates=2, n_edges=10, is_directed=True)\n    head_links = [(1, 2)]\n    gen = DirectedGraphSAGELinkGenerator(G, batch_size=n_batch, in_samples=self.in_samples, out_samples=self.out_samples).flow(head_links)\n    (ne, nl) = gen[0]\n    expected_sizes = [x.shape[1] for x in ne]\n    head_links = [(1, 5)]\n    gen = DirectedGraphSAGELinkGenerator(G, batch_size=n_batch, in_samples=self.in_samples, out_samples=self.out_samples).flow(head_links)\n    (ne, nl) = gen[0]\n    assert (pytest.approx(expected_sizes) == [x.shape[1] for x in ne])\n    head_links = [(4, 5)]\n    gen = DirectedGraphSAGELinkGenerator(G, batch_size=n_batch, in_samples=self.in_samples, out_samples=self.out_samples).flow(head_links)\n    (ne, nl) = gen[0]\n    assert (pytest.approx(expected_sizes) == [x.shape[1] for x in ne])", "masked_code": "def test_isolates(self):\n    '\\n        Test for handling of isolated nodes\\n        '\n    n_feat = 4\n    n_batch = 3\n    G = example_graph_random(feature_size=n_feat, n_nodes=6, n_isolates=2, n_edges=10, is_directed=True)\n    head_links = [(1, 2)]\n    gen = DirectedGraphSAGELinkGenerator(G, batch_size=n_batch, in_samples=self.in_samples, out_samples=self.out_samples).flow(head_links)\n    (ne, nl) = gen[0]\n    expected_sizes = [x.shape[1] for x in ne]\n    head_links = [(1, 5)]\n    gen = DirectedGraphSAGELinkGenerator(G, batch_size=n_batch, in_samples=self.in_samples, out_samples=self.out_samples).flow(head_links)\n    (ne, nl) = gen[0]\n    assert (pytest.approx(expected_sizes) == '???')\n    head_links = [(4, 5)]\n    gen = DirectedGraphSAGELinkGenerator(G, batch_size=n_batch, in_samples=self.in_samples, out_samples=self.out_samples).flow(head_links)\n    (ne, nl) = gen[0]\n    assert (pytest.approx(expected_sizes) == [x.shape[1] for x in ne])", "ground_truth": "[x.shape[1] for x in ne]", "quality_analysis": {"complexity_score": 4, "left_complexity": 4, "right_complexity": 0, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_952", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_DirectedGraphSAGELinkGenerator", "funcname": "test_isolates", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_isolates(self):\n    '\\n        Test for handling of isolated nodes\\n        '\n    n_feat = 4\n    n_batch = 3\n    G = example_graph_random(feature_size=n_feat, n_nodes=6, n_isolates=2, n_edges=10, is_directed=True)\n    head_links = [(1, 2)]\n    gen = DirectedGraphSAGELinkGenerator(G, batch_size=n_batch, in_samples=self.in_samples, out_samples=self.out_samples).flow(head_links)\n    (ne, nl) = gen[0]\n    expected_sizes = [x.shape[1] for x in ne]\n    head_links = [(1, 5)]\n    gen = DirectedGraphSAGELinkGenerator(G, batch_size=n_batch, in_samples=self.in_samples, out_samples=self.out_samples).flow(head_links)\n    (ne, nl) = gen[0]\n    assert (pytest.approx(expected_sizes) == [x.shape[1] for x in ne])\n    head_links = [(4, 5)]\n    gen = DirectedGraphSAGELinkGenerator(G, batch_size=n_batch, in_samples=self.in_samples, out_samples=self.out_samples).flow(head_links)\n    (ne, nl) = gen[0]\n    assert (pytest.approx(expected_sizes) == [x.shape[1] for x in ne])", "masked_code": "def test_isolates(self):\n    '\\n        Test for handling of isolated nodes\\n        '\n    n_feat = 4\n    n_batch = 3\n    G = example_graph_random(feature_size=n_feat, n_nodes=6, n_isolates=2, n_edges=10, is_directed=True)\n    head_links = [(1, 2)]\n    gen = DirectedGraphSAGELinkGenerator(G, batch_size=n_batch, in_samples=self.in_samples, out_samples=self.out_samples).flow(head_links)\n    (ne, nl) = gen[0]\n    expected_sizes = [x.shape[1] for x in ne]\n    head_links = [(1, 5)]\n    gen = DirectedGraphSAGELinkGenerator(G, batch_size=n_batch, in_samples=self.in_samples, out_samples=self.out_samples).flow(head_links)\n    (ne, nl) = gen[0]\n    assert (pytest.approx(expected_sizes) == [x.shape[1] for x in ne])\n    head_links = [(4, 5)]\n    gen = DirectedGraphSAGELinkGenerator(G, batch_size=n_batch, in_samples=self.in_samples, out_samples=self.out_samples).flow(head_links)\n    (ne, nl) = gen[0]\n    assert (pytest.approx(expected_sizes) == '???')", "ground_truth": "[x.shape[1] for x in ne]", "quality_analysis": {"complexity_score": 4, "left_complexity": 4, "right_complexity": 0, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_953", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_DirectedGraphSAGELinkGenerator", "funcname": "test_unsupervisedSampler_sample_generation", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_unsupervisedSampler_sample_generation(self):\n    G = example_graph(feature_size=self.n_feat, is_directed=True)\n    unsupervisedSamples = UnsupervisedSampler(G)\n    gen = DirectedGraphSAGELinkGenerator(G, batch_size=self.batch_size, in_samples=self.in_samples, out_samples=self.out_samples)\n    mapper = gen.flow(unsupervisedSamples)\n    assert (mapper.data_size == (len(list(G.nodes())) * 2))\n    assert (mapper.batch_size == self.batch_size)\n    assert (len(mapper) == np.ceil((mapper.data_size / mapper.batch_size)))\n    assert (len(set(gen.head_node_types)) == 1)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        assert (len(nf) == ((2 ** (len(self.in_samples) + 2)) - 2))\n        (ins, outs) = (self.in_samples, self.out_samples)\n        dims = [1, ins[0], outs[0], (ins[0] * ins[1]), (ins[0] * outs[1]), (outs[0] * ins[1]), (outs[0] * outs[1])]\n        for (ii, dim) in zip(range(7), dims):\n            assert (nf[(2 * ii)].shape == nf[((2 * ii) + 1)].shape == (min(self.batch_size, mapper.data_size), dim, self.n_feat))", "masked_code": "def test_unsupervisedSampler_sample_generation(self):\n    G = example_graph(feature_size=self.n_feat, is_directed=True)\n    unsupervisedSamples = UnsupervisedSampler(G)\n    gen = DirectedGraphSAGELinkGenerator(G, batch_size=self.batch_size, in_samples=self.in_samples, out_samples=self.out_samples)\n    mapper = gen.flow(unsupervisedSamples)\n    assert (mapper.data_size == '???')\n    assert (mapper.batch_size == self.batch_size)\n    assert (len(mapper) == np.ceil((mapper.data_size / mapper.batch_size)))\n    assert (len(set(gen.head_node_types)) == 1)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        assert (len(nf) == ((2 ** (len(self.in_samples) + 2)) - 2))\n        (ins, outs) = (self.in_samples, self.out_samples)\n        dims = [1, ins[0], outs[0], (ins[0] * ins[1]), (ins[0] * outs[1]), (outs[0] * ins[1]), (outs[0] * outs[1])]\n        for (ii, dim) in zip(range(7), dims):\n            assert (nf[(2 * ii)].shape == nf[((2 * ii) + 1)].shape == (min(self.batch_size, mapper.data_size), dim, self.n_feat))", "ground_truth": "(len(list(G.nodes())) * 2)", "quality_analysis": {"complexity_score": 14, "left_complexity": 2, "right_complexity": 12, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_954", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_DirectedGraphSAGELinkGenerator", "funcname": "test_unsupervisedSampler_sample_generation", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_unsupervisedSampler_sample_generation(self):\n    G = example_graph(feature_size=self.n_feat, is_directed=True)\n    unsupervisedSamples = UnsupervisedSampler(G)\n    gen = DirectedGraphSAGELinkGenerator(G, batch_size=self.batch_size, in_samples=self.in_samples, out_samples=self.out_samples)\n    mapper = gen.flow(unsupervisedSamples)\n    assert (mapper.data_size == (len(list(G.nodes())) * 2))\n    assert (mapper.batch_size == self.batch_size)\n    assert (len(mapper) == np.ceil((mapper.data_size / mapper.batch_size)))\n    assert (len(set(gen.head_node_types)) == 1)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        assert (len(nf) == ((2 ** (len(self.in_samples) + 2)) - 2))\n        (ins, outs) = (self.in_samples, self.out_samples)\n        dims = [1, ins[0], outs[0], (ins[0] * ins[1]), (ins[0] * outs[1]), (outs[0] * ins[1]), (outs[0] * outs[1])]\n        for (ii, dim) in zip(range(7), dims):\n            assert (nf[(2 * ii)].shape == nf[((2 * ii) + 1)].shape == (min(self.batch_size, mapper.data_size), dim, self.n_feat))", "masked_code": "def test_unsupervisedSampler_sample_generation(self):\n    G = example_graph(feature_size=self.n_feat, is_directed=True)\n    unsupervisedSamples = UnsupervisedSampler(G)\n    gen = DirectedGraphSAGELinkGenerator(G, batch_size=self.batch_size, in_samples=self.in_samples, out_samples=self.out_samples)\n    mapper = gen.flow(unsupervisedSamples)\n    assert (mapper.data_size == (len(list(G.nodes())) * 2))\n    assert (mapper.batch_size == '???')\n    assert (len(mapper) == np.ceil((mapper.data_size / mapper.batch_size)))\n    assert (len(set(gen.head_node_types)) == 1)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        assert (len(nf) == ((2 ** (len(self.in_samples) + 2)) - 2))\n        (ins, outs) = (self.in_samples, self.out_samples)\n        dims = [1, ins[0], outs[0], (ins[0] * ins[1]), (ins[0] * outs[1]), (outs[0] * ins[1]), (outs[0] * outs[1])]\n        for (ii, dim) in zip(range(7), dims):\n            assert (nf[(2 * ii)].shape == nf[((2 * ii) + 1)].shape == (min(self.batch_size, mapper.data_size), dim, self.n_feat))", "ground_truth": "self.batch_size", "quality_analysis": {"complexity_score": 4, "left_complexity": 2, "right_complexity": 2, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_955", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_DirectedGraphSAGELinkGenerator", "funcname": "test_unsupervisedSampler_sample_generation", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_unsupervisedSampler_sample_generation(self):\n    G = example_graph(feature_size=self.n_feat, is_directed=True)\n    unsupervisedSamples = UnsupervisedSampler(G)\n    gen = DirectedGraphSAGELinkGenerator(G, batch_size=self.batch_size, in_samples=self.in_samples, out_samples=self.out_samples)\n    mapper = gen.flow(unsupervisedSamples)\n    assert (mapper.data_size == (len(list(G.nodes())) * 2))\n    assert (mapper.batch_size == self.batch_size)\n    assert (len(mapper) == np.ceil((mapper.data_size / mapper.batch_size)))\n    assert (len(set(gen.head_node_types)) == 1)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        assert (len(nf) == ((2 ** (len(self.in_samples) + 2)) - 2))\n        (ins, outs) = (self.in_samples, self.out_samples)\n        dims = [1, ins[0], outs[0], (ins[0] * ins[1]), (ins[0] * outs[1]), (outs[0] * ins[1]), (outs[0] * outs[1])]\n        for (ii, dim) in zip(range(7), dims):\n            assert (nf[(2 * ii)].shape == nf[((2 * ii) + 1)].shape == (min(self.batch_size, mapper.data_size), dim, self.n_feat))", "masked_code": "def test_unsupervisedSampler_sample_generation(self):\n    G = example_graph(feature_size=self.n_feat, is_directed=True)\n    unsupervisedSamples = UnsupervisedSampler(G)\n    gen = DirectedGraphSAGELinkGenerator(G, batch_size=self.batch_size, in_samples=self.in_samples, out_samples=self.out_samples)\n    mapper = gen.flow(unsupervisedSamples)\n    assert (mapper.data_size == (len(list(G.nodes())) * 2))\n    assert (mapper.batch_size == self.batch_size)\n    assert (len(mapper) == '???')\n    assert (len(set(gen.head_node_types)) == 1)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        assert (len(nf) == ((2 ** (len(self.in_samples) + 2)) - 2))\n        (ins, outs) = (self.in_samples, self.out_samples)\n        dims = [1, ins[0], outs[0], (ins[0] * ins[1]), (ins[0] * outs[1]), (outs[0] * ins[1]), (outs[0] * outs[1])]\n        for (ii, dim) in zip(range(7), dims):\n            assert (nf[(2 * ii)].shape == nf[((2 * ii) + 1)].shape == (min(self.batch_size, mapper.data_size), dim, self.n_feat))", "ground_truth": "np.ceil((mapper.data_size / mapper.batch_size))", "quality_analysis": {"complexity_score": 13, "left_complexity": 4, "right_complexity": 9, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_956", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_DirectedGraphSAGELinkGenerator", "funcname": "test_unsupervisedSampler_sample_generation", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_unsupervisedSampler_sample_generation(self):\n    G = example_graph(feature_size=self.n_feat, is_directed=True)\n    unsupervisedSamples = UnsupervisedSampler(G)\n    gen = DirectedGraphSAGELinkGenerator(G, batch_size=self.batch_size, in_samples=self.in_samples, out_samples=self.out_samples)\n    mapper = gen.flow(unsupervisedSamples)\n    assert (mapper.data_size == (len(list(G.nodes())) * 2))\n    assert (mapper.batch_size == self.batch_size)\n    assert (len(mapper) == np.ceil((mapper.data_size / mapper.batch_size)))\n    assert (len(set(gen.head_node_types)) == 1)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        assert (len(nf) == ((2 ** (len(self.in_samples) + 2)) - 2))\n        (ins, outs) = (self.in_samples, self.out_samples)\n        dims = [1, ins[0], outs[0], (ins[0] * ins[1]), (ins[0] * outs[1]), (outs[0] * ins[1]), (outs[0] * outs[1])]\n        for (ii, dim) in zip(range(7), dims):\n            assert (nf[(2 * ii)].shape == nf[((2 * ii) + 1)].shape == (min(self.batch_size, mapper.data_size), dim, self.n_feat))", "masked_code": "def test_unsupervisedSampler_sample_generation(self):\n    G = example_graph(feature_size=self.n_feat, is_directed=True)\n    unsupervisedSamples = UnsupervisedSampler(G)\n    gen = DirectedGraphSAGELinkGenerator(G, batch_size=self.batch_size, in_samples=self.in_samples, out_samples=self.out_samples)\n    mapper = gen.flow(unsupervisedSamples)\n    assert (mapper.data_size == (len(list(G.nodes())) * 2))\n    assert (mapper.batch_size == self.batch_size)\n    assert (len(mapper) == np.ceil((mapper.data_size / mapper.batch_size)))\n    assert (len(set(gen.head_node_types)) == 1)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        assert (len(nf) == '???')\n        (ins, outs) = (self.in_samples, self.out_samples)\n        dims = [1, ins[0], outs[0], (ins[0] * ins[1]), (ins[0] * outs[1]), (outs[0] * ins[1]), (outs[0] * outs[1])]\n        for (ii, dim) in zip(range(7), dims):\n            assert (nf[(2 * ii)].shape == nf[((2 * ii) + 1)].shape == (min(self.batch_size, mapper.data_size), dim, self.n_feat))", "ground_truth": "((2 ** (len(self.in_samples) + 2)) - 2)", "quality_analysis": {"complexity_score": 18, "left_complexity": 4, "right_complexity": 14, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_957", "reponame": "stellargraph", "testpath": "tests/mapper/test_link_mappers.py", "testname": "test_link_mappers.py", "classname": "Test_DirectedGraphSAGELinkGenerator", "funcname": "test_unsupervisedSampler_sample_generation", "imports": ["import numpy as np", "import networkx as nx", "import pytest", "import random", "from stellargraph.mapper import *", "from stellargraph.core.graph import *", "from stellargraph.data.unsupervised_sampler import *", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_unsupervisedSampler_sample_generation(self):\n    G = example_graph(feature_size=self.n_feat, is_directed=True)\n    unsupervisedSamples = UnsupervisedSampler(G)\n    gen = DirectedGraphSAGELinkGenerator(G, batch_size=self.batch_size, in_samples=self.in_samples, out_samples=self.out_samples)\n    mapper = gen.flow(unsupervisedSamples)\n    assert (mapper.data_size == (len(list(G.nodes())) * 2))\n    assert (mapper.batch_size == self.batch_size)\n    assert (len(mapper) == np.ceil((mapper.data_size / mapper.batch_size)))\n    assert (len(set(gen.head_node_types)) == 1)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        assert (len(nf) == ((2 ** (len(self.in_samples) + 2)) - 2))\n        (ins, outs) = (self.in_samples, self.out_samples)\n        dims = [1, ins[0], outs[0], (ins[0] * ins[1]), (ins[0] * outs[1]), (outs[0] * ins[1]), (outs[0] * outs[1])]\n        for (ii, dim) in zip(range(7), dims):\n            assert (nf[(2 * ii)].shape == nf[((2 * ii) + 1)].shape == (min(self.batch_size, mapper.data_size), dim, self.n_feat))", "masked_code": "def test_unsupervisedSampler_sample_generation(self):\n    G = example_graph(feature_size=self.n_feat, is_directed=True)\n    unsupervisedSamples = UnsupervisedSampler(G)\n    gen = DirectedGraphSAGELinkGenerator(G, batch_size=self.batch_size, in_samples=self.in_samples, out_samples=self.out_samples)\n    mapper = gen.flow(unsupervisedSamples)\n    assert (mapper.data_size == (len(list(G.nodes())) * 2))\n    assert (mapper.batch_size == self.batch_size)\n    assert (len(mapper) == np.ceil((mapper.data_size / mapper.batch_size)))\n    assert (len(set(gen.head_node_types)) == 1)\n    for batch in range(len(mapper)):\n        (nf, nl) = mapper[batch]\n        assert (len(nf) == ((2 ** (len(self.in_samples) + 2)) - 2))\n        (ins, outs) = (self.in_samples, self.out_samples)\n        dims = [1, ins[0], outs[0], (ins[0] * ins[1]), (ins[0] * outs[1]), (outs[0] * ins[1]), (outs[0] * outs[1])]\n        for (ii, dim) in zip(range(7), dims):\n            assert (nf[(2 * ii)].shape == '???' == (min(self.batch_size, mapper.data_size), dim, self.n_feat))", "ground_truth": "nf[((2 * ii) + 1)].shape", "quality_analysis": {"complexity_score": 4, "left_complexity": 2, "right_complexity": 2, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_958", "reponame": "stellargraph", "testpath": "tests/mapper/test_node_mappers.py", "testname": "test_node_mappers.py", "classname": null, "funcname": "test_nodemapper_constructor", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper import *", "import networkx as nx", "import numpy as np", "import random", "import pytest", "import pandas as pd", "import scipy.sparse as sps", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, create_graph_features, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_nodemapper_constructor():\n    n_feat = 4\n    G = example_graph(feature_size=n_feat)\n    generator = GraphSAGENodeGenerator(G, batch_size=2, num_samples=[2, 2])\n    mapper = generator.flow(list(G.nodes()))\n    assert (generator.batch_size == 2)\n    assert (mapper.data_size == 4)\n    assert (len(mapper.ids) == 4)", "masked_code": "def test_nodemapper_constructor():\n    n_feat = 4\n    G = example_graph(feature_size=n_feat)\n    generator = GraphSAGENodeGenerator(G, batch_size=2, num_samples=[2, 2])\n    mapper = generator.flow(list(G.nodes()))\n    assert (generator.batch_size == 2)\n    assert (mapper.data_size == '???')\n    assert (len(mapper.ids) == 4)", "ground_truth": "4", "quality_analysis": {"complexity_score": 3, "left_complexity": 2, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_959", "reponame": "stellargraph", "testpath": "tests/mapper/test_node_mappers.py", "testname": "test_node_mappers.py", "classname": null, "funcname": "test_nodemapper_constructor", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper import *", "import networkx as nx", "import numpy as np", "import random", "import pytest", "import pandas as pd", "import scipy.sparse as sps", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, create_graph_features, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_nodemapper_constructor():\n    n_feat = 4\n    G = example_graph(feature_size=n_feat)\n    generator = GraphSAGENodeGenerator(G, batch_size=2, num_samples=[2, 2])\n    mapper = generator.flow(list(G.nodes()))\n    assert (generator.batch_size == 2)\n    assert (mapper.data_size == 4)\n    assert (len(mapper.ids) == 4)", "masked_code": "def test_nodemapper_constructor():\n    n_feat = 4\n    G = example_graph(feature_size=n_feat)\n    generator = GraphSAGENodeGenerator(G, batch_size=2, num_samples=[2, 2])\n    mapper = generator.flow(list(G.nodes()))\n    assert (generator.batch_size == 2)\n    assert (mapper.data_size == 4)\n    assert (len(mapper.ids) == '???')", "ground_truth": "4", "quality_analysis": {"complexity_score": 6, "left_complexity": 5, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_960", "reponame": "stellargraph", "testpath": "tests/mapper/test_node_mappers.py", "testname": "test_node_mappers.py", "classname": null, "funcname": "test_nodemapper_1", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper import *", "import networkx as nx", "import numpy as np", "import random", "import pytest", "import pandas as pd", "import scipy.sparse as sps", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, create_graph_features, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_nodemapper_1():\n    n_feat = 4\n    n_batch = 2\n    G1 = example_graph(n_feat)\n    mapper1 = GraphSAGENodeGenerator(G1, batch_size=n_batch, num_samples=[2, 2]).flow(G1.nodes())\n    assert (len(mapper1) == 2)\n    G2 = example_graph_2(n_feat)\n    mapper2 = GraphSAGENodeGenerator(G2, batch_size=n_batch, num_samples=[2, 2]).flow(G2.nodes())\n    assert (len(mapper2) == 3)\n    for mapper in [mapper1, mapper2]:\n        for ii in range(2):\n            (nf, nl) = mapper[ii]\n            assert (len(nf) == 3)\n            assert (nf[0].shape == (n_batch, 1, n_feat))\n            assert (nf[1].shape == (n_batch, 2, n_feat))\n            assert (nf[2].shape == (n_batch, (2 * 2), n_feat))\n            assert (nl is None)\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper1[len(mapper1)]\n    (nf, nl) = mapper2[(len(mapper2) - 1)]\n    assert (nf[0].shape == (1, 1, n_feat))\n    assert (nf[1].shape == (1, 2, n_feat))\n    assert (nf[2].shape == (1, (2 * 2), n_feat))\n    with pytest.raises(KeyError):\n        GraphSAGENodeGenerator(G1, batch_size=2, num_samples=[2, 2]).flow(['A', 'B'])", "masked_code": "def test_nodemapper_1():\n    n_feat = 4\n    n_batch = 2\n    G1 = example_graph(n_feat)\n    mapper1 = GraphSAGENodeGenerator(G1, batch_size=n_batch, num_samples=[2, 2]).flow(G1.nodes())\n    assert (len(mapper1) == 2)\n    G2 = example_graph_2(n_feat)\n    mapper2 = GraphSAGENodeGenerator(G2, batch_size=n_batch, num_samples=[2, 2]).flow(G2.nodes())\n    assert (len(mapper2) == '???')\n    for mapper in [mapper1, mapper2]:\n        for ii in range(2):\n            (nf, nl) = mapper[ii]\n            assert (len(nf) == 3)\n            assert (nf[0].shape == (n_batch, 1, n_feat))\n            assert (nf[1].shape == (n_batch, 2, n_feat))\n            assert (nf[2].shape == (n_batch, (2 * 2), n_feat))\n            assert (nl is None)\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper1[len(mapper1)]\n    (nf, nl) = mapper2[(len(mapper2) - 1)]\n    assert (nf[0].shape == (1, 1, n_feat))\n    assert (nf[1].shape == (1, 2, n_feat))\n    assert (nf[2].shape == (1, (2 * 2), n_feat))\n    with pytest.raises(KeyError):\n        GraphSAGENodeGenerator(G1, batch_size=2, num_samples=[2, 2]).flow(['A', 'B'])", "ground_truth": "3", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_961", "reponame": "stellargraph", "testpath": "tests/mapper/test_node_mappers.py", "testname": "test_node_mappers.py", "classname": null, "funcname": "test_nodemapper_1", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper import *", "import networkx as nx", "import numpy as np", "import random", "import pytest", "import pandas as pd", "import scipy.sparse as sps", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, create_graph_features, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_nodemapper_1():\n    n_feat = 4\n    n_batch = 2\n    G1 = example_graph(n_feat)\n    mapper1 = GraphSAGENodeGenerator(G1, batch_size=n_batch, num_samples=[2, 2]).flow(G1.nodes())\n    assert (len(mapper1) == 2)\n    G2 = example_graph_2(n_feat)\n    mapper2 = GraphSAGENodeGenerator(G2, batch_size=n_batch, num_samples=[2, 2]).flow(G2.nodes())\n    assert (len(mapper2) == 3)\n    for mapper in [mapper1, mapper2]:\n        for ii in range(2):\n            (nf, nl) = mapper[ii]\n            assert (len(nf) == 3)\n            assert (nf[0].shape == (n_batch, 1, n_feat))\n            assert (nf[1].shape == (n_batch, 2, n_feat))\n            assert (nf[2].shape == (n_batch, (2 * 2), n_feat))\n            assert (nl is None)\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper1[len(mapper1)]\n    (nf, nl) = mapper2[(len(mapper2) - 1)]\n    assert (nf[0].shape == (1, 1, n_feat))\n    assert (nf[1].shape == (1, 2, n_feat))\n    assert (nf[2].shape == (1, (2 * 2), n_feat))\n    with pytest.raises(KeyError):\n        GraphSAGENodeGenerator(G1, batch_size=2, num_samples=[2, 2]).flow(['A', 'B'])", "masked_code": "def test_nodemapper_1():\n    n_feat = 4\n    n_batch = 2\n    G1 = example_graph(n_feat)\n    mapper1 = GraphSAGENodeGenerator(G1, batch_size=n_batch, num_samples=[2, 2]).flow(G1.nodes())\n    assert (len(mapper1) == 2)\n    G2 = example_graph_2(n_feat)\n    mapper2 = GraphSAGENodeGenerator(G2, batch_size=n_batch, num_samples=[2, 2]).flow(G2.nodes())\n    assert (len(mapper2) == 3)\n    for mapper in [mapper1, mapper2]:\n        for ii in range(2):\n            (nf, nl) = mapper[ii]\n            assert (len(nf) == 3)\n            assert (nf[0].shape == (n_batch, 1, n_feat))\n            assert (nf[1].shape == (n_batch, 2, n_feat))\n            assert (nf[2].shape == (n_batch, (2 * 2), n_feat))\n            assert (nl is None)\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper1[len(mapper1)]\n    (nf, nl) = mapper2[(len(mapper2) - 1)]\n    assert (nf[0].shape == '???')\n    assert (nf[1].shape == (1, 2, n_feat))\n    assert (nf[2].shape == (1, (2 * 2), n_feat))\n    with pytest.raises(KeyError):\n        GraphSAGENodeGenerator(G1, batch_size=2, num_samples=[2, 2]).flow(['A', 'B'])", "ground_truth": "(1, 1, n_feat)", "quality_analysis": {"complexity_score": 7, "left_complexity": 2, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_962", "reponame": "stellargraph", "testpath": "tests/mapper/test_node_mappers.py", "testname": "test_node_mappers.py", "classname": null, "funcname": "test_nodemapper_1", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper import *", "import networkx as nx", "import numpy as np", "import random", "import pytest", "import pandas as pd", "import scipy.sparse as sps", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, create_graph_features, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_nodemapper_1():\n    n_feat = 4\n    n_batch = 2\n    G1 = example_graph(n_feat)\n    mapper1 = GraphSAGENodeGenerator(G1, batch_size=n_batch, num_samples=[2, 2]).flow(G1.nodes())\n    assert (len(mapper1) == 2)\n    G2 = example_graph_2(n_feat)\n    mapper2 = GraphSAGENodeGenerator(G2, batch_size=n_batch, num_samples=[2, 2]).flow(G2.nodes())\n    assert (len(mapper2) == 3)\n    for mapper in [mapper1, mapper2]:\n        for ii in range(2):\n            (nf, nl) = mapper[ii]\n            assert (len(nf) == 3)\n            assert (nf[0].shape == (n_batch, 1, n_feat))\n            assert (nf[1].shape == (n_batch, 2, n_feat))\n            assert (nf[2].shape == (n_batch, (2 * 2), n_feat))\n            assert (nl is None)\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper1[len(mapper1)]\n    (nf, nl) = mapper2[(len(mapper2) - 1)]\n    assert (nf[0].shape == (1, 1, n_feat))\n    assert (nf[1].shape == (1, 2, n_feat))\n    assert (nf[2].shape == (1, (2 * 2), n_feat))\n    with pytest.raises(KeyError):\n        GraphSAGENodeGenerator(G1, batch_size=2, num_samples=[2, 2]).flow(['A', 'B'])", "masked_code": "def test_nodemapper_1():\n    n_feat = 4\n    n_batch = 2\n    G1 = example_graph(n_feat)\n    mapper1 = GraphSAGENodeGenerator(G1, batch_size=n_batch, num_samples=[2, 2]).flow(G1.nodes())\n    assert (len(mapper1) == 2)\n    G2 = example_graph_2(n_feat)\n    mapper2 = GraphSAGENodeGenerator(G2, batch_size=n_batch, num_samples=[2, 2]).flow(G2.nodes())\n    assert (len(mapper2) == 3)\n    for mapper in [mapper1, mapper2]:\n        for ii in range(2):\n            (nf, nl) = mapper[ii]\n            assert (len(nf) == 3)\n            assert (nf[0].shape == (n_batch, 1, n_feat))\n            assert (nf[1].shape == (n_batch, 2, n_feat))\n            assert (nf[2].shape == (n_batch, (2 * 2), n_feat))\n            assert (nl is None)\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper1[len(mapper1)]\n    (nf, nl) = mapper2[(len(mapper2) - 1)]\n    assert (nf[0].shape == (1, 1, n_feat))\n    assert (nf[1].shape == '???')\n    assert (nf[2].shape == (1, (2 * 2), n_feat))\n    with pytest.raises(KeyError):\n        GraphSAGENodeGenerator(G1, batch_size=2, num_samples=[2, 2]).flow(['A', 'B'])", "ground_truth": "(1, 2, n_feat)", "quality_analysis": {"complexity_score": 7, "left_complexity": 2, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_963", "reponame": "stellargraph", "testpath": "tests/mapper/test_node_mappers.py", "testname": "test_node_mappers.py", "classname": null, "funcname": "test_nodemapper_1", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper import *", "import networkx as nx", "import numpy as np", "import random", "import pytest", "import pandas as pd", "import scipy.sparse as sps", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, create_graph_features, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_nodemapper_1():\n    n_feat = 4\n    n_batch = 2\n    G1 = example_graph(n_feat)\n    mapper1 = GraphSAGENodeGenerator(G1, batch_size=n_batch, num_samples=[2, 2]).flow(G1.nodes())\n    assert (len(mapper1) == 2)\n    G2 = example_graph_2(n_feat)\n    mapper2 = GraphSAGENodeGenerator(G2, batch_size=n_batch, num_samples=[2, 2]).flow(G2.nodes())\n    assert (len(mapper2) == 3)\n    for mapper in [mapper1, mapper2]:\n        for ii in range(2):\n            (nf, nl) = mapper[ii]\n            assert (len(nf) == 3)\n            assert (nf[0].shape == (n_batch, 1, n_feat))\n            assert (nf[1].shape == (n_batch, 2, n_feat))\n            assert (nf[2].shape == (n_batch, (2 * 2), n_feat))\n            assert (nl is None)\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper1[len(mapper1)]\n    (nf, nl) = mapper2[(len(mapper2) - 1)]\n    assert (nf[0].shape == (1, 1, n_feat))\n    assert (nf[1].shape == (1, 2, n_feat))\n    assert (nf[2].shape == (1, (2 * 2), n_feat))\n    with pytest.raises(KeyError):\n        GraphSAGENodeGenerator(G1, batch_size=2, num_samples=[2, 2]).flow(['A', 'B'])", "masked_code": "def test_nodemapper_1():\n    n_feat = 4\n    n_batch = 2\n    G1 = example_graph(n_feat)\n    mapper1 = GraphSAGENodeGenerator(G1, batch_size=n_batch, num_samples=[2, 2]).flow(G1.nodes())\n    assert (len(mapper1) == 2)\n    G2 = example_graph_2(n_feat)\n    mapper2 = GraphSAGENodeGenerator(G2, batch_size=n_batch, num_samples=[2, 2]).flow(G2.nodes())\n    assert (len(mapper2) == 3)\n    for mapper in [mapper1, mapper2]:\n        for ii in range(2):\n            (nf, nl) = mapper[ii]\n            assert (len(nf) == 3)\n            assert (nf[0].shape == (n_batch, 1, n_feat))\n            assert (nf[1].shape == (n_batch, 2, n_feat))\n            assert (nf[2].shape == (n_batch, (2 * 2), n_feat))\n            assert (nl is None)\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper1[len(mapper1)]\n    (nf, nl) = mapper2[(len(mapper2) - 1)]\n    assert (nf[0].shape == (1, 1, n_feat))\n    assert (nf[1].shape == (1, 2, n_feat))\n    assert (nf[2].shape == '???')\n    with pytest.raises(KeyError):\n        GraphSAGENodeGenerator(G1, batch_size=2, num_samples=[2, 2]).flow(['A', 'B'])", "ground_truth": "(1, (2 * 2), n_feat)", "quality_analysis": {"complexity_score": 10, "left_complexity": 2, "right_complexity": 8, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_964", "reponame": "stellargraph", "testpath": "tests/mapper/test_node_mappers.py", "testname": "test_node_mappers.py", "classname": null, "funcname": "test_nodemapper_1", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper import *", "import networkx as nx", "import numpy as np", "import random", "import pytest", "import pandas as pd", "import scipy.sparse as sps", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, create_graph_features, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_nodemapper_1():\n    n_feat = 4\n    n_batch = 2\n    G1 = example_graph(n_feat)\n    mapper1 = GraphSAGENodeGenerator(G1, batch_size=n_batch, num_samples=[2, 2]).flow(G1.nodes())\n    assert (len(mapper1) == 2)\n    G2 = example_graph_2(n_feat)\n    mapper2 = GraphSAGENodeGenerator(G2, batch_size=n_batch, num_samples=[2, 2]).flow(G2.nodes())\n    assert (len(mapper2) == 3)\n    for mapper in [mapper1, mapper2]:\n        for ii in range(2):\n            (nf, nl) = mapper[ii]\n            assert (len(nf) == 3)\n            assert (nf[0].shape == (n_batch, 1, n_feat))\n            assert (nf[1].shape == (n_batch, 2, n_feat))\n            assert (nf[2].shape == (n_batch, (2 * 2), n_feat))\n            assert (nl is None)\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper1[len(mapper1)]\n    (nf, nl) = mapper2[(len(mapper2) - 1)]\n    assert (nf[0].shape == (1, 1, n_feat))\n    assert (nf[1].shape == (1, 2, n_feat))\n    assert (nf[2].shape == (1, (2 * 2), n_feat))\n    with pytest.raises(KeyError):\n        GraphSAGENodeGenerator(G1, batch_size=2, num_samples=[2, 2]).flow(['A', 'B'])", "masked_code": "def test_nodemapper_1():\n    n_feat = 4\n    n_batch = 2\n    G1 = example_graph(n_feat)\n    mapper1 = GraphSAGENodeGenerator(G1, batch_size=n_batch, num_samples=[2, 2]).flow(G1.nodes())\n    assert (len(mapper1) == 2)\n    G2 = example_graph_2(n_feat)\n    mapper2 = GraphSAGENodeGenerator(G2, batch_size=n_batch, num_samples=[2, 2]).flow(G2.nodes())\n    assert (len(mapper2) == 3)\n    for mapper in [mapper1, mapper2]:\n        for ii in range(2):\n            (nf, nl) = mapper[ii]\n            assert (len(nf) == '???')\n            assert (nf[0].shape == (n_batch, 1, n_feat))\n            assert (nf[1].shape == (n_batch, 2, n_feat))\n            assert (nf[2].shape == (n_batch, (2 * 2), n_feat))\n            assert (nl is None)\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper1[len(mapper1)]\n    (nf, nl) = mapper2[(len(mapper2) - 1)]\n    assert (nf[0].shape == (1, 1, n_feat))\n    assert (nf[1].shape == (1, 2, n_feat))\n    assert (nf[2].shape == (1, (2 * 2), n_feat))\n    with pytest.raises(KeyError):\n        GraphSAGENodeGenerator(G1, batch_size=2, num_samples=[2, 2]).flow(['A', 'B'])", "ground_truth": "3", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_965", "reponame": "stellargraph", "testpath": "tests/mapper/test_node_mappers.py", "testname": "test_node_mappers.py", "classname": null, "funcname": "test_nodemapper_1", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper import *", "import networkx as nx", "import numpy as np", "import random", "import pytest", "import pandas as pd", "import scipy.sparse as sps", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, create_graph_features, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_nodemapper_1():\n    n_feat = 4\n    n_batch = 2\n    G1 = example_graph(n_feat)\n    mapper1 = GraphSAGENodeGenerator(G1, batch_size=n_batch, num_samples=[2, 2]).flow(G1.nodes())\n    assert (len(mapper1) == 2)\n    G2 = example_graph_2(n_feat)\n    mapper2 = GraphSAGENodeGenerator(G2, batch_size=n_batch, num_samples=[2, 2]).flow(G2.nodes())\n    assert (len(mapper2) == 3)\n    for mapper in [mapper1, mapper2]:\n        for ii in range(2):\n            (nf, nl) = mapper[ii]\n            assert (len(nf) == 3)\n            assert (nf[0].shape == (n_batch, 1, n_feat))\n            assert (nf[1].shape == (n_batch, 2, n_feat))\n            assert (nf[2].shape == (n_batch, (2 * 2), n_feat))\n            assert (nl is None)\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper1[len(mapper1)]\n    (nf, nl) = mapper2[(len(mapper2) - 1)]\n    assert (nf[0].shape == (1, 1, n_feat))\n    assert (nf[1].shape == (1, 2, n_feat))\n    assert (nf[2].shape == (1, (2 * 2), n_feat))\n    with pytest.raises(KeyError):\n        GraphSAGENodeGenerator(G1, batch_size=2, num_samples=[2, 2]).flow(['A', 'B'])", "masked_code": "def test_nodemapper_1():\n    n_feat = 4\n    n_batch = 2\n    G1 = example_graph(n_feat)\n    mapper1 = GraphSAGENodeGenerator(G1, batch_size=n_batch, num_samples=[2, 2]).flow(G1.nodes())\n    assert (len(mapper1) == 2)\n    G2 = example_graph_2(n_feat)\n    mapper2 = GraphSAGENodeGenerator(G2, batch_size=n_batch, num_samples=[2, 2]).flow(G2.nodes())\n    assert (len(mapper2) == 3)\n    for mapper in [mapper1, mapper2]:\n        for ii in range(2):\n            (nf, nl) = mapper[ii]\n            assert (len(nf) == 3)\n            assert (nf[0].shape == '???')\n            assert (nf[1].shape == (n_batch, 2, n_feat))\n            assert (nf[2].shape == (n_batch, (2 * 2), n_feat))\n            assert (nl is None)\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper1[len(mapper1)]\n    (nf, nl) = mapper2[(len(mapper2) - 1)]\n    assert (nf[0].shape == (1, 1, n_feat))\n    assert (nf[1].shape == (1, 2, n_feat))\n    assert (nf[2].shape == (1, (2 * 2), n_feat))\n    with pytest.raises(KeyError):\n        GraphSAGENodeGenerator(G1, batch_size=2, num_samples=[2, 2]).flow(['A', 'B'])", "ground_truth": "(n_batch, 1, n_feat)", "quality_analysis": {"complexity_score": 7, "left_complexity": 2, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_966", "reponame": "stellargraph", "testpath": "tests/mapper/test_node_mappers.py", "testname": "test_node_mappers.py", "classname": null, "funcname": "test_nodemapper_1", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper import *", "import networkx as nx", "import numpy as np", "import random", "import pytest", "import pandas as pd", "import scipy.sparse as sps", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, create_graph_features, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_nodemapper_1():\n    n_feat = 4\n    n_batch = 2\n    G1 = example_graph(n_feat)\n    mapper1 = GraphSAGENodeGenerator(G1, batch_size=n_batch, num_samples=[2, 2]).flow(G1.nodes())\n    assert (len(mapper1) == 2)\n    G2 = example_graph_2(n_feat)\n    mapper2 = GraphSAGENodeGenerator(G2, batch_size=n_batch, num_samples=[2, 2]).flow(G2.nodes())\n    assert (len(mapper2) == 3)\n    for mapper in [mapper1, mapper2]:\n        for ii in range(2):\n            (nf, nl) = mapper[ii]\n            assert (len(nf) == 3)\n            assert (nf[0].shape == (n_batch, 1, n_feat))\n            assert (nf[1].shape == (n_batch, 2, n_feat))\n            assert (nf[2].shape == (n_batch, (2 * 2), n_feat))\n            assert (nl is None)\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper1[len(mapper1)]\n    (nf, nl) = mapper2[(len(mapper2) - 1)]\n    assert (nf[0].shape == (1, 1, n_feat))\n    assert (nf[1].shape == (1, 2, n_feat))\n    assert (nf[2].shape == (1, (2 * 2), n_feat))\n    with pytest.raises(KeyError):\n        GraphSAGENodeGenerator(G1, batch_size=2, num_samples=[2, 2]).flow(['A', 'B'])", "masked_code": "def test_nodemapper_1():\n    n_feat = 4\n    n_batch = 2\n    G1 = example_graph(n_feat)\n    mapper1 = GraphSAGENodeGenerator(G1, batch_size=n_batch, num_samples=[2, 2]).flow(G1.nodes())\n    assert (len(mapper1) == 2)\n    G2 = example_graph_2(n_feat)\n    mapper2 = GraphSAGENodeGenerator(G2, batch_size=n_batch, num_samples=[2, 2]).flow(G2.nodes())\n    assert (len(mapper2) == 3)\n    for mapper in [mapper1, mapper2]:\n        for ii in range(2):\n            (nf, nl) = mapper[ii]\n            assert (len(nf) == 3)\n            assert (nf[0].shape == (n_batch, 1, n_feat))\n            assert (nf[1].shape == '???')\n            assert (nf[2].shape == (n_batch, (2 * 2), n_feat))\n            assert (nl is None)\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper1[len(mapper1)]\n    (nf, nl) = mapper2[(len(mapper2) - 1)]\n    assert (nf[0].shape == (1, 1, n_feat))\n    assert (nf[1].shape == (1, 2, n_feat))\n    assert (nf[2].shape == (1, (2 * 2), n_feat))\n    with pytest.raises(KeyError):\n        GraphSAGENodeGenerator(G1, batch_size=2, num_samples=[2, 2]).flow(['A', 'B'])", "ground_truth": "(n_batch, 2, n_feat)", "quality_analysis": {"complexity_score": 7, "left_complexity": 2, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_967", "reponame": "stellargraph", "testpath": "tests/mapper/test_node_mappers.py", "testname": "test_node_mappers.py", "classname": null, "funcname": "test_nodemapper_1", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper import *", "import networkx as nx", "import numpy as np", "import random", "import pytest", "import pandas as pd", "import scipy.sparse as sps", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, create_graph_features, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_nodemapper_1():\n    n_feat = 4\n    n_batch = 2\n    G1 = example_graph(n_feat)\n    mapper1 = GraphSAGENodeGenerator(G1, batch_size=n_batch, num_samples=[2, 2]).flow(G1.nodes())\n    assert (len(mapper1) == 2)\n    G2 = example_graph_2(n_feat)\n    mapper2 = GraphSAGENodeGenerator(G2, batch_size=n_batch, num_samples=[2, 2]).flow(G2.nodes())\n    assert (len(mapper2) == 3)\n    for mapper in [mapper1, mapper2]:\n        for ii in range(2):\n            (nf, nl) = mapper[ii]\n            assert (len(nf) == 3)\n            assert (nf[0].shape == (n_batch, 1, n_feat))\n            assert (nf[1].shape == (n_batch, 2, n_feat))\n            assert (nf[2].shape == (n_batch, (2 * 2), n_feat))\n            assert (nl is None)\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper1[len(mapper1)]\n    (nf, nl) = mapper2[(len(mapper2) - 1)]\n    assert (nf[0].shape == (1, 1, n_feat))\n    assert (nf[1].shape == (1, 2, n_feat))\n    assert (nf[2].shape == (1, (2 * 2), n_feat))\n    with pytest.raises(KeyError):\n        GraphSAGENodeGenerator(G1, batch_size=2, num_samples=[2, 2]).flow(['A', 'B'])", "masked_code": "def test_nodemapper_1():\n    n_feat = 4\n    n_batch = 2\n    G1 = example_graph(n_feat)\n    mapper1 = GraphSAGENodeGenerator(G1, batch_size=n_batch, num_samples=[2, 2]).flow(G1.nodes())\n    assert (len(mapper1) == 2)\n    G2 = example_graph_2(n_feat)\n    mapper2 = GraphSAGENodeGenerator(G2, batch_size=n_batch, num_samples=[2, 2]).flow(G2.nodes())\n    assert (len(mapper2) == 3)\n    for mapper in [mapper1, mapper2]:\n        for ii in range(2):\n            (nf, nl) = mapper[ii]\n            assert (len(nf) == 3)\n            assert (nf[0].shape == (n_batch, 1, n_feat))\n            assert (nf[1].shape == (n_batch, 2, n_feat))\n            assert (nf[2].shape == '???')\n            assert (nl is None)\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper1[len(mapper1)]\n    (nf, nl) = mapper2[(len(mapper2) - 1)]\n    assert (nf[0].shape == (1, 1, n_feat))\n    assert (nf[1].shape == (1, 2, n_feat))\n    assert (nf[2].shape == (1, (2 * 2), n_feat))\n    with pytest.raises(KeyError):\n        GraphSAGENodeGenerator(G1, batch_size=2, num_samples=[2, 2]).flow(['A', 'B'])", "ground_truth": "(n_batch, (2 * 2), n_feat)", "quality_analysis": {"complexity_score": 10, "left_complexity": 2, "right_complexity": 8, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_968", "reponame": "stellargraph", "testpath": "tests/mapper/test_node_mappers.py", "testname": "test_node_mappers.py", "classname": null, "funcname": "test_nodemapper_with_labels", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper import *", "import networkx as nx", "import numpy as np", "import random", "import pytest", "import pandas as pd", "import scipy.sparse as sps", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, create_graph_features, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_nodemapper_with_labels():\n    n_feat = 4\n    n_batch = 2\n    G2 = example_graph_2(n_feat)\n    nodes = list(G2.nodes())\n    labels = [(n * 2) for n in nodes]\n    gen = GraphSAGENodeGenerator(G2, batch_size=n_batch, num_samples=[2, 2]).flow(nodes, labels)\n    assert (len(gen) == 3)\n    for ii in range(3):\n        (nf, nl) = gen[ii]\n        assert (len(nf) == 3)\n        assert (nf[0].shape[1:] == (1, n_feat))\n        assert (nf[1].shape[1:] == (2, n_feat))\n        assert (nf[2].shape[1:] == ((2 * 2), n_feat))\n        assert all(((int(a) == int((2 * b))) for (a, b) in zip(nl, nf[0][(:, 0, 0)])))\n    with pytest.raises(IndexError):\n        (nf, nl) = gen[len(gen)]", "masked_code": "def test_nodemapper_with_labels():\n    n_feat = 4\n    n_batch = 2\n    G2 = example_graph_2(n_feat)\n    nodes = list(G2.nodes())\n    labels = [(n * 2) for n in nodes]\n    gen = GraphSAGENodeGenerator(G2, batch_size=n_batch, num_samples=[2, 2]).flow(nodes, labels)\n    assert (len(gen) == '???')\n    for ii in range(3):\n        (nf, nl) = gen[ii]\n        assert (len(nf) == 3)\n        assert (nf[0].shape[1:] == (1, n_feat))\n        assert (nf[1].shape[1:] == (2, n_feat))\n        assert (nf[2].shape[1:] == ((2 * 2), n_feat))\n        assert all(((int(a) == int((2 * b))) for (a, b) in zip(nl, nf[0][(:, 0, 0)])))\n    with pytest.raises(IndexError):\n        (nf, nl) = gen[len(gen)]", "ground_truth": "3", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_969", "reponame": "stellargraph", "testpath": "tests/mapper/test_node_mappers.py", "testname": "test_node_mappers.py", "classname": null, "funcname": "test_nodemapper_with_labels", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper import *", "import networkx as nx", "import numpy as np", "import random", "import pytest", "import pandas as pd", "import scipy.sparse as sps", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, create_graph_features, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_nodemapper_with_labels():\n    n_feat = 4\n    n_batch = 2\n    G2 = example_graph_2(n_feat)\n    nodes = list(G2.nodes())\n    labels = [(n * 2) for n in nodes]\n    gen = GraphSAGENodeGenerator(G2, batch_size=n_batch, num_samples=[2, 2]).flow(nodes, labels)\n    assert (len(gen) == 3)\n    for ii in range(3):\n        (nf, nl) = gen[ii]\n        assert (len(nf) == 3)\n        assert (nf[0].shape[1:] == (1, n_feat))\n        assert (nf[1].shape[1:] == (2, n_feat))\n        assert (nf[2].shape[1:] == ((2 * 2), n_feat))\n        assert all(((int(a) == int((2 * b))) for (a, b) in zip(nl, nf[0][(:, 0, 0)])))\n    with pytest.raises(IndexError):\n        (nf, nl) = gen[len(gen)]", "masked_code": "def test_nodemapper_with_labels():\n    n_feat = 4\n    n_batch = 2\n    G2 = example_graph_2(n_feat)\n    nodes = list(G2.nodes())\n    labels = [(n * 2) for n in nodes]\n    gen = GraphSAGENodeGenerator(G2, batch_size=n_batch, num_samples=[2, 2]).flow(nodes, labels)\n    assert (len(gen) == 3)\n    for ii in range(3):\n        (nf, nl) = gen[ii]\n        assert (len(nf) == '???')\n        assert (nf[0].shape[1:] == (1, n_feat))\n        assert (nf[1].shape[1:] == (2, n_feat))\n        assert (nf[2].shape[1:] == ((2 * 2), n_feat))\n        assert all(((int(a) == int((2 * b))) for (a, b) in zip(nl, nf[0][(:, 0, 0)])))\n    with pytest.raises(IndexError):\n        (nf, nl) = gen[len(gen)]", "ground_truth": "3", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_970", "reponame": "stellargraph", "testpath": "tests/mapper/test_node_mappers.py", "testname": "test_node_mappers.py", "classname": null, "funcname": "test_nodemapper_with_labels", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper import *", "import networkx as nx", "import numpy as np", "import random", "import pytest", "import pandas as pd", "import scipy.sparse as sps", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, create_graph_features, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_nodemapper_with_labels():\n    n_feat = 4\n    n_batch = 2\n    G2 = example_graph_2(n_feat)\n    nodes = list(G2.nodes())\n    labels = [(n * 2) for n in nodes]\n    gen = GraphSAGENodeGenerator(G2, batch_size=n_batch, num_samples=[2, 2]).flow(nodes, labels)\n    assert (len(gen) == 3)\n    for ii in range(3):\n        (nf, nl) = gen[ii]\n        assert (len(nf) == 3)\n        assert (nf[0].shape[1:] == (1, n_feat))\n        assert (nf[1].shape[1:] == (2, n_feat))\n        assert (nf[2].shape[1:] == ((2 * 2), n_feat))\n        assert all(((int(a) == int((2 * b))) for (a, b) in zip(nl, nf[0][(:, 0, 0)])))\n    with pytest.raises(IndexError):\n        (nf, nl) = gen[len(gen)]", "masked_code": "def test_nodemapper_with_labels():\n    n_feat = 4\n    n_batch = 2\n    G2 = example_graph_2(n_feat)\n    nodes = list(G2.nodes())\n    labels = [(n * 2) for n in nodes]\n    gen = GraphSAGENodeGenerator(G2, batch_size=n_batch, num_samples=[2, 2]).flow(nodes, labels)\n    assert (len(gen) == 3)\n    for ii in range(3):\n        (nf, nl) = gen[ii]\n        assert (len(nf) == 3)\n        assert (nf[0].shape[1:] == '???')\n        assert (nf[1].shape[1:] == (2, n_feat))\n        assert (nf[2].shape[1:] == ((2 * 2), n_feat))\n        assert all(((int(a) == int((2 * b))) for (a, b) in zip(nl, nf[0][(:, 0, 0)])))\n    with pytest.raises(IndexError):\n        (nf, nl) = gen[len(gen)]", "ground_truth": "(1, n_feat)", "quality_analysis": {"complexity_score": 9, "left_complexity": 5, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_971", "reponame": "stellargraph", "testpath": "tests/mapper/test_node_mappers.py", "testname": "test_node_mappers.py", "classname": null, "funcname": "test_nodemapper_with_labels", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper import *", "import networkx as nx", "import numpy as np", "import random", "import pytest", "import pandas as pd", "import scipy.sparse as sps", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, create_graph_features, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_nodemapper_with_labels():\n    n_feat = 4\n    n_batch = 2\n    G2 = example_graph_2(n_feat)\n    nodes = list(G2.nodes())\n    labels = [(n * 2) for n in nodes]\n    gen = GraphSAGENodeGenerator(G2, batch_size=n_batch, num_samples=[2, 2]).flow(nodes, labels)\n    assert (len(gen) == 3)\n    for ii in range(3):\n        (nf, nl) = gen[ii]\n        assert (len(nf) == 3)\n        assert (nf[0].shape[1:] == (1, n_feat))\n        assert (nf[1].shape[1:] == (2, n_feat))\n        assert (nf[2].shape[1:] == ((2 * 2), n_feat))\n        assert all(((int(a) == int((2 * b))) for (a, b) in zip(nl, nf[0][(:, 0, 0)])))\n    with pytest.raises(IndexError):\n        (nf, nl) = gen[len(gen)]", "masked_code": "def test_nodemapper_with_labels():\n    n_feat = 4\n    n_batch = 2\n    G2 = example_graph_2(n_feat)\n    nodes = list(G2.nodes())\n    labels = [(n * 2) for n in nodes]\n    gen = GraphSAGENodeGenerator(G2, batch_size=n_batch, num_samples=[2, 2]).flow(nodes, labels)\n    assert (len(gen) == 3)\n    for ii in range(3):\n        (nf, nl) = gen[ii]\n        assert (len(nf) == 3)\n        assert (nf[0].shape[1:] == (1, n_feat))\n        assert (nf[1].shape[1:] == '???')\n        assert (nf[2].shape[1:] == ((2 * 2), n_feat))\n        assert all(((int(a) == int((2 * b))) for (a, b) in zip(nl, nf[0][(:, 0, 0)])))\n    with pytest.raises(IndexError):\n        (nf, nl) = gen[len(gen)]", "ground_truth": "(2, n_feat)", "quality_analysis": {"complexity_score": 9, "left_complexity": 5, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_972", "reponame": "stellargraph", "testpath": "tests/mapper/test_node_mappers.py", "testname": "test_node_mappers.py", "classname": null, "funcname": "test_nodemapper_with_labels", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper import *", "import networkx as nx", "import numpy as np", "import random", "import pytest", "import pandas as pd", "import scipy.sparse as sps", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, create_graph_features, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_nodemapper_with_labels():\n    n_feat = 4\n    n_batch = 2\n    G2 = example_graph_2(n_feat)\n    nodes = list(G2.nodes())\n    labels = [(n * 2) for n in nodes]\n    gen = GraphSAGENodeGenerator(G2, batch_size=n_batch, num_samples=[2, 2]).flow(nodes, labels)\n    assert (len(gen) == 3)\n    for ii in range(3):\n        (nf, nl) = gen[ii]\n        assert (len(nf) == 3)\n        assert (nf[0].shape[1:] == (1, n_feat))\n        assert (nf[1].shape[1:] == (2, n_feat))\n        assert (nf[2].shape[1:] == ((2 * 2), n_feat))\n        assert all(((int(a) == int((2 * b))) for (a, b) in zip(nl, nf[0][(:, 0, 0)])))\n    with pytest.raises(IndexError):\n        (nf, nl) = gen[len(gen)]", "masked_code": "def test_nodemapper_with_labels():\n    n_feat = 4\n    n_batch = 2\n    G2 = example_graph_2(n_feat)\n    nodes = list(G2.nodes())\n    labels = [(n * 2) for n in nodes]\n    gen = GraphSAGENodeGenerator(G2, batch_size=n_batch, num_samples=[2, 2]).flow(nodes, labels)\n    assert (len(gen) == 3)\n    for ii in range(3):\n        (nf, nl) = gen[ii]\n        assert (len(nf) == 3)\n        assert (nf[0].shape[1:] == (1, n_feat))\n        assert (nf[1].shape[1:] == (2, n_feat))\n        assert (nf[2].shape[1:] == '???')\n        assert all(((int(a) == int((2 * b))) for (a, b) in zip(nl, nf[0][(:, 0, 0)])))\n    with pytest.raises(IndexError):\n        (nf, nl) = gen[len(gen)]", "ground_truth": "((2 * 2), n_feat)", "quality_analysis": {"complexity_score": 12, "left_complexity": 5, "right_complexity": 7, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_973", "reponame": "stellargraph", "testpath": "tests/mapper/test_node_mappers.py", "testname": "test_node_mappers.py", "classname": null, "funcname": "test_nodemapper_zero_samples", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper import *", "import networkx as nx", "import numpy as np", "import random", "import pytest", "import pandas as pd", "import scipy.sparse as sps", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, create_graph_features, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_nodemapper_zero_samples():\n    n_feat = 4\n    n_batch = 2\n    G = example_graph(feature_size=n_feat)\n    mapper = GraphSAGENodeGenerator(G, batch_size=n_batch, num_samples=[0]).flow(G.nodes())\n    assert (len(mapper) == 2)\n    for ii in range(len(mapper)):\n        (nf, nl) = mapper[ii]\n        assert (len(nf) == 2)\n        assert (nf[0].shape == (n_batch, 1, n_feat))\n        assert (nf[1].shape == (n_batch, 0, n_feat))\n        assert (nl is None)\n    G = example_graph(feature_size=n_feat)\n    mapper = GraphSAGENodeGenerator(G, batch_size=n_batch, num_samples=[0, 0]).flow(G.nodes())\n    assert (len(mapper) == 2)\n    for ii in range(len(mapper)):\n        (nf, nl) = mapper[ii]\n        assert (len(nf) == 3)\n        assert (nf[0].shape == (n_batch, 1, n_feat))\n        assert (nf[1].shape == (n_batch, 0, n_feat))\n        assert (nf[1].shape == (n_batch, 0, n_feat))\n        assert (nl is None)", "masked_code": "def test_nodemapper_zero_samples():\n    n_feat = 4\n    n_batch = 2\n    G = example_graph(feature_size=n_feat)\n    mapper = GraphSAGENodeGenerator(G, batch_size=n_batch, num_samples=[0]).flow(G.nodes())\n    assert (len(mapper) == 2)\n    for ii in range(len(mapper)):\n        (nf, nl) = mapper[ii]\n        assert (len(nf) == 2)\n        assert (nf[0].shape == '???')\n        assert (nf[1].shape == (n_batch, 0, n_feat))\n        assert (nl is None)\n    G = example_graph(feature_size=n_feat)\n    mapper = GraphSAGENodeGenerator(G, batch_size=n_batch, num_samples=[0, 0]).flow(G.nodes())\n    assert (len(mapper) == 2)\n    for ii in range(len(mapper)):\n        (nf, nl) = mapper[ii]\n        assert (len(nf) == 3)\n        assert (nf[0].shape == (n_batch, 1, n_feat))\n        assert (nf[1].shape == (n_batch, 0, n_feat))\n        assert (nf[1].shape == (n_batch, 0, n_feat))\n        assert (nl is None)", "ground_truth": "(n_batch, 1, n_feat)", "quality_analysis": {"complexity_score": 7, "left_complexity": 2, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_974", "reponame": "stellargraph", "testpath": "tests/mapper/test_node_mappers.py", "testname": "test_node_mappers.py", "classname": null, "funcname": "test_nodemapper_zero_samples", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper import *", "import networkx as nx", "import numpy as np", "import random", "import pytest", "import pandas as pd", "import scipy.sparse as sps", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, create_graph_features, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_nodemapper_zero_samples():\n    n_feat = 4\n    n_batch = 2\n    G = example_graph(feature_size=n_feat)\n    mapper = GraphSAGENodeGenerator(G, batch_size=n_batch, num_samples=[0]).flow(G.nodes())\n    assert (len(mapper) == 2)\n    for ii in range(len(mapper)):\n        (nf, nl) = mapper[ii]\n        assert (len(nf) == 2)\n        assert (nf[0].shape == (n_batch, 1, n_feat))\n        assert (nf[1].shape == (n_batch, 0, n_feat))\n        assert (nl is None)\n    G = example_graph(feature_size=n_feat)\n    mapper = GraphSAGENodeGenerator(G, batch_size=n_batch, num_samples=[0, 0]).flow(G.nodes())\n    assert (len(mapper) == 2)\n    for ii in range(len(mapper)):\n        (nf, nl) = mapper[ii]\n        assert (len(nf) == 3)\n        assert (nf[0].shape == (n_batch, 1, n_feat))\n        assert (nf[1].shape == (n_batch, 0, n_feat))\n        assert (nf[1].shape == (n_batch, 0, n_feat))\n        assert (nl is None)", "masked_code": "def test_nodemapper_zero_samples():\n    n_feat = 4\n    n_batch = 2\n    G = example_graph(feature_size=n_feat)\n    mapper = GraphSAGENodeGenerator(G, batch_size=n_batch, num_samples=[0]).flow(G.nodes())\n    assert (len(mapper) == 2)\n    for ii in range(len(mapper)):\n        (nf, nl) = mapper[ii]\n        assert (len(nf) == 2)\n        assert (nf[0].shape == (n_batch, 1, n_feat))\n        assert (nf[1].shape == '???')\n        assert (nl is None)\n    G = example_graph(feature_size=n_feat)\n    mapper = GraphSAGENodeGenerator(G, batch_size=n_batch, num_samples=[0, 0]).flow(G.nodes())\n    assert (len(mapper) == 2)\n    for ii in range(len(mapper)):\n        (nf, nl) = mapper[ii]\n        assert (len(nf) == 3)\n        assert (nf[0].shape == (n_batch, 1, n_feat))\n        assert (nf[1].shape == (n_batch, 0, n_feat))\n        assert (nf[1].shape == (n_batch, 0, n_feat))\n        assert (nl is None)", "ground_truth": "(n_batch, 0, n_feat)", "quality_analysis": {"complexity_score": 7, "left_complexity": 2, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_975", "reponame": "stellargraph", "testpath": "tests/mapper/test_node_mappers.py", "testname": "test_node_mappers.py", "classname": null, "funcname": "test_nodemapper_zero_samples", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper import *", "import networkx as nx", "import numpy as np", "import random", "import pytest", "import pandas as pd", "import scipy.sparse as sps", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, create_graph_features, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_nodemapper_zero_samples():\n    n_feat = 4\n    n_batch = 2\n    G = example_graph(feature_size=n_feat)\n    mapper = GraphSAGENodeGenerator(G, batch_size=n_batch, num_samples=[0]).flow(G.nodes())\n    assert (len(mapper) == 2)\n    for ii in range(len(mapper)):\n        (nf, nl) = mapper[ii]\n        assert (len(nf) == 2)\n        assert (nf[0].shape == (n_batch, 1, n_feat))\n        assert (nf[1].shape == (n_batch, 0, n_feat))\n        assert (nl is None)\n    G = example_graph(feature_size=n_feat)\n    mapper = GraphSAGENodeGenerator(G, batch_size=n_batch, num_samples=[0, 0]).flow(G.nodes())\n    assert (len(mapper) == 2)\n    for ii in range(len(mapper)):\n        (nf, nl) = mapper[ii]\n        assert (len(nf) == 3)\n        assert (nf[0].shape == (n_batch, 1, n_feat))\n        assert (nf[1].shape == (n_batch, 0, n_feat))\n        assert (nf[1].shape == (n_batch, 0, n_feat))\n        assert (nl is None)", "masked_code": "def test_nodemapper_zero_samples():\n    n_feat = 4\n    n_batch = 2\n    G = example_graph(feature_size=n_feat)\n    mapper = GraphSAGENodeGenerator(G, batch_size=n_batch, num_samples=[0]).flow(G.nodes())\n    assert (len(mapper) == 2)\n    for ii in range(len(mapper)):\n        (nf, nl) = mapper[ii]\n        assert (len(nf) == 2)\n        assert (nf[0].shape == (n_batch, 1, n_feat))\n        assert (nf[1].shape == (n_batch, 0, n_feat))\n        assert (nl is None)\n    G = example_graph(feature_size=n_feat)\n    mapper = GraphSAGENodeGenerator(G, batch_size=n_batch, num_samples=[0, 0]).flow(G.nodes())\n    assert (len(mapper) == 2)\n    for ii in range(len(mapper)):\n        (nf, nl) = mapper[ii]\n        assert (len(nf) == '???')\n        assert (nf[0].shape == (n_batch, 1, n_feat))\n        assert (nf[1].shape == (n_batch, 0, n_feat))\n        assert (nf[1].shape == (n_batch, 0, n_feat))\n        assert (nl is None)", "ground_truth": "3", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_976", "reponame": "stellargraph", "testpath": "tests/mapper/test_node_mappers.py", "testname": "test_node_mappers.py", "classname": null, "funcname": "test_nodemapper_zero_samples", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper import *", "import networkx as nx", "import numpy as np", "import random", "import pytest", "import pandas as pd", "import scipy.sparse as sps", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, create_graph_features, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_nodemapper_zero_samples():\n    n_feat = 4\n    n_batch = 2\n    G = example_graph(feature_size=n_feat)\n    mapper = GraphSAGENodeGenerator(G, batch_size=n_batch, num_samples=[0]).flow(G.nodes())\n    assert (len(mapper) == 2)\n    for ii in range(len(mapper)):\n        (nf, nl) = mapper[ii]\n        assert (len(nf) == 2)\n        assert (nf[0].shape == (n_batch, 1, n_feat))\n        assert (nf[1].shape == (n_batch, 0, n_feat))\n        assert (nl is None)\n    G = example_graph(feature_size=n_feat)\n    mapper = GraphSAGENodeGenerator(G, batch_size=n_batch, num_samples=[0, 0]).flow(G.nodes())\n    assert (len(mapper) == 2)\n    for ii in range(len(mapper)):\n        (nf, nl) = mapper[ii]\n        assert (len(nf) == 3)\n        assert (nf[0].shape == (n_batch, 1, n_feat))\n        assert (nf[1].shape == (n_batch, 0, n_feat))\n        assert (nf[1].shape == (n_batch, 0, n_feat))\n        assert (nl is None)", "masked_code": "def test_nodemapper_zero_samples():\n    n_feat = 4\n    n_batch = 2\n    G = example_graph(feature_size=n_feat)\n    mapper = GraphSAGENodeGenerator(G, batch_size=n_batch, num_samples=[0]).flow(G.nodes())\n    assert (len(mapper) == 2)\n    for ii in range(len(mapper)):\n        (nf, nl) = mapper[ii]\n        assert (len(nf) == 2)\n        assert (nf[0].shape == (n_batch, 1, n_feat))\n        assert (nf[1].shape == (n_batch, 0, n_feat))\n        assert (nl is None)\n    G = example_graph(feature_size=n_feat)\n    mapper = GraphSAGENodeGenerator(G, batch_size=n_batch, num_samples=[0, 0]).flow(G.nodes())\n    assert (len(mapper) == 2)\n    for ii in range(len(mapper)):\n        (nf, nl) = mapper[ii]\n        assert (len(nf) == 3)\n        assert (nf[0].shape == '???')\n        assert (nf[1].shape == (n_batch, 0, n_feat))\n        assert (nf[1].shape == (n_batch, 0, n_feat))\n        assert (nl is None)", "ground_truth": "(n_batch, 1, n_feat)", "quality_analysis": {"complexity_score": 7, "left_complexity": 2, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_977", "reponame": "stellargraph", "testpath": "tests/mapper/test_node_mappers.py", "testname": "test_node_mappers.py", "classname": null, "funcname": "test_nodemapper_zero_samples", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper import *", "import networkx as nx", "import numpy as np", "import random", "import pytest", "import pandas as pd", "import scipy.sparse as sps", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, create_graph_features, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_nodemapper_zero_samples():\n    n_feat = 4\n    n_batch = 2\n    G = example_graph(feature_size=n_feat)\n    mapper = GraphSAGENodeGenerator(G, batch_size=n_batch, num_samples=[0]).flow(G.nodes())\n    assert (len(mapper) == 2)\n    for ii in range(len(mapper)):\n        (nf, nl) = mapper[ii]\n        assert (len(nf) == 2)\n        assert (nf[0].shape == (n_batch, 1, n_feat))\n        assert (nf[1].shape == (n_batch, 0, n_feat))\n        assert (nl is None)\n    G = example_graph(feature_size=n_feat)\n    mapper = GraphSAGENodeGenerator(G, batch_size=n_batch, num_samples=[0, 0]).flow(G.nodes())\n    assert (len(mapper) == 2)\n    for ii in range(len(mapper)):\n        (nf, nl) = mapper[ii]\n        assert (len(nf) == 3)\n        assert (nf[0].shape == (n_batch, 1, n_feat))\n        assert (nf[1].shape == (n_batch, 0, n_feat))\n        assert (nf[1].shape == (n_batch, 0, n_feat))\n        assert (nl is None)", "masked_code": "def test_nodemapper_zero_samples():\n    n_feat = 4\n    n_batch = 2\n    G = example_graph(feature_size=n_feat)\n    mapper = GraphSAGENodeGenerator(G, batch_size=n_batch, num_samples=[0]).flow(G.nodes())\n    assert (len(mapper) == 2)\n    for ii in range(len(mapper)):\n        (nf, nl) = mapper[ii]\n        assert (len(nf) == 2)\n        assert (nf[0].shape == (n_batch, 1, n_feat))\n        assert (nf[1].shape == (n_batch, 0, n_feat))\n        assert (nl is None)\n    G = example_graph(feature_size=n_feat)\n    mapper = GraphSAGENodeGenerator(G, batch_size=n_batch, num_samples=[0, 0]).flow(G.nodes())\n    assert (len(mapper) == 2)\n    for ii in range(len(mapper)):\n        (nf, nl) = mapper[ii]\n        assert (len(nf) == 3)\n        assert (nf[0].shape == (n_batch, 1, n_feat))\n        assert (nf[1].shape == '???')\n        assert (nf[1].shape == (n_batch, 0, n_feat))\n        assert (nl is None)", "ground_truth": "(n_batch, 0, n_feat)", "quality_analysis": {"complexity_score": 7, "left_complexity": 2, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_978", "reponame": "stellargraph", "testpath": "tests/mapper/test_node_mappers.py", "testname": "test_node_mappers.py", "classname": null, "funcname": "test_nodemapper_zero_samples", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper import *", "import networkx as nx", "import numpy as np", "import random", "import pytest", "import pandas as pd", "import scipy.sparse as sps", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, create_graph_features, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_nodemapper_zero_samples():\n    n_feat = 4\n    n_batch = 2\n    G = example_graph(feature_size=n_feat)\n    mapper = GraphSAGENodeGenerator(G, batch_size=n_batch, num_samples=[0]).flow(G.nodes())\n    assert (len(mapper) == 2)\n    for ii in range(len(mapper)):\n        (nf, nl) = mapper[ii]\n        assert (len(nf) == 2)\n        assert (nf[0].shape == (n_batch, 1, n_feat))\n        assert (nf[1].shape == (n_batch, 0, n_feat))\n        assert (nl is None)\n    G = example_graph(feature_size=n_feat)\n    mapper = GraphSAGENodeGenerator(G, batch_size=n_batch, num_samples=[0, 0]).flow(G.nodes())\n    assert (len(mapper) == 2)\n    for ii in range(len(mapper)):\n        (nf, nl) = mapper[ii]\n        assert (len(nf) == 3)\n        assert (nf[0].shape == (n_batch, 1, n_feat))\n        assert (nf[1].shape == (n_batch, 0, n_feat))\n        assert (nf[1].shape == (n_batch, 0, n_feat))\n        assert (nl is None)", "masked_code": "def test_nodemapper_zero_samples():\n    n_feat = 4\n    n_batch = 2\n    G = example_graph(feature_size=n_feat)\n    mapper = GraphSAGENodeGenerator(G, batch_size=n_batch, num_samples=[0]).flow(G.nodes())\n    assert (len(mapper) == 2)\n    for ii in range(len(mapper)):\n        (nf, nl) = mapper[ii]\n        assert (len(nf) == 2)\n        assert (nf[0].shape == (n_batch, 1, n_feat))\n        assert (nf[1].shape == (n_batch, 0, n_feat))\n        assert (nl is None)\n    G = example_graph(feature_size=n_feat)\n    mapper = GraphSAGENodeGenerator(G, batch_size=n_batch, num_samples=[0, 0]).flow(G.nodes())\n    assert (len(mapper) == 2)\n    for ii in range(len(mapper)):\n        (nf, nl) = mapper[ii]\n        assert (len(nf) == 3)\n        assert (nf[0].shape == (n_batch, 1, n_feat))\n        assert (nf[1].shape == (n_batch, 0, n_feat))\n        assert (nf[1].shape == '???')\n        assert (nl is None)", "ground_truth": "(n_batch, 0, n_feat)", "quality_analysis": {"complexity_score": 7, "left_complexity": 2, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_979", "reponame": "stellargraph", "testpath": "tests/mapper/test_node_mappers.py", "testname": "test_node_mappers.py", "classname": null, "funcname": "test_nodemapper_isolated_nodes", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper import *", "import networkx as nx", "import numpy as np", "import random", "import pytest", "import pandas as pd", "import scipy.sparse as sps", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, create_graph_features, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_nodemapper_isolated_nodes():\n    n_feat = 4\n    n_batch = 2\n    G = example_graph_random(feature_size=n_feat, n_nodes=6, n_isolates=1, n_edges=1000)\n    Gnx = G.to_networkx()\n    ccs = list(nx.connected_components(Gnx))\n    assert (len(ccs) == 2)\n    n_isolates = [5]\n    assert (nx.degree(Gnx, n_isolates[0]) == 0)\n    for head_nodes in [[1], [2], n_isolates]:\n        mapper = GraphSAGENodeGenerator(G, batch_size=n_batch, num_samples=[2, 2]).flow(head_nodes)\n        (nf, nl) = mapper[0]\n        assert (nf[0].shape == (1, 1, n_feat))\n        assert (nf[1].shape == (1, 2, n_feat))\n        assert (nf[2].shape == (1, 4, n_feat))\n    mapper = GraphSAGENodeGenerator(G, batch_size=n_batch, num_samples=[2, 2]).flow([1, 5])\n    (nf, nl) = mapper[0]\n    assert (nf[0].shape == (2, 1, n_feat))\n    assert (nf[1].shape == (2, 2, n_feat))\n    assert (nf[2].shape == (2, 4, n_feat))\n    assert (pytest.approx(nf[1][1]) == 0)\n    assert (pytest.approx(nf[2][2:]) == 0)", "masked_code": "def test_nodemapper_isolated_nodes():\n    n_feat = 4\n    n_batch = 2\n    G = example_graph_random(feature_size=n_feat, n_nodes=6, n_isolates=1, n_edges=1000)\n    Gnx = G.to_networkx()\n    ccs = list(nx.connected_components(Gnx))\n    assert (len(ccs) == 2)\n    n_isolates = [5]\n    assert (nx.degree(Gnx, n_isolates[0]) == 0)\n    for head_nodes in [[1], [2], n_isolates]:\n        mapper = GraphSAGENodeGenerator(G, batch_size=n_batch, num_samples=[2, 2]).flow(head_nodes)\n        (nf, nl) = mapper[0]\n        assert (nf[0].shape == (1, 1, n_feat))\n        assert (nf[1].shape == (1, 2, n_feat))\n        assert (nf[2].shape == (1, 4, n_feat))\n    mapper = GraphSAGENodeGenerator(G, batch_size=n_batch, num_samples=[2, 2]).flow([1, 5])\n    (nf, nl) = mapper[0]\n    assert (nf[0].shape == '???')\n    assert (nf[1].shape == (2, 2, n_feat))\n    assert (nf[2].shape == (2, 4, n_feat))\n    assert (pytest.approx(nf[1][1]) == 0)\n    assert (pytest.approx(nf[2][2:]) == 0)", "ground_truth": "(2, 1, n_feat)", "quality_analysis": {"complexity_score": 7, "left_complexity": 2, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_980", "reponame": "stellargraph", "testpath": "tests/mapper/test_node_mappers.py", "testname": "test_node_mappers.py", "classname": null, "funcname": "test_nodemapper_isolated_nodes", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper import *", "import networkx as nx", "import numpy as np", "import random", "import pytest", "import pandas as pd", "import scipy.sparse as sps", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, create_graph_features, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_nodemapper_isolated_nodes():\n    n_feat = 4\n    n_batch = 2\n    G = example_graph_random(feature_size=n_feat, n_nodes=6, n_isolates=1, n_edges=1000)\n    Gnx = G.to_networkx()\n    ccs = list(nx.connected_components(Gnx))\n    assert (len(ccs) == 2)\n    n_isolates = [5]\n    assert (nx.degree(Gnx, n_isolates[0]) == 0)\n    for head_nodes in [[1], [2], n_isolates]:\n        mapper = GraphSAGENodeGenerator(G, batch_size=n_batch, num_samples=[2, 2]).flow(head_nodes)\n        (nf, nl) = mapper[0]\n        assert (nf[0].shape == (1, 1, n_feat))\n        assert (nf[1].shape == (1, 2, n_feat))\n        assert (nf[2].shape == (1, 4, n_feat))\n    mapper = GraphSAGENodeGenerator(G, batch_size=n_batch, num_samples=[2, 2]).flow([1, 5])\n    (nf, nl) = mapper[0]\n    assert (nf[0].shape == (2, 1, n_feat))\n    assert (nf[1].shape == (2, 2, n_feat))\n    assert (nf[2].shape == (2, 4, n_feat))\n    assert (pytest.approx(nf[1][1]) == 0)\n    assert (pytest.approx(nf[2][2:]) == 0)", "masked_code": "def test_nodemapper_isolated_nodes():\n    n_feat = 4\n    n_batch = 2\n    G = example_graph_random(feature_size=n_feat, n_nodes=6, n_isolates=1, n_edges=1000)\n    Gnx = G.to_networkx()\n    ccs = list(nx.connected_components(Gnx))\n    assert (len(ccs) == 2)\n    n_isolates = [5]\n    assert (nx.degree(Gnx, n_isolates[0]) == 0)\n    for head_nodes in [[1], [2], n_isolates]:\n        mapper = GraphSAGENodeGenerator(G, batch_size=n_batch, num_samples=[2, 2]).flow(head_nodes)\n        (nf, nl) = mapper[0]\n        assert (nf[0].shape == (1, 1, n_feat))\n        assert (nf[1].shape == (1, 2, n_feat))\n        assert (nf[2].shape == (1, 4, n_feat))\n    mapper = GraphSAGENodeGenerator(G, batch_size=n_batch, num_samples=[2, 2]).flow([1, 5])\n    (nf, nl) = mapper[0]\n    assert (nf[0].shape == (2, 1, n_feat))\n    assert (nf[1].shape == '???')\n    assert (nf[2].shape == (2, 4, n_feat))\n    assert (pytest.approx(nf[1][1]) == 0)\n    assert (pytest.approx(nf[2][2:]) == 0)", "ground_truth": "(2, 2, n_feat)", "quality_analysis": {"complexity_score": 7, "left_complexity": 2, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_981", "reponame": "stellargraph", "testpath": "tests/mapper/test_node_mappers.py", "testname": "test_node_mappers.py", "classname": null, "funcname": "test_nodemapper_isolated_nodes", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper import *", "import networkx as nx", "import numpy as np", "import random", "import pytest", "import pandas as pd", "import scipy.sparse as sps", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, create_graph_features, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_nodemapper_isolated_nodes():\n    n_feat = 4\n    n_batch = 2\n    G = example_graph_random(feature_size=n_feat, n_nodes=6, n_isolates=1, n_edges=1000)\n    Gnx = G.to_networkx()\n    ccs = list(nx.connected_components(Gnx))\n    assert (len(ccs) == 2)\n    n_isolates = [5]\n    assert (nx.degree(Gnx, n_isolates[0]) == 0)\n    for head_nodes in [[1], [2], n_isolates]:\n        mapper = GraphSAGENodeGenerator(G, batch_size=n_batch, num_samples=[2, 2]).flow(head_nodes)\n        (nf, nl) = mapper[0]\n        assert (nf[0].shape == (1, 1, n_feat))\n        assert (nf[1].shape == (1, 2, n_feat))\n        assert (nf[2].shape == (1, 4, n_feat))\n    mapper = GraphSAGENodeGenerator(G, batch_size=n_batch, num_samples=[2, 2]).flow([1, 5])\n    (nf, nl) = mapper[0]\n    assert (nf[0].shape == (2, 1, n_feat))\n    assert (nf[1].shape == (2, 2, n_feat))\n    assert (nf[2].shape == (2, 4, n_feat))\n    assert (pytest.approx(nf[1][1]) == 0)\n    assert (pytest.approx(nf[2][2:]) == 0)", "masked_code": "def test_nodemapper_isolated_nodes():\n    n_feat = 4\n    n_batch = 2\n    G = example_graph_random(feature_size=n_feat, n_nodes=6, n_isolates=1, n_edges=1000)\n    Gnx = G.to_networkx()\n    ccs = list(nx.connected_components(Gnx))\n    assert (len(ccs) == 2)\n    n_isolates = [5]\n    assert (nx.degree(Gnx, n_isolates[0]) == 0)\n    for head_nodes in [[1], [2], n_isolates]:\n        mapper = GraphSAGENodeGenerator(G, batch_size=n_batch, num_samples=[2, 2]).flow(head_nodes)\n        (nf, nl) = mapper[0]\n        assert (nf[0].shape == (1, 1, n_feat))\n        assert (nf[1].shape == (1, 2, n_feat))\n        assert (nf[2].shape == (1, 4, n_feat))\n    mapper = GraphSAGENodeGenerator(G, batch_size=n_batch, num_samples=[2, 2]).flow([1, 5])\n    (nf, nl) = mapper[0]\n    assert (nf[0].shape == (2, 1, n_feat))\n    assert (nf[1].shape == (2, 2, n_feat))\n    assert (nf[2].shape == '???')\n    assert (pytest.approx(nf[1][1]) == 0)\n    assert (pytest.approx(nf[2][2:]) == 0)", "ground_truth": "(2, 4, n_feat)", "quality_analysis": {"complexity_score": 7, "left_complexity": 2, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_982", "reponame": "stellargraph", "testpath": "tests/mapper/test_node_mappers.py", "testname": "test_node_mappers.py", "classname": null, "funcname": "test_nodemapper_isolated_nodes", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper import *", "import networkx as nx", "import numpy as np", "import random", "import pytest", "import pandas as pd", "import scipy.sparse as sps", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, create_graph_features, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_nodemapper_isolated_nodes():\n    n_feat = 4\n    n_batch = 2\n    G = example_graph_random(feature_size=n_feat, n_nodes=6, n_isolates=1, n_edges=1000)\n    Gnx = G.to_networkx()\n    ccs = list(nx.connected_components(Gnx))\n    assert (len(ccs) == 2)\n    n_isolates = [5]\n    assert (nx.degree(Gnx, n_isolates[0]) == 0)\n    for head_nodes in [[1], [2], n_isolates]:\n        mapper = GraphSAGENodeGenerator(G, batch_size=n_batch, num_samples=[2, 2]).flow(head_nodes)\n        (nf, nl) = mapper[0]\n        assert (nf[0].shape == (1, 1, n_feat))\n        assert (nf[1].shape == (1, 2, n_feat))\n        assert (nf[2].shape == (1, 4, n_feat))\n    mapper = GraphSAGENodeGenerator(G, batch_size=n_batch, num_samples=[2, 2]).flow([1, 5])\n    (nf, nl) = mapper[0]\n    assert (nf[0].shape == (2, 1, n_feat))\n    assert (nf[1].shape == (2, 2, n_feat))\n    assert (nf[2].shape == (2, 4, n_feat))\n    assert (pytest.approx(nf[1][1]) == 0)\n    assert (pytest.approx(nf[2][2:]) == 0)", "masked_code": "def test_nodemapper_isolated_nodes():\n    n_feat = 4\n    n_batch = 2\n    G = example_graph_random(feature_size=n_feat, n_nodes=6, n_isolates=1, n_edges=1000)\n    Gnx = G.to_networkx()\n    ccs = list(nx.connected_components(Gnx))\n    assert (len(ccs) == 2)\n    n_isolates = [5]\n    assert (nx.degree(Gnx, n_isolates[0]) == 0)\n    for head_nodes in [[1], [2], n_isolates]:\n        mapper = GraphSAGENodeGenerator(G, batch_size=n_batch, num_samples=[2, 2]).flow(head_nodes)\n        (nf, nl) = mapper[0]\n        assert (nf[0].shape == '???')\n        assert (nf[1].shape == (1, 2, n_feat))\n        assert (nf[2].shape == (1, 4, n_feat))\n    mapper = GraphSAGENodeGenerator(G, batch_size=n_batch, num_samples=[2, 2]).flow([1, 5])\n    (nf, nl) = mapper[0]\n    assert (nf[0].shape == (2, 1, n_feat))\n    assert (nf[1].shape == (2, 2, n_feat))\n    assert (nf[2].shape == (2, 4, n_feat))\n    assert (pytest.approx(nf[1][1]) == 0)\n    assert (pytest.approx(nf[2][2:]) == 0)", "ground_truth": "(1, 1, n_feat)", "quality_analysis": {"complexity_score": 7, "left_complexity": 2, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_983", "reponame": "stellargraph", "testpath": "tests/mapper/test_node_mappers.py", "testname": "test_node_mappers.py", "classname": null, "funcname": "test_nodemapper_isolated_nodes", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper import *", "import networkx as nx", "import numpy as np", "import random", "import pytest", "import pandas as pd", "import scipy.sparse as sps", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, create_graph_features, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_nodemapper_isolated_nodes():\n    n_feat = 4\n    n_batch = 2\n    G = example_graph_random(feature_size=n_feat, n_nodes=6, n_isolates=1, n_edges=1000)\n    Gnx = G.to_networkx()\n    ccs = list(nx.connected_components(Gnx))\n    assert (len(ccs) == 2)\n    n_isolates = [5]\n    assert (nx.degree(Gnx, n_isolates[0]) == 0)\n    for head_nodes in [[1], [2], n_isolates]:\n        mapper = GraphSAGENodeGenerator(G, batch_size=n_batch, num_samples=[2, 2]).flow(head_nodes)\n        (nf, nl) = mapper[0]\n        assert (nf[0].shape == (1, 1, n_feat))\n        assert (nf[1].shape == (1, 2, n_feat))\n        assert (nf[2].shape == (1, 4, n_feat))\n    mapper = GraphSAGENodeGenerator(G, batch_size=n_batch, num_samples=[2, 2]).flow([1, 5])\n    (nf, nl) = mapper[0]\n    assert (nf[0].shape == (2, 1, n_feat))\n    assert (nf[1].shape == (2, 2, n_feat))\n    assert (nf[2].shape == (2, 4, n_feat))\n    assert (pytest.approx(nf[1][1]) == 0)\n    assert (pytest.approx(nf[2][2:]) == 0)", "masked_code": "def test_nodemapper_isolated_nodes():\n    n_feat = 4\n    n_batch = 2\n    G = example_graph_random(feature_size=n_feat, n_nodes=6, n_isolates=1, n_edges=1000)\n    Gnx = G.to_networkx()\n    ccs = list(nx.connected_components(Gnx))\n    assert (len(ccs) == 2)\n    n_isolates = [5]\n    assert (nx.degree(Gnx, n_isolates[0]) == 0)\n    for head_nodes in [[1], [2], n_isolates]:\n        mapper = GraphSAGENodeGenerator(G, batch_size=n_batch, num_samples=[2, 2]).flow(head_nodes)\n        (nf, nl) = mapper[0]\n        assert (nf[0].shape == (1, 1, n_feat))\n        assert (nf[1].shape == '???')\n        assert (nf[2].shape == (1, 4, n_feat))\n    mapper = GraphSAGENodeGenerator(G, batch_size=n_batch, num_samples=[2, 2]).flow([1, 5])\n    (nf, nl) = mapper[0]\n    assert (nf[0].shape == (2, 1, n_feat))\n    assert (nf[1].shape == (2, 2, n_feat))\n    assert (nf[2].shape == (2, 4, n_feat))\n    assert (pytest.approx(nf[1][1]) == 0)\n    assert (pytest.approx(nf[2][2:]) == 0)", "ground_truth": "(1, 2, n_feat)", "quality_analysis": {"complexity_score": 7, "left_complexity": 2, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_984", "reponame": "stellargraph", "testpath": "tests/mapper/test_node_mappers.py", "testname": "test_node_mappers.py", "classname": null, "funcname": "test_nodemapper_isolated_nodes", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper import *", "import networkx as nx", "import numpy as np", "import random", "import pytest", "import pandas as pd", "import scipy.sparse as sps", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, create_graph_features, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_nodemapper_isolated_nodes():\n    n_feat = 4\n    n_batch = 2\n    G = example_graph_random(feature_size=n_feat, n_nodes=6, n_isolates=1, n_edges=1000)\n    Gnx = G.to_networkx()\n    ccs = list(nx.connected_components(Gnx))\n    assert (len(ccs) == 2)\n    n_isolates = [5]\n    assert (nx.degree(Gnx, n_isolates[0]) == 0)\n    for head_nodes in [[1], [2], n_isolates]:\n        mapper = GraphSAGENodeGenerator(G, batch_size=n_batch, num_samples=[2, 2]).flow(head_nodes)\n        (nf, nl) = mapper[0]\n        assert (nf[0].shape == (1, 1, n_feat))\n        assert (nf[1].shape == (1, 2, n_feat))\n        assert (nf[2].shape == (1, 4, n_feat))\n    mapper = GraphSAGENodeGenerator(G, batch_size=n_batch, num_samples=[2, 2]).flow([1, 5])\n    (nf, nl) = mapper[0]\n    assert (nf[0].shape == (2, 1, n_feat))\n    assert (nf[1].shape == (2, 2, n_feat))\n    assert (nf[2].shape == (2, 4, n_feat))\n    assert (pytest.approx(nf[1][1]) == 0)\n    assert (pytest.approx(nf[2][2:]) == 0)", "masked_code": "def test_nodemapper_isolated_nodes():\n    n_feat = 4\n    n_batch = 2\n    G = example_graph_random(feature_size=n_feat, n_nodes=6, n_isolates=1, n_edges=1000)\n    Gnx = G.to_networkx()\n    ccs = list(nx.connected_components(Gnx))\n    assert (len(ccs) == 2)\n    n_isolates = [5]\n    assert (nx.degree(Gnx, n_isolates[0]) == 0)\n    for head_nodes in [[1], [2], n_isolates]:\n        mapper = GraphSAGENodeGenerator(G, batch_size=n_batch, num_samples=[2, 2]).flow(head_nodes)\n        (nf, nl) = mapper[0]\n        assert (nf[0].shape == (1, 1, n_feat))\n        assert (nf[1].shape == (1, 2, n_feat))\n        assert (nf[2].shape == '???')\n    mapper = GraphSAGENodeGenerator(G, batch_size=n_batch, num_samples=[2, 2]).flow([1, 5])\n    (nf, nl) = mapper[0]\n    assert (nf[0].shape == (2, 1, n_feat))\n    assert (nf[1].shape == (2, 2, n_feat))\n    assert (nf[2].shape == (2, 4, n_feat))\n    assert (pytest.approx(nf[1][1]) == 0)\n    assert (pytest.approx(nf[2][2:]) == 0)", "ground_truth": "(1, 4, n_feat)", "quality_analysis": {"complexity_score": 7, "left_complexity": 2, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_985", "reponame": "stellargraph", "testpath": "tests/mapper/test_node_mappers.py", "testname": "test_node_mappers.py", "classname": null, "funcname": "test_hinnodemapper_constructor", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper import *", "import networkx as nx", "import numpy as np", "import random", "import pytest", "import pandas as pd", "import scipy.sparse as sps", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, create_graph_features, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_hinnodemapper_constructor():\n    feature_sizes = {'A': 10, 'B': 10}\n    G = example_hin_1(feature_sizes=feature_sizes)\n    with pytest.raises(ValueError):\n        HinSAGENodeGenerator(G, batch_size=2, num_samples=[2, 2], head_node_type='A').flow(G.nodes())\n    gen = HinSAGENodeGenerator(G, batch_size=2, num_samples=[2, 2], head_node_type='A')\n    mapper = gen.flow([0, 1, 2, 3])\n    assert (gen.batch_size == 2)\n    assert (mapper.data_size == 4)\n    assert (len(mapper.ids) == 4)", "masked_code": "def test_hinnodemapper_constructor():\n    feature_sizes = {'A': 10, 'B': 10}\n    G = example_hin_1(feature_sizes=feature_sizes)\n    with pytest.raises(ValueError):\n        HinSAGENodeGenerator(G, batch_size=2, num_samples=[2, 2], head_node_type='A').flow(G.nodes())\n    gen = HinSAGENodeGenerator(G, batch_size=2, num_samples=[2, 2], head_node_type='A')\n    mapper = gen.flow([0, 1, 2, 3])\n    assert (gen.batch_size == 2)\n    assert (mapper.data_size == '???')\n    assert (len(mapper.ids) == 4)", "ground_truth": "4", "quality_analysis": {"complexity_score": 3, "left_complexity": 2, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_986", "reponame": "stellargraph", "testpath": "tests/mapper/test_node_mappers.py", "testname": "test_node_mappers.py", "classname": null, "funcname": "test_hinnodemapper_constructor", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper import *", "import networkx as nx", "import numpy as np", "import random", "import pytest", "import pandas as pd", "import scipy.sparse as sps", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, create_graph_features, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_hinnodemapper_constructor():\n    feature_sizes = {'A': 10, 'B': 10}\n    G = example_hin_1(feature_sizes=feature_sizes)\n    with pytest.raises(ValueError):\n        HinSAGENodeGenerator(G, batch_size=2, num_samples=[2, 2], head_node_type='A').flow(G.nodes())\n    gen = HinSAGENodeGenerator(G, batch_size=2, num_samples=[2, 2], head_node_type='A')\n    mapper = gen.flow([0, 1, 2, 3])\n    assert (gen.batch_size == 2)\n    assert (mapper.data_size == 4)\n    assert (len(mapper.ids) == 4)", "masked_code": "def test_hinnodemapper_constructor():\n    feature_sizes = {'A': 10, 'B': 10}\n    G = example_hin_1(feature_sizes=feature_sizes)\n    with pytest.raises(ValueError):\n        HinSAGENodeGenerator(G, batch_size=2, num_samples=[2, 2], head_node_type='A').flow(G.nodes())\n    gen = HinSAGENodeGenerator(G, batch_size=2, num_samples=[2, 2], head_node_type='A')\n    mapper = gen.flow([0, 1, 2, 3])\n    assert (gen.batch_size == 2)\n    assert (mapper.data_size == 4)\n    assert (len(mapper.ids) == '???')", "ground_truth": "4", "quality_analysis": {"complexity_score": 6, "left_complexity": 5, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_987", "reponame": "stellargraph", "testpath": "tests/mapper/test_node_mappers.py", "testname": "test_node_mappers.py", "classname": null, "funcname": "test_hinnodemapper_constructor_all_options", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper import *", "import networkx as nx", "import numpy as np", "import random", "import pytest", "import pandas as pd", "import scipy.sparse as sps", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, create_graph_features, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_hinnodemapper_constructor_all_options():\n    feature_sizes = {'A': 10, 'B': 10}\n    G = example_hin_1(feature_sizes=feature_sizes)\n    gen = HinSAGENodeGenerator(G, batch_size=2, num_samples=[2, 2], head_node_type='A')\n    nodes_of_type_a = G.nodes(node_type='A')\n    mapper = gen.flow(nodes_of_type_a)\n    assert (gen.batch_size == 2)\n    assert (mapper.data_size == len(nodes_of_type_a))", "masked_code": "def test_hinnodemapper_constructor_all_options():\n    feature_sizes = {'A': 10, 'B': 10}\n    G = example_hin_1(feature_sizes=feature_sizes)\n    gen = HinSAGENodeGenerator(G, batch_size=2, num_samples=[2, 2], head_node_type='A')\n    nodes_of_type_a = G.nodes(node_type='A')\n    mapper = gen.flow(nodes_of_type_a)\n    assert (gen.batch_size == 2)\n    assert (mapper.data_size == '???')", "ground_truth": "len(nodes_of_type_a)", "quality_analysis": {"complexity_score": 6, "left_complexity": 2, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_988", "reponame": "stellargraph", "testpath": "tests/mapper/test_node_mappers.py", "testname": "test_node_mappers.py", "classname": null, "funcname": "test_hinnodemapper_level_1", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper import *", "import networkx as nx", "import numpy as np", "import random", "import pytest", "import pandas as pd", "import scipy.sparse as sps", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, create_graph_features, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_hinnodemapper_level_1():\n    batch_size = 2\n    feature_sizes = {'t1': 1, 't2': 2}\n    (G, nodes_type_1, nodes_type_2) = example_hin_2(feature_sizes)\n    mapper = HinSAGENodeGenerator(G, batch_size=batch_size, num_samples=[2], head_node_type='t2').flow(nodes_type_2)\n    schema = G.create_graph_schema()\n    sampling_adj = schema.type_adjacency_list(['t2'], 1)\n    assert (len(mapper) == 1)\n    (batch_feats, batch_targets) = mapper[0]\n    assert (np.shape(batch_feats[0]) == (2, 1, 2))\n    assert (np.shape(batch_feats[1]) == (2, 2, 1))\n    assert np.all((batch_feats[0] >= 4))\n    assert np.all((batch_feats[1] < 4))", "masked_code": "def test_hinnodemapper_level_1():\n    batch_size = 2\n    feature_sizes = {'t1': 1, 't2': 2}\n    (G, nodes_type_1, nodes_type_2) = example_hin_2(feature_sizes)\n    mapper = HinSAGENodeGenerator(G, batch_size=batch_size, num_samples=[2], head_node_type='t2').flow(nodes_type_2)\n    schema = G.create_graph_schema()\n    sampling_adj = schema.type_adjacency_list(['t2'], 1)\n    assert (len(mapper) == 1)\n    (batch_feats, batch_targets) = mapper[0]\n    assert (np.shape(batch_feats[0]) == '???')\n    assert (np.shape(batch_feats[1]) == (2, 2, 1))\n    assert np.all((batch_feats[0] >= 4))\n    assert np.all((batch_feats[1] < 4))", "ground_truth": "(2, 1, 2)", "quality_analysis": {"complexity_score": 13, "left_complexity": 8, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_989", "reponame": "stellargraph", "testpath": "tests/mapper/test_node_mappers.py", "testname": "test_node_mappers.py", "classname": null, "funcname": "test_hinnodemapper_level_1", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper import *", "import networkx as nx", "import numpy as np", "import random", "import pytest", "import pandas as pd", "import scipy.sparse as sps", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, create_graph_features, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_hinnodemapper_level_1():\n    batch_size = 2\n    feature_sizes = {'t1': 1, 't2': 2}\n    (G, nodes_type_1, nodes_type_2) = example_hin_2(feature_sizes)\n    mapper = HinSAGENodeGenerator(G, batch_size=batch_size, num_samples=[2], head_node_type='t2').flow(nodes_type_2)\n    schema = G.create_graph_schema()\n    sampling_adj = schema.type_adjacency_list(['t2'], 1)\n    assert (len(mapper) == 1)\n    (batch_feats, batch_targets) = mapper[0]\n    assert (np.shape(batch_feats[0]) == (2, 1, 2))\n    assert (np.shape(batch_feats[1]) == (2, 2, 1))\n    assert np.all((batch_feats[0] >= 4))\n    assert np.all((batch_feats[1] < 4))", "masked_code": "def test_hinnodemapper_level_1():\n    batch_size = 2\n    feature_sizes = {'t1': 1, 't2': 2}\n    (G, nodes_type_1, nodes_type_2) = example_hin_2(feature_sizes)\n    mapper = HinSAGENodeGenerator(G, batch_size=batch_size, num_samples=[2], head_node_type='t2').flow(nodes_type_2)\n    schema = G.create_graph_schema()\n    sampling_adj = schema.type_adjacency_list(['t2'], 1)\n    assert (len(mapper) == 1)\n    (batch_feats, batch_targets) = mapper[0]\n    assert (np.shape(batch_feats[0]) == (2, 1, 2))\n    assert (np.shape(batch_feats[1]) == '???')\n    assert np.all((batch_feats[0] >= 4))\n    assert np.all((batch_feats[1] < 4))", "ground_truth": "(2, 2, 1)", "quality_analysis": {"complexity_score": 13, "left_complexity": 8, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_990", "reponame": "stellargraph", "testpath": "tests/mapper/test_node_mappers.py", "testname": "test_node_mappers.py", "classname": null, "funcname": "test_hinnodemapper_level_2", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper import *", "import networkx as nx", "import numpy as np", "import random", "import pytest", "import pandas as pd", "import scipy.sparse as sps", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, create_graph_features, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_hinnodemapper_level_2():\n    batch_size = 2\n    feature_sizes = {'t1': 1, 't2': 2}\n    (G, nodes_type_1, nodes_type_2) = example_hin_2(feature_sizes)\n    mapper = HinSAGENodeGenerator(G, batch_size=batch_size, num_samples=[2, 3], head_node_type='t2').flow(nodes_type_2)\n    schema = G.create_graph_schema()\n    sampling_adj = schema.type_adjacency_list(['t2'], 2)\n    assert (len(mapper) == 1)\n    (batch_feats, batch_targets) = mapper[0]\n    assert (len(batch_feats) == len(sampling_adj))\n    for (bf, adj) in zip(batch_feats, sampling_adj):\n        nt = adj[0]\n        assert (bf.shape[0] == batch_size)\n        assert (bf.shape[2] == feature_sizes[nt])\n        batch_node_types = {G.node_type(n) for n in np.ravel(bf)}\n        assert (len(batch_node_types) == 1)\n        assert (nt in batch_node_types)", "masked_code": "def test_hinnodemapper_level_2():\n    batch_size = 2\n    feature_sizes = {'t1': 1, 't2': 2}\n    (G, nodes_type_1, nodes_type_2) = example_hin_2(feature_sizes)\n    mapper = HinSAGENodeGenerator(G, batch_size=batch_size, num_samples=[2, 3], head_node_type='t2').flow(nodes_type_2)\n    schema = G.create_graph_schema()\n    sampling_adj = schema.type_adjacency_list(['t2'], 2)\n    assert (len(mapper) == 1)\n    (batch_feats, batch_targets) = mapper[0]\n    assert (len(batch_feats) == '???')\n    for (bf, adj) in zip(batch_feats, sampling_adj):\n        nt = adj[0]\n        assert (bf.shape[0] == batch_size)\n        assert (bf.shape[2] == feature_sizes[nt])\n        batch_node_types = {G.node_type(n) for n in np.ravel(bf)}\n        assert (len(batch_node_types) == 1)\n        assert (nt in batch_node_types)", "ground_truth": "len(sampling_adj)", "quality_analysis": {"complexity_score": 8, "left_complexity": 4, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_991", "reponame": "stellargraph", "testpath": "tests/mapper/test_node_mappers.py", "testname": "test_node_mappers.py", "classname": null, "funcname": "test_hinnodemapper_level_2", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper import *", "import networkx as nx", "import numpy as np", "import random", "import pytest", "import pandas as pd", "import scipy.sparse as sps", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, create_graph_features, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_hinnodemapper_level_2():\n    batch_size = 2\n    feature_sizes = {'t1': 1, 't2': 2}\n    (G, nodes_type_1, nodes_type_2) = example_hin_2(feature_sizes)\n    mapper = HinSAGENodeGenerator(G, batch_size=batch_size, num_samples=[2, 3], head_node_type='t2').flow(nodes_type_2)\n    schema = G.create_graph_schema()\n    sampling_adj = schema.type_adjacency_list(['t2'], 2)\n    assert (len(mapper) == 1)\n    (batch_feats, batch_targets) = mapper[0]\n    assert (len(batch_feats) == len(sampling_adj))\n    for (bf, adj) in zip(batch_feats, sampling_adj):\n        nt = adj[0]\n        assert (bf.shape[0] == batch_size)\n        assert (bf.shape[2] == feature_sizes[nt])\n        batch_node_types = {G.node_type(n) for n in np.ravel(bf)}\n        assert (len(batch_node_types) == 1)\n        assert (nt in batch_node_types)", "masked_code": "def test_hinnodemapper_level_2():\n    batch_size = 2\n    feature_sizes = {'t1': 1, 't2': 2}\n    (G, nodes_type_1, nodes_type_2) = example_hin_2(feature_sizes)\n    mapper = HinSAGENodeGenerator(G, batch_size=batch_size, num_samples=[2, 3], head_node_type='t2').flow(nodes_type_2)\n    schema = G.create_graph_schema()\n    sampling_adj = schema.type_adjacency_list(['t2'], 2)\n    assert (len(mapper) == 1)\n    (batch_feats, batch_targets) = mapper[0]\n    assert (len(batch_feats) == len(sampling_adj))\n    for (bf, adj) in zip(batch_feats, sampling_adj):\n        nt = adj[0]\n        assert (bf.shape[0] == '???')\n        assert (bf.shape[2] == feature_sizes[nt])\n        batch_node_types = {G.node_type(n) for n in np.ravel(bf)}\n        assert (len(batch_node_types) == 1)\n        assert (nt in batch_node_types)", "ground_truth": "batch_size", "quality_analysis": {"complexity_score": 7, "left_complexity": 6, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_992", "reponame": "stellargraph", "testpath": "tests/mapper/test_node_mappers.py", "testname": "test_node_mappers.py", "classname": null, "funcname": "test_hinnodemapper_level_2", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper import *", "import networkx as nx", "import numpy as np", "import random", "import pytest", "import pandas as pd", "import scipy.sparse as sps", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, create_graph_features, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_hinnodemapper_level_2():\n    batch_size = 2\n    feature_sizes = {'t1': 1, 't2': 2}\n    (G, nodes_type_1, nodes_type_2) = example_hin_2(feature_sizes)\n    mapper = HinSAGENodeGenerator(G, batch_size=batch_size, num_samples=[2, 3], head_node_type='t2').flow(nodes_type_2)\n    schema = G.create_graph_schema()\n    sampling_adj = schema.type_adjacency_list(['t2'], 2)\n    assert (len(mapper) == 1)\n    (batch_feats, batch_targets) = mapper[0]\n    assert (len(batch_feats) == len(sampling_adj))\n    for (bf, adj) in zip(batch_feats, sampling_adj):\n        nt = adj[0]\n        assert (bf.shape[0] == batch_size)\n        assert (bf.shape[2] == feature_sizes[nt])\n        batch_node_types = {G.node_type(n) for n in np.ravel(bf)}\n        assert (len(batch_node_types) == 1)\n        assert (nt in batch_node_types)", "masked_code": "def test_hinnodemapper_level_2():\n    batch_size = 2\n    feature_sizes = {'t1': 1, 't2': 2}\n    (G, nodes_type_1, nodes_type_2) = example_hin_2(feature_sizes)\n    mapper = HinSAGENodeGenerator(G, batch_size=batch_size, num_samples=[2, 3], head_node_type='t2').flow(nodes_type_2)\n    schema = G.create_graph_schema()\n    sampling_adj = schema.type_adjacency_list(['t2'], 2)\n    assert (len(mapper) == 1)\n    (batch_feats, batch_targets) = mapper[0]\n    assert (len(batch_feats) == len(sampling_adj))\n    for (bf, adj) in zip(batch_feats, sampling_adj):\n        nt = adj[0]\n        assert (bf.shape[0] == batch_size)\n        assert (bf.shape[2] == '???')\n        batch_node_types = {G.node_type(n) for n in np.ravel(bf)}\n        assert (len(batch_node_types) == 1)\n        assert (nt in batch_node_types)", "ground_truth": "feature_sizes[nt]", "quality_analysis": {"complexity_score": 11, "left_complexity": 6, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_993", "reponame": "stellargraph", "testpath": "tests/mapper/test_node_mappers.py", "testname": "test_node_mappers.py", "classname": null, "funcname": "test_hinnodemapper_with_labels", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper import *", "import networkx as nx", "import numpy as np", "import random", "import pytest", "import pandas as pd", "import scipy.sparse as sps", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, create_graph_features, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_hinnodemapper_with_labels():\n    batch_size = 2\n    feature_sizes = {'t1': 1, 't2': 2}\n    (G, nodes_type_1, nodes_type_2) = example_hin_2(feature_sizes)\n    labels = [(n * 2) for n in nodes_type_1]\n    gen = HinSAGENodeGenerator(G, batch_size=batch_size, num_samples=[2, 3], head_node_type='t1').flow(nodes_type_1, labels, shuffle=False)\n    assert (len(gen) == 2)\n    for ii in range(2):\n        (nf, nl) = gen[ii]\n        assert (len(nf) == 3)\n        assert (nf[0].shape == (2, 1, 1))\n        assert (nf[1].shape == (2, 2, 2))\n        assert (nf[2].shape == (2, (2 * 3), 1))\n        assert all(((int(a) == int((2 * b))) for (a, b) in zip(nl, nf[0][(:, 0, 0)])))\n    with pytest.raises(IndexError):\n        (nf, nl) = gen[len(gen)]", "masked_code": "def test_hinnodemapper_with_labels():\n    batch_size = 2\n    feature_sizes = {'t1': 1, 't2': 2}\n    (G, nodes_type_1, nodes_type_2) = example_hin_2(feature_sizes)\n    labels = [(n * 2) for n in nodes_type_1]\n    gen = HinSAGENodeGenerator(G, batch_size=batch_size, num_samples=[2, 3], head_node_type='t1').flow(nodes_type_1, labels, shuffle=False)\n    assert (len(gen) == 2)\n    for ii in range(2):\n        (nf, nl) = gen[ii]\n        assert (len(nf) == '???')\n        assert (nf[0].shape == (2, 1, 1))\n        assert (nf[1].shape == (2, 2, 2))\n        assert (nf[2].shape == (2, (2 * 3), 1))\n        assert all(((int(a) == int((2 * b))) for (a, b) in zip(nl, nf[0][(:, 0, 0)])))\n    with pytest.raises(IndexError):\n        (nf, nl) = gen[len(gen)]", "ground_truth": "3", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_994", "reponame": "stellargraph", "testpath": "tests/mapper/test_node_mappers.py", "testname": "test_node_mappers.py", "classname": null, "funcname": "test_hinnodemapper_with_labels", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper import *", "import networkx as nx", "import numpy as np", "import random", "import pytest", "import pandas as pd", "import scipy.sparse as sps", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, create_graph_features, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_hinnodemapper_with_labels():\n    batch_size = 2\n    feature_sizes = {'t1': 1, 't2': 2}\n    (G, nodes_type_1, nodes_type_2) = example_hin_2(feature_sizes)\n    labels = [(n * 2) for n in nodes_type_1]\n    gen = HinSAGENodeGenerator(G, batch_size=batch_size, num_samples=[2, 3], head_node_type='t1').flow(nodes_type_1, labels, shuffle=False)\n    assert (len(gen) == 2)\n    for ii in range(2):\n        (nf, nl) = gen[ii]\n        assert (len(nf) == 3)\n        assert (nf[0].shape == (2, 1, 1))\n        assert (nf[1].shape == (2, 2, 2))\n        assert (nf[2].shape == (2, (2 * 3), 1))\n        assert all(((int(a) == int((2 * b))) for (a, b) in zip(nl, nf[0][(:, 0, 0)])))\n    with pytest.raises(IndexError):\n        (nf, nl) = gen[len(gen)]", "masked_code": "def test_hinnodemapper_with_labels():\n    batch_size = 2\n    feature_sizes = {'t1': 1, 't2': 2}\n    (G, nodes_type_1, nodes_type_2) = example_hin_2(feature_sizes)\n    labels = [(n * 2) for n in nodes_type_1]\n    gen = HinSAGENodeGenerator(G, batch_size=batch_size, num_samples=[2, 3], head_node_type='t1').flow(nodes_type_1, labels, shuffle=False)\n    assert (len(gen) == 2)\n    for ii in range(2):\n        (nf, nl) = gen[ii]\n        assert (len(nf) == 3)\n        assert (nf[0].shape == '???')\n        assert (nf[1].shape == (2, 2, 2))\n        assert (nf[2].shape == (2, (2 * 3), 1))\n        assert all(((int(a) == int((2 * b))) for (a, b) in zip(nl, nf[0][(:, 0, 0)])))\n    with pytest.raises(IndexError):\n        (nf, nl) = gen[len(gen)]", "ground_truth": "(2, 1, 1)", "quality_analysis": {"complexity_score": 7, "left_complexity": 2, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_995", "reponame": "stellargraph", "testpath": "tests/mapper/test_node_mappers.py", "testname": "test_node_mappers.py", "classname": null, "funcname": "test_hinnodemapper_with_labels", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper import *", "import networkx as nx", "import numpy as np", "import random", "import pytest", "import pandas as pd", "import scipy.sparse as sps", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, create_graph_features, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_hinnodemapper_with_labels():\n    batch_size = 2\n    feature_sizes = {'t1': 1, 't2': 2}\n    (G, nodes_type_1, nodes_type_2) = example_hin_2(feature_sizes)\n    labels = [(n * 2) for n in nodes_type_1]\n    gen = HinSAGENodeGenerator(G, batch_size=batch_size, num_samples=[2, 3], head_node_type='t1').flow(nodes_type_1, labels, shuffle=False)\n    assert (len(gen) == 2)\n    for ii in range(2):\n        (nf, nl) = gen[ii]\n        assert (len(nf) == 3)\n        assert (nf[0].shape == (2, 1, 1))\n        assert (nf[1].shape == (2, 2, 2))\n        assert (nf[2].shape == (2, (2 * 3), 1))\n        assert all(((int(a) == int((2 * b))) for (a, b) in zip(nl, nf[0][(:, 0, 0)])))\n    with pytest.raises(IndexError):\n        (nf, nl) = gen[len(gen)]", "masked_code": "def test_hinnodemapper_with_labels():\n    batch_size = 2\n    feature_sizes = {'t1': 1, 't2': 2}\n    (G, nodes_type_1, nodes_type_2) = example_hin_2(feature_sizes)\n    labels = [(n * 2) for n in nodes_type_1]\n    gen = HinSAGENodeGenerator(G, batch_size=batch_size, num_samples=[2, 3], head_node_type='t1').flow(nodes_type_1, labels, shuffle=False)\n    assert (len(gen) == 2)\n    for ii in range(2):\n        (nf, nl) = gen[ii]\n        assert (len(nf) == 3)\n        assert (nf[0].shape == (2, 1, 1))\n        assert (nf[1].shape == '???')\n        assert (nf[2].shape == (2, (2 * 3), 1))\n        assert all(((int(a) == int((2 * b))) for (a, b) in zip(nl, nf[0][(:, 0, 0)])))\n    with pytest.raises(IndexError):\n        (nf, nl) = gen[len(gen)]", "ground_truth": "(2, 2, 2)", "quality_analysis": {"complexity_score": 7, "left_complexity": 2, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_996", "reponame": "stellargraph", "testpath": "tests/mapper/test_node_mappers.py", "testname": "test_node_mappers.py", "classname": null, "funcname": "test_hinnodemapper_with_labels", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper import *", "import networkx as nx", "import numpy as np", "import random", "import pytest", "import pandas as pd", "import scipy.sparse as sps", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, create_graph_features, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_hinnodemapper_with_labels():\n    batch_size = 2\n    feature_sizes = {'t1': 1, 't2': 2}\n    (G, nodes_type_1, nodes_type_2) = example_hin_2(feature_sizes)\n    labels = [(n * 2) for n in nodes_type_1]\n    gen = HinSAGENodeGenerator(G, batch_size=batch_size, num_samples=[2, 3], head_node_type='t1').flow(nodes_type_1, labels, shuffle=False)\n    assert (len(gen) == 2)\n    for ii in range(2):\n        (nf, nl) = gen[ii]\n        assert (len(nf) == 3)\n        assert (nf[0].shape == (2, 1, 1))\n        assert (nf[1].shape == (2, 2, 2))\n        assert (nf[2].shape == (2, (2 * 3), 1))\n        assert all(((int(a) == int((2 * b))) for (a, b) in zip(nl, nf[0][(:, 0, 0)])))\n    with pytest.raises(IndexError):\n        (nf, nl) = gen[len(gen)]", "masked_code": "def test_hinnodemapper_with_labels():\n    batch_size = 2\n    feature_sizes = {'t1': 1, 't2': 2}\n    (G, nodes_type_1, nodes_type_2) = example_hin_2(feature_sizes)\n    labels = [(n * 2) for n in nodes_type_1]\n    gen = HinSAGENodeGenerator(G, batch_size=batch_size, num_samples=[2, 3], head_node_type='t1').flow(nodes_type_1, labels, shuffle=False)\n    assert (len(gen) == 2)\n    for ii in range(2):\n        (nf, nl) = gen[ii]\n        assert (len(nf) == 3)\n        assert (nf[0].shape == (2, 1, 1))\n        assert (nf[1].shape == (2, 2, 2))\n        assert (nf[2].shape == '???')\n        assert all(((int(a) == int((2 * b))) for (a, b) in zip(nl, nf[0][(:, 0, 0)])))\n    with pytest.raises(IndexError):\n        (nf, nl) = gen[len(gen)]", "ground_truth": "(2, (2 * 3), 1)", "quality_analysis": {"complexity_score": 10, "left_complexity": 2, "right_complexity": 8, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_997", "reponame": "stellargraph", "testpath": "tests/mapper/test_node_mappers.py", "testname": "test_node_mappers.py", "classname": null, "funcname": "test_hinnodemapper_zero_samples", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper import *", "import networkx as nx", "import numpy as np", "import random", "import pytest", "import pandas as pd", "import scipy.sparse as sps", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, create_graph_features, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_hinnodemapper_zero_samples():\n    batch_size = 3\n    feature_sizes = {'t1': 1, 't2': 1}\n    (G, nodes_type_1, nodes_type_2) = example_hin_3(feature_sizes)\n    mapper = HinSAGENodeGenerator(G, batch_size=batch_size, num_samples=[0, 0], head_node_type='t2').flow(nodes_type_2)\n    schema = G.create_graph_schema()\n    sampling_adj = schema.type_adjacency_list(['t2'], 2)\n    assert (len(mapper) == 1)\n    (batch_feats, batch_targets) = mapper[0]\n    assert (len(batch_feats) == len(sampling_adj))", "masked_code": "def test_hinnodemapper_zero_samples():\n    batch_size = 3\n    feature_sizes = {'t1': 1, 't2': 1}\n    (G, nodes_type_1, nodes_type_2) = example_hin_3(feature_sizes)\n    mapper = HinSAGENodeGenerator(G, batch_size=batch_size, num_samples=[0, 0], head_node_type='t2').flow(nodes_type_2)\n    schema = G.create_graph_schema()\n    sampling_adj = schema.type_adjacency_list(['t2'], 2)\n    assert (len(mapper) == 1)\n    (batch_feats, batch_targets) = mapper[0]\n    assert (len(batch_feats) == '???')", "ground_truth": "len(sampling_adj)", "quality_analysis": {"complexity_score": 8, "left_complexity": 4, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_998", "reponame": "stellargraph", "testpath": "tests/mapper/test_node_mappers.py", "testname": "test_node_mappers.py", "classname": null, "funcname": "test_hinnodemapper_no_neighbors", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper import *", "import networkx as nx", "import numpy as np", "import random", "import pytest", "import pandas as pd", "import scipy.sparse as sps", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, create_graph_features, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_hinnodemapper_no_neighbors():\n    batch_size = 3\n    feature_sizes = {'t1': 1, 't2': 1}\n    (G, nodes_type_1, nodes_type_2) = example_hin_3(feature_sizes)\n    mapper = HinSAGENodeGenerator(G, batch_size=batch_size, num_samples=[2, 1], head_node_type='t2').flow(nodes_type_2)\n    schema = G.create_graph_schema()\n    sampling_adj = schema.type_adjacency_list(['t2'], 2)\n    assert (len(mapper) == 1)\n    (batch_feats, batch_targets) = mapper[0]\n    assert (len(batch_feats) == len(sampling_adj))\n    assert np.all((np.ravel(batch_feats[0]) == np.array([14, 15, 16])))\n    assert np.all((batch_feats[1][(:, 0, 0)] == np.array([10, 11, 0])))\n    assert np.all((batch_feats[2][(:, 0, 0)] == np.array([14, 15, 0])))\n    assert np.all((batch_feats[3][(:, 0, 0)] == np.array([12, 0, 0])))", "masked_code": "def test_hinnodemapper_no_neighbors():\n    batch_size = 3\n    feature_sizes = {'t1': 1, 't2': 1}\n    (G, nodes_type_1, nodes_type_2) = example_hin_3(feature_sizes)\n    mapper = HinSAGENodeGenerator(G, batch_size=batch_size, num_samples=[2, 1], head_node_type='t2').flow(nodes_type_2)\n    schema = G.create_graph_schema()\n    sampling_adj = schema.type_adjacency_list(['t2'], 2)\n    assert (len(mapper) == 1)\n    (batch_feats, batch_targets) = mapper[0]\n    assert (len(batch_feats) == '???')\n    assert np.all((np.ravel(batch_feats[0]) == np.array([14, 15, 16])))\n    assert np.all((batch_feats[1][(:, 0, 0)] == np.array([10, 11, 0])))\n    assert np.all((batch_feats[2][(:, 0, 0)] == np.array([14, 15, 0])))\n    assert np.all((batch_feats[3][(:, 0, 0)] == np.array([12, 0, 0])))", "ground_truth": "len(sampling_adj)", "quality_analysis": {"complexity_score": 8, "left_complexity": 4, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_999", "reponame": "stellargraph", "testpath": "tests/mapper/test_node_mappers.py", "testname": "test_node_mappers.py", "classname": null, "funcname": "test_hinsage_corrupt_indices", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper import *", "import networkx as nx", "import numpy as np", "import random", "import pytest", "import pandas as pd", "import scipy.sparse as sps", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, create_graph_features, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_hinsage_corrupt_indices():\n    feature_sizes = {'t1': 7, 't2': 11}\n    (G, _, nodes_type_2) = example_hin_3(feature_sizes)\n    mapper = HinSAGENodeGenerator(G, batch_size=2, num_samples=[3, 5], head_node_type='t2')\n    seq = mapper.flow(nodes_type_2)\n    (tensors, _targets) = seq[0]\n    groups = mapper.default_corrupt_input_index_groups()\n    assert (len(groups) == 2)\n    assert ({idx for g in groups for idx in g} == set(range(len(tensors))))\n    assert ({tensors[idx].shape[(- 1)] for idx in groups[0]} == {11})\n    assert ({tensors[idx].shape[(- 1)] for idx in groups[1]} == {7})", "masked_code": "def test_hinsage_corrupt_indices():\n    feature_sizes = {'t1': 7, 't2': 11}\n    (G, _, nodes_type_2) = example_hin_3(feature_sizes)\n    mapper = HinSAGENodeGenerator(G, batch_size=2, num_samples=[3, 5], head_node_type='t2')\n    seq = mapper.flow(nodes_type_2)\n    (tensors, _targets) = seq[0]\n    groups = mapper.default_corrupt_input_index_groups()\n    assert (len(groups) == 2)\n    assert ({idx for g in groups for idx in g} == set(range(len(tensors))))\n    assert ({tensors[idx].shape[(- 1)] for idx in groups[0]} == '???')\n    assert ({tensors[idx].shape[(- 1)] for idx in groups[1]} == {7})", "ground_truth": "{11}", "quality_analysis": {"complexity_score": 0, "left_complexity": 0, "right_complexity": 0, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_1000", "reponame": "stellargraph", "testpath": "tests/mapper/test_node_mappers.py", "testname": "test_node_mappers.py", "classname": null, "funcname": "test_hinsage_corrupt_indices", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper import *", "import networkx as nx", "import numpy as np", "import random", "import pytest", "import pandas as pd", "import scipy.sparse as sps", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, create_graph_features, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_hinsage_corrupt_indices():\n    feature_sizes = {'t1': 7, 't2': 11}\n    (G, _, nodes_type_2) = example_hin_3(feature_sizes)\n    mapper = HinSAGENodeGenerator(G, batch_size=2, num_samples=[3, 5], head_node_type='t2')\n    seq = mapper.flow(nodes_type_2)\n    (tensors, _targets) = seq[0]\n    groups = mapper.default_corrupt_input_index_groups()\n    assert (len(groups) == 2)\n    assert ({idx for g in groups for idx in g} == set(range(len(tensors))))\n    assert ({tensors[idx].shape[(- 1)] for idx in groups[0]} == {11})\n    assert ({tensors[idx].shape[(- 1)] for idx in groups[1]} == {7})", "masked_code": "def test_hinsage_corrupt_indices():\n    feature_sizes = {'t1': 7, 't2': 11}\n    (G, _, nodes_type_2) = example_hin_3(feature_sizes)\n    mapper = HinSAGENodeGenerator(G, batch_size=2, num_samples=[3, 5], head_node_type='t2')\n    seq = mapper.flow(nodes_type_2)\n    (tensors, _targets) = seq[0]\n    groups = mapper.default_corrupt_input_index_groups()\n    assert (len(groups) == 2)\n    assert ({idx for g in groups for idx in g} == set(range(len(tensors))))\n    assert ({tensors[idx].shape[(- 1)] for idx in groups[0]} == {11})\n    assert ({tensors[idx].shape[(- 1)] for idx in groups[1]} == '???')", "ground_truth": "{7}", "quality_analysis": {"complexity_score": 0, "left_complexity": 0, "right_complexity": 0, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_1001", "reponame": "stellargraph", "testpath": "tests/mapper/test_node_mappers.py", "testname": "test_node_mappers.py", "classname": null, "funcname": "test_hinsage_homogeneous_inference", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper import *", "import networkx as nx", "import numpy as np", "import random", "import pytest", "import pandas as pd", "import scipy.sparse as sps", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, create_graph_features, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_hinsage_homogeneous_inference():\n    feature_size = 4\n    edge_types = 3\n    batch_size = 2\n    num_samples = [5, 7]\n    G = example_graph_random(feature_size=feature_size, node_types=1, edge_types=edge_types)\n    mapper = HinSAGENodeGenerator(G, batch_size=batch_size, num_samples=num_samples)\n    assert (mapper.head_node_types == ['n-0'])\n    nodes = [1, 4, 2]\n    seq = mapper.flow(nodes)\n    assert (len(seq) == 2)\n    samples_per_head = ((1 + edge_types) + (edge_types * edge_types))\n    for (batch_idx, (samples, labels)) in enumerate(seq):\n        this_batch_size = {0: batch_size, 1: 1}[batch_idx]\n        assert (len(samples) == samples_per_head)\n        assert (samples[0].shape == (this_batch_size, 1, feature_size))\n        for i in range(1, (1 + edge_types)):\n            assert (samples[i].shape == (this_batch_size, num_samples[0], feature_size))\n        for i in range((1 + edge_types), samples_per_head):\n            assert (samples[i].shape == (this_batch_size, np.product(num_samples), feature_size))\n        assert (labels is None)", "masked_code": "def test_hinsage_homogeneous_inference():\n    feature_size = 4\n    edge_types = 3\n    batch_size = 2\n    num_samples = [5, 7]\n    G = example_graph_random(feature_size=feature_size, node_types=1, edge_types=edge_types)\n    mapper = HinSAGENodeGenerator(G, batch_size=batch_size, num_samples=num_samples)\n    assert (mapper.head_node_types == '???')\n    nodes = [1, 4, 2]\n    seq = mapper.flow(nodes)\n    assert (len(seq) == 2)\n    samples_per_head = ((1 + edge_types) + (edge_types * edge_types))\n    for (batch_idx, (samples, labels)) in enumerate(seq):\n        this_batch_size = {0: batch_size, 1: 1}[batch_idx]\n        assert (len(samples) == samples_per_head)\n        assert (samples[0].shape == (this_batch_size, 1, feature_size))\n        for i in range(1, (1 + edge_types)):\n            assert (samples[i].shape == (this_batch_size, num_samples[0], feature_size))\n        for i in range((1 + edge_types), samples_per_head):\n            assert (samples[i].shape == (this_batch_size, np.product(num_samples), feature_size))\n        assert (labels is None)", "ground_truth": "['n-0']", "quality_analysis": {"complexity_score": 5, "left_complexity": 2, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_1002", "reponame": "stellargraph", "testpath": "tests/mapper/test_node_mappers.py", "testname": "test_node_mappers.py", "classname": null, "funcname": "test_hinsage_homogeneous_inference", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper import *", "import networkx as nx", "import numpy as np", "import random", "import pytest", "import pandas as pd", "import scipy.sparse as sps", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, create_graph_features, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_hinsage_homogeneous_inference():\n    feature_size = 4\n    edge_types = 3\n    batch_size = 2\n    num_samples = [5, 7]\n    G = example_graph_random(feature_size=feature_size, node_types=1, edge_types=edge_types)\n    mapper = HinSAGENodeGenerator(G, batch_size=batch_size, num_samples=num_samples)\n    assert (mapper.head_node_types == ['n-0'])\n    nodes = [1, 4, 2]\n    seq = mapper.flow(nodes)\n    assert (len(seq) == 2)\n    samples_per_head = ((1 + edge_types) + (edge_types * edge_types))\n    for (batch_idx, (samples, labels)) in enumerate(seq):\n        this_batch_size = {0: batch_size, 1: 1}[batch_idx]\n        assert (len(samples) == samples_per_head)\n        assert (samples[0].shape == (this_batch_size, 1, feature_size))\n        for i in range(1, (1 + edge_types)):\n            assert (samples[i].shape == (this_batch_size, num_samples[0], feature_size))\n        for i in range((1 + edge_types), samples_per_head):\n            assert (samples[i].shape == (this_batch_size, np.product(num_samples), feature_size))\n        assert (labels is None)", "masked_code": "def test_hinsage_homogeneous_inference():\n    feature_size = 4\n    edge_types = 3\n    batch_size = 2\n    num_samples = [5, 7]\n    G = example_graph_random(feature_size=feature_size, node_types=1, edge_types=edge_types)\n    mapper = HinSAGENodeGenerator(G, batch_size=batch_size, num_samples=num_samples)\n    assert (mapper.head_node_types == ['n-0'])\n    nodes = [1, 4, 2]\n    seq = mapper.flow(nodes)\n    assert (len(seq) == 2)\n    samples_per_head = ((1 + edge_types) + (edge_types * edge_types))\n    for (batch_idx, (samples, labels)) in enumerate(seq):\n        this_batch_size = {0: batch_size, 1: 1}[batch_idx]\n        assert (len(samples) == '???')\n        assert (samples[0].shape == (this_batch_size, 1, feature_size))\n        for i in range(1, (1 + edge_types)):\n            assert (samples[i].shape == (this_batch_size, num_samples[0], feature_size))\n        for i in range((1 + edge_types), samples_per_head):\n            assert (samples[i].shape == (this_batch_size, np.product(num_samples), feature_size))\n        assert (labels is None)", "ground_truth": "samples_per_head", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_1003", "reponame": "stellargraph", "testpath": "tests/mapper/test_node_mappers.py", "testname": "test_node_mappers.py", "classname": null, "funcname": "test_hinsage_homogeneous_inference", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper import *", "import networkx as nx", "import numpy as np", "import random", "import pytest", "import pandas as pd", "import scipy.sparse as sps", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, create_graph_features, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_hinsage_homogeneous_inference():\n    feature_size = 4\n    edge_types = 3\n    batch_size = 2\n    num_samples = [5, 7]\n    G = example_graph_random(feature_size=feature_size, node_types=1, edge_types=edge_types)\n    mapper = HinSAGENodeGenerator(G, batch_size=batch_size, num_samples=num_samples)\n    assert (mapper.head_node_types == ['n-0'])\n    nodes = [1, 4, 2]\n    seq = mapper.flow(nodes)\n    assert (len(seq) == 2)\n    samples_per_head = ((1 + edge_types) + (edge_types * edge_types))\n    for (batch_idx, (samples, labels)) in enumerate(seq):\n        this_batch_size = {0: batch_size, 1: 1}[batch_idx]\n        assert (len(samples) == samples_per_head)\n        assert (samples[0].shape == (this_batch_size, 1, feature_size))\n        for i in range(1, (1 + edge_types)):\n            assert (samples[i].shape == (this_batch_size, num_samples[0], feature_size))\n        for i in range((1 + edge_types), samples_per_head):\n            assert (samples[i].shape == (this_batch_size, np.product(num_samples), feature_size))\n        assert (labels is None)", "masked_code": "def test_hinsage_homogeneous_inference():\n    feature_size = 4\n    edge_types = 3\n    batch_size = 2\n    num_samples = [5, 7]\n    G = example_graph_random(feature_size=feature_size, node_types=1, edge_types=edge_types)\n    mapper = HinSAGENodeGenerator(G, batch_size=batch_size, num_samples=num_samples)\n    assert (mapper.head_node_types == ['n-0'])\n    nodes = [1, 4, 2]\n    seq = mapper.flow(nodes)\n    assert (len(seq) == 2)\n    samples_per_head = ((1 + edge_types) + (edge_types * edge_types))\n    for (batch_idx, (samples, labels)) in enumerate(seq):\n        this_batch_size = {0: batch_size, 1: 1}[batch_idx]\n        assert (len(samples) == samples_per_head)\n        assert (samples[0].shape == '???')\n        for i in range(1, (1 + edge_types)):\n            assert (samples[i].shape == (this_batch_size, num_samples[0], feature_size))\n        for i in range((1 + edge_types), samples_per_head):\n            assert (samples[i].shape == (this_batch_size, np.product(num_samples), feature_size))\n        assert (labels is None)", "ground_truth": "(this_batch_size, 1, feature_size)", "quality_analysis": {"complexity_score": 7, "left_complexity": 2, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_1004", "reponame": "stellargraph", "testpath": "tests/mapper/test_node_mappers.py", "testname": "test_node_mappers.py", "classname": null, "funcname": "test_hinsage_homogeneous_inference", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper import *", "import networkx as nx", "import numpy as np", "import random", "import pytest", "import pandas as pd", "import scipy.sparse as sps", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, create_graph_features, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_hinsage_homogeneous_inference():\n    feature_size = 4\n    edge_types = 3\n    batch_size = 2\n    num_samples = [5, 7]\n    G = example_graph_random(feature_size=feature_size, node_types=1, edge_types=edge_types)\n    mapper = HinSAGENodeGenerator(G, batch_size=batch_size, num_samples=num_samples)\n    assert (mapper.head_node_types == ['n-0'])\n    nodes = [1, 4, 2]\n    seq = mapper.flow(nodes)\n    assert (len(seq) == 2)\n    samples_per_head = ((1 + edge_types) + (edge_types * edge_types))\n    for (batch_idx, (samples, labels)) in enumerate(seq):\n        this_batch_size = {0: batch_size, 1: 1}[batch_idx]\n        assert (len(samples) == samples_per_head)\n        assert (samples[0].shape == (this_batch_size, 1, feature_size))\n        for i in range(1, (1 + edge_types)):\n            assert (samples[i].shape == (this_batch_size, num_samples[0], feature_size))\n        for i in range((1 + edge_types), samples_per_head):\n            assert (samples[i].shape == (this_batch_size, np.product(num_samples), feature_size))\n        assert (labels is None)", "masked_code": "def test_hinsage_homogeneous_inference():\n    feature_size = 4\n    edge_types = 3\n    batch_size = 2\n    num_samples = [5, 7]\n    G = example_graph_random(feature_size=feature_size, node_types=1, edge_types=edge_types)\n    mapper = HinSAGENodeGenerator(G, batch_size=batch_size, num_samples=num_samples)\n    assert (mapper.head_node_types == ['n-0'])\n    nodes = [1, 4, 2]\n    seq = mapper.flow(nodes)\n    assert (len(seq) == 2)\n    samples_per_head = ((1 + edge_types) + (edge_types * edge_types))\n    for (batch_idx, (samples, labels)) in enumerate(seq):\n        this_batch_size = {0: batch_size, 1: 1}[batch_idx]\n        assert (len(samples) == samples_per_head)\n        assert (samples[0].shape == (this_batch_size, 1, feature_size))\n        for i in range(1, (1 + edge_types)):\n            assert (samples[i].shape == '???')\n        for i in range((1 + edge_types), samples_per_head):\n            assert (samples[i].shape == (this_batch_size, np.product(num_samples), feature_size))\n        assert (labels is None)", "ground_truth": "(this_batch_size, num_samples[0], feature_size)", "quality_analysis": {"complexity_score": 11, "left_complexity": 2, "right_complexity": 9, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_1005", "reponame": "stellargraph", "testpath": "tests/mapper/test_node_mappers.py", "testname": "test_node_mappers.py", "classname": null, "funcname": "test_hinsage_homogeneous_inference", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper import *", "import networkx as nx", "import numpy as np", "import random", "import pytest", "import pandas as pd", "import scipy.sparse as sps", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, create_graph_features, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_hinsage_homogeneous_inference():\n    feature_size = 4\n    edge_types = 3\n    batch_size = 2\n    num_samples = [5, 7]\n    G = example_graph_random(feature_size=feature_size, node_types=1, edge_types=edge_types)\n    mapper = HinSAGENodeGenerator(G, batch_size=batch_size, num_samples=num_samples)\n    assert (mapper.head_node_types == ['n-0'])\n    nodes = [1, 4, 2]\n    seq = mapper.flow(nodes)\n    assert (len(seq) == 2)\n    samples_per_head = ((1 + edge_types) + (edge_types * edge_types))\n    for (batch_idx, (samples, labels)) in enumerate(seq):\n        this_batch_size = {0: batch_size, 1: 1}[batch_idx]\n        assert (len(samples) == samples_per_head)\n        assert (samples[0].shape == (this_batch_size, 1, feature_size))\n        for i in range(1, (1 + edge_types)):\n            assert (samples[i].shape == (this_batch_size, num_samples[0], feature_size))\n        for i in range((1 + edge_types), samples_per_head):\n            assert (samples[i].shape == (this_batch_size, np.product(num_samples), feature_size))\n        assert (labels is None)", "masked_code": "def test_hinsage_homogeneous_inference():\n    feature_size = 4\n    edge_types = 3\n    batch_size = 2\n    num_samples = [5, 7]\n    G = example_graph_random(feature_size=feature_size, node_types=1, edge_types=edge_types)\n    mapper = HinSAGENodeGenerator(G, batch_size=batch_size, num_samples=num_samples)\n    assert (mapper.head_node_types == ['n-0'])\n    nodes = [1, 4, 2]\n    seq = mapper.flow(nodes)\n    assert (len(seq) == 2)\n    samples_per_head = ((1 + edge_types) + (edge_types * edge_types))\n    for (batch_idx, (samples, labels)) in enumerate(seq):\n        this_batch_size = {0: batch_size, 1: 1}[batch_idx]\n        assert (len(samples) == samples_per_head)\n        assert (samples[0].shape == (this_batch_size, 1, feature_size))\n        for i in range(1, (1 + edge_types)):\n            assert (samples[i].shape == (this_batch_size, num_samples[0], feature_size))\n        for i in range((1 + edge_types), samples_per_head):\n            assert (samples[i].shape == '???')\n        assert (labels is None)", "ground_truth": "(this_batch_size, np.product(num_samples), feature_size)", "quality_analysis": {"complexity_score": 10, "left_complexity": 2, "right_complexity": 8, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_1006", "reponame": "stellargraph", "testpath": "tests/mapper/test_node_mappers.py", "testname": "test_node_mappers.py", "classname": null, "funcname": "test_attri2vec_nodemapper_constructor", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper import *", "import networkx as nx", "import numpy as np", "import random", "import pytest", "import pandas as pd", "import scipy.sparse as sps", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, create_graph_features, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_attri2vec_nodemapper_constructor():\n    n_feat = 4\n    G = example_graph(feature_size=n_feat)\n    generator = Attri2VecNodeGenerator(G, batch_size=2)\n    mapper = generator.flow(list(G.nodes()))\n    assert (generator.batch_size == 2)\n    assert (mapper.data_size == 4)\n    assert (len(mapper.ids) == 4)", "masked_code": "def test_attri2vec_nodemapper_constructor():\n    n_feat = 4\n    G = example_graph(feature_size=n_feat)\n    generator = Attri2VecNodeGenerator(G, batch_size=2)\n    mapper = generator.flow(list(G.nodes()))\n    assert (generator.batch_size == 2)\n    assert (mapper.data_size == '???')\n    assert (len(mapper.ids) == 4)", "ground_truth": "4", "quality_analysis": {"complexity_score": 3, "left_complexity": 2, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_1007", "reponame": "stellargraph", "testpath": "tests/mapper/test_node_mappers.py", "testname": "test_node_mappers.py", "classname": null, "funcname": "test_attri2vec_nodemapper_constructor", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper import *", "import networkx as nx", "import numpy as np", "import random", "import pytest", "import pandas as pd", "import scipy.sparse as sps", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, create_graph_features, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_attri2vec_nodemapper_constructor():\n    n_feat = 4\n    G = example_graph(feature_size=n_feat)\n    generator = Attri2VecNodeGenerator(G, batch_size=2)\n    mapper = generator.flow(list(G.nodes()))\n    assert (generator.batch_size == 2)\n    assert (mapper.data_size == 4)\n    assert (len(mapper.ids) == 4)", "masked_code": "def test_attri2vec_nodemapper_constructor():\n    n_feat = 4\n    G = example_graph(feature_size=n_feat)\n    generator = Attri2VecNodeGenerator(G, batch_size=2)\n    mapper = generator.flow(list(G.nodes()))\n    assert (generator.batch_size == 2)\n    assert (mapper.data_size == 4)\n    assert (len(mapper.ids) == '???')", "ground_truth": "4", "quality_analysis": {"complexity_score": 6, "left_complexity": 5, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_1008", "reponame": "stellargraph", "testpath": "tests/mapper/test_node_mappers.py", "testname": "test_node_mappers.py", "classname": null, "funcname": "test_attri2vec_nodemapper_1", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper import *", "import networkx as nx", "import numpy as np", "import random", "import pytest", "import pandas as pd", "import scipy.sparse as sps", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, create_graph_features, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_attri2vec_nodemapper_1():\n    n_feat = 4\n    n_batch = 2\n    G1 = example_graph(n_feat)\n    mapper1 = Attri2VecNodeGenerator(G1, batch_size=n_batch).flow(G1.nodes())\n    assert (len(mapper1) == 2)\n    G2 = example_graph_2(n_feat)\n    mapper2 = Attri2VecNodeGenerator(G2, batch_size=n_batch).flow(G2.nodes())\n    assert (len(mapper2) == 3)\n    for mapper in [mapper1, mapper2]:\n        for ii in range(2):\n            (nf, nl) = mapper[ii]\n            assert (nf.shape == (n_batch, n_feat))\n            assert (nl is None)\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper1[len(mapper1)]\n    (nf, nl) = mapper2[(len(mapper2) - 1)]\n    assert (nf.shape == (1, n_feat))\n    with pytest.raises(KeyError):\n        Attri2VecNodeGenerator(G1, batch_size=2).flow(['A', 'B'])", "masked_code": "def test_attri2vec_nodemapper_1():\n    n_feat = 4\n    n_batch = 2\n    G1 = example_graph(n_feat)\n    mapper1 = Attri2VecNodeGenerator(G1, batch_size=n_batch).flow(G1.nodes())\n    assert (len(mapper1) == 2)\n    G2 = example_graph_2(n_feat)\n    mapper2 = Attri2VecNodeGenerator(G2, batch_size=n_batch).flow(G2.nodes())\n    assert (len(mapper2) == '???')\n    for mapper in [mapper1, mapper2]:\n        for ii in range(2):\n            (nf, nl) = mapper[ii]\n            assert (nf.shape == (n_batch, n_feat))\n            assert (nl is None)\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper1[len(mapper1)]\n    (nf, nl) = mapper2[(len(mapper2) - 1)]\n    assert (nf.shape == (1, n_feat))\n    with pytest.raises(KeyError):\n        Attri2VecNodeGenerator(G1, batch_size=2).flow(['A', 'B'])", "ground_truth": "3", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_1009", "reponame": "stellargraph", "testpath": "tests/mapper/test_node_mappers.py", "testname": "test_node_mappers.py", "classname": null, "funcname": "test_attri2vec_nodemapper_1", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper import *", "import networkx as nx", "import numpy as np", "import random", "import pytest", "import pandas as pd", "import scipy.sparse as sps", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, create_graph_features, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_attri2vec_nodemapper_1():\n    n_feat = 4\n    n_batch = 2\n    G1 = example_graph(n_feat)\n    mapper1 = Attri2VecNodeGenerator(G1, batch_size=n_batch).flow(G1.nodes())\n    assert (len(mapper1) == 2)\n    G2 = example_graph_2(n_feat)\n    mapper2 = Attri2VecNodeGenerator(G2, batch_size=n_batch).flow(G2.nodes())\n    assert (len(mapper2) == 3)\n    for mapper in [mapper1, mapper2]:\n        for ii in range(2):\n            (nf, nl) = mapper[ii]\n            assert (nf.shape == (n_batch, n_feat))\n            assert (nl is None)\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper1[len(mapper1)]\n    (nf, nl) = mapper2[(len(mapper2) - 1)]\n    assert (nf.shape == (1, n_feat))\n    with pytest.raises(KeyError):\n        Attri2VecNodeGenerator(G1, batch_size=2).flow(['A', 'B'])", "masked_code": "def test_attri2vec_nodemapper_1():\n    n_feat = 4\n    n_batch = 2\n    G1 = example_graph(n_feat)\n    mapper1 = Attri2VecNodeGenerator(G1, batch_size=n_batch).flow(G1.nodes())\n    assert (len(mapper1) == 2)\n    G2 = example_graph_2(n_feat)\n    mapper2 = Attri2VecNodeGenerator(G2, batch_size=n_batch).flow(G2.nodes())\n    assert (len(mapper2) == 3)\n    for mapper in [mapper1, mapper2]:\n        for ii in range(2):\n            (nf, nl) = mapper[ii]\n            assert (nf.shape == (n_batch, n_feat))\n            assert (nl is None)\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper1[len(mapper1)]\n    (nf, nl) = mapper2[(len(mapper2) - 1)]\n    assert (nf.shape == '???')\n    with pytest.raises(KeyError):\n        Attri2VecNodeGenerator(G1, batch_size=2).flow(['A', 'B'])", "ground_truth": "(1, n_feat)", "quality_analysis": {"complexity_score": 6, "left_complexity": 2, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_1010", "reponame": "stellargraph", "testpath": "tests/mapper/test_node_mappers.py", "testname": "test_node_mappers.py", "classname": null, "funcname": "test_attri2vec_nodemapper_1", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper import *", "import networkx as nx", "import numpy as np", "import random", "import pytest", "import pandas as pd", "import scipy.sparse as sps", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, create_graph_features, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_attri2vec_nodemapper_1():\n    n_feat = 4\n    n_batch = 2\n    G1 = example_graph(n_feat)\n    mapper1 = Attri2VecNodeGenerator(G1, batch_size=n_batch).flow(G1.nodes())\n    assert (len(mapper1) == 2)\n    G2 = example_graph_2(n_feat)\n    mapper2 = Attri2VecNodeGenerator(G2, batch_size=n_batch).flow(G2.nodes())\n    assert (len(mapper2) == 3)\n    for mapper in [mapper1, mapper2]:\n        for ii in range(2):\n            (nf, nl) = mapper[ii]\n            assert (nf.shape == (n_batch, n_feat))\n            assert (nl is None)\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper1[len(mapper1)]\n    (nf, nl) = mapper2[(len(mapper2) - 1)]\n    assert (nf.shape == (1, n_feat))\n    with pytest.raises(KeyError):\n        Attri2VecNodeGenerator(G1, batch_size=2).flow(['A', 'B'])", "masked_code": "def test_attri2vec_nodemapper_1():\n    n_feat = 4\n    n_batch = 2\n    G1 = example_graph(n_feat)\n    mapper1 = Attri2VecNodeGenerator(G1, batch_size=n_batch).flow(G1.nodes())\n    assert (len(mapper1) == 2)\n    G2 = example_graph_2(n_feat)\n    mapper2 = Attri2VecNodeGenerator(G2, batch_size=n_batch).flow(G2.nodes())\n    assert (len(mapper2) == 3)\n    for mapper in [mapper1, mapper2]:\n        for ii in range(2):\n            (nf, nl) = mapper[ii]\n            assert (nf.shape == '???')\n            assert (nl is None)\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper1[len(mapper1)]\n    (nf, nl) = mapper2[(len(mapper2) - 1)]\n    assert (nf.shape == (1, n_feat))\n    with pytest.raises(KeyError):\n        Attri2VecNodeGenerator(G1, batch_size=2).flow(['A', 'B'])", "ground_truth": "(n_batch, n_feat)", "quality_analysis": {"complexity_score": 6, "left_complexity": 2, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_1011", "reponame": "stellargraph", "testpath": "tests/mapper/test_node_mappers.py", "testname": "test_node_mappers.py", "classname": null, "funcname": "test_attri2vec_nodemapper_2", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper import *", "import networkx as nx", "import numpy as np", "import random", "import pytest", "import pandas as pd", "import scipy.sparse as sps", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, create_graph_features, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_attri2vec_nodemapper_2():\n    n_feat = 1\n    n_batch = 2\n    G = example_graph_2(feature_size=n_feat)\n    nodes = list(G.nodes())\n    mapper = Attri2VecNodeGenerator(G, batch_size=n_batch).flow(nodes)\n    expected_node_batches = [[1, 2], [3, 4], [5]]\n    assert (len(mapper) == 3)\n    for ii in range(len(mapper)):\n        (nf, nl) = mapper[ii]\n        assert all((np.ravel(nf) == expected_node_batches[ii]))", "masked_code": "def test_attri2vec_nodemapper_2():\n    n_feat = 1\n    n_batch = 2\n    G = example_graph_2(feature_size=n_feat)\n    nodes = list(G.nodes())\n    mapper = Attri2VecNodeGenerator(G, batch_size=n_batch).flow(nodes)\n    expected_node_batches = [[1, 2], [3, 4], [5]]\n    assert (len(mapper) == '???')\n    for ii in range(len(mapper)):\n        (nf, nl) = mapper[ii]\n        assert all((np.ravel(nf) == expected_node_batches[ii]))", "ground_truth": "3", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_1012", "reponame": "stellargraph", "testpath": "tests/mapper/test_node_mappers.py", "testname": "test_node_mappers.py", "classname": null, "funcname": "test_node2vec_nodemapper_constructor", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper import *", "import networkx as nx", "import numpy as np", "import random", "import pytest", "import pandas as pd", "import scipy.sparse as sps", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, create_graph_features, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_node2vec_nodemapper_constructor():\n    G = example_graph()\n    generator = Node2VecNodeGenerator(G, batch_size=2)\n    mapper = generator.flow(list(G.nodes()))\n    assert (generator.batch_size == 2)\n    assert (mapper.data_size == 4)\n    assert (len(mapper.ids) == 4)", "masked_code": "def test_node2vec_nodemapper_constructor():\n    G = example_graph()\n    generator = Node2VecNodeGenerator(G, batch_size=2)\n    mapper = generator.flow(list(G.nodes()))\n    assert (generator.batch_size == 2)\n    assert (mapper.data_size == '???')\n    assert (len(mapper.ids) == 4)", "ground_truth": "4", "quality_analysis": {"complexity_score": 3, "left_complexity": 2, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_1013", "reponame": "stellargraph", "testpath": "tests/mapper/test_node_mappers.py", "testname": "test_node_mappers.py", "classname": null, "funcname": "test_node2vec_nodemapper_constructor", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper import *", "import networkx as nx", "import numpy as np", "import random", "import pytest", "import pandas as pd", "import scipy.sparse as sps", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, create_graph_features, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_node2vec_nodemapper_constructor():\n    G = example_graph()\n    generator = Node2VecNodeGenerator(G, batch_size=2)\n    mapper = generator.flow(list(G.nodes()))\n    assert (generator.batch_size == 2)\n    assert (mapper.data_size == 4)\n    assert (len(mapper.ids) == 4)", "masked_code": "def test_node2vec_nodemapper_constructor():\n    G = example_graph()\n    generator = Node2VecNodeGenerator(G, batch_size=2)\n    mapper = generator.flow(list(G.nodes()))\n    assert (generator.batch_size == 2)\n    assert (mapper.data_size == 4)\n    assert (len(mapper.ids) == '???')", "ground_truth": "4", "quality_analysis": {"complexity_score": 6, "left_complexity": 5, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_1014", "reponame": "stellargraph", "testpath": "tests/mapper/test_node_mappers.py", "testname": "test_node_mappers.py", "classname": null, "funcname": "test_node2vec_nodemapper_1", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper import *", "import networkx as nx", "import numpy as np", "import random", "import pytest", "import pandas as pd", "import scipy.sparse as sps", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, create_graph_features, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_node2vec_nodemapper_1():\n    n_batch = 2\n    G1 = example_graph()\n    mapper1 = Node2VecNodeGenerator(G1, batch_size=n_batch).flow(G1.nodes())\n    assert (len(mapper1) == 2)\n    G2 = example_graph_2()\n    mapper2 = Node2VecNodeGenerator(G2, batch_size=n_batch).flow(G2.nodes())\n    assert (len(mapper2) == 3)\n    for mapper in [mapper1, mapper2]:\n        for ii in range(2):\n            (nf, nl) = mapper[ii]\n            assert (nf.shape == (n_batch,))\n            assert (nl is None)\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper1[len(mapper1)]\n    (nf, nl) = mapper2[(len(mapper2) - 1)]\n    assert (nf.shape == (1,))", "masked_code": "def test_node2vec_nodemapper_1():\n    n_batch = 2\n    G1 = example_graph()\n    mapper1 = Node2VecNodeGenerator(G1, batch_size=n_batch).flow(G1.nodes())\n    assert (len(mapper1) == 2)\n    G2 = example_graph_2()\n    mapper2 = Node2VecNodeGenerator(G2, batch_size=n_batch).flow(G2.nodes())\n    assert (len(mapper2) == '???')\n    for mapper in [mapper1, mapper2]:\n        for ii in range(2):\n            (nf, nl) = mapper[ii]\n            assert (nf.shape == (n_batch,))\n            assert (nl is None)\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper1[len(mapper1)]\n    (nf, nl) = mapper2[(len(mapper2) - 1)]\n    assert (nf.shape == (1,))", "ground_truth": "3", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_1015", "reponame": "stellargraph", "testpath": "tests/mapper/test_node_mappers.py", "testname": "test_node_mappers.py", "classname": null, "funcname": "test_node2vec_nodemapper_1", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper import *", "import networkx as nx", "import numpy as np", "import random", "import pytest", "import pandas as pd", "import scipy.sparse as sps", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, create_graph_features, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_node2vec_nodemapper_1():\n    n_batch = 2\n    G1 = example_graph()\n    mapper1 = Node2VecNodeGenerator(G1, batch_size=n_batch).flow(G1.nodes())\n    assert (len(mapper1) == 2)\n    G2 = example_graph_2()\n    mapper2 = Node2VecNodeGenerator(G2, batch_size=n_batch).flow(G2.nodes())\n    assert (len(mapper2) == 3)\n    for mapper in [mapper1, mapper2]:\n        for ii in range(2):\n            (nf, nl) = mapper[ii]\n            assert (nf.shape == (n_batch,))\n            assert (nl is None)\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper1[len(mapper1)]\n    (nf, nl) = mapper2[(len(mapper2) - 1)]\n    assert (nf.shape == (1,))", "masked_code": "def test_node2vec_nodemapper_1():\n    n_batch = 2\n    G1 = example_graph()\n    mapper1 = Node2VecNodeGenerator(G1, batch_size=n_batch).flow(G1.nodes())\n    assert (len(mapper1) == 2)\n    G2 = example_graph_2()\n    mapper2 = Node2VecNodeGenerator(G2, batch_size=n_batch).flow(G2.nodes())\n    assert (len(mapper2) == 3)\n    for mapper in [mapper1, mapper2]:\n        for ii in range(2):\n            (nf, nl) = mapper[ii]\n            assert (nf.shape == (n_batch,))\n            assert (nl is None)\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper1[len(mapper1)]\n    (nf, nl) = mapper2[(len(mapper2) - 1)]\n    assert (nf.shape == '???')", "ground_truth": "(1,)", "quality_analysis": {"complexity_score": 5, "left_complexity": 2, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_1016", "reponame": "stellargraph", "testpath": "tests/mapper/test_node_mappers.py", "testname": "test_node_mappers.py", "classname": null, "funcname": "test_node2vec_nodemapper_1", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper import *", "import networkx as nx", "import numpy as np", "import random", "import pytest", "import pandas as pd", "import scipy.sparse as sps", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, create_graph_features, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_node2vec_nodemapper_1():\n    n_batch = 2\n    G1 = example_graph()\n    mapper1 = Node2VecNodeGenerator(G1, batch_size=n_batch).flow(G1.nodes())\n    assert (len(mapper1) == 2)\n    G2 = example_graph_2()\n    mapper2 = Node2VecNodeGenerator(G2, batch_size=n_batch).flow(G2.nodes())\n    assert (len(mapper2) == 3)\n    for mapper in [mapper1, mapper2]:\n        for ii in range(2):\n            (nf, nl) = mapper[ii]\n            assert (nf.shape == (n_batch,))\n            assert (nl is None)\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper1[len(mapper1)]\n    (nf, nl) = mapper2[(len(mapper2) - 1)]\n    assert (nf.shape == (1,))", "masked_code": "def test_node2vec_nodemapper_1():\n    n_batch = 2\n    G1 = example_graph()\n    mapper1 = Node2VecNodeGenerator(G1, batch_size=n_batch).flow(G1.nodes())\n    assert (len(mapper1) == 2)\n    G2 = example_graph_2()\n    mapper2 = Node2VecNodeGenerator(G2, batch_size=n_batch).flow(G2.nodes())\n    assert (len(mapper2) == 3)\n    for mapper in [mapper1, mapper2]:\n        for ii in range(2):\n            (nf, nl) = mapper[ii]\n            assert (nf.shape == '???')\n            assert (nl is None)\n    with pytest.raises(IndexError):\n        (nf, nl) = mapper1[len(mapper1)]\n    (nf, nl) = mapper2[(len(mapper2) - 1)]\n    assert (nf.shape == (1,))", "ground_truth": "(n_batch,)", "quality_analysis": {"complexity_score": 5, "left_complexity": 2, "right_complexity": 3, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_1017", "reponame": "stellargraph", "testpath": "tests/mapper/test_node_mappers.py", "testname": "test_node_mappers.py", "classname": null, "funcname": "test_node2vec_nodemapper_2", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper import *", "import networkx as nx", "import numpy as np", "import random", "import pytest", "import pandas as pd", "import scipy.sparse as sps", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, create_graph_features, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_node2vec_nodemapper_2():\n    n_batch = 2\n    G = example_graph_2()\n    nodes = list(G.nodes())\n    mapper = Node2VecNodeGenerator(G, batch_size=n_batch).flow(nodes)\n    expected_node_batches = [G.node_ids_to_ilocs([1, 2]), G.node_ids_to_ilocs([3, 4]), G.node_ids_to_ilocs([5])]\n    assert (len(mapper) == 3)\n    for ii in range(len(mapper)):\n        (nf, nl) = mapper[ii]\n        assert all((np.ravel(nf) == expected_node_batches[ii]))", "masked_code": "def test_node2vec_nodemapper_2():\n    n_batch = 2\n    G = example_graph_2()\n    nodes = list(G.nodes())\n    mapper = Node2VecNodeGenerator(G, batch_size=n_batch).flow(nodes)\n    expected_node_batches = [G.node_ids_to_ilocs([1, 2]), G.node_ids_to_ilocs([3, 4]), G.node_ids_to_ilocs([5])]\n    assert (len(mapper) == '???')\n    for ii in range(len(mapper)):\n        (nf, nl) = mapper[ii]\n        assert all((np.ravel(nf) == expected_node_batches[ii]))", "ground_truth": "3", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_1018", "reponame": "stellargraph", "testpath": "tests/mapper/test_node_mappers.py", "testname": "test_node_mappers.py", "classname": "Test_FullBatchNodeGenerator", "funcname": "test_generator_constructor", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper import *", "import networkx as nx", "import numpy as np", "import random", "import pytest", "import pandas as pd", "import scipy.sparse as sps", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, create_graph_features, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_generator_constructor(self):\n    generator = FullBatchNodeGenerator(self.G)\n    assert (generator.Aadj.shape == (self.N, self.N))\n    assert (generator.features.shape == (self.N, self.n_feat))", "masked_code": "def test_generator_constructor(self):\n    generator = FullBatchNodeGenerator(self.G)\n    assert (generator.Aadj.shape == '???')\n    assert (generator.features.shape == (self.N, self.n_feat))", "ground_truth": "(self.N, self.N)", "quality_analysis": {"complexity_score": 8, "left_complexity": 2, "right_complexity": 6, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_1019", "reponame": "stellargraph", "testpath": "tests/mapper/test_node_mappers.py", "testname": "test_node_mappers.py", "classname": "Test_FullBatchNodeGenerator", "funcname": "test_generator_constructor", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper import *", "import networkx as nx", "import numpy as np", "import random", "import pytest", "import pandas as pd", "import scipy.sparse as sps", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, create_graph_features, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_generator_constructor(self):\n    generator = FullBatchNodeGenerator(self.G)\n    assert (generator.Aadj.shape == (self.N, self.N))\n    assert (generator.features.shape == (self.N, self.n_feat))", "masked_code": "def test_generator_constructor(self):\n    generator = FullBatchNodeGenerator(self.G)\n    assert (generator.Aadj.shape == (self.N, self.N))\n    assert (generator.features.shape == '???')", "ground_truth": "(self.N, self.n_feat)", "quality_analysis": {"complexity_score": 8, "left_complexity": 2, "right_complexity": 6, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_1020", "reponame": "stellargraph", "testpath": "tests/mapper/test_node_mappers.py", "testname": "test_node_mappers.py", "classname": "Test_FullBatchNodeGenerator", "funcname": "test_generator_flow_targets_as_list", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper import *", "import networkx as nx", "import numpy as np", "import random", "import pytest", "import pandas as pd", "import scipy.sparse as sps", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, create_graph_features, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_generator_flow_targets_as_list(self):\n    generator = FullBatchNodeGenerator(self.G)\n    node_ids = list(self.G.nodes())[:3]\n    node_targets = ([1] * len(node_ids))\n    gen = generator.flow(node_ids, node_targets)\n    (inputs, y) = gen[0]\n    assert (y.shape == (1, 3))\n    assert (np.sum(y) == 3)", "masked_code": "def test_generator_flow_targets_as_list(self):\n    generator = FullBatchNodeGenerator(self.G)\n    node_ids = list(self.G.nodes())[:3]\n    node_targets = ([1] * len(node_ids))\n    gen = generator.flow(node_ids, node_targets)\n    (inputs, y) = gen[0]\n    assert (y.shape == '???')\n    assert (np.sum(y) == 3)", "ground_truth": "(1, 3)", "quality_analysis": {"complexity_score": 6, "left_complexity": 2, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_1021", "reponame": "stellargraph", "testpath": "tests/mapper/test_node_mappers.py", "testname": "test_node_mappers.py", "classname": "Test_FullBatchNodeGenerator", "funcname": "test_generator_flow_targets_as_list", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper import *", "import networkx as nx", "import numpy as np", "import random", "import pytest", "import pandas as pd", "import scipy.sparse as sps", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, create_graph_features, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_generator_flow_targets_as_list(self):\n    generator = FullBatchNodeGenerator(self.G)\n    node_ids = list(self.G.nodes())[:3]\n    node_targets = ([1] * len(node_ids))\n    gen = generator.flow(node_ids, node_targets)\n    (inputs, y) = gen[0]\n    assert (y.shape == (1, 3))\n    assert (np.sum(y) == 3)", "masked_code": "def test_generator_flow_targets_as_list(self):\n    generator = FullBatchNodeGenerator(self.G)\n    node_ids = list(self.G.nodes())[:3]\n    node_targets = ([1] * len(node_ids))\n    gen = generator.flow(node_ids, node_targets)\n    (inputs, y) = gen[0]\n    assert (y.shape == (1, 3))\n    assert (np.sum(y) == '???')", "ground_truth": "3", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_1022", "reponame": "stellargraph", "testpath": "tests/mapper/test_node_mappers.py", "testname": "test_node_mappers.py", "classname": "Test_FullBatchNodeGenerator", "funcname": "test_fullbatch_generator_transform", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper import *", "import networkx as nx", "import numpy as np", "import random", "import pytest", "import pandas as pd", "import scipy.sparse as sps", "from ..test_utils.graphs import example_graph, example_graph_random, example_hin_1, create_graph_features, repeated_features, weighted_tree", "from .. import test_utils"], "code": "def test_fullbatch_generator_transform(self):\n    (G, _) = create_graph_features()\n\n    def func(features, A, **kwargs):\n        return (features, A.dot(A))\n    generator = FullBatchNodeGenerator(G, 'test', transform=func)\n    assert (generator.name == 'test')\n    A = G.to_adjacency_matrix().toarray()\n    np.testing.assert_array_equal(A.dot(A), generator.Aadj.toarray())", "masked_code": "def test_fullbatch_generator_transform(self):\n    (G, _) = create_graph_features()\n\n    def func(features, A, **kwargs):\n        return (features, A.dot(A))\n    generator = FullBatchNodeGenerator(G, 'test', transform=func)\n    assert (generator.name == '???')\n    A = G.to_adjacency_matrix().toarray()\n    np.testing.assert_array_equal(A.dot(A), generator.Aadj.toarray())", "ground_truth": "'test'", "quality_analysis": {"complexity_score": 3, "left_complexity": 2, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_1023", "reponame": "stellargraph", "testpath": "tests/mapper/test_padded_graph_generator.py", "testname": "test_padded_graph_generator.py", "classname": null, "funcname": "test_generator_init", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper.padded_graph_generator import PaddedGraphGenerator, PaddedGraphSequence", "import numpy as np", "import pytest", "from ..test_utils.graphs import example_graph_random, example_graph, example_hin_1"], "code": "def test_generator_init():\n    generator = PaddedGraphGenerator(graphs=graphs)\n    assert (len(generator.graphs) == len(graphs))", "masked_code": "def test_generator_init():\n    generator = PaddedGraphGenerator(graphs=graphs)\n    assert (len(generator.graphs) == '???')", "ground_truth": "len(graphs)", "quality_analysis": {"complexity_score": 9, "left_complexity": 5, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_1024", "reponame": "stellargraph", "testpath": "tests/mapper/test_padded_graph_generator.py", "testname": "test_padded_graph_generator.py", "classname": null, "funcname": "test_generator_flow_no_targets", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper.padded_graph_generator import PaddedGraphGenerator, PaddedGraphSequence", "import numpy as np", "import pytest", "from ..test_utils.graphs import example_graph_random, example_graph, example_hin_1"], "code": "def test_generator_flow_no_targets():\n    generator = PaddedGraphGenerator(graphs=graphs)\n    seq = generator.flow(graphs=[0, 1, 2], batch_size=2)\n    assert isinstance(seq, PaddedGraphSequence)\n    assert (len(seq) == 2)\n    (values_0, targets_0) = seq[0]\n    assert (len(values_0) == 3)\n    assert (values_0[0].shape[0] == 2)\n    assert (values_0[1].shape[0] == 2)\n    assert (values_0[2].shape[0] == 2)\n    assert (targets_0 is None)\n    (values_1, targets_1) = seq[1]\n    assert (len(values_1) == 3)\n    assert (values_1[0].shape[0] == 1)\n    assert (values_1[1].shape[0] == 1)\n    assert (values_1[2].shape[0] == 1)\n    assert (targets_1 is None)", "masked_code": "def test_generator_flow_no_targets():\n    generator = PaddedGraphGenerator(graphs=graphs)\n    seq = generator.flow(graphs=[0, 1, 2], batch_size=2)\n    assert isinstance(seq, PaddedGraphSequence)\n    assert (len(seq) == 2)\n    (values_0, targets_0) = seq[0]\n    assert (len(values_0) == '???')\n    assert (values_0[0].shape[0] == 2)\n    assert (values_0[1].shape[0] == 2)\n    assert (values_0[2].shape[0] == 2)\n    assert (targets_0 is None)\n    (values_1, targets_1) = seq[1]\n    assert (len(values_1) == 3)\n    assert (values_1[0].shape[0] == 1)\n    assert (values_1[1].shape[0] == 1)\n    assert (values_1[2].shape[0] == 1)\n    assert (targets_1 is None)", "ground_truth": "3", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_1025", "reponame": "stellargraph", "testpath": "tests/mapper/test_padded_graph_generator.py", "testname": "test_padded_graph_generator.py", "classname": null, "funcname": "test_generator_flow_no_targets", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper.padded_graph_generator import PaddedGraphGenerator, PaddedGraphSequence", "import numpy as np", "import pytest", "from ..test_utils.graphs import example_graph_random, example_graph, example_hin_1"], "code": "def test_generator_flow_no_targets():\n    generator = PaddedGraphGenerator(graphs=graphs)\n    seq = generator.flow(graphs=[0, 1, 2], batch_size=2)\n    assert isinstance(seq, PaddedGraphSequence)\n    assert (len(seq) == 2)\n    (values_0, targets_0) = seq[0]\n    assert (len(values_0) == 3)\n    assert (values_0[0].shape[0] == 2)\n    assert (values_0[1].shape[0] == 2)\n    assert (values_0[2].shape[0] == 2)\n    assert (targets_0 is None)\n    (values_1, targets_1) = seq[1]\n    assert (len(values_1) == 3)\n    assert (values_1[0].shape[0] == 1)\n    assert (values_1[1].shape[0] == 1)\n    assert (values_1[2].shape[0] == 1)\n    assert (targets_1 is None)", "masked_code": "def test_generator_flow_no_targets():\n    generator = PaddedGraphGenerator(graphs=graphs)\n    seq = generator.flow(graphs=[0, 1, 2], batch_size=2)\n    assert isinstance(seq, PaddedGraphSequence)\n    assert (len(seq) == 2)\n    (values_0, targets_0) = seq[0]\n    assert (len(values_0) == 3)\n    assert (values_0[0].shape[0] == 2)\n    assert (values_0[1].shape[0] == 2)\n    assert (values_0[2].shape[0] == 2)\n    assert (targets_0 is None)\n    (values_1, targets_1) = seq[1]\n    assert (len(values_1) == '???')\n    assert (values_1[0].shape[0] == 1)\n    assert (values_1[1].shape[0] == 1)\n    assert (values_1[2].shape[0] == 1)\n    assert (targets_1 is None)", "ground_truth": "3", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_1026", "reponame": "stellargraph", "testpath": "tests/mapper/test_padded_graph_generator.py", "testname": "test_padded_graph_generator.py", "classname": null, "funcname": "test_generator_flow_check_padding", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper.padded_graph_generator import PaddedGraphGenerator, PaddedGraphSequence", "import numpy as np", "import pytest", "from ..test_utils.graphs import example_graph_random, example_graph, example_hin_1"], "code": "def test_generator_flow_check_padding():\n    generator = PaddedGraphGenerator(graphs=graphs)\n    seq = generator.flow(graphs=[0, 2], batch_size=2)\n    assert isinstance(seq, PaddedGraphSequence)\n    assert (len(seq) == 1)\n    batch = seq[0]\n    assert (batch[0][0].shape == (2, 6, 4))\n    assert (batch[0][1].shape == (2, 6))\n    assert (batch[0][2].shape == (2, 6, 6))\n    for mask in batch[0][1]:\n        assert ((np.sum(mask) == 6) or (np.sum(mask) == 3))", "masked_code": "def test_generator_flow_check_padding():\n    generator = PaddedGraphGenerator(graphs=graphs)\n    seq = generator.flow(graphs=[0, 2], batch_size=2)\n    assert isinstance(seq, PaddedGraphSequence)\n    assert (len(seq) == 1)\n    batch = seq[0]\n    assert (batch[0][0].shape == '???')\n    assert (batch[0][1].shape == (2, 6))\n    assert (batch[0][2].shape == (2, 6, 6))\n    for mask in batch[0][1]:\n        assert ((np.sum(mask) == 6) or (np.sum(mask) == 3))", "ground_truth": "(2, 6, 4)", "quality_analysis": {"complexity_score": 7, "left_complexity": 2, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_1027", "reponame": "stellargraph", "testpath": "tests/mapper/test_padded_graph_generator.py", "testname": "test_padded_graph_generator.py", "classname": null, "funcname": "test_generator_flow_check_padding", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper.padded_graph_generator import PaddedGraphGenerator, PaddedGraphSequence", "import numpy as np", "import pytest", "from ..test_utils.graphs import example_graph_random, example_graph, example_hin_1"], "code": "def test_generator_flow_check_padding():\n    generator = PaddedGraphGenerator(graphs=graphs)\n    seq = generator.flow(graphs=[0, 2], batch_size=2)\n    assert isinstance(seq, PaddedGraphSequence)\n    assert (len(seq) == 1)\n    batch = seq[0]\n    assert (batch[0][0].shape == (2, 6, 4))\n    assert (batch[0][1].shape == (2, 6))\n    assert (batch[0][2].shape == (2, 6, 6))\n    for mask in batch[0][1]:\n        assert ((np.sum(mask) == 6) or (np.sum(mask) == 3))", "masked_code": "def test_generator_flow_check_padding():\n    generator = PaddedGraphGenerator(graphs=graphs)\n    seq = generator.flow(graphs=[0, 2], batch_size=2)\n    assert isinstance(seq, PaddedGraphSequence)\n    assert (len(seq) == 1)\n    batch = seq[0]\n    assert (batch[0][0].shape == (2, 6, 4))\n    assert (batch[0][1].shape == '???')\n    assert (batch[0][2].shape == (2, 6, 6))\n    for mask in batch[0][1]:\n        assert ((np.sum(mask) == 6) or (np.sum(mask) == 3))", "ground_truth": "(2, 6)", "quality_analysis": {"complexity_score": 6, "left_complexity": 2, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_1028", "reponame": "stellargraph", "testpath": "tests/mapper/test_padded_graph_generator.py", "testname": "test_padded_graph_generator.py", "classname": null, "funcname": "test_generator_flow_check_padding", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper.padded_graph_generator import PaddedGraphGenerator, PaddedGraphSequence", "import numpy as np", "import pytest", "from ..test_utils.graphs import example_graph_random, example_graph, example_hin_1"], "code": "def test_generator_flow_check_padding():\n    generator = PaddedGraphGenerator(graphs=graphs)\n    seq = generator.flow(graphs=[0, 2], batch_size=2)\n    assert isinstance(seq, PaddedGraphSequence)\n    assert (len(seq) == 1)\n    batch = seq[0]\n    assert (batch[0][0].shape == (2, 6, 4))\n    assert (batch[0][1].shape == (2, 6))\n    assert (batch[0][2].shape == (2, 6, 6))\n    for mask in batch[0][1]:\n        assert ((np.sum(mask) == 6) or (np.sum(mask) == 3))", "masked_code": "def test_generator_flow_check_padding():\n    generator = PaddedGraphGenerator(graphs=graphs)\n    seq = generator.flow(graphs=[0, 2], batch_size=2)\n    assert isinstance(seq, PaddedGraphSequence)\n    assert (len(seq) == 1)\n    batch = seq[0]\n    assert (batch[0][0].shape == (2, 6, 4))\n    assert (batch[0][1].shape == (2, 6))\n    assert (batch[0][2].shape == '???')\n    for mask in batch[0][1]:\n        assert ((np.sum(mask) == 6) or (np.sum(mask) == 3))", "ground_truth": "(2, 6, 6)", "quality_analysis": {"complexity_score": 7, "left_complexity": 2, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_1029", "reponame": "stellargraph", "testpath": "tests/mapper/test_padded_graph_generator.py", "testname": "test_padded_graph_generator.py", "classname": null, "funcname": "test_generator_flow_StellarGraphs", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper.padded_graph_generator import PaddedGraphGenerator, PaddedGraphSequence", "import numpy as np", "import pytest", "from ..test_utils.graphs import example_graph_random, example_graph, example_hin_1"], "code": "def test_generator_flow_StellarGraphs():\n    generator = PaddedGraphGenerator(graphs=graphs)\n    graph_ilocs = [1, 2, 0]\n    seq_1 = generator.flow(graph_ilocs)\n    seq_2 = generator.flow([graphs[1], graphs[2], graphs[0]])\n    assert (len(seq_1) == len(seq_2) == 3)\n    for ((values_1, targets_1), (values_2, targets_2)) in zip(seq_1, seq_2):\n        assert (len(values_1) == len(values_2) == 3)\n        assert (targets_1 is targets_2 is None)\n        for (arr_1, arr_2) in zip(values_1, values_2):\n            np.testing.assert_array_equal(arr_1, arr_2)", "masked_code": "def test_generator_flow_StellarGraphs():\n    generator = PaddedGraphGenerator(graphs=graphs)\n    graph_ilocs = [1, 2, 0]\n    seq_1 = generator.flow(graph_ilocs)\n    seq_2 = generator.flow([graphs[1], graphs[2], graphs[0]])\n    assert (len(seq_1) == '???' == 3)\n    for ((values_1, targets_1), (values_2, targets_2)) in zip(seq_1, seq_2):\n        assert (len(values_1) == len(values_2) == 3)\n        assert (targets_1 is targets_2 is None)\n        for (arr_1, arr_2) in zip(values_1, values_2):\n            np.testing.assert_array_equal(arr_1, arr_2)", "ground_truth": "len(seq_2)", "quality_analysis": {"complexity_score": 8, "left_complexity": 4, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_1030", "reponame": "stellargraph", "testpath": "tests/mapper/test_padded_graph_generator.py", "testname": "test_padded_graph_generator.py", "classname": null, "funcname": "test_generator_flow_StellarGraphs", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper.padded_graph_generator import PaddedGraphGenerator, PaddedGraphSequence", "import numpy as np", "import pytest", "from ..test_utils.graphs import example_graph_random, example_graph, example_hin_1"], "code": "def test_generator_flow_StellarGraphs():\n    generator = PaddedGraphGenerator(graphs=graphs)\n    graph_ilocs = [1, 2, 0]\n    seq_1 = generator.flow(graph_ilocs)\n    seq_2 = generator.flow([graphs[1], graphs[2], graphs[0]])\n    assert (len(seq_1) == len(seq_2) == 3)\n    for ((values_1, targets_1), (values_2, targets_2)) in zip(seq_1, seq_2):\n        assert (len(values_1) == len(values_2) == 3)\n        assert (targets_1 is targets_2 is None)\n        for (arr_1, arr_2) in zip(values_1, values_2):\n            np.testing.assert_array_equal(arr_1, arr_2)", "masked_code": "def test_generator_flow_StellarGraphs():\n    generator = PaddedGraphGenerator(graphs=graphs)\n    graph_ilocs = [1, 2, 0]\n    seq_1 = generator.flow(graph_ilocs)\n    seq_2 = generator.flow([graphs[1], graphs[2], graphs[0]])\n    assert (len(seq_1) == len(seq_2) == 3)\n    for ((values_1, targets_1), (values_2, targets_2)) in zip(seq_1, seq_2):\n        assert (len(values_1) == '???' == 3)\n        assert (targets_1 is targets_2 is None)\n        for (arr_1, arr_2) in zip(values_1, values_2):\n            np.testing.assert_array_equal(arr_1, arr_2)", "ground_truth": "len(values_2)", "quality_analysis": {"complexity_score": 8, "left_complexity": 4, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_1031", "reponame": "stellargraph", "testpath": "tests/mapper/test_padded_graph_generator.py", "testname": "test_padded_graph_generator.py", "classname": null, "funcname": "test_generator_pairs", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper.padded_graph_generator import PaddedGraphGenerator, PaddedGraphSequence", "import numpy as np", "import pytest", "from ..test_utils.graphs import example_graph_random, example_graph, example_hin_1"], "code": "@pytest.mark.parametrize('use_targets', [False, True])\n@pytest.mark.parametrize('use_ilocs', [False, True])\ndef test_generator_pairs(use_targets, use_ilocs):\n    generator = PaddedGraphGenerator(graphs=graphs)\n    targets = ([12, 34, 56] if use_targets else None)\n    ilocs = [(1, 0), (0, 2), (2, 1)]\n    input = (ilocs if use_ilocs else [[graphs[x] for x in pair] for pair in ilocs])\n    seq = generator.flow(input, targets=targets, batch_size=2)\n    assert (len(seq) == 2)\n    (values_0, targets_0) = seq[0]\n    assert (len(values_0) == 6)\n    assert (values_0[0].shape == (2, 6, 4))\n    assert (values_0[3].shape == (2, 6, 4))\n    np.testing.assert_array_equal(values_0[1], [_mask(5, 6), _mask(6, 6)])\n    np.testing.assert_array_equal(values_0[4], [_mask(6, 6), _mask(3, 6)])\n    assert (values_0[2].shape == (2, 6, 6))\n    assert (values_0[5].shape == (2, 6, 6))\n    if use_targets:\n        np.testing.assert_array_equal(targets_0, [12, 34])\n    else:\n        assert (targets_0 is None)\n    (values_1, targets_1) = seq[1]\n    assert (len(values_1) == 6)\n    assert (values_1[0].shape == (1, 5, 4))\n    assert (values_1[3].shape == (1, 5, 4))\n    np.testing.assert_array_equal(values_1[1], [_mask(3, 5)])\n    np.testing.assert_array_equal(values_1[4], [_mask(5, 5)])\n    assert (values_1[2].shape == (1, 5, 5))\n    assert (values_1[5].shape == (1, 5, 5))\n    if use_targets:\n        np.testing.assert_array_equal(targets_1, [56])\n    else:\n        assert (targets_1 is None)", "masked_code": "@pytest.mark.parametrize('use_targets', [False, True])\n@pytest.mark.parametrize('use_ilocs', [False, True])\ndef test_generator_pairs(use_targets, use_ilocs):\n    generator = PaddedGraphGenerator(graphs=graphs)\n    targets = ([12, 34, 56] if use_targets else None)\n    ilocs = [(1, 0), (0, 2), (2, 1)]\n    input = (ilocs if use_ilocs else [[graphs[x] for x in pair] for pair in ilocs])\n    seq = generator.flow(input, targets=targets, batch_size=2)\n    assert (len(seq) == 2)\n    (values_0, targets_0) = seq[0]\n    assert (len(values_0) == '???')\n    assert (values_0[0].shape == (2, 6, 4))\n    assert (values_0[3].shape == (2, 6, 4))\n    np.testing.assert_array_equal(values_0[1], [_mask(5, 6), _mask(6, 6)])\n    np.testing.assert_array_equal(values_0[4], [_mask(6, 6), _mask(3, 6)])\n    assert (values_0[2].shape == (2, 6, 6))\n    assert (values_0[5].shape == (2, 6, 6))\n    if use_targets:\n        np.testing.assert_array_equal(targets_0, [12, 34])\n    else:\n        assert (targets_0 is None)\n    (values_1, targets_1) = seq[1]\n    assert (len(values_1) == 6)\n    assert (values_1[0].shape == (1, 5, 4))\n    assert (values_1[3].shape == (1, 5, 4))\n    np.testing.assert_array_equal(values_1[1], [_mask(3, 5)])\n    np.testing.assert_array_equal(values_1[4], [_mask(5, 5)])\n    assert (values_1[2].shape == (1, 5, 5))\n    assert (values_1[5].shape == (1, 5, 5))\n    if use_targets:\n        np.testing.assert_array_equal(targets_1, [56])\n    else:\n        assert (targets_1 is None)", "ground_truth": "6", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_1032", "reponame": "stellargraph", "testpath": "tests/mapper/test_padded_graph_generator.py", "testname": "test_padded_graph_generator.py", "classname": null, "funcname": "test_generator_pairs", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper.padded_graph_generator import PaddedGraphGenerator, PaddedGraphSequence", "import numpy as np", "import pytest", "from ..test_utils.graphs import example_graph_random, example_graph, example_hin_1"], "code": "@pytest.mark.parametrize('use_targets', [False, True])\n@pytest.mark.parametrize('use_ilocs', [False, True])\ndef test_generator_pairs(use_targets, use_ilocs):\n    generator = PaddedGraphGenerator(graphs=graphs)\n    targets = ([12, 34, 56] if use_targets else None)\n    ilocs = [(1, 0), (0, 2), (2, 1)]\n    input = (ilocs if use_ilocs else [[graphs[x] for x in pair] for pair in ilocs])\n    seq = generator.flow(input, targets=targets, batch_size=2)\n    assert (len(seq) == 2)\n    (values_0, targets_0) = seq[0]\n    assert (len(values_0) == 6)\n    assert (values_0[0].shape == (2, 6, 4))\n    assert (values_0[3].shape == (2, 6, 4))\n    np.testing.assert_array_equal(values_0[1], [_mask(5, 6), _mask(6, 6)])\n    np.testing.assert_array_equal(values_0[4], [_mask(6, 6), _mask(3, 6)])\n    assert (values_0[2].shape == (2, 6, 6))\n    assert (values_0[5].shape == (2, 6, 6))\n    if use_targets:\n        np.testing.assert_array_equal(targets_0, [12, 34])\n    else:\n        assert (targets_0 is None)\n    (values_1, targets_1) = seq[1]\n    assert (len(values_1) == 6)\n    assert (values_1[0].shape == (1, 5, 4))\n    assert (values_1[3].shape == (1, 5, 4))\n    np.testing.assert_array_equal(values_1[1], [_mask(3, 5)])\n    np.testing.assert_array_equal(values_1[4], [_mask(5, 5)])\n    assert (values_1[2].shape == (1, 5, 5))\n    assert (values_1[5].shape == (1, 5, 5))\n    if use_targets:\n        np.testing.assert_array_equal(targets_1, [56])\n    else:\n        assert (targets_1 is None)", "masked_code": "@pytest.mark.parametrize('use_targets', [False, True])\n@pytest.mark.parametrize('use_ilocs', [False, True])\ndef test_generator_pairs(use_targets, use_ilocs):\n    generator = PaddedGraphGenerator(graphs=graphs)\n    targets = ([12, 34, 56] if use_targets else None)\n    ilocs = [(1, 0), (0, 2), (2, 1)]\n    input = (ilocs if use_ilocs else [[graphs[x] for x in pair] for pair in ilocs])\n    seq = generator.flow(input, targets=targets, batch_size=2)\n    assert (len(seq) == 2)\n    (values_0, targets_0) = seq[0]\n    assert (len(values_0) == 6)\n    assert (values_0[0].shape == '???')\n    assert (values_0[3].shape == (2, 6, 4))\n    np.testing.assert_array_equal(values_0[1], [_mask(5, 6), _mask(6, 6)])\n    np.testing.assert_array_equal(values_0[4], [_mask(6, 6), _mask(3, 6)])\n    assert (values_0[2].shape == (2, 6, 6))\n    assert (values_0[5].shape == (2, 6, 6))\n    if use_targets:\n        np.testing.assert_array_equal(targets_0, [12, 34])\n    else:\n        assert (targets_0 is None)\n    (values_1, targets_1) = seq[1]\n    assert (len(values_1) == 6)\n    assert (values_1[0].shape == (1, 5, 4))\n    assert (values_1[3].shape == (1, 5, 4))\n    np.testing.assert_array_equal(values_1[1], [_mask(3, 5)])\n    np.testing.assert_array_equal(values_1[4], [_mask(5, 5)])\n    assert (values_1[2].shape == (1, 5, 5))\n    assert (values_1[5].shape == (1, 5, 5))\n    if use_targets:\n        np.testing.assert_array_equal(targets_1, [56])\n    else:\n        assert (targets_1 is None)", "ground_truth": "(2, 6, 4)", "quality_analysis": {"complexity_score": 7, "left_complexity": 2, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_1033", "reponame": "stellargraph", "testpath": "tests/mapper/test_padded_graph_generator.py", "testname": "test_padded_graph_generator.py", "classname": null, "funcname": "test_generator_pairs", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper.padded_graph_generator import PaddedGraphGenerator, PaddedGraphSequence", "import numpy as np", "import pytest", "from ..test_utils.graphs import example_graph_random, example_graph, example_hin_1"], "code": "@pytest.mark.parametrize('use_targets', [False, True])\n@pytest.mark.parametrize('use_ilocs', [False, True])\ndef test_generator_pairs(use_targets, use_ilocs):\n    generator = PaddedGraphGenerator(graphs=graphs)\n    targets = ([12, 34, 56] if use_targets else None)\n    ilocs = [(1, 0), (0, 2), (2, 1)]\n    input = (ilocs if use_ilocs else [[graphs[x] for x in pair] for pair in ilocs])\n    seq = generator.flow(input, targets=targets, batch_size=2)\n    assert (len(seq) == 2)\n    (values_0, targets_0) = seq[0]\n    assert (len(values_0) == 6)\n    assert (values_0[0].shape == (2, 6, 4))\n    assert (values_0[3].shape == (2, 6, 4))\n    np.testing.assert_array_equal(values_0[1], [_mask(5, 6), _mask(6, 6)])\n    np.testing.assert_array_equal(values_0[4], [_mask(6, 6), _mask(3, 6)])\n    assert (values_0[2].shape == (2, 6, 6))\n    assert (values_0[5].shape == (2, 6, 6))\n    if use_targets:\n        np.testing.assert_array_equal(targets_0, [12, 34])\n    else:\n        assert (targets_0 is None)\n    (values_1, targets_1) = seq[1]\n    assert (len(values_1) == 6)\n    assert (values_1[0].shape == (1, 5, 4))\n    assert (values_1[3].shape == (1, 5, 4))\n    np.testing.assert_array_equal(values_1[1], [_mask(3, 5)])\n    np.testing.assert_array_equal(values_1[4], [_mask(5, 5)])\n    assert (values_1[2].shape == (1, 5, 5))\n    assert (values_1[5].shape == (1, 5, 5))\n    if use_targets:\n        np.testing.assert_array_equal(targets_1, [56])\n    else:\n        assert (targets_1 is None)", "masked_code": "@pytest.mark.parametrize('use_targets', [False, True])\n@pytest.mark.parametrize('use_ilocs', [False, True])\ndef test_generator_pairs(use_targets, use_ilocs):\n    generator = PaddedGraphGenerator(graphs=graphs)\n    targets = ([12, 34, 56] if use_targets else None)\n    ilocs = [(1, 0), (0, 2), (2, 1)]\n    input = (ilocs if use_ilocs else [[graphs[x] for x in pair] for pair in ilocs])\n    seq = generator.flow(input, targets=targets, batch_size=2)\n    assert (len(seq) == 2)\n    (values_0, targets_0) = seq[0]\n    assert (len(values_0) == 6)\n    assert (values_0[0].shape == (2, 6, 4))\n    assert (values_0[3].shape == '???')\n    np.testing.assert_array_equal(values_0[1], [_mask(5, 6), _mask(6, 6)])\n    np.testing.assert_array_equal(values_0[4], [_mask(6, 6), _mask(3, 6)])\n    assert (values_0[2].shape == (2, 6, 6))\n    assert (values_0[5].shape == (2, 6, 6))\n    if use_targets:\n        np.testing.assert_array_equal(targets_0, [12, 34])\n    else:\n        assert (targets_0 is None)\n    (values_1, targets_1) = seq[1]\n    assert (len(values_1) == 6)\n    assert (values_1[0].shape == (1, 5, 4))\n    assert (values_1[3].shape == (1, 5, 4))\n    np.testing.assert_array_equal(values_1[1], [_mask(3, 5)])\n    np.testing.assert_array_equal(values_1[4], [_mask(5, 5)])\n    assert (values_1[2].shape == (1, 5, 5))\n    assert (values_1[5].shape == (1, 5, 5))\n    if use_targets:\n        np.testing.assert_array_equal(targets_1, [56])\n    else:\n        assert (targets_1 is None)", "ground_truth": "(2, 6, 4)", "quality_analysis": {"complexity_score": 7, "left_complexity": 2, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_1034", "reponame": "stellargraph", "testpath": "tests/mapper/test_padded_graph_generator.py", "testname": "test_padded_graph_generator.py", "classname": null, "funcname": "test_generator_pairs", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper.padded_graph_generator import PaddedGraphGenerator, PaddedGraphSequence", "import numpy as np", "import pytest", "from ..test_utils.graphs import example_graph_random, example_graph, example_hin_1"], "code": "@pytest.mark.parametrize('use_targets', [False, True])\n@pytest.mark.parametrize('use_ilocs', [False, True])\ndef test_generator_pairs(use_targets, use_ilocs):\n    generator = PaddedGraphGenerator(graphs=graphs)\n    targets = ([12, 34, 56] if use_targets else None)\n    ilocs = [(1, 0), (0, 2), (2, 1)]\n    input = (ilocs if use_ilocs else [[graphs[x] for x in pair] for pair in ilocs])\n    seq = generator.flow(input, targets=targets, batch_size=2)\n    assert (len(seq) == 2)\n    (values_0, targets_0) = seq[0]\n    assert (len(values_0) == 6)\n    assert (values_0[0].shape == (2, 6, 4))\n    assert (values_0[3].shape == (2, 6, 4))\n    np.testing.assert_array_equal(values_0[1], [_mask(5, 6), _mask(6, 6)])\n    np.testing.assert_array_equal(values_0[4], [_mask(6, 6), _mask(3, 6)])\n    assert (values_0[2].shape == (2, 6, 6))\n    assert (values_0[5].shape == (2, 6, 6))\n    if use_targets:\n        np.testing.assert_array_equal(targets_0, [12, 34])\n    else:\n        assert (targets_0 is None)\n    (values_1, targets_1) = seq[1]\n    assert (len(values_1) == 6)\n    assert (values_1[0].shape == (1, 5, 4))\n    assert (values_1[3].shape == (1, 5, 4))\n    np.testing.assert_array_equal(values_1[1], [_mask(3, 5)])\n    np.testing.assert_array_equal(values_1[4], [_mask(5, 5)])\n    assert (values_1[2].shape == (1, 5, 5))\n    assert (values_1[5].shape == (1, 5, 5))\n    if use_targets:\n        np.testing.assert_array_equal(targets_1, [56])\n    else:\n        assert (targets_1 is None)", "masked_code": "@pytest.mark.parametrize('use_targets', [False, True])\n@pytest.mark.parametrize('use_ilocs', [False, True])\ndef test_generator_pairs(use_targets, use_ilocs):\n    generator = PaddedGraphGenerator(graphs=graphs)\n    targets = ([12, 34, 56] if use_targets else None)\n    ilocs = [(1, 0), (0, 2), (2, 1)]\n    input = (ilocs if use_ilocs else [[graphs[x] for x in pair] for pair in ilocs])\n    seq = generator.flow(input, targets=targets, batch_size=2)\n    assert (len(seq) == 2)\n    (values_0, targets_0) = seq[0]\n    assert (len(values_0) == 6)\n    assert (values_0[0].shape == (2, 6, 4))\n    assert (values_0[3].shape == (2, 6, 4))\n    np.testing.assert_array_equal(values_0[1], [_mask(5, 6), _mask(6, 6)])\n    np.testing.assert_array_equal(values_0[4], [_mask(6, 6), _mask(3, 6)])\n    assert (values_0[2].shape == '???')\n    assert (values_0[5].shape == (2, 6, 6))\n    if use_targets:\n        np.testing.assert_array_equal(targets_0, [12, 34])\n    else:\n        assert (targets_0 is None)\n    (values_1, targets_1) = seq[1]\n    assert (len(values_1) == 6)\n    assert (values_1[0].shape == (1, 5, 4))\n    assert (values_1[3].shape == (1, 5, 4))\n    np.testing.assert_array_equal(values_1[1], [_mask(3, 5)])\n    np.testing.assert_array_equal(values_1[4], [_mask(5, 5)])\n    assert (values_1[2].shape == (1, 5, 5))\n    assert (values_1[5].shape == (1, 5, 5))\n    if use_targets:\n        np.testing.assert_array_equal(targets_1, [56])\n    else:\n        assert (targets_1 is None)", "ground_truth": "(2, 6, 6)", "quality_analysis": {"complexity_score": 7, "left_complexity": 2, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_1035", "reponame": "stellargraph", "testpath": "tests/mapper/test_padded_graph_generator.py", "testname": "test_padded_graph_generator.py", "classname": null, "funcname": "test_generator_pairs", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper.padded_graph_generator import PaddedGraphGenerator, PaddedGraphSequence", "import numpy as np", "import pytest", "from ..test_utils.graphs import example_graph_random, example_graph, example_hin_1"], "code": "@pytest.mark.parametrize('use_targets', [False, True])\n@pytest.mark.parametrize('use_ilocs', [False, True])\ndef test_generator_pairs(use_targets, use_ilocs):\n    generator = PaddedGraphGenerator(graphs=graphs)\n    targets = ([12, 34, 56] if use_targets else None)\n    ilocs = [(1, 0), (0, 2), (2, 1)]\n    input = (ilocs if use_ilocs else [[graphs[x] for x in pair] for pair in ilocs])\n    seq = generator.flow(input, targets=targets, batch_size=2)\n    assert (len(seq) == 2)\n    (values_0, targets_0) = seq[0]\n    assert (len(values_0) == 6)\n    assert (values_0[0].shape == (2, 6, 4))\n    assert (values_0[3].shape == (2, 6, 4))\n    np.testing.assert_array_equal(values_0[1], [_mask(5, 6), _mask(6, 6)])\n    np.testing.assert_array_equal(values_0[4], [_mask(6, 6), _mask(3, 6)])\n    assert (values_0[2].shape == (2, 6, 6))\n    assert (values_0[5].shape == (2, 6, 6))\n    if use_targets:\n        np.testing.assert_array_equal(targets_0, [12, 34])\n    else:\n        assert (targets_0 is None)\n    (values_1, targets_1) = seq[1]\n    assert (len(values_1) == 6)\n    assert (values_1[0].shape == (1, 5, 4))\n    assert (values_1[3].shape == (1, 5, 4))\n    np.testing.assert_array_equal(values_1[1], [_mask(3, 5)])\n    np.testing.assert_array_equal(values_1[4], [_mask(5, 5)])\n    assert (values_1[2].shape == (1, 5, 5))\n    assert (values_1[5].shape == (1, 5, 5))\n    if use_targets:\n        np.testing.assert_array_equal(targets_1, [56])\n    else:\n        assert (targets_1 is None)", "masked_code": "@pytest.mark.parametrize('use_targets', [False, True])\n@pytest.mark.parametrize('use_ilocs', [False, True])\ndef test_generator_pairs(use_targets, use_ilocs):\n    generator = PaddedGraphGenerator(graphs=graphs)\n    targets = ([12, 34, 56] if use_targets else None)\n    ilocs = [(1, 0), (0, 2), (2, 1)]\n    input = (ilocs if use_ilocs else [[graphs[x] for x in pair] for pair in ilocs])\n    seq = generator.flow(input, targets=targets, batch_size=2)\n    assert (len(seq) == 2)\n    (values_0, targets_0) = seq[0]\n    assert (len(values_0) == 6)\n    assert (values_0[0].shape == (2, 6, 4))\n    assert (values_0[3].shape == (2, 6, 4))\n    np.testing.assert_array_equal(values_0[1], [_mask(5, 6), _mask(6, 6)])\n    np.testing.assert_array_equal(values_0[4], [_mask(6, 6), _mask(3, 6)])\n    assert (values_0[2].shape == (2, 6, 6))\n    assert (values_0[5].shape == '???')\n    if use_targets:\n        np.testing.assert_array_equal(targets_0, [12, 34])\n    else:\n        assert (targets_0 is None)\n    (values_1, targets_1) = seq[1]\n    assert (len(values_1) == 6)\n    assert (values_1[0].shape == (1, 5, 4))\n    assert (values_1[3].shape == (1, 5, 4))\n    np.testing.assert_array_equal(values_1[1], [_mask(3, 5)])\n    np.testing.assert_array_equal(values_1[4], [_mask(5, 5)])\n    assert (values_1[2].shape == (1, 5, 5))\n    assert (values_1[5].shape == (1, 5, 5))\n    if use_targets:\n        np.testing.assert_array_equal(targets_1, [56])\n    else:\n        assert (targets_1 is None)", "ground_truth": "(2, 6, 6)", "quality_analysis": {"complexity_score": 7, "left_complexity": 2, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_1036", "reponame": "stellargraph", "testpath": "tests/mapper/test_padded_graph_generator.py", "testname": "test_padded_graph_generator.py", "classname": null, "funcname": "test_generator_pairs", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper.padded_graph_generator import PaddedGraphGenerator, PaddedGraphSequence", "import numpy as np", "import pytest", "from ..test_utils.graphs import example_graph_random, example_graph, example_hin_1"], "code": "@pytest.mark.parametrize('use_targets', [False, True])\n@pytest.mark.parametrize('use_ilocs', [False, True])\ndef test_generator_pairs(use_targets, use_ilocs):\n    generator = PaddedGraphGenerator(graphs=graphs)\n    targets = ([12, 34, 56] if use_targets else None)\n    ilocs = [(1, 0), (0, 2), (2, 1)]\n    input = (ilocs if use_ilocs else [[graphs[x] for x in pair] for pair in ilocs])\n    seq = generator.flow(input, targets=targets, batch_size=2)\n    assert (len(seq) == 2)\n    (values_0, targets_0) = seq[0]\n    assert (len(values_0) == 6)\n    assert (values_0[0].shape == (2, 6, 4))\n    assert (values_0[3].shape == (2, 6, 4))\n    np.testing.assert_array_equal(values_0[1], [_mask(5, 6), _mask(6, 6)])\n    np.testing.assert_array_equal(values_0[4], [_mask(6, 6), _mask(3, 6)])\n    assert (values_0[2].shape == (2, 6, 6))\n    assert (values_0[5].shape == (2, 6, 6))\n    if use_targets:\n        np.testing.assert_array_equal(targets_0, [12, 34])\n    else:\n        assert (targets_0 is None)\n    (values_1, targets_1) = seq[1]\n    assert (len(values_1) == 6)\n    assert (values_1[0].shape == (1, 5, 4))\n    assert (values_1[3].shape == (1, 5, 4))\n    np.testing.assert_array_equal(values_1[1], [_mask(3, 5)])\n    np.testing.assert_array_equal(values_1[4], [_mask(5, 5)])\n    assert (values_1[2].shape == (1, 5, 5))\n    assert (values_1[5].shape == (1, 5, 5))\n    if use_targets:\n        np.testing.assert_array_equal(targets_1, [56])\n    else:\n        assert (targets_1 is None)", "masked_code": "@pytest.mark.parametrize('use_targets', [False, True])\n@pytest.mark.parametrize('use_ilocs', [False, True])\ndef test_generator_pairs(use_targets, use_ilocs):\n    generator = PaddedGraphGenerator(graphs=graphs)\n    targets = ([12, 34, 56] if use_targets else None)\n    ilocs = [(1, 0), (0, 2), (2, 1)]\n    input = (ilocs if use_ilocs else [[graphs[x] for x in pair] for pair in ilocs])\n    seq = generator.flow(input, targets=targets, batch_size=2)\n    assert (len(seq) == 2)\n    (values_0, targets_0) = seq[0]\n    assert (len(values_0) == 6)\n    assert (values_0[0].shape == (2, 6, 4))\n    assert (values_0[3].shape == (2, 6, 4))\n    np.testing.assert_array_equal(values_0[1], [_mask(5, 6), _mask(6, 6)])\n    np.testing.assert_array_equal(values_0[4], [_mask(6, 6), _mask(3, 6)])\n    assert (values_0[2].shape == (2, 6, 6))\n    assert (values_0[5].shape == (2, 6, 6))\n    if use_targets:\n        np.testing.assert_array_equal(targets_0, [12, 34])\n    else:\n        assert (targets_0 is None)\n    (values_1, targets_1) = seq[1]\n    assert (len(values_1) == '???')\n    assert (values_1[0].shape == (1, 5, 4))\n    assert (values_1[3].shape == (1, 5, 4))\n    np.testing.assert_array_equal(values_1[1], [_mask(3, 5)])\n    np.testing.assert_array_equal(values_1[4], [_mask(5, 5)])\n    assert (values_1[2].shape == (1, 5, 5))\n    assert (values_1[5].shape == (1, 5, 5))\n    if use_targets:\n        np.testing.assert_array_equal(targets_1, [56])\n    else:\n        assert (targets_1 is None)", "ground_truth": "6", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_1037", "reponame": "stellargraph", "testpath": "tests/mapper/test_padded_graph_generator.py", "testname": "test_padded_graph_generator.py", "classname": null, "funcname": "test_generator_pairs", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper.padded_graph_generator import PaddedGraphGenerator, PaddedGraphSequence", "import numpy as np", "import pytest", "from ..test_utils.graphs import example_graph_random, example_graph, example_hin_1"], "code": "@pytest.mark.parametrize('use_targets', [False, True])\n@pytest.mark.parametrize('use_ilocs', [False, True])\ndef test_generator_pairs(use_targets, use_ilocs):\n    generator = PaddedGraphGenerator(graphs=graphs)\n    targets = ([12, 34, 56] if use_targets else None)\n    ilocs = [(1, 0), (0, 2), (2, 1)]\n    input = (ilocs if use_ilocs else [[graphs[x] for x in pair] for pair in ilocs])\n    seq = generator.flow(input, targets=targets, batch_size=2)\n    assert (len(seq) == 2)\n    (values_0, targets_0) = seq[0]\n    assert (len(values_0) == 6)\n    assert (values_0[0].shape == (2, 6, 4))\n    assert (values_0[3].shape == (2, 6, 4))\n    np.testing.assert_array_equal(values_0[1], [_mask(5, 6), _mask(6, 6)])\n    np.testing.assert_array_equal(values_0[4], [_mask(6, 6), _mask(3, 6)])\n    assert (values_0[2].shape == (2, 6, 6))\n    assert (values_0[5].shape == (2, 6, 6))\n    if use_targets:\n        np.testing.assert_array_equal(targets_0, [12, 34])\n    else:\n        assert (targets_0 is None)\n    (values_1, targets_1) = seq[1]\n    assert (len(values_1) == 6)\n    assert (values_1[0].shape == (1, 5, 4))\n    assert (values_1[3].shape == (1, 5, 4))\n    np.testing.assert_array_equal(values_1[1], [_mask(3, 5)])\n    np.testing.assert_array_equal(values_1[4], [_mask(5, 5)])\n    assert (values_1[2].shape == (1, 5, 5))\n    assert (values_1[5].shape == (1, 5, 5))\n    if use_targets:\n        np.testing.assert_array_equal(targets_1, [56])\n    else:\n        assert (targets_1 is None)", "masked_code": "@pytest.mark.parametrize('use_targets', [False, True])\n@pytest.mark.parametrize('use_ilocs', [False, True])\ndef test_generator_pairs(use_targets, use_ilocs):\n    generator = PaddedGraphGenerator(graphs=graphs)\n    targets = ([12, 34, 56] if use_targets else None)\n    ilocs = [(1, 0), (0, 2), (2, 1)]\n    input = (ilocs if use_ilocs else [[graphs[x] for x in pair] for pair in ilocs])\n    seq = generator.flow(input, targets=targets, batch_size=2)\n    assert (len(seq) == 2)\n    (values_0, targets_0) = seq[0]\n    assert (len(values_0) == 6)\n    assert (values_0[0].shape == (2, 6, 4))\n    assert (values_0[3].shape == (2, 6, 4))\n    np.testing.assert_array_equal(values_0[1], [_mask(5, 6), _mask(6, 6)])\n    np.testing.assert_array_equal(values_0[4], [_mask(6, 6), _mask(3, 6)])\n    assert (values_0[2].shape == (2, 6, 6))\n    assert (values_0[5].shape == (2, 6, 6))\n    if use_targets:\n        np.testing.assert_array_equal(targets_0, [12, 34])\n    else:\n        assert (targets_0 is None)\n    (values_1, targets_1) = seq[1]\n    assert (len(values_1) == 6)\n    assert (values_1[0].shape == '???')\n    assert (values_1[3].shape == (1, 5, 4))\n    np.testing.assert_array_equal(values_1[1], [_mask(3, 5)])\n    np.testing.assert_array_equal(values_1[4], [_mask(5, 5)])\n    assert (values_1[2].shape == (1, 5, 5))\n    assert (values_1[5].shape == (1, 5, 5))\n    if use_targets:\n        np.testing.assert_array_equal(targets_1, [56])\n    else:\n        assert (targets_1 is None)", "ground_truth": "(1, 5, 4)", "quality_analysis": {"complexity_score": 7, "left_complexity": 2, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_1038", "reponame": "stellargraph", "testpath": "tests/mapper/test_padded_graph_generator.py", "testname": "test_padded_graph_generator.py", "classname": null, "funcname": "test_generator_pairs", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper.padded_graph_generator import PaddedGraphGenerator, PaddedGraphSequence", "import numpy as np", "import pytest", "from ..test_utils.graphs import example_graph_random, example_graph, example_hin_1"], "code": "@pytest.mark.parametrize('use_targets', [False, True])\n@pytest.mark.parametrize('use_ilocs', [False, True])\ndef test_generator_pairs(use_targets, use_ilocs):\n    generator = PaddedGraphGenerator(graphs=graphs)\n    targets = ([12, 34, 56] if use_targets else None)\n    ilocs = [(1, 0), (0, 2), (2, 1)]\n    input = (ilocs if use_ilocs else [[graphs[x] for x in pair] for pair in ilocs])\n    seq = generator.flow(input, targets=targets, batch_size=2)\n    assert (len(seq) == 2)\n    (values_0, targets_0) = seq[0]\n    assert (len(values_0) == 6)\n    assert (values_0[0].shape == (2, 6, 4))\n    assert (values_0[3].shape == (2, 6, 4))\n    np.testing.assert_array_equal(values_0[1], [_mask(5, 6), _mask(6, 6)])\n    np.testing.assert_array_equal(values_0[4], [_mask(6, 6), _mask(3, 6)])\n    assert (values_0[2].shape == (2, 6, 6))\n    assert (values_0[5].shape == (2, 6, 6))\n    if use_targets:\n        np.testing.assert_array_equal(targets_0, [12, 34])\n    else:\n        assert (targets_0 is None)\n    (values_1, targets_1) = seq[1]\n    assert (len(values_1) == 6)\n    assert (values_1[0].shape == (1, 5, 4))\n    assert (values_1[3].shape == (1, 5, 4))\n    np.testing.assert_array_equal(values_1[1], [_mask(3, 5)])\n    np.testing.assert_array_equal(values_1[4], [_mask(5, 5)])\n    assert (values_1[2].shape == (1, 5, 5))\n    assert (values_1[5].shape == (1, 5, 5))\n    if use_targets:\n        np.testing.assert_array_equal(targets_1, [56])\n    else:\n        assert (targets_1 is None)", "masked_code": "@pytest.mark.parametrize('use_targets', [False, True])\n@pytest.mark.parametrize('use_ilocs', [False, True])\ndef test_generator_pairs(use_targets, use_ilocs):\n    generator = PaddedGraphGenerator(graphs=graphs)\n    targets = ([12, 34, 56] if use_targets else None)\n    ilocs = [(1, 0), (0, 2), (2, 1)]\n    input = (ilocs if use_ilocs else [[graphs[x] for x in pair] for pair in ilocs])\n    seq = generator.flow(input, targets=targets, batch_size=2)\n    assert (len(seq) == 2)\n    (values_0, targets_0) = seq[0]\n    assert (len(values_0) == 6)\n    assert (values_0[0].shape == (2, 6, 4))\n    assert (values_0[3].shape == (2, 6, 4))\n    np.testing.assert_array_equal(values_0[1], [_mask(5, 6), _mask(6, 6)])\n    np.testing.assert_array_equal(values_0[4], [_mask(6, 6), _mask(3, 6)])\n    assert (values_0[2].shape == (2, 6, 6))\n    assert (values_0[5].shape == (2, 6, 6))\n    if use_targets:\n        np.testing.assert_array_equal(targets_0, [12, 34])\n    else:\n        assert (targets_0 is None)\n    (values_1, targets_1) = seq[1]\n    assert (len(values_1) == 6)\n    assert (values_1[0].shape == (1, 5, 4))\n    assert (values_1[3].shape == '???')\n    np.testing.assert_array_equal(values_1[1], [_mask(3, 5)])\n    np.testing.assert_array_equal(values_1[4], [_mask(5, 5)])\n    assert (values_1[2].shape == (1, 5, 5))\n    assert (values_1[5].shape == (1, 5, 5))\n    if use_targets:\n        np.testing.assert_array_equal(targets_1, [56])\n    else:\n        assert (targets_1 is None)", "ground_truth": "(1, 5, 4)", "quality_analysis": {"complexity_score": 7, "left_complexity": 2, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_1039", "reponame": "stellargraph", "testpath": "tests/mapper/test_padded_graph_generator.py", "testname": "test_padded_graph_generator.py", "classname": null, "funcname": "test_generator_pairs", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper.padded_graph_generator import PaddedGraphGenerator, PaddedGraphSequence", "import numpy as np", "import pytest", "from ..test_utils.graphs import example_graph_random, example_graph, example_hin_1"], "code": "@pytest.mark.parametrize('use_targets', [False, True])\n@pytest.mark.parametrize('use_ilocs', [False, True])\ndef test_generator_pairs(use_targets, use_ilocs):\n    generator = PaddedGraphGenerator(graphs=graphs)\n    targets = ([12, 34, 56] if use_targets else None)\n    ilocs = [(1, 0), (0, 2), (2, 1)]\n    input = (ilocs if use_ilocs else [[graphs[x] for x in pair] for pair in ilocs])\n    seq = generator.flow(input, targets=targets, batch_size=2)\n    assert (len(seq) == 2)\n    (values_0, targets_0) = seq[0]\n    assert (len(values_0) == 6)\n    assert (values_0[0].shape == (2, 6, 4))\n    assert (values_0[3].shape == (2, 6, 4))\n    np.testing.assert_array_equal(values_0[1], [_mask(5, 6), _mask(6, 6)])\n    np.testing.assert_array_equal(values_0[4], [_mask(6, 6), _mask(3, 6)])\n    assert (values_0[2].shape == (2, 6, 6))\n    assert (values_0[5].shape == (2, 6, 6))\n    if use_targets:\n        np.testing.assert_array_equal(targets_0, [12, 34])\n    else:\n        assert (targets_0 is None)\n    (values_1, targets_1) = seq[1]\n    assert (len(values_1) == 6)\n    assert (values_1[0].shape == (1, 5, 4))\n    assert (values_1[3].shape == (1, 5, 4))\n    np.testing.assert_array_equal(values_1[1], [_mask(3, 5)])\n    np.testing.assert_array_equal(values_1[4], [_mask(5, 5)])\n    assert (values_1[2].shape == (1, 5, 5))\n    assert (values_1[5].shape == (1, 5, 5))\n    if use_targets:\n        np.testing.assert_array_equal(targets_1, [56])\n    else:\n        assert (targets_1 is None)", "masked_code": "@pytest.mark.parametrize('use_targets', [False, True])\n@pytest.mark.parametrize('use_ilocs', [False, True])\ndef test_generator_pairs(use_targets, use_ilocs):\n    generator = PaddedGraphGenerator(graphs=graphs)\n    targets = ([12, 34, 56] if use_targets else None)\n    ilocs = [(1, 0), (0, 2), (2, 1)]\n    input = (ilocs if use_ilocs else [[graphs[x] for x in pair] for pair in ilocs])\n    seq = generator.flow(input, targets=targets, batch_size=2)\n    assert (len(seq) == 2)\n    (values_0, targets_0) = seq[0]\n    assert (len(values_0) == 6)\n    assert (values_0[0].shape == (2, 6, 4))\n    assert (values_0[3].shape == (2, 6, 4))\n    np.testing.assert_array_equal(values_0[1], [_mask(5, 6), _mask(6, 6)])\n    np.testing.assert_array_equal(values_0[4], [_mask(6, 6), _mask(3, 6)])\n    assert (values_0[2].shape == (2, 6, 6))\n    assert (values_0[5].shape == (2, 6, 6))\n    if use_targets:\n        np.testing.assert_array_equal(targets_0, [12, 34])\n    else:\n        assert (targets_0 is None)\n    (values_1, targets_1) = seq[1]\n    assert (len(values_1) == 6)\n    assert (values_1[0].shape == (1, 5, 4))\n    assert (values_1[3].shape == (1, 5, 4))\n    np.testing.assert_array_equal(values_1[1], [_mask(3, 5)])\n    np.testing.assert_array_equal(values_1[4], [_mask(5, 5)])\n    assert (values_1[2].shape == '???')\n    assert (values_1[5].shape == (1, 5, 5))\n    if use_targets:\n        np.testing.assert_array_equal(targets_1, [56])\n    else:\n        assert (targets_1 is None)", "ground_truth": "(1, 5, 5)", "quality_analysis": {"complexity_score": 7, "left_complexity": 2, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_1040", "reponame": "stellargraph", "testpath": "tests/mapper/test_padded_graph_generator.py", "testname": "test_padded_graph_generator.py", "classname": null, "funcname": "test_generator_pairs", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper.padded_graph_generator import PaddedGraphGenerator, PaddedGraphSequence", "import numpy as np", "import pytest", "from ..test_utils.graphs import example_graph_random, example_graph, example_hin_1"], "code": "@pytest.mark.parametrize('use_targets', [False, True])\n@pytest.mark.parametrize('use_ilocs', [False, True])\ndef test_generator_pairs(use_targets, use_ilocs):\n    generator = PaddedGraphGenerator(graphs=graphs)\n    targets = ([12, 34, 56] if use_targets else None)\n    ilocs = [(1, 0), (0, 2), (2, 1)]\n    input = (ilocs if use_ilocs else [[graphs[x] for x in pair] for pair in ilocs])\n    seq = generator.flow(input, targets=targets, batch_size=2)\n    assert (len(seq) == 2)\n    (values_0, targets_0) = seq[0]\n    assert (len(values_0) == 6)\n    assert (values_0[0].shape == (2, 6, 4))\n    assert (values_0[3].shape == (2, 6, 4))\n    np.testing.assert_array_equal(values_0[1], [_mask(5, 6), _mask(6, 6)])\n    np.testing.assert_array_equal(values_0[4], [_mask(6, 6), _mask(3, 6)])\n    assert (values_0[2].shape == (2, 6, 6))\n    assert (values_0[5].shape == (2, 6, 6))\n    if use_targets:\n        np.testing.assert_array_equal(targets_0, [12, 34])\n    else:\n        assert (targets_0 is None)\n    (values_1, targets_1) = seq[1]\n    assert (len(values_1) == 6)\n    assert (values_1[0].shape == (1, 5, 4))\n    assert (values_1[3].shape == (1, 5, 4))\n    np.testing.assert_array_equal(values_1[1], [_mask(3, 5)])\n    np.testing.assert_array_equal(values_1[4], [_mask(5, 5)])\n    assert (values_1[2].shape == (1, 5, 5))\n    assert (values_1[5].shape == (1, 5, 5))\n    if use_targets:\n        np.testing.assert_array_equal(targets_1, [56])\n    else:\n        assert (targets_1 is None)", "masked_code": "@pytest.mark.parametrize('use_targets', [False, True])\n@pytest.mark.parametrize('use_ilocs', [False, True])\ndef test_generator_pairs(use_targets, use_ilocs):\n    generator = PaddedGraphGenerator(graphs=graphs)\n    targets = ([12, 34, 56] if use_targets else None)\n    ilocs = [(1, 0), (0, 2), (2, 1)]\n    input = (ilocs if use_ilocs else [[graphs[x] for x in pair] for pair in ilocs])\n    seq = generator.flow(input, targets=targets, batch_size=2)\n    assert (len(seq) == 2)\n    (values_0, targets_0) = seq[0]\n    assert (len(values_0) == 6)\n    assert (values_0[0].shape == (2, 6, 4))\n    assert (values_0[3].shape == (2, 6, 4))\n    np.testing.assert_array_equal(values_0[1], [_mask(5, 6), _mask(6, 6)])\n    np.testing.assert_array_equal(values_0[4], [_mask(6, 6), _mask(3, 6)])\n    assert (values_0[2].shape == (2, 6, 6))\n    assert (values_0[5].shape == (2, 6, 6))\n    if use_targets:\n        np.testing.assert_array_equal(targets_0, [12, 34])\n    else:\n        assert (targets_0 is None)\n    (values_1, targets_1) = seq[1]\n    assert (len(values_1) == 6)\n    assert (values_1[0].shape == (1, 5, 4))\n    assert (values_1[3].shape == (1, 5, 4))\n    np.testing.assert_array_equal(values_1[1], [_mask(3, 5)])\n    np.testing.assert_array_equal(values_1[4], [_mask(5, 5)])\n    assert (values_1[2].shape == (1, 5, 5))\n    assert (values_1[5].shape == '???')\n    if use_targets:\n        np.testing.assert_array_equal(targets_1, [56])\n    else:\n        assert (targets_1 is None)", "ground_truth": "(1, 5, 5)", "quality_analysis": {"complexity_score": 7, "left_complexity": 2, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_1041", "reponame": "stellargraph", "testpath": "tests/mapper/test_relational_node_mappers.py", "testname": "test_relational_node_mappers.py", "classname": "Test_RelationalFullBatchNodeGenerator", "funcname": "test_generator_constructor", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper.full_batch_generators import RelationalFullBatchNodeGenerator", "import networkx as nx", "import numpy as np", "import pytest", "import pandas as pd", "import scipy.sparse as sps", "from ..test_utils.graphs import relational_create_graph_features as create_graph_features, example_hin_1"], "code": "def test_generator_constructor(self):\n    generator = RelationalFullBatchNodeGenerator(self.G)\n    assert (len(generator.As) == self.num_relationships)\n    assert all(((A.shape == (self.N, self.N)) for A in generator.As))\n    assert (generator.features.shape == (self.N, self.n_feat))", "masked_code": "def test_generator_constructor(self):\n    generator = RelationalFullBatchNodeGenerator(self.G)\n    assert (len(generator.As) == '???')\n    assert all(((A.shape == (self.N, self.N)) for A in generator.As))\n    assert (generator.features.shape == (self.N, self.n_feat))", "ground_truth": "self.num_relationships", "quality_analysis": {"complexity_score": 7, "left_complexity": 5, "right_complexity": 2, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_1042", "reponame": "stellargraph", "testpath": "tests/mapper/test_relational_node_mappers.py", "testname": "test_relational_node_mappers.py", "classname": "Test_RelationalFullBatchNodeGenerator", "funcname": "test_generator_constructor", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper.full_batch_generators import RelationalFullBatchNodeGenerator", "import networkx as nx", "import numpy as np", "import pytest", "import pandas as pd", "import scipy.sparse as sps", "from ..test_utils.graphs import relational_create_graph_features as create_graph_features, example_hin_1"], "code": "def test_generator_constructor(self):\n    generator = RelationalFullBatchNodeGenerator(self.G)\n    assert (len(generator.As) == self.num_relationships)\n    assert all(((A.shape == (self.N, self.N)) for A in generator.As))\n    assert (generator.features.shape == (self.N, self.n_feat))", "masked_code": "def test_generator_constructor(self):\n    generator = RelationalFullBatchNodeGenerator(self.G)\n    assert (len(generator.As) == self.num_relationships)\n    assert all(((A.shape == (self.N, self.N)) for A in generator.As))\n    assert (generator.features.shape == '???')", "ground_truth": "(self.N, self.n_feat)", "quality_analysis": {"complexity_score": 8, "left_complexity": 2, "right_complexity": 6, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_1043", "reponame": "stellargraph", "testpath": "tests/mapper/test_relational_node_mappers.py", "testname": "test_relational_node_mappers.py", "classname": "Test_RelationalFullBatchNodeGenerator", "funcname": "test_generator_flow_targets_as_list", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper.full_batch_generators import RelationalFullBatchNodeGenerator", "import networkx as nx", "import numpy as np", "import pytest", "import pandas as pd", "import scipy.sparse as sps", "from ..test_utils.graphs import relational_create_graph_features as create_graph_features, example_hin_1"], "code": "def test_generator_flow_targets_as_list(self):\n    generator = RelationalFullBatchNodeGenerator(self.G)\n    node_ids = list(self.G.nodes())[:3]\n    node_targets = ([1] * len(node_ids))\n    gen = generator.flow(node_ids, node_targets)\n    (inputs, y) = gen[0]\n    assert (y.shape == (1, 3))\n    assert (np.sum(y) == 3)", "masked_code": "def test_generator_flow_targets_as_list(self):\n    generator = RelationalFullBatchNodeGenerator(self.G)\n    node_ids = list(self.G.nodes())[:3]\n    node_targets = ([1] * len(node_ids))\n    gen = generator.flow(node_ids, node_targets)\n    (inputs, y) = gen[0]\n    assert (y.shape == '???')\n    assert (np.sum(y) == 3)", "ground_truth": "(1, 3)", "quality_analysis": {"complexity_score": 6, "left_complexity": 2, "right_complexity": 4, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_1044", "reponame": "stellargraph", "testpath": "tests/mapper/test_relational_node_mappers.py", "testname": "test_relational_node_mappers.py", "classname": "Test_RelationalFullBatchNodeGenerator", "funcname": "test_generator_flow_targets_as_list", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper.full_batch_generators import RelationalFullBatchNodeGenerator", "import networkx as nx", "import numpy as np", "import pytest", "import pandas as pd", "import scipy.sparse as sps", "from ..test_utils.graphs import relational_create_graph_features as create_graph_features, example_hin_1"], "code": "def test_generator_flow_targets_as_list(self):\n    generator = RelationalFullBatchNodeGenerator(self.G)\n    node_ids = list(self.G.nodes())[:3]\n    node_targets = ([1] * len(node_ids))\n    gen = generator.flow(node_ids, node_targets)\n    (inputs, y) = gen[0]\n    assert (y.shape == (1, 3))\n    assert (np.sum(y) == 3)", "masked_code": "def test_generator_flow_targets_as_list(self):\n    generator = RelationalFullBatchNodeGenerator(self.G)\n    node_ids = list(self.G.nodes())[:3]\n    node_targets = ([1] * len(node_ids))\n    gen = generator.flow(node_ids, node_targets)\n    (inputs, y) = gen[0]\n    assert (y.shape == (1, 3))\n    assert (np.sum(y) == '???')", "ground_truth": "3", "quality_analysis": {"complexity_score": 5, "left_complexity": 4, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_1045", "reponame": "stellargraph", "testpath": "tests/mapper/test_relational_node_mappers.py", "testname": "test_relational_node_mappers.py", "classname": "Test_RelationalFullBatchNodeGenerator", "funcname": "test_fullbatch_generator_init_1", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper.full_batch_generators import RelationalFullBatchNodeGenerator", "import networkx as nx", "import numpy as np", "import pytest", "import pandas as pd", "import scipy.sparse as sps", "from ..test_utils.graphs import relational_create_graph_features as create_graph_features, example_hin_1"], "code": "def test_fullbatch_generator_init_1(self):\n    (G, feats) = create_graph_features()\n    generator = RelationalFullBatchNodeGenerator(G, name='test')\n    assert (generator.name == 'test')\n    np.testing.assert_array_equal(feats, generator.features)", "masked_code": "def test_fullbatch_generator_init_1(self):\n    (G, feats) = create_graph_features()\n    generator = RelationalFullBatchNodeGenerator(G, name='test')\n    assert (generator.name == '???')\n    np.testing.assert_array_equal(feats, generator.features)", "ground_truth": "'test'", "quality_analysis": {"complexity_score": 3, "left_complexity": 2, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_1046", "reponame": "stellargraph", "testpath": "tests/mapper/test_relational_node_mappers.py", "testname": "test_relational_node_mappers.py", "classname": "Test_RelationalFullBatchNodeGenerator", "funcname": "test_fullbatch_generator_transform", "imports": ["from stellargraph.core.graph import *", "from stellargraph.mapper.full_batch_generators import RelationalFullBatchNodeGenerator", "import networkx as nx", "import numpy as np", "import pytest", "import pandas as pd", "import scipy.sparse as sps", "from ..test_utils.graphs import relational_create_graph_features as create_graph_features, example_hin_1"], "code": "def test_fullbatch_generator_transform(self):\n    (G, _) = create_graph_features(is_directed=True)\n\n    def func(features, A, **kwargs):\n        return (features, A.dot(A))\n    generator = RelationalFullBatchNodeGenerator(G, 'test', transform=func)\n    assert (generator.name == 'test')\n    As = []\n    edge_types = sorted(set((e[(- 1)] for e in G.edges(include_edge_type=True))))\n    node_list = list(G.nodes())\n    node_index = dict(zip(node_list, range(len(node_list))))\n    for edge_type in edge_types:\n        col_index = [node_index[n1] for (n1, n2, etype) in G.edges(include_edge_type=True) if (etype == edge_type)]\n        row_index = [node_index[n2] for (n1, n2, etype) in G.edges(include_edge_type=True) if (etype == edge_type)]\n        data = np.ones(len(col_index), np.float64)\n        A = sps.coo_matrix((data, (row_index, col_index)), shape=(len(node_list), len(node_list)))\n        As.append(A)\n    for (A_1, A_2) in zip(As, generator.As):\n        np.testing.assert_array_equal(A_1.dot(A_1).todense(), A_2.todense())", "masked_code": "def test_fullbatch_generator_transform(self):\n    (G, _) = create_graph_features(is_directed=True)\n\n    def func(features, A, **kwargs):\n        return (features, A.dot(A))\n    generator = RelationalFullBatchNodeGenerator(G, 'test', transform=func)\n    assert (generator.name == '???')\n    As = []\n    edge_types = sorted(set((e[(- 1)] for e in G.edges(include_edge_type=True))))\n    node_list = list(G.nodes())\n    node_index = dict(zip(node_list, range(len(node_list))))\n    for edge_type in edge_types:\n        col_index = [node_index[n1] for (n1, n2, etype) in G.edges(include_edge_type=True) if (etype == edge_type)]\n        row_index = [node_index[n2] for (n1, n2, etype) in G.edges(include_edge_type=True) if (etype == edge_type)]\n        data = np.ones(len(col_index), np.float64)\n        A = sps.coo_matrix((data, (row_index, col_index)), shape=(len(node_list), len(node_list)))\n        As.append(A)\n    for (A_1, A_2) in zip(As, generator.As):\n        np.testing.assert_array_equal(A_1.dot(A_1).todense(), A_2.todense())", "ground_truth": "'test'", "quality_analysis": {"complexity_score": 3, "left_complexity": 2, "right_complexity": 1, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_1047", "reponame": "stellargraph", "testpath": "tests/utils/test_hyperbolic.py", "testname": "test_hyperbolic.py", "classname": null, "funcname": "test_poincare_ball_exp_specialisation", "imports": ["import pytest", "import numpy as np", "from stellargraph.utils.hyperbolic import *"], "code": "def test_poincare_ball_exp_specialisation(seeded):\n    for _ in range(100):\n        (c, _vs) = _generate(0)\n        (_c, vs) = _generate(17, euclidean_max_norm=1000)\n        specialised = poincare_ball_exp(c, None, vs)\n        assert (specialised.shape == vs.shape)\n        actual = poincare_ball_exp(c, np.zeros_like(vs), vs)\n        np.testing.assert_allclose(specialised.numpy(), actual.numpy())", "masked_code": "def test_poincare_ball_exp_specialisation(seeded):\n    for _ in range(100):\n        (c, _vs) = _generate(0)\n        (_c, vs) = _generate(17, euclidean_max_norm=1000)\n        specialised = poincare_ball_exp(c, None, vs)\n        assert (specialised.shape == '???')\n        actual = poincare_ball_exp(c, np.zeros_like(vs), vs)\n        np.testing.assert_allclose(specialised.numpy(), actual.numpy())", "ground_truth": "vs.shape", "quality_analysis": {"complexity_score": 4, "left_complexity": 2, "right_complexity": 2, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_1048", "reponame": "stellargraph", "testpath": "tests/utils/test_hyperbolic.py", "testname": "test_hyperbolic.py", "classname": null, "funcname": "test_poincare_ball_distance_self", "imports": ["import pytest", "import numpy as np", "from stellargraph.utils.hyperbolic import *"], "code": "def test_poincare_ball_distance_self(seeded):\n    for _ in range(100):\n        (c, vs) = _generate(17)\n        d = poincare_ball_distance(c, vs, vs)\n        assert (d.shape == vs.shape[:(- 1)])\n        np.testing.assert_allclose(d, 0, rtol=1e-06, atol=1e-05)", "masked_code": "def test_poincare_ball_distance_self(seeded):\n    for _ in range(100):\n        (c, vs) = _generate(17)\n        d = poincare_ball_distance(c, vs, vs)\n        assert (d.shape == '???')\n        np.testing.assert_allclose(d, 0, rtol=1e-06, atol=1e-05)", "ground_truth": "vs.shape[:(- 1)]", "quality_analysis": {"complexity_score": 7, "left_complexity": 2, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_1049", "reponame": "stellargraph", "testpath": "tests/utils/test_hyperbolic.py", "testname": "test_hyperbolic.py", "classname": null, "funcname": "test_poincare_ball_distance_exp", "imports": ["import pytest", "import numpy as np", "from stellargraph.utils.hyperbolic import *"], "code": "def test_poincare_ball_distance_exp(seeded):\n    for _ in range(100):\n        (c, _vs) = _generate(0)\n        (_c, tangents) = _generate(17, euclidean_max_norm=1e-10)\n        tangent_lengths = np.linalg.norm(tangents, axis=(- 1))\n\n        def check(x, y):\n            d = poincare_ball_distance(c, x, y)\n            assert (d.shape == tangents.shape[:(- 1)])\n            np.testing.assert_allclose(d, (2 * tangent_lengths), rtol=0.001)\n        zeros = np.zeros_like(tangents)\n        zero_moved = poincare_ball_exp(c, None, tangents)\n        assert (zero_moved.shape == tangents.shape)\n        check(zeros, zero_moved)\n        check(zero_moved, zeros)", "masked_code": "def test_poincare_ball_distance_exp(seeded):\n    for _ in range(100):\n        (c, _vs) = _generate(0)\n        (_c, tangents) = _generate(17, euclidean_max_norm=1e-10)\n        tangent_lengths = np.linalg.norm(tangents, axis=(- 1))\n\n        def check(x, y):\n            d = poincare_ball_distance(c, x, y)\n            assert (d.shape == tangents.shape[:(- 1)])\n            np.testing.assert_allclose(d, (2 * tangent_lengths), rtol=0.001)\n        zeros = np.zeros_like(tangents)\n        zero_moved = poincare_ball_exp(c, None, tangents)\n        assert (zero_moved.shape == '???')\n        check(zeros, zero_moved)\n        check(zero_moved, zeros)", "ground_truth": "tangents.shape", "quality_analysis": {"complexity_score": 4, "left_complexity": 2, "right_complexity": 2, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_1050", "reponame": "stellargraph", "testpath": "tests/utils/test_hyperbolic.py", "testname": "test_hyperbolic.py", "classname": null, "funcname": "test_poincare_ball_distance_exp", "imports": ["import pytest", "import numpy as np", "from stellargraph.utils.hyperbolic import *"], "code": "def test_poincare_ball_distance_exp(seeded):\n    for _ in range(100):\n        (c, _vs) = _generate(0)\n        (_c, tangents) = _generate(17, euclidean_max_norm=1e-10)\n        tangent_lengths = np.linalg.norm(tangents, axis=(- 1))\n\n        def check(x, y):\n            d = poincare_ball_distance(c, x, y)\n            assert (d.shape == tangents.shape[:(- 1)])\n            np.testing.assert_allclose(d, (2 * tangent_lengths), rtol=0.001)\n        zeros = np.zeros_like(tangents)\n        zero_moved = poincare_ball_exp(c, None, tangents)\n        assert (zero_moved.shape == tangents.shape)\n        check(zeros, zero_moved)\n        check(zero_moved, zeros)", "masked_code": "def test_poincare_ball_distance_exp(seeded):\n    for _ in range(100):\n        (c, _vs) = _generate(0)\n        (_c, tangents) = _generate(17, euclidean_max_norm=1e-10)\n        tangent_lengths = np.linalg.norm(tangents, axis=(- 1))\n\n        def check(x, y):\n            d = poincare_ball_distance(c, x, y)\n            assert (d.shape == '???')\n            np.testing.assert_allclose(d, (2 * tangent_lengths), rtol=0.001)\n        zeros = np.zeros_like(tangents)\n        zero_moved = poincare_ball_exp(c, None, tangents)\n        assert (zero_moved.shape == tangents.shape)\n        check(zeros, zero_moved)\n        check(zero_moved, zeros)", "ground_truth": "tangents.shape[:(- 1)]", "quality_analysis": {"complexity_score": 7, "left_complexity": 2, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_1051", "reponame": "stellargraph", "testpath": "tests/utils/test_hyperbolic.py", "testname": "test_hyperbolic.py", "classname": null, "funcname": "test_poincare_ball_distance_vs_euclidean", "imports": ["import pytest", "import numpy as np", "from stellargraph.utils.hyperbolic import *"], "code": "def test_poincare_ball_distance_vs_euclidean(seeded):\n    for _ in range(100):\n        (c, vs) = _generate(17, norm_range=(0, 0.01))\n        zeros = np.zeros_like(vs)\n        hyperbolic = poincare_ball_distance(c, zeros, vs)\n        assert (hyperbolic.shape == vs.shape[:(- 1)])\n        euclidean = np.linalg.norm(vs, axis=(- 1))\n        np.testing.assert_allclose(hyperbolic, (2 * euclidean), rtol=0.001, atol=1e-15)\n        (c, vs) = _generate(17, norm_range=(0.99, 1))\n        zeros = np.zeros_like(vs)\n        hyperbolic = poincare_ball_distance(c, zeros, vs)\n        assert (hyperbolic.shape == vs.shape[:(- 1)])\n        euclidean = np.linalg.norm(vs, axis=(- 1))\n        np.testing.assert_array_less((4 * euclidean), hyperbolic)", "masked_code": "def test_poincare_ball_distance_vs_euclidean(seeded):\n    for _ in range(100):\n        (c, vs) = _generate(17, norm_range=(0, 0.01))\n        zeros = np.zeros_like(vs)\n        hyperbolic = poincare_ball_distance(c, zeros, vs)\n        assert (hyperbolic.shape == '???')\n        euclidean = np.linalg.norm(vs, axis=(- 1))\n        np.testing.assert_allclose(hyperbolic, (2 * euclidean), rtol=0.001, atol=1e-15)\n        (c, vs) = _generate(17, norm_range=(0.99, 1))\n        zeros = np.zeros_like(vs)\n        hyperbolic = poincare_ball_distance(c, zeros, vs)\n        assert (hyperbolic.shape == vs.shape[:(- 1)])\n        euclidean = np.linalg.norm(vs, axis=(- 1))\n        np.testing.assert_array_less((4 * euclidean), hyperbolic)", "ground_truth": "vs.shape[:(- 1)]", "quality_analysis": {"complexity_score": 7, "left_complexity": 2, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
{"task_id": "stellargraph_1052", "reponame": "stellargraph", "testpath": "tests/utils/test_hyperbolic.py", "testname": "test_hyperbolic.py", "classname": null, "funcname": "test_poincare_ball_distance_vs_euclidean", "imports": ["import pytest", "import numpy as np", "from stellargraph.utils.hyperbolic import *"], "code": "def test_poincare_ball_distance_vs_euclidean(seeded):\n    for _ in range(100):\n        (c, vs) = _generate(17, norm_range=(0, 0.01))\n        zeros = np.zeros_like(vs)\n        hyperbolic = poincare_ball_distance(c, zeros, vs)\n        assert (hyperbolic.shape == vs.shape[:(- 1)])\n        euclidean = np.linalg.norm(vs, axis=(- 1))\n        np.testing.assert_allclose(hyperbolic, (2 * euclidean), rtol=0.001, atol=1e-15)\n        (c, vs) = _generate(17, norm_range=(0.99, 1))\n        zeros = np.zeros_like(vs)\n        hyperbolic = poincare_ball_distance(c, zeros, vs)\n        assert (hyperbolic.shape == vs.shape[:(- 1)])\n        euclidean = np.linalg.norm(vs, axis=(- 1))\n        np.testing.assert_array_less((4 * euclidean), hyperbolic)", "masked_code": "def test_poincare_ball_distance_vs_euclidean(seeded):\n    for _ in range(100):\n        (c, vs) = _generate(17, norm_range=(0, 0.01))\n        zeros = np.zeros_like(vs)\n        hyperbolic = poincare_ball_distance(c, zeros, vs)\n        assert (hyperbolic.shape == vs.shape[:(- 1)])\n        euclidean = np.linalg.norm(vs, axis=(- 1))\n        np.testing.assert_allclose(hyperbolic, (2 * euclidean), rtol=0.001, atol=1e-15)\n        (c, vs) = _generate(17, norm_range=(0.99, 1))\n        zeros = np.zeros_like(vs)\n        hyperbolic = poincare_ball_distance(c, zeros, vs)\n        assert (hyperbolic.shape == '???')\n        euclidean = np.linalg.norm(vs, axis=(- 1))\n        np.testing.assert_array_less((4 * euclidean), hyperbolic)", "ground_truth": "vs.shape[:(- 1)]", "quality_analysis": {"complexity_score": 7, "left_complexity": 2, "right_complexity": 5, "is_quality": true, "reason": "High quality assertion"}}
